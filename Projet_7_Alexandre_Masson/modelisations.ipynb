{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ad8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, roc_curve, auc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn.neighbors._base\n",
    "from numpy import where\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b91f31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importation du package\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c96b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessing_train.csv')\n",
    "df_test = pd.read_csv('preprocessing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d19810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = pd.read_csv('best_fetaures.csv')\n",
    "feats = best_features['feature'].unique()\n",
    "feats = np.append(feats,'INTERET_CUMULE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627728b5",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "964c55a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>PAYMENT_RATE</td>\n",
       "      <td>3927</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>3926</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>3900</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>3891</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>3853</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>INSTAL_PAYMENT_PERC_VAR</td>\n",
       "      <td>1022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>PREV_AMT_CREDIT_MEAN</td>\n",
       "      <td>1019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>PREV_NAME_TYPE_SUITE_nan_MEAN</td>\n",
       "      <td>994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>APPROVED_AMT_ANNUITY_MAX</td>\n",
       "      <td>979</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>PREV_RATE_DOWN_PAYMENT_MEAN</td>\n",
       "      <td>976</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance  fold\n",
       "320                   PAYMENT_RATE        3927     4\n",
       "112                   EXT_SOURCE_2        3926     2\n",
       "413                   EXT_SOURCE_3        3900     5\n",
       "313                   EXT_SOURCE_3        3891     4\n",
       "212                   EXT_SOURCE_2        3853     3\n",
       "..                             ...         ...   ...\n",
       "290        INSTAL_PAYMENT_PERC_VAR        1022     3\n",
       "459           PREV_AMT_CREDIT_MEAN        1019     5\n",
       "469  PREV_NAME_TYPE_SUITE_nan_MEAN         994     5\n",
       "272       APPROVED_AMT_ANNUITY_MAX         979     3\n",
       "164    PREV_RATE_DOWN_PAYMENT_MEAN         976     2\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "120fe7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>1473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>1311</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>1324</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>1301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "      <td>1395</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance  fold\n",
       "0    AMT_INCOME_TOTAL        1473     1\n",
       "100  AMT_INCOME_TOTAL        1311     2\n",
       "200  AMT_INCOME_TOTAL        1324     3\n",
       "300  AMT_INCOME_TOTAL        1301     4\n",
       "400  AMT_INCOME_TOTAL        1395     5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features[best_features['feature'] == 'AMT_INCOME_TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c36367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1d5cf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307507 entries, 0 to 307506\n",
      "Data columns (total 101 columns):\n",
      " #    Column                                   Dtype  \n",
      "---   ------                                   -----  \n",
      " 0    AMT_INCOME_TOTAL                         float64\n",
      " 1    AMT_CREDIT                               float64\n",
      " 2    AMT_ANNUITY                              float64\n",
      " 3    AMT_GOODS_PRICE                          float64\n",
      " 4    REGION_POPULATION_RELATIVE               float64\n",
      " 5    DAYS_BIRTH                               int64  \n",
      " 6    DAYS_EMPLOYED                            float64\n",
      " 7    DAYS_REGISTRATION                        float64\n",
      " 8    DAYS_ID_PUBLISH                          int64  \n",
      " 9    OWN_CAR_AGE                              float64\n",
      " 10   HOUR_APPR_PROCESS_START                  int64  \n",
      " 11   EXT_SOURCE_1                             float64\n",
      " 12   EXT_SOURCE_2                             float64\n",
      " 13   EXT_SOURCE_3                             float64\n",
      " 14   TOTALAREA_MODE                           float64\n",
      " 15   DAYS_LAST_PHONE_CHANGE                   float64\n",
      " 16   DAYS_EMPLOYED_PERC                       float64\n",
      " 17   INCOME_CREDIT_PERC                       float64\n",
      " 18   INCOME_PER_PERSON                        float64\n",
      " 19   ANNUITY_INCOME_PERC                      float64\n",
      " 20   PAYMENT_RATE                             float64\n",
      " 21   BURO_DAYS_CREDIT_MIN                     float64\n",
      " 22   BURO_DAYS_CREDIT_MAX                     float64\n",
      " 23   BURO_DAYS_CREDIT_MEAN                    float64\n",
      " 24   BURO_DAYS_CREDIT_VAR                     float64\n",
      " 25   BURO_DAYS_CREDIT_ENDDATE_MIN             float64\n",
      " 26   BURO_DAYS_CREDIT_ENDDATE_MAX             float64\n",
      " 27   BURO_DAYS_CREDIT_ENDDATE_MEAN            float64\n",
      " 28   BURO_DAYS_CREDIT_UPDATE_MEAN             float64\n",
      " 29   BURO_AMT_CREDIT_MAX_OVERDUE_MEAN         float64\n",
      " 30   BURO_AMT_CREDIT_SUM_MAX                  float64\n",
      " 31   BURO_AMT_CREDIT_SUM_MEAN                 float64\n",
      " 32   BURO_AMT_CREDIT_SUM_SUM                  float64\n",
      " 33   BURO_AMT_CREDIT_SUM_DEBT_MEAN            float64\n",
      " 34   ACTIVE_DAYS_CREDIT_MIN                   float64\n",
      " 35   ACTIVE_DAYS_CREDIT_MAX                   float64\n",
      " 36   ACTIVE_DAYS_CREDIT_MEAN                  float64\n",
      " 37   ACTIVE_DAYS_CREDIT_VAR                   float64\n",
      " 38   ACTIVE_DAYS_CREDIT_ENDDATE_MIN           float64\n",
      " 39   ACTIVE_DAYS_CREDIT_ENDDATE_MAX           float64\n",
      " 40   ACTIVE_DAYS_CREDIT_ENDDATE_MEAN          float64\n",
      " 41   ACTIVE_DAYS_CREDIT_UPDATE_MEAN           float64\n",
      " 42   ACTIVE_AMT_CREDIT_SUM_MAX                float64\n",
      " 43   ACTIVE_AMT_CREDIT_SUM_MEAN               float64\n",
      " 44   ACTIVE_AMT_CREDIT_SUM_SUM                float64\n",
      " 45   ACTIVE_AMT_CREDIT_SUM_DEBT_MEAN          float64\n",
      " 46   CLOSED_DAYS_CREDIT_MIN                   float64\n",
      " 47   CLOSED_DAYS_CREDIT_MAX                   float64\n",
      " 48   CLOSED_DAYS_CREDIT_MEAN                  float64\n",
      " 49   CLOSED_DAYS_CREDIT_VAR                   float64\n",
      " 50   CLOSED_DAYS_CREDIT_ENDDATE_MIN           float64\n",
      " 51   CLOSED_DAYS_CREDIT_ENDDATE_MAX           float64\n",
      " 52   CLOSED_DAYS_CREDIT_ENDDATE_MEAN          float64\n",
      " 53   CLOSED_DAYS_CREDIT_UPDATE_MEAN           float64\n",
      " 54   CLOSED_AMT_CREDIT_SUM_MAX                float64\n",
      " 55   CLOSED_AMT_CREDIT_SUM_MEAN               float64\n",
      " 56   CLOSED_AMT_CREDIT_SUM_SUM                float64\n",
      " 57   PREV_AMT_ANNUITY_MIN                     float64\n",
      " 58   PREV_AMT_ANNUITY_MEAN                    float64\n",
      " 59   PREV_AMT_CREDIT_MEAN                     float64\n",
      " 60   PREV_APP_CREDIT_PERC_MIN                 float64\n",
      " 61   PREV_APP_CREDIT_PERC_MEAN                float64\n",
      " 62   PREV_APP_CREDIT_PERC_VAR                 float64\n",
      " 63   PREV_HOUR_APPR_PROCESS_START_MEAN        float64\n",
      " 64   PREV_RATE_DOWN_PAYMENT_MEAN              float64\n",
      " 65   PREV_DAYS_DECISION_MAX                   float64\n",
      " 66   PREV_DAYS_DECISION_MEAN                  float64\n",
      " 67   PREV_CNT_PAYMENT_MEAN                    float64\n",
      " 68   PREV_NAME_TYPE_SUITE_Unaccompanied_MEAN  float64\n",
      " 69   PREV_NAME_TYPE_SUITE_nan_MEAN            float64\n",
      " 70   PREV_NAME_YIELD_GROUP_middle_MEAN        float64\n",
      " 71   APPROVED_AMT_ANNUITY_MIN                 float64\n",
      " 72   APPROVED_AMT_ANNUITY_MAX                 float64\n",
      " 73   APPROVED_AMT_ANNUITY_MEAN                float64\n",
      " 74   APPROVED_AMT_CREDIT_MIN                  float64\n",
      " 75   APPROVED_APP_CREDIT_PERC_MIN             float64\n",
      " 76   APPROVED_APP_CREDIT_PERC_MEAN            float64\n",
      " 77   APPROVED_APP_CREDIT_PERC_VAR             float64\n",
      " 78   APPROVED_HOUR_APPR_PROCESS_START_MEAN    float64\n",
      " 79   APPROVED_DAYS_DECISION_MAX               float64\n",
      " 80   APPROVED_DAYS_DECISION_MEAN              float64\n",
      " 81   APPROVED_CNT_PAYMENT_MEAN                float64\n",
      " 82   POS_MONTHS_BALANCE_MEAN                  float64\n",
      " 83   POS_MONTHS_BALANCE_SIZE                  float64\n",
      " 84   POS_NAME_CONTRACT_STATUS_Active_MEAN     float64\n",
      " 85   POS_NAME_CONTRACT_STATUS_Completed_MEAN  float64\n",
      " 86   INSTAL_DPD_MEAN                          float64\n",
      " 87   INSTAL_DBD_MAX                           float64\n",
      " 88   INSTAL_DBD_MEAN                          float64\n",
      " 89   INSTAL_DBD_SUM                           float64\n",
      " 90   INSTAL_PAYMENT_PERC_VAR                  float64\n",
      " 91   INSTAL_AMT_INSTALMENT_MAX                float64\n",
      " 92   INSTAL_AMT_INSTALMENT_MEAN               float64\n",
      " 93   INSTAL_AMT_PAYMENT_MIN                   float64\n",
      " 94   INSTAL_AMT_PAYMENT_MAX                   float64\n",
      " 95   INSTAL_AMT_PAYMENT_MEAN                  float64\n",
      " 96   INSTAL_AMT_PAYMENT_SUM                   float64\n",
      " 97   INSTAL_DAYS_ENTRY_PAYMENT_MAX            float64\n",
      " 98   INSTAL_DAYS_ENTRY_PAYMENT_MEAN           float64\n",
      " 99   INSTAL_DAYS_ENTRY_PAYMENT_SUM            float64\n",
      " 100  INTERET_CUMULE                           float64\n",
      "dtypes: float64(98), int64(3)\n",
      "memory usage: 237.0 MB\n"
     ]
    }
   ],
   "source": [
    "df[feats].info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3022f6",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fac463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40dc6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['TARGET'].notnull()]\n",
    "\n",
    "# Sélectionner les colonnes de type int et float\n",
    "numeric_columns = df[feats].select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Initialiser le MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normaliser les colonnes sélectionnées\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "median_values = df[feats].median()\n",
    "\n",
    "# Imputer les valeurs manquantes avec la médiane\n",
    "df.fillna(median_values, inplace=True) \n",
    "\n",
    "X = df[feats]\n",
    "\n",
    "y = df['TARGET']\n",
    "\n",
    "# Diviser l'ensemble de données en ensembles d'entraînement, de validation et de test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Diviser X_temp et y_temp pour obtenir le X_validation, y_validation, X_test, y_test\n",
    "X_hide_test, X_test, y_hide_test, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e80c68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215254, 101)\n",
      "(46127, 101)\n",
      "(46126, 101)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_hide_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28047779",
   "metadata": {},
   "source": [
    "# Score AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "519d3b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.714124\ttraining's binary_logloss: 0.279387\n",
      "[2]\ttraining's auc: 0.715768\ttraining's binary_logloss: 0.278305\n",
      "[3]\ttraining's auc: 0.717634\ttraining's binary_logloss: 0.27728\n",
      "[4]\ttraining's auc: 0.720066\ttraining's binary_logloss: 0.276315\n",
      "[5]\ttraining's auc: 0.721276\ttraining's binary_logloss: 0.275401\n",
      "[6]\ttraining's auc: 0.721519\ttraining's binary_logloss: 0.274538\n",
      "[7]\ttraining's auc: 0.722342\ttraining's binary_logloss: 0.273717\n",
      "[8]\ttraining's auc: 0.723545\ttraining's binary_logloss: 0.272926\n",
      "[9]\ttraining's auc: 0.724566\ttraining's binary_logloss: 0.272165\n",
      "[10]\ttraining's auc: 0.725684\ttraining's binary_logloss: 0.271441\n",
      "[11]\ttraining's auc: 0.726745\ttraining's binary_logloss: 0.270741\n",
      "[12]\ttraining's auc: 0.728208\ttraining's binary_logloss: 0.270064\n",
      "[13]\ttraining's auc: 0.73123\ttraining's binary_logloss: 0.269498\n",
      "[14]\ttraining's auc: 0.73324\ttraining's binary_logloss: 0.268954\n",
      "[15]\ttraining's auc: 0.733857\ttraining's binary_logloss: 0.26835\n",
      "[16]\ttraining's auc: 0.734272\ttraining's binary_logloss: 0.267775\n",
      "[17]\ttraining's auc: 0.73481\ttraining's binary_logloss: 0.267206\n",
      "[18]\ttraining's auc: 0.735376\ttraining's binary_logloss: 0.266663\n",
      "[19]\ttraining's auc: 0.735945\ttraining's binary_logloss: 0.266135\n",
      "[20]\ttraining's auc: 0.736183\ttraining's binary_logloss: 0.265636\n",
      "[21]\ttraining's auc: 0.737554\ttraining's binary_logloss: 0.26517\n",
      "[22]\ttraining's auc: 0.737915\ttraining's binary_logloss: 0.264695\n",
      "[23]\ttraining's auc: 0.738346\ttraining's binary_logloss: 0.26424\n",
      "[24]\ttraining's auc: 0.7388\ttraining's binary_logloss: 0.263785\n",
      "[25]\ttraining's auc: 0.739078\ttraining's binary_logloss: 0.263357\n",
      "[26]\ttraining's auc: 0.740254\ttraining's binary_logloss: 0.262958\n",
      "[27]\ttraining's auc: 0.740599\ttraining's binary_logloss: 0.262547\n",
      "[28]\ttraining's auc: 0.741003\ttraining's binary_logloss: 0.262154\n",
      "[29]\ttraining's auc: 0.741202\ttraining's binary_logloss: 0.261769\n",
      "[30]\ttraining's auc: 0.741694\ttraining's binary_logloss: 0.261396\n",
      "[31]\ttraining's auc: 0.742105\ttraining's binary_logloss: 0.26103\n",
      "[32]\ttraining's auc: 0.742474\ttraining's binary_logloss: 0.260682\n",
      "[33]\ttraining's auc: 0.74333\ttraining's binary_logloss: 0.260342\n",
      "[34]\ttraining's auc: 0.744142\ttraining's binary_logloss: 0.260013\n",
      "[35]\ttraining's auc: 0.744266\ttraining's binary_logloss: 0.25969\n",
      "[36]\ttraining's auc: 0.744807\ttraining's binary_logloss: 0.25936\n",
      "[37]\ttraining's auc: 0.745264\ttraining's binary_logloss: 0.259036\n",
      "[38]\ttraining's auc: 0.745488\ttraining's binary_logloss: 0.258725\n",
      "[39]\ttraining's auc: 0.746203\ttraining's binary_logloss: 0.258437\n",
      "[40]\ttraining's auc: 0.7466\ttraining's binary_logloss: 0.258126\n",
      "[41]\ttraining's auc: 0.747093\ttraining's binary_logloss: 0.257822\n",
      "[42]\ttraining's auc: 0.747483\ttraining's binary_logloss: 0.257523\n",
      "[43]\ttraining's auc: 0.747862\ttraining's binary_logloss: 0.257236\n",
      "[44]\ttraining's auc: 0.748273\ttraining's binary_logloss: 0.256947\n",
      "[45]\ttraining's auc: 0.748599\ttraining's binary_logloss: 0.256677\n",
      "[46]\ttraining's auc: 0.74902\ttraining's binary_logloss: 0.256399\n",
      "[47]\ttraining's auc: 0.74937\ttraining's binary_logloss: 0.256142\n",
      "[48]\ttraining's auc: 0.749765\ttraining's binary_logloss: 0.255886\n",
      "[49]\ttraining's auc: 0.750107\ttraining's binary_logloss: 0.255643\n",
      "[50]\ttraining's auc: 0.750369\ttraining's binary_logloss: 0.255409\n",
      "[51]\ttraining's auc: 0.750744\ttraining's binary_logloss: 0.255151\n",
      "[52]\ttraining's auc: 0.751077\ttraining's binary_logloss: 0.254915\n",
      "[53]\ttraining's auc: 0.751309\ttraining's binary_logloss: 0.254687\n",
      "[54]\ttraining's auc: 0.751712\ttraining's binary_logloss: 0.254449\n",
      "[55]\ttraining's auc: 0.751959\ttraining's binary_logloss: 0.254238\n",
      "[56]\ttraining's auc: 0.752249\ttraining's binary_logloss: 0.254034\n",
      "[57]\ttraining's auc: 0.752973\ttraining's binary_logloss: 0.253791\n",
      "[58]\ttraining's auc: 0.753337\ttraining's binary_logloss: 0.253585\n",
      "[59]\ttraining's auc: 0.7537\ttraining's binary_logloss: 0.253377\n",
      "[60]\ttraining's auc: 0.754084\ttraining's binary_logloss: 0.253166\n",
      "[61]\ttraining's auc: 0.75437\ttraining's binary_logloss: 0.252965\n",
      "[62]\ttraining's auc: 0.754743\ttraining's binary_logloss: 0.252765\n",
      "[63]\ttraining's auc: 0.755225\ttraining's binary_logloss: 0.252565\n",
      "[64]\ttraining's auc: 0.755484\ttraining's binary_logloss: 0.252375\n",
      "[65]\ttraining's auc: 0.755808\ttraining's binary_logloss: 0.252183\n",
      "[66]\ttraining's auc: 0.756288\ttraining's binary_logloss: 0.251984\n",
      "[67]\ttraining's auc: 0.756639\ttraining's binary_logloss: 0.251797\n",
      "[68]\ttraining's auc: 0.756897\ttraining's binary_logloss: 0.251618\n",
      "[69]\ttraining's auc: 0.757306\ttraining's binary_logloss: 0.251421\n",
      "[70]\ttraining's auc: 0.75763\ttraining's binary_logloss: 0.251244\n",
      "[71]\ttraining's auc: 0.758011\ttraining's binary_logloss: 0.251055\n",
      "[72]\ttraining's auc: 0.758504\ttraining's binary_logloss: 0.250852\n",
      "[73]\ttraining's auc: 0.758962\ttraining's binary_logloss: 0.250657\n",
      "[74]\ttraining's auc: 0.759323\ttraining's binary_logloss: 0.250488\n",
      "[75]\ttraining's auc: 0.759708\ttraining's binary_logloss: 0.250304\n",
      "[76]\ttraining's auc: 0.760064\ttraining's binary_logloss: 0.250144\n",
      "[77]\ttraining's auc: 0.760376\ttraining's binary_logloss: 0.249981\n",
      "[78]\ttraining's auc: 0.760687\ttraining's binary_logloss: 0.249825\n",
      "[79]\ttraining's auc: 0.761081\ttraining's binary_logloss: 0.24966\n",
      "[80]\ttraining's auc: 0.761412\ttraining's binary_logloss: 0.249499\n",
      "[81]\ttraining's auc: 0.761775\ttraining's binary_logloss: 0.249341\n",
      "[82]\ttraining's auc: 0.762092\ttraining's binary_logloss: 0.249188\n",
      "[83]\ttraining's auc: 0.762453\ttraining's binary_logloss: 0.249033\n",
      "[84]\ttraining's auc: 0.762819\ttraining's binary_logloss: 0.24888\n",
      "[85]\ttraining's auc: 0.76309\ttraining's binary_logloss: 0.248735\n",
      "[86]\ttraining's auc: 0.763307\ttraining's binary_logloss: 0.248598\n",
      "[87]\ttraining's auc: 0.763703\ttraining's binary_logloss: 0.248432\n",
      "[88]\ttraining's auc: 0.764023\ttraining's binary_logloss: 0.248286\n",
      "[89]\ttraining's auc: 0.764495\ttraining's binary_logloss: 0.248133\n",
      "[90]\ttraining's auc: 0.764714\ttraining's binary_logloss: 0.248001\n",
      "[91]\ttraining's auc: 0.765239\ttraining's binary_logloss: 0.247833\n",
      "[92]\ttraining's auc: 0.765538\ttraining's binary_logloss: 0.247689\n",
      "[93]\ttraining's auc: 0.765844\ttraining's binary_logloss: 0.247557\n",
      "[94]\ttraining's auc: 0.766183\ttraining's binary_logloss: 0.247414\n",
      "[95]\ttraining's auc: 0.76657\ttraining's binary_logloss: 0.247265\n",
      "[96]\ttraining's auc: 0.766954\ttraining's binary_logloss: 0.247128\n",
      "[97]\ttraining's auc: 0.767235\ttraining's binary_logloss: 0.246992\n",
      "[98]\ttraining's auc: 0.767614\ttraining's binary_logloss: 0.246842\n",
      "[99]\ttraining's auc: 0.767876\ttraining's binary_logloss: 0.246716\n",
      "[100]\ttraining's auc: 0.768337\ttraining's binary_logloss: 0.246561\n",
      "[101]\ttraining's auc: 0.768625\ttraining's binary_logloss: 0.246428\n",
      "[102]\ttraining's auc: 0.768921\ttraining's binary_logloss: 0.246293\n",
      "[103]\ttraining's auc: 0.769185\ttraining's binary_logloss: 0.246175\n",
      "[104]\ttraining's auc: 0.769491\ttraining's binary_logloss: 0.246056\n",
      "[105]\ttraining's auc: 0.769791\ttraining's binary_logloss: 0.245933\n",
      "[106]\ttraining's auc: 0.770101\ttraining's binary_logloss: 0.245803\n",
      "[107]\ttraining's auc: 0.770464\ttraining's binary_logloss: 0.245669\n",
      "[108]\ttraining's auc: 0.770755\ttraining's binary_logloss: 0.245553\n",
      "[109]\ttraining's auc: 0.771051\ttraining's binary_logloss: 0.245438\n",
      "[110]\ttraining's auc: 0.77131\ttraining's binary_logloss: 0.245324\n",
      "[111]\ttraining's auc: 0.771581\ttraining's binary_logloss: 0.245211\n",
      "[112]\ttraining's auc: 0.771779\ttraining's binary_logloss: 0.245105\n",
      "[113]\ttraining's auc: 0.772108\ttraining's binary_logloss: 0.244985\n",
      "[114]\ttraining's auc: 0.772388\ttraining's binary_logloss: 0.244869\n",
      "[115]\ttraining's auc: 0.772622\ttraining's binary_logloss: 0.244768\n",
      "[116]\ttraining's auc: 0.772855\ttraining's binary_logloss: 0.244665\n",
      "[117]\ttraining's auc: 0.773139\ttraining's binary_logloss: 0.244555\n",
      "[118]\ttraining's auc: 0.77341\ttraining's binary_logloss: 0.244444\n",
      "[119]\ttraining's auc: 0.773731\ttraining's binary_logloss: 0.244336\n",
      "[120]\ttraining's auc: 0.774018\ttraining's binary_logloss: 0.244224\n",
      "[121]\ttraining's auc: 0.774315\ttraining's binary_logloss: 0.244117\n",
      "[122]\ttraining's auc: 0.774565\ttraining's binary_logloss: 0.244014\n",
      "[123]\ttraining's auc: 0.774763\ttraining's binary_logloss: 0.243915\n",
      "[124]\ttraining's auc: 0.775027\ttraining's binary_logloss: 0.24381\n",
      "[125]\ttraining's auc: 0.775389\ttraining's binary_logloss: 0.243686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126]\ttraining's auc: 0.775634\ttraining's binary_logloss: 0.243585\n",
      "[127]\ttraining's auc: 0.775873\ttraining's binary_logloss: 0.243486\n",
      "[128]\ttraining's auc: 0.77608\ttraining's binary_logloss: 0.243389\n",
      "[129]\ttraining's auc: 0.776322\ttraining's binary_logloss: 0.243293\n",
      "[130]\ttraining's auc: 0.776657\ttraining's binary_logloss: 0.243177\n",
      "[131]\ttraining's auc: 0.776874\ttraining's binary_logloss: 0.243083\n",
      "[132]\ttraining's auc: 0.777099\ttraining's binary_logloss: 0.24299\n",
      "[133]\ttraining's auc: 0.77738\ttraining's binary_logloss: 0.24289\n",
      "[134]\ttraining's auc: 0.777654\ttraining's binary_logloss: 0.242795\n",
      "[135]\ttraining's auc: 0.777853\ttraining's binary_logloss: 0.242705\n",
      "[136]\ttraining's auc: 0.778087\ttraining's binary_logloss: 0.242601\n",
      "[137]\ttraining's auc: 0.778336\ttraining's binary_logloss: 0.242506\n",
      "[138]\ttraining's auc: 0.778642\ttraining's binary_logloss: 0.2424\n",
      "[139]\ttraining's auc: 0.778919\ttraining's binary_logloss: 0.242303\n",
      "[140]\ttraining's auc: 0.779139\ttraining's binary_logloss: 0.242207\n",
      "[141]\ttraining's auc: 0.779362\ttraining's binary_logloss: 0.242119\n",
      "[142]\ttraining's auc: 0.779629\ttraining's binary_logloss: 0.242018\n",
      "[143]\ttraining's auc: 0.779885\ttraining's binary_logloss: 0.241925\n",
      "[144]\ttraining's auc: 0.780057\ttraining's binary_logloss: 0.241845\n",
      "[145]\ttraining's auc: 0.780293\ttraining's binary_logloss: 0.241749\n",
      "[146]\ttraining's auc: 0.780553\ttraining's binary_logloss: 0.241653\n",
      "[147]\ttraining's auc: 0.780778\ttraining's binary_logloss: 0.241567\n",
      "[148]\ttraining's auc: 0.781015\ttraining's binary_logloss: 0.241476\n",
      "[149]\ttraining's auc: 0.781224\ttraining's binary_logloss: 0.241395\n",
      "[150]\ttraining's auc: 0.781453\ttraining's binary_logloss: 0.24131\n",
      "[151]\ttraining's auc: 0.781614\ttraining's binary_logloss: 0.241238\n",
      "[152]\ttraining's auc: 0.781867\ttraining's binary_logloss: 0.241143\n",
      "[153]\ttraining's auc: 0.782061\ttraining's binary_logloss: 0.241067\n",
      "[154]\ttraining's auc: 0.782289\ttraining's binary_logloss: 0.240981\n",
      "[155]\ttraining's auc: 0.782527\ttraining's binary_logloss: 0.240891\n",
      "[156]\ttraining's auc: 0.782727\ttraining's binary_logloss: 0.240807\n",
      "[157]\ttraining's auc: 0.782934\ttraining's binary_logloss: 0.240732\n",
      "[158]\ttraining's auc: 0.783111\ttraining's binary_logloss: 0.240654\n",
      "[159]\ttraining's auc: 0.783306\ttraining's binary_logloss: 0.24057\n",
      "[160]\ttraining's auc: 0.783536\ttraining's binary_logloss: 0.240487\n",
      "[161]\ttraining's auc: 0.783716\ttraining's binary_logloss: 0.240407\n",
      "[162]\ttraining's auc: 0.783919\ttraining's binary_logloss: 0.24033\n",
      "[163]\ttraining's auc: 0.784033\ttraining's binary_logloss: 0.240256\n",
      "[164]\ttraining's auc: 0.784249\ttraining's binary_logloss: 0.240175\n",
      "[165]\ttraining's auc: 0.78444\ttraining's binary_logloss: 0.240104\n",
      "[166]\ttraining's auc: 0.784608\ttraining's binary_logloss: 0.240026\n",
      "[167]\ttraining's auc: 0.784762\ttraining's binary_logloss: 0.239951\n",
      "[168]\ttraining's auc: 0.78495\ttraining's binary_logloss: 0.239884\n",
      "[169]\ttraining's auc: 0.78512\ttraining's binary_logloss: 0.239809\n",
      "[170]\ttraining's auc: 0.785323\ttraining's binary_logloss: 0.239728\n",
      "[171]\ttraining's auc: 0.785505\ttraining's binary_logloss: 0.239658\n",
      "[172]\ttraining's auc: 0.785702\ttraining's binary_logloss: 0.239582\n",
      "[173]\ttraining's auc: 0.785837\ttraining's binary_logloss: 0.239515\n",
      "[174]\ttraining's auc: 0.786038\ttraining's binary_logloss: 0.239442\n",
      "[175]\ttraining's auc: 0.786238\ttraining's binary_logloss: 0.23937\n",
      "[176]\ttraining's auc: 0.786415\ttraining's binary_logloss: 0.2393\n",
      "[177]\ttraining's auc: 0.786605\ttraining's binary_logloss: 0.239229\n",
      "[178]\ttraining's auc: 0.78679\ttraining's binary_logloss: 0.239152\n",
      "[179]\ttraining's auc: 0.786924\ttraining's binary_logloss: 0.239082\n",
      "[180]\ttraining's auc: 0.787107\ttraining's binary_logloss: 0.239013\n",
      "[181]\ttraining's auc: 0.787292\ttraining's binary_logloss: 0.238942\n",
      "[182]\ttraining's auc: 0.787481\ttraining's binary_logloss: 0.238868\n",
      "[183]\ttraining's auc: 0.787637\ttraining's binary_logloss: 0.238801\n",
      "[184]\ttraining's auc: 0.787795\ttraining's binary_logloss: 0.238737\n",
      "[185]\ttraining's auc: 0.787938\ttraining's binary_logloss: 0.238673\n",
      "[186]\ttraining's auc: 0.788099\ttraining's binary_logloss: 0.238603\n",
      "[187]\ttraining's auc: 0.788245\ttraining's binary_logloss: 0.238539\n",
      "[188]\ttraining's auc: 0.788396\ttraining's binary_logloss: 0.238471\n",
      "[189]\ttraining's auc: 0.788562\ttraining's binary_logloss: 0.238407\n",
      "[190]\ttraining's auc: 0.788731\ttraining's binary_logloss: 0.238344\n",
      "[191]\ttraining's auc: 0.788888\ttraining's binary_logloss: 0.238285\n",
      "[192]\ttraining's auc: 0.789024\ttraining's binary_logloss: 0.238222\n",
      "[193]\ttraining's auc: 0.789168\ttraining's binary_logloss: 0.23816\n",
      "[194]\ttraining's auc: 0.789331\ttraining's binary_logloss: 0.238094\n",
      "[195]\ttraining's auc: 0.789496\ttraining's binary_logloss: 0.238029\n",
      "[196]\ttraining's auc: 0.789672\ttraining's binary_logloss: 0.237964\n",
      "[197]\ttraining's auc: 0.789819\ttraining's binary_logloss: 0.237904\n",
      "[198]\ttraining's auc: 0.789981\ttraining's binary_logloss: 0.237844\n",
      "[199]\ttraining's auc: 0.79015\ttraining's binary_logloss: 0.237778\n",
      "[200]\ttraining's auc: 0.790313\ttraining's binary_logloss: 0.237709\n",
      "[201]\ttraining's auc: 0.790451\ttraining's binary_logloss: 0.23765\n",
      "[202]\ttraining's auc: 0.79062\ttraining's binary_logloss: 0.237586\n",
      "[203]\ttraining's auc: 0.79076\ttraining's binary_logloss: 0.237533\n",
      "[204]\ttraining's auc: 0.790907\ttraining's binary_logloss: 0.237471\n",
      "[205]\ttraining's auc: 0.791064\ttraining's binary_logloss: 0.237413\n",
      "[206]\ttraining's auc: 0.791201\ttraining's binary_logloss: 0.237354\n",
      "[207]\ttraining's auc: 0.791369\ttraining's binary_logloss: 0.237292\n",
      "[208]\ttraining's auc: 0.791507\ttraining's binary_logloss: 0.23723\n",
      "[209]\ttraining's auc: 0.791651\ttraining's binary_logloss: 0.23717\n",
      "[210]\ttraining's auc: 0.791813\ttraining's binary_logloss: 0.237113\n",
      "[211]\ttraining's auc: 0.79196\ttraining's binary_logloss: 0.237058\n",
      "[212]\ttraining's auc: 0.792102\ttraining's binary_logloss: 0.236999\n",
      "[213]\ttraining's auc: 0.792246\ttraining's binary_logloss: 0.236935\n",
      "[214]\ttraining's auc: 0.792373\ttraining's binary_logloss: 0.236879\n",
      "[215]\ttraining's auc: 0.792554\ttraining's binary_logloss: 0.236816\n",
      "[216]\ttraining's auc: 0.792707\ttraining's binary_logloss: 0.23675\n",
      "[217]\ttraining's auc: 0.792856\ttraining's binary_logloss: 0.236696\n",
      "[218]\ttraining's auc: 0.792963\ttraining's binary_logloss: 0.236644\n",
      "[219]\ttraining's auc: 0.793112\ttraining's binary_logloss: 0.236583\n",
      "[220]\ttraining's auc: 0.793235\ttraining's binary_logloss: 0.236529\n",
      "[221]\ttraining's auc: 0.793387\ttraining's binary_logloss: 0.236463\n",
      "[222]\ttraining's auc: 0.793541\ttraining's binary_logloss: 0.236404\n",
      "[223]\ttraining's auc: 0.793673\ttraining's binary_logloss: 0.236354\n",
      "[224]\ttraining's auc: 0.793835\ttraining's binary_logloss: 0.236292\n",
      "[225]\ttraining's auc: 0.793979\ttraining's binary_logloss: 0.236233\n",
      "[226]\ttraining's auc: 0.794134\ttraining's binary_logloss: 0.236177\n",
      "[227]\ttraining's auc: 0.794282\ttraining's binary_logloss: 0.236121\n",
      "[228]\ttraining's auc: 0.794429\ttraining's binary_logloss: 0.236065\n",
      "[229]\ttraining's auc: 0.794586\ttraining's binary_logloss: 0.236005\n",
      "[230]\ttraining's auc: 0.794711\ttraining's binary_logloss: 0.235955\n",
      "[231]\ttraining's auc: 0.794819\ttraining's binary_logloss: 0.235907\n",
      "[232]\ttraining's auc: 0.794953\ttraining's binary_logloss: 0.23585\n",
      "[233]\ttraining's auc: 0.795087\ttraining's binary_logloss: 0.235796\n",
      "[234]\ttraining's auc: 0.795188\ttraining's binary_logloss: 0.235751\n",
      "[235]\ttraining's auc: 0.795304\ttraining's binary_logloss: 0.235697\n",
      "[236]\ttraining's auc: 0.79544\ttraining's binary_logloss: 0.235644\n",
      "[237]\ttraining's auc: 0.79557\ttraining's binary_logloss: 0.23559\n",
      "[238]\ttraining's auc: 0.79571\ttraining's binary_logloss: 0.235537\n",
      "[239]\ttraining's auc: 0.795841\ttraining's binary_logloss: 0.235485\n",
      "[240]\ttraining's auc: 0.795944\ttraining's binary_logloss: 0.235437\n",
      "[241]\ttraining's auc: 0.796068\ttraining's binary_logloss: 0.235386\n",
      "[242]\ttraining's auc: 0.796211\ttraining's binary_logloss: 0.235331\n",
      "[243]\ttraining's auc: 0.796336\ttraining's binary_logloss: 0.235281\n",
      "[244]\ttraining's auc: 0.796468\ttraining's binary_logloss: 0.235231\n",
      "[245]\ttraining's auc: 0.796575\ttraining's binary_logloss: 0.235183\n",
      "[246]\ttraining's auc: 0.796701\ttraining's binary_logloss: 0.23513\n",
      "[247]\ttraining's auc: 0.796836\ttraining's binary_logloss: 0.235077\n",
      "[248]\ttraining's auc: 0.796989\ttraining's binary_logloss: 0.235019\n",
      "[249]\ttraining's auc: 0.797106\ttraining's binary_logloss: 0.234969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttraining's auc: 0.797229\ttraining's binary_logloss: 0.23492\n",
      "[251]\ttraining's auc: 0.797346\ttraining's binary_logloss: 0.234869\n",
      "[252]\ttraining's auc: 0.79747\ttraining's binary_logloss: 0.234823\n",
      "[253]\ttraining's auc: 0.797599\ttraining's binary_logloss: 0.234773\n",
      "[254]\ttraining's auc: 0.79771\ttraining's binary_logloss: 0.23473\n",
      "[255]\ttraining's auc: 0.797839\ttraining's binary_logloss: 0.234675\n",
      "[256]\ttraining's auc: 0.797958\ttraining's binary_logloss: 0.234626\n",
      "[257]\ttraining's auc: 0.798083\ttraining's binary_logloss: 0.234583\n",
      "[258]\ttraining's auc: 0.798213\ttraining's binary_logloss: 0.234529\n",
      "[259]\ttraining's auc: 0.798356\ttraining's binary_logloss: 0.234477\n",
      "[260]\ttraining's auc: 0.798452\ttraining's binary_logloss: 0.234432\n",
      "[261]\ttraining's auc: 0.798553\ttraining's binary_logloss: 0.234388\n",
      "[262]\ttraining's auc: 0.798677\ttraining's binary_logloss: 0.234336\n",
      "[263]\ttraining's auc: 0.798799\ttraining's binary_logloss: 0.234287\n",
      "[264]\ttraining's auc: 0.798895\ttraining's binary_logloss: 0.234242\n",
      "[265]\ttraining's auc: 0.799029\ttraining's binary_logloss: 0.23419\n",
      "[266]\ttraining's auc: 0.799135\ttraining's binary_logloss: 0.234145\n",
      "[267]\ttraining's auc: 0.799215\ttraining's binary_logloss: 0.234102\n",
      "[268]\ttraining's auc: 0.799364\ttraining's binary_logloss: 0.234047\n",
      "[269]\ttraining's auc: 0.799485\ttraining's binary_logloss: 0.233999\n",
      "[270]\ttraining's auc: 0.799643\ttraining's binary_logloss: 0.233943\n",
      "[271]\ttraining's auc: 0.799758\ttraining's binary_logloss: 0.233894\n",
      "[272]\ttraining's auc: 0.7999\ttraining's binary_logloss: 0.233843\n",
      "[273]\ttraining's auc: 0.799992\ttraining's binary_logloss: 0.233801\n",
      "[274]\ttraining's auc: 0.800123\ttraining's binary_logloss: 0.233747\n",
      "[275]\ttraining's auc: 0.800231\ttraining's binary_logloss: 0.233701\n",
      "[276]\ttraining's auc: 0.800359\ttraining's binary_logloss: 0.233652\n",
      "[277]\ttraining's auc: 0.800493\ttraining's binary_logloss: 0.233605\n",
      "[278]\ttraining's auc: 0.800617\ttraining's binary_logloss: 0.233559\n",
      "[279]\ttraining's auc: 0.80074\ttraining's binary_logloss: 0.233512\n",
      "[280]\ttraining's auc: 0.800875\ttraining's binary_logloss: 0.233459\n",
      "[281]\ttraining's auc: 0.801004\ttraining's binary_logloss: 0.233412\n",
      "[282]\ttraining's auc: 0.801111\ttraining's binary_logloss: 0.233366\n",
      "[283]\ttraining's auc: 0.801207\ttraining's binary_logloss: 0.233328\n",
      "[284]\ttraining's auc: 0.801332\ttraining's binary_logloss: 0.233279\n",
      "[285]\ttraining's auc: 0.801443\ttraining's binary_logloss: 0.233237\n",
      "[286]\ttraining's auc: 0.801548\ttraining's binary_logloss: 0.233193\n",
      "[287]\ttraining's auc: 0.801656\ttraining's binary_logloss: 0.233149\n",
      "[288]\ttraining's auc: 0.801814\ttraining's binary_logloss: 0.23309\n",
      "[289]\ttraining's auc: 0.801943\ttraining's binary_logloss: 0.233042\n",
      "[290]\ttraining's auc: 0.802049\ttraining's binary_logloss: 0.232995\n",
      "[291]\ttraining's auc: 0.80218\ttraining's binary_logloss: 0.232946\n",
      "[292]\ttraining's auc: 0.802271\ttraining's binary_logloss: 0.232906\n",
      "[293]\ttraining's auc: 0.80239\ttraining's binary_logloss: 0.232863\n",
      "[294]\ttraining's auc: 0.802489\ttraining's binary_logloss: 0.232823\n",
      "[295]\ttraining's auc: 0.802597\ttraining's binary_logloss: 0.232775\n",
      "[296]\ttraining's auc: 0.802699\ttraining's binary_logloss: 0.23274\n",
      "[297]\ttraining's auc: 0.802798\ttraining's binary_logloss: 0.2327\n",
      "[298]\ttraining's auc: 0.802902\ttraining's binary_logloss: 0.232655\n",
      "[299]\ttraining's auc: 0.803021\ttraining's binary_logloss: 0.232611\n",
      "[300]\ttraining's auc: 0.803119\ttraining's binary_logloss: 0.23257\n",
      "[301]\ttraining's auc: 0.803266\ttraining's binary_logloss: 0.232517\n",
      "[302]\ttraining's auc: 0.803398\ttraining's binary_logloss: 0.232469\n",
      "[303]\ttraining's auc: 0.803492\ttraining's binary_logloss: 0.232434\n",
      "[304]\ttraining's auc: 0.803584\ttraining's binary_logloss: 0.232392\n",
      "[305]\ttraining's auc: 0.803726\ttraining's binary_logloss: 0.232337\n",
      "[306]\ttraining's auc: 0.803818\ttraining's binary_logloss: 0.232295\n",
      "[307]\ttraining's auc: 0.803924\ttraining's binary_logloss: 0.232248\n",
      "[308]\ttraining's auc: 0.804063\ttraining's binary_logloss: 0.232202\n",
      "[309]\ttraining's auc: 0.80416\ttraining's binary_logloss: 0.232164\n",
      "[310]\ttraining's auc: 0.804279\ttraining's binary_logloss: 0.232123\n",
      "[311]\ttraining's auc: 0.804387\ttraining's binary_logloss: 0.232078\n",
      "[312]\ttraining's auc: 0.804487\ttraining's binary_logloss: 0.232037\n",
      "[313]\ttraining's auc: 0.804611\ttraining's binary_logloss: 0.231992\n",
      "[314]\ttraining's auc: 0.804706\ttraining's binary_logloss: 0.231956\n",
      "[315]\ttraining's auc: 0.804808\ttraining's binary_logloss: 0.231919\n",
      "[316]\ttraining's auc: 0.80493\ttraining's binary_logloss: 0.231876\n",
      "[317]\ttraining's auc: 0.805043\ttraining's binary_logloss: 0.231836\n",
      "[318]\ttraining's auc: 0.805146\ttraining's binary_logloss: 0.231793\n",
      "[319]\ttraining's auc: 0.805258\ttraining's binary_logloss: 0.231751\n",
      "[320]\ttraining's auc: 0.805339\ttraining's binary_logloss: 0.231713\n",
      "[321]\ttraining's auc: 0.80547\ttraining's binary_logloss: 0.231663\n",
      "[322]\ttraining's auc: 0.805573\ttraining's binary_logloss: 0.231624\n",
      "[323]\ttraining's auc: 0.805658\ttraining's binary_logloss: 0.231586\n",
      "[324]\ttraining's auc: 0.805777\ttraining's binary_logloss: 0.231544\n",
      "[325]\ttraining's auc: 0.805871\ttraining's binary_logloss: 0.231502\n",
      "[326]\ttraining's auc: 0.805982\ttraining's binary_logloss: 0.231459\n",
      "[327]\ttraining's auc: 0.806081\ttraining's binary_logloss: 0.23142\n",
      "[328]\ttraining's auc: 0.806179\ttraining's binary_logloss: 0.231383\n",
      "[329]\ttraining's auc: 0.806293\ttraining's binary_logloss: 0.231342\n",
      "[330]\ttraining's auc: 0.806406\ttraining's binary_logloss: 0.2313\n",
      "[331]\ttraining's auc: 0.806494\ttraining's binary_logloss: 0.231261\n",
      "[332]\ttraining's auc: 0.806607\ttraining's binary_logloss: 0.23122\n",
      "[333]\ttraining's auc: 0.806722\ttraining's binary_logloss: 0.231176\n",
      "[334]\ttraining's auc: 0.806822\ttraining's binary_logloss: 0.231135\n",
      "[335]\ttraining's auc: 0.806916\ttraining's binary_logloss: 0.231099\n",
      "[336]\ttraining's auc: 0.807015\ttraining's binary_logloss: 0.231062\n",
      "[337]\ttraining's auc: 0.807107\ttraining's binary_logloss: 0.231026\n",
      "[338]\ttraining's auc: 0.807212\ttraining's binary_logloss: 0.230988\n",
      "[339]\ttraining's auc: 0.807315\ttraining's binary_logloss: 0.230949\n",
      "[340]\ttraining's auc: 0.807409\ttraining's binary_logloss: 0.230911\n",
      "[341]\ttraining's auc: 0.807507\ttraining's binary_logloss: 0.23087\n",
      "[342]\ttraining's auc: 0.807603\ttraining's binary_logloss: 0.230834\n",
      "[343]\ttraining's auc: 0.807679\ttraining's binary_logloss: 0.230799\n",
      "[344]\ttraining's auc: 0.807753\ttraining's binary_logloss: 0.23076\n",
      "[345]\ttraining's auc: 0.807876\ttraining's binary_logloss: 0.230712\n",
      "[346]\ttraining's auc: 0.807948\ttraining's binary_logloss: 0.230677\n",
      "[347]\ttraining's auc: 0.808064\ttraining's binary_logloss: 0.230636\n",
      "[348]\ttraining's auc: 0.808194\ttraining's binary_logloss: 0.230595\n",
      "[349]\ttraining's auc: 0.808306\ttraining's binary_logloss: 0.230552\n",
      "[350]\ttraining's auc: 0.808389\ttraining's binary_logloss: 0.230516\n",
      "[351]\ttraining's auc: 0.808487\ttraining's binary_logloss: 0.230476\n",
      "[352]\ttraining's auc: 0.808608\ttraining's binary_logloss: 0.230432\n",
      "[353]\ttraining's auc: 0.808697\ttraining's binary_logloss: 0.230397\n",
      "[354]\ttraining's auc: 0.808782\ttraining's binary_logloss: 0.230366\n",
      "[355]\ttraining's auc: 0.808858\ttraining's binary_logloss: 0.230332\n",
      "[356]\ttraining's auc: 0.808958\ttraining's binary_logloss: 0.230291\n",
      "[357]\ttraining's auc: 0.809058\ttraining's binary_logloss: 0.230251\n",
      "[358]\ttraining's auc: 0.809157\ttraining's binary_logloss: 0.230213\n",
      "[359]\ttraining's auc: 0.80926\ttraining's binary_logloss: 0.230175\n",
      "[360]\ttraining's auc: 0.809347\ttraining's binary_logloss: 0.230142\n",
      "[361]\ttraining's auc: 0.809456\ttraining's binary_logloss: 0.230102\n",
      "[362]\ttraining's auc: 0.809563\ttraining's binary_logloss: 0.230062\n",
      "[363]\ttraining's auc: 0.809672\ttraining's binary_logloss: 0.230023\n",
      "[364]\ttraining's auc: 0.809797\ttraining's binary_logloss: 0.229982\n",
      "[365]\ttraining's auc: 0.809883\ttraining's binary_logloss: 0.229945\n",
      "[366]\ttraining's auc: 0.809999\ttraining's binary_logloss: 0.229904\n",
      "[367]\ttraining's auc: 0.810115\ttraining's binary_logloss: 0.229859\n",
      "[368]\ttraining's auc: 0.810236\ttraining's binary_logloss: 0.229813\n",
      "[369]\ttraining's auc: 0.810342\ttraining's binary_logloss: 0.229773\n",
      "[370]\ttraining's auc: 0.810448\ttraining's binary_logloss: 0.229737\n",
      "[371]\ttraining's auc: 0.810555\ttraining's binary_logloss: 0.229699\n",
      "[372]\ttraining's auc: 0.810659\ttraining's binary_logloss: 0.229657\n",
      "[373]\ttraining's auc: 0.810753\ttraining's binary_logloss: 0.22962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[374]\ttraining's auc: 0.810837\ttraining's binary_logloss: 0.229584\n",
      "[375]\ttraining's auc: 0.81095\ttraining's binary_logloss: 0.229546\n",
      "[376]\ttraining's auc: 0.81103\ttraining's binary_logloss: 0.229514\n",
      "[377]\ttraining's auc: 0.811135\ttraining's binary_logloss: 0.22948\n",
      "[378]\ttraining's auc: 0.811234\ttraining's binary_logloss: 0.229436\n",
      "[379]\ttraining's auc: 0.811356\ttraining's binary_logloss: 0.229389\n",
      "[380]\ttraining's auc: 0.81146\ttraining's binary_logloss: 0.229348\n",
      "[381]\ttraining's auc: 0.811573\ttraining's binary_logloss: 0.229311\n",
      "[382]\ttraining's auc: 0.811672\ttraining's binary_logloss: 0.229274\n",
      "[383]\ttraining's auc: 0.811737\ttraining's binary_logloss: 0.22925\n",
      "[384]\ttraining's auc: 0.811849\ttraining's binary_logloss: 0.229209\n",
      "[385]\ttraining's auc: 0.811945\ttraining's binary_logloss: 0.229172\n",
      "[386]\ttraining's auc: 0.812033\ttraining's binary_logloss: 0.229138\n",
      "[387]\ttraining's auc: 0.812086\ttraining's binary_logloss: 0.229112\n",
      "[388]\ttraining's auc: 0.812169\ttraining's binary_logloss: 0.22908\n",
      "[389]\ttraining's auc: 0.812243\ttraining's binary_logloss: 0.229055\n",
      "[390]\ttraining's auc: 0.812353\ttraining's binary_logloss: 0.229016\n",
      "[391]\ttraining's auc: 0.812466\ttraining's binary_logloss: 0.228978\n",
      "[392]\ttraining's auc: 0.812576\ttraining's binary_logloss: 0.228937\n",
      "[393]\ttraining's auc: 0.812668\ttraining's binary_logloss: 0.228903\n",
      "[394]\ttraining's auc: 0.812781\ttraining's binary_logloss: 0.228865\n",
      "[395]\ttraining's auc: 0.812883\ttraining's binary_logloss: 0.228829\n",
      "[396]\ttraining's auc: 0.812964\ttraining's binary_logloss: 0.228798\n",
      "[397]\ttraining's auc: 0.813074\ttraining's binary_logloss: 0.228758\n",
      "[398]\ttraining's auc: 0.813161\ttraining's binary_logloss: 0.228724\n",
      "[399]\ttraining's auc: 0.81324\ttraining's binary_logloss: 0.228692\n",
      "[400]\ttraining's auc: 0.813345\ttraining's binary_logloss: 0.228656\n",
      "[401]\ttraining's auc: 0.813474\ttraining's binary_logloss: 0.228612\n",
      "[402]\ttraining's auc: 0.813561\ttraining's binary_logloss: 0.228578\n",
      "[403]\ttraining's auc: 0.813654\ttraining's binary_logloss: 0.228543\n",
      "[404]\ttraining's auc: 0.813753\ttraining's binary_logloss: 0.228507\n",
      "[405]\ttraining's auc: 0.813838\ttraining's binary_logloss: 0.228477\n",
      "[406]\ttraining's auc: 0.813956\ttraining's binary_logloss: 0.228433\n",
      "[407]\ttraining's auc: 0.814045\ttraining's binary_logloss: 0.228401\n",
      "[408]\ttraining's auc: 0.814128\ttraining's binary_logloss: 0.228368\n",
      "[409]\ttraining's auc: 0.814237\ttraining's binary_logloss: 0.228323\n",
      "[410]\ttraining's auc: 0.814318\ttraining's binary_logloss: 0.228289\n",
      "[411]\ttraining's auc: 0.814413\ttraining's binary_logloss: 0.228255\n",
      "[412]\ttraining's auc: 0.814476\ttraining's binary_logloss: 0.228226\n",
      "[413]\ttraining's auc: 0.814567\ttraining's binary_logloss: 0.228192\n",
      "[414]\ttraining's auc: 0.81467\ttraining's binary_logloss: 0.228158\n",
      "[415]\ttraining's auc: 0.814762\ttraining's binary_logloss: 0.22812\n",
      "[416]\ttraining's auc: 0.814868\ttraining's binary_logloss: 0.228083\n",
      "[417]\ttraining's auc: 0.814961\ttraining's binary_logloss: 0.228046\n",
      "[418]\ttraining's auc: 0.815066\ttraining's binary_logloss: 0.228005\n",
      "[419]\ttraining's auc: 0.815162\ttraining's binary_logloss: 0.227972\n",
      "[420]\ttraining's auc: 0.815265\ttraining's binary_logloss: 0.227936\n",
      "[421]\ttraining's auc: 0.815371\ttraining's binary_logloss: 0.227901\n",
      "[422]\ttraining's auc: 0.815457\ttraining's binary_logloss: 0.22787\n",
      "[423]\ttraining's auc: 0.815521\ttraining's binary_logloss: 0.227838\n",
      "[424]\ttraining's auc: 0.815622\ttraining's binary_logloss: 0.227801\n",
      "[425]\ttraining's auc: 0.815707\ttraining's binary_logloss: 0.227766\n",
      "[426]\ttraining's auc: 0.815814\ttraining's binary_logloss: 0.227725\n",
      "[427]\ttraining's auc: 0.815905\ttraining's binary_logloss: 0.227691\n",
      "[428]\ttraining's auc: 0.815994\ttraining's binary_logloss: 0.227657\n",
      "[429]\ttraining's auc: 0.816086\ttraining's binary_logloss: 0.227627\n",
      "[430]\ttraining's auc: 0.816169\ttraining's binary_logloss: 0.227593\n",
      "[431]\ttraining's auc: 0.816242\ttraining's binary_logloss: 0.227564\n",
      "[432]\ttraining's auc: 0.816344\ttraining's binary_logloss: 0.227528\n",
      "[433]\ttraining's auc: 0.816428\ttraining's binary_logloss: 0.227492\n",
      "[434]\ttraining's auc: 0.816515\ttraining's binary_logloss: 0.227458\n",
      "[435]\ttraining's auc: 0.816579\ttraining's binary_logloss: 0.227435\n",
      "[436]\ttraining's auc: 0.816688\ttraining's binary_logloss: 0.227392\n",
      "[437]\ttraining's auc: 0.816781\ttraining's binary_logloss: 0.227356\n",
      "[438]\ttraining's auc: 0.816871\ttraining's binary_logloss: 0.227321\n",
      "[439]\ttraining's auc: 0.816967\ttraining's binary_logloss: 0.227284\n",
      "[440]\ttraining's auc: 0.817081\ttraining's binary_logloss: 0.227247\n",
      "[441]\ttraining's auc: 0.81718\ttraining's binary_logloss: 0.227213\n",
      "[442]\ttraining's auc: 0.817257\ttraining's binary_logloss: 0.227181\n",
      "[443]\ttraining's auc: 0.817337\ttraining's binary_logloss: 0.227153\n",
      "[444]\ttraining's auc: 0.817436\ttraining's binary_logloss: 0.227119\n",
      "[445]\ttraining's auc: 0.817533\ttraining's binary_logloss: 0.227084\n",
      "[446]\ttraining's auc: 0.817627\ttraining's binary_logloss: 0.227049\n",
      "[447]\ttraining's auc: 0.817715\ttraining's binary_logloss: 0.227019\n",
      "[448]\ttraining's auc: 0.817801\ttraining's binary_logloss: 0.226986\n",
      "[449]\ttraining's auc: 0.817885\ttraining's binary_logloss: 0.226954\n",
      "[450]\ttraining's auc: 0.817976\ttraining's binary_logloss: 0.226922\n",
      "[451]\ttraining's auc: 0.818057\ttraining's binary_logloss: 0.226886\n",
      "[452]\ttraining's auc: 0.818161\ttraining's binary_logloss: 0.226849\n",
      "[453]\ttraining's auc: 0.818236\ttraining's binary_logloss: 0.226818\n",
      "[454]\ttraining's auc: 0.818337\ttraining's binary_logloss: 0.226785\n",
      "[455]\ttraining's auc: 0.81845\ttraining's binary_logloss: 0.226746\n",
      "[456]\ttraining's auc: 0.81855\ttraining's binary_logloss: 0.226712\n",
      "[457]\ttraining's auc: 0.818623\ttraining's binary_logloss: 0.22668\n",
      "[458]\ttraining's auc: 0.818699\ttraining's binary_logloss: 0.22665\n",
      "[459]\ttraining's auc: 0.818791\ttraining's binary_logloss: 0.226618\n",
      "[460]\ttraining's auc: 0.818856\ttraining's binary_logloss: 0.226591\n",
      "[461]\ttraining's auc: 0.818963\ttraining's binary_logloss: 0.22655\n",
      "[462]\ttraining's auc: 0.819045\ttraining's binary_logloss: 0.226516\n",
      "[463]\ttraining's auc: 0.819126\ttraining's binary_logloss: 0.226488\n",
      "[464]\ttraining's auc: 0.819226\ttraining's binary_logloss: 0.22645\n",
      "[465]\ttraining's auc: 0.819319\ttraining's binary_logloss: 0.226417\n",
      "[466]\ttraining's auc: 0.819401\ttraining's binary_logloss: 0.22638\n",
      "[467]\ttraining's auc: 0.819497\ttraining's binary_logloss: 0.226346\n",
      "[468]\ttraining's auc: 0.819598\ttraining's binary_logloss: 0.22631\n",
      "[469]\ttraining's auc: 0.819685\ttraining's binary_logloss: 0.226276\n",
      "[470]\ttraining's auc: 0.819774\ttraining's binary_logloss: 0.226247\n",
      "[471]\ttraining's auc: 0.819861\ttraining's binary_logloss: 0.226213\n",
      "[472]\ttraining's auc: 0.819968\ttraining's binary_logloss: 0.226179\n",
      "[473]\ttraining's auc: 0.820043\ttraining's binary_logloss: 0.226145\n",
      "[474]\ttraining's auc: 0.82013\ttraining's binary_logloss: 0.226111\n",
      "[475]\ttraining's auc: 0.820225\ttraining's binary_logloss: 0.226076\n",
      "[476]\ttraining's auc: 0.820319\ttraining's binary_logloss: 0.226042\n",
      "[477]\ttraining's auc: 0.820372\ttraining's binary_logloss: 0.22602\n",
      "[478]\ttraining's auc: 0.820449\ttraining's binary_logloss: 0.225991\n",
      "[479]\ttraining's auc: 0.820548\ttraining's binary_logloss: 0.225958\n",
      "[480]\ttraining's auc: 0.820629\ttraining's binary_logloss: 0.225925\n",
      "[481]\ttraining's auc: 0.820727\ttraining's binary_logloss: 0.22589\n",
      "[482]\ttraining's auc: 0.82081\ttraining's binary_logloss: 0.225856\n",
      "[483]\ttraining's auc: 0.820906\ttraining's binary_logloss: 0.225819\n",
      "[484]\ttraining's auc: 0.821004\ttraining's binary_logloss: 0.225786\n",
      "[485]\ttraining's auc: 0.821089\ttraining's binary_logloss: 0.225755\n",
      "[486]\ttraining's auc: 0.821179\ttraining's binary_logloss: 0.225725\n",
      "[487]\ttraining's auc: 0.821268\ttraining's binary_logloss: 0.225695\n",
      "[488]\ttraining's auc: 0.821349\ttraining's binary_logloss: 0.225664\n",
      "[489]\ttraining's auc: 0.82145\ttraining's binary_logloss: 0.225624\n",
      "[490]\ttraining's auc: 0.821496\ttraining's binary_logloss: 0.22561\n",
      "[491]\ttraining's auc: 0.821559\ttraining's binary_logloss: 0.225587\n",
      "[492]\ttraining's auc: 0.821645\ttraining's binary_logloss: 0.225554\n",
      "[493]\ttraining's auc: 0.821729\ttraining's binary_logloss: 0.22552\n",
      "[494]\ttraining's auc: 0.821831\ttraining's binary_logloss: 0.225483\n",
      "[495]\ttraining's auc: 0.82191\ttraining's binary_logloss: 0.22545\n",
      "[496]\ttraining's auc: 0.821999\ttraining's binary_logloss: 0.225415\n",
      "[497]\ttraining's auc: 0.822098\ttraining's binary_logloss: 0.22538\n",
      "[498]\ttraining's auc: 0.822195\ttraining's binary_logloss: 0.225347\n",
      "[499]\ttraining's auc: 0.822285\ttraining's binary_logloss: 0.225316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's auc: 0.822372\ttraining's binary_logloss: 0.225287\n",
      "[501]\ttraining's auc: 0.822412\ttraining's binary_logloss: 0.225273\n",
      "[502]\ttraining's auc: 0.8225\ttraining's binary_logloss: 0.225241\n",
      "[503]\ttraining's auc: 0.822573\ttraining's binary_logloss: 0.225211\n",
      "[504]\ttraining's auc: 0.822675\ttraining's binary_logloss: 0.225177\n",
      "[505]\ttraining's auc: 0.822748\ttraining's binary_logloss: 0.225146\n",
      "[506]\ttraining's auc: 0.822851\ttraining's binary_logloss: 0.225108\n",
      "[507]\ttraining's auc: 0.82296\ttraining's binary_logloss: 0.225069\n",
      "[508]\ttraining's auc: 0.823022\ttraining's binary_logloss: 0.225044\n",
      "[509]\ttraining's auc: 0.823101\ttraining's binary_logloss: 0.225011\n",
      "[510]\ttraining's auc: 0.823194\ttraining's binary_logloss: 0.224977\n",
      "[511]\ttraining's auc: 0.823278\ttraining's binary_logloss: 0.224946\n",
      "[512]\ttraining's auc: 0.823366\ttraining's binary_logloss: 0.224914\n",
      "[513]\ttraining's auc: 0.823433\ttraining's binary_logloss: 0.224887\n",
      "[514]\ttraining's auc: 0.823499\ttraining's binary_logloss: 0.224863\n",
      "[515]\ttraining's auc: 0.82359\ttraining's binary_logloss: 0.224836\n",
      "[516]\ttraining's auc: 0.823678\ttraining's binary_logloss: 0.224806\n",
      "[517]\ttraining's auc: 0.823763\ttraining's binary_logloss: 0.224776\n",
      "[518]\ttraining's auc: 0.823856\ttraining's binary_logloss: 0.224745\n",
      "[519]\ttraining's auc: 0.823942\ttraining's binary_logloss: 0.224707\n",
      "[520]\ttraining's auc: 0.824021\ttraining's binary_logloss: 0.224676\n",
      "[521]\ttraining's auc: 0.8241\ttraining's binary_logloss: 0.224646\n",
      "[522]\ttraining's auc: 0.824181\ttraining's binary_logloss: 0.224612\n",
      "[523]\ttraining's auc: 0.824237\ttraining's binary_logloss: 0.22459\n",
      "[524]\ttraining's auc: 0.824337\ttraining's binary_logloss: 0.224557\n",
      "[525]\ttraining's auc: 0.824384\ttraining's binary_logloss: 0.224536\n",
      "[526]\ttraining's auc: 0.824471\ttraining's binary_logloss: 0.224503\n",
      "[527]\ttraining's auc: 0.824552\ttraining's binary_logloss: 0.224474\n",
      "[528]\ttraining's auc: 0.824629\ttraining's binary_logloss: 0.224448\n",
      "[529]\ttraining's auc: 0.824713\ttraining's binary_logloss: 0.224417\n",
      "[530]\ttraining's auc: 0.824771\ttraining's binary_logloss: 0.224396\n",
      "[531]\ttraining's auc: 0.824841\ttraining's binary_logloss: 0.224368\n",
      "[532]\ttraining's auc: 0.824914\ttraining's binary_logloss: 0.224344\n",
      "[533]\ttraining's auc: 0.82498\ttraining's binary_logloss: 0.224311\n",
      "[534]\ttraining's auc: 0.825057\ttraining's binary_logloss: 0.224283\n",
      "[535]\ttraining's auc: 0.82513\ttraining's binary_logloss: 0.224257\n",
      "[536]\ttraining's auc: 0.825196\ttraining's binary_logloss: 0.22423\n",
      "[537]\ttraining's auc: 0.825249\ttraining's binary_logloss: 0.224211\n",
      "[538]\ttraining's auc: 0.825298\ttraining's binary_logloss: 0.224189\n",
      "[539]\ttraining's auc: 0.825381\ttraining's binary_logloss: 0.224159\n",
      "[540]\ttraining's auc: 0.825447\ttraining's binary_logloss: 0.22413\n",
      "[541]\ttraining's auc: 0.825522\ttraining's binary_logloss: 0.224099\n",
      "[542]\ttraining's auc: 0.825569\ttraining's binary_logloss: 0.224082\n",
      "[543]\ttraining's auc: 0.825657\ttraining's binary_logloss: 0.224052\n",
      "[544]\ttraining's auc: 0.825746\ttraining's binary_logloss: 0.224018\n",
      "[545]\ttraining's auc: 0.825826\ttraining's binary_logloss: 0.22399\n",
      "[546]\ttraining's auc: 0.825903\ttraining's binary_logloss: 0.223959\n",
      "[547]\ttraining's auc: 0.826009\ttraining's binary_logloss: 0.223925\n",
      "[548]\ttraining's auc: 0.826106\ttraining's binary_logloss: 0.22389\n",
      "[549]\ttraining's auc: 0.826168\ttraining's binary_logloss: 0.223864\n",
      "[550]\ttraining's auc: 0.826248\ttraining's binary_logloss: 0.223833\n",
      "[551]\ttraining's auc: 0.826332\ttraining's binary_logloss: 0.223804\n",
      "[552]\ttraining's auc: 0.826414\ttraining's binary_logloss: 0.223775\n",
      "[553]\ttraining's auc: 0.826491\ttraining's binary_logloss: 0.223746\n",
      "[554]\ttraining's auc: 0.826566\ttraining's binary_logloss: 0.223716\n",
      "[555]\ttraining's auc: 0.826637\ttraining's binary_logloss: 0.22369\n",
      "[556]\ttraining's auc: 0.826721\ttraining's binary_logloss: 0.223657\n",
      "[557]\ttraining's auc: 0.826814\ttraining's binary_logloss: 0.22363\n",
      "[558]\ttraining's auc: 0.826898\ttraining's binary_logloss: 0.2236\n",
      "[559]\ttraining's auc: 0.826975\ttraining's binary_logloss: 0.223571\n",
      "[560]\ttraining's auc: 0.827033\ttraining's binary_logloss: 0.223542\n",
      "[561]\ttraining's auc: 0.827133\ttraining's binary_logloss: 0.223508\n",
      "[562]\ttraining's auc: 0.827213\ttraining's binary_logloss: 0.223477\n",
      "[563]\ttraining's auc: 0.827314\ttraining's binary_logloss: 0.223445\n",
      "[564]\ttraining's auc: 0.827393\ttraining's binary_logloss: 0.223416\n",
      "[565]\ttraining's auc: 0.827463\ttraining's binary_logloss: 0.223387\n",
      "[566]\ttraining's auc: 0.827531\ttraining's binary_logloss: 0.223362\n",
      "[567]\ttraining's auc: 0.827611\ttraining's binary_logloss: 0.223331\n",
      "[568]\ttraining's auc: 0.82769\ttraining's binary_logloss: 0.223302\n",
      "[569]\ttraining's auc: 0.827766\ttraining's binary_logloss: 0.223271\n",
      "[570]\ttraining's auc: 0.827858\ttraining's binary_logloss: 0.223238\n",
      "[571]\ttraining's auc: 0.827944\ttraining's binary_logloss: 0.2232\n",
      "[572]\ttraining's auc: 0.828028\ttraining's binary_logloss: 0.223168\n",
      "[573]\ttraining's auc: 0.828097\ttraining's binary_logloss: 0.22314\n",
      "[574]\ttraining's auc: 0.828132\ttraining's binary_logloss: 0.223125\n",
      "[575]\ttraining's auc: 0.828194\ttraining's binary_logloss: 0.223099\n",
      "[576]\ttraining's auc: 0.828222\ttraining's binary_logloss: 0.223083\n",
      "[577]\ttraining's auc: 0.828299\ttraining's binary_logloss: 0.223054\n",
      "[578]\ttraining's auc: 0.828385\ttraining's binary_logloss: 0.223022\n",
      "[579]\ttraining's auc: 0.828473\ttraining's binary_logloss: 0.22299\n",
      "[580]\ttraining's auc: 0.828547\ttraining's binary_logloss: 0.222961\n",
      "[581]\ttraining's auc: 0.828648\ttraining's binary_logloss: 0.222925\n",
      "[582]\ttraining's auc: 0.828712\ttraining's binary_logloss: 0.222897\n",
      "[583]\ttraining's auc: 0.828794\ttraining's binary_logloss: 0.22287\n",
      "[584]\ttraining's auc: 0.828855\ttraining's binary_logloss: 0.222843\n",
      "[585]\ttraining's auc: 0.828929\ttraining's binary_logloss: 0.222817\n",
      "[586]\ttraining's auc: 0.829022\ttraining's binary_logloss: 0.222785\n",
      "[587]\ttraining's auc: 0.829085\ttraining's binary_logloss: 0.222757\n",
      "[588]\ttraining's auc: 0.829174\ttraining's binary_logloss: 0.222727\n",
      "[589]\ttraining's auc: 0.829253\ttraining's binary_logloss: 0.222699\n",
      "[590]\ttraining's auc: 0.829332\ttraining's binary_logloss: 0.222667\n",
      "[591]\ttraining's auc: 0.829415\ttraining's binary_logloss: 0.222636\n",
      "[592]\ttraining's auc: 0.829504\ttraining's binary_logloss: 0.222608\n",
      "[593]\ttraining's auc: 0.829586\ttraining's binary_logloss: 0.222572\n",
      "[594]\ttraining's auc: 0.829656\ttraining's binary_logloss: 0.222547\n",
      "[595]\ttraining's auc: 0.829723\ttraining's binary_logloss: 0.222518\n",
      "[596]\ttraining's auc: 0.82982\ttraining's binary_logloss: 0.22249\n",
      "[597]\ttraining's auc: 0.829906\ttraining's binary_logloss: 0.222459\n",
      "[598]\ttraining's auc: 0.829993\ttraining's binary_logloss: 0.222423\n",
      "[599]\ttraining's auc: 0.830078\ttraining's binary_logloss: 0.222392\n",
      "[600]\ttraining's auc: 0.830157\ttraining's binary_logloss: 0.222363\n",
      "[601]\ttraining's auc: 0.830222\ttraining's binary_logloss: 0.222335\n",
      "[602]\ttraining's auc: 0.830296\ttraining's binary_logloss: 0.222307\n",
      "[603]\ttraining's auc: 0.830349\ttraining's binary_logloss: 0.222287\n",
      "[604]\ttraining's auc: 0.83043\ttraining's binary_logloss: 0.222258\n",
      "[605]\ttraining's auc: 0.830512\ttraining's binary_logloss: 0.222224\n",
      "[606]\ttraining's auc: 0.830603\ttraining's binary_logloss: 0.222194\n",
      "[607]\ttraining's auc: 0.83069\ttraining's binary_logloss: 0.222159\n",
      "[608]\ttraining's auc: 0.830762\ttraining's binary_logloss: 0.222128\n",
      "[609]\ttraining's auc: 0.830807\ttraining's binary_logloss: 0.222109\n",
      "[610]\ttraining's auc: 0.830906\ttraining's binary_logloss: 0.222075\n",
      "[611]\ttraining's auc: 0.830998\ttraining's binary_logloss: 0.222045\n",
      "[612]\ttraining's auc: 0.831084\ttraining's binary_logloss: 0.222015\n",
      "[613]\ttraining's auc: 0.831167\ttraining's binary_logloss: 0.221986\n",
      "[614]\ttraining's auc: 0.831247\ttraining's binary_logloss: 0.221951\n",
      "[615]\ttraining's auc: 0.831333\ttraining's binary_logloss: 0.221921\n",
      "[616]\ttraining's auc: 0.831411\ttraining's binary_logloss: 0.221891\n",
      "[617]\ttraining's auc: 0.831476\ttraining's binary_logloss: 0.221861\n",
      "[618]\ttraining's auc: 0.831537\ttraining's binary_logloss: 0.221835\n",
      "[619]\ttraining's auc: 0.831611\ttraining's binary_logloss: 0.221803\n",
      "[620]\ttraining's auc: 0.831708\ttraining's binary_logloss: 0.22177\n",
      "[621]\ttraining's auc: 0.831791\ttraining's binary_logloss: 0.221741\n",
      "[622]\ttraining's auc: 0.831842\ttraining's binary_logloss: 0.221724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[623]\ttraining's auc: 0.831908\ttraining's binary_logloss: 0.221701\n",
      "[624]\ttraining's auc: 0.83199\ttraining's binary_logloss: 0.221672\n",
      "[625]\ttraining's auc: 0.832076\ttraining's binary_logloss: 0.221642\n",
      "[626]\ttraining's auc: 0.832105\ttraining's binary_logloss: 0.221629\n",
      "[627]\ttraining's auc: 0.832182\ttraining's binary_logloss: 0.221601\n",
      "[628]\ttraining's auc: 0.832257\ttraining's binary_logloss: 0.221568\n",
      "[629]\ttraining's auc: 0.83233\ttraining's binary_logloss: 0.221537\n",
      "[630]\ttraining's auc: 0.832413\ttraining's binary_logloss: 0.221509\n",
      "[631]\ttraining's auc: 0.832465\ttraining's binary_logloss: 0.221483\n",
      "[632]\ttraining's auc: 0.832511\ttraining's binary_logloss: 0.221466\n",
      "[633]\ttraining's auc: 0.83258\ttraining's binary_logloss: 0.221439\n",
      "[634]\ttraining's auc: 0.832661\ttraining's binary_logloss: 0.221411\n",
      "[635]\ttraining's auc: 0.832723\ttraining's binary_logloss: 0.221385\n",
      "[636]\ttraining's auc: 0.832768\ttraining's binary_logloss: 0.221368\n",
      "[637]\ttraining's auc: 0.832858\ttraining's binary_logloss: 0.221336\n",
      "[638]\ttraining's auc: 0.832936\ttraining's binary_logloss: 0.221308\n",
      "[639]\ttraining's auc: 0.833013\ttraining's binary_logloss: 0.221278\n",
      "[640]\ttraining's auc: 0.833068\ttraining's binary_logloss: 0.221259\n",
      "[641]\ttraining's auc: 0.833142\ttraining's binary_logloss: 0.221231\n",
      "[642]\ttraining's auc: 0.83321\ttraining's binary_logloss: 0.221206\n",
      "[643]\ttraining's auc: 0.833278\ttraining's binary_logloss: 0.221177\n",
      "[644]\ttraining's auc: 0.833371\ttraining's binary_logloss: 0.221148\n",
      "[645]\ttraining's auc: 0.833475\ttraining's binary_logloss: 0.22111\n",
      "[646]\ttraining's auc: 0.833555\ttraining's binary_logloss: 0.221076\n",
      "[647]\ttraining's auc: 0.833636\ttraining's binary_logloss: 0.221045\n",
      "[648]\ttraining's auc: 0.833699\ttraining's binary_logloss: 0.22102\n",
      "[649]\ttraining's auc: 0.83377\ttraining's binary_logloss: 0.220994\n",
      "[650]\ttraining's auc: 0.833823\ttraining's binary_logloss: 0.220976\n",
      "[651]\ttraining's auc: 0.833894\ttraining's binary_logloss: 0.220948\n",
      "[652]\ttraining's auc: 0.833961\ttraining's binary_logloss: 0.220922\n",
      "[653]\ttraining's auc: 0.834034\ttraining's binary_logloss: 0.220894\n",
      "[654]\ttraining's auc: 0.834102\ttraining's binary_logloss: 0.220865\n",
      "[655]\ttraining's auc: 0.8342\ttraining's binary_logloss: 0.220833\n",
      "[656]\ttraining's auc: 0.834281\ttraining's binary_logloss: 0.220805\n",
      "[657]\ttraining's auc: 0.834366\ttraining's binary_logloss: 0.220778\n",
      "[658]\ttraining's auc: 0.83444\ttraining's binary_logloss: 0.220752\n",
      "[659]\ttraining's auc: 0.834512\ttraining's binary_logloss: 0.220726\n",
      "[660]\ttraining's auc: 0.83459\ttraining's binary_logloss: 0.220697\n",
      "[661]\ttraining's auc: 0.834656\ttraining's binary_logloss: 0.220672\n",
      "[662]\ttraining's auc: 0.834726\ttraining's binary_logloss: 0.220643\n",
      "[663]\ttraining's auc: 0.83479\ttraining's binary_logloss: 0.220616\n",
      "[664]\ttraining's auc: 0.834839\ttraining's binary_logloss: 0.220601\n",
      "[665]\ttraining's auc: 0.834924\ttraining's binary_logloss: 0.220569\n",
      "[666]\ttraining's auc: 0.834993\ttraining's binary_logloss: 0.220542\n",
      "[667]\ttraining's auc: 0.835035\ttraining's binary_logloss: 0.220525\n",
      "[668]\ttraining's auc: 0.835102\ttraining's binary_logloss: 0.220501\n",
      "[669]\ttraining's auc: 0.835171\ttraining's binary_logloss: 0.220477\n",
      "[670]\ttraining's auc: 0.835236\ttraining's binary_logloss: 0.22045\n",
      "[671]\ttraining's auc: 0.835283\ttraining's binary_logloss: 0.220432\n",
      "[672]\ttraining's auc: 0.835371\ttraining's binary_logloss: 0.2204\n",
      "[673]\ttraining's auc: 0.835445\ttraining's binary_logloss: 0.22037\n",
      "[674]\ttraining's auc: 0.835523\ttraining's binary_logloss: 0.220343\n",
      "[675]\ttraining's auc: 0.835556\ttraining's binary_logloss: 0.220331\n",
      "[676]\ttraining's auc: 0.835636\ttraining's binary_logloss: 0.220303\n",
      "[677]\ttraining's auc: 0.835713\ttraining's binary_logloss: 0.220275\n",
      "[678]\ttraining's auc: 0.835796\ttraining's binary_logloss: 0.220243\n",
      "[679]\ttraining's auc: 0.835873\ttraining's binary_logloss: 0.220213\n",
      "[680]\ttraining's auc: 0.835953\ttraining's binary_logloss: 0.220186\n",
      "[681]\ttraining's auc: 0.836037\ttraining's binary_logloss: 0.220157\n",
      "[682]\ttraining's auc: 0.836107\ttraining's binary_logloss: 0.220131\n",
      "[683]\ttraining's auc: 0.83618\ttraining's binary_logloss: 0.220102\n",
      "[684]\ttraining's auc: 0.836265\ttraining's binary_logloss: 0.220072\n",
      "[685]\ttraining's auc: 0.836334\ttraining's binary_logloss: 0.220041\n",
      "[686]\ttraining's auc: 0.836409\ttraining's binary_logloss: 0.22001\n",
      "[687]\ttraining's auc: 0.836482\ttraining's binary_logloss: 0.219982\n",
      "[688]\ttraining's auc: 0.836537\ttraining's binary_logloss: 0.219957\n",
      "[689]\ttraining's auc: 0.836595\ttraining's binary_logloss: 0.219931\n",
      "[690]\ttraining's auc: 0.83669\ttraining's binary_logloss: 0.219901\n",
      "[691]\ttraining's auc: 0.836738\ttraining's binary_logloss: 0.219885\n",
      "[692]\ttraining's auc: 0.83681\ttraining's binary_logloss: 0.219858\n",
      "[693]\ttraining's auc: 0.836869\ttraining's binary_logloss: 0.219838\n",
      "[694]\ttraining's auc: 0.836956\ttraining's binary_logloss: 0.219806\n",
      "[695]\ttraining's auc: 0.837017\ttraining's binary_logloss: 0.219788\n",
      "[696]\ttraining's auc: 0.837096\ttraining's binary_logloss: 0.21976\n",
      "[697]\ttraining's auc: 0.837175\ttraining's binary_logloss: 0.219732\n",
      "[698]\ttraining's auc: 0.837225\ttraining's binary_logloss: 0.219708\n",
      "[699]\ttraining's auc: 0.837273\ttraining's binary_logloss: 0.219689\n",
      "[700]\ttraining's auc: 0.837336\ttraining's binary_logloss: 0.219664\n",
      "[701]\ttraining's auc: 0.837409\ttraining's binary_logloss: 0.219639\n",
      "[702]\ttraining's auc: 0.837491\ttraining's binary_logloss: 0.219611\n",
      "[703]\ttraining's auc: 0.837564\ttraining's binary_logloss: 0.219579\n",
      "[704]\ttraining's auc: 0.837623\ttraining's binary_logloss: 0.219553\n",
      "[705]\ttraining's auc: 0.837685\ttraining's binary_logloss: 0.219526\n",
      "[706]\ttraining's auc: 0.837775\ttraining's binary_logloss: 0.219499\n",
      "[707]\ttraining's auc: 0.837839\ttraining's binary_logloss: 0.219475\n",
      "[708]\ttraining's auc: 0.837899\ttraining's binary_logloss: 0.219445\n",
      "[709]\ttraining's auc: 0.837962\ttraining's binary_logloss: 0.219422\n",
      "[710]\ttraining's auc: 0.838038\ttraining's binary_logloss: 0.219394\n",
      "[711]\ttraining's auc: 0.838115\ttraining's binary_logloss: 0.219367\n",
      "[712]\ttraining's auc: 0.838139\ttraining's binary_logloss: 0.219356\n",
      "[713]\ttraining's auc: 0.838189\ttraining's binary_logloss: 0.219337\n",
      "[714]\ttraining's auc: 0.838267\ttraining's binary_logloss: 0.219307\n",
      "[715]\ttraining's auc: 0.838352\ttraining's binary_logloss: 0.21928\n",
      "[716]\ttraining's auc: 0.838429\ttraining's binary_logloss: 0.21925\n",
      "[717]\ttraining's auc: 0.838483\ttraining's binary_logloss: 0.219227\n",
      "[718]\ttraining's auc: 0.838525\ttraining's binary_logloss: 0.21921\n",
      "[719]\ttraining's auc: 0.838593\ttraining's binary_logloss: 0.219181\n",
      "[720]\ttraining's auc: 0.838679\ttraining's binary_logloss: 0.219154\n",
      "[721]\ttraining's auc: 0.838741\ttraining's binary_logloss: 0.219131\n",
      "[722]\ttraining's auc: 0.83881\ttraining's binary_logloss: 0.219102\n",
      "[723]\ttraining's auc: 0.838874\ttraining's binary_logloss: 0.219076\n",
      "[724]\ttraining's auc: 0.838929\ttraining's binary_logloss: 0.219054\n",
      "[725]\ttraining's auc: 0.838996\ttraining's binary_logloss: 0.219028\n",
      "[726]\ttraining's auc: 0.839088\ttraining's binary_logloss: 0.219001\n",
      "[727]\ttraining's auc: 0.839159\ttraining's binary_logloss: 0.218973\n",
      "[728]\ttraining's auc: 0.839237\ttraining's binary_logloss: 0.218946\n",
      "[729]\ttraining's auc: 0.839309\ttraining's binary_logloss: 0.218919\n",
      "[730]\ttraining's auc: 0.839338\ttraining's binary_logloss: 0.218908\n",
      "[731]\ttraining's auc: 0.839382\ttraining's binary_logloss: 0.218892\n",
      "[732]\ttraining's auc: 0.839444\ttraining's binary_logloss: 0.218866\n",
      "[733]\ttraining's auc: 0.839535\ttraining's binary_logloss: 0.218838\n",
      "[734]\ttraining's auc: 0.839598\ttraining's binary_logloss: 0.218811\n",
      "[735]\ttraining's auc: 0.839675\ttraining's binary_logloss: 0.218785\n",
      "[736]\ttraining's auc: 0.839734\ttraining's binary_logloss: 0.218763\n",
      "[737]\ttraining's auc: 0.839779\ttraining's binary_logloss: 0.21874\n",
      "[738]\ttraining's auc: 0.839809\ttraining's binary_logloss: 0.218729\n",
      "[739]\ttraining's auc: 0.839875\ttraining's binary_logloss: 0.218703\n",
      "[740]\ttraining's auc: 0.839964\ttraining's binary_logloss: 0.218673\n",
      "[741]\ttraining's auc: 0.840039\ttraining's binary_logloss: 0.218648\n",
      "[742]\ttraining's auc: 0.84008\ttraining's binary_logloss: 0.218632\n",
      "[743]\ttraining's auc: 0.840151\ttraining's binary_logloss: 0.218603\n",
      "[744]\ttraining's auc: 0.840212\ttraining's binary_logloss: 0.218577\n",
      "[745]\ttraining's auc: 0.840283\ttraining's binary_logloss: 0.218547\n",
      "[746]\ttraining's auc: 0.840343\ttraining's binary_logloss: 0.218522\n",
      "[747]\ttraining's auc: 0.840368\ttraining's binary_logloss: 0.218512\n",
      "[748]\ttraining's auc: 0.840418\ttraining's binary_logloss: 0.218494\n",
      "[749]\ttraining's auc: 0.840492\ttraining's binary_logloss: 0.218464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttraining's auc: 0.840574\ttraining's binary_logloss: 0.218438\n",
      "[751]\ttraining's auc: 0.840601\ttraining's binary_logloss: 0.218427\n",
      "[752]\ttraining's auc: 0.840666\ttraining's binary_logloss: 0.2184\n",
      "[753]\ttraining's auc: 0.84073\ttraining's binary_logloss: 0.218372\n",
      "[754]\ttraining's auc: 0.840803\ttraining's binary_logloss: 0.218346\n",
      "[755]\ttraining's auc: 0.840887\ttraining's binary_logloss: 0.218318\n",
      "[756]\ttraining's auc: 0.840922\ttraining's binary_logloss: 0.218302\n",
      "[757]\ttraining's auc: 0.840968\ttraining's binary_logloss: 0.218287\n",
      "[758]\ttraining's auc: 0.841028\ttraining's binary_logloss: 0.218263\n",
      "[759]\ttraining's auc: 0.841136\ttraining's binary_logloss: 0.218232\n",
      "[760]\ttraining's auc: 0.841201\ttraining's binary_logloss: 0.218205\n",
      "[761]\ttraining's auc: 0.841264\ttraining's binary_logloss: 0.218181\n",
      "[762]\ttraining's auc: 0.841317\ttraining's binary_logloss: 0.218163\n",
      "[763]\ttraining's auc: 0.841415\ttraining's binary_logloss: 0.218137\n",
      "[764]\ttraining's auc: 0.841471\ttraining's binary_logloss: 0.218117\n",
      "[765]\ttraining's auc: 0.841503\ttraining's binary_logloss: 0.218102\n",
      "[766]\ttraining's auc: 0.841566\ttraining's binary_logloss: 0.218076\n",
      "[767]\ttraining's auc: 0.84164\ttraining's binary_logloss: 0.218047\n",
      "[768]\ttraining's auc: 0.841712\ttraining's binary_logloss: 0.218022\n",
      "[769]\ttraining's auc: 0.841785\ttraining's binary_logloss: 0.217995\n",
      "[770]\ttraining's auc: 0.841848\ttraining's binary_logloss: 0.217969\n",
      "[771]\ttraining's auc: 0.841943\ttraining's binary_logloss: 0.217941\n",
      "[772]\ttraining's auc: 0.842023\ttraining's binary_logloss: 0.217913\n",
      "[773]\ttraining's auc: 0.842043\ttraining's binary_logloss: 0.217902\n",
      "[774]\ttraining's auc: 0.842104\ttraining's binary_logloss: 0.217875\n",
      "[775]\ttraining's auc: 0.842158\ttraining's binary_logloss: 0.217852\n",
      "[776]\ttraining's auc: 0.842226\ttraining's binary_logloss: 0.217825\n",
      "[777]\ttraining's auc: 0.842299\ttraining's binary_logloss: 0.217798\n",
      "[778]\ttraining's auc: 0.842336\ttraining's binary_logloss: 0.217783\n",
      "[779]\ttraining's auc: 0.84242\ttraining's binary_logloss: 0.217754\n",
      "[780]\ttraining's auc: 0.842495\ttraining's binary_logloss: 0.217728\n",
      "[781]\ttraining's auc: 0.842553\ttraining's binary_logloss: 0.217702\n",
      "[782]\ttraining's auc: 0.842615\ttraining's binary_logloss: 0.217679\n",
      "[783]\ttraining's auc: 0.842724\ttraining's binary_logloss: 0.217647\n",
      "[784]\ttraining's auc: 0.842802\ttraining's binary_logloss: 0.217622\n",
      "[785]\ttraining's auc: 0.842877\ttraining's binary_logloss: 0.217592\n",
      "[786]\ttraining's auc: 0.842953\ttraining's binary_logloss: 0.217562\n",
      "[787]\ttraining's auc: 0.843015\ttraining's binary_logloss: 0.217541\n",
      "[788]\ttraining's auc: 0.843043\ttraining's binary_logloss: 0.21753\n",
      "[789]\ttraining's auc: 0.843107\ttraining's binary_logloss: 0.217504\n",
      "[790]\ttraining's auc: 0.843171\ttraining's binary_logloss: 0.217481\n",
      "[791]\ttraining's auc: 0.843245\ttraining's binary_logloss: 0.217454\n",
      "[792]\ttraining's auc: 0.843306\ttraining's binary_logloss: 0.217431\n",
      "[793]\ttraining's auc: 0.843365\ttraining's binary_logloss: 0.217407\n",
      "[794]\ttraining's auc: 0.843427\ttraining's binary_logloss: 0.217381\n",
      "[795]\ttraining's auc: 0.84349\ttraining's binary_logloss: 0.217357\n",
      "[796]\ttraining's auc: 0.843553\ttraining's binary_logloss: 0.21733\n",
      "[797]\ttraining's auc: 0.843585\ttraining's binary_logloss: 0.217316\n",
      "[798]\ttraining's auc: 0.843649\ttraining's binary_logloss: 0.217292\n",
      "[799]\ttraining's auc: 0.843712\ttraining's binary_logloss: 0.217265\n",
      "[800]\ttraining's auc: 0.843784\ttraining's binary_logloss: 0.217236\n",
      "[801]\ttraining's auc: 0.84386\ttraining's binary_logloss: 0.217205\n",
      "[802]\ttraining's auc: 0.843935\ttraining's binary_logloss: 0.217177\n",
      "[803]\ttraining's auc: 0.84401\ttraining's binary_logloss: 0.217151\n",
      "[804]\ttraining's auc: 0.844092\ttraining's binary_logloss: 0.217122\n",
      "[805]\ttraining's auc: 0.844151\ttraining's binary_logloss: 0.217099\n",
      "[806]\ttraining's auc: 0.84417\ttraining's binary_logloss: 0.217091\n",
      "[807]\ttraining's auc: 0.844207\ttraining's binary_logloss: 0.217074\n",
      "[808]\ttraining's auc: 0.844234\ttraining's binary_logloss: 0.217064\n",
      "[809]\ttraining's auc: 0.844299\ttraining's binary_logloss: 0.217039\n",
      "[810]\ttraining's auc: 0.844362\ttraining's binary_logloss: 0.217014\n",
      "[811]\ttraining's auc: 0.844425\ttraining's binary_logloss: 0.21699\n",
      "[812]\ttraining's auc: 0.844529\ttraining's binary_logloss: 0.216959\n",
      "[813]\ttraining's auc: 0.844595\ttraining's binary_logloss: 0.216933\n",
      "[814]\ttraining's auc: 0.844646\ttraining's binary_logloss: 0.216909\n",
      "[815]\ttraining's auc: 0.844668\ttraining's binary_logloss: 0.216898\n",
      "[816]\ttraining's auc: 0.844729\ttraining's binary_logloss: 0.216873\n",
      "[817]\ttraining's auc: 0.844767\ttraining's binary_logloss: 0.21686\n",
      "[818]\ttraining's auc: 0.844843\ttraining's binary_logloss: 0.216837\n",
      "[819]\ttraining's auc: 0.844906\ttraining's binary_logloss: 0.216816\n",
      "[820]\ttraining's auc: 0.844973\ttraining's binary_logloss: 0.216787\n",
      "[821]\ttraining's auc: 0.845022\ttraining's binary_logloss: 0.216768\n",
      "[822]\ttraining's auc: 0.845082\ttraining's binary_logloss: 0.216745\n",
      "[823]\ttraining's auc: 0.845169\ttraining's binary_logloss: 0.216716\n",
      "[824]\ttraining's auc: 0.845224\ttraining's binary_logloss: 0.216694\n",
      "[825]\ttraining's auc: 0.845285\ttraining's binary_logloss: 0.216672\n",
      "[826]\ttraining's auc: 0.84534\ttraining's binary_logloss: 0.216648\n",
      "[827]\ttraining's auc: 0.845393\ttraining's binary_logloss: 0.216624\n",
      "[828]\ttraining's auc: 0.845435\ttraining's binary_logloss: 0.216609\n",
      "[829]\ttraining's auc: 0.845505\ttraining's binary_logloss: 0.216581\n",
      "[830]\ttraining's auc: 0.845536\ttraining's binary_logloss: 0.21657\n",
      "[831]\ttraining's auc: 0.845592\ttraining's binary_logloss: 0.216546\n",
      "[832]\ttraining's auc: 0.845633\ttraining's binary_logloss: 0.216532\n",
      "[833]\ttraining's auc: 0.845666\ttraining's binary_logloss: 0.216518\n",
      "[834]\ttraining's auc: 0.845725\ttraining's binary_logloss: 0.216493\n",
      "[835]\ttraining's auc: 0.845797\ttraining's binary_logloss: 0.216466\n",
      "[836]\ttraining's auc: 0.845867\ttraining's binary_logloss: 0.216441\n",
      "[837]\ttraining's auc: 0.845938\ttraining's binary_logloss: 0.216416\n",
      "[838]\ttraining's auc: 0.845998\ttraining's binary_logloss: 0.216392\n",
      "[839]\ttraining's auc: 0.846058\ttraining's binary_logloss: 0.216367\n",
      "[840]\ttraining's auc: 0.846106\ttraining's binary_logloss: 0.216351\n",
      "[841]\ttraining's auc: 0.846166\ttraining's binary_logloss: 0.216327\n",
      "[842]\ttraining's auc: 0.846234\ttraining's binary_logloss: 0.2163\n",
      "[843]\ttraining's auc: 0.846288\ttraining's binary_logloss: 0.216278\n",
      "[844]\ttraining's auc: 0.846356\ttraining's binary_logloss: 0.216252\n",
      "[845]\ttraining's auc: 0.846413\ttraining's binary_logloss: 0.21623\n",
      "[846]\ttraining's auc: 0.846474\ttraining's binary_logloss: 0.216204\n",
      "[847]\ttraining's auc: 0.846536\ttraining's binary_logloss: 0.216179\n",
      "[848]\ttraining's auc: 0.846594\ttraining's binary_logloss: 0.216154\n",
      "[849]\ttraining's auc: 0.846661\ttraining's binary_logloss: 0.216127\n",
      "[850]\ttraining's auc: 0.846705\ttraining's binary_logloss: 0.216104\n",
      "[851]\ttraining's auc: 0.846801\ttraining's binary_logloss: 0.216076\n",
      "[852]\ttraining's auc: 0.846839\ttraining's binary_logloss: 0.21606\n",
      "[853]\ttraining's auc: 0.846897\ttraining's binary_logloss: 0.216033\n",
      "[854]\ttraining's auc: 0.846969\ttraining's binary_logloss: 0.216006\n",
      "[855]\ttraining's auc: 0.847048\ttraining's binary_logloss: 0.21598\n",
      "[856]\ttraining's auc: 0.847101\ttraining's binary_logloss: 0.215958\n",
      "[857]\ttraining's auc: 0.84714\ttraining's binary_logloss: 0.215942\n",
      "[858]\ttraining's auc: 0.847151\ttraining's binary_logloss: 0.215937\n",
      "[859]\ttraining's auc: 0.847215\ttraining's binary_logloss: 0.215912\n",
      "[860]\ttraining's auc: 0.847313\ttraining's binary_logloss: 0.215884\n",
      "[861]\ttraining's auc: 0.847381\ttraining's binary_logloss: 0.215857\n",
      "[862]\ttraining's auc: 0.847441\ttraining's binary_logloss: 0.215834\n",
      "[863]\ttraining's auc: 0.847493\ttraining's binary_logloss: 0.215808\n",
      "[864]\ttraining's auc: 0.847552\ttraining's binary_logloss: 0.215784\n",
      "[865]\ttraining's auc: 0.847591\ttraining's binary_logloss: 0.215768\n",
      "[866]\ttraining's auc: 0.847643\ttraining's binary_logloss: 0.215743\n",
      "[867]\ttraining's auc: 0.847701\ttraining's binary_logloss: 0.21572\n",
      "[868]\ttraining's auc: 0.847781\ttraining's binary_logloss: 0.215692\n",
      "[869]\ttraining's auc: 0.847819\ttraining's binary_logloss: 0.215674\n",
      "[870]\ttraining's auc: 0.847902\ttraining's binary_logloss: 0.215646\n",
      "[871]\ttraining's auc: 0.847954\ttraining's binary_logloss: 0.21562\n",
      "[872]\ttraining's auc: 0.848019\ttraining's binary_logloss: 0.215595\n",
      "[873]\ttraining's auc: 0.848078\ttraining's binary_logloss: 0.215569\n",
      "[874]\ttraining's auc: 0.848143\ttraining's binary_logloss: 0.215543\n",
      "[875]\ttraining's auc: 0.848165\ttraining's binary_logloss: 0.215535\n",
      "[876]\ttraining's auc: 0.84822\ttraining's binary_logloss: 0.215513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[877]\ttraining's auc: 0.848278\ttraining's binary_logloss: 0.215489\n",
      "[878]\ttraining's auc: 0.848317\ttraining's binary_logloss: 0.215473\n",
      "[879]\ttraining's auc: 0.848371\ttraining's binary_logloss: 0.215448\n",
      "[880]\ttraining's auc: 0.848419\ttraining's binary_logloss: 0.215429\n",
      "[881]\ttraining's auc: 0.848469\ttraining's binary_logloss: 0.215404\n",
      "[882]\ttraining's auc: 0.848501\ttraining's binary_logloss: 0.215393\n",
      "[883]\ttraining's auc: 0.848559\ttraining's binary_logloss: 0.215369\n",
      "[884]\ttraining's auc: 0.848633\ttraining's binary_logloss: 0.215345\n",
      "[885]\ttraining's auc: 0.848691\ttraining's binary_logloss: 0.215322\n",
      "[886]\ttraining's auc: 0.848772\ttraining's binary_logloss: 0.215288\n",
      "[887]\ttraining's auc: 0.848824\ttraining's binary_logloss: 0.215264\n",
      "[888]\ttraining's auc: 0.848904\ttraining's binary_logloss: 0.215238\n",
      "[889]\ttraining's auc: 0.848966\ttraining's binary_logloss: 0.215212\n",
      "[890]\ttraining's auc: 0.849023\ttraining's binary_logloss: 0.215191\n",
      "[891]\ttraining's auc: 0.849077\ttraining's binary_logloss: 0.21517\n",
      "[892]\ttraining's auc: 0.849145\ttraining's binary_logloss: 0.215144\n",
      "[893]\ttraining's auc: 0.849207\ttraining's binary_logloss: 0.215118\n",
      "[894]\ttraining's auc: 0.849291\ttraining's binary_logloss: 0.215084\n",
      "[895]\ttraining's auc: 0.849327\ttraining's binary_logloss: 0.215071\n",
      "[896]\ttraining's auc: 0.849394\ttraining's binary_logloss: 0.215045\n",
      "[897]\ttraining's auc: 0.849476\ttraining's binary_logloss: 0.215012\n",
      "[898]\ttraining's auc: 0.849537\ttraining's binary_logloss: 0.214988\n",
      "[899]\ttraining's auc: 0.849627\ttraining's binary_logloss: 0.21496\n",
      "[900]\ttraining's auc: 0.849663\ttraining's binary_logloss: 0.214943\n",
      "[901]\ttraining's auc: 0.849731\ttraining's binary_logloss: 0.214921\n",
      "[902]\ttraining's auc: 0.849783\ttraining's binary_logloss: 0.214896\n",
      "[903]\ttraining's auc: 0.849863\ttraining's binary_logloss: 0.214867\n",
      "[904]\ttraining's auc: 0.849908\ttraining's binary_logloss: 0.21485\n",
      "[905]\ttraining's auc: 0.849939\ttraining's binary_logloss: 0.214839\n",
      "[906]\ttraining's auc: 0.850011\ttraining's binary_logloss: 0.214811\n",
      "[907]\ttraining's auc: 0.850094\ttraining's binary_logloss: 0.214783\n",
      "[908]\ttraining's auc: 0.85013\ttraining's binary_logloss: 0.214768\n",
      "[909]\ttraining's auc: 0.850177\ttraining's binary_logloss: 0.214744\n",
      "[910]\ttraining's auc: 0.850236\ttraining's binary_logloss: 0.214721\n",
      "[911]\ttraining's auc: 0.850292\ttraining's binary_logloss: 0.214698\n",
      "[912]\ttraining's auc: 0.850347\ttraining's binary_logloss: 0.214677\n",
      "[913]\ttraining's auc: 0.850384\ttraining's binary_logloss: 0.21466\n",
      "[914]\ttraining's auc: 0.850443\ttraining's binary_logloss: 0.214633\n",
      "[915]\ttraining's auc: 0.850508\ttraining's binary_logloss: 0.214607\n",
      "[916]\ttraining's auc: 0.850568\ttraining's binary_logloss: 0.214579\n",
      "[917]\ttraining's auc: 0.850668\ttraining's binary_logloss: 0.214551\n",
      "[918]\ttraining's auc: 0.850723\ttraining's binary_logloss: 0.214529\n",
      "[919]\ttraining's auc: 0.850787\ttraining's binary_logloss: 0.214502\n",
      "[920]\ttraining's auc: 0.850844\ttraining's binary_logloss: 0.214476\n",
      "[921]\ttraining's auc: 0.850911\ttraining's binary_logloss: 0.214453\n",
      "[922]\ttraining's auc: 0.850955\ttraining's binary_logloss: 0.214437\n",
      "[923]\ttraining's auc: 0.851026\ttraining's binary_logloss: 0.214411\n",
      "[924]\ttraining's auc: 0.851091\ttraining's binary_logloss: 0.214386\n",
      "[925]\ttraining's auc: 0.851154\ttraining's binary_logloss: 0.214359\n",
      "[926]\ttraining's auc: 0.85121\ttraining's binary_logloss: 0.214335\n",
      "[927]\ttraining's auc: 0.851268\ttraining's binary_logloss: 0.21431\n",
      "[928]\ttraining's auc: 0.851325\ttraining's binary_logloss: 0.214288\n",
      "[929]\ttraining's auc: 0.851377\ttraining's binary_logloss: 0.214268\n",
      "[930]\ttraining's auc: 0.851432\ttraining's binary_logloss: 0.214244\n",
      "[931]\ttraining's auc: 0.851502\ttraining's binary_logloss: 0.214218\n",
      "[932]\ttraining's auc: 0.851574\ttraining's binary_logloss: 0.214195\n",
      "[933]\ttraining's auc: 0.851629\ttraining's binary_logloss: 0.214172\n",
      "[934]\ttraining's auc: 0.851692\ttraining's binary_logloss: 0.214148\n",
      "[935]\ttraining's auc: 0.851755\ttraining's binary_logloss: 0.214123\n",
      "[936]\ttraining's auc: 0.851811\ttraining's binary_logloss: 0.2141\n",
      "[937]\ttraining's auc: 0.85185\ttraining's binary_logloss: 0.214084\n",
      "[938]\ttraining's auc: 0.851895\ttraining's binary_logloss: 0.214061\n",
      "[939]\ttraining's auc: 0.851988\ttraining's binary_logloss: 0.214033\n",
      "[940]\ttraining's auc: 0.852049\ttraining's binary_logloss: 0.214008\n",
      "[941]\ttraining's auc: 0.852106\ttraining's binary_logloss: 0.213983\n",
      "[942]\ttraining's auc: 0.852127\ttraining's binary_logloss: 0.213974\n",
      "[943]\ttraining's auc: 0.85218\ttraining's binary_logloss: 0.213953\n",
      "[944]\ttraining's auc: 0.852237\ttraining's binary_logloss: 0.213929\n",
      "[945]\ttraining's auc: 0.8523\ttraining's binary_logloss: 0.213903\n",
      "[946]\ttraining's auc: 0.852366\ttraining's binary_logloss: 0.213879\n",
      "[947]\ttraining's auc: 0.852459\ttraining's binary_logloss: 0.213851\n",
      "[948]\ttraining's auc: 0.852515\ttraining's binary_logloss: 0.213829\n",
      "[949]\ttraining's auc: 0.852556\ttraining's binary_logloss: 0.213804\n",
      "[950]\ttraining's auc: 0.852623\ttraining's binary_logloss: 0.213775\n",
      "[951]\ttraining's auc: 0.852675\ttraining's binary_logloss: 0.213753\n",
      "[952]\ttraining's auc: 0.852744\ttraining's binary_logloss: 0.213724\n",
      "[953]\ttraining's auc: 0.852826\ttraining's binary_logloss: 0.213697\n",
      "[954]\ttraining's auc: 0.852848\ttraining's binary_logloss: 0.213688\n",
      "[955]\ttraining's auc: 0.852907\ttraining's binary_logloss: 0.213665\n",
      "[956]\ttraining's auc: 0.852936\ttraining's binary_logloss: 0.21365\n",
      "[957]\ttraining's auc: 0.852991\ttraining's binary_logloss: 0.213628\n",
      "[958]\ttraining's auc: 0.853054\ttraining's binary_logloss: 0.213604\n",
      "[959]\ttraining's auc: 0.853147\ttraining's binary_logloss: 0.213576\n",
      "[960]\ttraining's auc: 0.853173\ttraining's binary_logloss: 0.213566\n",
      "[961]\ttraining's auc: 0.853243\ttraining's binary_logloss: 0.213542\n",
      "[962]\ttraining's auc: 0.85327\ttraining's binary_logloss: 0.21353\n",
      "[963]\ttraining's auc: 0.853349\ttraining's binary_logloss: 0.213503\n",
      "[964]\ttraining's auc: 0.853416\ttraining's binary_logloss: 0.213477\n",
      "[965]\ttraining's auc: 0.853475\ttraining's binary_logloss: 0.213449\n",
      "[966]\ttraining's auc: 0.853535\ttraining's binary_logloss: 0.213427\n",
      "[967]\ttraining's auc: 0.853568\ttraining's binary_logloss: 0.213414\n",
      "[968]\ttraining's auc: 0.853617\ttraining's binary_logloss: 0.213394\n",
      "[969]\ttraining's auc: 0.853671\ttraining's binary_logloss: 0.213372\n",
      "[970]\ttraining's auc: 0.853729\ttraining's binary_logloss: 0.213347\n",
      "[971]\ttraining's auc: 0.853745\ttraining's binary_logloss: 0.213335\n",
      "[972]\ttraining's auc: 0.853794\ttraining's binary_logloss: 0.213317\n",
      "[973]\ttraining's auc: 0.853862\ttraining's binary_logloss: 0.21329\n",
      "[974]\ttraining's auc: 0.853905\ttraining's binary_logloss: 0.213267\n",
      "[975]\ttraining's auc: 0.853964\ttraining's binary_logloss: 0.213242\n",
      "[976]\ttraining's auc: 0.854019\ttraining's binary_logloss: 0.213219\n",
      "[977]\ttraining's auc: 0.85408\ttraining's binary_logloss: 0.213195\n",
      "[978]\ttraining's auc: 0.854094\ttraining's binary_logloss: 0.213183\n",
      "[979]\ttraining's auc: 0.854176\ttraining's binary_logloss: 0.213157\n",
      "[980]\ttraining's auc: 0.854246\ttraining's binary_logloss: 0.213133\n",
      "[981]\ttraining's auc: 0.854303\ttraining's binary_logloss: 0.213109\n",
      "[982]\ttraining's auc: 0.85436\ttraining's binary_logloss: 0.213085\n",
      "[983]\ttraining's auc: 0.854411\ttraining's binary_logloss: 0.213065\n",
      "[984]\ttraining's auc: 0.85446\ttraining's binary_logloss: 0.213042\n",
      "[985]\ttraining's auc: 0.854528\ttraining's binary_logloss: 0.213015\n",
      "[986]\ttraining's auc: 0.854595\ttraining's binary_logloss: 0.212989\n",
      "[987]\ttraining's auc: 0.854643\ttraining's binary_logloss: 0.212971\n",
      "[988]\ttraining's auc: 0.85471\ttraining's binary_logloss: 0.212945\n",
      "[989]\ttraining's auc: 0.85478\ttraining's binary_logloss: 0.212917\n",
      "[990]\ttraining's auc: 0.854813\ttraining's binary_logloss: 0.212901\n",
      "[991]\ttraining's auc: 0.854878\ttraining's binary_logloss: 0.212876\n",
      "[992]\ttraining's auc: 0.854929\ttraining's binary_logloss: 0.212856\n",
      "[993]\ttraining's auc: 0.854985\ttraining's binary_logloss: 0.212834\n",
      "[994]\ttraining's auc: 0.855052\ttraining's binary_logloss: 0.212805\n",
      "[995]\ttraining's auc: 0.855109\ttraining's binary_logloss: 0.212781\n",
      "[996]\ttraining's auc: 0.855154\ttraining's binary_logloss: 0.212756\n",
      "[997]\ttraining's auc: 0.855209\ttraining's binary_logloss: 0.212732\n",
      "[998]\ttraining's auc: 0.85527\ttraining's binary_logloss: 0.212707\n",
      "[999]\ttraining's auc: 0.855326\ttraining's binary_logloss: 0.212684\n",
      "[1000]\ttraining's auc: 0.855394\ttraining's binary_logloss: 0.212659\n",
      "[1001]\ttraining's auc: 0.855448\ttraining's binary_logloss: 0.212636\n",
      "[1002]\ttraining's auc: 0.855507\ttraining's binary_logloss: 0.212614\n",
      "[1003]\ttraining's auc: 0.855566\ttraining's binary_logloss: 0.212589\n",
      "[1004]\ttraining's auc: 0.855628\ttraining's binary_logloss: 0.212562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005]\ttraining's auc: 0.855675\ttraining's binary_logloss: 0.212538\n",
      "[1006]\ttraining's auc: 0.855735\ttraining's binary_logloss: 0.212513\n",
      "[1007]\ttraining's auc: 0.855828\ttraining's binary_logloss: 0.212486\n",
      "[1008]\ttraining's auc: 0.855873\ttraining's binary_logloss: 0.212464\n",
      "[1009]\ttraining's auc: 0.855942\ttraining's binary_logloss: 0.212439\n",
      "[1010]\ttraining's auc: 0.855994\ttraining's binary_logloss: 0.212416\n",
      "[1011]\ttraining's auc: 0.856049\ttraining's binary_logloss: 0.212396\n",
      "[1012]\ttraining's auc: 0.85611\ttraining's binary_logloss: 0.212373\n",
      "[1013]\ttraining's auc: 0.856154\ttraining's binary_logloss: 0.212353\n",
      "[1014]\ttraining's auc: 0.856207\ttraining's binary_logloss: 0.21233\n",
      "[1015]\ttraining's auc: 0.85626\ttraining's binary_logloss: 0.212302\n",
      "[1016]\ttraining's auc: 0.856324\ttraining's binary_logloss: 0.212276\n",
      "[1017]\ttraining's auc: 0.856354\ttraining's binary_logloss: 0.212261\n",
      "[1018]\ttraining's auc: 0.856395\ttraining's binary_logloss: 0.212243\n",
      "[1019]\ttraining's auc: 0.856443\ttraining's binary_logloss: 0.212224\n",
      "[1020]\ttraining's auc: 0.856455\ttraining's binary_logloss: 0.212219\n",
      "[1021]\ttraining's auc: 0.856519\ttraining's binary_logloss: 0.212195\n",
      "[1022]\ttraining's auc: 0.856567\ttraining's binary_logloss: 0.212168\n",
      "[1023]\ttraining's auc: 0.85665\ttraining's binary_logloss: 0.212142\n",
      "[1024]\ttraining's auc: 0.856713\ttraining's binary_logloss: 0.212119\n",
      "[1025]\ttraining's auc: 0.856784\ttraining's binary_logloss: 0.212093\n",
      "[1026]\ttraining's auc: 0.856808\ttraining's binary_logloss: 0.212084\n",
      "[1027]\ttraining's auc: 0.856874\ttraining's binary_logloss: 0.212056\n",
      "[1028]\ttraining's auc: 0.856929\ttraining's binary_logloss: 0.212034\n",
      "[1029]\ttraining's auc: 0.856979\ttraining's binary_logloss: 0.212015\n",
      "[1030]\ttraining's auc: 0.857048\ttraining's binary_logloss: 0.211988\n",
      "[1031]\ttraining's auc: 0.857095\ttraining's binary_logloss: 0.211968\n",
      "[1032]\ttraining's auc: 0.857154\ttraining's binary_logloss: 0.211944\n",
      "[1033]\ttraining's auc: 0.857218\ttraining's binary_logloss: 0.211918\n",
      "[1034]\ttraining's auc: 0.857258\ttraining's binary_logloss: 0.211896\n",
      "[1035]\ttraining's auc: 0.857331\ttraining's binary_logloss: 0.211871\n",
      "[1036]\ttraining's auc: 0.85741\ttraining's binary_logloss: 0.211845\n",
      "[1037]\ttraining's auc: 0.857464\ttraining's binary_logloss: 0.211819\n",
      "[1038]\ttraining's auc: 0.857515\ttraining's binary_logloss: 0.211797\n",
      "[1039]\ttraining's auc: 0.857586\ttraining's binary_logloss: 0.211771\n",
      "[1040]\ttraining's auc: 0.857612\ttraining's binary_logloss: 0.211762\n",
      "[1041]\ttraining's auc: 0.85767\ttraining's binary_logloss: 0.211739\n",
      "[1042]\ttraining's auc: 0.85772\ttraining's binary_logloss: 0.211717\n",
      "[1043]\ttraining's auc: 0.857778\ttraining's binary_logloss: 0.211693\n",
      "[1044]\ttraining's auc: 0.857839\ttraining's binary_logloss: 0.211669\n",
      "[1045]\ttraining's auc: 0.857878\ttraining's binary_logloss: 0.211653\n",
      "[1046]\ttraining's auc: 0.85794\ttraining's binary_logloss: 0.211629\n",
      "[1047]\ttraining's auc: 0.858005\ttraining's binary_logloss: 0.211607\n",
      "[1048]\ttraining's auc: 0.85806\ttraining's binary_logloss: 0.211582\n",
      "[1049]\ttraining's auc: 0.858117\ttraining's binary_logloss: 0.211555\n",
      "[1050]\ttraining's auc: 0.858197\ttraining's binary_logloss: 0.211527\n",
      "[1051]\ttraining's auc: 0.858247\ttraining's binary_logloss: 0.211503\n",
      "[1052]\ttraining's auc: 0.858306\ttraining's binary_logloss: 0.211482\n",
      "[1053]\ttraining's auc: 0.858351\ttraining's binary_logloss: 0.211459\n",
      "[1054]\ttraining's auc: 0.858402\ttraining's binary_logloss: 0.211437\n",
      "[1055]\ttraining's auc: 0.858469\ttraining's binary_logloss: 0.211408\n",
      "[1056]\ttraining's auc: 0.858511\ttraining's binary_logloss: 0.211388\n",
      "[1057]\ttraining's auc: 0.85857\ttraining's binary_logloss: 0.211365\n",
      "[1058]\ttraining's auc: 0.858628\ttraining's binary_logloss: 0.211345\n",
      "[1059]\ttraining's auc: 0.858663\ttraining's binary_logloss: 0.211321\n",
      "[1060]\ttraining's auc: 0.858713\ttraining's binary_logloss: 0.211299\n",
      "[1061]\ttraining's auc: 0.858773\ttraining's binary_logloss: 0.211273\n",
      "[1062]\ttraining's auc: 0.858834\ttraining's binary_logloss: 0.211249\n",
      "[1063]\ttraining's auc: 0.858876\ttraining's binary_logloss: 0.211228\n",
      "[1064]\ttraining's auc: 0.858911\ttraining's binary_logloss: 0.211213\n",
      "[1065]\ttraining's auc: 0.858938\ttraining's binary_logloss: 0.211203\n",
      "[1066]\ttraining's auc: 0.858995\ttraining's binary_logloss: 0.211177\n",
      "[1067]\ttraining's auc: 0.859025\ttraining's binary_logloss: 0.211166\n",
      "[1068]\ttraining's auc: 0.859084\ttraining's binary_logloss: 0.21114\n",
      "[1069]\ttraining's auc: 0.859151\ttraining's binary_logloss: 0.211114\n",
      "[1070]\ttraining's auc: 0.859205\ttraining's binary_logloss: 0.211094\n",
      "[1071]\ttraining's auc: 0.859275\ttraining's binary_logloss: 0.211069\n",
      "[1072]\ttraining's auc: 0.859323\ttraining's binary_logloss: 0.211049\n",
      "[1073]\ttraining's auc: 0.859356\ttraining's binary_logloss: 0.211035\n",
      "[1074]\ttraining's auc: 0.859415\ttraining's binary_logloss: 0.211012\n",
      "[1075]\ttraining's auc: 0.859471\ttraining's binary_logloss: 0.210989\n",
      "[1076]\ttraining's auc: 0.859537\ttraining's binary_logloss: 0.210963\n",
      "[1077]\ttraining's auc: 0.859583\ttraining's binary_logloss: 0.210941\n",
      "[1078]\ttraining's auc: 0.859616\ttraining's binary_logloss: 0.210929\n",
      "[1079]\ttraining's auc: 0.859683\ttraining's binary_logloss: 0.210904\n",
      "[1080]\ttraining's auc: 0.859746\ttraining's binary_logloss: 0.21088\n",
      "[1081]\ttraining's auc: 0.859795\ttraining's binary_logloss: 0.210858\n",
      "[1082]\ttraining's auc: 0.859854\ttraining's binary_logloss: 0.210833\n",
      "[1083]\ttraining's auc: 0.859912\ttraining's binary_logloss: 0.210808\n",
      "[1084]\ttraining's auc: 0.859969\ttraining's binary_logloss: 0.210785\n",
      "[1085]\ttraining's auc: 0.860022\ttraining's binary_logloss: 0.210761\n",
      "[1086]\ttraining's auc: 0.860093\ttraining's binary_logloss: 0.210735\n",
      "[1087]\ttraining's auc: 0.860147\ttraining's binary_logloss: 0.210714\n",
      "[1088]\ttraining's auc: 0.860205\ttraining's binary_logloss: 0.210691\n",
      "[1089]\ttraining's auc: 0.860256\ttraining's binary_logloss: 0.210668\n",
      "[1090]\ttraining's auc: 0.860317\ttraining's binary_logloss: 0.210645\n",
      "[1091]\ttraining's auc: 0.860369\ttraining's binary_logloss: 0.210621\n",
      "[1092]\ttraining's auc: 0.860418\ttraining's binary_logloss: 0.210598\n",
      "[1093]\ttraining's auc: 0.860486\ttraining's binary_logloss: 0.210573\n",
      "[1094]\ttraining's auc: 0.860533\ttraining's binary_logloss: 0.210549\n",
      "[1095]\ttraining's auc: 0.860603\ttraining's binary_logloss: 0.210523\n",
      "[1096]\ttraining's auc: 0.860658\ttraining's binary_logloss: 0.210501\n",
      "[1097]\ttraining's auc: 0.860709\ttraining's binary_logloss: 0.210478\n",
      "[1098]\ttraining's auc: 0.860766\ttraining's binary_logloss: 0.210455\n",
      "[1099]\ttraining's auc: 0.860801\ttraining's binary_logloss: 0.21044\n",
      "[1100]\ttraining's auc: 0.860853\ttraining's binary_logloss: 0.210418\n",
      "[1101]\ttraining's auc: 0.860911\ttraining's binary_logloss: 0.210392\n",
      "[1102]\ttraining's auc: 0.860941\ttraining's binary_logloss: 0.210381\n",
      "[1103]\ttraining's auc: 0.860985\ttraining's binary_logloss: 0.210355\n",
      "[1104]\ttraining's auc: 0.861061\ttraining's binary_logloss: 0.210327\n",
      "[1105]\ttraining's auc: 0.861141\ttraining's binary_logloss: 0.210301\n",
      "[1106]\ttraining's auc: 0.861174\ttraining's binary_logloss: 0.210284\n",
      "[1107]\ttraining's auc: 0.86123\ttraining's binary_logloss: 0.210258\n",
      "[1108]\ttraining's auc: 0.861298\ttraining's binary_logloss: 0.210232\n",
      "[1109]\ttraining's auc: 0.861356\ttraining's binary_logloss: 0.21021\n",
      "[1110]\ttraining's auc: 0.861366\ttraining's binary_logloss: 0.210205\n",
      "[1111]\ttraining's auc: 0.861427\ttraining's binary_logloss: 0.210181\n",
      "[1112]\ttraining's auc: 0.861494\ttraining's binary_logloss: 0.210155\n",
      "[1113]\ttraining's auc: 0.861557\ttraining's binary_logloss: 0.210132\n",
      "[1114]\ttraining's auc: 0.86163\ttraining's binary_logloss: 0.210104\n",
      "[1115]\ttraining's auc: 0.861688\ttraining's binary_logloss: 0.210078\n",
      "[1116]\ttraining's auc: 0.861735\ttraining's binary_logloss: 0.210052\n",
      "[1117]\ttraining's auc: 0.861814\ttraining's binary_logloss: 0.210027\n",
      "[1118]\ttraining's auc: 0.861865\ttraining's binary_logloss: 0.210005\n",
      "[1119]\ttraining's auc: 0.861879\ttraining's binary_logloss: 0.209999\n",
      "[1120]\ttraining's auc: 0.861938\ttraining's binary_logloss: 0.209974\n",
      "[1121]\ttraining's auc: 0.861998\ttraining's binary_logloss: 0.20995\n",
      "[1122]\ttraining's auc: 0.862052\ttraining's binary_logloss: 0.209927\n",
      "[1123]\ttraining's auc: 0.862104\ttraining's binary_logloss: 0.209905\n",
      "[1124]\ttraining's auc: 0.862162\ttraining's binary_logloss: 0.209879\n",
      "[1125]\ttraining's auc: 0.862205\ttraining's binary_logloss: 0.209855\n",
      "[1126]\ttraining's auc: 0.862258\ttraining's binary_logloss: 0.209833\n",
      "[1127]\ttraining's auc: 0.862286\ttraining's binary_logloss: 0.209821\n",
      "[1128]\ttraining's auc: 0.862336\ttraining's binary_logloss: 0.209799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1129]\ttraining's auc: 0.862391\ttraining's binary_logloss: 0.209776\n",
      "[1130]\ttraining's auc: 0.862454\ttraining's binary_logloss: 0.20975\n",
      "[1131]\ttraining's auc: 0.862516\ttraining's binary_logloss: 0.209726\n",
      "[1132]\ttraining's auc: 0.862588\ttraining's binary_logloss: 0.209701\n",
      "[1133]\ttraining's auc: 0.862645\ttraining's binary_logloss: 0.209674\n",
      "[1134]\ttraining's auc: 0.8627\ttraining's binary_logloss: 0.209652\n",
      "[1135]\ttraining's auc: 0.862756\ttraining's binary_logloss: 0.209629\n",
      "[1136]\ttraining's auc: 0.86278\ttraining's binary_logloss: 0.20962\n",
      "[1137]\ttraining's auc: 0.862791\ttraining's binary_logloss: 0.209614\n",
      "[1138]\ttraining's auc: 0.862849\ttraining's binary_logloss: 0.209591\n",
      "[1139]\ttraining's auc: 0.862874\ttraining's binary_logloss: 0.209584\n",
      "[1140]\ttraining's auc: 0.862927\ttraining's binary_logloss: 0.209561\n",
      "[1141]\ttraining's auc: 0.86298\ttraining's binary_logloss: 0.209538\n",
      "[1142]\ttraining's auc: 0.863022\ttraining's binary_logloss: 0.20952\n",
      "[1143]\ttraining's auc: 0.863084\ttraining's binary_logloss: 0.209492\n",
      "[1144]\ttraining's auc: 0.863138\ttraining's binary_logloss: 0.20947\n",
      "[1145]\ttraining's auc: 0.863183\ttraining's binary_logloss: 0.20945\n",
      "[1146]\ttraining's auc: 0.863244\ttraining's binary_logloss: 0.209424\n",
      "[1147]\ttraining's auc: 0.863293\ttraining's binary_logloss: 0.209403\n",
      "[1148]\ttraining's auc: 0.863368\ttraining's binary_logloss: 0.209378\n",
      "[1149]\ttraining's auc: 0.86344\ttraining's binary_logloss: 0.209351\n",
      "[1150]\ttraining's auc: 0.863496\ttraining's binary_logloss: 0.209326\n",
      "[1151]\ttraining's auc: 0.863548\ttraining's binary_logloss: 0.209304\n",
      "[1152]\ttraining's auc: 0.86358\ttraining's binary_logloss: 0.209287\n",
      "[1153]\ttraining's auc: 0.863629\ttraining's binary_logloss: 0.209267\n",
      "[1154]\ttraining's auc: 0.86369\ttraining's binary_logloss: 0.209241\n",
      "[1155]\ttraining's auc: 0.863743\ttraining's binary_logloss: 0.20922\n",
      "[1156]\ttraining's auc: 0.863782\ttraining's binary_logloss: 0.2092\n",
      "[1157]\ttraining's auc: 0.863824\ttraining's binary_logloss: 0.209181\n",
      "[1158]\ttraining's auc: 0.86391\ttraining's binary_logloss: 0.209156\n",
      "[1159]\ttraining's auc: 0.863932\ttraining's binary_logloss: 0.209149\n",
      "[1160]\ttraining's auc: 0.863992\ttraining's binary_logloss: 0.209124\n",
      "[1161]\ttraining's auc: 0.864046\ttraining's binary_logloss: 0.209099\n",
      "[1162]\ttraining's auc: 0.864099\ttraining's binary_logloss: 0.209074\n",
      "[1163]\ttraining's auc: 0.864166\ttraining's binary_logloss: 0.209048\n",
      "[1164]\ttraining's auc: 0.86421\ttraining's binary_logloss: 0.209027\n",
      "[1165]\ttraining's auc: 0.864288\ttraining's binary_logloss: 0.209001\n",
      "[1166]\ttraining's auc: 0.864348\ttraining's binary_logloss: 0.208977\n",
      "[1167]\ttraining's auc: 0.864413\ttraining's binary_logloss: 0.208954\n",
      "[1168]\ttraining's auc: 0.864468\ttraining's binary_logloss: 0.208928\n",
      "[1169]\ttraining's auc: 0.864516\ttraining's binary_logloss: 0.208907\n",
      "[1170]\ttraining's auc: 0.86454\ttraining's binary_logloss: 0.208896\n",
      "[1171]\ttraining's auc: 0.864631\ttraining's binary_logloss: 0.20887\n",
      "[1172]\ttraining's auc: 0.864682\ttraining's binary_logloss: 0.208845\n",
      "[1173]\ttraining's auc: 0.864726\ttraining's binary_logloss: 0.208823\n",
      "[1174]\ttraining's auc: 0.864773\ttraining's binary_logloss: 0.208799\n",
      "[1175]\ttraining's auc: 0.86483\ttraining's binary_logloss: 0.208775\n",
      "[1176]\ttraining's auc: 0.864901\ttraining's binary_logloss: 0.20875\n",
      "[1177]\ttraining's auc: 0.864956\ttraining's binary_logloss: 0.208723\n",
      "[1178]\ttraining's auc: 0.86504\ttraining's binary_logloss: 0.208697\n",
      "[1179]\ttraining's auc: 0.865092\ttraining's binary_logloss: 0.208674\n",
      "[1180]\ttraining's auc: 0.865118\ttraining's binary_logloss: 0.208664\n",
      "[1181]\ttraining's auc: 0.865182\ttraining's binary_logloss: 0.208637\n",
      "[1182]\ttraining's auc: 0.865235\ttraining's binary_logloss: 0.208616\n",
      "[1183]\ttraining's auc: 0.8653\ttraining's binary_logloss: 0.208593\n",
      "[1184]\ttraining's auc: 0.865363\ttraining's binary_logloss: 0.208569\n",
      "[1185]\ttraining's auc: 0.865395\ttraining's binary_logloss: 0.208555\n",
      "[1186]\ttraining's auc: 0.865463\ttraining's binary_logloss: 0.208531\n",
      "[1187]\ttraining's auc: 0.865518\ttraining's binary_logloss: 0.208506\n",
      "[1188]\ttraining's auc: 0.865598\ttraining's binary_logloss: 0.208479\n",
      "[1189]\ttraining's auc: 0.865643\ttraining's binary_logloss: 0.208457\n",
      "[1190]\ttraining's auc: 0.86571\ttraining's binary_logloss: 0.208432\n",
      "[1191]\ttraining's auc: 0.865731\ttraining's binary_logloss: 0.208424\n",
      "[1192]\ttraining's auc: 0.86579\ttraining's binary_logloss: 0.208401\n",
      "[1193]\ttraining's auc: 0.86586\ttraining's binary_logloss: 0.208374\n",
      "[1194]\ttraining's auc: 0.865926\ttraining's binary_logloss: 0.208347\n",
      "[1195]\ttraining's auc: 0.865981\ttraining's binary_logloss: 0.208324\n",
      "[1196]\ttraining's auc: 0.866034\ttraining's binary_logloss: 0.208299\n",
      "[1197]\ttraining's auc: 0.866102\ttraining's binary_logloss: 0.20827\n",
      "[1198]\ttraining's auc: 0.866166\ttraining's binary_logloss: 0.208247\n",
      "[1199]\ttraining's auc: 0.866219\ttraining's binary_logloss: 0.208222\n",
      "[1200]\ttraining's auc: 0.866239\ttraining's binary_logloss: 0.208214\n",
      "[1201]\ttraining's auc: 0.866262\ttraining's binary_logloss: 0.208204\n",
      "[1202]\ttraining's auc: 0.866319\ttraining's binary_logloss: 0.208178\n",
      "[1203]\ttraining's auc: 0.866364\ttraining's binary_logloss: 0.20816\n",
      "[1204]\ttraining's auc: 0.86643\ttraining's binary_logloss: 0.208136\n",
      "[1205]\ttraining's auc: 0.866498\ttraining's binary_logloss: 0.208111\n",
      "[1206]\ttraining's auc: 0.866562\ttraining's binary_logloss: 0.208084\n",
      "[1207]\ttraining's auc: 0.866611\ttraining's binary_logloss: 0.208063\n",
      "[1208]\ttraining's auc: 0.866683\ttraining's binary_logloss: 0.208039\n",
      "[1209]\ttraining's auc: 0.866752\ttraining's binary_logloss: 0.208013\n",
      "[1210]\ttraining's auc: 0.866803\ttraining's binary_logloss: 0.207988\n",
      "[1211]\ttraining's auc: 0.866849\ttraining's binary_logloss: 0.207965\n",
      "[1212]\ttraining's auc: 0.866877\ttraining's binary_logloss: 0.207952\n",
      "[1213]\ttraining's auc: 0.866929\ttraining's binary_logloss: 0.207931\n",
      "[1214]\ttraining's auc: 0.866984\ttraining's binary_logloss: 0.207905\n",
      "[1215]\ttraining's auc: 0.867023\ttraining's binary_logloss: 0.207885\n",
      "[1216]\ttraining's auc: 0.867074\ttraining's binary_logloss: 0.207863\n",
      "[1217]\ttraining's auc: 0.867123\ttraining's binary_logloss: 0.207841\n",
      "[1218]\ttraining's auc: 0.867139\ttraining's binary_logloss: 0.207834\n",
      "[1219]\ttraining's auc: 0.867189\ttraining's binary_logloss: 0.207815\n",
      "[1220]\ttraining's auc: 0.867247\ttraining's binary_logloss: 0.20779\n",
      "[1221]\ttraining's auc: 0.867314\ttraining's binary_logloss: 0.207765\n",
      "[1222]\ttraining's auc: 0.867359\ttraining's binary_logloss: 0.207741\n",
      "[1223]\ttraining's auc: 0.867404\ttraining's binary_logloss: 0.207719\n",
      "[1224]\ttraining's auc: 0.867465\ttraining's binary_logloss: 0.207694\n",
      "[1225]\ttraining's auc: 0.867549\ttraining's binary_logloss: 0.207669\n",
      "[1226]\ttraining's auc: 0.867604\ttraining's binary_logloss: 0.207645\n",
      "[1227]\ttraining's auc: 0.867615\ttraining's binary_logloss: 0.207639\n",
      "[1228]\ttraining's auc: 0.867685\ttraining's binary_logloss: 0.207614\n",
      "[1229]\ttraining's auc: 0.867708\ttraining's binary_logloss: 0.207604\n",
      "[1230]\ttraining's auc: 0.867758\ttraining's binary_logloss: 0.207579\n",
      "[1231]\ttraining's auc: 0.867805\ttraining's binary_logloss: 0.207558\n",
      "[1232]\ttraining's auc: 0.867833\ttraining's binary_logloss: 0.207548\n",
      "[1233]\ttraining's auc: 0.867881\ttraining's binary_logloss: 0.207523\n",
      "[1234]\ttraining's auc: 0.867938\ttraining's binary_logloss: 0.207503\n",
      "[1235]\ttraining's auc: 0.867995\ttraining's binary_logloss: 0.207478\n",
      "[1236]\ttraining's auc: 0.868061\ttraining's binary_logloss: 0.207453\n",
      "[1237]\ttraining's auc: 0.868103\ttraining's binary_logloss: 0.207431\n",
      "[1238]\ttraining's auc: 0.868161\ttraining's binary_logloss: 0.207408\n",
      "[1239]\ttraining's auc: 0.868208\ttraining's binary_logloss: 0.207385\n",
      "[1240]\ttraining's auc: 0.868221\ttraining's binary_logloss: 0.207379\n",
      "[1241]\ttraining's auc: 0.868294\ttraining's binary_logloss: 0.207355\n",
      "[1242]\ttraining's auc: 0.868364\ttraining's binary_logloss: 0.207326\n",
      "[1243]\ttraining's auc: 0.868408\ttraining's binary_logloss: 0.207307\n",
      "[1244]\ttraining's auc: 0.868463\ttraining's binary_logloss: 0.207283\n",
      "[1245]\ttraining's auc: 0.868513\ttraining's binary_logloss: 0.207262\n",
      "[1246]\ttraining's auc: 0.868564\ttraining's binary_logloss: 0.207239\n",
      "[1247]\ttraining's auc: 0.86863\ttraining's binary_logloss: 0.207216\n",
      "[1248]\ttraining's auc: 0.868685\ttraining's binary_logloss: 0.207191\n",
      "[1249]\ttraining's auc: 0.868736\ttraining's binary_logloss: 0.207169\n",
      "[1250]\ttraining's auc: 0.868784\ttraining's binary_logloss: 0.207143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1251]\ttraining's auc: 0.86884\ttraining's binary_logloss: 0.207123\n",
      "[1252]\ttraining's auc: 0.868882\ttraining's binary_logloss: 0.207105\n",
      "[1253]\ttraining's auc: 0.868898\ttraining's binary_logloss: 0.207094\n",
      "[1254]\ttraining's auc: 0.868938\ttraining's binary_logloss: 0.207073\n",
      "[1255]\ttraining's auc: 0.868982\ttraining's binary_logloss: 0.207048\n",
      "[1256]\ttraining's auc: 0.869051\ttraining's binary_logloss: 0.207024\n",
      "[1257]\ttraining's auc: 0.869116\ttraining's binary_logloss: 0.207\n",
      "[1258]\ttraining's auc: 0.869153\ttraining's binary_logloss: 0.206979\n",
      "[1259]\ttraining's auc: 0.869193\ttraining's binary_logloss: 0.206957\n",
      "[1260]\ttraining's auc: 0.869212\ttraining's binary_logloss: 0.206948\n",
      "[1261]\ttraining's auc: 0.869271\ttraining's binary_logloss: 0.206923\n",
      "[1262]\ttraining's auc: 0.869335\ttraining's binary_logloss: 0.206899\n",
      "[1263]\ttraining's auc: 0.86939\ttraining's binary_logloss: 0.206876\n",
      "[1264]\ttraining's auc: 0.869437\ttraining's binary_logloss: 0.206854\n",
      "[1265]\ttraining's auc: 0.869484\ttraining's binary_logloss: 0.206833\n",
      "[1266]\ttraining's auc: 0.869534\ttraining's binary_logloss: 0.206808\n",
      "[1267]\ttraining's auc: 0.869573\ttraining's binary_logloss: 0.206786\n",
      "[1268]\ttraining's auc: 0.86964\ttraining's binary_logloss: 0.20676\n",
      "[1269]\ttraining's auc: 0.86968\ttraining's binary_logloss: 0.206735\n",
      "[1270]\ttraining's auc: 0.86973\ttraining's binary_logloss: 0.206709\n",
      "[1271]\ttraining's auc: 0.869777\ttraining's binary_logloss: 0.206688\n",
      "[1272]\ttraining's auc: 0.869831\ttraining's binary_logloss: 0.206665\n",
      "[1273]\ttraining's auc: 0.869885\ttraining's binary_logloss: 0.206641\n",
      "[1274]\ttraining's auc: 0.86994\ttraining's binary_logloss: 0.206617\n",
      "[1275]\ttraining's auc: 0.869982\ttraining's binary_logloss: 0.206599\n",
      "[1276]\ttraining's auc: 0.870033\ttraining's binary_logloss: 0.206576\n",
      "[1277]\ttraining's auc: 0.870104\ttraining's binary_logloss: 0.206553\n",
      "[1278]\ttraining's auc: 0.870158\ttraining's binary_logloss: 0.206529\n",
      "[1279]\ttraining's auc: 0.87021\ttraining's binary_logloss: 0.206504\n",
      "[1280]\ttraining's auc: 0.870255\ttraining's binary_logloss: 0.206484\n",
      "[1281]\ttraining's auc: 0.870307\ttraining's binary_logloss: 0.206462\n",
      "[1282]\ttraining's auc: 0.870347\ttraining's binary_logloss: 0.20644\n",
      "[1283]\ttraining's auc: 0.870411\ttraining's binary_logloss: 0.206417\n",
      "[1284]\ttraining's auc: 0.87045\ttraining's binary_logloss: 0.206399\n",
      "[1285]\ttraining's auc: 0.87051\ttraining's binary_logloss: 0.206374\n",
      "[1286]\ttraining's auc: 0.870584\ttraining's binary_logloss: 0.206349\n",
      "[1287]\ttraining's auc: 0.870621\ttraining's binary_logloss: 0.206327\n",
      "[1288]\ttraining's auc: 0.870685\ttraining's binary_logloss: 0.206304\n",
      "[1289]\ttraining's auc: 0.870735\ttraining's binary_logloss: 0.206282\n",
      "[1290]\ttraining's auc: 0.870785\ttraining's binary_logloss: 0.206258\n",
      "[1291]\ttraining's auc: 0.870852\ttraining's binary_logloss: 0.206233\n",
      "[1292]\ttraining's auc: 0.870897\ttraining's binary_logloss: 0.206214\n",
      "[1293]\ttraining's auc: 0.870946\ttraining's binary_logloss: 0.20619\n",
      "[1294]\ttraining's auc: 0.870966\ttraining's binary_logloss: 0.206182\n",
      "[1295]\ttraining's auc: 0.871017\ttraining's binary_logloss: 0.20616\n",
      "[1296]\ttraining's auc: 0.871076\ttraining's binary_logloss: 0.206136\n",
      "[1297]\ttraining's auc: 0.871132\ttraining's binary_logloss: 0.206113\n",
      "[1298]\ttraining's auc: 0.871189\ttraining's binary_logloss: 0.206087\n",
      "[1299]\ttraining's auc: 0.871263\ttraining's binary_logloss: 0.20606\n",
      "[1300]\ttraining's auc: 0.87131\ttraining's binary_logloss: 0.206039\n",
      "[1301]\ttraining's auc: 0.871361\ttraining's binary_logloss: 0.206014\n",
      "[1302]\ttraining's auc: 0.871405\ttraining's binary_logloss: 0.205994\n",
      "[1303]\ttraining's auc: 0.871451\ttraining's binary_logloss: 0.205972\n",
      "[1304]\ttraining's auc: 0.871497\ttraining's binary_logloss: 0.205953\n",
      "[1305]\ttraining's auc: 0.871562\ttraining's binary_logloss: 0.205927\n",
      "[1306]\ttraining's auc: 0.871597\ttraining's binary_logloss: 0.205909\n",
      "[1307]\ttraining's auc: 0.871643\ttraining's binary_logloss: 0.205889\n",
      "[1308]\ttraining's auc: 0.871697\ttraining's binary_logloss: 0.205866\n",
      "[1309]\ttraining's auc: 0.871737\ttraining's binary_logloss: 0.205845\n",
      "[1310]\ttraining's auc: 0.871759\ttraining's binary_logloss: 0.205836\n",
      "[1311]\ttraining's auc: 0.871821\ttraining's binary_logloss: 0.205811\n",
      "[1312]\ttraining's auc: 0.871862\ttraining's binary_logloss: 0.20579\n",
      "[1313]\ttraining's auc: 0.871914\ttraining's binary_logloss: 0.205765\n",
      "[1314]\ttraining's auc: 0.87197\ttraining's binary_logloss: 0.20574\n",
      "[1315]\ttraining's auc: 0.871994\ttraining's binary_logloss: 0.20573\n",
      "[1316]\ttraining's auc: 0.872042\ttraining's binary_logloss: 0.205706\n",
      "[1317]\ttraining's auc: 0.872092\ttraining's binary_logloss: 0.205684\n",
      "[1318]\ttraining's auc: 0.872144\ttraining's binary_logloss: 0.205661\n",
      "[1319]\ttraining's auc: 0.872202\ttraining's binary_logloss: 0.205638\n",
      "[1320]\ttraining's auc: 0.872243\ttraining's binary_logloss: 0.205616\n",
      "[1321]\ttraining's auc: 0.872282\ttraining's binary_logloss: 0.205595\n",
      "[1322]\ttraining's auc: 0.872326\ttraining's binary_logloss: 0.205575\n",
      "[1323]\ttraining's auc: 0.872382\ttraining's binary_logloss: 0.205552\n",
      "[1324]\ttraining's auc: 0.872448\ttraining's binary_logloss: 0.205524\n",
      "[1325]\ttraining's auc: 0.872498\ttraining's binary_logloss: 0.205503\n",
      "[1326]\ttraining's auc: 0.872564\ttraining's binary_logloss: 0.205474\n",
      "[1327]\ttraining's auc: 0.872583\ttraining's binary_logloss: 0.205468\n",
      "[1328]\ttraining's auc: 0.872621\ttraining's binary_logloss: 0.205448\n",
      "[1329]\ttraining's auc: 0.872684\ttraining's binary_logloss: 0.205424\n",
      "[1330]\ttraining's auc: 0.872732\ttraining's binary_logloss: 0.205402\n",
      "[1331]\ttraining's auc: 0.872785\ttraining's binary_logloss: 0.205381\n",
      "[1332]\ttraining's auc: 0.872835\ttraining's binary_logloss: 0.205359\n",
      "[1333]\ttraining's auc: 0.872886\ttraining's binary_logloss: 0.205336\n",
      "[1334]\ttraining's auc: 0.872943\ttraining's binary_logloss: 0.205314\n",
      "[1335]\ttraining's auc: 0.873003\ttraining's binary_logloss: 0.205289\n",
      "[1336]\ttraining's auc: 0.873083\ttraining's binary_logloss: 0.20526\n",
      "[1337]\ttraining's auc: 0.873127\ttraining's binary_logloss: 0.205239\n",
      "[1338]\ttraining's auc: 0.87319\ttraining's binary_logloss: 0.205215\n",
      "[1339]\ttraining's auc: 0.873247\ttraining's binary_logloss: 0.205191\n",
      "[1340]\ttraining's auc: 0.873289\ttraining's binary_logloss: 0.205169\n",
      "[1341]\ttraining's auc: 0.873349\ttraining's binary_logloss: 0.205145\n",
      "[1342]\ttraining's auc: 0.873404\ttraining's binary_logloss: 0.205122\n",
      "[1343]\ttraining's auc: 0.873452\ttraining's binary_logloss: 0.205106\n",
      "[1344]\ttraining's auc: 0.873526\ttraining's binary_logloss: 0.205078\n",
      "[1345]\ttraining's auc: 0.873575\ttraining's binary_logloss: 0.205052\n",
      "[1346]\ttraining's auc: 0.873642\ttraining's binary_logloss: 0.205027\n",
      "[1347]\ttraining's auc: 0.873653\ttraining's binary_logloss: 0.205022\n",
      "[1348]\ttraining's auc: 0.873696\ttraining's binary_logloss: 0.205004\n",
      "[1349]\ttraining's auc: 0.873751\ttraining's binary_logloss: 0.204982\n",
      "[1350]\ttraining's auc: 0.873809\ttraining's binary_logloss: 0.204953\n",
      "[1351]\ttraining's auc: 0.873858\ttraining's binary_logloss: 0.20493\n",
      "[1352]\ttraining's auc: 0.873908\ttraining's binary_logloss: 0.204909\n",
      "[1353]\ttraining's auc: 0.873935\ttraining's binary_logloss: 0.204898\n",
      "[1354]\ttraining's auc: 0.873979\ttraining's binary_logloss: 0.20488\n",
      "[1355]\ttraining's auc: 0.874034\ttraining's binary_logloss: 0.204857\n",
      "[1356]\ttraining's auc: 0.874099\ttraining's binary_logloss: 0.204831\n",
      "[1357]\ttraining's auc: 0.874157\ttraining's binary_logloss: 0.204809\n",
      "[1358]\ttraining's auc: 0.874189\ttraining's binary_logloss: 0.204795\n",
      "[1359]\ttraining's auc: 0.874196\ttraining's binary_logloss: 0.204791\n",
      "[1360]\ttraining's auc: 0.874242\ttraining's binary_logloss: 0.204771\n",
      "[1361]\ttraining's auc: 0.8743\ttraining's binary_logloss: 0.204745\n",
      "[1362]\ttraining's auc: 0.874336\ttraining's binary_logloss: 0.204729\n",
      "[1363]\ttraining's auc: 0.874355\ttraining's binary_logloss: 0.204721\n",
      "[1364]\ttraining's auc: 0.874421\ttraining's binary_logloss: 0.204695\n",
      "[1365]\ttraining's auc: 0.874473\ttraining's binary_logloss: 0.204672\n",
      "[1366]\ttraining's auc: 0.874538\ttraining's binary_logloss: 0.204647\n",
      "[1367]\ttraining's auc: 0.874599\ttraining's binary_logloss: 0.204624\n",
      "[1368]\ttraining's auc: 0.874663\ttraining's binary_logloss: 0.204601\n",
      "[1369]\ttraining's auc: 0.874687\ttraining's binary_logloss: 0.20459\n",
      "[1370]\ttraining's auc: 0.87471\ttraining's binary_logloss: 0.204581\n",
      "[1371]\ttraining's auc: 0.874768\ttraining's binary_logloss: 0.204554\n",
      "[1372]\ttraining's auc: 0.874832\ttraining's binary_logloss: 0.20453\n",
      "[1373]\ttraining's auc: 0.874879\ttraining's binary_logloss: 0.20451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1374]\ttraining's auc: 0.874941\ttraining's binary_logloss: 0.204488\n",
      "[1375]\ttraining's auc: 0.874974\ttraining's binary_logloss: 0.204471\n",
      "[1376]\ttraining's auc: 0.87503\ttraining's binary_logloss: 0.204448\n",
      "[1377]\ttraining's auc: 0.87508\ttraining's binary_logloss: 0.204427\n",
      "[1378]\ttraining's auc: 0.875125\ttraining's binary_logloss: 0.204404\n",
      "[1379]\ttraining's auc: 0.875204\ttraining's binary_logloss: 0.204374\n",
      "[1380]\ttraining's auc: 0.875245\ttraining's binary_logloss: 0.204353\n",
      "[1381]\ttraining's auc: 0.875293\ttraining's binary_logloss: 0.204333\n",
      "[1382]\ttraining's auc: 0.875341\ttraining's binary_logloss: 0.204311\n",
      "[1383]\ttraining's auc: 0.875406\ttraining's binary_logloss: 0.204289\n",
      "[1384]\ttraining's auc: 0.87547\ttraining's binary_logloss: 0.204261\n",
      "[1385]\ttraining's auc: 0.875524\ttraining's binary_logloss: 0.204235\n",
      "[1386]\ttraining's auc: 0.875575\ttraining's binary_logloss: 0.204214\n",
      "[1387]\ttraining's auc: 0.875638\ttraining's binary_logloss: 0.204187\n",
      "[1388]\ttraining's auc: 0.875676\ttraining's binary_logloss: 0.204174\n",
      "[1389]\ttraining's auc: 0.875727\ttraining's binary_logloss: 0.204149\n",
      "[1390]\ttraining's auc: 0.875787\ttraining's binary_logloss: 0.204127\n",
      "[1391]\ttraining's auc: 0.875834\ttraining's binary_logloss: 0.204105\n",
      "[1392]\ttraining's auc: 0.875882\ttraining's binary_logloss: 0.204084\n",
      "[1393]\ttraining's auc: 0.875949\ttraining's binary_logloss: 0.204058\n",
      "[1394]\ttraining's auc: 0.87602\ttraining's binary_logloss: 0.204032\n",
      "[1395]\ttraining's auc: 0.876064\ttraining's binary_logloss: 0.204011\n",
      "[1396]\ttraining's auc: 0.876124\ttraining's binary_logloss: 0.203987\n",
      "[1397]\ttraining's auc: 0.87618\ttraining's binary_logloss: 0.203962\n",
      "[1398]\ttraining's auc: 0.876227\ttraining's binary_logloss: 0.203941\n",
      "[1399]\ttraining's auc: 0.876271\ttraining's binary_logloss: 0.203919\n",
      "[1400]\ttraining's auc: 0.87633\ttraining's binary_logloss: 0.203896\n",
      "[1401]\ttraining's auc: 0.876381\ttraining's binary_logloss: 0.203876\n",
      "[1402]\ttraining's auc: 0.87641\ttraining's binary_logloss: 0.203855\n",
      "[1403]\ttraining's auc: 0.876465\ttraining's binary_logloss: 0.203831\n",
      "[1404]\ttraining's auc: 0.87651\ttraining's binary_logloss: 0.20381\n",
      "[1405]\ttraining's auc: 0.876576\ttraining's binary_logloss: 0.203782\n",
      "[1406]\ttraining's auc: 0.876619\ttraining's binary_logloss: 0.203765\n",
      "[1407]\ttraining's auc: 0.876687\ttraining's binary_logloss: 0.203743\n",
      "[1408]\ttraining's auc: 0.876748\ttraining's binary_logloss: 0.203717\n",
      "[1409]\ttraining's auc: 0.876785\ttraining's binary_logloss: 0.203699\n",
      "[1410]\ttraining's auc: 0.876829\ttraining's binary_logloss: 0.203678\n",
      "[1411]\ttraining's auc: 0.876876\ttraining's binary_logloss: 0.203655\n",
      "[1412]\ttraining's auc: 0.876921\ttraining's binary_logloss: 0.203632\n",
      "[1413]\ttraining's auc: 0.876966\ttraining's binary_logloss: 0.203609\n",
      "[1414]\ttraining's auc: 0.87703\ttraining's binary_logloss: 0.203584\n",
      "[1415]\ttraining's auc: 0.877065\ttraining's binary_logloss: 0.20357\n",
      "[1416]\ttraining's auc: 0.87711\ttraining's binary_logloss: 0.203552\n",
      "[1417]\ttraining's auc: 0.877173\ttraining's binary_logloss: 0.203526\n",
      "[1418]\ttraining's auc: 0.877226\ttraining's binary_logloss: 0.203503\n",
      "[1419]\ttraining's auc: 0.87727\ttraining's binary_logloss: 0.203481\n",
      "[1420]\ttraining's auc: 0.877293\ttraining's binary_logloss: 0.203473\n",
      "[1421]\ttraining's auc: 0.877351\ttraining's binary_logloss: 0.203446\n",
      "[1422]\ttraining's auc: 0.87739\ttraining's binary_logloss: 0.203424\n",
      "[1423]\ttraining's auc: 0.877443\ttraining's binary_logloss: 0.203401\n",
      "[1424]\ttraining's auc: 0.877489\ttraining's binary_logloss: 0.203377\n",
      "[1425]\ttraining's auc: 0.877508\ttraining's binary_logloss: 0.203372\n",
      "[1426]\ttraining's auc: 0.877537\ttraining's binary_logloss: 0.203353\n",
      "[1427]\ttraining's auc: 0.877581\ttraining's binary_logloss: 0.203334\n",
      "[1428]\ttraining's auc: 0.877636\ttraining's binary_logloss: 0.20331\n",
      "[1429]\ttraining's auc: 0.877669\ttraining's binary_logloss: 0.203296\n",
      "[1430]\ttraining's auc: 0.877709\ttraining's binary_logloss: 0.203275\n",
      "[1431]\ttraining's auc: 0.877772\ttraining's binary_logloss: 0.20325\n",
      "[1432]\ttraining's auc: 0.87781\ttraining's binary_logloss: 0.203229\n",
      "[1433]\ttraining's auc: 0.877867\ttraining's binary_logloss: 0.203203\n",
      "[1434]\ttraining's auc: 0.877898\ttraining's binary_logloss: 0.20319\n",
      "[1435]\ttraining's auc: 0.877914\ttraining's binary_logloss: 0.203184\n",
      "[1436]\ttraining's auc: 0.877957\ttraining's binary_logloss: 0.203159\n",
      "[1437]\ttraining's auc: 0.878\ttraining's binary_logloss: 0.20314\n",
      "[1438]\ttraining's auc: 0.878066\ttraining's binary_logloss: 0.203117\n",
      "[1439]\ttraining's auc: 0.878115\ttraining's binary_logloss: 0.203096\n",
      "[1440]\ttraining's auc: 0.878172\ttraining's binary_logloss: 0.20307\n",
      "[1441]\ttraining's auc: 0.878182\ttraining's binary_logloss: 0.203064\n",
      "[1442]\ttraining's auc: 0.878227\ttraining's binary_logloss: 0.203042\n",
      "[1443]\ttraining's auc: 0.878275\ttraining's binary_logloss: 0.20302\n",
      "[1444]\ttraining's auc: 0.87833\ttraining's binary_logloss: 0.202997\n",
      "[1445]\ttraining's auc: 0.87836\ttraining's binary_logloss: 0.202985\n",
      "[1446]\ttraining's auc: 0.878416\ttraining's binary_logloss: 0.202959\n",
      "[1447]\ttraining's auc: 0.878479\ttraining's binary_logloss: 0.202938\n",
      "[1448]\ttraining's auc: 0.878534\ttraining's binary_logloss: 0.202912\n",
      "[1449]\ttraining's auc: 0.878596\ttraining's binary_logloss: 0.20289\n",
      "[1450]\ttraining's auc: 0.878643\ttraining's binary_logloss: 0.202867\n",
      "[1451]\ttraining's auc: 0.878697\ttraining's binary_logloss: 0.202843\n",
      "[1452]\ttraining's auc: 0.878743\ttraining's binary_logloss: 0.202823\n",
      "[1453]\ttraining's auc: 0.878768\ttraining's binary_logloss: 0.202811\n",
      "[1454]\ttraining's auc: 0.878789\ttraining's binary_logloss: 0.202803\n",
      "[1455]\ttraining's auc: 0.878843\ttraining's binary_logloss: 0.202778\n",
      "[1456]\ttraining's auc: 0.878903\ttraining's binary_logloss: 0.202757\n",
      "[1457]\ttraining's auc: 0.878949\ttraining's binary_logloss: 0.202735\n",
      "[1458]\ttraining's auc: 0.879009\ttraining's binary_logloss: 0.202712\n",
      "[1459]\ttraining's auc: 0.879065\ttraining's binary_logloss: 0.202687\n",
      "[1460]\ttraining's auc: 0.879116\ttraining's binary_logloss: 0.202662\n",
      "[1461]\ttraining's auc: 0.879145\ttraining's binary_logloss: 0.202649\n",
      "[1462]\ttraining's auc: 0.879165\ttraining's binary_logloss: 0.202641\n",
      "[1463]\ttraining's auc: 0.879225\ttraining's binary_logloss: 0.202616\n",
      "[1464]\ttraining's auc: 0.879263\ttraining's binary_logloss: 0.202597\n",
      "[1465]\ttraining's auc: 0.879319\ttraining's binary_logloss: 0.202572\n",
      "[1466]\ttraining's auc: 0.879372\ttraining's binary_logloss: 0.202548\n",
      "[1467]\ttraining's auc: 0.87943\ttraining's binary_logloss: 0.202523\n",
      "[1468]\ttraining's auc: 0.879487\ttraining's binary_logloss: 0.202499\n",
      "[1469]\ttraining's auc: 0.879543\ttraining's binary_logloss: 0.202477\n",
      "[1470]\ttraining's auc: 0.87957\ttraining's binary_logloss: 0.202467\n",
      "[1471]\ttraining's auc: 0.879619\ttraining's binary_logloss: 0.202447\n",
      "[1472]\ttraining's auc: 0.879664\ttraining's binary_logloss: 0.202428\n",
      "[1473]\ttraining's auc: 0.879687\ttraining's binary_logloss: 0.202419\n",
      "[1474]\ttraining's auc: 0.87971\ttraining's binary_logloss: 0.202409\n",
      "[1475]\ttraining's auc: 0.879755\ttraining's binary_logloss: 0.202389\n",
      "[1476]\ttraining's auc: 0.879805\ttraining's binary_logloss: 0.202368\n",
      "[1477]\ttraining's auc: 0.879844\ttraining's binary_logloss: 0.202349\n",
      "[1478]\ttraining's auc: 0.879899\ttraining's binary_logloss: 0.202325\n",
      "[1479]\ttraining's auc: 0.879955\ttraining's binary_logloss: 0.202303\n",
      "[1480]\ttraining's auc: 0.880021\ttraining's binary_logloss: 0.20228\n",
      "[1481]\ttraining's auc: 0.880078\ttraining's binary_logloss: 0.202255\n",
      "[1482]\ttraining's auc: 0.880126\ttraining's binary_logloss: 0.202233\n",
      "[1483]\ttraining's auc: 0.880145\ttraining's binary_logloss: 0.202225\n",
      "[1484]\ttraining's auc: 0.880193\ttraining's binary_logloss: 0.202203\n",
      "[1485]\ttraining's auc: 0.880239\ttraining's binary_logloss: 0.202179\n",
      "[1486]\ttraining's auc: 0.880289\ttraining's binary_logloss: 0.202156\n",
      "[1487]\ttraining's auc: 0.880346\ttraining's binary_logloss: 0.202134\n",
      "[1488]\ttraining's auc: 0.880406\ttraining's binary_logloss: 0.202105\n",
      "[1489]\ttraining's auc: 0.880444\ttraining's binary_logloss: 0.202085\n",
      "[1490]\ttraining's auc: 0.880489\ttraining's binary_logloss: 0.202065\n",
      "[1491]\ttraining's auc: 0.880541\ttraining's binary_logloss: 0.202042\n",
      "[1492]\ttraining's auc: 0.880585\ttraining's binary_logloss: 0.202022\n",
      "[1493]\ttraining's auc: 0.880617\ttraining's binary_logloss: 0.202009\n",
      "[1494]\ttraining's auc: 0.88065\ttraining's binary_logloss: 0.201995\n",
      "[1495]\ttraining's auc: 0.880701\ttraining's binary_logloss: 0.201973\n",
      "[1496]\ttraining's auc: 0.880722\ttraining's binary_logloss: 0.201964\n",
      "[1497]\ttraining's auc: 0.880767\ttraining's binary_logloss: 0.201942\n",
      "[1498]\ttraining's auc: 0.880785\ttraining's binary_logloss: 0.201934\n",
      "[1499]\ttraining's auc: 0.880834\ttraining's binary_logloss: 0.201913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's auc: 0.880856\ttraining's binary_logloss: 0.201901\n",
      "[1501]\ttraining's auc: 0.8809\ttraining's binary_logloss: 0.201883\n",
      "[1502]\ttraining's auc: 0.880952\ttraining's binary_logloss: 0.201857\n",
      "[1503]\ttraining's auc: 0.881\ttraining's binary_logloss: 0.201834\n",
      "[1504]\ttraining's auc: 0.881041\ttraining's binary_logloss: 0.201811\n",
      "[1505]\ttraining's auc: 0.881068\ttraining's binary_logloss: 0.2018\n",
      "[1506]\ttraining's auc: 0.881112\ttraining's binary_logloss: 0.201781\n",
      "[1507]\ttraining's auc: 0.881164\ttraining's binary_logloss: 0.201758\n",
      "[1508]\ttraining's auc: 0.88122\ttraining's binary_logloss: 0.201735\n",
      "[1509]\ttraining's auc: 0.881267\ttraining's binary_logloss: 0.201711\n",
      "[1510]\ttraining's auc: 0.881316\ttraining's binary_logloss: 0.20169\n",
      "[1511]\ttraining's auc: 0.88136\ttraining's binary_logloss: 0.201668\n",
      "[1512]\ttraining's auc: 0.881414\ttraining's binary_logloss: 0.201648\n",
      "[1513]\ttraining's auc: 0.881474\ttraining's binary_logloss: 0.201621\n",
      "[1514]\ttraining's auc: 0.881528\ttraining's binary_logloss: 0.201597\n",
      "[1515]\ttraining's auc: 0.881577\ttraining's binary_logloss: 0.201575\n",
      "[1516]\ttraining's auc: 0.881628\ttraining's binary_logloss: 0.201554\n",
      "[1517]\ttraining's auc: 0.881689\ttraining's binary_logloss: 0.201533\n",
      "[1518]\ttraining's auc: 0.881701\ttraining's binary_logloss: 0.201528\n",
      "[1519]\ttraining's auc: 0.881716\ttraining's binary_logloss: 0.20152\n",
      "[1520]\ttraining's auc: 0.88177\ttraining's binary_logloss: 0.201495\n",
      "[1521]\ttraining's auc: 0.881835\ttraining's binary_logloss: 0.201466\n",
      "[1522]\ttraining's auc: 0.881873\ttraining's binary_logloss: 0.201443\n",
      "[1523]\ttraining's auc: 0.881883\ttraining's binary_logloss: 0.201438\n",
      "[1524]\ttraining's auc: 0.881926\ttraining's binary_logloss: 0.20142\n",
      "[1525]\ttraining's auc: 0.881969\ttraining's binary_logloss: 0.2014\n",
      "[1526]\ttraining's auc: 0.882019\ttraining's binary_logloss: 0.20138\n",
      "[1527]\ttraining's auc: 0.882053\ttraining's binary_logloss: 0.201364\n",
      "[1528]\ttraining's auc: 0.882109\ttraining's binary_logloss: 0.201339\n",
      "[1529]\ttraining's auc: 0.882163\ttraining's binary_logloss: 0.201315\n",
      "[1530]\ttraining's auc: 0.882188\ttraining's binary_logloss: 0.201302\n",
      "[1531]\ttraining's auc: 0.882225\ttraining's binary_logloss: 0.201283\n",
      "[1532]\ttraining's auc: 0.882245\ttraining's binary_logloss: 0.201277\n",
      "[1533]\ttraining's auc: 0.882291\ttraining's binary_logloss: 0.201255\n",
      "[1534]\ttraining's auc: 0.882348\ttraining's binary_logloss: 0.201228\n",
      "[1535]\ttraining's auc: 0.882387\ttraining's binary_logloss: 0.201206\n",
      "[1536]\ttraining's auc: 0.882442\ttraining's binary_logloss: 0.201184\n",
      "[1537]\ttraining's auc: 0.882491\ttraining's binary_logloss: 0.201162\n",
      "[1538]\ttraining's auc: 0.882536\ttraining's binary_logloss: 0.201141\n",
      "[1539]\ttraining's auc: 0.882564\ttraining's binary_logloss: 0.201128\n",
      "[1540]\ttraining's auc: 0.882602\ttraining's binary_logloss: 0.201108\n",
      "[1541]\ttraining's auc: 0.882668\ttraining's binary_logloss: 0.201085\n",
      "[1542]\ttraining's auc: 0.882725\ttraining's binary_logloss: 0.20106\n",
      "[1543]\ttraining's auc: 0.882774\ttraining's binary_logloss: 0.20104\n",
      "[1544]\ttraining's auc: 0.8828\ttraining's binary_logloss: 0.201026\n",
      "[1545]\ttraining's auc: 0.882842\ttraining's binary_logloss: 0.201009\n",
      "[1546]\ttraining's auc: 0.882881\ttraining's binary_logloss: 0.200988\n",
      "[1547]\ttraining's auc: 0.882892\ttraining's binary_logloss: 0.200981\n",
      "[1548]\ttraining's auc: 0.882942\ttraining's binary_logloss: 0.200958\n",
      "[1549]\ttraining's auc: 0.882977\ttraining's binary_logloss: 0.200942\n",
      "[1550]\ttraining's auc: 0.883026\ttraining's binary_logloss: 0.200919\n",
      "[1551]\ttraining's auc: 0.883085\ttraining's binary_logloss: 0.200894\n",
      "[1552]\ttraining's auc: 0.883128\ttraining's binary_logloss: 0.200872\n",
      "[1553]\ttraining's auc: 0.883172\ttraining's binary_logloss: 0.200852\n",
      "[1554]\ttraining's auc: 0.883232\ttraining's binary_logloss: 0.200828\n",
      "[1555]\ttraining's auc: 0.883279\ttraining's binary_logloss: 0.200807\n",
      "[1556]\ttraining's auc: 0.883345\ttraining's binary_logloss: 0.200784\n",
      "[1557]\ttraining's auc: 0.883397\ttraining's binary_logloss: 0.20076\n",
      "[1558]\ttraining's auc: 0.883436\ttraining's binary_logloss: 0.200738\n",
      "[1559]\ttraining's auc: 0.883485\ttraining's binary_logloss: 0.200712\n",
      "[1560]\ttraining's auc: 0.883534\ttraining's binary_logloss: 0.200689\n",
      "[1561]\ttraining's auc: 0.883583\ttraining's binary_logloss: 0.200669\n",
      "[1562]\ttraining's auc: 0.883623\ttraining's binary_logloss: 0.200647\n",
      "[1563]\ttraining's auc: 0.883674\ttraining's binary_logloss: 0.200625\n",
      "[1564]\ttraining's auc: 0.883724\ttraining's binary_logloss: 0.200602\n",
      "[1565]\ttraining's auc: 0.883773\ttraining's binary_logloss: 0.20058\n",
      "[1566]\ttraining's auc: 0.883795\ttraining's binary_logloss: 0.20057\n",
      "[1567]\ttraining's auc: 0.883846\ttraining's binary_logloss: 0.200549\n",
      "[1568]\ttraining's auc: 0.883919\ttraining's binary_logloss: 0.20052\n",
      "[1569]\ttraining's auc: 0.883977\ttraining's binary_logloss: 0.200495\n",
      "[1570]\ttraining's auc: 0.884031\ttraining's binary_logloss: 0.200473\n",
      "[1571]\ttraining's auc: 0.884056\ttraining's binary_logloss: 0.200457\n",
      "[1572]\ttraining's auc: 0.884101\ttraining's binary_logloss: 0.200435\n",
      "[1573]\ttraining's auc: 0.884126\ttraining's binary_logloss: 0.200424\n",
      "[1574]\ttraining's auc: 0.884173\ttraining's binary_logloss: 0.200401\n",
      "[1575]\ttraining's auc: 0.884232\ttraining's binary_logloss: 0.200374\n",
      "[1576]\ttraining's auc: 0.884295\ttraining's binary_logloss: 0.200349\n",
      "[1577]\ttraining's auc: 0.88433\ttraining's binary_logloss: 0.200328\n",
      "[1578]\ttraining's auc: 0.884386\ttraining's binary_logloss: 0.200308\n",
      "[1579]\ttraining's auc: 0.884396\ttraining's binary_logloss: 0.200302\n",
      "[1580]\ttraining's auc: 0.884443\ttraining's binary_logloss: 0.20028\n",
      "[1581]\ttraining's auc: 0.884495\ttraining's binary_logloss: 0.200256\n",
      "[1582]\ttraining's auc: 0.884557\ttraining's binary_logloss: 0.200231\n",
      "[1583]\ttraining's auc: 0.884612\ttraining's binary_logloss: 0.200206\n",
      "[1584]\ttraining's auc: 0.88465\ttraining's binary_logloss: 0.200187\n",
      "[1585]\ttraining's auc: 0.884668\ttraining's binary_logloss: 0.20018\n",
      "[1586]\ttraining's auc: 0.884682\ttraining's binary_logloss: 0.200172\n",
      "[1587]\ttraining's auc: 0.884693\ttraining's binary_logloss: 0.200166\n",
      "[1588]\ttraining's auc: 0.884749\ttraining's binary_logloss: 0.200139\n",
      "[1589]\ttraining's auc: 0.884805\ttraining's binary_logloss: 0.200115\n",
      "[1590]\ttraining's auc: 0.884842\ttraining's binary_logloss: 0.200094\n",
      "[1591]\ttraining's auc: 0.88489\ttraining's binary_logloss: 0.200071\n",
      "[1592]\ttraining's auc: 0.884908\ttraining's binary_logloss: 0.200063\n",
      "[1593]\ttraining's auc: 0.884963\ttraining's binary_logloss: 0.200039\n",
      "[1594]\ttraining's auc: 0.885004\ttraining's binary_logloss: 0.200017\n",
      "[1595]\ttraining's auc: 0.88505\ttraining's binary_logloss: 0.199997\n",
      "[1596]\ttraining's auc: 0.8851\ttraining's binary_logloss: 0.199973\n",
      "[1597]\ttraining's auc: 0.885151\ttraining's binary_logloss: 0.199948\n",
      "[1598]\ttraining's auc: 0.885171\ttraining's binary_logloss: 0.199937\n",
      "[1599]\ttraining's auc: 0.885198\ttraining's binary_logloss: 0.199924\n",
      "[1600]\ttraining's auc: 0.885248\ttraining's binary_logloss: 0.199901\n",
      "[1601]\ttraining's auc: 0.885286\ttraining's binary_logloss: 0.19988\n",
      "[1602]\ttraining's auc: 0.885335\ttraining's binary_logloss: 0.199857\n",
      "[1603]\ttraining's auc: 0.885383\ttraining's binary_logloss: 0.199834\n",
      "[1604]\ttraining's auc: 0.88542\ttraining's binary_logloss: 0.19981\n",
      "[1605]\ttraining's auc: 0.885453\ttraining's binary_logloss: 0.199794\n",
      "[1606]\ttraining's auc: 0.885501\ttraining's binary_logloss: 0.199773\n",
      "[1607]\ttraining's auc: 0.885535\ttraining's binary_logloss: 0.199757\n",
      "[1608]\ttraining's auc: 0.885586\ttraining's binary_logloss: 0.199734\n",
      "[1609]\ttraining's auc: 0.885634\ttraining's binary_logloss: 0.199712\n",
      "[1610]\ttraining's auc: 0.885688\ttraining's binary_logloss: 0.199688\n",
      "[1611]\ttraining's auc: 0.885723\ttraining's binary_logloss: 0.199668\n",
      "[1612]\ttraining's auc: 0.885764\ttraining's binary_logloss: 0.199647\n",
      "[1613]\ttraining's auc: 0.885795\ttraining's binary_logloss: 0.199631\n",
      "[1614]\ttraining's auc: 0.885846\ttraining's binary_logloss: 0.199607\n",
      "[1615]\ttraining's auc: 0.885896\ttraining's binary_logloss: 0.199586\n",
      "[1616]\ttraining's auc: 0.885936\ttraining's binary_logloss: 0.199566\n",
      "[1617]\ttraining's auc: 0.885983\ttraining's binary_logloss: 0.199544\n",
      "[1618]\ttraining's auc: 0.886028\ttraining's binary_logloss: 0.199521\n",
      "[1619]\ttraining's auc: 0.886084\ttraining's binary_logloss: 0.199502\n",
      "[1620]\ttraining's auc: 0.886134\ttraining's binary_logloss: 0.199477\n",
      "[1621]\ttraining's auc: 0.886187\ttraining's binary_logloss: 0.199456\n",
      "[1622]\ttraining's auc: 0.88623\ttraining's binary_logloss: 0.199437\n",
      "[1623]\ttraining's auc: 0.886262\ttraining's binary_logloss: 0.199421\n",
      "[1624]\ttraining's auc: 0.886307\ttraining's binary_logloss: 0.1994\n",
      "[1625]\ttraining's auc: 0.886344\ttraining's binary_logloss: 0.199378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1626]\ttraining's auc: 0.886362\ttraining's binary_logloss: 0.199368\n",
      "[1627]\ttraining's auc: 0.886413\ttraining's binary_logloss: 0.199348\n",
      "[1628]\ttraining's auc: 0.886449\ttraining's binary_logloss: 0.199327\n",
      "[1629]\ttraining's auc: 0.886489\ttraining's binary_logloss: 0.199303\n",
      "[1630]\ttraining's auc: 0.886542\ttraining's binary_logloss: 0.199278\n",
      "[1631]\ttraining's auc: 0.886585\ttraining's binary_logloss: 0.19926\n",
      "[1632]\ttraining's auc: 0.886638\ttraining's binary_logloss: 0.199236\n",
      "[1633]\ttraining's auc: 0.886686\ttraining's binary_logloss: 0.199213\n",
      "[1634]\ttraining's auc: 0.886749\ttraining's binary_logloss: 0.199188\n",
      "[1635]\ttraining's auc: 0.886788\ttraining's binary_logloss: 0.199168\n",
      "[1636]\ttraining's auc: 0.886833\ttraining's binary_logloss: 0.199146\n",
      "[1637]\ttraining's auc: 0.886881\ttraining's binary_logloss: 0.199125\n",
      "[1638]\ttraining's auc: 0.886914\ttraining's binary_logloss: 0.199109\n",
      "[1639]\ttraining's auc: 0.886959\ttraining's binary_logloss: 0.199087\n",
      "[1640]\ttraining's auc: 0.887021\ttraining's binary_logloss: 0.199061\n",
      "[1641]\ttraining's auc: 0.887061\ttraining's binary_logloss: 0.199039\n",
      "[1642]\ttraining's auc: 0.887089\ttraining's binary_logloss: 0.199024\n",
      "[1643]\ttraining's auc: 0.887135\ttraining's binary_logloss: 0.199003\n",
      "[1644]\ttraining's auc: 0.887178\ttraining's binary_logloss: 0.198986\n",
      "[1645]\ttraining's auc: 0.887232\ttraining's binary_logloss: 0.198962\n",
      "[1646]\ttraining's auc: 0.887289\ttraining's binary_logloss: 0.19894\n",
      "[1647]\ttraining's auc: 0.887328\ttraining's binary_logloss: 0.198918\n",
      "[1648]\ttraining's auc: 0.887378\ttraining's binary_logloss: 0.198894\n",
      "[1649]\ttraining's auc: 0.887421\ttraining's binary_logloss: 0.198871\n",
      "[1650]\ttraining's auc: 0.887466\ttraining's binary_logloss: 0.19885\n",
      "[1651]\ttraining's auc: 0.887509\ttraining's binary_logloss: 0.198829\n",
      "[1652]\ttraining's auc: 0.887559\ttraining's binary_logloss: 0.198807\n",
      "[1653]\ttraining's auc: 0.887581\ttraining's binary_logloss: 0.198795\n",
      "[1654]\ttraining's auc: 0.887638\ttraining's binary_logloss: 0.198773\n",
      "[1655]\ttraining's auc: 0.887694\ttraining's binary_logloss: 0.198754\n",
      "[1656]\ttraining's auc: 0.887729\ttraining's binary_logloss: 0.198732\n",
      "[1657]\ttraining's auc: 0.887775\ttraining's binary_logloss: 0.19871\n",
      "[1658]\ttraining's auc: 0.887824\ttraining's binary_logloss: 0.198687\n",
      "[1659]\ttraining's auc: 0.887873\ttraining's binary_logloss: 0.198665\n",
      "[1660]\ttraining's auc: 0.887918\ttraining's binary_logloss: 0.198644\n",
      "[1661]\ttraining's auc: 0.887962\ttraining's binary_logloss: 0.198622\n",
      "[1662]\ttraining's auc: 0.888007\ttraining's binary_logloss: 0.198601\n",
      "[1663]\ttraining's auc: 0.888045\ttraining's binary_logloss: 0.19858\n",
      "[1664]\ttraining's auc: 0.888111\ttraining's binary_logloss: 0.198557\n",
      "[1665]\ttraining's auc: 0.888144\ttraining's binary_logloss: 0.198539\n",
      "[1666]\ttraining's auc: 0.888199\ttraining's binary_logloss: 0.198515\n",
      "[1667]\ttraining's auc: 0.888219\ttraining's binary_logloss: 0.198505\n",
      "[1668]\ttraining's auc: 0.888238\ttraining's binary_logloss: 0.198497\n",
      "[1669]\ttraining's auc: 0.888282\ttraining's binary_logloss: 0.198475\n",
      "[1670]\ttraining's auc: 0.888329\ttraining's binary_logloss: 0.198454\n",
      "[1671]\ttraining's auc: 0.888374\ttraining's binary_logloss: 0.198433\n",
      "[1672]\ttraining's auc: 0.888422\ttraining's binary_logloss: 0.198412\n",
      "[1673]\ttraining's auc: 0.888441\ttraining's binary_logloss: 0.198403\n",
      "[1674]\ttraining's auc: 0.888492\ttraining's binary_logloss: 0.198379\n",
      "[1675]\ttraining's auc: 0.888537\ttraining's binary_logloss: 0.198356\n",
      "[1676]\ttraining's auc: 0.888573\ttraining's binary_logloss: 0.198337\n",
      "[1677]\ttraining's auc: 0.888622\ttraining's binary_logloss: 0.198315\n",
      "[1678]\ttraining's auc: 0.888656\ttraining's binary_logloss: 0.198297\n",
      "[1679]\ttraining's auc: 0.888693\ttraining's binary_logloss: 0.198276\n",
      "[1680]\ttraining's auc: 0.888705\ttraining's binary_logloss: 0.198269\n",
      "[1681]\ttraining's auc: 0.888741\ttraining's binary_logloss: 0.198249\n",
      "[1682]\ttraining's auc: 0.888784\ttraining's binary_logloss: 0.198228\n",
      "[1683]\ttraining's auc: 0.888827\ttraining's binary_logloss: 0.198205\n",
      "[1684]\ttraining's auc: 0.888886\ttraining's binary_logloss: 0.19818\n",
      "[1685]\ttraining's auc: 0.888943\ttraining's binary_logloss: 0.198158\n",
      "[1686]\ttraining's auc: 0.888979\ttraining's binary_logloss: 0.198139\n",
      "[1687]\ttraining's auc: 0.889001\ttraining's binary_logloss: 0.198125\n",
      "[1688]\ttraining's auc: 0.889043\ttraining's binary_logloss: 0.198105\n",
      "[1689]\ttraining's auc: 0.889095\ttraining's binary_logloss: 0.198084\n",
      "[1690]\ttraining's auc: 0.889146\ttraining's binary_logloss: 0.19806\n",
      "[1691]\ttraining's auc: 0.889175\ttraining's binary_logloss: 0.198047\n",
      "[1692]\ttraining's auc: 0.889214\ttraining's binary_logloss: 0.198025\n",
      "[1693]\ttraining's auc: 0.889271\ttraining's binary_logloss: 0.198001\n",
      "[1694]\ttraining's auc: 0.889302\ttraining's binary_logloss: 0.197981\n",
      "[1695]\ttraining's auc: 0.889344\ttraining's binary_logloss: 0.197959\n",
      "[1696]\ttraining's auc: 0.889359\ttraining's binary_logloss: 0.197951\n",
      "[1697]\ttraining's auc: 0.889414\ttraining's binary_logloss: 0.19793\n",
      "[1698]\ttraining's auc: 0.889424\ttraining's binary_logloss: 0.197923\n",
      "[1699]\ttraining's auc: 0.889467\ttraining's binary_logloss: 0.197903\n",
      "[1700]\ttraining's auc: 0.889497\ttraining's binary_logloss: 0.197889\n",
      "[1701]\ttraining's auc: 0.889552\ttraining's binary_logloss: 0.197866\n",
      "[1702]\ttraining's auc: 0.889569\ttraining's binary_logloss: 0.197855\n",
      "[1703]\ttraining's auc: 0.889623\ttraining's binary_logloss: 0.197831\n",
      "[1704]\ttraining's auc: 0.889674\ttraining's binary_logloss: 0.197808\n",
      "[1705]\ttraining's auc: 0.889722\ttraining's binary_logloss: 0.197789\n",
      "[1706]\ttraining's auc: 0.889758\ttraining's binary_logloss: 0.197773\n",
      "[1707]\ttraining's auc: 0.889798\ttraining's binary_logloss: 0.19775\n",
      "[1708]\ttraining's auc: 0.889845\ttraining's binary_logloss: 0.197729\n",
      "[1709]\ttraining's auc: 0.889901\ttraining's binary_logloss: 0.197704\n",
      "[1710]\ttraining's auc: 0.889947\ttraining's binary_logloss: 0.19768\n",
      "[1711]\ttraining's auc: 0.88998\ttraining's binary_logloss: 0.197662\n",
      "[1712]\ttraining's auc: 0.890023\ttraining's binary_logloss: 0.197641\n",
      "[1713]\ttraining's auc: 0.89006\ttraining's binary_logloss: 0.19762\n",
      "[1714]\ttraining's auc: 0.890099\ttraining's binary_logloss: 0.1976\n",
      "[1715]\ttraining's auc: 0.890143\ttraining's binary_logloss: 0.197578\n",
      "[1716]\ttraining's auc: 0.890178\ttraining's binary_logloss: 0.197563\n",
      "[1717]\ttraining's auc: 0.890233\ttraining's binary_logloss: 0.19754\n",
      "[1718]\ttraining's auc: 0.890285\ttraining's binary_logloss: 0.197517\n",
      "[1719]\ttraining's auc: 0.890315\ttraining's binary_logloss: 0.197503\n",
      "[1720]\ttraining's auc: 0.890363\ttraining's binary_logloss: 0.19748\n",
      "[1721]\ttraining's auc: 0.890403\ttraining's binary_logloss: 0.19746\n",
      "[1722]\ttraining's auc: 0.890452\ttraining's binary_logloss: 0.197436\n",
      "[1723]\ttraining's auc: 0.890478\ttraining's binary_logloss: 0.19742\n",
      "[1724]\ttraining's auc: 0.890531\ttraining's binary_logloss: 0.197396\n",
      "[1725]\ttraining's auc: 0.89059\ttraining's binary_logloss: 0.197375\n",
      "[1726]\ttraining's auc: 0.890645\ttraining's binary_logloss: 0.197351\n",
      "[1727]\ttraining's auc: 0.890705\ttraining's binary_logloss: 0.197329\n",
      "[1728]\ttraining's auc: 0.890761\ttraining's binary_logloss: 0.197308\n",
      "[1729]\ttraining's auc: 0.890773\ttraining's binary_logloss: 0.197302\n",
      "[1730]\ttraining's auc: 0.890808\ttraining's binary_logloss: 0.197282\n",
      "[1731]\ttraining's auc: 0.890858\ttraining's binary_logloss: 0.19726\n",
      "[1732]\ttraining's auc: 0.8909\ttraining's binary_logloss: 0.197239\n",
      "[1733]\ttraining's auc: 0.890949\ttraining's binary_logloss: 0.197217\n",
      "[1734]\ttraining's auc: 0.890988\ttraining's binary_logloss: 0.197198\n",
      "[1735]\ttraining's auc: 0.89103\ttraining's binary_logloss: 0.197175\n",
      "[1736]\ttraining's auc: 0.891092\ttraining's binary_logloss: 0.197155\n",
      "[1737]\ttraining's auc: 0.891125\ttraining's binary_logloss: 0.197132\n",
      "[1738]\ttraining's auc: 0.89118\ttraining's binary_logloss: 0.19711\n",
      "[1739]\ttraining's auc: 0.891214\ttraining's binary_logloss: 0.197096\n",
      "[1740]\ttraining's auc: 0.891261\ttraining's binary_logloss: 0.197074\n",
      "[1741]\ttraining's auc: 0.8913\ttraining's binary_logloss: 0.197054\n",
      "[1742]\ttraining's auc: 0.891354\ttraining's binary_logloss: 0.19703\n",
      "[1743]\ttraining's auc: 0.8914\ttraining's binary_logloss: 0.197009\n",
      "[1744]\ttraining's auc: 0.891437\ttraining's binary_logloss: 0.196989\n",
      "[1745]\ttraining's auc: 0.891485\ttraining's binary_logloss: 0.196969\n",
      "[1746]\ttraining's auc: 0.891553\ttraining's binary_logloss: 0.196948\n",
      "[1747]\ttraining's auc: 0.891599\ttraining's binary_logloss: 0.196926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1748]\ttraining's auc: 0.891644\ttraining's binary_logloss: 0.196901\n",
      "[1749]\ttraining's auc: 0.891695\ttraining's binary_logloss: 0.19688\n",
      "[1750]\ttraining's auc: 0.891739\ttraining's binary_logloss: 0.196861\n",
      "[1751]\ttraining's auc: 0.891793\ttraining's binary_logloss: 0.196839\n",
      "[1752]\ttraining's auc: 0.891843\ttraining's binary_logloss: 0.196819\n",
      "[1753]\ttraining's auc: 0.891876\ttraining's binary_logloss: 0.196799\n",
      "[1754]\ttraining's auc: 0.89192\ttraining's binary_logloss: 0.196777\n",
      "[1755]\ttraining's auc: 0.891958\ttraining's binary_logloss: 0.196758\n",
      "[1756]\ttraining's auc: 0.892004\ttraining's binary_logloss: 0.196733\n",
      "[1757]\ttraining's auc: 0.892021\ttraining's binary_logloss: 0.196724\n",
      "[1758]\ttraining's auc: 0.892062\ttraining's binary_logloss: 0.196702\n",
      "[1759]\ttraining's auc: 0.892103\ttraining's binary_logloss: 0.19668\n",
      "[1760]\ttraining's auc: 0.892154\ttraining's binary_logloss: 0.196657\n",
      "[1761]\ttraining's auc: 0.89219\ttraining's binary_logloss: 0.196638\n",
      "[1762]\ttraining's auc: 0.892266\ttraining's binary_logloss: 0.196614\n",
      "[1763]\ttraining's auc: 0.892319\ttraining's binary_logloss: 0.196594\n",
      "[1764]\ttraining's auc: 0.892358\ttraining's binary_logloss: 0.196572\n",
      "[1765]\ttraining's auc: 0.892402\ttraining's binary_logloss: 0.196551\n",
      "[1766]\ttraining's auc: 0.892419\ttraining's binary_logloss: 0.196543\n",
      "[1767]\ttraining's auc: 0.892468\ttraining's binary_logloss: 0.196522\n",
      "[1768]\ttraining's auc: 0.892518\ttraining's binary_logloss: 0.196501\n",
      "[1769]\ttraining's auc: 0.892571\ttraining's binary_logloss: 0.196475\n",
      "[1770]\ttraining's auc: 0.892613\ttraining's binary_logloss: 0.196455\n",
      "[1771]\ttraining's auc: 0.892652\ttraining's binary_logloss: 0.196434\n",
      "[1772]\ttraining's auc: 0.892687\ttraining's binary_logloss: 0.196414\n",
      "[1773]\ttraining's auc: 0.892737\ttraining's binary_logloss: 0.196395\n",
      "[1774]\ttraining's auc: 0.892749\ttraining's binary_logloss: 0.196388\n",
      "[1775]\ttraining's auc: 0.892786\ttraining's binary_logloss: 0.196369\n",
      "[1776]\ttraining's auc: 0.892826\ttraining's binary_logloss: 0.196348\n",
      "[1777]\ttraining's auc: 0.892872\ttraining's binary_logloss: 0.196326\n",
      "[1778]\ttraining's auc: 0.892908\ttraining's binary_logloss: 0.196305\n",
      "[1779]\ttraining's auc: 0.892947\ttraining's binary_logloss: 0.196286\n",
      "[1780]\ttraining's auc: 0.892991\ttraining's binary_logloss: 0.196264\n",
      "[1781]\ttraining's auc: 0.893036\ttraining's binary_logloss: 0.196243\n",
      "[1782]\ttraining's auc: 0.893074\ttraining's binary_logloss: 0.196224\n",
      "[1783]\ttraining's auc: 0.893119\ttraining's binary_logloss: 0.196201\n",
      "[1784]\ttraining's auc: 0.89317\ttraining's binary_logloss: 0.196179\n",
      "[1785]\ttraining's auc: 0.893222\ttraining's binary_logloss: 0.19616\n",
      "[1786]\ttraining's auc: 0.893268\ttraining's binary_logloss: 0.196138\n",
      "[1787]\ttraining's auc: 0.893307\ttraining's binary_logloss: 0.196119\n",
      "[1788]\ttraining's auc: 0.893357\ttraining's binary_logloss: 0.1961\n",
      "[1789]\ttraining's auc: 0.893399\ttraining's binary_logloss: 0.19608\n",
      "[1790]\ttraining's auc: 0.893452\ttraining's binary_logloss: 0.196058\n",
      "[1791]\ttraining's auc: 0.893493\ttraining's binary_logloss: 0.196039\n",
      "[1792]\ttraining's auc: 0.893549\ttraining's binary_logloss: 0.196019\n",
      "[1793]\ttraining's auc: 0.893586\ttraining's binary_logloss: 0.195999\n",
      "[1794]\ttraining's auc: 0.893635\ttraining's binary_logloss: 0.195976\n",
      "[1795]\ttraining's auc: 0.893651\ttraining's binary_logloss: 0.195967\n",
      "[1796]\ttraining's auc: 0.89369\ttraining's binary_logloss: 0.195946\n",
      "[1797]\ttraining's auc: 0.893738\ttraining's binary_logloss: 0.195925\n",
      "[1798]\ttraining's auc: 0.893774\ttraining's binary_logloss: 0.195904\n",
      "[1799]\ttraining's auc: 0.893812\ttraining's binary_logloss: 0.195884\n",
      "[1800]\ttraining's auc: 0.89385\ttraining's binary_logloss: 0.195865\n",
      "[1801]\ttraining's auc: 0.893893\ttraining's binary_logloss: 0.195843\n",
      "[1802]\ttraining's auc: 0.893936\ttraining's binary_logloss: 0.195822\n",
      "[1803]\ttraining's auc: 0.894008\ttraining's binary_logloss: 0.195795\n",
      "[1804]\ttraining's auc: 0.894031\ttraining's binary_logloss: 0.195787\n",
      "[1805]\ttraining's auc: 0.894051\ttraining's binary_logloss: 0.195781\n",
      "[1806]\ttraining's auc: 0.894105\ttraining's binary_logloss: 0.195758\n",
      "[1807]\ttraining's auc: 0.894139\ttraining's binary_logloss: 0.195737\n",
      "[1808]\ttraining's auc: 0.894178\ttraining's binary_logloss: 0.195716\n",
      "[1809]\ttraining's auc: 0.894217\ttraining's binary_logloss: 0.195697\n",
      "[1810]\ttraining's auc: 0.894261\ttraining's binary_logloss: 0.195678\n",
      "[1811]\ttraining's auc: 0.894304\ttraining's binary_logloss: 0.195656\n",
      "[1812]\ttraining's auc: 0.894355\ttraining's binary_logloss: 0.195633\n",
      "[1813]\ttraining's auc: 0.894392\ttraining's binary_logloss: 0.195613\n",
      "[1814]\ttraining's auc: 0.894433\ttraining's binary_logloss: 0.195593\n",
      "[1815]\ttraining's auc: 0.894466\ttraining's binary_logloss: 0.195573\n",
      "[1816]\ttraining's auc: 0.894501\ttraining's binary_logloss: 0.195556\n",
      "[1817]\ttraining's auc: 0.894555\ttraining's binary_logloss: 0.195536\n",
      "[1818]\ttraining's auc: 0.894618\ttraining's binary_logloss: 0.195511\n",
      "[1819]\ttraining's auc: 0.894657\ttraining's binary_logloss: 0.19549\n",
      "[1820]\ttraining's auc: 0.894724\ttraining's binary_logloss: 0.195463\n",
      "[1821]\ttraining's auc: 0.894768\ttraining's binary_logloss: 0.195438\n",
      "[1822]\ttraining's auc: 0.894824\ttraining's binary_logloss: 0.195414\n",
      "[1823]\ttraining's auc: 0.894866\ttraining's binary_logloss: 0.195394\n",
      "[1824]\ttraining's auc: 0.894909\ttraining's binary_logloss: 0.195374\n",
      "[1825]\ttraining's auc: 0.894957\ttraining's binary_logloss: 0.195351\n",
      "[1826]\ttraining's auc: 0.894981\ttraining's binary_logloss: 0.195338\n",
      "[1827]\ttraining's auc: 0.895021\ttraining's binary_logloss: 0.195319\n",
      "[1828]\ttraining's auc: 0.895039\ttraining's binary_logloss: 0.195309\n",
      "[1829]\ttraining's auc: 0.895093\ttraining's binary_logloss: 0.195287\n",
      "[1830]\ttraining's auc: 0.895133\ttraining's binary_logloss: 0.195269\n",
      "[1831]\ttraining's auc: 0.895175\ttraining's binary_logloss: 0.195249\n",
      "[1832]\ttraining's auc: 0.895199\ttraining's binary_logloss: 0.195231\n",
      "[1833]\ttraining's auc: 0.895262\ttraining's binary_logloss: 0.195207\n",
      "[1834]\ttraining's auc: 0.895283\ttraining's binary_logloss: 0.195195\n",
      "[1835]\ttraining's auc: 0.895336\ttraining's binary_logloss: 0.195172\n",
      "[1836]\ttraining's auc: 0.895392\ttraining's binary_logloss: 0.195147\n",
      "[1837]\ttraining's auc: 0.895435\ttraining's binary_logloss: 0.195126\n",
      "[1838]\ttraining's auc: 0.895474\ttraining's binary_logloss: 0.195105\n",
      "[1839]\ttraining's auc: 0.895518\ttraining's binary_logloss: 0.195084\n",
      "[1840]\ttraining's auc: 0.895572\ttraining's binary_logloss: 0.19506\n",
      "[1841]\ttraining's auc: 0.895588\ttraining's binary_logloss: 0.195055\n",
      "[1842]\ttraining's auc: 0.895625\ttraining's binary_logloss: 0.195035\n",
      "[1843]\ttraining's auc: 0.895666\ttraining's binary_logloss: 0.195014\n",
      "[1844]\ttraining's auc: 0.895706\ttraining's binary_logloss: 0.194993\n",
      "[1845]\ttraining's auc: 0.89576\ttraining's binary_logloss: 0.194971\n",
      "[1846]\ttraining's auc: 0.8958\ttraining's binary_logloss: 0.194947\n",
      "[1847]\ttraining's auc: 0.89585\ttraining's binary_logloss: 0.194925\n",
      "[1848]\ttraining's auc: 0.895892\ttraining's binary_logloss: 0.194904\n",
      "[1849]\ttraining's auc: 0.895929\ttraining's binary_logloss: 0.194884\n",
      "[1850]\ttraining's auc: 0.895984\ttraining's binary_logloss: 0.194863\n",
      "[1851]\ttraining's auc: 0.896038\ttraining's binary_logloss: 0.194841\n",
      "[1852]\ttraining's auc: 0.896055\ttraining's binary_logloss: 0.194834\n",
      "[1853]\ttraining's auc: 0.896089\ttraining's binary_logloss: 0.194816\n",
      "[1854]\ttraining's auc: 0.896129\ttraining's binary_logloss: 0.194798\n",
      "[1855]\ttraining's auc: 0.896178\ttraining's binary_logloss: 0.194775\n",
      "[1856]\ttraining's auc: 0.896215\ttraining's binary_logloss: 0.194755\n",
      "[1857]\ttraining's auc: 0.896253\ttraining's binary_logloss: 0.194736\n",
      "[1858]\ttraining's auc: 0.896264\ttraining's binary_logloss: 0.19473\n",
      "[1859]\ttraining's auc: 0.896301\ttraining's binary_logloss: 0.194713\n",
      "[1860]\ttraining's auc: 0.896314\ttraining's binary_logloss: 0.194706\n",
      "[1861]\ttraining's auc: 0.896327\ttraining's binary_logloss: 0.194697\n",
      "[1862]\ttraining's auc: 0.896382\ttraining's binary_logloss: 0.194675\n",
      "[1863]\ttraining's auc: 0.896398\ttraining's binary_logloss: 0.194666\n",
      "[1864]\ttraining's auc: 0.896432\ttraining's binary_logloss: 0.194648\n",
      "[1865]\ttraining's auc: 0.896475\ttraining's binary_logloss: 0.194628\n",
      "[1866]\ttraining's auc: 0.896519\ttraining's binary_logloss: 0.194607\n",
      "[1867]\ttraining's auc: 0.896567\ttraining's binary_logloss: 0.194584\n",
      "[1868]\ttraining's auc: 0.896605\ttraining's binary_logloss: 0.194565\n",
      "[1869]\ttraining's auc: 0.896639\ttraining's binary_logloss: 0.194545\n",
      "[1870]\ttraining's auc: 0.896678\ttraining's binary_logloss: 0.194525\n",
      "[1871]\ttraining's auc: 0.896718\ttraining's binary_logloss: 0.194505\n",
      "[1872]\ttraining's auc: 0.896729\ttraining's binary_logloss: 0.194499\n",
      "[1873]\ttraining's auc: 0.896781\ttraining's binary_logloss: 0.194478\n",
      "[1874]\ttraining's auc: 0.896831\ttraining's binary_logloss: 0.194454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1875]\ttraining's auc: 0.896862\ttraining's binary_logloss: 0.194433\n",
      "[1876]\ttraining's auc: 0.896874\ttraining's binary_logloss: 0.194427\n",
      "[1877]\ttraining's auc: 0.8969\ttraining's binary_logloss: 0.194415\n",
      "[1878]\ttraining's auc: 0.896908\ttraining's binary_logloss: 0.194409\n",
      "[1879]\ttraining's auc: 0.896926\ttraining's binary_logloss: 0.194399\n",
      "[1880]\ttraining's auc: 0.896974\ttraining's binary_logloss: 0.194379\n",
      "[1881]\ttraining's auc: 0.896981\ttraining's binary_logloss: 0.194375\n",
      "[1882]\ttraining's auc: 0.897025\ttraining's binary_logloss: 0.194353\n",
      "[1883]\ttraining's auc: 0.897066\ttraining's binary_logloss: 0.194332\n",
      "[1884]\ttraining's auc: 0.897117\ttraining's binary_logloss: 0.194308\n",
      "[1885]\ttraining's auc: 0.897167\ttraining's binary_logloss: 0.194288\n",
      "[1886]\ttraining's auc: 0.897187\ttraining's binary_logloss: 0.194283\n",
      "[1887]\ttraining's auc: 0.897236\ttraining's binary_logloss: 0.194261\n",
      "[1888]\ttraining's auc: 0.897277\ttraining's binary_logloss: 0.19424\n",
      "[1889]\ttraining's auc: 0.897306\ttraining's binary_logloss: 0.194221\n",
      "[1890]\ttraining's auc: 0.897334\ttraining's binary_logloss: 0.194199\n",
      "[1891]\ttraining's auc: 0.897383\ttraining's binary_logloss: 0.194177\n",
      "[1892]\ttraining's auc: 0.897403\ttraining's binary_logloss: 0.194168\n",
      "[1893]\ttraining's auc: 0.897435\ttraining's binary_logloss: 0.194154\n",
      "[1894]\ttraining's auc: 0.897478\ttraining's binary_logloss: 0.194132\n",
      "[1895]\ttraining's auc: 0.897521\ttraining's binary_logloss: 0.194112\n",
      "[1896]\ttraining's auc: 0.89753\ttraining's binary_logloss: 0.194106\n",
      "[1897]\ttraining's auc: 0.897581\ttraining's binary_logloss: 0.194084\n",
      "[1898]\ttraining's auc: 0.89762\ttraining's binary_logloss: 0.194065\n",
      "[1899]\ttraining's auc: 0.897655\ttraining's binary_logloss: 0.194045\n",
      "[1900]\ttraining's auc: 0.89768\ttraining's binary_logloss: 0.194029\n",
      "[1901]\ttraining's auc: 0.897721\ttraining's binary_logloss: 0.194008\n",
      "[1902]\ttraining's auc: 0.897761\ttraining's binary_logloss: 0.193986\n",
      "[1903]\ttraining's auc: 0.897808\ttraining's binary_logloss: 0.193968\n",
      "[1904]\ttraining's auc: 0.897818\ttraining's binary_logloss: 0.193961\n",
      "[1905]\ttraining's auc: 0.897844\ttraining's binary_logloss: 0.193949\n",
      "[1906]\ttraining's auc: 0.897889\ttraining's binary_logloss: 0.19393\n",
      "[1907]\ttraining's auc: 0.897903\ttraining's binary_logloss: 0.193925\n",
      "[1908]\ttraining's auc: 0.897937\ttraining's binary_logloss: 0.193907\n",
      "[1909]\ttraining's auc: 0.897978\ttraining's binary_logloss: 0.193887\n",
      "[1910]\ttraining's auc: 0.898019\ttraining's binary_logloss: 0.193865\n",
      "[1911]\ttraining's auc: 0.898046\ttraining's binary_logloss: 0.193851\n",
      "[1912]\ttraining's auc: 0.898109\ttraining's binary_logloss: 0.193832\n",
      "[1913]\ttraining's auc: 0.898163\ttraining's binary_logloss: 0.193805\n",
      "[1914]\ttraining's auc: 0.89822\ttraining's binary_logloss: 0.193782\n",
      "[1915]\ttraining's auc: 0.898238\ttraining's binary_logloss: 0.193772\n",
      "[1916]\ttraining's auc: 0.898271\ttraining's binary_logloss: 0.193757\n",
      "[1917]\ttraining's auc: 0.898325\ttraining's binary_logloss: 0.193733\n",
      "[1918]\ttraining's auc: 0.898362\ttraining's binary_logloss: 0.193714\n",
      "[1919]\ttraining's auc: 0.898387\ttraining's binary_logloss: 0.193694\n",
      "[1920]\ttraining's auc: 0.898439\ttraining's binary_logloss: 0.193675\n",
      "[1921]\ttraining's auc: 0.898484\ttraining's binary_logloss: 0.193652\n",
      "[1922]\ttraining's auc: 0.898531\ttraining's binary_logloss: 0.19363\n",
      "[1923]\ttraining's auc: 0.898569\ttraining's binary_logloss: 0.193609\n",
      "[1924]\ttraining's auc: 0.898596\ttraining's binary_logloss: 0.193595\n",
      "[1925]\ttraining's auc: 0.898615\ttraining's binary_logloss: 0.193584\n",
      "[1926]\ttraining's auc: 0.898629\ttraining's binary_logloss: 0.193577\n",
      "[1927]\ttraining's auc: 0.898655\ttraining's binary_logloss: 0.193564\n",
      "[1928]\ttraining's auc: 0.898699\ttraining's binary_logloss: 0.193544\n",
      "[1929]\ttraining's auc: 0.898753\ttraining's binary_logloss: 0.193522\n",
      "[1930]\ttraining's auc: 0.898757\ttraining's binary_logloss: 0.19352\n",
      "[1931]\ttraining's auc: 0.898794\ttraining's binary_logloss: 0.193501\n",
      "[1932]\ttraining's auc: 0.898829\ttraining's binary_logloss: 0.19348\n",
      "[1933]\ttraining's auc: 0.898882\ttraining's binary_logloss: 0.193459\n",
      "[1934]\ttraining's auc: 0.898895\ttraining's binary_logloss: 0.193448\n",
      "[1935]\ttraining's auc: 0.898918\ttraining's binary_logloss: 0.193437\n",
      "[1936]\ttraining's auc: 0.898949\ttraining's binary_logloss: 0.193418\n",
      "[1937]\ttraining's auc: 0.89898\ttraining's binary_logloss: 0.1934\n",
      "[1938]\ttraining's auc: 0.89903\ttraining's binary_logloss: 0.193375\n",
      "[1939]\ttraining's auc: 0.899068\ttraining's binary_logloss: 0.193354\n",
      "[1940]\ttraining's auc: 0.899122\ttraining's binary_logloss: 0.193332\n",
      "[1941]\ttraining's auc: 0.899151\ttraining's binary_logloss: 0.193315\n",
      "[1942]\ttraining's auc: 0.899193\ttraining's binary_logloss: 0.193294\n",
      "[1943]\ttraining's auc: 0.899247\ttraining's binary_logloss: 0.193271\n",
      "[1944]\ttraining's auc: 0.899297\ttraining's binary_logloss: 0.19325\n",
      "[1945]\ttraining's auc: 0.89933\ttraining's binary_logloss: 0.193232\n",
      "[1946]\ttraining's auc: 0.899373\ttraining's binary_logloss: 0.19321\n",
      "[1947]\ttraining's auc: 0.899415\ttraining's binary_logloss: 0.193189\n",
      "[1948]\ttraining's auc: 0.899455\ttraining's binary_logloss: 0.193171\n",
      "[1949]\ttraining's auc: 0.899504\ttraining's binary_logloss: 0.193149\n",
      "[1950]\ttraining's auc: 0.899536\ttraining's binary_logloss: 0.193131\n",
      "[1951]\ttraining's auc: 0.899586\ttraining's binary_logloss: 0.193107\n",
      "[1952]\ttraining's auc: 0.89962\ttraining's binary_logloss: 0.193093\n",
      "[1953]\ttraining's auc: 0.899664\ttraining's binary_logloss: 0.193074\n",
      "[1954]\ttraining's auc: 0.899712\ttraining's binary_logloss: 0.193052\n",
      "[1955]\ttraining's auc: 0.899755\ttraining's binary_logloss: 0.193033\n",
      "[1956]\ttraining's auc: 0.899802\ttraining's binary_logloss: 0.193014\n",
      "[1957]\ttraining's auc: 0.899822\ttraining's binary_logloss: 0.193\n",
      "[1958]\ttraining's auc: 0.899862\ttraining's binary_logloss: 0.19298\n",
      "[1959]\ttraining's auc: 0.899904\ttraining's binary_logloss: 0.192961\n",
      "[1960]\ttraining's auc: 0.899908\ttraining's binary_logloss: 0.192959\n",
      "[1961]\ttraining's auc: 0.899949\ttraining's binary_logloss: 0.192939\n",
      "[1962]\ttraining's auc: 0.89998\ttraining's binary_logloss: 0.192921\n",
      "[1963]\ttraining's auc: 0.900037\ttraining's binary_logloss: 0.192896\n",
      "[1964]\ttraining's auc: 0.900087\ttraining's binary_logloss: 0.192876\n",
      "[1965]\ttraining's auc: 0.900123\ttraining's binary_logloss: 0.192856\n",
      "[1966]\ttraining's auc: 0.900166\ttraining's binary_logloss: 0.192837\n",
      "[1967]\ttraining's auc: 0.9002\ttraining's binary_logloss: 0.192818\n",
      "[1968]\ttraining's auc: 0.900241\ttraining's binary_logloss: 0.192798\n",
      "[1969]\ttraining's auc: 0.900283\ttraining's binary_logloss: 0.192775\n",
      "[1970]\ttraining's auc: 0.900331\ttraining's binary_logloss: 0.192752\n",
      "[1971]\ttraining's auc: 0.900363\ttraining's binary_logloss: 0.192735\n",
      "[1972]\ttraining's auc: 0.9004\ttraining's binary_logloss: 0.192715\n",
      "[1973]\ttraining's auc: 0.900446\ttraining's binary_logloss: 0.192692\n",
      "[1974]\ttraining's auc: 0.900478\ttraining's binary_logloss: 0.192671\n",
      "[1975]\ttraining's auc: 0.900525\ttraining's binary_logloss: 0.192649\n",
      "[1976]\ttraining's auc: 0.900576\ttraining's binary_logloss: 0.192627\n",
      "[1977]\ttraining's auc: 0.900608\ttraining's binary_logloss: 0.192608\n",
      "[1978]\ttraining's auc: 0.900644\ttraining's binary_logloss: 0.192589\n",
      "[1979]\ttraining's auc: 0.900691\ttraining's binary_logloss: 0.192566\n",
      "[1980]\ttraining's auc: 0.900732\ttraining's binary_logloss: 0.192548\n",
      "[1981]\ttraining's auc: 0.900739\ttraining's binary_logloss: 0.192538\n",
      "[1982]\ttraining's auc: 0.900784\ttraining's binary_logloss: 0.192516\n",
      "[1983]\ttraining's auc: 0.900812\ttraining's binary_logloss: 0.192499\n",
      "[1984]\ttraining's auc: 0.900864\ttraining's binary_logloss: 0.192477\n",
      "[1985]\ttraining's auc: 0.900893\ttraining's binary_logloss: 0.192465\n",
      "[1986]\ttraining's auc: 0.900906\ttraining's binary_logloss: 0.192456\n",
      "[1987]\ttraining's auc: 0.90096\ttraining's binary_logloss: 0.192437\n",
      "[1988]\ttraining's auc: 0.901006\ttraining's binary_logloss: 0.192417\n",
      "[1989]\ttraining's auc: 0.901048\ttraining's binary_logloss: 0.192397\n",
      "[1990]\ttraining's auc: 0.901055\ttraining's binary_logloss: 0.192394\n",
      "[1991]\ttraining's auc: 0.901092\ttraining's binary_logloss: 0.192372\n",
      "[1992]\ttraining's auc: 0.901126\ttraining's binary_logloss: 0.192353\n",
      "[1993]\ttraining's auc: 0.901174\ttraining's binary_logloss: 0.192331\n",
      "[1994]\ttraining's auc: 0.90122\ttraining's binary_logloss: 0.192309\n",
      "[1995]\ttraining's auc: 0.901257\ttraining's binary_logloss: 0.192288\n",
      "[1996]\ttraining's auc: 0.901302\ttraining's binary_logloss: 0.192267\n",
      "[1997]\ttraining's auc: 0.901346\ttraining's binary_logloss: 0.192245\n",
      "[1998]\ttraining's auc: 0.90139\ttraining's binary_logloss: 0.192225\n",
      "[1999]\ttraining's auc: 0.901432\ttraining's binary_logloss: 0.192205\n",
      "[2000]\ttraining's auc: 0.901475\ttraining's binary_logloss: 0.192184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2001]\ttraining's auc: 0.901504\ttraining's binary_logloss: 0.192166\n",
      "[2002]\ttraining's auc: 0.901549\ttraining's binary_logloss: 0.19214\n",
      "[2003]\ttraining's auc: 0.90159\ttraining's binary_logloss: 0.192119\n",
      "[2004]\ttraining's auc: 0.901647\ttraining's binary_logloss: 0.192096\n",
      "[2005]\ttraining's auc: 0.901677\ttraining's binary_logloss: 0.19208\n",
      "[2006]\ttraining's auc: 0.901685\ttraining's binary_logloss: 0.192075\n",
      "[2007]\ttraining's auc: 0.901702\ttraining's binary_logloss: 0.192066\n",
      "[2008]\ttraining's auc: 0.901734\ttraining's binary_logloss: 0.192047\n",
      "[2009]\ttraining's auc: 0.901783\ttraining's binary_logloss: 0.192029\n",
      "[2010]\ttraining's auc: 0.901834\ttraining's binary_logloss: 0.192004\n",
      "[2011]\ttraining's auc: 0.901882\ttraining's binary_logloss: 0.191981\n",
      "[2012]\ttraining's auc: 0.901923\ttraining's binary_logloss: 0.191959\n",
      "[2013]\ttraining's auc: 0.901963\ttraining's binary_logloss: 0.19194\n",
      "[2014]\ttraining's auc: 0.901998\ttraining's binary_logloss: 0.191919\n",
      "[2015]\ttraining's auc: 0.902048\ttraining's binary_logloss: 0.191896\n",
      "[2016]\ttraining's auc: 0.902107\ttraining's binary_logloss: 0.191873\n",
      "[2017]\ttraining's auc: 0.90215\ttraining's binary_logloss: 0.191853\n",
      "[2018]\ttraining's auc: 0.902184\ttraining's binary_logloss: 0.191834\n",
      "[2019]\ttraining's auc: 0.90222\ttraining's binary_logloss: 0.191815\n",
      "[2020]\ttraining's auc: 0.902254\ttraining's binary_logloss: 0.191796\n",
      "[2021]\ttraining's auc: 0.902289\ttraining's binary_logloss: 0.191773\n",
      "[2022]\ttraining's auc: 0.902338\ttraining's binary_logloss: 0.191756\n",
      "[2023]\ttraining's auc: 0.902374\ttraining's binary_logloss: 0.191737\n",
      "[2024]\ttraining's auc: 0.902404\ttraining's binary_logloss: 0.191719\n",
      "[2025]\ttraining's auc: 0.902443\ttraining's binary_logloss: 0.191699\n",
      "[2026]\ttraining's auc: 0.902474\ttraining's binary_logloss: 0.191685\n",
      "[2027]\ttraining's auc: 0.902518\ttraining's binary_logloss: 0.191666\n",
      "[2028]\ttraining's auc: 0.902566\ttraining's binary_logloss: 0.191644\n",
      "[2029]\ttraining's auc: 0.902612\ttraining's binary_logloss: 0.191624\n",
      "[2030]\ttraining's auc: 0.902656\ttraining's binary_logloss: 0.191602\n",
      "[2031]\ttraining's auc: 0.902688\ttraining's binary_logloss: 0.191587\n",
      "[2032]\ttraining's auc: 0.902724\ttraining's binary_logloss: 0.191567\n",
      "[2033]\ttraining's auc: 0.902762\ttraining's binary_logloss: 0.191547\n",
      "[2034]\ttraining's auc: 0.902813\ttraining's binary_logloss: 0.191525\n",
      "[2035]\ttraining's auc: 0.902845\ttraining's binary_logloss: 0.191507\n",
      "[2036]\ttraining's auc: 0.902881\ttraining's binary_logloss: 0.191487\n",
      "[2037]\ttraining's auc: 0.902929\ttraining's binary_logloss: 0.191464\n",
      "[2038]\ttraining's auc: 0.902958\ttraining's binary_logloss: 0.191443\n",
      "[2039]\ttraining's auc: 0.902991\ttraining's binary_logloss: 0.191424\n",
      "[2040]\ttraining's auc: 0.903041\ttraining's binary_logloss: 0.191403\n",
      "[2041]\ttraining's auc: 0.903068\ttraining's binary_logloss: 0.19139\n",
      "[2042]\ttraining's auc: 0.903111\ttraining's binary_logloss: 0.191371\n",
      "[2043]\ttraining's auc: 0.90315\ttraining's binary_logloss: 0.191353\n",
      "[2044]\ttraining's auc: 0.903174\ttraining's binary_logloss: 0.191334\n",
      "[2045]\ttraining's auc: 0.903221\ttraining's binary_logloss: 0.191315\n",
      "[2046]\ttraining's auc: 0.903264\ttraining's binary_logloss: 0.191296\n",
      "[2047]\ttraining's auc: 0.903307\ttraining's binary_logloss: 0.191276\n",
      "[2048]\ttraining's auc: 0.903317\ttraining's binary_logloss: 0.191272\n",
      "[2049]\ttraining's auc: 0.90335\ttraining's binary_logloss: 0.191257\n",
      "[2050]\ttraining's auc: 0.903391\ttraining's binary_logloss: 0.191237\n",
      "[2051]\ttraining's auc: 0.903419\ttraining's binary_logloss: 0.191221\n",
      "[2052]\ttraining's auc: 0.903452\ttraining's binary_logloss: 0.191209\n",
      "[2053]\ttraining's auc: 0.90351\ttraining's binary_logloss: 0.191185\n",
      "[2054]\ttraining's auc: 0.903547\ttraining's binary_logloss: 0.191166\n",
      "[2055]\ttraining's auc: 0.903566\ttraining's binary_logloss: 0.191155\n",
      "[2056]\ttraining's auc: 0.903623\ttraining's binary_logloss: 0.191133\n",
      "[2057]\ttraining's auc: 0.903654\ttraining's binary_logloss: 0.191112\n",
      "[2058]\ttraining's auc: 0.903682\ttraining's binary_logloss: 0.191101\n",
      "[2059]\ttraining's auc: 0.903723\ttraining's binary_logloss: 0.191079\n",
      "[2060]\ttraining's auc: 0.903756\ttraining's binary_logloss: 0.191064\n",
      "[2061]\ttraining's auc: 0.903792\ttraining's binary_logloss: 0.191051\n",
      "[2062]\ttraining's auc: 0.903842\ttraining's binary_logloss: 0.191028\n",
      "[2063]\ttraining's auc: 0.903887\ttraining's binary_logloss: 0.191006\n",
      "[2064]\ttraining's auc: 0.903915\ttraining's binary_logloss: 0.190989\n",
      "[2065]\ttraining's auc: 0.903956\ttraining's binary_logloss: 0.19097\n",
      "[2066]\ttraining's auc: 0.903996\ttraining's binary_logloss: 0.19095\n",
      "[2067]\ttraining's auc: 0.904045\ttraining's binary_logloss: 0.190927\n",
      "[2068]\ttraining's auc: 0.904085\ttraining's binary_logloss: 0.190908\n",
      "[2069]\ttraining's auc: 0.904126\ttraining's binary_logloss: 0.190887\n",
      "[2070]\ttraining's auc: 0.904165\ttraining's binary_logloss: 0.190869\n",
      "[2071]\ttraining's auc: 0.904194\ttraining's binary_logloss: 0.19085\n",
      "[2072]\ttraining's auc: 0.904245\ttraining's binary_logloss: 0.190829\n",
      "[2073]\ttraining's auc: 0.904282\ttraining's binary_logloss: 0.190806\n",
      "[2074]\ttraining's auc: 0.90432\ttraining's binary_logloss: 0.190787\n",
      "[2075]\ttraining's auc: 0.90438\ttraining's binary_logloss: 0.190762\n",
      "[2076]\ttraining's auc: 0.904409\ttraining's binary_logloss: 0.190746\n",
      "[2077]\ttraining's auc: 0.90445\ttraining's binary_logloss: 0.190723\n",
      "[2078]\ttraining's auc: 0.904487\ttraining's binary_logloss: 0.190704\n",
      "[2079]\ttraining's auc: 0.904532\ttraining's binary_logloss: 0.190684\n",
      "[2080]\ttraining's auc: 0.904574\ttraining's binary_logloss: 0.19066\n",
      "[2081]\ttraining's auc: 0.904596\ttraining's binary_logloss: 0.190646\n",
      "[2082]\ttraining's auc: 0.904612\ttraining's binary_logloss: 0.190636\n",
      "[2083]\ttraining's auc: 0.904658\ttraining's binary_logloss: 0.190612\n",
      "[2084]\ttraining's auc: 0.9047\ttraining's binary_logloss: 0.190591\n",
      "[2085]\ttraining's auc: 0.904733\ttraining's binary_logloss: 0.19057\n",
      "[2086]\ttraining's auc: 0.904766\ttraining's binary_logloss: 0.190551\n",
      "[2087]\ttraining's auc: 0.904807\ttraining's binary_logloss: 0.190532\n",
      "[2088]\ttraining's auc: 0.904847\ttraining's binary_logloss: 0.19051\n",
      "[2089]\ttraining's auc: 0.90489\ttraining's binary_logloss: 0.190487\n",
      "[2090]\ttraining's auc: 0.904936\ttraining's binary_logloss: 0.190462\n",
      "[2091]\ttraining's auc: 0.904973\ttraining's binary_logloss: 0.190444\n",
      "[2092]\ttraining's auc: 0.905015\ttraining's binary_logloss: 0.190424\n",
      "[2093]\ttraining's auc: 0.905045\ttraining's binary_logloss: 0.190406\n",
      "[2094]\ttraining's auc: 0.905083\ttraining's binary_logloss: 0.190383\n",
      "[2095]\ttraining's auc: 0.90511\ttraining's binary_logloss: 0.190369\n",
      "[2096]\ttraining's auc: 0.905152\ttraining's binary_logloss: 0.19035\n",
      "[2097]\ttraining's auc: 0.905207\ttraining's binary_logloss: 0.190326\n",
      "[2098]\ttraining's auc: 0.905241\ttraining's binary_logloss: 0.190308\n",
      "[2099]\ttraining's auc: 0.905275\ttraining's binary_logloss: 0.190287\n",
      "[2100]\ttraining's auc: 0.905316\ttraining's binary_logloss: 0.190266\n",
      "[2101]\ttraining's auc: 0.905358\ttraining's binary_logloss: 0.190242\n",
      "[2102]\ttraining's auc: 0.905398\ttraining's binary_logloss: 0.19022\n",
      "[2103]\ttraining's auc: 0.905401\ttraining's binary_logloss: 0.190219\n",
      "[2104]\ttraining's auc: 0.905452\ttraining's binary_logloss: 0.190192\n",
      "[2105]\ttraining's auc: 0.905479\ttraining's binary_logloss: 0.190172\n",
      "[2106]\ttraining's auc: 0.905519\ttraining's binary_logloss: 0.190149\n",
      "[2107]\ttraining's auc: 0.905573\ttraining's binary_logloss: 0.190128\n",
      "[2108]\ttraining's auc: 0.905593\ttraining's binary_logloss: 0.190119\n",
      "[2109]\ttraining's auc: 0.905633\ttraining's binary_logloss: 0.190098\n",
      "[2110]\ttraining's auc: 0.90567\ttraining's binary_logloss: 0.190081\n",
      "[2111]\ttraining's auc: 0.905722\ttraining's binary_logloss: 0.190057\n",
      "[2112]\ttraining's auc: 0.905745\ttraining's binary_logloss: 0.190039\n",
      "[2113]\ttraining's auc: 0.905786\ttraining's binary_logloss: 0.190017\n",
      "[2114]\ttraining's auc: 0.90582\ttraining's binary_logloss: 0.189997\n",
      "[2115]\ttraining's auc: 0.905861\ttraining's binary_logloss: 0.189978\n",
      "[2116]\ttraining's auc: 0.905908\ttraining's binary_logloss: 0.189958\n",
      "[2117]\ttraining's auc: 0.905964\ttraining's binary_logloss: 0.189935\n",
      "[2118]\ttraining's auc: 0.905999\ttraining's binary_logloss: 0.189916\n",
      "[2119]\ttraining's auc: 0.90604\ttraining's binary_logloss: 0.189898\n",
      "[2120]\ttraining's auc: 0.906092\ttraining's binary_logloss: 0.189876\n",
      "[2121]\ttraining's auc: 0.906139\ttraining's binary_logloss: 0.189854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2122]\ttraining's auc: 0.906179\ttraining's binary_logloss: 0.189832\n",
      "[2123]\ttraining's auc: 0.906218\ttraining's binary_logloss: 0.189813\n",
      "[2124]\ttraining's auc: 0.906254\ttraining's binary_logloss: 0.189793\n",
      "[2125]\ttraining's auc: 0.906297\ttraining's binary_logloss: 0.189772\n",
      "[2126]\ttraining's auc: 0.906335\ttraining's binary_logloss: 0.189757\n",
      "[2127]\ttraining's auc: 0.90637\ttraining's binary_logloss: 0.189739\n",
      "[2128]\ttraining's auc: 0.906406\ttraining's binary_logloss: 0.189718\n",
      "[2129]\ttraining's auc: 0.90645\ttraining's binary_logloss: 0.189698\n",
      "[2130]\ttraining's auc: 0.906492\ttraining's binary_logloss: 0.189679\n",
      "[2131]\ttraining's auc: 0.906508\ttraining's binary_logloss: 0.18967\n",
      "[2132]\ttraining's auc: 0.906518\ttraining's binary_logloss: 0.189664\n",
      "[2133]\ttraining's auc: 0.906561\ttraining's binary_logloss: 0.189642\n",
      "[2134]\ttraining's auc: 0.906608\ttraining's binary_logloss: 0.18962\n",
      "[2135]\ttraining's auc: 0.906646\ttraining's binary_logloss: 0.189599\n",
      "[2136]\ttraining's auc: 0.906675\ttraining's binary_logloss: 0.189579\n",
      "[2137]\ttraining's auc: 0.906716\ttraining's binary_logloss: 0.189557\n",
      "[2138]\ttraining's auc: 0.90676\ttraining's binary_logloss: 0.189537\n",
      "[2139]\ttraining's auc: 0.906798\ttraining's binary_logloss: 0.189519\n",
      "[2140]\ttraining's auc: 0.906804\ttraining's binary_logloss: 0.189515\n",
      "[2141]\ttraining's auc: 0.906836\ttraining's binary_logloss: 0.189498\n",
      "[2142]\ttraining's auc: 0.906865\ttraining's binary_logloss: 0.18948\n",
      "[2143]\ttraining's auc: 0.906907\ttraining's binary_logloss: 0.189462\n",
      "[2144]\ttraining's auc: 0.906922\ttraining's binary_logloss: 0.189455\n",
      "[2145]\ttraining's auc: 0.906952\ttraining's binary_logloss: 0.189439\n",
      "[2146]\ttraining's auc: 0.906987\ttraining's binary_logloss: 0.189421\n",
      "[2147]\ttraining's auc: 0.907017\ttraining's binary_logloss: 0.189404\n",
      "[2148]\ttraining's auc: 0.90705\ttraining's binary_logloss: 0.189383\n",
      "[2149]\ttraining's auc: 0.907091\ttraining's binary_logloss: 0.189361\n",
      "[2150]\ttraining's auc: 0.907128\ttraining's binary_logloss: 0.189346\n",
      "[2151]\ttraining's auc: 0.907166\ttraining's binary_logloss: 0.189327\n",
      "[2152]\ttraining's auc: 0.907201\ttraining's binary_logloss: 0.189308\n",
      "[2153]\ttraining's auc: 0.907229\ttraining's binary_logloss: 0.189288\n",
      "[2154]\ttraining's auc: 0.907262\ttraining's binary_logloss: 0.189268\n",
      "[2155]\ttraining's auc: 0.907288\ttraining's binary_logloss: 0.189249\n",
      "[2156]\ttraining's auc: 0.907327\ttraining's binary_logloss: 0.18923\n",
      "[2157]\ttraining's auc: 0.907364\ttraining's binary_logloss: 0.189211\n",
      "[2158]\ttraining's auc: 0.907403\ttraining's binary_logloss: 0.189191\n",
      "[2159]\ttraining's auc: 0.907433\ttraining's binary_logloss: 0.189172\n",
      "[2160]\ttraining's auc: 0.90747\ttraining's binary_logloss: 0.189152\n",
      "[2161]\ttraining's auc: 0.907508\ttraining's binary_logloss: 0.189135\n",
      "[2162]\ttraining's auc: 0.907541\ttraining's binary_logloss: 0.189118\n",
      "[2163]\ttraining's auc: 0.907579\ttraining's binary_logloss: 0.189098\n",
      "[2164]\ttraining's auc: 0.907614\ttraining's binary_logloss: 0.189079\n",
      "[2165]\ttraining's auc: 0.907647\ttraining's binary_logloss: 0.18906\n",
      "[2166]\ttraining's auc: 0.907687\ttraining's binary_logloss: 0.189039\n",
      "[2167]\ttraining's auc: 0.907725\ttraining's binary_logloss: 0.189019\n",
      "[2168]\ttraining's auc: 0.907764\ttraining's binary_logloss: 0.189\n",
      "[2169]\ttraining's auc: 0.907815\ttraining's binary_logloss: 0.188979\n",
      "[2170]\ttraining's auc: 0.907838\ttraining's binary_logloss: 0.188961\n",
      "[2171]\ttraining's auc: 0.907846\ttraining's binary_logloss: 0.188957\n",
      "[2172]\ttraining's auc: 0.907881\ttraining's binary_logloss: 0.188938\n",
      "[2173]\ttraining's auc: 0.907928\ttraining's binary_logloss: 0.188917\n",
      "[2174]\ttraining's auc: 0.907963\ttraining's binary_logloss: 0.188897\n",
      "[2175]\ttraining's auc: 0.907996\ttraining's binary_logloss: 0.188877\n",
      "[2176]\ttraining's auc: 0.90805\ttraining's binary_logloss: 0.188855\n",
      "[2177]\ttraining's auc: 0.908081\ttraining's binary_logloss: 0.188835\n",
      "[2178]\ttraining's auc: 0.908106\ttraining's binary_logloss: 0.188823\n",
      "[2179]\ttraining's auc: 0.908135\ttraining's binary_logloss: 0.188806\n",
      "[2180]\ttraining's auc: 0.908178\ttraining's binary_logloss: 0.188784\n",
      "[2181]\ttraining's auc: 0.908233\ttraining's binary_logloss: 0.188763\n",
      "[2182]\ttraining's auc: 0.908287\ttraining's binary_logloss: 0.18874\n",
      "[2183]\ttraining's auc: 0.908333\ttraining's binary_logloss: 0.18872\n",
      "[2184]\ttraining's auc: 0.908371\ttraining's binary_logloss: 0.188702\n",
      "[2185]\ttraining's auc: 0.908401\ttraining's binary_logloss: 0.188684\n",
      "[2186]\ttraining's auc: 0.908427\ttraining's binary_logloss: 0.188665\n",
      "[2187]\ttraining's auc: 0.908465\ttraining's binary_logloss: 0.188646\n",
      "[2188]\ttraining's auc: 0.908506\ttraining's binary_logloss: 0.188626\n",
      "[2189]\ttraining's auc: 0.908545\ttraining's binary_logloss: 0.188607\n",
      "[2190]\ttraining's auc: 0.908593\ttraining's binary_logloss: 0.188583\n",
      "[2191]\ttraining's auc: 0.908627\ttraining's binary_logloss: 0.188565\n",
      "[2192]\ttraining's auc: 0.908667\ttraining's binary_logloss: 0.188544\n",
      "[2193]\ttraining's auc: 0.908687\ttraining's binary_logloss: 0.188534\n",
      "[2194]\ttraining's auc: 0.908715\ttraining's binary_logloss: 0.188521\n",
      "[2195]\ttraining's auc: 0.908751\ttraining's binary_logloss: 0.188501\n",
      "[2196]\ttraining's auc: 0.90879\ttraining's binary_logloss: 0.188481\n",
      "[2197]\ttraining's auc: 0.908839\ttraining's binary_logloss: 0.188457\n",
      "[2198]\ttraining's auc: 0.90887\ttraining's binary_logloss: 0.18844\n",
      "[2199]\ttraining's auc: 0.90888\ttraining's binary_logloss: 0.188436\n",
      "[2200]\ttraining's auc: 0.908916\ttraining's binary_logloss: 0.18842\n",
      "[2201]\ttraining's auc: 0.908955\ttraining's binary_logloss: 0.188398\n",
      "[2202]\ttraining's auc: 0.909001\ttraining's binary_logloss: 0.188376\n",
      "[2203]\ttraining's auc: 0.909031\ttraining's binary_logloss: 0.188358\n",
      "[2204]\ttraining's auc: 0.909063\ttraining's binary_logloss: 0.188336\n",
      "[2205]\ttraining's auc: 0.909096\ttraining's binary_logloss: 0.188316\n",
      "[2206]\ttraining's auc: 0.909136\ttraining's binary_logloss: 0.188296\n",
      "[2207]\ttraining's auc: 0.909179\ttraining's binary_logloss: 0.188274\n",
      "[2208]\ttraining's auc: 0.90922\ttraining's binary_logloss: 0.188254\n",
      "[2209]\ttraining's auc: 0.909273\ttraining's binary_logloss: 0.188231\n",
      "[2210]\ttraining's auc: 0.909314\ttraining's binary_logloss: 0.188212\n",
      "[2211]\ttraining's auc: 0.90935\ttraining's binary_logloss: 0.188191\n",
      "[2212]\ttraining's auc: 0.909359\ttraining's binary_logloss: 0.188187\n",
      "[2213]\ttraining's auc: 0.909414\ttraining's binary_logloss: 0.188165\n",
      "[2214]\ttraining's auc: 0.909452\ttraining's binary_logloss: 0.188144\n",
      "[2215]\ttraining's auc: 0.909504\ttraining's binary_logloss: 0.188121\n",
      "[2216]\ttraining's auc: 0.909541\ttraining's binary_logloss: 0.1881\n",
      "[2217]\ttraining's auc: 0.909584\ttraining's binary_logloss: 0.188078\n",
      "[2218]\ttraining's auc: 0.909627\ttraining's binary_logloss: 0.188057\n",
      "[2219]\ttraining's auc: 0.909663\ttraining's binary_logloss: 0.188037\n",
      "[2220]\ttraining's auc: 0.9097\ttraining's binary_logloss: 0.188014\n",
      "[2221]\ttraining's auc: 0.909745\ttraining's binary_logloss: 0.187993\n",
      "[2222]\ttraining's auc: 0.909785\ttraining's binary_logloss: 0.18797\n",
      "[2223]\ttraining's auc: 0.909818\ttraining's binary_logloss: 0.187952\n",
      "[2224]\ttraining's auc: 0.909827\ttraining's binary_logloss: 0.187947\n",
      "[2225]\ttraining's auc: 0.909878\ttraining's binary_logloss: 0.187927\n",
      "[2226]\ttraining's auc: 0.909915\ttraining's binary_logloss: 0.187909\n",
      "[2227]\ttraining's auc: 0.909954\ttraining's binary_logloss: 0.187891\n",
      "[2228]\ttraining's auc: 0.909995\ttraining's binary_logloss: 0.18787\n",
      "[2229]\ttraining's auc: 0.910023\ttraining's binary_logloss: 0.187858\n",
      "[2230]\ttraining's auc: 0.910049\ttraining's binary_logloss: 0.187839\n",
      "[2231]\ttraining's auc: 0.910088\ttraining's binary_logloss: 0.187821\n",
      "[2232]\ttraining's auc: 0.910128\ttraining's binary_logloss: 0.1878\n",
      "[2233]\ttraining's auc: 0.910163\ttraining's binary_logloss: 0.187781\n",
      "[2234]\ttraining's auc: 0.910211\ttraining's binary_logloss: 0.18776\n",
      "[2235]\ttraining's auc: 0.910253\ttraining's binary_logloss: 0.18774\n",
      "[2236]\ttraining's auc: 0.910302\ttraining's binary_logloss: 0.18772\n",
      "[2237]\ttraining's auc: 0.910337\ttraining's binary_logloss: 0.187702\n",
      "[2238]\ttraining's auc: 0.910381\ttraining's binary_logloss: 0.187678\n",
      "[2239]\ttraining's auc: 0.910419\ttraining's binary_logloss: 0.187657\n",
      "[2240]\ttraining's auc: 0.910462\ttraining's binary_logloss: 0.187634\n",
      "[2241]\ttraining's auc: 0.910486\ttraining's binary_logloss: 0.187619\n",
      "[2242]\ttraining's auc: 0.910529\ttraining's binary_logloss: 0.1876\n",
      "[2243]\ttraining's auc: 0.910564\ttraining's binary_logloss: 0.18758\n",
      "[2244]\ttraining's auc: 0.910605\ttraining's binary_logloss: 0.187559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2245]\ttraining's auc: 0.910642\ttraining's binary_logloss: 0.18754\n",
      "[2246]\ttraining's auc: 0.910685\ttraining's binary_logloss: 0.187517\n",
      "[2247]\ttraining's auc: 0.910711\ttraining's binary_logloss: 0.187505\n",
      "[2248]\ttraining's auc: 0.910742\ttraining's binary_logloss: 0.187487\n",
      "[2249]\ttraining's auc: 0.910767\ttraining's binary_logloss: 0.187473\n",
      "[2250]\ttraining's auc: 0.910812\ttraining's binary_logloss: 0.187452\n",
      "[2251]\ttraining's auc: 0.910845\ttraining's binary_logloss: 0.187434\n",
      "[2252]\ttraining's auc: 0.910868\ttraining's binary_logloss: 0.187424\n",
      "[2253]\ttraining's auc: 0.910899\ttraining's binary_logloss: 0.187401\n",
      "[2254]\ttraining's auc: 0.910947\ttraining's binary_logloss: 0.18738\n",
      "[2255]\ttraining's auc: 0.910988\ttraining's binary_logloss: 0.187358\n",
      "[2256]\ttraining's auc: 0.911028\ttraining's binary_logloss: 0.187337\n",
      "[2257]\ttraining's auc: 0.911042\ttraining's binary_logloss: 0.187331\n",
      "[2258]\ttraining's auc: 0.911066\ttraining's binary_logloss: 0.187318\n",
      "[2259]\ttraining's auc: 0.91111\ttraining's binary_logloss: 0.1873\n",
      "[2260]\ttraining's auc: 0.911142\ttraining's binary_logloss: 0.187281\n",
      "[2261]\ttraining's auc: 0.911183\ttraining's binary_logloss: 0.18726\n",
      "[2262]\ttraining's auc: 0.911224\ttraining's binary_logloss: 0.187239\n",
      "[2263]\ttraining's auc: 0.911258\ttraining's binary_logloss: 0.187217\n",
      "[2264]\ttraining's auc: 0.911281\ttraining's binary_logloss: 0.187206\n",
      "[2265]\ttraining's auc: 0.911322\ttraining's binary_logloss: 0.187184\n",
      "[2266]\ttraining's auc: 0.911362\ttraining's binary_logloss: 0.187164\n",
      "[2267]\ttraining's auc: 0.911402\ttraining's binary_logloss: 0.187143\n",
      "[2268]\ttraining's auc: 0.911433\ttraining's binary_logloss: 0.187124\n",
      "[2269]\ttraining's auc: 0.911477\ttraining's binary_logloss: 0.187104\n",
      "[2270]\ttraining's auc: 0.911511\ttraining's binary_logloss: 0.187083\n",
      "[2271]\ttraining's auc: 0.911555\ttraining's binary_logloss: 0.187064\n",
      "[2272]\ttraining's auc: 0.911588\ttraining's binary_logloss: 0.187045\n",
      "[2273]\ttraining's auc: 0.911617\ttraining's binary_logloss: 0.187024\n",
      "[2274]\ttraining's auc: 0.91165\ttraining's binary_logloss: 0.187004\n",
      "[2275]\ttraining's auc: 0.911684\ttraining's binary_logloss: 0.186982\n",
      "[2276]\ttraining's auc: 0.911721\ttraining's binary_logloss: 0.186965\n",
      "[2277]\ttraining's auc: 0.911731\ttraining's binary_logloss: 0.18696\n",
      "[2278]\ttraining's auc: 0.911742\ttraining's binary_logloss: 0.18695\n",
      "[2279]\ttraining's auc: 0.911774\ttraining's binary_logloss: 0.186932\n",
      "[2280]\ttraining's auc: 0.911806\ttraining's binary_logloss: 0.186914\n",
      "[2281]\ttraining's auc: 0.91184\ttraining's binary_logloss: 0.186894\n",
      "[2282]\ttraining's auc: 0.911859\ttraining's binary_logloss: 0.186884\n",
      "[2283]\ttraining's auc: 0.911883\ttraining's binary_logloss: 0.186866\n",
      "[2284]\ttraining's auc: 0.911933\ttraining's binary_logloss: 0.186846\n",
      "[2285]\ttraining's auc: 0.911981\ttraining's binary_logloss: 0.186827\n",
      "[2286]\ttraining's auc: 0.911998\ttraining's binary_logloss: 0.186818\n",
      "[2287]\ttraining's auc: 0.912036\ttraining's binary_logloss: 0.186799\n",
      "[2288]\ttraining's auc: 0.91208\ttraining's binary_logloss: 0.186778\n",
      "[2289]\ttraining's auc: 0.912105\ttraining's binary_logloss: 0.186765\n",
      "[2290]\ttraining's auc: 0.912137\ttraining's binary_logloss: 0.186747\n",
      "[2291]\ttraining's auc: 0.912161\ttraining's binary_logloss: 0.186734\n",
      "[2292]\ttraining's auc: 0.912196\ttraining's binary_logloss: 0.186715\n",
      "[2293]\ttraining's auc: 0.912244\ttraining's binary_logloss: 0.186694\n",
      "[2294]\ttraining's auc: 0.9123\ttraining's binary_logloss: 0.18667\n",
      "[2295]\ttraining's auc: 0.912332\ttraining's binary_logloss: 0.18665\n",
      "[2296]\ttraining's auc: 0.912392\ttraining's binary_logloss: 0.186626\n",
      "[2297]\ttraining's auc: 0.912424\ttraining's binary_logloss: 0.186606\n",
      "[2298]\ttraining's auc: 0.912463\ttraining's binary_logloss: 0.186587\n",
      "[2299]\ttraining's auc: 0.9125\ttraining's binary_logloss: 0.186568\n",
      "[2300]\ttraining's auc: 0.912534\ttraining's binary_logloss: 0.186548\n",
      "[2301]\ttraining's auc: 0.912565\ttraining's binary_logloss: 0.18653\n",
      "[2302]\ttraining's auc: 0.912595\ttraining's binary_logloss: 0.186509\n",
      "[2303]\ttraining's auc: 0.912625\ttraining's binary_logloss: 0.186494\n",
      "[2304]\ttraining's auc: 0.912658\ttraining's binary_logloss: 0.18648\n",
      "[2305]\ttraining's auc: 0.912681\ttraining's binary_logloss: 0.186468\n",
      "[2306]\ttraining's auc: 0.912726\ttraining's binary_logloss: 0.186447\n",
      "[2307]\ttraining's auc: 0.912755\ttraining's binary_logloss: 0.186429\n",
      "[2308]\ttraining's auc: 0.912786\ttraining's binary_logloss: 0.186411\n",
      "[2309]\ttraining's auc: 0.912821\ttraining's binary_logloss: 0.186391\n",
      "[2310]\ttraining's auc: 0.912862\ttraining's binary_logloss: 0.186372\n",
      "[2311]\ttraining's auc: 0.912891\ttraining's binary_logloss: 0.186353\n",
      "[2312]\ttraining's auc: 0.912924\ttraining's binary_logloss: 0.186333\n",
      "[2313]\ttraining's auc: 0.912962\ttraining's binary_logloss: 0.186313\n",
      "[2314]\ttraining's auc: 0.913008\ttraining's binary_logloss: 0.186291\n",
      "[2315]\ttraining's auc: 0.913043\ttraining's binary_logloss: 0.186273\n",
      "[2316]\ttraining's auc: 0.913082\ttraining's binary_logloss: 0.186252\n",
      "[2317]\ttraining's auc: 0.913134\ttraining's binary_logloss: 0.186228\n",
      "[2318]\ttraining's auc: 0.91317\ttraining's binary_logloss: 0.186207\n",
      "[2319]\ttraining's auc: 0.913196\ttraining's binary_logloss: 0.186191\n",
      "[2320]\ttraining's auc: 0.913228\ttraining's binary_logloss: 0.186173\n",
      "[2321]\ttraining's auc: 0.913264\ttraining's binary_logloss: 0.186153\n",
      "[2322]\ttraining's auc: 0.913309\ttraining's binary_logloss: 0.186133\n",
      "[2323]\ttraining's auc: 0.913343\ttraining's binary_logloss: 0.186112\n",
      "[2324]\ttraining's auc: 0.913372\ttraining's binary_logloss: 0.186092\n",
      "[2325]\ttraining's auc: 0.9134\ttraining's binary_logloss: 0.186073\n",
      "[2326]\ttraining's auc: 0.913445\ttraining's binary_logloss: 0.18605\n",
      "[2327]\ttraining's auc: 0.913473\ttraining's binary_logloss: 0.18603\n",
      "[2328]\ttraining's auc: 0.913512\ttraining's binary_logloss: 0.186012\n",
      "[2329]\ttraining's auc: 0.913557\ttraining's binary_logloss: 0.18599\n",
      "[2330]\ttraining's auc: 0.913589\ttraining's binary_logloss: 0.18597\n",
      "[2331]\ttraining's auc: 0.913629\ttraining's binary_logloss: 0.185951\n",
      "[2332]\ttraining's auc: 0.913662\ttraining's binary_logloss: 0.185932\n",
      "[2333]\ttraining's auc: 0.913686\ttraining's binary_logloss: 0.185915\n",
      "[2334]\ttraining's auc: 0.913731\ttraining's binary_logloss: 0.185893\n",
      "[2335]\ttraining's auc: 0.91376\ttraining's binary_logloss: 0.185875\n",
      "[2336]\ttraining's auc: 0.91379\ttraining's binary_logloss: 0.185856\n",
      "[2337]\ttraining's auc: 0.913823\ttraining's binary_logloss: 0.185836\n",
      "[2338]\ttraining's auc: 0.913863\ttraining's binary_logloss: 0.185818\n",
      "[2339]\ttraining's auc: 0.913896\ttraining's binary_logloss: 0.1858\n",
      "[2340]\ttraining's auc: 0.913932\ttraining's binary_logloss: 0.185779\n",
      "[2341]\ttraining's auc: 0.913958\ttraining's binary_logloss: 0.185761\n",
      "[2342]\ttraining's auc: 0.914001\ttraining's binary_logloss: 0.185742\n",
      "[2343]\ttraining's auc: 0.914042\ttraining's binary_logloss: 0.185722\n",
      "[2344]\ttraining's auc: 0.914073\ttraining's binary_logloss: 0.185704\n",
      "[2345]\ttraining's auc: 0.914106\ttraining's binary_logloss: 0.185684\n",
      "[2346]\ttraining's auc: 0.914145\ttraining's binary_logloss: 0.185665\n",
      "[2347]\ttraining's auc: 0.914186\ttraining's binary_logloss: 0.185642\n",
      "[2348]\ttraining's auc: 0.91424\ttraining's binary_logloss: 0.185619\n",
      "[2349]\ttraining's auc: 0.914288\ttraining's binary_logloss: 0.185597\n",
      "[2350]\ttraining's auc: 0.914312\ttraining's binary_logloss: 0.18558\n",
      "[2351]\ttraining's auc: 0.91435\ttraining's binary_logloss: 0.185559\n",
      "[2352]\ttraining's auc: 0.91439\ttraining's binary_logloss: 0.185542\n",
      "[2353]\ttraining's auc: 0.914425\ttraining's binary_logloss: 0.185522\n",
      "[2354]\ttraining's auc: 0.914467\ttraining's binary_logloss: 0.1855\n",
      "[2355]\ttraining's auc: 0.914507\ttraining's binary_logloss: 0.185478\n",
      "[2356]\ttraining's auc: 0.914539\ttraining's binary_logloss: 0.185457\n",
      "[2357]\ttraining's auc: 0.914575\ttraining's binary_logloss: 0.185438\n",
      "[2358]\ttraining's auc: 0.91461\ttraining's binary_logloss: 0.185417\n",
      "[2359]\ttraining's auc: 0.914634\ttraining's binary_logloss: 0.185399\n",
      "[2360]\ttraining's auc: 0.914668\ttraining's binary_logloss: 0.185378\n",
      "[2361]\ttraining's auc: 0.914699\ttraining's binary_logloss: 0.185358\n",
      "[2362]\ttraining's auc: 0.914743\ttraining's binary_logloss: 0.185337\n",
      "[2363]\ttraining's auc: 0.914785\ttraining's binary_logloss: 0.185315\n",
      "[2364]\ttraining's auc: 0.91483\ttraining's binary_logloss: 0.185293\n",
      "[2365]\ttraining's auc: 0.914862\ttraining's binary_logloss: 0.185274\n",
      "[2366]\ttraining's auc: 0.914905\ttraining's binary_logloss: 0.185254\n",
      "[2367]\ttraining's auc: 0.914928\ttraining's binary_logloss: 0.185235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2368]\ttraining's auc: 0.914959\ttraining's binary_logloss: 0.185218\n",
      "[2369]\ttraining's auc: 0.914989\ttraining's binary_logloss: 0.1852\n",
      "[2370]\ttraining's auc: 0.915029\ttraining's binary_logloss: 0.185177\n",
      "[2371]\ttraining's auc: 0.915075\ttraining's binary_logloss: 0.185156\n",
      "[2372]\ttraining's auc: 0.915111\ttraining's binary_logloss: 0.185137\n",
      "[2373]\ttraining's auc: 0.91515\ttraining's binary_logloss: 0.185117\n",
      "[2374]\ttraining's auc: 0.915203\ttraining's binary_logloss: 0.185096\n",
      "[2375]\ttraining's auc: 0.91524\ttraining's binary_logloss: 0.185075\n",
      "[2376]\ttraining's auc: 0.915281\ttraining's binary_logloss: 0.185057\n",
      "[2377]\ttraining's auc: 0.915317\ttraining's binary_logloss: 0.185038\n",
      "[2378]\ttraining's auc: 0.915357\ttraining's binary_logloss: 0.185017\n",
      "[2379]\ttraining's auc: 0.91539\ttraining's binary_logloss: 0.184997\n",
      "[2380]\ttraining's auc: 0.915428\ttraining's binary_logloss: 0.184978\n",
      "[2381]\ttraining's auc: 0.915436\ttraining's binary_logloss: 0.184974\n",
      "[2382]\ttraining's auc: 0.915472\ttraining's binary_logloss: 0.184954\n",
      "[2383]\ttraining's auc: 0.915509\ttraining's binary_logloss: 0.184934\n",
      "[2384]\ttraining's auc: 0.915523\ttraining's binary_logloss: 0.184928\n",
      "[2385]\ttraining's auc: 0.915553\ttraining's binary_logloss: 0.184909\n",
      "[2386]\ttraining's auc: 0.915586\ttraining's binary_logloss: 0.184891\n",
      "[2387]\ttraining's auc: 0.915621\ttraining's binary_logloss: 0.184873\n",
      "[2388]\ttraining's auc: 0.915648\ttraining's binary_logloss: 0.184856\n",
      "[2389]\ttraining's auc: 0.915694\ttraining's binary_logloss: 0.184833\n",
      "[2390]\ttraining's auc: 0.915726\ttraining's binary_logloss: 0.184814\n",
      "[2391]\ttraining's auc: 0.915763\ttraining's binary_logloss: 0.184795\n",
      "[2392]\ttraining's auc: 0.915798\ttraining's binary_logloss: 0.184773\n",
      "[2393]\ttraining's auc: 0.915846\ttraining's binary_logloss: 0.184752\n",
      "[2394]\ttraining's auc: 0.915879\ttraining's binary_logloss: 0.184733\n",
      "[2395]\ttraining's auc: 0.91592\ttraining's binary_logloss: 0.184711\n",
      "[2396]\ttraining's auc: 0.915961\ttraining's binary_logloss: 0.18469\n",
      "[2397]\ttraining's auc: 0.915992\ttraining's binary_logloss: 0.18467\n",
      "[2398]\ttraining's auc: 0.916028\ttraining's binary_logloss: 0.184652\n",
      "[2399]\ttraining's auc: 0.916064\ttraining's binary_logloss: 0.184632\n",
      "[2400]\ttraining's auc: 0.916105\ttraining's binary_logloss: 0.184613\n",
      "[2401]\ttraining's auc: 0.916151\ttraining's binary_logloss: 0.18459\n",
      "[2402]\ttraining's auc: 0.916177\ttraining's binary_logloss: 0.18458\n",
      "[2403]\ttraining's auc: 0.916223\ttraining's binary_logloss: 0.18456\n",
      "[2404]\ttraining's auc: 0.916255\ttraining's binary_logloss: 0.184538\n",
      "[2405]\ttraining's auc: 0.916293\ttraining's binary_logloss: 0.18452\n",
      "[2406]\ttraining's auc: 0.916337\ttraining's binary_logloss: 0.184501\n",
      "[2407]\ttraining's auc: 0.916373\ttraining's binary_logloss: 0.184483\n",
      "[2408]\ttraining's auc: 0.916411\ttraining's binary_logloss: 0.184462\n",
      "[2409]\ttraining's auc: 0.916463\ttraining's binary_logloss: 0.184441\n",
      "[2410]\ttraining's auc: 0.916501\ttraining's binary_logloss: 0.184422\n",
      "[2411]\ttraining's auc: 0.91654\ttraining's binary_logloss: 0.184403\n",
      "[2412]\ttraining's auc: 0.916548\ttraining's binary_logloss: 0.184398\n",
      "[2413]\ttraining's auc: 0.916591\ttraining's binary_logloss: 0.184379\n",
      "[2414]\ttraining's auc: 0.916622\ttraining's binary_logloss: 0.18436\n",
      "[2415]\ttraining's auc: 0.916671\ttraining's binary_logloss: 0.184339\n",
      "[2416]\ttraining's auc: 0.9167\ttraining's binary_logloss: 0.184322\n",
      "[2417]\ttraining's auc: 0.916705\ttraining's binary_logloss: 0.184319\n",
      "[2418]\ttraining's auc: 0.916728\ttraining's binary_logloss: 0.184307\n",
      "[2419]\ttraining's auc: 0.916771\ttraining's binary_logloss: 0.184286\n",
      "[2420]\ttraining's auc: 0.916808\ttraining's binary_logloss: 0.184265\n",
      "[2421]\ttraining's auc: 0.916834\ttraining's binary_logloss: 0.184247\n",
      "[2422]\ttraining's auc: 0.916866\ttraining's binary_logloss: 0.184231\n",
      "[2423]\ttraining's auc: 0.91691\ttraining's binary_logloss: 0.184206\n",
      "[2424]\ttraining's auc: 0.916952\ttraining's binary_logloss: 0.184187\n",
      "[2425]\ttraining's auc: 0.916996\ttraining's binary_logloss: 0.184164\n",
      "[2426]\ttraining's auc: 0.917026\ttraining's binary_logloss: 0.184146\n",
      "[2427]\ttraining's auc: 0.917064\ttraining's binary_logloss: 0.184126\n",
      "[2428]\ttraining's auc: 0.917102\ttraining's binary_logloss: 0.184107\n",
      "[2429]\ttraining's auc: 0.91713\ttraining's binary_logloss: 0.184089\n",
      "[2430]\ttraining's auc: 0.917167\ttraining's binary_logloss: 0.184071\n",
      "[2431]\ttraining's auc: 0.917214\ttraining's binary_logloss: 0.184049\n",
      "[2432]\ttraining's auc: 0.917244\ttraining's binary_logloss: 0.18403\n",
      "[2433]\ttraining's auc: 0.917283\ttraining's binary_logloss: 0.184013\n",
      "[2434]\ttraining's auc: 0.917314\ttraining's binary_logloss: 0.183997\n",
      "[2435]\ttraining's auc: 0.917349\ttraining's binary_logloss: 0.183977\n",
      "[2436]\ttraining's auc: 0.917381\ttraining's binary_logloss: 0.183962\n",
      "[2437]\ttraining's auc: 0.917404\ttraining's binary_logloss: 0.183944\n",
      "[2438]\ttraining's auc: 0.917444\ttraining's binary_logloss: 0.183922\n",
      "[2439]\ttraining's auc: 0.917459\ttraining's binary_logloss: 0.183909\n",
      "[2440]\ttraining's auc: 0.917503\ttraining's binary_logloss: 0.183891\n",
      "[2441]\ttraining's auc: 0.917533\ttraining's binary_logloss: 0.183874\n",
      "[2442]\ttraining's auc: 0.917567\ttraining's binary_logloss: 0.183855\n",
      "[2443]\ttraining's auc: 0.917604\ttraining's binary_logloss: 0.183838\n",
      "[2444]\ttraining's auc: 0.917638\ttraining's binary_logloss: 0.183825\n",
      "[2445]\ttraining's auc: 0.917668\ttraining's binary_logloss: 0.183808\n",
      "[2446]\ttraining's auc: 0.9177\ttraining's binary_logloss: 0.183789\n",
      "[2447]\ttraining's auc: 0.917728\ttraining's binary_logloss: 0.183772\n",
      "[2448]\ttraining's auc: 0.91774\ttraining's binary_logloss: 0.183763\n",
      "[2449]\ttraining's auc: 0.917754\ttraining's binary_logloss: 0.183754\n",
      "[2450]\ttraining's auc: 0.917757\ttraining's binary_logloss: 0.183752\n",
      "[2451]\ttraining's auc: 0.917783\ttraining's binary_logloss: 0.183734\n",
      "[2452]\ttraining's auc: 0.917826\ttraining's binary_logloss: 0.183714\n",
      "[2453]\ttraining's auc: 0.917864\ttraining's binary_logloss: 0.183692\n",
      "[2454]\ttraining's auc: 0.917904\ttraining's binary_logloss: 0.183672\n",
      "[2455]\ttraining's auc: 0.917929\ttraining's binary_logloss: 0.183657\n",
      "[2456]\ttraining's auc: 0.917968\ttraining's binary_logloss: 0.183636\n",
      "[2457]\ttraining's auc: 0.918019\ttraining's binary_logloss: 0.183614\n",
      "[2458]\ttraining's auc: 0.91805\ttraining's binary_logloss: 0.183599\n",
      "[2459]\ttraining's auc: 0.918075\ttraining's binary_logloss: 0.183581\n",
      "[2460]\ttraining's auc: 0.918101\ttraining's binary_logloss: 0.183565\n",
      "[2461]\ttraining's auc: 0.91814\ttraining's binary_logloss: 0.183546\n",
      "[2462]\ttraining's auc: 0.918163\ttraining's binary_logloss: 0.183531\n",
      "[2463]\ttraining's auc: 0.918206\ttraining's binary_logloss: 0.183512\n",
      "[2464]\ttraining's auc: 0.918239\ttraining's binary_logloss: 0.183492\n",
      "[2465]\ttraining's auc: 0.918277\ttraining's binary_logloss: 0.183472\n",
      "[2466]\ttraining's auc: 0.918314\ttraining's binary_logloss: 0.183453\n",
      "[2467]\ttraining's auc: 0.918347\ttraining's binary_logloss: 0.183437\n",
      "[2468]\ttraining's auc: 0.918372\ttraining's binary_logloss: 0.183416\n",
      "[2469]\ttraining's auc: 0.918407\ttraining's binary_logloss: 0.183398\n",
      "[2470]\ttraining's auc: 0.918426\ttraining's binary_logloss: 0.183386\n",
      "[2471]\ttraining's auc: 0.918474\ttraining's binary_logloss: 0.183365\n",
      "[2472]\ttraining's auc: 0.918513\ttraining's binary_logloss: 0.183346\n",
      "[2473]\ttraining's auc: 0.918558\ttraining's binary_logloss: 0.183323\n",
      "[2474]\ttraining's auc: 0.918577\ttraining's binary_logloss: 0.18331\n",
      "[2475]\ttraining's auc: 0.918605\ttraining's binary_logloss: 0.183294\n",
      "[2476]\ttraining's auc: 0.918637\ttraining's binary_logloss: 0.183276\n",
      "[2477]\ttraining's auc: 0.918664\ttraining's binary_logloss: 0.183264\n",
      "[2478]\ttraining's auc: 0.918688\ttraining's binary_logloss: 0.183244\n",
      "[2479]\ttraining's auc: 0.918716\ttraining's binary_logloss: 0.183228\n",
      "[2480]\ttraining's auc: 0.918752\ttraining's binary_logloss: 0.183209\n",
      "[2481]\ttraining's auc: 0.918787\ttraining's binary_logloss: 0.183194\n",
      "[2482]\ttraining's auc: 0.918802\ttraining's binary_logloss: 0.183187\n",
      "[2483]\ttraining's auc: 0.918845\ttraining's binary_logloss: 0.183167\n",
      "[2484]\ttraining's auc: 0.918875\ttraining's binary_logloss: 0.183149\n",
      "[2485]\ttraining's auc: 0.918895\ttraining's binary_logloss: 0.183136\n",
      "[2486]\ttraining's auc: 0.918913\ttraining's binary_logloss: 0.183128\n",
      "[2487]\ttraining's auc: 0.918943\ttraining's binary_logloss: 0.183109\n",
      "[2488]\ttraining's auc: 0.918984\ttraining's binary_logloss: 0.183088\n",
      "[2489]\ttraining's auc: 0.919029\ttraining's binary_logloss: 0.183065\n",
      "[2490]\ttraining's auc: 0.919069\ttraining's binary_logloss: 0.183046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2491]\ttraining's auc: 0.919102\ttraining's binary_logloss: 0.183028\n",
      "[2492]\ttraining's auc: 0.919134\ttraining's binary_logloss: 0.18301\n",
      "[2493]\ttraining's auc: 0.919153\ttraining's binary_logloss: 0.182997\n",
      "[2494]\ttraining's auc: 0.91919\ttraining's binary_logloss: 0.182978\n",
      "[2495]\ttraining's auc: 0.919216\ttraining's binary_logloss: 0.18296\n",
      "[2496]\ttraining's auc: 0.919256\ttraining's binary_logloss: 0.182939\n",
      "[2497]\ttraining's auc: 0.9193\ttraining's binary_logloss: 0.18292\n",
      "[2498]\ttraining's auc: 0.919318\ttraining's binary_logloss: 0.182908\n",
      "[2499]\ttraining's auc: 0.919364\ttraining's binary_logloss: 0.182887\n",
      "[2500]\ttraining's auc: 0.919401\ttraining's binary_logloss: 0.182866\n",
      "[2501]\ttraining's auc: 0.919432\ttraining's binary_logloss: 0.182848\n",
      "[2502]\ttraining's auc: 0.919478\ttraining's binary_logloss: 0.182825\n",
      "[2503]\ttraining's auc: 0.919515\ttraining's binary_logloss: 0.182804\n",
      "[2504]\ttraining's auc: 0.919548\ttraining's binary_logloss: 0.182783\n",
      "[2505]\ttraining's auc: 0.919598\ttraining's binary_logloss: 0.182761\n",
      "[2506]\ttraining's auc: 0.919635\ttraining's binary_logloss: 0.182741\n",
      "[2507]\ttraining's auc: 0.91967\ttraining's binary_logloss: 0.182723\n",
      "[2508]\ttraining's auc: 0.919685\ttraining's binary_logloss: 0.182714\n",
      "[2509]\ttraining's auc: 0.919704\ttraining's binary_logloss: 0.182701\n",
      "[2510]\ttraining's auc: 0.919733\ttraining's binary_logloss: 0.182683\n",
      "[2511]\ttraining's auc: 0.919769\ttraining's binary_logloss: 0.182662\n",
      "[2512]\ttraining's auc: 0.919807\ttraining's binary_logloss: 0.182641\n",
      "[2513]\ttraining's auc: 0.919832\ttraining's binary_logloss: 0.182626\n",
      "[2514]\ttraining's auc: 0.919853\ttraining's binary_logloss: 0.182614\n",
      "[2515]\ttraining's auc: 0.919893\ttraining's binary_logloss: 0.182594\n",
      "[2516]\ttraining's auc: 0.919923\ttraining's binary_logloss: 0.182576\n",
      "[2517]\ttraining's auc: 0.919948\ttraining's binary_logloss: 0.182557\n",
      "[2518]\ttraining's auc: 0.919991\ttraining's binary_logloss: 0.182534\n",
      "[2519]\ttraining's auc: 0.92\ttraining's binary_logloss: 0.182527\n",
      "[2520]\ttraining's auc: 0.920041\ttraining's binary_logloss: 0.182506\n",
      "[2521]\ttraining's auc: 0.920075\ttraining's binary_logloss: 0.182487\n",
      "[2522]\ttraining's auc: 0.920095\ttraining's binary_logloss: 0.18247\n",
      "[2523]\ttraining's auc: 0.92012\ttraining's binary_logloss: 0.182453\n",
      "[2524]\ttraining's auc: 0.920154\ttraining's binary_logloss: 0.182433\n",
      "[2525]\ttraining's auc: 0.920186\ttraining's binary_logloss: 0.182415\n",
      "[2526]\ttraining's auc: 0.920208\ttraining's binary_logloss: 0.182403\n",
      "[2527]\ttraining's auc: 0.920237\ttraining's binary_logloss: 0.182385\n",
      "[2528]\ttraining's auc: 0.920289\ttraining's binary_logloss: 0.182367\n",
      "[2529]\ttraining's auc: 0.92032\ttraining's binary_logloss: 0.182349\n",
      "[2530]\ttraining's auc: 0.920338\ttraining's binary_logloss: 0.182336\n",
      "[2531]\ttraining's auc: 0.920354\ttraining's binary_logloss: 0.182325\n",
      "[2532]\ttraining's auc: 0.920392\ttraining's binary_logloss: 0.182307\n",
      "[2533]\ttraining's auc: 0.920427\ttraining's binary_logloss: 0.182287\n",
      "[2534]\ttraining's auc: 0.920459\ttraining's binary_logloss: 0.18227\n",
      "[2535]\ttraining's auc: 0.920493\ttraining's binary_logloss: 0.182252\n",
      "[2536]\ttraining's auc: 0.920534\ttraining's binary_logloss: 0.182234\n",
      "[2537]\ttraining's auc: 0.920574\ttraining's binary_logloss: 0.182216\n",
      "[2538]\ttraining's auc: 0.920597\ttraining's binary_logloss: 0.1822\n",
      "[2539]\ttraining's auc: 0.920632\ttraining's binary_logloss: 0.182179\n",
      "[2540]\ttraining's auc: 0.92069\ttraining's binary_logloss: 0.182156\n",
      "[2541]\ttraining's auc: 0.920722\ttraining's binary_logloss: 0.182135\n",
      "[2542]\ttraining's auc: 0.920747\ttraining's binary_logloss: 0.182122\n",
      "[2543]\ttraining's auc: 0.920782\ttraining's binary_logloss: 0.182102\n",
      "[2544]\ttraining's auc: 0.920821\ttraining's binary_logloss: 0.182081\n",
      "[2545]\ttraining's auc: 0.920862\ttraining's binary_logloss: 0.182064\n",
      "[2546]\ttraining's auc: 0.920882\ttraining's binary_logloss: 0.182053\n",
      "[2547]\ttraining's auc: 0.920917\ttraining's binary_logloss: 0.182035\n",
      "[2548]\ttraining's auc: 0.920951\ttraining's binary_logloss: 0.182018\n",
      "[2549]\ttraining's auc: 0.920983\ttraining's binary_logloss: 0.181999\n",
      "[2550]\ttraining's auc: 0.921011\ttraining's binary_logloss: 0.181982\n",
      "[2551]\ttraining's auc: 0.921049\ttraining's binary_logloss: 0.181964\n",
      "[2552]\ttraining's auc: 0.921077\ttraining's binary_logloss: 0.181946\n",
      "[2553]\ttraining's auc: 0.921112\ttraining's binary_logloss: 0.181925\n",
      "[2554]\ttraining's auc: 0.921141\ttraining's binary_logloss: 0.181908\n",
      "[2555]\ttraining's auc: 0.921153\ttraining's binary_logloss: 0.181901\n",
      "[2556]\ttraining's auc: 0.921179\ttraining's binary_logloss: 0.181888\n",
      "[2557]\ttraining's auc: 0.921214\ttraining's binary_logloss: 0.181868\n",
      "[2558]\ttraining's auc: 0.921249\ttraining's binary_logloss: 0.181849\n",
      "[2559]\ttraining's auc: 0.92128\ttraining's binary_logloss: 0.181834\n",
      "[2560]\ttraining's auc: 0.921315\ttraining's binary_logloss: 0.181814\n",
      "[2561]\ttraining's auc: 0.921325\ttraining's binary_logloss: 0.181808\n",
      "[2562]\ttraining's auc: 0.921336\ttraining's binary_logloss: 0.181803\n",
      "[2563]\ttraining's auc: 0.921375\ttraining's binary_logloss: 0.181786\n",
      "[2564]\ttraining's auc: 0.921391\ttraining's binary_logloss: 0.181777\n",
      "[2565]\ttraining's auc: 0.921419\ttraining's binary_logloss: 0.181759\n",
      "[2566]\ttraining's auc: 0.921432\ttraining's binary_logloss: 0.181751\n",
      "[2567]\ttraining's auc: 0.921443\ttraining's binary_logloss: 0.181745\n",
      "[2568]\ttraining's auc: 0.921475\ttraining's binary_logloss: 0.181727\n",
      "[2569]\ttraining's auc: 0.921503\ttraining's binary_logloss: 0.181714\n",
      "[2570]\ttraining's auc: 0.921527\ttraining's binary_logloss: 0.181696\n",
      "[2571]\ttraining's auc: 0.921561\ttraining's binary_logloss: 0.181677\n",
      "[2572]\ttraining's auc: 0.921599\ttraining's binary_logloss: 0.181661\n",
      "[2573]\ttraining's auc: 0.921627\ttraining's binary_logloss: 0.181641\n",
      "[2574]\ttraining's auc: 0.921667\ttraining's binary_logloss: 0.181627\n",
      "[2575]\ttraining's auc: 0.921703\ttraining's binary_logloss: 0.181609\n",
      "[2576]\ttraining's auc: 0.921761\ttraining's binary_logloss: 0.181586\n",
      "[2577]\ttraining's auc: 0.921787\ttraining's binary_logloss: 0.181573\n",
      "[2578]\ttraining's auc: 0.921823\ttraining's binary_logloss: 0.181554\n",
      "[2579]\ttraining's auc: 0.921862\ttraining's binary_logloss: 0.181533\n",
      "[2580]\ttraining's auc: 0.921871\ttraining's binary_logloss: 0.181525\n",
      "[2581]\ttraining's auc: 0.921894\ttraining's binary_logloss: 0.181508\n",
      "[2582]\ttraining's auc: 0.921928\ttraining's binary_logloss: 0.181492\n",
      "[2583]\ttraining's auc: 0.92197\ttraining's binary_logloss: 0.181473\n",
      "[2584]\ttraining's auc: 0.922001\ttraining's binary_logloss: 0.181453\n",
      "[2585]\ttraining's auc: 0.92204\ttraining's binary_logloss: 0.181435\n",
      "[2586]\ttraining's auc: 0.922062\ttraining's binary_logloss: 0.181418\n",
      "[2587]\ttraining's auc: 0.922114\ttraining's binary_logloss: 0.181396\n",
      "[2588]\ttraining's auc: 0.922148\ttraining's binary_logloss: 0.181378\n",
      "[2589]\ttraining's auc: 0.922178\ttraining's binary_logloss: 0.181361\n",
      "[2590]\ttraining's auc: 0.922205\ttraining's binary_logloss: 0.181343\n",
      "[2591]\ttraining's auc: 0.922226\ttraining's binary_logloss: 0.181325\n",
      "[2592]\ttraining's auc: 0.922259\ttraining's binary_logloss: 0.181308\n",
      "[2593]\ttraining's auc: 0.922283\ttraining's binary_logloss: 0.181288\n",
      "[2594]\ttraining's auc: 0.922304\ttraining's binary_logloss: 0.181275\n",
      "[2595]\ttraining's auc: 0.922341\ttraining's binary_logloss: 0.181255\n",
      "[2596]\ttraining's auc: 0.922371\ttraining's binary_logloss: 0.181238\n",
      "[2597]\ttraining's auc: 0.92241\ttraining's binary_logloss: 0.181216\n",
      "[2598]\ttraining's auc: 0.922416\ttraining's binary_logloss: 0.181211\n",
      "[2599]\ttraining's auc: 0.922434\ttraining's binary_logloss: 0.181197\n",
      "[2600]\ttraining's auc: 0.922464\ttraining's binary_logloss: 0.181181\n",
      "[2601]\ttraining's auc: 0.92248\ttraining's binary_logloss: 0.181173\n",
      "[2602]\ttraining's auc: 0.922503\ttraining's binary_logloss: 0.181157\n",
      "[2603]\ttraining's auc: 0.92255\ttraining's binary_logloss: 0.181138\n",
      "[2604]\ttraining's auc: 0.922597\ttraining's binary_logloss: 0.181115\n",
      "[2605]\ttraining's auc: 0.922624\ttraining's binary_logloss: 0.181099\n",
      "[2606]\ttraining's auc: 0.922651\ttraining's binary_logloss: 0.181081\n",
      "[2607]\ttraining's auc: 0.922661\ttraining's binary_logloss: 0.181075\n",
      "[2608]\ttraining's auc: 0.922686\ttraining's binary_logloss: 0.181061\n",
      "[2609]\ttraining's auc: 0.922711\ttraining's binary_logloss: 0.181045\n",
      "[2610]\ttraining's auc: 0.922759\ttraining's binary_logloss: 0.181027\n",
      "[2611]\ttraining's auc: 0.92279\ttraining's binary_logloss: 0.181009\n",
      "[2612]\ttraining's auc: 0.922824\ttraining's binary_logloss: 0.180993\n",
      "[2613]\ttraining's auc: 0.922843\ttraining's binary_logloss: 0.180981\n",
      "[2614]\ttraining's auc: 0.922869\ttraining's binary_logloss: 0.180966\n",
      "[2615]\ttraining's auc: 0.922895\ttraining's binary_logloss: 0.180949\n",
      "[2616]\ttraining's auc: 0.922909\ttraining's binary_logloss: 0.180937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2617]\ttraining's auc: 0.922931\ttraining's binary_logloss: 0.180926\n",
      "[2618]\ttraining's auc: 0.922961\ttraining's binary_logloss: 0.180907\n",
      "[2619]\ttraining's auc: 0.922981\ttraining's binary_logloss: 0.180895\n",
      "[2620]\ttraining's auc: 0.923012\ttraining's binary_logloss: 0.180878\n",
      "[2621]\ttraining's auc: 0.923046\ttraining's binary_logloss: 0.180856\n",
      "[2622]\ttraining's auc: 0.923066\ttraining's binary_logloss: 0.180845\n",
      "[2623]\ttraining's auc: 0.923098\ttraining's binary_logloss: 0.180828\n",
      "[2624]\ttraining's auc: 0.923106\ttraining's binary_logloss: 0.180824\n",
      "[2625]\ttraining's auc: 0.923137\ttraining's binary_logloss: 0.180804\n",
      "[2626]\ttraining's auc: 0.923166\ttraining's binary_logloss: 0.180786\n",
      "[2627]\ttraining's auc: 0.92319\ttraining's binary_logloss: 0.180771\n",
      "[2628]\ttraining's auc: 0.923216\ttraining's binary_logloss: 0.18076\n",
      "[2629]\ttraining's auc: 0.923253\ttraining's binary_logloss: 0.180741\n",
      "[2630]\ttraining's auc: 0.923284\ttraining's binary_logloss: 0.180723\n",
      "[2631]\ttraining's auc: 0.923311\ttraining's binary_logloss: 0.180705\n",
      "[2632]\ttraining's auc: 0.923322\ttraining's binary_logloss: 0.180695\n",
      "[2633]\ttraining's auc: 0.923351\ttraining's binary_logloss: 0.180675\n",
      "[2634]\ttraining's auc: 0.923358\ttraining's binary_logloss: 0.180668\n",
      "[2635]\ttraining's auc: 0.923395\ttraining's binary_logloss: 0.180651\n",
      "[2636]\ttraining's auc: 0.92342\ttraining's binary_logloss: 0.180631\n",
      "[2637]\ttraining's auc: 0.923453\ttraining's binary_logloss: 0.180616\n",
      "[2638]\ttraining's auc: 0.923484\ttraining's binary_logloss: 0.180597\n",
      "[2639]\ttraining's auc: 0.92351\ttraining's binary_logloss: 0.180577\n",
      "[2640]\ttraining's auc: 0.923548\ttraining's binary_logloss: 0.180557\n",
      "[2641]\ttraining's auc: 0.923596\ttraining's binary_logloss: 0.180536\n",
      "[2642]\ttraining's auc: 0.923601\ttraining's binary_logloss: 0.180531\n",
      "[2643]\ttraining's auc: 0.923622\ttraining's binary_logloss: 0.180517\n",
      "[2644]\ttraining's auc: 0.923632\ttraining's binary_logloss: 0.180513\n",
      "[2645]\ttraining's auc: 0.923646\ttraining's binary_logloss: 0.180504\n",
      "[2646]\ttraining's auc: 0.923678\ttraining's binary_logloss: 0.180488\n",
      "[2647]\ttraining's auc: 0.923728\ttraining's binary_logloss: 0.180465\n",
      "[2648]\ttraining's auc: 0.923743\ttraining's binary_logloss: 0.180454\n",
      "[2649]\ttraining's auc: 0.923776\ttraining's binary_logloss: 0.180437\n",
      "[2650]\ttraining's auc: 0.923821\ttraining's binary_logloss: 0.180416\n",
      "[2651]\ttraining's auc: 0.923857\ttraining's binary_logloss: 0.180399\n",
      "[2652]\ttraining's auc: 0.923895\ttraining's binary_logloss: 0.180379\n",
      "[2653]\ttraining's auc: 0.923932\ttraining's binary_logloss: 0.180359\n",
      "[2654]\ttraining's auc: 0.923962\ttraining's binary_logloss: 0.18034\n",
      "[2655]\ttraining's auc: 0.924002\ttraining's binary_logloss: 0.180321\n",
      "[2656]\ttraining's auc: 0.924034\ttraining's binary_logloss: 0.1803\n",
      "[2657]\ttraining's auc: 0.924051\ttraining's binary_logloss: 0.18029\n",
      "[2658]\ttraining's auc: 0.924072\ttraining's binary_logloss: 0.18028\n",
      "[2659]\ttraining's auc: 0.924103\ttraining's binary_logloss: 0.180262\n",
      "[2660]\ttraining's auc: 0.924136\ttraining's binary_logloss: 0.180244\n",
      "[2661]\ttraining's auc: 0.924162\ttraining's binary_logloss: 0.180226\n",
      "[2662]\ttraining's auc: 0.924196\ttraining's binary_logloss: 0.180207\n",
      "[2663]\ttraining's auc: 0.924198\ttraining's binary_logloss: 0.180204\n",
      "[2664]\ttraining's auc: 0.924241\ttraining's binary_logloss: 0.180182\n",
      "[2665]\ttraining's auc: 0.924275\ttraining's binary_logloss: 0.180165\n",
      "[2666]\ttraining's auc: 0.924303\ttraining's binary_logloss: 0.180146\n",
      "[2667]\ttraining's auc: 0.924344\ttraining's binary_logloss: 0.180127\n",
      "[2668]\ttraining's auc: 0.924381\ttraining's binary_logloss: 0.180107\n",
      "[2669]\ttraining's auc: 0.924423\ttraining's binary_logloss: 0.180086\n",
      "[2670]\ttraining's auc: 0.924465\ttraining's binary_logloss: 0.180067\n",
      "[2671]\ttraining's auc: 0.924477\ttraining's binary_logloss: 0.180059\n",
      "[2672]\ttraining's auc: 0.924504\ttraining's binary_logloss: 0.180039\n",
      "[2673]\ttraining's auc: 0.924527\ttraining's binary_logloss: 0.180019\n",
      "[2674]\ttraining's auc: 0.924572\ttraining's binary_logloss: 0.179999\n",
      "[2675]\ttraining's auc: 0.924599\ttraining's binary_logloss: 0.179982\n",
      "[2676]\ttraining's auc: 0.924633\ttraining's binary_logloss: 0.179966\n",
      "[2677]\ttraining's auc: 0.924645\ttraining's binary_logloss: 0.179959\n",
      "[2678]\ttraining's auc: 0.924668\ttraining's binary_logloss: 0.179943\n",
      "[2679]\ttraining's auc: 0.924696\ttraining's binary_logloss: 0.179927\n",
      "[2680]\ttraining's auc: 0.924721\ttraining's binary_logloss: 0.179908\n",
      "[2681]\ttraining's auc: 0.924735\ttraining's binary_logloss: 0.179897\n",
      "[2682]\ttraining's auc: 0.924761\ttraining's binary_logloss: 0.179882\n",
      "[2683]\ttraining's auc: 0.924773\ttraining's binary_logloss: 0.179875\n",
      "[2684]\ttraining's auc: 0.924813\ttraining's binary_logloss: 0.179856\n",
      "[2685]\ttraining's auc: 0.92485\ttraining's binary_logloss: 0.17984\n",
      "[2686]\ttraining's auc: 0.924884\ttraining's binary_logloss: 0.179819\n",
      "[2687]\ttraining's auc: 0.924915\ttraining's binary_logloss: 0.1798\n",
      "[2688]\ttraining's auc: 0.924945\ttraining's binary_logloss: 0.179783\n",
      "[2689]\ttraining's auc: 0.924973\ttraining's binary_logloss: 0.179765\n",
      "[2690]\ttraining's auc: 0.925004\ttraining's binary_logloss: 0.179745\n",
      "[2691]\ttraining's auc: 0.925048\ttraining's binary_logloss: 0.179723\n",
      "[2692]\ttraining's auc: 0.925086\ttraining's binary_logloss: 0.179704\n",
      "[2693]\ttraining's auc: 0.925099\ttraining's binary_logloss: 0.179697\n",
      "[2694]\ttraining's auc: 0.925127\ttraining's binary_logloss: 0.179679\n",
      "[2695]\ttraining's auc: 0.925153\ttraining's binary_logloss: 0.179659\n",
      "[2696]\ttraining's auc: 0.925185\ttraining's binary_logloss: 0.179641\n",
      "[2697]\ttraining's auc: 0.925217\ttraining's binary_logloss: 0.179622\n",
      "[2698]\ttraining's auc: 0.92525\ttraining's binary_logloss: 0.179604\n",
      "[2699]\ttraining's auc: 0.925277\ttraining's binary_logloss: 0.179585\n",
      "[2700]\ttraining's auc: 0.925297\ttraining's binary_logloss: 0.179568\n",
      "[2701]\ttraining's auc: 0.92533\ttraining's binary_logloss: 0.179549\n",
      "[2702]\ttraining's auc: 0.925361\ttraining's binary_logloss: 0.179529\n",
      "[2703]\ttraining's auc: 0.925393\ttraining's binary_logloss: 0.17951\n",
      "[2704]\ttraining's auc: 0.925419\ttraining's binary_logloss: 0.179494\n",
      "[2705]\ttraining's auc: 0.925456\ttraining's binary_logloss: 0.179474\n",
      "[2706]\ttraining's auc: 0.925487\ttraining's binary_logloss: 0.179456\n",
      "[2707]\ttraining's auc: 0.925503\ttraining's binary_logloss: 0.179447\n",
      "[2708]\ttraining's auc: 0.925524\ttraining's binary_logloss: 0.179435\n",
      "[2709]\ttraining's auc: 0.925569\ttraining's binary_logloss: 0.179413\n",
      "[2710]\ttraining's auc: 0.925579\ttraining's binary_logloss: 0.179404\n",
      "[2711]\ttraining's auc: 0.925605\ttraining's binary_logloss: 0.179385\n",
      "[2712]\ttraining's auc: 0.925633\ttraining's binary_logloss: 0.179369\n",
      "[2713]\ttraining's auc: 0.925653\ttraining's binary_logloss: 0.179355\n",
      "[2714]\ttraining's auc: 0.925685\ttraining's binary_logloss: 0.179336\n",
      "[2715]\ttraining's auc: 0.925704\ttraining's binary_logloss: 0.179317\n",
      "[2716]\ttraining's auc: 0.925719\ttraining's binary_logloss: 0.179307\n",
      "[2717]\ttraining's auc: 0.925749\ttraining's binary_logloss: 0.179289\n",
      "[2718]\ttraining's auc: 0.925782\ttraining's binary_logloss: 0.179269\n",
      "[2719]\ttraining's auc: 0.925814\ttraining's binary_logloss: 0.179253\n",
      "[2720]\ttraining's auc: 0.925855\ttraining's binary_logloss: 0.179234\n",
      "[2721]\ttraining's auc: 0.925879\ttraining's binary_logloss: 0.179219\n",
      "[2722]\ttraining's auc: 0.925913\ttraining's binary_logloss: 0.179199\n",
      "[2723]\ttraining's auc: 0.925941\ttraining's binary_logloss: 0.17918\n",
      "[2724]\ttraining's auc: 0.925964\ttraining's binary_logloss: 0.179163\n",
      "[2725]\ttraining's auc: 0.925987\ttraining's binary_logloss: 0.179148\n",
      "[2726]\ttraining's auc: 0.926013\ttraining's binary_logloss: 0.179131\n",
      "[2727]\ttraining's auc: 0.92605\ttraining's binary_logloss: 0.179112\n",
      "[2728]\ttraining's auc: 0.92606\ttraining's binary_logloss: 0.179103\n",
      "[2729]\ttraining's auc: 0.926098\ttraining's binary_logloss: 0.179084\n",
      "[2730]\ttraining's auc: 0.926121\ttraining's binary_logloss: 0.17907\n",
      "[2731]\ttraining's auc: 0.926141\ttraining's binary_logloss: 0.179054\n",
      "[2732]\ttraining's auc: 0.926172\ttraining's binary_logloss: 0.179036\n",
      "[2733]\ttraining's auc: 0.926195\ttraining's binary_logloss: 0.179023\n",
      "[2734]\ttraining's auc: 0.926215\ttraining's binary_logloss: 0.179009\n",
      "[2735]\ttraining's auc: 0.926239\ttraining's binary_logloss: 0.178992\n",
      "[2736]\ttraining's auc: 0.926262\ttraining's binary_logloss: 0.178975\n",
      "[2737]\ttraining's auc: 0.926295\ttraining's binary_logloss: 0.178959\n",
      "[2738]\ttraining's auc: 0.92633\ttraining's binary_logloss: 0.17894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2739]\ttraining's auc: 0.926361\ttraining's binary_logloss: 0.178922\n",
      "[2740]\ttraining's auc: 0.92639\ttraining's binary_logloss: 0.178904\n",
      "[2741]\ttraining's auc: 0.92641\ttraining's binary_logloss: 0.178893\n",
      "[2742]\ttraining's auc: 0.926445\ttraining's binary_logloss: 0.178875\n",
      "[2743]\ttraining's auc: 0.926473\ttraining's binary_logloss: 0.178859\n",
      "[2744]\ttraining's auc: 0.926499\ttraining's binary_logloss: 0.178841\n",
      "[2745]\ttraining's auc: 0.926523\ttraining's binary_logloss: 0.178825\n",
      "[2746]\ttraining's auc: 0.92656\ttraining's binary_logloss: 0.178804\n",
      "[2747]\ttraining's auc: 0.926569\ttraining's binary_logloss: 0.178798\n",
      "[2748]\ttraining's auc: 0.926599\ttraining's binary_logloss: 0.17878\n",
      "[2749]\ttraining's auc: 0.92663\ttraining's binary_logloss: 0.178763\n",
      "[2750]\ttraining's auc: 0.926662\ttraining's binary_logloss: 0.178744\n",
      "[2751]\ttraining's auc: 0.926702\ttraining's binary_logloss: 0.178724\n",
      "[2752]\ttraining's auc: 0.926719\ttraining's binary_logloss: 0.178706\n",
      "[2753]\ttraining's auc: 0.926758\ttraining's binary_logloss: 0.178686\n",
      "[2754]\ttraining's auc: 0.926788\ttraining's binary_logloss: 0.178668\n",
      "[2755]\ttraining's auc: 0.926825\ttraining's binary_logloss: 0.178648\n",
      "[2756]\ttraining's auc: 0.926851\ttraining's binary_logloss: 0.178634\n",
      "[2757]\ttraining's auc: 0.926868\ttraining's binary_logloss: 0.178619\n",
      "[2758]\ttraining's auc: 0.926902\ttraining's binary_logloss: 0.178599\n",
      "[2759]\ttraining's auc: 0.926946\ttraining's binary_logloss: 0.178578\n",
      "[2760]\ttraining's auc: 0.926987\ttraining's binary_logloss: 0.178558\n",
      "[2761]\ttraining's auc: 0.927022\ttraining's binary_logloss: 0.178539\n",
      "[2762]\ttraining's auc: 0.927029\ttraining's binary_logloss: 0.178534\n",
      "[2763]\ttraining's auc: 0.927043\ttraining's binary_logloss: 0.178524\n",
      "[2764]\ttraining's auc: 0.92705\ttraining's binary_logloss: 0.178519\n",
      "[2765]\ttraining's auc: 0.927079\ttraining's binary_logloss: 0.178501\n",
      "[2766]\ttraining's auc: 0.927112\ttraining's binary_logloss: 0.178484\n",
      "[2767]\ttraining's auc: 0.927137\ttraining's binary_logloss: 0.178469\n",
      "[2768]\ttraining's auc: 0.92716\ttraining's binary_logloss: 0.178458\n",
      "[2769]\ttraining's auc: 0.927187\ttraining's binary_logloss: 0.178439\n",
      "[2770]\ttraining's auc: 0.927199\ttraining's binary_logloss: 0.178433\n",
      "[2771]\ttraining's auc: 0.927232\ttraining's binary_logloss: 0.178414\n",
      "[2772]\ttraining's auc: 0.927257\ttraining's binary_logloss: 0.178396\n",
      "[2773]\ttraining's auc: 0.927291\ttraining's binary_logloss: 0.178376\n",
      "[2774]\ttraining's auc: 0.927307\ttraining's binary_logloss: 0.178366\n",
      "[2775]\ttraining's auc: 0.927342\ttraining's binary_logloss: 0.178346\n",
      "[2776]\ttraining's auc: 0.927378\ttraining's binary_logloss: 0.178328\n",
      "[2777]\ttraining's auc: 0.927398\ttraining's binary_logloss: 0.178312\n",
      "[2778]\ttraining's auc: 0.927421\ttraining's binary_logloss: 0.178294\n",
      "[2779]\ttraining's auc: 0.92745\ttraining's binary_logloss: 0.178277\n",
      "[2780]\ttraining's auc: 0.927465\ttraining's binary_logloss: 0.178259\n",
      "[2781]\ttraining's auc: 0.927494\ttraining's binary_logloss: 0.178242\n",
      "[2782]\ttraining's auc: 0.927511\ttraining's binary_logloss: 0.17823\n",
      "[2783]\ttraining's auc: 0.927551\ttraining's binary_logloss: 0.178209\n",
      "[2784]\ttraining's auc: 0.927583\ttraining's binary_logloss: 0.178192\n",
      "[2785]\ttraining's auc: 0.927614\ttraining's binary_logloss: 0.178173\n",
      "[2786]\ttraining's auc: 0.927642\ttraining's binary_logloss: 0.178155\n",
      "[2787]\ttraining's auc: 0.927677\ttraining's binary_logloss: 0.178135\n",
      "[2788]\ttraining's auc: 0.927702\ttraining's binary_logloss: 0.17812\n",
      "[2789]\ttraining's auc: 0.927723\ttraining's binary_logloss: 0.178107\n",
      "[2790]\ttraining's auc: 0.927757\ttraining's binary_logloss: 0.17809\n",
      "[2791]\ttraining's auc: 0.927795\ttraining's binary_logloss: 0.178071\n",
      "[2792]\ttraining's auc: 0.927826\ttraining's binary_logloss: 0.178055\n",
      "[2793]\ttraining's auc: 0.927859\ttraining's binary_logloss: 0.178034\n",
      "[2794]\ttraining's auc: 0.927888\ttraining's binary_logloss: 0.178018\n",
      "[2795]\ttraining's auc: 0.927906\ttraining's binary_logloss: 0.178005\n",
      "[2796]\ttraining's auc: 0.927934\ttraining's binary_logloss: 0.17799\n",
      "[2797]\ttraining's auc: 0.927965\ttraining's binary_logloss: 0.177973\n",
      "[2798]\ttraining's auc: 0.927985\ttraining's binary_logloss: 0.177961\n",
      "[2799]\ttraining's auc: 0.927999\ttraining's binary_logloss: 0.177943\n",
      "[2800]\ttraining's auc: 0.928034\ttraining's binary_logloss: 0.177923\n",
      "[2801]\ttraining's auc: 0.928051\ttraining's binary_logloss: 0.177915\n",
      "[2802]\ttraining's auc: 0.928054\ttraining's binary_logloss: 0.177912\n",
      "[2803]\ttraining's auc: 0.928084\ttraining's binary_logloss: 0.177893\n",
      "[2804]\ttraining's auc: 0.92811\ttraining's binary_logloss: 0.177874\n",
      "[2805]\ttraining's auc: 0.928148\ttraining's binary_logloss: 0.177855\n",
      "[2806]\ttraining's auc: 0.928177\ttraining's binary_logloss: 0.177837\n",
      "[2807]\ttraining's auc: 0.92819\ttraining's binary_logloss: 0.177827\n",
      "[2808]\ttraining's auc: 0.928215\ttraining's binary_logloss: 0.177811\n",
      "[2809]\ttraining's auc: 0.928246\ttraining's binary_logloss: 0.177794\n",
      "[2810]\ttraining's auc: 0.928274\ttraining's binary_logloss: 0.177775\n",
      "[2811]\ttraining's auc: 0.928301\ttraining's binary_logloss: 0.177755\n",
      "[2812]\ttraining's auc: 0.928328\ttraining's binary_logloss: 0.177738\n",
      "[2813]\ttraining's auc: 0.928344\ttraining's binary_logloss: 0.177722\n",
      "[2814]\ttraining's auc: 0.928379\ttraining's binary_logloss: 0.177702\n",
      "[2815]\ttraining's auc: 0.928393\ttraining's binary_logloss: 0.177694\n",
      "[2816]\ttraining's auc: 0.928424\ttraining's binary_logloss: 0.177675\n",
      "[2817]\ttraining's auc: 0.928453\ttraining's binary_logloss: 0.177659\n",
      "[2818]\ttraining's auc: 0.928481\ttraining's binary_logloss: 0.177641\n",
      "[2819]\ttraining's auc: 0.928511\ttraining's binary_logloss: 0.177622\n",
      "[2820]\ttraining's auc: 0.928555\ttraining's binary_logloss: 0.1776\n",
      "[2821]\ttraining's auc: 0.928578\ttraining's binary_logloss: 0.177582\n",
      "[2822]\ttraining's auc: 0.928593\ttraining's binary_logloss: 0.177572\n",
      "[2823]\ttraining's auc: 0.928618\ttraining's binary_logloss: 0.177554\n",
      "[2824]\ttraining's auc: 0.928639\ttraining's binary_logloss: 0.177545\n",
      "[2825]\ttraining's auc: 0.928671\ttraining's binary_logloss: 0.177529\n",
      "[2826]\ttraining's auc: 0.928688\ttraining's binary_logloss: 0.17752\n",
      "[2827]\ttraining's auc: 0.928716\ttraining's binary_logloss: 0.177504\n",
      "[2828]\ttraining's auc: 0.928744\ttraining's binary_logloss: 0.177483\n",
      "[2829]\ttraining's auc: 0.928776\ttraining's binary_logloss: 0.177465\n",
      "[2830]\ttraining's auc: 0.928809\ttraining's binary_logloss: 0.177446\n",
      "[2831]\ttraining's auc: 0.928837\ttraining's binary_logloss: 0.177428\n",
      "[2832]\ttraining's auc: 0.928858\ttraining's binary_logloss: 0.177414\n",
      "[2833]\ttraining's auc: 0.928865\ttraining's binary_logloss: 0.17741\n",
      "[2834]\ttraining's auc: 0.928902\ttraining's binary_logloss: 0.177391\n",
      "[2835]\ttraining's auc: 0.928937\ttraining's binary_logloss: 0.177373\n",
      "[2836]\ttraining's auc: 0.928972\ttraining's binary_logloss: 0.177355\n",
      "[2837]\ttraining's auc: 0.929002\ttraining's binary_logloss: 0.177335\n",
      "[2838]\ttraining's auc: 0.92904\ttraining's binary_logloss: 0.177314\n",
      "[2839]\ttraining's auc: 0.929064\ttraining's binary_logloss: 0.177302\n",
      "[2840]\ttraining's auc: 0.929104\ttraining's binary_logloss: 0.177282\n",
      "[2841]\ttraining's auc: 0.929129\ttraining's binary_logloss: 0.177264\n",
      "[2842]\ttraining's auc: 0.929163\ttraining's binary_logloss: 0.177242\n",
      "[2843]\ttraining's auc: 0.929187\ttraining's binary_logloss: 0.177224\n",
      "[2844]\ttraining's auc: 0.929209\ttraining's binary_logloss: 0.177207\n",
      "[2845]\ttraining's auc: 0.929243\ttraining's binary_logloss: 0.177188\n",
      "[2846]\ttraining's auc: 0.929268\ttraining's binary_logloss: 0.177169\n",
      "[2847]\ttraining's auc: 0.9293\ttraining's binary_logloss: 0.177151\n",
      "[2848]\ttraining's auc: 0.929319\ttraining's binary_logloss: 0.177138\n",
      "[2849]\ttraining's auc: 0.929355\ttraining's binary_logloss: 0.177117\n",
      "[2850]\ttraining's auc: 0.929374\ttraining's binary_logloss: 0.177099\n",
      "[2851]\ttraining's auc: 0.929401\ttraining's binary_logloss: 0.177084\n",
      "[2852]\ttraining's auc: 0.929429\ttraining's binary_logloss: 0.177067\n",
      "[2853]\ttraining's auc: 0.929436\ttraining's binary_logloss: 0.177062\n",
      "[2854]\ttraining's auc: 0.929458\ttraining's binary_logloss: 0.177045\n",
      "[2855]\ttraining's auc: 0.929481\ttraining's binary_logloss: 0.177025\n",
      "[2856]\ttraining's auc: 0.929509\ttraining's binary_logloss: 0.177007\n",
      "[2857]\ttraining's auc: 0.92953\ttraining's binary_logloss: 0.17699\n",
      "[2858]\ttraining's auc: 0.929558\ttraining's binary_logloss: 0.176972\n",
      "[2859]\ttraining's auc: 0.929586\ttraining's binary_logloss: 0.176956\n",
      "[2860]\ttraining's auc: 0.929617\ttraining's binary_logloss: 0.176938\n",
      "[2861]\ttraining's auc: 0.929632\ttraining's binary_logloss: 0.176929\n",
      "[2862]\ttraining's auc: 0.929631\ttraining's binary_logloss: 0.17692\n",
      "[2863]\ttraining's auc: 0.929653\ttraining's binary_logloss: 0.176912\n",
      "[2864]\ttraining's auc: 0.92969\ttraining's binary_logloss: 0.176892\n",
      "[2865]\ttraining's auc: 0.929714\ttraining's binary_logloss: 0.176876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2866]\ttraining's auc: 0.929724\ttraining's binary_logloss: 0.176868\n",
      "[2867]\ttraining's auc: 0.929753\ttraining's binary_logloss: 0.176851\n",
      "[2868]\ttraining's auc: 0.929772\ttraining's binary_logloss: 0.176841\n",
      "[2869]\ttraining's auc: 0.929805\ttraining's binary_logloss: 0.176822\n",
      "[2870]\ttraining's auc: 0.929822\ttraining's binary_logloss: 0.176813\n",
      "[2871]\ttraining's auc: 0.929845\ttraining's binary_logloss: 0.176802\n",
      "[2872]\ttraining's auc: 0.929872\ttraining's binary_logloss: 0.176781\n",
      "[2873]\ttraining's auc: 0.929896\ttraining's binary_logloss: 0.176768\n",
      "[2874]\ttraining's auc: 0.929911\ttraining's binary_logloss: 0.176757\n",
      "[2875]\ttraining's auc: 0.929941\ttraining's binary_logloss: 0.176742\n",
      "[2876]\ttraining's auc: 0.929952\ttraining's binary_logloss: 0.176735\n",
      "[2877]\ttraining's auc: 0.929976\ttraining's binary_logloss: 0.176722\n",
      "[2878]\ttraining's auc: 0.930008\ttraining's binary_logloss: 0.176703\n",
      "[2879]\ttraining's auc: 0.93003\ttraining's binary_logloss: 0.176687\n",
      "[2880]\ttraining's auc: 0.930047\ttraining's binary_logloss: 0.176673\n",
      "[2881]\ttraining's auc: 0.930065\ttraining's binary_logloss: 0.176663\n",
      "[2882]\ttraining's auc: 0.930084\ttraining's binary_logloss: 0.176649\n",
      "[2883]\ttraining's auc: 0.930101\ttraining's binary_logloss: 0.176634\n",
      "[2884]\ttraining's auc: 0.930134\ttraining's binary_logloss: 0.176617\n",
      "[2885]\ttraining's auc: 0.930156\ttraining's binary_logloss: 0.1766\n",
      "[2886]\ttraining's auc: 0.930185\ttraining's binary_logloss: 0.176583\n",
      "[2887]\ttraining's auc: 0.930209\ttraining's binary_logloss: 0.176565\n",
      "[2888]\ttraining's auc: 0.930234\ttraining's binary_logloss: 0.176552\n",
      "[2889]\ttraining's auc: 0.930251\ttraining's binary_logloss: 0.176542\n",
      "[2890]\ttraining's auc: 0.930277\ttraining's binary_logloss: 0.176525\n",
      "[2891]\ttraining's auc: 0.930308\ttraining's binary_logloss: 0.176504\n",
      "[2892]\ttraining's auc: 0.930324\ttraining's binary_logloss: 0.17649\n",
      "[2893]\ttraining's auc: 0.930343\ttraining's binary_logloss: 0.176478\n",
      "[2894]\ttraining's auc: 0.930372\ttraining's binary_logloss: 0.176462\n",
      "[2895]\ttraining's auc: 0.930382\ttraining's binary_logloss: 0.176456\n",
      "[2896]\ttraining's auc: 0.930407\ttraining's binary_logloss: 0.17644\n",
      "[2897]\ttraining's auc: 0.930432\ttraining's binary_logloss: 0.176422\n",
      "[2898]\ttraining's auc: 0.930453\ttraining's binary_logloss: 0.176406\n",
      "[2899]\ttraining's auc: 0.93047\ttraining's binary_logloss: 0.176396\n",
      "[2900]\ttraining's auc: 0.930496\ttraining's binary_logloss: 0.176384\n",
      "[2901]\ttraining's auc: 0.930511\ttraining's binary_logloss: 0.176366\n",
      "[2902]\ttraining's auc: 0.930543\ttraining's binary_logloss: 0.176349\n",
      "[2903]\ttraining's auc: 0.93056\ttraining's binary_logloss: 0.176337\n",
      "[2904]\ttraining's auc: 0.930596\ttraining's binary_logloss: 0.176315\n",
      "[2905]\ttraining's auc: 0.930617\ttraining's binary_logloss: 0.1763\n",
      "[2906]\ttraining's auc: 0.930647\ttraining's binary_logloss: 0.17628\n",
      "[2907]\ttraining's auc: 0.93068\ttraining's binary_logloss: 0.176264\n",
      "[2908]\ttraining's auc: 0.930707\ttraining's binary_logloss: 0.176246\n",
      "[2909]\ttraining's auc: 0.930737\ttraining's binary_logloss: 0.176227\n",
      "[2910]\ttraining's auc: 0.930766\ttraining's binary_logloss: 0.176208\n",
      "[2911]\ttraining's auc: 0.930799\ttraining's binary_logloss: 0.176189\n",
      "[2912]\ttraining's auc: 0.930809\ttraining's binary_logloss: 0.176183\n",
      "[2913]\ttraining's auc: 0.930842\ttraining's binary_logloss: 0.176165\n",
      "[2914]\ttraining's auc: 0.930869\ttraining's binary_logloss: 0.176151\n",
      "[2915]\ttraining's auc: 0.930877\ttraining's binary_logloss: 0.176145\n",
      "[2916]\ttraining's auc: 0.930899\ttraining's binary_logloss: 0.176135\n",
      "[2917]\ttraining's auc: 0.930925\ttraining's binary_logloss: 0.176117\n",
      "[2918]\ttraining's auc: 0.930955\ttraining's binary_logloss: 0.176099\n",
      "[2919]\ttraining's auc: 0.930974\ttraining's binary_logloss: 0.176088\n",
      "[2920]\ttraining's auc: 0.930997\ttraining's binary_logloss: 0.176075\n",
      "[2921]\ttraining's auc: 0.931027\ttraining's binary_logloss: 0.176058\n",
      "[2922]\ttraining's auc: 0.931056\ttraining's binary_logloss: 0.17604\n",
      "[2923]\ttraining's auc: 0.931083\ttraining's binary_logloss: 0.17602\n",
      "[2924]\ttraining's auc: 0.931114\ttraining's binary_logloss: 0.176002\n",
      "[2925]\ttraining's auc: 0.931139\ttraining's binary_logloss: 0.175984\n",
      "[2926]\ttraining's auc: 0.93117\ttraining's binary_logloss: 0.175967\n",
      "[2927]\ttraining's auc: 0.931212\ttraining's binary_logloss: 0.175946\n",
      "[2928]\ttraining's auc: 0.93122\ttraining's binary_logloss: 0.175942\n",
      "[2929]\ttraining's auc: 0.931243\ttraining's binary_logloss: 0.175922\n",
      "[2930]\ttraining's auc: 0.931275\ttraining's binary_logloss: 0.175905\n",
      "[2931]\ttraining's auc: 0.931302\ttraining's binary_logloss: 0.175887\n",
      "[2932]\ttraining's auc: 0.931328\ttraining's binary_logloss: 0.175869\n",
      "[2933]\ttraining's auc: 0.931355\ttraining's binary_logloss: 0.17585\n",
      "[2934]\ttraining's auc: 0.931375\ttraining's binary_logloss: 0.175834\n",
      "[2935]\ttraining's auc: 0.931403\ttraining's binary_logloss: 0.175816\n",
      "[2936]\ttraining's auc: 0.931426\ttraining's binary_logloss: 0.175799\n",
      "[2937]\ttraining's auc: 0.931442\ttraining's binary_logloss: 0.175788\n",
      "[2938]\ttraining's auc: 0.93148\ttraining's binary_logloss: 0.175765\n",
      "[2939]\ttraining's auc: 0.931498\ttraining's binary_logloss: 0.175753\n",
      "[2940]\ttraining's auc: 0.931505\ttraining's binary_logloss: 0.175746\n",
      "[2941]\ttraining's auc: 0.93154\ttraining's binary_logloss: 0.175726\n",
      "[2942]\ttraining's auc: 0.931576\ttraining's binary_logloss: 0.175707\n",
      "[2943]\ttraining's auc: 0.931613\ttraining's binary_logloss: 0.175688\n",
      "[2944]\ttraining's auc: 0.931631\ttraining's binary_logloss: 0.17567\n",
      "[2945]\ttraining's auc: 0.931658\ttraining's binary_logloss: 0.175655\n",
      "[2946]\ttraining's auc: 0.931688\ttraining's binary_logloss: 0.175636\n",
      "[2947]\ttraining's auc: 0.931716\ttraining's binary_logloss: 0.17562\n",
      "[2948]\ttraining's auc: 0.931739\ttraining's binary_logloss: 0.175603\n",
      "[2949]\ttraining's auc: 0.931758\ttraining's binary_logloss: 0.175593\n",
      "[2950]\ttraining's auc: 0.931781\ttraining's binary_logloss: 0.175575\n",
      "[2951]\ttraining's auc: 0.931813\ttraining's binary_logloss: 0.175556\n",
      "[2952]\ttraining's auc: 0.931851\ttraining's binary_logloss: 0.175533\n",
      "[2953]\ttraining's auc: 0.931885\ttraining's binary_logloss: 0.175511\n",
      "[2954]\ttraining's auc: 0.931914\ttraining's binary_logloss: 0.175493\n",
      "[2955]\ttraining's auc: 0.931944\ttraining's binary_logloss: 0.175475\n",
      "[2956]\ttraining's auc: 0.931968\ttraining's binary_logloss: 0.175458\n",
      "[2957]\ttraining's auc: 0.93199\ttraining's binary_logloss: 0.175442\n",
      "[2958]\ttraining's auc: 0.932017\ttraining's binary_logloss: 0.175425\n",
      "[2959]\ttraining's auc: 0.932058\ttraining's binary_logloss: 0.175404\n",
      "[2960]\ttraining's auc: 0.93209\ttraining's binary_logloss: 0.175386\n",
      "[2961]\ttraining's auc: 0.932117\ttraining's binary_logloss: 0.175368\n",
      "[2962]\ttraining's auc: 0.932156\ttraining's binary_logloss: 0.175347\n",
      "[2963]\ttraining's auc: 0.932185\ttraining's binary_logloss: 0.175327\n",
      "[2964]\ttraining's auc: 0.932212\ttraining's binary_logloss: 0.175309\n",
      "[2965]\ttraining's auc: 0.932239\ttraining's binary_logloss: 0.175292\n",
      "[2966]\ttraining's auc: 0.932274\ttraining's binary_logloss: 0.175274\n",
      "[2967]\ttraining's auc: 0.932297\ttraining's binary_logloss: 0.175258\n",
      "[2968]\ttraining's auc: 0.932305\ttraining's binary_logloss: 0.175253\n",
      "[2969]\ttraining's auc: 0.932333\ttraining's binary_logloss: 0.175235\n",
      "[2970]\ttraining's auc: 0.932364\ttraining's binary_logloss: 0.175217\n",
      "[2971]\ttraining's auc: 0.932397\ttraining's binary_logloss: 0.175201\n",
      "[2972]\ttraining's auc: 0.932423\ttraining's binary_logloss: 0.175183\n",
      "[2973]\ttraining's auc: 0.932446\ttraining's binary_logloss: 0.175164\n",
      "[2974]\ttraining's auc: 0.932479\ttraining's binary_logloss: 0.175145\n",
      "[2975]\ttraining's auc: 0.932505\ttraining's binary_logloss: 0.175127\n",
      "[2976]\ttraining's auc: 0.932526\ttraining's binary_logloss: 0.175114\n",
      "[2977]\ttraining's auc: 0.932555\ttraining's binary_logloss: 0.175097\n",
      "[2978]\ttraining's auc: 0.932582\ttraining's binary_logloss: 0.175082\n",
      "[2979]\ttraining's auc: 0.932605\ttraining's binary_logloss: 0.175065\n",
      "[2980]\ttraining's auc: 0.932631\ttraining's binary_logloss: 0.175047\n",
      "[2981]\ttraining's auc: 0.932669\ttraining's binary_logloss: 0.175027\n",
      "[2982]\ttraining's auc: 0.932694\ttraining's binary_logloss: 0.175008\n",
      "[2983]\ttraining's auc: 0.932711\ttraining's binary_logloss: 0.174991\n",
      "[2984]\ttraining's auc: 0.932744\ttraining's binary_logloss: 0.174971\n",
      "[2985]\ttraining's auc: 0.932759\ttraining's binary_logloss: 0.174957\n",
      "[2986]\ttraining's auc: 0.932798\ttraining's binary_logloss: 0.17494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2987]\ttraining's auc: 0.932828\ttraining's binary_logloss: 0.174921\n",
      "[2988]\ttraining's auc: 0.932865\ttraining's binary_logloss: 0.174902\n",
      "[2989]\ttraining's auc: 0.932869\ttraining's binary_logloss: 0.174899\n",
      "[2990]\ttraining's auc: 0.932899\ttraining's binary_logloss: 0.174882\n",
      "[2991]\ttraining's auc: 0.932928\ttraining's binary_logloss: 0.174865\n",
      "[2992]\ttraining's auc: 0.932964\ttraining's binary_logloss: 0.174845\n",
      "[2993]\ttraining's auc: 0.932999\ttraining's binary_logloss: 0.174824\n",
      "[2994]\ttraining's auc: 0.93303\ttraining's binary_logloss: 0.174805\n",
      "[2995]\ttraining's auc: 0.933069\ttraining's binary_logloss: 0.174787\n",
      "[2996]\ttraining's auc: 0.933094\ttraining's binary_logloss: 0.174769\n",
      "[2997]\ttraining's auc: 0.933116\ttraining's binary_logloss: 0.17475\n",
      "[2998]\ttraining's auc: 0.933142\ttraining's binary_logloss: 0.174731\n",
      "[2999]\ttraining's auc: 0.933174\ttraining's binary_logloss: 0.174714\n",
      "[3000]\ttraining's auc: 0.933188\ttraining's binary_logloss: 0.174705\n",
      "[3001]\ttraining's auc: 0.933217\ttraining's binary_logloss: 0.174688\n",
      "[3002]\ttraining's auc: 0.933245\ttraining's binary_logloss: 0.174671\n",
      "[3003]\ttraining's auc: 0.933272\ttraining's binary_logloss: 0.174651\n",
      "[3004]\ttraining's auc: 0.933293\ttraining's binary_logloss: 0.174635\n",
      "[3005]\ttraining's auc: 0.933315\ttraining's binary_logloss: 0.174623\n",
      "[3006]\ttraining's auc: 0.933342\ttraining's binary_logloss: 0.174608\n",
      "[3007]\ttraining's auc: 0.933366\ttraining's binary_logloss: 0.174593\n",
      "[3008]\ttraining's auc: 0.933399\ttraining's binary_logloss: 0.174573\n",
      "[3009]\ttraining's auc: 0.933427\ttraining's binary_logloss: 0.174555\n",
      "[3010]\ttraining's auc: 0.93344\ttraining's binary_logloss: 0.174546\n",
      "[3011]\ttraining's auc: 0.933469\ttraining's binary_logloss: 0.174531\n",
      "[3012]\ttraining's auc: 0.933495\ttraining's binary_logloss: 0.174513\n",
      "[3013]\ttraining's auc: 0.933529\ttraining's binary_logloss: 0.174491\n",
      "[3014]\ttraining's auc: 0.933562\ttraining's binary_logloss: 0.174472\n",
      "[3015]\ttraining's auc: 0.93357\ttraining's binary_logloss: 0.174464\n",
      "[3016]\ttraining's auc: 0.933603\ttraining's binary_logloss: 0.174445\n",
      "[3017]\ttraining's auc: 0.933629\ttraining's binary_logloss: 0.174426\n",
      "[3018]\ttraining's auc: 0.933641\ttraining's binary_logloss: 0.174418\n",
      "[3019]\ttraining's auc: 0.93366\ttraining's binary_logloss: 0.174408\n",
      "[3020]\ttraining's auc: 0.93368\ttraining's binary_logloss: 0.174395\n",
      "[3021]\ttraining's auc: 0.933715\ttraining's binary_logloss: 0.174378\n",
      "[3022]\ttraining's auc: 0.933748\ttraining's binary_logloss: 0.174359\n",
      "[3023]\ttraining's auc: 0.933777\ttraining's binary_logloss: 0.17434\n",
      "[3024]\ttraining's auc: 0.93381\ttraining's binary_logloss: 0.17432\n",
      "[3025]\ttraining's auc: 0.933838\ttraining's binary_logloss: 0.174303\n",
      "[3026]\ttraining's auc: 0.933867\ttraining's binary_logloss: 0.174286\n",
      "[3027]\ttraining's auc: 0.933891\ttraining's binary_logloss: 0.174268\n",
      "[3028]\ttraining's auc: 0.933929\ttraining's binary_logloss: 0.174249\n",
      "[3029]\ttraining's auc: 0.93396\ttraining's binary_logloss: 0.174232\n",
      "[3030]\ttraining's auc: 0.934\ttraining's binary_logloss: 0.174211\n",
      "[3031]\ttraining's auc: 0.934025\ttraining's binary_logloss: 0.174193\n",
      "[3032]\ttraining's auc: 0.934056\ttraining's binary_logloss: 0.174176\n",
      "[3033]\ttraining's auc: 0.934086\ttraining's binary_logloss: 0.174159\n",
      "[3034]\ttraining's auc: 0.934109\ttraining's binary_logloss: 0.174141\n",
      "[3035]\ttraining's auc: 0.934131\ttraining's binary_logloss: 0.174123\n",
      "[3036]\ttraining's auc: 0.934153\ttraining's binary_logloss: 0.174107\n",
      "[3037]\ttraining's auc: 0.934181\ttraining's binary_logloss: 0.174089\n",
      "[3038]\ttraining's auc: 0.934201\ttraining's binary_logloss: 0.174076\n",
      "[3039]\ttraining's auc: 0.934206\ttraining's binary_logloss: 0.174073\n",
      "[3040]\ttraining's auc: 0.934232\ttraining's binary_logloss: 0.174055\n",
      "[3041]\ttraining's auc: 0.93425\ttraining's binary_logloss: 0.17404\n",
      "[3042]\ttraining's auc: 0.934254\ttraining's binary_logloss: 0.174037\n",
      "[3043]\ttraining's auc: 0.934282\ttraining's binary_logloss: 0.174019\n",
      "[3044]\ttraining's auc: 0.934309\ttraining's binary_logloss: 0.174001\n",
      "[3045]\ttraining's auc: 0.934323\ttraining's binary_logloss: 0.173989\n",
      "[3046]\ttraining's auc: 0.934359\ttraining's binary_logloss: 0.17397\n",
      "[3047]\ttraining's auc: 0.934387\ttraining's binary_logloss: 0.173951\n",
      "[3048]\ttraining's auc: 0.934414\ttraining's binary_logloss: 0.173933\n",
      "[3049]\ttraining's auc: 0.934434\ttraining's binary_logloss: 0.173917\n",
      "[3050]\ttraining's auc: 0.934474\ttraining's binary_logloss: 0.173896\n",
      "[3051]\ttraining's auc: 0.934497\ttraining's binary_logloss: 0.173878\n",
      "[3052]\ttraining's auc: 0.934519\ttraining's binary_logloss: 0.173861\n",
      "[3053]\ttraining's auc: 0.934553\ttraining's binary_logloss: 0.173843\n",
      "[3054]\ttraining's auc: 0.934566\ttraining's binary_logloss: 0.173834\n",
      "[3055]\ttraining's auc: 0.934596\ttraining's binary_logloss: 0.173817\n",
      "[3056]\ttraining's auc: 0.934619\ttraining's binary_logloss: 0.173804\n",
      "[3057]\ttraining's auc: 0.934626\ttraining's binary_logloss: 0.173796\n",
      "[3058]\ttraining's auc: 0.934649\ttraining's binary_logloss: 0.173777\n",
      "[3059]\ttraining's auc: 0.934677\ttraining's binary_logloss: 0.17376\n",
      "[3060]\ttraining's auc: 0.934711\ttraining's binary_logloss: 0.173742\n",
      "[3061]\ttraining's auc: 0.934738\ttraining's binary_logloss: 0.173724\n",
      "[3062]\ttraining's auc: 0.934754\ttraining's binary_logloss: 0.173715\n",
      "[3063]\ttraining's auc: 0.934781\ttraining's binary_logloss: 0.173699\n",
      "[3064]\ttraining's auc: 0.934795\ttraining's binary_logloss: 0.173691\n",
      "[3065]\ttraining's auc: 0.93482\ttraining's binary_logloss: 0.173676\n",
      "[3066]\ttraining's auc: 0.934841\ttraining's binary_logloss: 0.173658\n",
      "[3067]\ttraining's auc: 0.934865\ttraining's binary_logloss: 0.173642\n",
      "[3068]\ttraining's auc: 0.934892\ttraining's binary_logloss: 0.173625\n",
      "[3069]\ttraining's auc: 0.934935\ttraining's binary_logloss: 0.173606\n",
      "[3070]\ttraining's auc: 0.934966\ttraining's binary_logloss: 0.173586\n",
      "[3071]\ttraining's auc: 0.934987\ttraining's binary_logloss: 0.173571\n",
      "[3072]\ttraining's auc: 0.935019\ttraining's binary_logloss: 0.173551\n",
      "[3073]\ttraining's auc: 0.935051\ttraining's binary_logloss: 0.173535\n",
      "[3074]\ttraining's auc: 0.935085\ttraining's binary_logloss: 0.173514\n",
      "[3075]\ttraining's auc: 0.935115\ttraining's binary_logloss: 0.173496\n",
      "[3076]\ttraining's auc: 0.935148\ttraining's binary_logloss: 0.173477\n",
      "[3077]\ttraining's auc: 0.935168\ttraining's binary_logloss: 0.173462\n",
      "[3078]\ttraining's auc: 0.935201\ttraining's binary_logloss: 0.173447\n",
      "[3079]\ttraining's auc: 0.935219\ttraining's binary_logloss: 0.173432\n",
      "[3080]\ttraining's auc: 0.935228\ttraining's binary_logloss: 0.173427\n",
      "[3081]\ttraining's auc: 0.935258\ttraining's binary_logloss: 0.173408\n",
      "[3082]\ttraining's auc: 0.935295\ttraining's binary_logloss: 0.17339\n",
      "[3083]\ttraining's auc: 0.9353\ttraining's binary_logloss: 0.173385\n",
      "[3084]\ttraining's auc: 0.935314\ttraining's binary_logloss: 0.173374\n",
      "[3085]\ttraining's auc: 0.935337\ttraining's binary_logloss: 0.173357\n",
      "[3086]\ttraining's auc: 0.935356\ttraining's binary_logloss: 0.173345\n",
      "[3087]\ttraining's auc: 0.935389\ttraining's binary_logloss: 0.173325\n",
      "[3088]\ttraining's auc: 0.935424\ttraining's binary_logloss: 0.173307\n",
      "[3089]\ttraining's auc: 0.935457\ttraining's binary_logloss: 0.173288\n",
      "[3090]\ttraining's auc: 0.935482\ttraining's binary_logloss: 0.17327\n",
      "[3091]\ttraining's auc: 0.935506\ttraining's binary_logloss: 0.173256\n",
      "[3092]\ttraining's auc: 0.935531\ttraining's binary_logloss: 0.173239\n",
      "[3093]\ttraining's auc: 0.935571\ttraining's binary_logloss: 0.173218\n",
      "[3094]\ttraining's auc: 0.9356\ttraining's binary_logloss: 0.1732\n",
      "[3095]\ttraining's auc: 0.935621\ttraining's binary_logloss: 0.173184\n",
      "[3096]\ttraining's auc: 0.935649\ttraining's binary_logloss: 0.173167\n",
      "[3097]\ttraining's auc: 0.935677\ttraining's binary_logloss: 0.17315\n",
      "[3098]\ttraining's auc: 0.935715\ttraining's binary_logloss: 0.173129\n",
      "[3099]\ttraining's auc: 0.935725\ttraining's binary_logloss: 0.173121\n",
      "[3100]\ttraining's auc: 0.935743\ttraining's binary_logloss: 0.173104\n",
      "[3101]\ttraining's auc: 0.935772\ttraining's binary_logloss: 0.173086\n",
      "[3102]\ttraining's auc: 0.935782\ttraining's binary_logloss: 0.173079\n",
      "[3103]\ttraining's auc: 0.935811\ttraining's binary_logloss: 0.173059\n",
      "[3104]\ttraining's auc: 0.935838\ttraining's binary_logloss: 0.173043\n",
      "[3105]\ttraining's auc: 0.935847\ttraining's binary_logloss: 0.17303\n",
      "[3106]\ttraining's auc: 0.935877\ttraining's binary_logloss: 0.173012\n",
      "[3107]\ttraining's auc: 0.935889\ttraining's binary_logloss: 0.173001\n",
      "[3108]\ttraining's auc: 0.935906\ttraining's binary_logloss: 0.17299\n",
      "[3109]\ttraining's auc: 0.935919\ttraining's binary_logloss: 0.172981\n",
      "[3110]\ttraining's auc: 0.935928\ttraining's binary_logloss: 0.172972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3111]\ttraining's auc: 0.935949\ttraining's binary_logloss: 0.172961\n",
      "[3112]\ttraining's auc: 0.93596\ttraining's binary_logloss: 0.172954\n",
      "[3113]\ttraining's auc: 0.935994\ttraining's binary_logloss: 0.172935\n",
      "[3114]\ttraining's auc: 0.936019\ttraining's binary_logloss: 0.172917\n",
      "[3115]\ttraining's auc: 0.936047\ttraining's binary_logloss: 0.172899\n",
      "[3116]\ttraining's auc: 0.936059\ttraining's binary_logloss: 0.17289\n",
      "[3117]\ttraining's auc: 0.936093\ttraining's binary_logloss: 0.172872\n",
      "[3118]\ttraining's auc: 0.936121\ttraining's binary_logloss: 0.172853\n",
      "[3119]\ttraining's auc: 0.936141\ttraining's binary_logloss: 0.172837\n",
      "[3120]\ttraining's auc: 0.936156\ttraining's binary_logloss: 0.172821\n",
      "[3121]\ttraining's auc: 0.936174\ttraining's binary_logloss: 0.172802\n",
      "[3122]\ttraining's auc: 0.9362\ttraining's binary_logloss: 0.172786\n",
      "[3123]\ttraining's auc: 0.936226\ttraining's binary_logloss: 0.172769\n",
      "[3124]\ttraining's auc: 0.936245\ttraining's binary_logloss: 0.17276\n",
      "[3125]\ttraining's auc: 0.936276\ttraining's binary_logloss: 0.172742\n",
      "[3126]\ttraining's auc: 0.936289\ttraining's binary_logloss: 0.172735\n",
      "[3127]\ttraining's auc: 0.936319\ttraining's binary_logloss: 0.172717\n",
      "[3128]\ttraining's auc: 0.936337\ttraining's binary_logloss: 0.172704\n",
      "[3129]\ttraining's auc: 0.936359\ttraining's binary_logloss: 0.17269\n",
      "[3130]\ttraining's auc: 0.936387\ttraining's binary_logloss: 0.172672\n",
      "[3131]\ttraining's auc: 0.936392\ttraining's binary_logloss: 0.172666\n",
      "[3132]\ttraining's auc: 0.936414\ttraining's binary_logloss: 0.172651\n",
      "[3133]\ttraining's auc: 0.936434\ttraining's binary_logloss: 0.172635\n",
      "[3134]\ttraining's auc: 0.936439\ttraining's binary_logloss: 0.172631\n",
      "[3135]\ttraining's auc: 0.936465\ttraining's binary_logloss: 0.172616\n",
      "[3136]\ttraining's auc: 0.936492\ttraining's binary_logloss: 0.1726\n",
      "[3137]\ttraining's auc: 0.936519\ttraining's binary_logloss: 0.172583\n",
      "[3138]\ttraining's auc: 0.936539\ttraining's binary_logloss: 0.172567\n",
      "[3139]\ttraining's auc: 0.93656\ttraining's binary_logloss: 0.172549\n",
      "[3140]\ttraining's auc: 0.936588\ttraining's binary_logloss: 0.172529\n",
      "[3141]\ttraining's auc: 0.936619\ttraining's binary_logloss: 0.172511\n",
      "[3142]\ttraining's auc: 0.936645\ttraining's binary_logloss: 0.172495\n",
      "[3143]\ttraining's auc: 0.936676\ttraining's binary_logloss: 0.172476\n",
      "[3144]\ttraining's auc: 0.936708\ttraining's binary_logloss: 0.172457\n",
      "[3145]\ttraining's auc: 0.93674\ttraining's binary_logloss: 0.172441\n",
      "[3146]\ttraining's auc: 0.936755\ttraining's binary_logloss: 0.17243\n",
      "[3147]\ttraining's auc: 0.936774\ttraining's binary_logloss: 0.172418\n",
      "[3148]\ttraining's auc: 0.936793\ttraining's binary_logloss: 0.172406\n",
      "[3149]\ttraining's auc: 0.936821\ttraining's binary_logloss: 0.172389\n",
      "[3150]\ttraining's auc: 0.93684\ttraining's binary_logloss: 0.172373\n",
      "[3151]\ttraining's auc: 0.936867\ttraining's binary_logloss: 0.172355\n",
      "[3152]\ttraining's auc: 0.936894\ttraining's binary_logloss: 0.172336\n",
      "[3153]\ttraining's auc: 0.936914\ttraining's binary_logloss: 0.172319\n",
      "[3154]\ttraining's auc: 0.936935\ttraining's binary_logloss: 0.172304\n",
      "[3155]\ttraining's auc: 0.936955\ttraining's binary_logloss: 0.172288\n",
      "[3156]\ttraining's auc: 0.936977\ttraining's binary_logloss: 0.172272\n",
      "[3157]\ttraining's auc: 0.93701\ttraining's binary_logloss: 0.172253\n",
      "[3158]\ttraining's auc: 0.937039\ttraining's binary_logloss: 0.172237\n",
      "[3159]\ttraining's auc: 0.937063\ttraining's binary_logloss: 0.17222\n",
      "[3160]\ttraining's auc: 0.937086\ttraining's binary_logloss: 0.172202\n",
      "[3161]\ttraining's auc: 0.937113\ttraining's binary_logloss: 0.172183\n",
      "[3162]\ttraining's auc: 0.937139\ttraining's binary_logloss: 0.172166\n",
      "[3163]\ttraining's auc: 0.937166\ttraining's binary_logloss: 0.172148\n",
      "[3164]\ttraining's auc: 0.937189\ttraining's binary_logloss: 0.172131\n",
      "[3165]\ttraining's auc: 0.937219\ttraining's binary_logloss: 0.172117\n",
      "[3166]\ttraining's auc: 0.937243\ttraining's binary_logloss: 0.172099\n",
      "[3167]\ttraining's auc: 0.937267\ttraining's binary_logloss: 0.172082\n",
      "[3168]\ttraining's auc: 0.937289\ttraining's binary_logloss: 0.172063\n",
      "[3169]\ttraining's auc: 0.937313\ttraining's binary_logloss: 0.172046\n",
      "[3170]\ttraining's auc: 0.937341\ttraining's binary_logloss: 0.17203\n",
      "[3171]\ttraining's auc: 0.937368\ttraining's binary_logloss: 0.172012\n",
      "[3172]\ttraining's auc: 0.937388\ttraining's binary_logloss: 0.171998\n",
      "[3173]\ttraining's auc: 0.937418\ttraining's binary_logloss: 0.171981\n",
      "[3174]\ttraining's auc: 0.937442\ttraining's binary_logloss: 0.171964\n",
      "[3175]\ttraining's auc: 0.937468\ttraining's binary_logloss: 0.171946\n",
      "[3176]\ttraining's auc: 0.9375\ttraining's binary_logloss: 0.171928\n",
      "[3177]\ttraining's auc: 0.937516\ttraining's binary_logloss: 0.171919\n",
      "[3178]\ttraining's auc: 0.937536\ttraining's binary_logloss: 0.171903\n",
      "[3179]\ttraining's auc: 0.937557\ttraining's binary_logloss: 0.171882\n",
      "[3180]\ttraining's auc: 0.937574\ttraining's binary_logloss: 0.171868\n",
      "[3181]\ttraining's auc: 0.937599\ttraining's binary_logloss: 0.171851\n",
      "[3182]\ttraining's auc: 0.937628\ttraining's binary_logloss: 0.171834\n",
      "[3183]\ttraining's auc: 0.937668\ttraining's binary_logloss: 0.171815\n",
      "[3184]\ttraining's auc: 0.937701\ttraining's binary_logloss: 0.171795\n",
      "[3185]\ttraining's auc: 0.937736\ttraining's binary_logloss: 0.171775\n",
      "[3186]\ttraining's auc: 0.937763\ttraining's binary_logloss: 0.171758\n",
      "[3187]\ttraining's auc: 0.937798\ttraining's binary_logloss: 0.171737\n",
      "[3188]\ttraining's auc: 0.937826\ttraining's binary_logloss: 0.171719\n",
      "[3189]\ttraining's auc: 0.937838\ttraining's binary_logloss: 0.17171\n",
      "[3190]\ttraining's auc: 0.937854\ttraining's binary_logloss: 0.171697\n",
      "[3191]\ttraining's auc: 0.937878\ttraining's binary_logloss: 0.171681\n",
      "[3192]\ttraining's auc: 0.937905\ttraining's binary_logloss: 0.171663\n",
      "[3193]\ttraining's auc: 0.937932\ttraining's binary_logloss: 0.171644\n",
      "[3194]\ttraining's auc: 0.937955\ttraining's binary_logloss: 0.17163\n",
      "[3195]\ttraining's auc: 0.937984\ttraining's binary_logloss: 0.171612\n",
      "[3196]\ttraining's auc: 0.938014\ttraining's binary_logloss: 0.171595\n",
      "[3197]\ttraining's auc: 0.938044\ttraining's binary_logloss: 0.171579\n",
      "[3198]\ttraining's auc: 0.938075\ttraining's binary_logloss: 0.171563\n",
      "[3199]\ttraining's auc: 0.938097\ttraining's binary_logloss: 0.171546\n",
      "[3200]\ttraining's auc: 0.938119\ttraining's binary_logloss: 0.171535\n",
      "[3201]\ttraining's auc: 0.938149\ttraining's binary_logloss: 0.171516\n",
      "[3202]\ttraining's auc: 0.938179\ttraining's binary_logloss: 0.171497\n",
      "[3203]\ttraining's auc: 0.938188\ttraining's binary_logloss: 0.171489\n",
      "[3204]\ttraining's auc: 0.938204\ttraining's binary_logloss: 0.171477\n",
      "[3205]\ttraining's auc: 0.938222\ttraining's binary_logloss: 0.171461\n",
      "[3206]\ttraining's auc: 0.938241\ttraining's binary_logloss: 0.171442\n",
      "[3207]\ttraining's auc: 0.938264\ttraining's binary_logloss: 0.171427\n",
      "[3208]\ttraining's auc: 0.938303\ttraining's binary_logloss: 0.171407\n",
      "[3209]\ttraining's auc: 0.938333\ttraining's binary_logloss: 0.171388\n",
      "[3210]\ttraining's auc: 0.938365\ttraining's binary_logloss: 0.171368\n",
      "[3211]\ttraining's auc: 0.938391\ttraining's binary_logloss: 0.17135\n",
      "[3212]\ttraining's auc: 0.938416\ttraining's binary_logloss: 0.171332\n",
      "[3213]\ttraining's auc: 0.938442\ttraining's binary_logloss: 0.171313\n",
      "[3214]\ttraining's auc: 0.938458\ttraining's binary_logloss: 0.171298\n",
      "[3215]\ttraining's auc: 0.938491\ttraining's binary_logloss: 0.171278\n",
      "[3216]\ttraining's auc: 0.938518\ttraining's binary_logloss: 0.171263\n",
      "[3217]\ttraining's auc: 0.938548\ttraining's binary_logloss: 0.171243\n",
      "[3218]\ttraining's auc: 0.938579\ttraining's binary_logloss: 0.171221\n",
      "[3219]\ttraining's auc: 0.938601\ttraining's binary_logloss: 0.171203\n",
      "[3220]\ttraining's auc: 0.938635\ttraining's binary_logloss: 0.171183\n",
      "[3221]\ttraining's auc: 0.938664\ttraining's binary_logloss: 0.171163\n",
      "[3222]\ttraining's auc: 0.938688\ttraining's binary_logloss: 0.171146\n",
      "[3223]\ttraining's auc: 0.938711\ttraining's binary_logloss: 0.171131\n",
      "[3224]\ttraining's auc: 0.938745\ttraining's binary_logloss: 0.171115\n",
      "[3225]\ttraining's auc: 0.938771\ttraining's binary_logloss: 0.171098\n",
      "[3226]\ttraining's auc: 0.938788\ttraining's binary_logloss: 0.171081\n",
      "[3227]\ttraining's auc: 0.938826\ttraining's binary_logloss: 0.171063\n",
      "[3228]\ttraining's auc: 0.93884\ttraining's binary_logloss: 0.171051\n",
      "[3229]\ttraining's auc: 0.938864\ttraining's binary_logloss: 0.171036\n",
      "[3230]\ttraining's auc: 0.938891\ttraining's binary_logloss: 0.171017\n",
      "[3231]\ttraining's auc: 0.938918\ttraining's binary_logloss: 0.171001\n",
      "[3232]\ttraining's auc: 0.938955\ttraining's binary_logloss: 0.170983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3233]\ttraining's auc: 0.938978\ttraining's binary_logloss: 0.170966\n",
      "[3234]\ttraining's auc: 0.939\ttraining's binary_logloss: 0.170956\n",
      "[3235]\ttraining's auc: 0.939034\ttraining's binary_logloss: 0.170939\n",
      "[3236]\ttraining's auc: 0.939069\ttraining's binary_logloss: 0.170921\n",
      "[3237]\ttraining's auc: 0.9391\ttraining's binary_logloss: 0.170903\n",
      "[3238]\ttraining's auc: 0.939124\ttraining's binary_logloss: 0.170887\n",
      "[3239]\ttraining's auc: 0.939146\ttraining's binary_logloss: 0.170873\n",
      "[3240]\ttraining's auc: 0.939156\ttraining's binary_logloss: 0.170868\n",
      "[3241]\ttraining's auc: 0.939176\ttraining's binary_logloss: 0.170856\n",
      "[3242]\ttraining's auc: 0.939183\ttraining's binary_logloss: 0.17085\n",
      "[3243]\ttraining's auc: 0.93921\ttraining's binary_logloss: 0.170833\n",
      "[3244]\ttraining's auc: 0.939243\ttraining's binary_logloss: 0.170815\n",
      "[3245]\ttraining's auc: 0.939266\ttraining's binary_logloss: 0.170797\n",
      "[3246]\ttraining's auc: 0.939287\ttraining's binary_logloss: 0.17078\n",
      "[3247]\ttraining's auc: 0.939295\ttraining's binary_logloss: 0.170774\n",
      "[3248]\ttraining's auc: 0.939315\ttraining's binary_logloss: 0.170759\n",
      "[3249]\ttraining's auc: 0.939345\ttraining's binary_logloss: 0.170741\n",
      "[3250]\ttraining's auc: 0.939366\ttraining's binary_logloss: 0.170724\n",
      "[3251]\ttraining's auc: 0.939381\ttraining's binary_logloss: 0.170712\n",
      "[3252]\ttraining's auc: 0.939409\ttraining's binary_logloss: 0.170695\n",
      "[3253]\ttraining's auc: 0.939438\ttraining's binary_logloss: 0.170677\n",
      "[3254]\ttraining's auc: 0.939464\ttraining's binary_logloss: 0.170661\n",
      "[3255]\ttraining's auc: 0.939494\ttraining's binary_logloss: 0.170642\n",
      "[3256]\ttraining's auc: 0.939524\ttraining's binary_logloss: 0.170622\n",
      "[3257]\ttraining's auc: 0.939548\ttraining's binary_logloss: 0.170604\n",
      "[3258]\ttraining's auc: 0.939575\ttraining's binary_logloss: 0.170587\n",
      "[3259]\ttraining's auc: 0.939604\ttraining's binary_logloss: 0.170569\n",
      "[3260]\ttraining's auc: 0.939627\ttraining's binary_logloss: 0.170552\n",
      "[3261]\ttraining's auc: 0.939652\ttraining's binary_logloss: 0.170534\n",
      "[3262]\ttraining's auc: 0.939673\ttraining's binary_logloss: 0.170519\n",
      "[3263]\ttraining's auc: 0.939681\ttraining's binary_logloss: 0.170512\n",
      "[3264]\ttraining's auc: 0.939701\ttraining's binary_logloss: 0.170498\n",
      "[3265]\ttraining's auc: 0.939711\ttraining's binary_logloss: 0.170492\n",
      "[3266]\ttraining's auc: 0.93972\ttraining's binary_logloss: 0.170487\n",
      "[3267]\ttraining's auc: 0.939746\ttraining's binary_logloss: 0.170469\n",
      "[3268]\ttraining's auc: 0.939779\ttraining's binary_logloss: 0.170449\n",
      "[3269]\ttraining's auc: 0.939811\ttraining's binary_logloss: 0.170429\n",
      "[3270]\ttraining's auc: 0.939833\ttraining's binary_logloss: 0.170413\n",
      "[3271]\ttraining's auc: 0.939855\ttraining's binary_logloss: 0.170397\n",
      "[3272]\ttraining's auc: 0.939892\ttraining's binary_logloss: 0.170378\n",
      "[3273]\ttraining's auc: 0.939921\ttraining's binary_logloss: 0.170362\n",
      "[3274]\ttraining's auc: 0.939951\ttraining's binary_logloss: 0.17034\n",
      "[3275]\ttraining's auc: 0.939971\ttraining's binary_logloss: 0.170325\n",
      "[3276]\ttraining's auc: 0.939992\ttraining's binary_logloss: 0.170309\n",
      "[3277]\ttraining's auc: 0.940017\ttraining's binary_logloss: 0.170299\n",
      "[3278]\ttraining's auc: 0.940041\ttraining's binary_logloss: 0.170283\n",
      "[3279]\ttraining's auc: 0.940052\ttraining's binary_logloss: 0.170275\n",
      "[3280]\ttraining's auc: 0.940089\ttraining's binary_logloss: 0.170257\n",
      "[3281]\ttraining's auc: 0.940109\ttraining's binary_logloss: 0.170243\n",
      "[3282]\ttraining's auc: 0.940143\ttraining's binary_logloss: 0.170225\n",
      "[3283]\ttraining's auc: 0.940162\ttraining's binary_logloss: 0.170216\n",
      "[3284]\ttraining's auc: 0.940185\ttraining's binary_logloss: 0.1702\n",
      "[3285]\ttraining's auc: 0.940208\ttraining's binary_logloss: 0.170183\n",
      "[3286]\ttraining's auc: 0.94024\ttraining's binary_logloss: 0.170168\n",
      "[3287]\ttraining's auc: 0.940265\ttraining's binary_logloss: 0.17015\n",
      "[3288]\ttraining's auc: 0.94029\ttraining's binary_logloss: 0.170134\n",
      "[3289]\ttraining's auc: 0.940305\ttraining's binary_logloss: 0.170125\n",
      "[3290]\ttraining's auc: 0.94032\ttraining's binary_logloss: 0.170114\n",
      "[3291]\ttraining's auc: 0.940327\ttraining's binary_logloss: 0.170108\n",
      "[3292]\ttraining's auc: 0.940349\ttraining's binary_logloss: 0.170093\n",
      "[3293]\ttraining's auc: 0.94037\ttraining's binary_logloss: 0.170077\n",
      "[3294]\ttraining's auc: 0.940383\ttraining's binary_logloss: 0.170069\n",
      "[3295]\ttraining's auc: 0.940402\ttraining's binary_logloss: 0.170054\n",
      "[3296]\ttraining's auc: 0.940406\ttraining's binary_logloss: 0.17005\n",
      "[3297]\ttraining's auc: 0.940424\ttraining's binary_logloss: 0.170038\n",
      "[3298]\ttraining's auc: 0.940451\ttraining's binary_logloss: 0.170025\n",
      "[3299]\ttraining's auc: 0.94048\ttraining's binary_logloss: 0.170009\n",
      "[3300]\ttraining's auc: 0.940496\ttraining's binary_logloss: 0.169997\n",
      "[3301]\ttraining's auc: 0.940517\ttraining's binary_logloss: 0.16998\n",
      "[3302]\ttraining's auc: 0.940537\ttraining's binary_logloss: 0.169966\n",
      "[3303]\ttraining's auc: 0.940559\ttraining's binary_logloss: 0.169953\n",
      "[3304]\ttraining's auc: 0.940579\ttraining's binary_logloss: 0.169936\n",
      "[3305]\ttraining's auc: 0.940595\ttraining's binary_logloss: 0.169922\n",
      "[3306]\ttraining's auc: 0.940612\ttraining's binary_logloss: 0.16991\n",
      "[3307]\ttraining's auc: 0.940637\ttraining's binary_logloss: 0.169894\n",
      "[3308]\ttraining's auc: 0.940661\ttraining's binary_logloss: 0.169881\n",
      "[3309]\ttraining's auc: 0.940677\ttraining's binary_logloss: 0.169866\n",
      "[3310]\ttraining's auc: 0.9407\ttraining's binary_logloss: 0.16985\n",
      "[3311]\ttraining's auc: 0.940724\ttraining's binary_logloss: 0.169828\n",
      "[3312]\ttraining's auc: 0.940752\ttraining's binary_logloss: 0.169809\n",
      "[3313]\ttraining's auc: 0.940771\ttraining's binary_logloss: 0.169798\n",
      "[3314]\ttraining's auc: 0.940785\ttraining's binary_logloss: 0.169788\n",
      "[3315]\ttraining's auc: 0.940804\ttraining's binary_logloss: 0.169771\n",
      "[3316]\ttraining's auc: 0.94083\ttraining's binary_logloss: 0.169753\n",
      "[3317]\ttraining's auc: 0.940856\ttraining's binary_logloss: 0.169737\n",
      "[3318]\ttraining's auc: 0.940883\ttraining's binary_logloss: 0.169717\n",
      "[3319]\ttraining's auc: 0.940908\ttraining's binary_logloss: 0.169698\n",
      "[3320]\ttraining's auc: 0.940936\ttraining's binary_logloss: 0.16968\n",
      "[3321]\ttraining's auc: 0.940961\ttraining's binary_logloss: 0.169661\n",
      "[3322]\ttraining's auc: 0.940993\ttraining's binary_logloss: 0.169643\n",
      "[3323]\ttraining's auc: 0.941029\ttraining's binary_logloss: 0.169621\n",
      "[3324]\ttraining's auc: 0.941059\ttraining's binary_logloss: 0.169605\n",
      "[3325]\ttraining's auc: 0.94108\ttraining's binary_logloss: 0.169589\n",
      "[3326]\ttraining's auc: 0.941086\ttraining's binary_logloss: 0.169585\n",
      "[3327]\ttraining's auc: 0.941113\ttraining's binary_logloss: 0.169569\n",
      "[3328]\ttraining's auc: 0.941132\ttraining's binary_logloss: 0.169554\n",
      "[3329]\ttraining's auc: 0.941159\ttraining's binary_logloss: 0.169536\n",
      "[3330]\ttraining's auc: 0.941188\ttraining's binary_logloss: 0.169517\n",
      "[3331]\ttraining's auc: 0.941208\ttraining's binary_logloss: 0.169503\n",
      "[3332]\ttraining's auc: 0.941233\ttraining's binary_logloss: 0.169485\n",
      "[3333]\ttraining's auc: 0.941242\ttraining's binary_logloss: 0.169479\n",
      "[3334]\ttraining's auc: 0.941266\ttraining's binary_logloss: 0.169466\n",
      "[3335]\ttraining's auc: 0.941277\ttraining's binary_logloss: 0.169458\n",
      "[3336]\ttraining's auc: 0.941297\ttraining's binary_logloss: 0.169449\n",
      "[3337]\ttraining's auc: 0.941327\ttraining's binary_logloss: 0.169431\n",
      "[3338]\ttraining's auc: 0.941343\ttraining's binary_logloss: 0.16942\n",
      "[3339]\ttraining's auc: 0.941371\ttraining's binary_logloss: 0.169402\n",
      "[3340]\ttraining's auc: 0.941397\ttraining's binary_logloss: 0.169385\n",
      "[3341]\ttraining's auc: 0.941413\ttraining's binary_logloss: 0.16937\n",
      "[3342]\ttraining's auc: 0.941435\ttraining's binary_logloss: 0.169351\n",
      "[3343]\ttraining's auc: 0.941466\ttraining's binary_logloss: 0.169335\n",
      "[3344]\ttraining's auc: 0.941486\ttraining's binary_logloss: 0.169321\n",
      "[3345]\ttraining's auc: 0.941511\ttraining's binary_logloss: 0.169302\n",
      "[3346]\ttraining's auc: 0.941533\ttraining's binary_logloss: 0.169285\n",
      "[3347]\ttraining's auc: 0.94156\ttraining's binary_logloss: 0.16927\n",
      "[3348]\ttraining's auc: 0.941575\ttraining's binary_logloss: 0.169257\n",
      "[3349]\ttraining's auc: 0.941585\ttraining's binary_logloss: 0.16925\n",
      "[3350]\ttraining's auc: 0.94161\ttraining's binary_logloss: 0.169234\n",
      "[3351]\ttraining's auc: 0.941627\ttraining's binary_logloss: 0.169217\n",
      "[3352]\ttraining's auc: 0.941657\ttraining's binary_logloss: 0.169201\n",
      "[3353]\ttraining's auc: 0.941665\ttraining's binary_logloss: 0.169192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3354]\ttraining's auc: 0.9417\ttraining's binary_logloss: 0.169174\n",
      "[3355]\ttraining's auc: 0.941713\ttraining's binary_logloss: 0.169166\n",
      "[3356]\ttraining's auc: 0.941724\ttraining's binary_logloss: 0.16916\n",
      "[3357]\ttraining's auc: 0.941761\ttraining's binary_logloss: 0.169139\n",
      "[3358]\ttraining's auc: 0.941778\ttraining's binary_logloss: 0.169122\n",
      "[3359]\ttraining's auc: 0.941802\ttraining's binary_logloss: 0.169105\n",
      "[3360]\ttraining's auc: 0.941822\ttraining's binary_logloss: 0.169088\n",
      "[3361]\ttraining's auc: 0.941834\ttraining's binary_logloss: 0.16908\n",
      "[3362]\ttraining's auc: 0.941859\ttraining's binary_logloss: 0.169064\n",
      "[3363]\ttraining's auc: 0.941887\ttraining's binary_logloss: 0.169047\n",
      "[3364]\ttraining's auc: 0.941904\ttraining's binary_logloss: 0.16903\n",
      "[3365]\ttraining's auc: 0.941915\ttraining's binary_logloss: 0.169021\n",
      "[3366]\ttraining's auc: 0.941934\ttraining's binary_logloss: 0.169006\n",
      "[3367]\ttraining's auc: 0.941957\ttraining's binary_logloss: 0.168988\n",
      "[3368]\ttraining's auc: 0.94198\ttraining's binary_logloss: 0.168971\n",
      "[3369]\ttraining's auc: 0.942006\ttraining's binary_logloss: 0.168956\n",
      "[3370]\ttraining's auc: 0.942022\ttraining's binary_logloss: 0.168947\n",
      "[3371]\ttraining's auc: 0.942043\ttraining's binary_logloss: 0.168931\n",
      "[3372]\ttraining's auc: 0.942058\ttraining's binary_logloss: 0.16892\n",
      "[3373]\ttraining's auc: 0.942076\ttraining's binary_logloss: 0.168907\n",
      "[3374]\ttraining's auc: 0.942101\ttraining's binary_logloss: 0.168889\n",
      "[3375]\ttraining's auc: 0.942126\ttraining's binary_logloss: 0.168873\n",
      "[3376]\ttraining's auc: 0.942166\ttraining's binary_logloss: 0.168856\n",
      "[3377]\ttraining's auc: 0.942188\ttraining's binary_logloss: 0.168839\n",
      "[3378]\ttraining's auc: 0.942215\ttraining's binary_logloss: 0.168821\n",
      "[3379]\ttraining's auc: 0.942236\ttraining's binary_logloss: 0.168804\n",
      "[3380]\ttraining's auc: 0.942259\ttraining's binary_logloss: 0.168787\n",
      "[3381]\ttraining's auc: 0.942285\ttraining's binary_logloss: 0.168773\n",
      "[3382]\ttraining's auc: 0.942311\ttraining's binary_logloss: 0.168755\n",
      "[3383]\ttraining's auc: 0.942348\ttraining's binary_logloss: 0.168736\n",
      "[3384]\ttraining's auc: 0.942372\ttraining's binary_logloss: 0.168716\n",
      "[3385]\ttraining's auc: 0.942392\ttraining's binary_logloss: 0.168703\n",
      "[3386]\ttraining's auc: 0.942419\ttraining's binary_logloss: 0.168687\n",
      "[3387]\ttraining's auc: 0.942444\ttraining's binary_logloss: 0.16867\n",
      "[3388]\ttraining's auc: 0.942469\ttraining's binary_logloss: 0.168652\n",
      "[3389]\ttraining's auc: 0.942498\ttraining's binary_logloss: 0.168634\n",
      "[3390]\ttraining's auc: 0.942529\ttraining's binary_logloss: 0.168618\n",
      "[3391]\ttraining's auc: 0.942556\ttraining's binary_logloss: 0.1686\n",
      "[3392]\ttraining's auc: 0.942577\ttraining's binary_logloss: 0.168585\n",
      "[3393]\ttraining's auc: 0.942611\ttraining's binary_logloss: 0.168567\n",
      "[3394]\ttraining's auc: 0.942635\ttraining's binary_logloss: 0.16855\n",
      "[3395]\ttraining's auc: 0.942658\ttraining's binary_logloss: 0.168533\n",
      "[3396]\ttraining's auc: 0.94268\ttraining's binary_logloss: 0.168517\n",
      "[3397]\ttraining's auc: 0.942695\ttraining's binary_logloss: 0.168503\n",
      "[3398]\ttraining's auc: 0.942723\ttraining's binary_logloss: 0.168487\n",
      "[3399]\ttraining's auc: 0.942748\ttraining's binary_logloss: 0.168471\n",
      "[3400]\ttraining's auc: 0.94277\ttraining's binary_logloss: 0.168455\n",
      "[3401]\ttraining's auc: 0.942804\ttraining's binary_logloss: 0.168436\n",
      "[3402]\ttraining's auc: 0.94283\ttraining's binary_logloss: 0.16842\n",
      "[3403]\ttraining's auc: 0.942834\ttraining's binary_logloss: 0.168413\n",
      "[3404]\ttraining's auc: 0.942856\ttraining's binary_logloss: 0.168398\n",
      "[3405]\ttraining's auc: 0.942884\ttraining's binary_logloss: 0.168382\n",
      "[3406]\ttraining's auc: 0.942902\ttraining's binary_logloss: 0.168364\n",
      "[3407]\ttraining's auc: 0.942922\ttraining's binary_logloss: 0.16835\n",
      "[3408]\ttraining's auc: 0.942938\ttraining's binary_logloss: 0.168336\n",
      "[3409]\ttraining's auc: 0.942941\ttraining's binary_logloss: 0.168334\n",
      "[3410]\ttraining's auc: 0.942956\ttraining's binary_logloss: 0.168319\n",
      "[3411]\ttraining's auc: 0.942981\ttraining's binary_logloss: 0.168303\n",
      "[3412]\ttraining's auc: 0.942985\ttraining's binary_logloss: 0.168298\n",
      "[3413]\ttraining's auc: 0.942999\ttraining's binary_logloss: 0.168288\n",
      "[3414]\ttraining's auc: 0.943025\ttraining's binary_logloss: 0.168272\n",
      "[3415]\ttraining's auc: 0.943051\ttraining's binary_logloss: 0.168255\n",
      "[3416]\ttraining's auc: 0.943086\ttraining's binary_logloss: 0.168234\n",
      "[3417]\ttraining's auc: 0.943111\ttraining's binary_logloss: 0.168217\n",
      "[3418]\ttraining's auc: 0.943123\ttraining's binary_logloss: 0.168209\n",
      "[3419]\ttraining's auc: 0.943129\ttraining's binary_logloss: 0.168202\n",
      "[3420]\ttraining's auc: 0.943136\ttraining's binary_logloss: 0.168195\n",
      "[3421]\ttraining's auc: 0.943167\ttraining's binary_logloss: 0.168178\n",
      "[3422]\ttraining's auc: 0.943192\ttraining's binary_logloss: 0.168163\n",
      "[3423]\ttraining's auc: 0.943216\ttraining's binary_logloss: 0.168143\n",
      "[3424]\ttraining's auc: 0.943238\ttraining's binary_logloss: 0.16813\n",
      "[3425]\ttraining's auc: 0.943241\ttraining's binary_logloss: 0.168124\n",
      "[3426]\ttraining's auc: 0.943274\ttraining's binary_logloss: 0.168106\n",
      "[3427]\ttraining's auc: 0.943303\ttraining's binary_logloss: 0.168089\n",
      "[3428]\ttraining's auc: 0.943319\ttraining's binary_logloss: 0.16808\n",
      "[3429]\ttraining's auc: 0.943335\ttraining's binary_logloss: 0.168068\n",
      "[3430]\ttraining's auc: 0.943357\ttraining's binary_logloss: 0.168055\n",
      "[3431]\ttraining's auc: 0.94338\ttraining's binary_logloss: 0.16804\n",
      "[3432]\ttraining's auc: 0.943406\ttraining's binary_logloss: 0.168023\n",
      "[3433]\ttraining's auc: 0.943439\ttraining's binary_logloss: 0.168005\n",
      "[3434]\ttraining's auc: 0.943465\ttraining's binary_logloss: 0.167991\n",
      "[3435]\ttraining's auc: 0.943469\ttraining's binary_logloss: 0.167985\n",
      "[3436]\ttraining's auc: 0.943491\ttraining's binary_logloss: 0.167969\n",
      "[3437]\ttraining's auc: 0.943511\ttraining's binary_logloss: 0.167954\n",
      "[3438]\ttraining's auc: 0.943544\ttraining's binary_logloss: 0.167937\n",
      "[3439]\ttraining's auc: 0.943575\ttraining's binary_logloss: 0.16792\n",
      "[3440]\ttraining's auc: 0.943582\ttraining's binary_logloss: 0.167914\n",
      "[3441]\ttraining's auc: 0.943603\ttraining's binary_logloss: 0.1679\n",
      "[3442]\ttraining's auc: 0.943623\ttraining's binary_logloss: 0.167882\n",
      "[3443]\ttraining's auc: 0.943634\ttraining's binary_logloss: 0.167866\n",
      "[3444]\ttraining's auc: 0.943662\ttraining's binary_logloss: 0.167847\n",
      "[3445]\ttraining's auc: 0.943664\ttraining's binary_logloss: 0.167845\n",
      "[3446]\ttraining's auc: 0.94369\ttraining's binary_logloss: 0.167828\n",
      "[3447]\ttraining's auc: 0.943721\ttraining's binary_logloss: 0.167811\n",
      "[3448]\ttraining's auc: 0.943744\ttraining's binary_logloss: 0.167793\n",
      "[3449]\ttraining's auc: 0.94377\ttraining's binary_logloss: 0.167775\n",
      "[3450]\ttraining's auc: 0.943793\ttraining's binary_logloss: 0.167759\n",
      "[3451]\ttraining's auc: 0.943822\ttraining's binary_logloss: 0.16774\n",
      "[3452]\ttraining's auc: 0.943834\ttraining's binary_logloss: 0.16773\n",
      "[3453]\ttraining's auc: 0.943849\ttraining's binary_logloss: 0.167716\n",
      "[3454]\ttraining's auc: 0.943866\ttraining's binary_logloss: 0.167701\n",
      "[3455]\ttraining's auc: 0.943897\ttraining's binary_logloss: 0.167684\n",
      "[3456]\ttraining's auc: 0.943923\ttraining's binary_logloss: 0.167666\n",
      "[3457]\ttraining's auc: 0.943943\ttraining's binary_logloss: 0.167651\n",
      "[3458]\ttraining's auc: 0.943974\ttraining's binary_logloss: 0.167632\n",
      "[3459]\ttraining's auc: 0.943999\ttraining's binary_logloss: 0.167615\n",
      "[3460]\ttraining's auc: 0.944019\ttraining's binary_logloss: 0.167599\n",
      "[3461]\ttraining's auc: 0.944037\ttraining's binary_logloss: 0.167582\n",
      "[3462]\ttraining's auc: 0.94406\ttraining's binary_logloss: 0.167565\n",
      "[3463]\ttraining's auc: 0.944089\ttraining's binary_logloss: 0.167547\n",
      "[3464]\ttraining's auc: 0.944117\ttraining's binary_logloss: 0.167533\n",
      "[3465]\ttraining's auc: 0.944135\ttraining's binary_logloss: 0.167519\n",
      "[3466]\ttraining's auc: 0.94416\ttraining's binary_logloss: 0.1675\n",
      "[3467]\ttraining's auc: 0.944178\ttraining's binary_logloss: 0.167484\n",
      "[3468]\ttraining's auc: 0.944196\ttraining's binary_logloss: 0.167469\n",
      "[3469]\ttraining's auc: 0.944225\ttraining's binary_logloss: 0.167452\n",
      "[3470]\ttraining's auc: 0.94425\ttraining's binary_logloss: 0.167436\n",
      "[3471]\ttraining's auc: 0.944274\ttraining's binary_logloss: 0.167418\n",
      "[3472]\ttraining's auc: 0.944281\ttraining's binary_logloss: 0.167413\n",
      "[3473]\ttraining's auc: 0.944315\ttraining's binary_logloss: 0.167398\n",
      "[3474]\ttraining's auc: 0.94432\ttraining's binary_logloss: 0.167393\n",
      "[3475]\ttraining's auc: 0.944332\ttraining's binary_logloss: 0.167383\n",
      "[3476]\ttraining's auc: 0.944333\ttraining's binary_logloss: 0.167381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3477]\ttraining's auc: 0.944352\ttraining's binary_logloss: 0.167361\n",
      "[3478]\ttraining's auc: 0.944374\ttraining's binary_logloss: 0.167346\n",
      "[3479]\ttraining's auc: 0.944403\ttraining's binary_logloss: 0.167332\n",
      "[3480]\ttraining's auc: 0.944426\ttraining's binary_logloss: 0.167315\n",
      "[3481]\ttraining's auc: 0.944452\ttraining's binary_logloss: 0.167297\n",
      "[3482]\ttraining's auc: 0.944477\ttraining's binary_logloss: 0.16728\n",
      "[3483]\ttraining's auc: 0.944508\ttraining's binary_logloss: 0.167262\n",
      "[3484]\ttraining's auc: 0.944524\ttraining's binary_logloss: 0.167245\n",
      "[3485]\ttraining's auc: 0.944553\ttraining's binary_logloss: 0.167228\n",
      "[3486]\ttraining's auc: 0.94457\ttraining's binary_logloss: 0.167212\n",
      "[3487]\ttraining's auc: 0.944594\ttraining's binary_logloss: 0.167197\n",
      "[3488]\ttraining's auc: 0.944619\ttraining's binary_logloss: 0.167181\n",
      "[3489]\ttraining's auc: 0.944624\ttraining's binary_logloss: 0.167175\n",
      "[3490]\ttraining's auc: 0.944642\ttraining's binary_logloss: 0.167159\n",
      "[3491]\ttraining's auc: 0.944656\ttraining's binary_logloss: 0.167145\n",
      "[3492]\ttraining's auc: 0.944683\ttraining's binary_logloss: 0.167127\n",
      "[3493]\ttraining's auc: 0.944717\ttraining's binary_logloss: 0.167108\n",
      "[3494]\ttraining's auc: 0.944736\ttraining's binary_logloss: 0.167092\n",
      "[3495]\ttraining's auc: 0.944757\ttraining's binary_logloss: 0.167079\n",
      "[3496]\ttraining's auc: 0.944782\ttraining's binary_logloss: 0.167064\n",
      "[3497]\ttraining's auc: 0.944808\ttraining's binary_logloss: 0.167047\n",
      "[3498]\ttraining's auc: 0.944832\ttraining's binary_logloss: 0.16703\n",
      "[3499]\ttraining's auc: 0.94486\ttraining's binary_logloss: 0.167013\n",
      "[3500]\ttraining's auc: 0.944879\ttraining's binary_logloss: 0.166999\n",
      "[3501]\ttraining's auc: 0.944901\ttraining's binary_logloss: 0.166981\n",
      "[3502]\ttraining's auc: 0.944924\ttraining's binary_logloss: 0.166964\n",
      "[3503]\ttraining's auc: 0.944948\ttraining's binary_logloss: 0.166947\n",
      "[3504]\ttraining's auc: 0.944971\ttraining's binary_logloss: 0.16693\n",
      "[3505]\ttraining's auc: 0.944997\ttraining's binary_logloss: 0.166912\n",
      "[3506]\ttraining's auc: 0.945029\ttraining's binary_logloss: 0.166894\n",
      "[3507]\ttraining's auc: 0.945047\ttraining's binary_logloss: 0.166878\n",
      "[3508]\ttraining's auc: 0.945074\ttraining's binary_logloss: 0.166861\n",
      "[3509]\ttraining's auc: 0.945102\ttraining's binary_logloss: 0.166845\n",
      "[3510]\ttraining's auc: 0.945128\ttraining's binary_logloss: 0.166825\n",
      "[3511]\ttraining's auc: 0.945153\ttraining's binary_logloss: 0.166809\n",
      "[3512]\ttraining's auc: 0.945181\ttraining's binary_logloss: 0.16679\n",
      "[3513]\ttraining's auc: 0.945203\ttraining's binary_logloss: 0.166774\n",
      "[3514]\ttraining's auc: 0.945212\ttraining's binary_logloss: 0.166768\n",
      "[3515]\ttraining's auc: 0.945244\ttraining's binary_logloss: 0.166748\n",
      "[3516]\ttraining's auc: 0.945264\ttraining's binary_logloss: 0.16673\n",
      "[3517]\ttraining's auc: 0.94528\ttraining's binary_logloss: 0.166712\n",
      "[3518]\ttraining's auc: 0.9453\ttraining's binary_logloss: 0.166696\n",
      "[3519]\ttraining's auc: 0.945324\ttraining's binary_logloss: 0.166678\n",
      "[3520]\ttraining's auc: 0.945354\ttraining's binary_logloss: 0.166658\n",
      "[3521]\ttraining's auc: 0.945379\ttraining's binary_logloss: 0.166641\n",
      "[3522]\ttraining's auc: 0.9454\ttraining's binary_logloss: 0.166626\n",
      "[3523]\ttraining's auc: 0.945422\ttraining's binary_logloss: 0.166612\n",
      "[3524]\ttraining's auc: 0.945451\ttraining's binary_logloss: 0.166594\n",
      "[3525]\ttraining's auc: 0.945471\ttraining's binary_logloss: 0.166578\n",
      "[3526]\ttraining's auc: 0.945488\ttraining's binary_logloss: 0.166562\n",
      "[3527]\ttraining's auc: 0.945517\ttraining's binary_logloss: 0.166545\n",
      "[3528]\ttraining's auc: 0.945542\ttraining's binary_logloss: 0.16653\n",
      "[3529]\ttraining's auc: 0.945566\ttraining's binary_logloss: 0.166514\n",
      "[3530]\ttraining's auc: 0.945577\ttraining's binary_logloss: 0.166509\n",
      "[3531]\ttraining's auc: 0.945604\ttraining's binary_logloss: 0.166491\n",
      "[3532]\ttraining's auc: 0.945628\ttraining's binary_logloss: 0.166476\n",
      "[3533]\ttraining's auc: 0.945651\ttraining's binary_logloss: 0.166459\n",
      "[3534]\ttraining's auc: 0.945673\ttraining's binary_logloss: 0.166443\n",
      "[3535]\ttraining's auc: 0.945693\ttraining's binary_logloss: 0.166427\n",
      "[3536]\ttraining's auc: 0.945715\ttraining's binary_logloss: 0.16641\n",
      "[3537]\ttraining's auc: 0.945741\ttraining's binary_logloss: 0.166393\n",
      "[3538]\ttraining's auc: 0.945773\ttraining's binary_logloss: 0.166375\n",
      "[3539]\ttraining's auc: 0.945799\ttraining's binary_logloss: 0.166358\n",
      "[3540]\ttraining's auc: 0.94582\ttraining's binary_logloss: 0.166343\n",
      "[3541]\ttraining's auc: 0.945841\ttraining's binary_logloss: 0.166326\n",
      "[3542]\ttraining's auc: 0.945856\ttraining's binary_logloss: 0.16631\n",
      "[3543]\ttraining's auc: 0.945869\ttraining's binary_logloss: 0.166296\n",
      "[3544]\ttraining's auc: 0.945889\ttraining's binary_logloss: 0.166281\n",
      "[3545]\ttraining's auc: 0.945908\ttraining's binary_logloss: 0.166265\n",
      "[3546]\ttraining's auc: 0.945938\ttraining's binary_logloss: 0.16625\n",
      "[3547]\ttraining's auc: 0.945964\ttraining's binary_logloss: 0.166231\n",
      "[3548]\ttraining's auc: 0.945989\ttraining's binary_logloss: 0.166214\n",
      "[3549]\ttraining's auc: 0.946012\ttraining's binary_logloss: 0.166198\n",
      "[3550]\ttraining's auc: 0.946041\ttraining's binary_logloss: 0.166179\n",
      "[3551]\ttraining's auc: 0.946043\ttraining's binary_logloss: 0.166176\n",
      "[3552]\ttraining's auc: 0.946064\ttraining's binary_logloss: 0.16616\n",
      "[3553]\ttraining's auc: 0.946088\ttraining's binary_logloss: 0.166141\n",
      "[3554]\ttraining's auc: 0.946106\ttraining's binary_logloss: 0.166125\n",
      "[3555]\ttraining's auc: 0.946128\ttraining's binary_logloss: 0.166108\n",
      "[3556]\ttraining's auc: 0.946152\ttraining's binary_logloss: 0.166092\n",
      "[3557]\ttraining's auc: 0.946167\ttraining's binary_logloss: 0.16608\n",
      "[3558]\ttraining's auc: 0.94618\ttraining's binary_logloss: 0.166066\n",
      "[3559]\ttraining's auc: 0.946201\ttraining's binary_logloss: 0.16605\n",
      "[3560]\ttraining's auc: 0.946209\ttraining's binary_logloss: 0.166041\n",
      "[3561]\ttraining's auc: 0.946227\ttraining's binary_logloss: 0.166025\n",
      "[3562]\ttraining's auc: 0.94625\ttraining's binary_logloss: 0.16601\n",
      "[3563]\ttraining's auc: 0.946276\ttraining's binary_logloss: 0.165995\n",
      "[3564]\ttraining's auc: 0.946304\ttraining's binary_logloss: 0.165977\n",
      "[3565]\ttraining's auc: 0.946326\ttraining's binary_logloss: 0.165957\n",
      "[3566]\ttraining's auc: 0.946338\ttraining's binary_logloss: 0.165945\n",
      "[3567]\ttraining's auc: 0.946358\ttraining's binary_logloss: 0.16593\n",
      "[3568]\ttraining's auc: 0.946385\ttraining's binary_logloss: 0.165914\n",
      "[3569]\ttraining's auc: 0.946395\ttraining's binary_logloss: 0.165899\n",
      "[3570]\ttraining's auc: 0.946416\ttraining's binary_logloss: 0.165886\n",
      "[3571]\ttraining's auc: 0.946431\ttraining's binary_logloss: 0.165873\n",
      "[3572]\ttraining's auc: 0.946457\ttraining's binary_logloss: 0.165858\n",
      "[3573]\ttraining's auc: 0.946478\ttraining's binary_logloss: 0.165842\n",
      "[3574]\ttraining's auc: 0.946508\ttraining's binary_logloss: 0.165824\n",
      "[3575]\ttraining's auc: 0.946529\ttraining's binary_logloss: 0.165806\n",
      "[3576]\ttraining's auc: 0.946548\ttraining's binary_logloss: 0.165789\n",
      "[3577]\ttraining's auc: 0.946569\ttraining's binary_logloss: 0.165774\n",
      "[3578]\ttraining's auc: 0.946594\ttraining's binary_logloss: 0.16576\n",
      "[3579]\ttraining's auc: 0.946609\ttraining's binary_logloss: 0.165749\n",
      "[3580]\ttraining's auc: 0.946632\ttraining's binary_logloss: 0.165735\n",
      "[3581]\ttraining's auc: 0.946662\ttraining's binary_logloss: 0.165717\n",
      "[3582]\ttraining's auc: 0.946694\ttraining's binary_logloss: 0.165696\n",
      "[3583]\ttraining's auc: 0.946713\ttraining's binary_logloss: 0.165681\n",
      "[3584]\ttraining's auc: 0.946724\ttraining's binary_logloss: 0.165672\n",
      "[3585]\ttraining's auc: 0.946742\ttraining's binary_logloss: 0.165661\n",
      "[3586]\ttraining's auc: 0.946769\ttraining's binary_logloss: 0.165644\n",
      "[3587]\ttraining's auc: 0.946795\ttraining's binary_logloss: 0.165625\n",
      "[3588]\ttraining's auc: 0.946809\ttraining's binary_logloss: 0.165611\n",
      "[3589]\ttraining's auc: 0.946834\ttraining's binary_logloss: 0.165596\n",
      "[3590]\ttraining's auc: 0.94685\ttraining's binary_logloss: 0.16558\n",
      "[3591]\ttraining's auc: 0.946872\ttraining's binary_logloss: 0.165568\n",
      "[3592]\ttraining's auc: 0.946895\ttraining's binary_logloss: 0.165553\n",
      "[3593]\ttraining's auc: 0.946918\ttraining's binary_logloss: 0.165533\n",
      "[3594]\ttraining's auc: 0.946941\ttraining's binary_logloss: 0.165516\n",
      "[3595]\ttraining's auc: 0.946973\ttraining's binary_logloss: 0.1655\n",
      "[3596]\ttraining's auc: 0.946998\ttraining's binary_logloss: 0.165481\n",
      "[3597]\ttraining's auc: 0.947022\ttraining's binary_logloss: 0.165465\n",
      "[3598]\ttraining's auc: 0.947045\ttraining's binary_logloss: 0.16545\n",
      "[3599]\ttraining's auc: 0.947064\ttraining's binary_logloss: 0.165435\n",
      "[3600]\ttraining's auc: 0.94708\ttraining's binary_logloss: 0.165419\n",
      "[3601]\ttraining's auc: 0.947087\ttraining's binary_logloss: 0.165413\n",
      "[3602]\ttraining's auc: 0.947107\ttraining's binary_logloss: 0.165397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3603]\ttraining's auc: 0.94712\ttraining's binary_logloss: 0.165383\n",
      "[3604]\ttraining's auc: 0.947144\ttraining's binary_logloss: 0.165364\n",
      "[3605]\ttraining's auc: 0.947166\ttraining's binary_logloss: 0.165348\n",
      "[3606]\ttraining's auc: 0.947204\ttraining's binary_logloss: 0.16533\n",
      "[3607]\ttraining's auc: 0.94722\ttraining's binary_logloss: 0.165314\n",
      "[3608]\ttraining's auc: 0.947252\ttraining's binary_logloss: 0.165293\n",
      "[3609]\ttraining's auc: 0.947264\ttraining's binary_logloss: 0.165284\n",
      "[3610]\ttraining's auc: 0.947279\ttraining's binary_logloss: 0.165269\n",
      "[3611]\ttraining's auc: 0.947302\ttraining's binary_logloss: 0.165254\n",
      "[3612]\ttraining's auc: 0.947321\ttraining's binary_logloss: 0.165239\n",
      "[3613]\ttraining's auc: 0.947343\ttraining's binary_logloss: 0.165222\n",
      "[3614]\ttraining's auc: 0.947371\ttraining's binary_logloss: 0.165202\n",
      "[3615]\ttraining's auc: 0.947388\ttraining's binary_logloss: 0.165186\n",
      "[3616]\ttraining's auc: 0.947406\ttraining's binary_logloss: 0.165174\n",
      "[3617]\ttraining's auc: 0.947424\ttraining's binary_logloss: 0.16516\n",
      "[3618]\ttraining's auc: 0.947437\ttraining's binary_logloss: 0.16515\n",
      "[3619]\ttraining's auc: 0.947463\ttraining's binary_logloss: 0.165136\n",
      "[3620]\ttraining's auc: 0.947496\ttraining's binary_logloss: 0.165121\n",
      "[3621]\ttraining's auc: 0.947511\ttraining's binary_logloss: 0.165104\n",
      "[3622]\ttraining's auc: 0.947534\ttraining's binary_logloss: 0.16509\n",
      "[3623]\ttraining's auc: 0.947562\ttraining's binary_logloss: 0.165072\n",
      "[3624]\ttraining's auc: 0.947583\ttraining's binary_logloss: 0.165056\n",
      "[3625]\ttraining's auc: 0.94761\ttraining's binary_logloss: 0.16504\n",
      "[3626]\ttraining's auc: 0.947629\ttraining's binary_logloss: 0.165024\n",
      "[3627]\ttraining's auc: 0.947648\ttraining's binary_logloss: 0.165012\n",
      "[3628]\ttraining's auc: 0.947663\ttraining's binary_logloss: 0.165003\n",
      "[3629]\ttraining's auc: 0.947685\ttraining's binary_logloss: 0.164986\n",
      "[3630]\ttraining's auc: 0.947694\ttraining's binary_logloss: 0.164976\n",
      "[3631]\ttraining's auc: 0.947712\ttraining's binary_logloss: 0.164961\n",
      "[3632]\ttraining's auc: 0.947728\ttraining's binary_logloss: 0.164945\n",
      "[3633]\ttraining's auc: 0.947756\ttraining's binary_logloss: 0.164925\n",
      "[3634]\ttraining's auc: 0.947776\ttraining's binary_logloss: 0.164907\n",
      "[3635]\ttraining's auc: 0.947794\ttraining's binary_logloss: 0.164893\n",
      "[3636]\ttraining's auc: 0.947813\ttraining's binary_logloss: 0.16488\n",
      "[3637]\ttraining's auc: 0.947838\ttraining's binary_logloss: 0.164864\n",
      "[3638]\ttraining's auc: 0.947841\ttraining's binary_logloss: 0.164861\n",
      "[3639]\ttraining's auc: 0.94788\ttraining's binary_logloss: 0.164841\n",
      "[3640]\ttraining's auc: 0.947891\ttraining's binary_logloss: 0.164831\n",
      "[3641]\ttraining's auc: 0.947911\ttraining's binary_logloss: 0.164813\n",
      "[3642]\ttraining's auc: 0.947937\ttraining's binary_logloss: 0.164797\n",
      "[3643]\ttraining's auc: 0.947958\ttraining's binary_logloss: 0.164779\n",
      "[3644]\ttraining's auc: 0.947976\ttraining's binary_logloss: 0.164764\n",
      "[3645]\ttraining's auc: 0.948005\ttraining's binary_logloss: 0.164746\n",
      "[3646]\ttraining's auc: 0.948031\ttraining's binary_logloss: 0.164728\n",
      "[3647]\ttraining's auc: 0.948051\ttraining's binary_logloss: 0.164712\n",
      "[3648]\ttraining's auc: 0.948071\ttraining's binary_logloss: 0.164698\n",
      "[3649]\ttraining's auc: 0.94809\ttraining's binary_logloss: 0.164683\n",
      "[3650]\ttraining's auc: 0.94811\ttraining's binary_logloss: 0.164665\n",
      "[3651]\ttraining's auc: 0.948135\ttraining's binary_logloss: 0.164647\n",
      "[3652]\ttraining's auc: 0.948161\ttraining's binary_logloss: 0.164631\n",
      "[3653]\ttraining's auc: 0.948184\ttraining's binary_logloss: 0.164614\n",
      "[3654]\ttraining's auc: 0.948208\ttraining's binary_logloss: 0.164597\n",
      "[3655]\ttraining's auc: 0.948233\ttraining's binary_logloss: 0.16458\n",
      "[3656]\ttraining's auc: 0.948247\ttraining's binary_logloss: 0.164566\n",
      "[3657]\ttraining's auc: 0.948267\ttraining's binary_logloss: 0.164552\n",
      "[3658]\ttraining's auc: 0.948287\ttraining's binary_logloss: 0.16454\n",
      "[3659]\ttraining's auc: 0.948312\ttraining's binary_logloss: 0.164523\n",
      "[3660]\ttraining's auc: 0.948327\ttraining's binary_logloss: 0.164506\n",
      "[3661]\ttraining's auc: 0.948352\ttraining's binary_logloss: 0.16449\n",
      "[3662]\ttraining's auc: 0.948378\ttraining's binary_logloss: 0.164474\n",
      "[3663]\ttraining's auc: 0.948393\ttraining's binary_logloss: 0.164456\n",
      "[3664]\ttraining's auc: 0.948421\ttraining's binary_logloss: 0.164439\n",
      "[3665]\ttraining's auc: 0.948444\ttraining's binary_logloss: 0.164425\n",
      "[3666]\ttraining's auc: 0.948465\ttraining's binary_logloss: 0.16441\n",
      "[3667]\ttraining's auc: 0.948483\ttraining's binary_logloss: 0.164392\n",
      "[3668]\ttraining's auc: 0.948505\ttraining's binary_logloss: 0.164376\n",
      "[3669]\ttraining's auc: 0.948528\ttraining's binary_logloss: 0.164359\n",
      "[3670]\ttraining's auc: 0.948555\ttraining's binary_logloss: 0.164344\n",
      "[3671]\ttraining's auc: 0.948593\ttraining's binary_logloss: 0.164324\n",
      "[3672]\ttraining's auc: 0.94862\ttraining's binary_logloss: 0.164307\n",
      "[3673]\ttraining's auc: 0.948639\ttraining's binary_logloss: 0.16429\n",
      "[3674]\ttraining's auc: 0.948667\ttraining's binary_logloss: 0.164274\n",
      "[3675]\ttraining's auc: 0.948686\ttraining's binary_logloss: 0.164261\n",
      "[3676]\ttraining's auc: 0.948718\ttraining's binary_logloss: 0.16424\n",
      "[3677]\ttraining's auc: 0.948734\ttraining's binary_logloss: 0.16423\n",
      "[3678]\ttraining's auc: 0.948746\ttraining's binary_logloss: 0.164218\n",
      "[3679]\ttraining's auc: 0.94876\ttraining's binary_logloss: 0.164209\n",
      "[3680]\ttraining's auc: 0.948783\ttraining's binary_logloss: 0.164192\n",
      "[3681]\ttraining's auc: 0.948797\ttraining's binary_logloss: 0.164178\n",
      "[3682]\ttraining's auc: 0.948834\ttraining's binary_logloss: 0.164159\n",
      "[3683]\ttraining's auc: 0.948866\ttraining's binary_logloss: 0.164143\n",
      "[3684]\ttraining's auc: 0.948886\ttraining's binary_logloss: 0.164126\n",
      "[3685]\ttraining's auc: 0.948898\ttraining's binary_logloss: 0.164115\n",
      "[3686]\ttraining's auc: 0.948917\ttraining's binary_logloss: 0.164104\n",
      "[3687]\ttraining's auc: 0.948945\ttraining's binary_logloss: 0.164087\n",
      "[3688]\ttraining's auc: 0.948953\ttraining's binary_logloss: 0.164079\n",
      "[3689]\ttraining's auc: 0.948969\ttraining's binary_logloss: 0.164067\n",
      "[3690]\ttraining's auc: 0.948983\ttraining's binary_logloss: 0.164057\n",
      "[3691]\ttraining's auc: 0.949004\ttraining's binary_logloss: 0.164041\n",
      "[3692]\ttraining's auc: 0.949022\ttraining's binary_logloss: 0.164025\n",
      "[3693]\ttraining's auc: 0.949042\ttraining's binary_logloss: 0.164008\n",
      "[3694]\ttraining's auc: 0.949063\ttraining's binary_logloss: 0.163993\n",
      "[3695]\ttraining's auc: 0.949078\ttraining's binary_logloss: 0.16398\n",
      "[3696]\ttraining's auc: 0.949107\ttraining's binary_logloss: 0.163961\n",
      "[3697]\ttraining's auc: 0.949128\ttraining's binary_logloss: 0.163941\n",
      "[3698]\ttraining's auc: 0.949146\ttraining's binary_logloss: 0.163925\n",
      "[3699]\ttraining's auc: 0.949174\ttraining's binary_logloss: 0.163909\n",
      "[3700]\ttraining's auc: 0.949204\ttraining's binary_logloss: 0.163893\n",
      "[3701]\ttraining's auc: 0.94922\ttraining's binary_logloss: 0.163876\n",
      "[3702]\ttraining's auc: 0.94924\ttraining's binary_logloss: 0.163856\n",
      "[3703]\ttraining's auc: 0.949266\ttraining's binary_logloss: 0.163836\n",
      "[3704]\ttraining's auc: 0.949288\ttraining's binary_logloss: 0.16382\n",
      "[3705]\ttraining's auc: 0.949322\ttraining's binary_logloss: 0.163801\n",
      "[3706]\ttraining's auc: 0.94934\ttraining's binary_logloss: 0.16379\n",
      "[3707]\ttraining's auc: 0.949348\ttraining's binary_logloss: 0.163782\n",
      "[3708]\ttraining's auc: 0.949376\ttraining's binary_logloss: 0.163764\n",
      "[3709]\ttraining's auc: 0.949401\ttraining's binary_logloss: 0.163748\n",
      "[3710]\ttraining's auc: 0.949405\ttraining's binary_logloss: 0.163745\n",
      "[3711]\ttraining's auc: 0.949409\ttraining's binary_logloss: 0.163741\n",
      "[3712]\ttraining's auc: 0.949429\ttraining's binary_logloss: 0.163726\n",
      "[3713]\ttraining's auc: 0.949456\ttraining's binary_logloss: 0.163707\n",
      "[3714]\ttraining's auc: 0.949465\ttraining's binary_logloss: 0.163702\n",
      "[3715]\ttraining's auc: 0.94948\ttraining's binary_logloss: 0.163686\n",
      "[3716]\ttraining's auc: 0.949505\ttraining's binary_logloss: 0.163668\n",
      "[3717]\ttraining's auc: 0.949519\ttraining's binary_logloss: 0.163658\n",
      "[3718]\ttraining's auc: 0.949538\ttraining's binary_logloss: 0.163641\n",
      "[3719]\ttraining's auc: 0.949558\ttraining's binary_logloss: 0.163627\n",
      "[3720]\ttraining's auc: 0.949588\ttraining's binary_logloss: 0.163608\n",
      "[3721]\ttraining's auc: 0.949609\ttraining's binary_logloss: 0.163592\n",
      "[3722]\ttraining's auc: 0.949623\ttraining's binary_logloss: 0.163577\n",
      "[3723]\ttraining's auc: 0.949645\ttraining's binary_logloss: 0.16356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3724]\ttraining's auc: 0.949665\ttraining's binary_logloss: 0.163547\n",
      "[3725]\ttraining's auc: 0.949688\ttraining's binary_logloss: 0.163533\n",
      "[3726]\ttraining's auc: 0.949709\ttraining's binary_logloss: 0.163519\n",
      "[3727]\ttraining's auc: 0.94973\ttraining's binary_logloss: 0.163503\n",
      "[3728]\ttraining's auc: 0.949763\ttraining's binary_logloss: 0.163485\n",
      "[3729]\ttraining's auc: 0.949775\ttraining's binary_logloss: 0.163479\n",
      "[3730]\ttraining's auc: 0.949803\ttraining's binary_logloss: 0.163464\n",
      "[3731]\ttraining's auc: 0.949806\ttraining's binary_logloss: 0.16346\n",
      "[3732]\ttraining's auc: 0.94983\ttraining's binary_logloss: 0.16344\n",
      "[3733]\ttraining's auc: 0.94985\ttraining's binary_logloss: 0.163426\n",
      "[3734]\ttraining's auc: 0.949874\ttraining's binary_logloss: 0.163409\n",
      "[3735]\ttraining's auc: 0.949898\ttraining's binary_logloss: 0.163391\n",
      "[3736]\ttraining's auc: 0.949918\ttraining's binary_logloss: 0.163375\n",
      "[3737]\ttraining's auc: 0.94992\ttraining's binary_logloss: 0.163373\n",
      "[3738]\ttraining's auc: 0.949945\ttraining's binary_logloss: 0.163355\n",
      "[3739]\ttraining's auc: 0.949969\ttraining's binary_logloss: 0.16334\n",
      "[3740]\ttraining's auc: 0.949991\ttraining's binary_logloss: 0.163323\n",
      "[3741]\ttraining's auc: 0.950019\ttraining's binary_logloss: 0.163306\n",
      "[3742]\ttraining's auc: 0.950031\ttraining's binary_logloss: 0.163297\n",
      "[3743]\ttraining's auc: 0.950043\ttraining's binary_logloss: 0.163288\n",
      "[3744]\ttraining's auc: 0.950074\ttraining's binary_logloss: 0.163272\n",
      "[3745]\ttraining's auc: 0.950093\ttraining's binary_logloss: 0.163256\n",
      "[3746]\ttraining's auc: 0.950123\ttraining's binary_logloss: 0.163239\n",
      "[3747]\ttraining's auc: 0.950149\ttraining's binary_logloss: 0.163223\n",
      "[3748]\ttraining's auc: 0.950171\ttraining's binary_logloss: 0.163203\n",
      "[3749]\ttraining's auc: 0.950173\ttraining's binary_logloss: 0.163201\n",
      "[3750]\ttraining's auc: 0.95019\ttraining's binary_logloss: 0.163188\n",
      "[3751]\ttraining's auc: 0.950193\ttraining's binary_logloss: 0.163186\n",
      "[3752]\ttraining's auc: 0.950215\ttraining's binary_logloss: 0.163169\n",
      "[3753]\ttraining's auc: 0.950233\ttraining's binary_logloss: 0.163152\n",
      "[3754]\ttraining's auc: 0.950249\ttraining's binary_logloss: 0.163142\n",
      "[3755]\ttraining's auc: 0.950272\ttraining's binary_logloss: 0.163125\n",
      "[3756]\ttraining's auc: 0.950287\ttraining's binary_logloss: 0.163112\n",
      "[3757]\ttraining's auc: 0.950309\ttraining's binary_logloss: 0.163096\n",
      "[3758]\ttraining's auc: 0.95033\ttraining's binary_logloss: 0.163079\n",
      "[3759]\ttraining's auc: 0.950345\ttraining's binary_logloss: 0.163069\n",
      "[3760]\ttraining's auc: 0.950355\ttraining's binary_logloss: 0.16306\n",
      "[3761]\ttraining's auc: 0.950379\ttraining's binary_logloss: 0.163046\n",
      "[3762]\ttraining's auc: 0.950389\ttraining's binary_logloss: 0.163038\n",
      "[3763]\ttraining's auc: 0.950405\ttraining's binary_logloss: 0.163023\n",
      "[3764]\ttraining's auc: 0.950425\ttraining's binary_logloss: 0.163007\n",
      "[3765]\ttraining's auc: 0.950428\ttraining's binary_logloss: 0.163004\n",
      "[3766]\ttraining's auc: 0.950453\ttraining's binary_logloss: 0.162988\n",
      "[3767]\ttraining's auc: 0.950473\ttraining's binary_logloss: 0.16297\n",
      "[3768]\ttraining's auc: 0.950496\ttraining's binary_logloss: 0.162954\n",
      "[3769]\ttraining's auc: 0.950512\ttraining's binary_logloss: 0.162938\n",
      "[3770]\ttraining's auc: 0.950521\ttraining's binary_logloss: 0.162931\n",
      "[3771]\ttraining's auc: 0.950541\ttraining's binary_logloss: 0.162915\n",
      "[3772]\ttraining's auc: 0.950561\ttraining's binary_logloss: 0.162902\n",
      "[3773]\ttraining's auc: 0.950582\ttraining's binary_logloss: 0.162886\n",
      "[3774]\ttraining's auc: 0.950588\ttraining's binary_logloss: 0.162874\n",
      "[3775]\ttraining's auc: 0.950614\ttraining's binary_logloss: 0.162855\n",
      "[3776]\ttraining's auc: 0.950643\ttraining's binary_logloss: 0.162839\n",
      "[3777]\ttraining's auc: 0.950647\ttraining's binary_logloss: 0.162834\n",
      "[3778]\ttraining's auc: 0.950674\ttraining's binary_logloss: 0.162815\n",
      "[3779]\ttraining's auc: 0.950699\ttraining's binary_logloss: 0.162797\n",
      "[3780]\ttraining's auc: 0.950725\ttraining's binary_logloss: 0.162782\n",
      "[3781]\ttraining's auc: 0.950753\ttraining's binary_logloss: 0.162766\n",
      "[3782]\ttraining's auc: 0.950776\ttraining's binary_logloss: 0.162749\n",
      "[3783]\ttraining's auc: 0.9508\ttraining's binary_logloss: 0.162732\n",
      "[3784]\ttraining's auc: 0.950815\ttraining's binary_logloss: 0.16272\n",
      "[3785]\ttraining's auc: 0.950837\ttraining's binary_logloss: 0.162705\n",
      "[3786]\ttraining's auc: 0.950841\ttraining's binary_logloss: 0.162701\n",
      "[3787]\ttraining's auc: 0.950851\ttraining's binary_logloss: 0.162693\n",
      "[3788]\ttraining's auc: 0.950867\ttraining's binary_logloss: 0.162678\n",
      "[3789]\ttraining's auc: 0.950888\ttraining's binary_logloss: 0.162661\n",
      "[3790]\ttraining's auc: 0.950913\ttraining's binary_logloss: 0.162644\n",
      "[3791]\ttraining's auc: 0.950925\ttraining's binary_logloss: 0.162632\n",
      "[3792]\ttraining's auc: 0.950944\ttraining's binary_logloss: 0.162616\n",
      "[3793]\ttraining's auc: 0.950964\ttraining's binary_logloss: 0.162602\n",
      "[3794]\ttraining's auc: 0.950988\ttraining's binary_logloss: 0.162586\n",
      "[3795]\ttraining's auc: 0.951009\ttraining's binary_logloss: 0.162569\n",
      "[3796]\ttraining's auc: 0.951015\ttraining's binary_logloss: 0.162564\n",
      "[3797]\ttraining's auc: 0.951035\ttraining's binary_logloss: 0.16255\n",
      "[3798]\ttraining's auc: 0.951049\ttraining's binary_logloss: 0.16254\n",
      "[3799]\ttraining's auc: 0.951076\ttraining's binary_logloss: 0.162522\n",
      "[3800]\ttraining's auc: 0.951078\ttraining's binary_logloss: 0.16252\n",
      "[3801]\ttraining's auc: 0.951085\ttraining's binary_logloss: 0.162516\n",
      "[3802]\ttraining's auc: 0.951098\ttraining's binary_logloss: 0.162503\n",
      "[3803]\ttraining's auc: 0.951115\ttraining's binary_logloss: 0.162493\n",
      "[3804]\ttraining's auc: 0.951123\ttraining's binary_logloss: 0.162484\n",
      "[3805]\ttraining's auc: 0.951151\ttraining's binary_logloss: 0.162466\n",
      "[3806]\ttraining's auc: 0.951175\ttraining's binary_logloss: 0.16245\n",
      "[3807]\ttraining's auc: 0.951202\ttraining's binary_logloss: 0.162431\n",
      "[3808]\ttraining's auc: 0.951216\ttraining's binary_logloss: 0.162421\n",
      "[3809]\ttraining's auc: 0.95124\ttraining's binary_logloss: 0.162405\n",
      "[3810]\ttraining's auc: 0.951265\ttraining's binary_logloss: 0.162387\n",
      "[3811]\ttraining's auc: 0.95129\ttraining's binary_logloss: 0.162371\n",
      "[3812]\ttraining's auc: 0.951308\ttraining's binary_logloss: 0.162356\n",
      "[3813]\ttraining's auc: 0.951314\ttraining's binary_logloss: 0.162351\n",
      "[3814]\ttraining's auc: 0.951341\ttraining's binary_logloss: 0.162333\n",
      "[3815]\ttraining's auc: 0.951362\ttraining's binary_logloss: 0.162316\n",
      "[3816]\ttraining's auc: 0.951383\ttraining's binary_logloss: 0.162301\n",
      "[3817]\ttraining's auc: 0.951405\ttraining's binary_logloss: 0.162283\n",
      "[3818]\ttraining's auc: 0.951428\ttraining's binary_logloss: 0.162265\n",
      "[3819]\ttraining's auc: 0.951452\ttraining's binary_logloss: 0.16225\n",
      "[3820]\ttraining's auc: 0.951462\ttraining's binary_logloss: 0.16224\n",
      "[3821]\ttraining's auc: 0.951481\ttraining's binary_logloss: 0.162225\n",
      "[3822]\ttraining's auc: 0.951499\ttraining's binary_logloss: 0.162212\n",
      "[3823]\ttraining's auc: 0.951518\ttraining's binary_logloss: 0.162196\n",
      "[3824]\ttraining's auc: 0.951535\ttraining's binary_logloss: 0.162181\n",
      "[3825]\ttraining's auc: 0.951559\ttraining's binary_logloss: 0.162161\n",
      "[3826]\ttraining's auc: 0.951569\ttraining's binary_logloss: 0.162154\n",
      "[3827]\ttraining's auc: 0.951572\ttraining's binary_logloss: 0.16215\n",
      "[3828]\ttraining's auc: 0.951589\ttraining's binary_logloss: 0.162137\n",
      "[3829]\ttraining's auc: 0.951614\ttraining's binary_logloss: 0.16212\n",
      "[3830]\ttraining's auc: 0.951634\ttraining's binary_logloss: 0.162104\n",
      "[3831]\ttraining's auc: 0.951645\ttraining's binary_logloss: 0.162094\n",
      "[3832]\ttraining's auc: 0.95165\ttraining's binary_logloss: 0.162091\n",
      "[3833]\ttraining's auc: 0.951668\ttraining's binary_logloss: 0.162074\n",
      "[3834]\ttraining's auc: 0.951688\ttraining's binary_logloss: 0.162059\n",
      "[3835]\ttraining's auc: 0.951717\ttraining's binary_logloss: 0.16204\n",
      "[3836]\ttraining's auc: 0.951736\ttraining's binary_logloss: 0.162025\n",
      "[3837]\ttraining's auc: 0.951744\ttraining's binary_logloss: 0.162017\n",
      "[3838]\ttraining's auc: 0.95175\ttraining's binary_logloss: 0.162012\n",
      "[3839]\ttraining's auc: 0.951773\ttraining's binary_logloss: 0.161995\n",
      "[3840]\ttraining's auc: 0.95179\ttraining's binary_logloss: 0.161978\n",
      "[3841]\ttraining's auc: 0.951811\ttraining's binary_logloss: 0.161962\n",
      "[3842]\ttraining's auc: 0.951833\ttraining's binary_logloss: 0.161944\n",
      "[3843]\ttraining's auc: 0.95185\ttraining's binary_logloss: 0.161934\n",
      "[3844]\ttraining's auc: 0.951871\ttraining's binary_logloss: 0.161918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3845]\ttraining's auc: 0.951881\ttraining's binary_logloss: 0.16191\n",
      "[3846]\ttraining's auc: 0.951886\ttraining's binary_logloss: 0.161905\n",
      "[3847]\ttraining's auc: 0.951888\ttraining's binary_logloss: 0.161902\n",
      "[3848]\ttraining's auc: 0.951908\ttraining's binary_logloss: 0.161887\n",
      "[3849]\ttraining's auc: 0.95193\ttraining's binary_logloss: 0.161872\n",
      "[3850]\ttraining's auc: 0.95194\ttraining's binary_logloss: 0.161863\n",
      "[3851]\ttraining's auc: 0.951953\ttraining's binary_logloss: 0.161857\n",
      "[3852]\ttraining's auc: 0.95197\ttraining's binary_logloss: 0.161846\n",
      "[3853]\ttraining's auc: 0.951988\ttraining's binary_logloss: 0.16183\n",
      "[3854]\ttraining's auc: 0.952012\ttraining's binary_logloss: 0.161814\n",
      "[3855]\ttraining's auc: 0.952035\ttraining's binary_logloss: 0.161795\n",
      "[3856]\ttraining's auc: 0.952056\ttraining's binary_logloss: 0.161779\n",
      "[3857]\ttraining's auc: 0.952085\ttraining's binary_logloss: 0.161759\n",
      "[3858]\ttraining's auc: 0.952104\ttraining's binary_logloss: 0.161742\n",
      "[3859]\ttraining's auc: 0.952122\ttraining's binary_logloss: 0.161726\n",
      "[3860]\ttraining's auc: 0.952145\ttraining's binary_logloss: 0.161711\n",
      "[3861]\ttraining's auc: 0.952165\ttraining's binary_logloss: 0.161696\n",
      "[3862]\ttraining's auc: 0.952194\ttraining's binary_logloss: 0.161677\n",
      "[3863]\ttraining's auc: 0.952215\ttraining's binary_logloss: 0.161663\n",
      "[3864]\ttraining's auc: 0.952238\ttraining's binary_logloss: 0.161646\n",
      "[3865]\ttraining's auc: 0.952263\ttraining's binary_logloss: 0.16163\n",
      "[3866]\ttraining's auc: 0.952281\ttraining's binary_logloss: 0.161618\n",
      "[3867]\ttraining's auc: 0.952299\ttraining's binary_logloss: 0.161604\n",
      "[3868]\ttraining's auc: 0.952317\ttraining's binary_logloss: 0.161593\n",
      "[3869]\ttraining's auc: 0.952345\ttraining's binary_logloss: 0.161574\n",
      "[3870]\ttraining's auc: 0.952368\ttraining's binary_logloss: 0.161557\n",
      "[3871]\ttraining's auc: 0.952388\ttraining's binary_logloss: 0.161539\n",
      "[3872]\ttraining's auc: 0.952413\ttraining's binary_logloss: 0.161524\n",
      "[3873]\ttraining's auc: 0.952436\ttraining's binary_logloss: 0.161508\n",
      "[3874]\ttraining's auc: 0.952455\ttraining's binary_logloss: 0.161496\n",
      "[3875]\ttraining's auc: 0.952475\ttraining's binary_logloss: 0.161482\n",
      "[3876]\ttraining's auc: 0.952482\ttraining's binary_logloss: 0.161475\n",
      "[3877]\ttraining's auc: 0.952497\ttraining's binary_logloss: 0.161461\n",
      "[3878]\ttraining's auc: 0.952519\ttraining's binary_logloss: 0.161445\n",
      "[3879]\ttraining's auc: 0.952538\ttraining's binary_logloss: 0.161428\n",
      "[3880]\ttraining's auc: 0.95256\ttraining's binary_logloss: 0.161412\n",
      "[3881]\ttraining's auc: 0.952575\ttraining's binary_logloss: 0.161396\n",
      "[3882]\ttraining's auc: 0.95259\ttraining's binary_logloss: 0.161386\n",
      "[3883]\ttraining's auc: 0.952609\ttraining's binary_logloss: 0.161372\n",
      "[3884]\ttraining's auc: 0.952629\ttraining's binary_logloss: 0.161356\n",
      "[3885]\ttraining's auc: 0.952644\ttraining's binary_logloss: 0.161342\n",
      "[3886]\ttraining's auc: 0.952673\ttraining's binary_logloss: 0.161325\n",
      "[3887]\ttraining's auc: 0.952703\ttraining's binary_logloss: 0.161309\n",
      "[3888]\ttraining's auc: 0.952718\ttraining's binary_logloss: 0.161293\n",
      "[3889]\ttraining's auc: 0.952737\ttraining's binary_logloss: 0.16128\n",
      "[3890]\ttraining's auc: 0.952758\ttraining's binary_logloss: 0.161264\n",
      "[3891]\ttraining's auc: 0.952773\ttraining's binary_logloss: 0.161249\n",
      "[3892]\ttraining's auc: 0.952796\ttraining's binary_logloss: 0.161233\n",
      "[3893]\ttraining's auc: 0.95281\ttraining's binary_logloss: 0.161222\n",
      "[3894]\ttraining's auc: 0.952827\ttraining's binary_logloss: 0.161206\n",
      "[3895]\ttraining's auc: 0.952845\ttraining's binary_logloss: 0.161191\n",
      "[3896]\ttraining's auc: 0.95286\ttraining's binary_logloss: 0.161176\n",
      "[3897]\ttraining's auc: 0.952879\ttraining's binary_logloss: 0.161164\n",
      "[3898]\ttraining's auc: 0.952898\ttraining's binary_logloss: 0.161149\n",
      "[3899]\ttraining's auc: 0.952916\ttraining's binary_logloss: 0.161134\n",
      "[3900]\ttraining's auc: 0.952932\ttraining's binary_logloss: 0.161116\n",
      "[3901]\ttraining's auc: 0.952948\ttraining's binary_logloss: 0.1611\n",
      "[3902]\ttraining's auc: 0.952977\ttraining's binary_logloss: 0.161082\n",
      "[3903]\ttraining's auc: 0.952998\ttraining's binary_logloss: 0.161066\n",
      "[3904]\ttraining's auc: 0.953016\ttraining's binary_logloss: 0.161051\n",
      "[3905]\ttraining's auc: 0.953036\ttraining's binary_logloss: 0.161038\n",
      "[3906]\ttraining's auc: 0.953061\ttraining's binary_logloss: 0.161022\n",
      "[3907]\ttraining's auc: 0.953074\ttraining's binary_logloss: 0.161008\n",
      "[3908]\ttraining's auc: 0.95308\ttraining's binary_logloss: 0.161005\n",
      "[3909]\ttraining's auc: 0.953085\ttraining's binary_logloss: 0.160999\n",
      "[3910]\ttraining's auc: 0.9531\ttraining's binary_logloss: 0.160986\n",
      "[3911]\ttraining's auc: 0.953108\ttraining's binary_logloss: 0.16098\n",
      "[3912]\ttraining's auc: 0.953127\ttraining's binary_logloss: 0.160968\n",
      "[3913]\ttraining's auc: 0.95316\ttraining's binary_logloss: 0.16095\n",
      "[3914]\ttraining's auc: 0.95318\ttraining's binary_logloss: 0.160935\n",
      "[3915]\ttraining's auc: 0.953198\ttraining's binary_logloss: 0.160921\n",
      "[3916]\ttraining's auc: 0.953213\ttraining's binary_logloss: 0.160909\n",
      "[3917]\ttraining's auc: 0.953225\ttraining's binary_logloss: 0.160897\n",
      "[3918]\ttraining's auc: 0.953244\ttraining's binary_logloss: 0.160886\n",
      "[3919]\ttraining's auc: 0.953259\ttraining's binary_logloss: 0.160876\n",
      "[3920]\ttraining's auc: 0.953273\ttraining's binary_logloss: 0.160859\n",
      "[3921]\ttraining's auc: 0.953287\ttraining's binary_logloss: 0.160844\n",
      "[3922]\ttraining's auc: 0.953305\ttraining's binary_logloss: 0.160829\n",
      "[3923]\ttraining's auc: 0.953325\ttraining's binary_logloss: 0.160813\n",
      "[3924]\ttraining's auc: 0.953335\ttraining's binary_logloss: 0.160802\n",
      "[3925]\ttraining's auc: 0.953359\ttraining's binary_logloss: 0.160785\n",
      "[3926]\ttraining's auc: 0.953377\ttraining's binary_logloss: 0.160769\n",
      "[3927]\ttraining's auc: 0.953392\ttraining's binary_logloss: 0.160758\n",
      "[3928]\ttraining's auc: 0.953414\ttraining's binary_logloss: 0.160742\n",
      "[3929]\ttraining's auc: 0.953433\ttraining's binary_logloss: 0.160727\n",
      "[3930]\ttraining's auc: 0.953453\ttraining's binary_logloss: 0.160712\n",
      "[3931]\ttraining's auc: 0.953466\ttraining's binary_logloss: 0.160701\n",
      "[3932]\ttraining's auc: 0.953483\ttraining's binary_logloss: 0.160685\n",
      "[3933]\ttraining's auc: 0.953494\ttraining's binary_logloss: 0.160675\n",
      "[3934]\ttraining's auc: 0.953512\ttraining's binary_logloss: 0.16066\n",
      "[3935]\ttraining's auc: 0.95352\ttraining's binary_logloss: 0.160654\n",
      "[3936]\ttraining's auc: 0.953537\ttraining's binary_logloss: 0.160638\n",
      "[3937]\ttraining's auc: 0.953554\ttraining's binary_logloss: 0.160626\n",
      "[3938]\ttraining's auc: 0.953559\ttraining's binary_logloss: 0.160619\n",
      "[3939]\ttraining's auc: 0.953583\ttraining's binary_logloss: 0.160601\n",
      "[3940]\ttraining's auc: 0.953608\ttraining's binary_logloss: 0.160585\n",
      "[3941]\ttraining's auc: 0.953627\ttraining's binary_logloss: 0.160572\n",
      "[3942]\ttraining's auc: 0.953647\ttraining's binary_logloss: 0.160558\n",
      "[3943]\ttraining's auc: 0.953663\ttraining's binary_logloss: 0.160545\n",
      "[3944]\ttraining's auc: 0.953692\ttraining's binary_logloss: 0.160528\n",
      "[3945]\ttraining's auc: 0.953713\ttraining's binary_logloss: 0.160511\n",
      "[3946]\ttraining's auc: 0.953737\ttraining's binary_logloss: 0.160494\n",
      "[3947]\ttraining's auc: 0.95376\ttraining's binary_logloss: 0.160478\n",
      "[3948]\ttraining's auc: 0.953778\ttraining's binary_logloss: 0.160463\n",
      "[3949]\ttraining's auc: 0.953807\ttraining's binary_logloss: 0.160445\n",
      "[3950]\ttraining's auc: 0.953823\ttraining's binary_logloss: 0.160429\n",
      "[3951]\ttraining's auc: 0.95384\ttraining's binary_logloss: 0.160416\n",
      "[3952]\ttraining's auc: 0.953847\ttraining's binary_logloss: 0.16041\n",
      "[3953]\ttraining's auc: 0.953859\ttraining's binary_logloss: 0.1604\n",
      "[3954]\ttraining's auc: 0.953885\ttraining's binary_logloss: 0.160385\n",
      "[3955]\ttraining's auc: 0.953891\ttraining's binary_logloss: 0.160378\n",
      "[3956]\ttraining's auc: 0.953923\ttraining's binary_logloss: 0.160359\n",
      "[3957]\ttraining's auc: 0.95394\ttraining's binary_logloss: 0.160343\n",
      "[3958]\ttraining's auc: 0.953958\ttraining's binary_logloss: 0.160327\n",
      "[3959]\ttraining's auc: 0.953983\ttraining's binary_logloss: 0.160311\n",
      "[3960]\ttraining's auc: 0.953993\ttraining's binary_logloss: 0.160303\n",
      "[3961]\ttraining's auc: 0.954015\ttraining's binary_logloss: 0.160287\n",
      "[3962]\ttraining's auc: 0.954025\ttraining's binary_logloss: 0.160281\n",
      "[3963]\ttraining's auc: 0.954047\ttraining's binary_logloss: 0.160265\n",
      "[3964]\ttraining's auc: 0.954059\ttraining's binary_logloss: 0.16025\n",
      "[3965]\ttraining's auc: 0.954074\ttraining's binary_logloss: 0.160235\n",
      "[3966]\ttraining's auc: 0.954096\ttraining's binary_logloss: 0.160219\n",
      "[3967]\ttraining's auc: 0.954114\ttraining's binary_logloss: 0.160207\n",
      "[3968]\ttraining's auc: 0.954129\ttraining's binary_logloss: 0.160194\n",
      "[3969]\ttraining's auc: 0.954142\ttraining's binary_logloss: 0.160179\n",
      "[3970]\ttraining's auc: 0.954168\ttraining's binary_logloss: 0.160161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3971]\ttraining's auc: 0.954189\ttraining's binary_logloss: 0.160146\n",
      "[3972]\ttraining's auc: 0.954199\ttraining's binary_logloss: 0.160136\n",
      "[3973]\ttraining's auc: 0.954217\ttraining's binary_logloss: 0.160121\n",
      "[3974]\ttraining's auc: 0.954244\ttraining's binary_logloss: 0.160105\n",
      "[3975]\ttraining's auc: 0.95425\ttraining's binary_logloss: 0.160099\n",
      "[3976]\ttraining's auc: 0.95426\ttraining's binary_logloss: 0.160092\n",
      "[3977]\ttraining's auc: 0.954286\ttraining's binary_logloss: 0.160075\n",
      "[3978]\ttraining's auc: 0.954294\ttraining's binary_logloss: 0.160068\n",
      "[3979]\ttraining's auc: 0.954318\ttraining's binary_logloss: 0.160052\n",
      "[3980]\ttraining's auc: 0.954326\ttraining's binary_logloss: 0.160046\n",
      "[3981]\ttraining's auc: 0.954346\ttraining's binary_logloss: 0.160029\n",
      "[3982]\ttraining's auc: 0.954351\ttraining's binary_logloss: 0.160026\n",
      "[3983]\ttraining's auc: 0.954377\ttraining's binary_logloss: 0.160009\n",
      "[3984]\ttraining's auc: 0.954387\ttraining's binary_logloss: 0.160002\n",
      "[3985]\ttraining's auc: 0.954428\ttraining's binary_logloss: 0.159983\n",
      "[3986]\ttraining's auc: 0.95445\ttraining's binary_logloss: 0.159968\n",
      "[3987]\ttraining's auc: 0.954473\ttraining's binary_logloss: 0.159952\n",
      "[3988]\ttraining's auc: 0.95449\ttraining's binary_logloss: 0.159936\n",
      "[3989]\ttraining's auc: 0.954508\ttraining's binary_logloss: 0.159922\n",
      "[3990]\ttraining's auc: 0.954521\ttraining's binary_logloss: 0.159907\n",
      "[3991]\ttraining's auc: 0.954538\ttraining's binary_logloss: 0.159893\n",
      "[3992]\ttraining's auc: 0.954558\ttraining's binary_logloss: 0.159875\n",
      "[3993]\ttraining's auc: 0.954577\ttraining's binary_logloss: 0.159858\n",
      "[3994]\ttraining's auc: 0.954594\ttraining's binary_logloss: 0.159843\n",
      "[3995]\ttraining's auc: 0.954604\ttraining's binary_logloss: 0.159835\n",
      "[3996]\ttraining's auc: 0.954621\ttraining's binary_logloss: 0.159819\n",
      "[3997]\ttraining's auc: 0.954633\ttraining's binary_logloss: 0.159807\n",
      "[3998]\ttraining's auc: 0.95465\ttraining's binary_logloss: 0.159791\n",
      "[3999]\ttraining's auc: 0.95467\ttraining's binary_logloss: 0.159777\n",
      "[4000]\ttraining's auc: 0.954688\ttraining's binary_logloss: 0.159761\n",
      "[4001]\ttraining's auc: 0.954717\ttraining's binary_logloss: 0.159745\n",
      "[4002]\ttraining's auc: 0.95474\ttraining's binary_logloss: 0.159729\n",
      "[4003]\ttraining's auc: 0.954757\ttraining's binary_logloss: 0.159713\n",
      "[4004]\ttraining's auc: 0.954776\ttraining's binary_logloss: 0.159698\n",
      "[4005]\ttraining's auc: 0.954792\ttraining's binary_logloss: 0.159682\n",
      "[4006]\ttraining's auc: 0.954806\ttraining's binary_logloss: 0.159666\n",
      "[4007]\ttraining's auc: 0.954822\ttraining's binary_logloss: 0.159654\n",
      "[4008]\ttraining's auc: 0.954843\ttraining's binary_logloss: 0.159638\n",
      "[4009]\ttraining's auc: 0.954859\ttraining's binary_logloss: 0.159623\n",
      "[4010]\ttraining's auc: 0.954882\ttraining's binary_logloss: 0.159607\n",
      "[4011]\ttraining's auc: 0.954903\ttraining's binary_logloss: 0.159593\n",
      "[4012]\ttraining's auc: 0.95492\ttraining's binary_logloss: 0.159579\n",
      "[4013]\ttraining's auc: 0.954939\ttraining's binary_logloss: 0.159566\n",
      "[4014]\ttraining's auc: 0.954951\ttraining's binary_logloss: 0.159552\n",
      "[4015]\ttraining's auc: 0.954976\ttraining's binary_logloss: 0.159536\n",
      "[4016]\ttraining's auc: 0.954994\ttraining's binary_logloss: 0.159521\n",
      "[4017]\ttraining's auc: 0.955008\ttraining's binary_logloss: 0.159506\n",
      "[4018]\ttraining's auc: 0.955028\ttraining's binary_logloss: 0.159493\n",
      "[4019]\ttraining's auc: 0.955043\ttraining's binary_logloss: 0.159479\n",
      "[4020]\ttraining's auc: 0.955061\ttraining's binary_logloss: 0.159465\n",
      "[4021]\ttraining's auc: 0.955078\ttraining's binary_logloss: 0.159452\n",
      "[4022]\ttraining's auc: 0.955087\ttraining's binary_logloss: 0.159446\n",
      "[4023]\ttraining's auc: 0.955113\ttraining's binary_logloss: 0.159429\n",
      "[4024]\ttraining's auc: 0.955133\ttraining's binary_logloss: 0.159413\n",
      "[4025]\ttraining's auc: 0.955152\ttraining's binary_logloss: 0.159398\n",
      "[4026]\ttraining's auc: 0.955171\ttraining's binary_logloss: 0.159382\n",
      "[4027]\ttraining's auc: 0.955188\ttraining's binary_logloss: 0.159367\n",
      "[4028]\ttraining's auc: 0.955203\ttraining's binary_logloss: 0.159355\n",
      "[4029]\ttraining's auc: 0.95522\ttraining's binary_logloss: 0.15934\n",
      "[4030]\ttraining's auc: 0.955232\ttraining's binary_logloss: 0.159332\n",
      "[4031]\ttraining's auc: 0.955253\ttraining's binary_logloss: 0.159314\n",
      "[4032]\ttraining's auc: 0.955265\ttraining's binary_logloss: 0.159302\n",
      "[4033]\ttraining's auc: 0.955275\ttraining's binary_logloss: 0.159292\n",
      "[4034]\ttraining's auc: 0.955292\ttraining's binary_logloss: 0.159277\n",
      "[4035]\ttraining's auc: 0.955308\ttraining's binary_logloss: 0.159261\n",
      "[4036]\ttraining's auc: 0.955344\ttraining's binary_logloss: 0.159243\n",
      "[4037]\ttraining's auc: 0.955356\ttraining's binary_logloss: 0.15923\n",
      "[4038]\ttraining's auc: 0.955377\ttraining's binary_logloss: 0.159215\n",
      "[4039]\ttraining's auc: 0.955404\ttraining's binary_logloss: 0.159199\n",
      "[4040]\ttraining's auc: 0.955415\ttraining's binary_logloss: 0.159186\n",
      "[4041]\ttraining's auc: 0.955429\ttraining's binary_logloss: 0.159175\n",
      "[4042]\ttraining's auc: 0.955438\ttraining's binary_logloss: 0.159167\n",
      "[4043]\ttraining's auc: 0.955451\ttraining's binary_logloss: 0.159154\n",
      "[4044]\ttraining's auc: 0.955465\ttraining's binary_logloss: 0.159139\n",
      "[4045]\ttraining's auc: 0.955484\ttraining's binary_logloss: 0.159123\n",
      "[4046]\ttraining's auc: 0.955501\ttraining's binary_logloss: 0.15911\n",
      "[4047]\ttraining's auc: 0.955524\ttraining's binary_logloss: 0.159093\n",
      "[4048]\ttraining's auc: 0.955551\ttraining's binary_logloss: 0.159076\n",
      "[4049]\ttraining's auc: 0.955566\ttraining's binary_logloss: 0.159065\n",
      "[4050]\ttraining's auc: 0.955574\ttraining's binary_logloss: 0.159053\n",
      "[4051]\ttraining's auc: 0.955583\ttraining's binary_logloss: 0.159047\n",
      "[4052]\ttraining's auc: 0.955595\ttraining's binary_logloss: 0.15903\n",
      "[4053]\ttraining's auc: 0.95561\ttraining's binary_logloss: 0.159016\n",
      "[4054]\ttraining's auc: 0.955652\ttraining's binary_logloss: 0.158997\n",
      "[4055]\ttraining's auc: 0.955658\ttraining's binary_logloss: 0.158989\n",
      "[4056]\ttraining's auc: 0.955675\ttraining's binary_logloss: 0.158977\n",
      "[4057]\ttraining's auc: 0.95569\ttraining's binary_logloss: 0.158965\n",
      "[4058]\ttraining's auc: 0.95571\ttraining's binary_logloss: 0.158949\n",
      "[4059]\ttraining's auc: 0.95573\ttraining's binary_logloss: 0.158934\n",
      "[4060]\ttraining's auc: 0.955744\ttraining's binary_logloss: 0.158923\n",
      "[4061]\ttraining's auc: 0.955747\ttraining's binary_logloss: 0.158919\n",
      "[4062]\ttraining's auc: 0.955754\ttraining's binary_logloss: 0.158913\n",
      "[4063]\ttraining's auc: 0.955766\ttraining's binary_logloss: 0.158897\n",
      "[4064]\ttraining's auc: 0.955787\ttraining's binary_logloss: 0.158882\n",
      "[4065]\ttraining's auc: 0.955799\ttraining's binary_logloss: 0.15887\n",
      "[4066]\ttraining's auc: 0.955817\ttraining's binary_logloss: 0.158856\n",
      "[4067]\ttraining's auc: 0.955845\ttraining's binary_logloss: 0.158839\n",
      "[4068]\ttraining's auc: 0.955861\ttraining's binary_logloss: 0.158826\n",
      "[4069]\ttraining's auc: 0.955885\ttraining's binary_logloss: 0.158809\n",
      "[4070]\ttraining's auc: 0.955904\ttraining's binary_logloss: 0.158794\n",
      "[4071]\ttraining's auc: 0.955929\ttraining's binary_logloss: 0.158774\n",
      "[4072]\ttraining's auc: 0.955947\ttraining's binary_logloss: 0.158762\n",
      "[4073]\ttraining's auc: 0.955959\ttraining's binary_logloss: 0.158754\n",
      "[4074]\ttraining's auc: 0.955981\ttraining's binary_logloss: 0.158739\n",
      "[4075]\ttraining's auc: 0.955992\ttraining's binary_logloss: 0.158727\n",
      "[4076]\ttraining's auc: 0.956007\ttraining's binary_logloss: 0.158711\n",
      "[4077]\ttraining's auc: 0.956035\ttraining's binary_logloss: 0.158694\n",
      "[4078]\ttraining's auc: 0.956047\ttraining's binary_logloss: 0.158681\n",
      "[4079]\ttraining's auc: 0.956078\ttraining's binary_logloss: 0.158665\n",
      "[4080]\ttraining's auc: 0.956098\ttraining's binary_logloss: 0.158648\n",
      "[4081]\ttraining's auc: 0.956116\ttraining's binary_logloss: 0.158633\n",
      "[4082]\ttraining's auc: 0.956132\ttraining's binary_logloss: 0.15862\n",
      "[4083]\ttraining's auc: 0.956152\ttraining's binary_logloss: 0.158607\n",
      "[4084]\ttraining's auc: 0.956168\ttraining's binary_logloss: 0.15859\n",
      "[4085]\ttraining's auc: 0.95618\ttraining's binary_logloss: 0.158574\n",
      "[4086]\ttraining's auc: 0.956214\ttraining's binary_logloss: 0.158557\n",
      "[4087]\ttraining's auc: 0.95623\ttraining's binary_logloss: 0.158543\n",
      "[4088]\ttraining's auc: 0.956237\ttraining's binary_logloss: 0.158539\n",
      "[4089]\ttraining's auc: 0.956251\ttraining's binary_logloss: 0.158528\n",
      "[4090]\ttraining's auc: 0.956277\ttraining's binary_logloss: 0.158512\n",
      "[4091]\ttraining's auc: 0.956298\ttraining's binary_logloss: 0.158496\n",
      "[4092]\ttraining's auc: 0.956335\ttraining's binary_logloss: 0.158478\n",
      "[4093]\ttraining's auc: 0.956351\ttraining's binary_logloss: 0.158464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4094]\ttraining's auc: 0.956381\ttraining's binary_logloss: 0.158446\n",
      "[4095]\ttraining's auc: 0.956402\ttraining's binary_logloss: 0.158431\n",
      "[4096]\ttraining's auc: 0.956419\ttraining's binary_logloss: 0.158416\n",
      "[4097]\ttraining's auc: 0.956424\ttraining's binary_logloss: 0.158412\n",
      "[4098]\ttraining's auc: 0.956434\ttraining's binary_logloss: 0.158398\n",
      "[4099]\ttraining's auc: 0.956459\ttraining's binary_logloss: 0.15838\n",
      "[4100]\ttraining's auc: 0.956482\ttraining's binary_logloss: 0.158362\n",
      "[4101]\ttraining's auc: 0.956502\ttraining's binary_logloss: 0.158346\n",
      "[4102]\ttraining's auc: 0.956522\ttraining's binary_logloss: 0.158333\n",
      "[4103]\ttraining's auc: 0.956542\ttraining's binary_logloss: 0.158319\n",
      "[4104]\ttraining's auc: 0.956558\ttraining's binary_logloss: 0.158307\n",
      "[4105]\ttraining's auc: 0.956576\ttraining's binary_logloss: 0.158289\n",
      "[4106]\ttraining's auc: 0.956593\ttraining's binary_logloss: 0.158273\n",
      "[4107]\ttraining's auc: 0.956613\ttraining's binary_logloss: 0.158259\n",
      "[4108]\ttraining's auc: 0.956647\ttraining's binary_logloss: 0.158241\n",
      "[4109]\ttraining's auc: 0.956663\ttraining's binary_logloss: 0.158227\n",
      "[4110]\ttraining's auc: 0.956667\ttraining's binary_logloss: 0.158223\n",
      "[4111]\ttraining's auc: 0.956674\ttraining's binary_logloss: 0.158217\n",
      "[4112]\ttraining's auc: 0.956686\ttraining's binary_logloss: 0.158205\n",
      "[4113]\ttraining's auc: 0.956694\ttraining's binary_logloss: 0.158198\n",
      "[4114]\ttraining's auc: 0.956724\ttraining's binary_logloss: 0.158181\n",
      "[4115]\ttraining's auc: 0.95675\ttraining's binary_logloss: 0.158165\n",
      "[4116]\ttraining's auc: 0.956762\ttraining's binary_logloss: 0.158155\n",
      "[4117]\ttraining's auc: 0.956774\ttraining's binary_logloss: 0.158141\n",
      "[4118]\ttraining's auc: 0.956795\ttraining's binary_logloss: 0.158128\n",
      "[4119]\ttraining's auc: 0.956796\ttraining's binary_logloss: 0.158126\n",
      "[4120]\ttraining's auc: 0.956811\ttraining's binary_logloss: 0.158114\n",
      "[4121]\ttraining's auc: 0.956827\ttraining's binary_logloss: 0.158098\n",
      "[4122]\ttraining's auc: 0.956846\ttraining's binary_logloss: 0.158082\n",
      "[4123]\ttraining's auc: 0.956864\ttraining's binary_logloss: 0.158065\n",
      "[4124]\ttraining's auc: 0.95688\ttraining's binary_logloss: 0.158052\n",
      "[4125]\ttraining's auc: 0.956902\ttraining's binary_logloss: 0.158035\n",
      "[4126]\ttraining's auc: 0.956926\ttraining's binary_logloss: 0.15802\n",
      "[4127]\ttraining's auc: 0.95695\ttraining's binary_logloss: 0.158004\n",
      "[4128]\ttraining's auc: 0.956962\ttraining's binary_logloss: 0.157989\n",
      "[4129]\ttraining's auc: 0.95698\ttraining's binary_logloss: 0.157975\n",
      "[4130]\ttraining's auc: 0.956997\ttraining's binary_logloss: 0.157961\n",
      "[4131]\ttraining's auc: 0.957013\ttraining's binary_logloss: 0.15795\n",
      "[4132]\ttraining's auc: 0.957022\ttraining's binary_logloss: 0.157943\n",
      "[4133]\ttraining's auc: 0.957026\ttraining's binary_logloss: 0.157937\n",
      "[4134]\ttraining's auc: 0.957044\ttraining's binary_logloss: 0.157921\n",
      "[4135]\ttraining's auc: 0.957068\ttraining's binary_logloss: 0.157905\n",
      "[4136]\ttraining's auc: 0.957089\ttraining's binary_logloss: 0.157889\n",
      "[4137]\ttraining's auc: 0.957107\ttraining's binary_logloss: 0.157875\n",
      "[4138]\ttraining's auc: 0.95713\ttraining's binary_logloss: 0.157859\n",
      "[4139]\ttraining's auc: 0.957149\ttraining's binary_logloss: 0.157843\n",
      "[4140]\ttraining's auc: 0.957169\ttraining's binary_logloss: 0.157826\n",
      "[4141]\ttraining's auc: 0.957178\ttraining's binary_logloss: 0.15782\n",
      "[4142]\ttraining's auc: 0.957188\ttraining's binary_logloss: 0.157812\n",
      "[4143]\ttraining's auc: 0.957204\ttraining's binary_logloss: 0.1578\n",
      "[4144]\ttraining's auc: 0.957227\ttraining's binary_logloss: 0.157784\n",
      "[4145]\ttraining's auc: 0.957245\ttraining's binary_logloss: 0.15777\n",
      "[4146]\ttraining's auc: 0.957258\ttraining's binary_logloss: 0.15776\n",
      "[4147]\ttraining's auc: 0.957275\ttraining's binary_logloss: 0.157744\n",
      "[4148]\ttraining's auc: 0.957282\ttraining's binary_logloss: 0.157731\n",
      "[4149]\ttraining's auc: 0.957286\ttraining's binary_logloss: 0.157728\n",
      "[4150]\ttraining's auc: 0.957304\ttraining's binary_logloss: 0.157716\n",
      "[4151]\ttraining's auc: 0.957319\ttraining's binary_logloss: 0.1577\n",
      "[4152]\ttraining's auc: 0.957344\ttraining's binary_logloss: 0.157681\n",
      "[4153]\ttraining's auc: 0.957379\ttraining's binary_logloss: 0.157664\n",
      "[4154]\ttraining's auc: 0.957408\ttraining's binary_logloss: 0.157646\n",
      "[4155]\ttraining's auc: 0.957425\ttraining's binary_logloss: 0.15763\n",
      "[4156]\ttraining's auc: 0.95743\ttraining's binary_logloss: 0.157626\n",
      "[4157]\ttraining's auc: 0.957449\ttraining's binary_logloss: 0.15761\n",
      "[4158]\ttraining's auc: 0.957464\ttraining's binary_logloss: 0.157597\n",
      "[4159]\ttraining's auc: 0.957483\ttraining's binary_logloss: 0.15758\n",
      "[4160]\ttraining's auc: 0.957509\ttraining's binary_logloss: 0.157562\n",
      "[4161]\ttraining's auc: 0.957528\ttraining's binary_logloss: 0.157545\n",
      "[4162]\ttraining's auc: 0.957551\ttraining's binary_logloss: 0.157528\n",
      "[4163]\ttraining's auc: 0.957579\ttraining's binary_logloss: 0.157511\n",
      "[4164]\ttraining's auc: 0.9576\ttraining's binary_logloss: 0.157495\n",
      "[4165]\ttraining's auc: 0.957619\ttraining's binary_logloss: 0.157482\n",
      "[4166]\ttraining's auc: 0.95763\ttraining's binary_logloss: 0.157467\n",
      "[4167]\ttraining's auc: 0.957646\ttraining's binary_logloss: 0.157452\n",
      "[4168]\ttraining's auc: 0.957657\ttraining's binary_logloss: 0.157445\n",
      "[4169]\ttraining's auc: 0.957669\ttraining's binary_logloss: 0.157436\n",
      "[4170]\ttraining's auc: 0.957683\ttraining's binary_logloss: 0.157421\n",
      "[4171]\ttraining's auc: 0.957697\ttraining's binary_logloss: 0.157411\n",
      "[4172]\ttraining's auc: 0.957715\ttraining's binary_logloss: 0.157394\n",
      "[4173]\ttraining's auc: 0.957737\ttraining's binary_logloss: 0.157377\n",
      "[4174]\ttraining's auc: 0.957761\ttraining's binary_logloss: 0.157361\n",
      "[4175]\ttraining's auc: 0.957774\ttraining's binary_logloss: 0.157345\n",
      "[4176]\ttraining's auc: 0.957802\ttraining's binary_logloss: 0.157326\n",
      "[4177]\ttraining's auc: 0.957824\ttraining's binary_logloss: 0.157308\n",
      "[4178]\ttraining's auc: 0.957835\ttraining's binary_logloss: 0.157296\n",
      "[4179]\ttraining's auc: 0.957855\ttraining's binary_logloss: 0.157279\n",
      "[4180]\ttraining's auc: 0.957874\ttraining's binary_logloss: 0.157263\n",
      "[4181]\ttraining's auc: 0.957892\ttraining's binary_logloss: 0.157251\n",
      "[4182]\ttraining's auc: 0.957917\ttraining's binary_logloss: 0.157233\n",
      "[4183]\ttraining's auc: 0.957937\ttraining's binary_logloss: 0.157215\n",
      "[4184]\ttraining's auc: 0.957955\ttraining's binary_logloss: 0.157198\n",
      "[4185]\ttraining's auc: 0.957971\ttraining's binary_logloss: 0.157183\n",
      "[4186]\ttraining's auc: 0.95799\ttraining's binary_logloss: 0.157167\n",
      "[4187]\ttraining's auc: 0.958002\ttraining's binary_logloss: 0.157155\n",
      "[4188]\ttraining's auc: 0.958021\ttraining's binary_logloss: 0.157138\n",
      "[4189]\ttraining's auc: 0.958038\ttraining's binary_logloss: 0.157125\n",
      "[4190]\ttraining's auc: 0.958052\ttraining's binary_logloss: 0.157112\n",
      "[4191]\ttraining's auc: 0.958073\ttraining's binary_logloss: 0.157097\n",
      "[4192]\ttraining's auc: 0.958085\ttraining's binary_logloss: 0.157089\n",
      "[4193]\ttraining's auc: 0.958104\ttraining's binary_logloss: 0.157076\n",
      "[4194]\ttraining's auc: 0.958117\ttraining's binary_logloss: 0.157062\n",
      "[4195]\ttraining's auc: 0.958134\ttraining's binary_logloss: 0.157046\n",
      "[4196]\ttraining's auc: 0.958152\ttraining's binary_logloss: 0.157029\n",
      "[4197]\ttraining's auc: 0.958169\ttraining's binary_logloss: 0.157015\n",
      "[4198]\ttraining's auc: 0.958182\ttraining's binary_logloss: 0.157004\n",
      "[4199]\ttraining's auc: 0.958192\ttraining's binary_logloss: 0.156995\n",
      "[4200]\ttraining's auc: 0.958216\ttraining's binary_logloss: 0.15698\n",
      "[4201]\ttraining's auc: 0.958241\ttraining's binary_logloss: 0.156962\n",
      "[4202]\ttraining's auc: 0.95826\ttraining's binary_logloss: 0.156945\n",
      "[4203]\ttraining's auc: 0.958278\ttraining's binary_logloss: 0.156931\n",
      "[4204]\ttraining's auc: 0.958293\ttraining's binary_logloss: 0.156919\n",
      "[4205]\ttraining's auc: 0.958318\ttraining's binary_logloss: 0.156901\n",
      "[4206]\ttraining's auc: 0.958331\ttraining's binary_logloss: 0.156886\n",
      "[4207]\ttraining's auc: 0.95835\ttraining's binary_logloss: 0.156869\n",
      "[4208]\ttraining's auc: 0.958378\ttraining's binary_logloss: 0.156853\n",
      "[4209]\ttraining's auc: 0.958395\ttraining's binary_logloss: 0.156838\n",
      "[4210]\ttraining's auc: 0.95841\ttraining's binary_logloss: 0.156825\n",
      "[4211]\ttraining's auc: 0.95843\ttraining's binary_logloss: 0.156809\n",
      "[4212]\ttraining's auc: 0.95845\ttraining's binary_logloss: 0.156792\n",
      "[4213]\ttraining's auc: 0.958465\ttraining's binary_logloss: 0.156779\n",
      "[4214]\ttraining's auc: 0.95848\ttraining's binary_logloss: 0.156765\n",
      "[4215]\ttraining's auc: 0.958498\ttraining's binary_logloss: 0.156749\n",
      "[4216]\ttraining's auc: 0.958518\ttraining's binary_logloss: 0.156735\n",
      "[4217]\ttraining's auc: 0.958528\ttraining's binary_logloss: 0.156719\n",
      "[4218]\ttraining's auc: 0.958552\ttraining's binary_logloss: 0.156704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4219]\ttraining's auc: 0.958572\ttraining's binary_logloss: 0.15669\n",
      "[4220]\ttraining's auc: 0.958585\ttraining's binary_logloss: 0.156674\n",
      "[4221]\ttraining's auc: 0.958599\ttraining's binary_logloss: 0.156661\n",
      "[4222]\ttraining's auc: 0.958629\ttraining's binary_logloss: 0.156646\n",
      "[4223]\ttraining's auc: 0.958636\ttraining's binary_logloss: 0.156639\n",
      "[4224]\ttraining's auc: 0.958661\ttraining's binary_logloss: 0.156623\n",
      "[4225]\ttraining's auc: 0.958669\ttraining's binary_logloss: 0.156613\n",
      "[4226]\ttraining's auc: 0.958697\ttraining's binary_logloss: 0.156597\n",
      "[4227]\ttraining's auc: 0.958708\ttraining's binary_logloss: 0.156582\n",
      "[4228]\ttraining's auc: 0.958737\ttraining's binary_logloss: 0.156563\n",
      "[4229]\ttraining's auc: 0.958761\ttraining's binary_logloss: 0.156546\n",
      "[4230]\ttraining's auc: 0.958779\ttraining's binary_logloss: 0.15653\n",
      "[4231]\ttraining's auc: 0.958796\ttraining's binary_logloss: 0.156516\n",
      "[4232]\ttraining's auc: 0.958815\ttraining's binary_logloss: 0.156499\n",
      "[4233]\ttraining's auc: 0.958831\ttraining's binary_logloss: 0.156481\n",
      "[4234]\ttraining's auc: 0.958851\ttraining's binary_logloss: 0.156466\n",
      "[4235]\ttraining's auc: 0.958867\ttraining's binary_logloss: 0.156451\n",
      "[4236]\ttraining's auc: 0.958878\ttraining's binary_logloss: 0.156439\n",
      "[4237]\ttraining's auc: 0.958891\ttraining's binary_logloss: 0.156424\n",
      "[4238]\ttraining's auc: 0.958912\ttraining's binary_logloss: 0.156409\n",
      "[4239]\ttraining's auc: 0.958934\ttraining's binary_logloss: 0.156392\n",
      "[4240]\ttraining's auc: 0.95895\ttraining's binary_logloss: 0.156379\n",
      "[4241]\ttraining's auc: 0.958966\ttraining's binary_logloss: 0.156364\n",
      "[4242]\ttraining's auc: 0.958993\ttraining's binary_logloss: 0.156347\n",
      "[4243]\ttraining's auc: 0.959014\ttraining's binary_logloss: 0.156331\n",
      "[4244]\ttraining's auc: 0.959031\ttraining's binary_logloss: 0.156316\n",
      "[4245]\ttraining's auc: 0.959055\ttraining's binary_logloss: 0.156299\n",
      "[4246]\ttraining's auc: 0.959061\ttraining's binary_logloss: 0.156292\n",
      "[4247]\ttraining's auc: 0.959072\ttraining's binary_logloss: 0.156278\n",
      "[4248]\ttraining's auc: 0.959093\ttraining's binary_logloss: 0.156264\n",
      "[4249]\ttraining's auc: 0.959103\ttraining's binary_logloss: 0.156251\n",
      "[4250]\ttraining's auc: 0.959122\ttraining's binary_logloss: 0.156235\n",
      "[4251]\ttraining's auc: 0.959139\ttraining's binary_logloss: 0.156219\n",
      "[4252]\ttraining's auc: 0.959157\ttraining's binary_logloss: 0.156208\n",
      "[4253]\ttraining's auc: 0.959179\ttraining's binary_logloss: 0.156193\n",
      "[4254]\ttraining's auc: 0.959197\ttraining's binary_logloss: 0.156176\n",
      "[4255]\ttraining's auc: 0.959221\ttraining's binary_logloss: 0.156159\n",
      "[4256]\ttraining's auc: 0.959244\ttraining's binary_logloss: 0.15614\n",
      "[4257]\ttraining's auc: 0.959264\ttraining's binary_logloss: 0.156126\n",
      "[4258]\ttraining's auc: 0.959289\ttraining's binary_logloss: 0.156109\n",
      "[4259]\ttraining's auc: 0.959312\ttraining's binary_logloss: 0.156092\n",
      "[4260]\ttraining's auc: 0.959342\ttraining's binary_logloss: 0.156072\n",
      "[4261]\ttraining's auc: 0.959356\ttraining's binary_logloss: 0.156057\n",
      "[4262]\ttraining's auc: 0.95938\ttraining's binary_logloss: 0.156038\n",
      "[4263]\ttraining's auc: 0.959402\ttraining's binary_logloss: 0.156022\n",
      "[4264]\ttraining's auc: 0.959426\ttraining's binary_logloss: 0.156003\n",
      "[4265]\ttraining's auc: 0.959441\ttraining's binary_logloss: 0.155989\n",
      "[4266]\ttraining's auc: 0.959455\ttraining's binary_logloss: 0.155975\n",
      "[4267]\ttraining's auc: 0.959479\ttraining's binary_logloss: 0.155959\n",
      "[4268]\ttraining's auc: 0.959501\ttraining's binary_logloss: 0.155942\n",
      "[4269]\ttraining's auc: 0.95952\ttraining's binary_logloss: 0.155929\n",
      "[4270]\ttraining's auc: 0.95954\ttraining's binary_logloss: 0.155914\n",
      "[4271]\ttraining's auc: 0.95955\ttraining's binary_logloss: 0.155903\n",
      "[4272]\ttraining's auc: 0.959573\ttraining's binary_logloss: 0.155884\n",
      "[4273]\ttraining's auc: 0.959595\ttraining's binary_logloss: 0.15587\n",
      "[4274]\ttraining's auc: 0.959611\ttraining's binary_logloss: 0.155855\n",
      "[4275]\ttraining's auc: 0.959625\ttraining's binary_logloss: 0.15584\n",
      "[4276]\ttraining's auc: 0.959639\ttraining's binary_logloss: 0.155826\n",
      "[4277]\ttraining's auc: 0.959657\ttraining's binary_logloss: 0.155811\n",
      "[4278]\ttraining's auc: 0.959665\ttraining's binary_logloss: 0.155799\n",
      "[4279]\ttraining's auc: 0.95968\ttraining's binary_logloss: 0.155785\n",
      "[4280]\ttraining's auc: 0.95969\ttraining's binary_logloss: 0.155774\n",
      "[4281]\ttraining's auc: 0.959706\ttraining's binary_logloss: 0.155759\n",
      "[4282]\ttraining's auc: 0.959725\ttraining's binary_logloss: 0.155742\n",
      "[4283]\ttraining's auc: 0.959747\ttraining's binary_logloss: 0.155725\n",
      "[4284]\ttraining's auc: 0.959774\ttraining's binary_logloss: 0.155711\n",
      "[4285]\ttraining's auc: 0.959788\ttraining's binary_logloss: 0.155697\n",
      "[4286]\ttraining's auc: 0.959805\ttraining's binary_logloss: 0.155681\n",
      "[4287]\ttraining's auc: 0.959826\ttraining's binary_logloss: 0.155665\n",
      "[4288]\ttraining's auc: 0.959843\ttraining's binary_logloss: 0.15565\n",
      "[4289]\ttraining's auc: 0.959855\ttraining's binary_logloss: 0.155635\n",
      "[4290]\ttraining's auc: 0.959879\ttraining's binary_logloss: 0.155619\n",
      "[4291]\ttraining's auc: 0.959897\ttraining's binary_logloss: 0.155603\n",
      "[4292]\ttraining's auc: 0.959917\ttraining's binary_logloss: 0.155587\n",
      "[4293]\ttraining's auc: 0.959938\ttraining's binary_logloss: 0.155571\n",
      "[4294]\ttraining's auc: 0.959962\ttraining's binary_logloss: 0.155552\n",
      "[4295]\ttraining's auc: 0.959985\ttraining's binary_logloss: 0.155536\n",
      "[4296]\ttraining's auc: 0.960005\ttraining's binary_logloss: 0.15552\n",
      "[4297]\ttraining's auc: 0.960022\ttraining's binary_logloss: 0.155506\n",
      "[4298]\ttraining's auc: 0.960042\ttraining's binary_logloss: 0.155487\n",
      "[4299]\ttraining's auc: 0.960063\ttraining's binary_logloss: 0.155469\n",
      "[4300]\ttraining's auc: 0.960091\ttraining's binary_logloss: 0.155451\n",
      "[4301]\ttraining's auc: 0.96011\ttraining's binary_logloss: 0.155435\n",
      "[4302]\ttraining's auc: 0.960129\ttraining's binary_logloss: 0.15542\n",
      "[4303]\ttraining's auc: 0.960151\ttraining's binary_logloss: 0.155403\n",
      "[4304]\ttraining's auc: 0.960172\ttraining's binary_logloss: 0.155387\n",
      "[4305]\ttraining's auc: 0.96019\ttraining's binary_logloss: 0.155369\n",
      "[4306]\ttraining's auc: 0.960206\ttraining's binary_logloss: 0.155354\n",
      "[4307]\ttraining's auc: 0.96023\ttraining's binary_logloss: 0.155338\n",
      "[4308]\ttraining's auc: 0.960248\ttraining's binary_logloss: 0.155323\n",
      "[4309]\ttraining's auc: 0.960258\ttraining's binary_logloss: 0.155312\n",
      "[4310]\ttraining's auc: 0.960265\ttraining's binary_logloss: 0.155305\n",
      "[4311]\ttraining's auc: 0.960281\ttraining's binary_logloss: 0.15529\n",
      "[4312]\ttraining's auc: 0.960294\ttraining's binary_logloss: 0.155276\n",
      "[4313]\ttraining's auc: 0.960305\ttraining's binary_logloss: 0.155262\n",
      "[4314]\ttraining's auc: 0.960314\ttraining's binary_logloss: 0.155253\n",
      "[4315]\ttraining's auc: 0.96033\ttraining's binary_logloss: 0.155237\n",
      "[4316]\ttraining's auc: 0.96034\ttraining's binary_logloss: 0.155226\n",
      "[4317]\ttraining's auc: 0.960355\ttraining's binary_logloss: 0.155209\n",
      "[4318]\ttraining's auc: 0.960377\ttraining's binary_logloss: 0.155193\n",
      "[4319]\ttraining's auc: 0.960392\ttraining's binary_logloss: 0.155179\n",
      "[4320]\ttraining's auc: 0.960404\ttraining's binary_logloss: 0.155167\n",
      "[4321]\ttraining's auc: 0.96042\ttraining's binary_logloss: 0.155153\n",
      "[4322]\ttraining's auc: 0.960443\ttraining's binary_logloss: 0.155139\n",
      "[4323]\ttraining's auc: 0.960462\ttraining's binary_logloss: 0.155124\n",
      "[4324]\ttraining's auc: 0.960476\ttraining's binary_logloss: 0.155109\n",
      "[4325]\ttraining's auc: 0.960491\ttraining's binary_logloss: 0.155094\n",
      "[4326]\ttraining's auc: 0.960507\ttraining's binary_logloss: 0.155077\n",
      "[4327]\ttraining's auc: 0.960529\ttraining's binary_logloss: 0.15506\n",
      "[4328]\ttraining's auc: 0.960546\ttraining's binary_logloss: 0.155046\n",
      "[4329]\ttraining's auc: 0.96057\ttraining's binary_logloss: 0.155027\n",
      "[4330]\ttraining's auc: 0.96059\ttraining's binary_logloss: 0.155012\n",
      "[4331]\ttraining's auc: 0.960592\ttraining's binary_logloss: 0.155007\n",
      "[4332]\ttraining's auc: 0.960597\ttraining's binary_logloss: 0.155002\n",
      "[4333]\ttraining's auc: 0.960604\ttraining's binary_logloss: 0.154996\n",
      "[4334]\ttraining's auc: 0.960624\ttraining's binary_logloss: 0.154979\n",
      "[4335]\ttraining's auc: 0.960646\ttraining's binary_logloss: 0.154962\n",
      "[4336]\ttraining's auc: 0.960649\ttraining's binary_logloss: 0.154959\n",
      "[4337]\ttraining's auc: 0.960655\ttraining's binary_logloss: 0.154952\n",
      "[4338]\ttraining's auc: 0.960658\ttraining's binary_logloss: 0.15495\n",
      "[4339]\ttraining's auc: 0.960665\ttraining's binary_logloss: 0.154945\n",
      "[4340]\ttraining's auc: 0.960682\ttraining's binary_logloss: 0.154933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4341]\ttraining's auc: 0.960698\ttraining's binary_logloss: 0.154921\n",
      "[4342]\ttraining's auc: 0.960704\ttraining's binary_logloss: 0.154914\n",
      "[4343]\ttraining's auc: 0.960719\ttraining's binary_logloss: 0.154898\n",
      "[4344]\ttraining's auc: 0.96074\ttraining's binary_logloss: 0.154881\n",
      "[4345]\ttraining's auc: 0.960758\ttraining's binary_logloss: 0.154865\n",
      "[4346]\ttraining's auc: 0.960771\ttraining's binary_logloss: 0.154855\n",
      "[4347]\ttraining's auc: 0.96079\ttraining's binary_logloss: 0.154841\n",
      "[4348]\ttraining's auc: 0.960806\ttraining's binary_logloss: 0.154827\n",
      "[4349]\ttraining's auc: 0.960818\ttraining's binary_logloss: 0.154813\n",
      "[4350]\ttraining's auc: 0.96082\ttraining's binary_logloss: 0.154811\n",
      "[4351]\ttraining's auc: 0.960836\ttraining's binary_logloss: 0.154797\n",
      "[4352]\ttraining's auc: 0.960841\ttraining's binary_logloss: 0.154791\n",
      "[4353]\ttraining's auc: 0.960866\ttraining's binary_logloss: 0.154774\n",
      "[4354]\ttraining's auc: 0.960887\ttraining's binary_logloss: 0.154758\n",
      "[4355]\ttraining's auc: 0.960898\ttraining's binary_logloss: 0.154747\n",
      "[4356]\ttraining's auc: 0.960917\ttraining's binary_logloss: 0.154733\n",
      "[4357]\ttraining's auc: 0.960941\ttraining's binary_logloss: 0.154716\n",
      "[4358]\ttraining's auc: 0.960949\ttraining's binary_logloss: 0.154703\n",
      "[4359]\ttraining's auc: 0.96096\ttraining's binary_logloss: 0.154688\n",
      "[4360]\ttraining's auc: 0.960973\ttraining's binary_logloss: 0.154672\n",
      "[4361]\ttraining's auc: 0.960995\ttraining's binary_logloss: 0.154653\n",
      "[4362]\ttraining's auc: 0.961019\ttraining's binary_logloss: 0.154635\n",
      "[4363]\ttraining's auc: 0.961044\ttraining's binary_logloss: 0.154619\n",
      "[4364]\ttraining's auc: 0.961056\ttraining's binary_logloss: 0.154606\n",
      "[4365]\ttraining's auc: 0.961076\ttraining's binary_logloss: 0.154589\n",
      "[4366]\ttraining's auc: 0.961092\ttraining's binary_logloss: 0.154575\n",
      "[4367]\ttraining's auc: 0.961098\ttraining's binary_logloss: 0.154567\n",
      "[4368]\ttraining's auc: 0.961119\ttraining's binary_logloss: 0.154551\n",
      "[4369]\ttraining's auc: 0.961129\ttraining's binary_logloss: 0.154541\n",
      "[4370]\ttraining's auc: 0.961142\ttraining's binary_logloss: 0.154524\n",
      "[4371]\ttraining's auc: 0.961154\ttraining's binary_logloss: 0.154517\n",
      "[4372]\ttraining's auc: 0.961177\ttraining's binary_logloss: 0.1545\n",
      "[4373]\ttraining's auc: 0.961184\ttraining's binary_logloss: 0.154493\n",
      "[4374]\ttraining's auc: 0.961188\ttraining's binary_logloss: 0.154489\n",
      "[4375]\ttraining's auc: 0.961205\ttraining's binary_logloss: 0.154475\n",
      "[4376]\ttraining's auc: 0.961218\ttraining's binary_logloss: 0.154461\n",
      "[4377]\ttraining's auc: 0.961225\ttraining's binary_logloss: 0.154451\n",
      "[4378]\ttraining's auc: 0.961242\ttraining's binary_logloss: 0.154438\n",
      "[4379]\ttraining's auc: 0.961253\ttraining's binary_logloss: 0.154424\n",
      "[4380]\ttraining's auc: 0.961256\ttraining's binary_logloss: 0.15442\n",
      "[4381]\ttraining's auc: 0.961274\ttraining's binary_logloss: 0.154405\n",
      "[4382]\ttraining's auc: 0.96129\ttraining's binary_logloss: 0.15439\n",
      "[4383]\ttraining's auc: 0.9613\ttraining's binary_logloss: 0.154378\n",
      "[4384]\ttraining's auc: 0.961311\ttraining's binary_logloss: 0.154364\n",
      "[4385]\ttraining's auc: 0.961329\ttraining's binary_logloss: 0.154351\n",
      "[4386]\ttraining's auc: 0.961335\ttraining's binary_logloss: 0.154346\n",
      "[4387]\ttraining's auc: 0.961338\ttraining's binary_logloss: 0.154341\n",
      "[4388]\ttraining's auc: 0.961354\ttraining's binary_logloss: 0.154325\n",
      "[4389]\ttraining's auc: 0.961367\ttraining's binary_logloss: 0.154313\n",
      "[4390]\ttraining's auc: 0.961384\ttraining's binary_logloss: 0.154297\n",
      "[4391]\ttraining's auc: 0.9614\ttraining's binary_logloss: 0.15428\n",
      "[4392]\ttraining's auc: 0.961405\ttraining's binary_logloss: 0.154274\n",
      "[4393]\ttraining's auc: 0.961429\ttraining's binary_logloss: 0.154258\n",
      "[4394]\ttraining's auc: 0.961445\ttraining's binary_logloss: 0.154243\n",
      "[4395]\ttraining's auc: 0.961463\ttraining's binary_logloss: 0.154229\n",
      "[4396]\ttraining's auc: 0.961485\ttraining's binary_logloss: 0.154211\n",
      "[4397]\ttraining's auc: 0.961505\ttraining's binary_logloss: 0.154196\n",
      "[4398]\ttraining's auc: 0.96152\ttraining's binary_logloss: 0.154182\n",
      "[4399]\ttraining's auc: 0.961535\ttraining's binary_logloss: 0.154169\n",
      "[4400]\ttraining's auc: 0.961554\ttraining's binary_logloss: 0.154151\n",
      "[4401]\ttraining's auc: 0.961569\ttraining's binary_logloss: 0.154136\n",
      "[4402]\ttraining's auc: 0.96159\ttraining's binary_logloss: 0.154116\n",
      "[4403]\ttraining's auc: 0.961601\ttraining's binary_logloss: 0.154106\n",
      "[4404]\ttraining's auc: 0.961613\ttraining's binary_logloss: 0.154092\n",
      "[4405]\ttraining's auc: 0.961632\ttraining's binary_logloss: 0.154077\n",
      "[4406]\ttraining's auc: 0.961647\ttraining's binary_logloss: 0.154063\n",
      "[4407]\ttraining's auc: 0.961667\ttraining's binary_logloss: 0.154048\n",
      "[4408]\ttraining's auc: 0.961682\ttraining's binary_logloss: 0.154034\n",
      "[4409]\ttraining's auc: 0.961688\ttraining's binary_logloss: 0.154029\n",
      "[4410]\ttraining's auc: 0.961704\ttraining's binary_logloss: 0.154015\n",
      "[4411]\ttraining's auc: 0.961718\ttraining's binary_logloss: 0.153999\n",
      "[4412]\ttraining's auc: 0.961732\ttraining's binary_logloss: 0.153985\n",
      "[4413]\ttraining's auc: 0.961752\ttraining's binary_logloss: 0.153969\n",
      "[4414]\ttraining's auc: 0.961752\ttraining's binary_logloss: 0.153967\n",
      "[4415]\ttraining's auc: 0.961769\ttraining's binary_logloss: 0.153951\n",
      "[4416]\ttraining's auc: 0.961782\ttraining's binary_logloss: 0.153937\n",
      "[4417]\ttraining's auc: 0.961799\ttraining's binary_logloss: 0.153922\n",
      "[4418]\ttraining's auc: 0.961816\ttraining's binary_logloss: 0.153907\n",
      "[4419]\ttraining's auc: 0.961825\ttraining's binary_logloss: 0.153898\n",
      "[4420]\ttraining's auc: 0.961848\ttraining's binary_logloss: 0.153883\n",
      "[4421]\ttraining's auc: 0.961857\ttraining's binary_logloss: 0.153875\n",
      "[4422]\ttraining's auc: 0.96186\ttraining's binary_logloss: 0.153869\n",
      "[4423]\ttraining's auc: 0.961867\ttraining's binary_logloss: 0.153861\n",
      "[4424]\ttraining's auc: 0.961878\ttraining's binary_logloss: 0.15385\n",
      "[4425]\ttraining's auc: 0.96188\ttraining's binary_logloss: 0.153848\n",
      "[4426]\ttraining's auc: 0.961897\ttraining's binary_logloss: 0.153833\n",
      "[4427]\ttraining's auc: 0.961913\ttraining's binary_logloss: 0.153817\n",
      "[4428]\ttraining's auc: 0.961934\ttraining's binary_logloss: 0.153799\n",
      "[4429]\ttraining's auc: 0.961942\ttraining's binary_logloss: 0.153788\n",
      "[4430]\ttraining's auc: 0.961953\ttraining's binary_logloss: 0.153778\n",
      "[4431]\ttraining's auc: 0.961966\ttraining's binary_logloss: 0.153766\n",
      "[4432]\ttraining's auc: 0.961986\ttraining's binary_logloss: 0.153751\n",
      "[4433]\ttraining's auc: 0.962008\ttraining's binary_logloss: 0.153734\n",
      "[4434]\ttraining's auc: 0.962023\ttraining's binary_logloss: 0.15372\n",
      "[4435]\ttraining's auc: 0.962046\ttraining's binary_logloss: 0.153702\n",
      "[4436]\ttraining's auc: 0.962063\ttraining's binary_logloss: 0.153687\n",
      "[4437]\ttraining's auc: 0.962077\ttraining's binary_logloss: 0.153675\n",
      "[4438]\ttraining's auc: 0.962093\ttraining's binary_logloss: 0.153659\n",
      "[4439]\ttraining's auc: 0.962109\ttraining's binary_logloss: 0.153644\n",
      "[4440]\ttraining's auc: 0.962125\ttraining's binary_logloss: 0.153628\n",
      "[4441]\ttraining's auc: 0.962147\ttraining's binary_logloss: 0.15361\n",
      "[4442]\ttraining's auc: 0.962165\ttraining's binary_logloss: 0.153597\n",
      "[4443]\ttraining's auc: 0.962181\ttraining's binary_logloss: 0.15358\n",
      "[4444]\ttraining's auc: 0.962193\ttraining's binary_logloss: 0.153565\n",
      "[4445]\ttraining's auc: 0.962215\ttraining's binary_logloss: 0.15355\n",
      "[4446]\ttraining's auc: 0.962228\ttraining's binary_logloss: 0.153536\n",
      "[4447]\ttraining's auc: 0.96224\ttraining's binary_logloss: 0.153523\n",
      "[4448]\ttraining's auc: 0.96226\ttraining's binary_logloss: 0.153507\n",
      "[4449]\ttraining's auc: 0.962279\ttraining's binary_logloss: 0.153489\n",
      "[4450]\ttraining's auc: 0.962294\ttraining's binary_logloss: 0.153475\n",
      "[4451]\ttraining's auc: 0.962308\ttraining's binary_logloss: 0.153461\n",
      "[4452]\ttraining's auc: 0.96233\ttraining's binary_logloss: 0.153444\n",
      "[4453]\ttraining's auc: 0.96235\ttraining's binary_logloss: 0.153429\n",
      "[4454]\ttraining's auc: 0.962357\ttraining's binary_logloss: 0.153425\n",
      "[4455]\ttraining's auc: 0.962371\ttraining's binary_logloss: 0.15341\n",
      "[4456]\ttraining's auc: 0.962392\ttraining's binary_logloss: 0.153397\n",
      "[4457]\ttraining's auc: 0.962406\ttraining's binary_logloss: 0.153383\n",
      "[4458]\ttraining's auc: 0.962411\ttraining's binary_logloss: 0.153378\n",
      "[4459]\ttraining's auc: 0.962421\ttraining's binary_logloss: 0.153365\n",
      "[4460]\ttraining's auc: 0.962436\ttraining's binary_logloss: 0.15335\n",
      "[4461]\ttraining's auc: 0.962449\ttraining's binary_logloss: 0.153338\n",
      "[4462]\ttraining's auc: 0.962463\ttraining's binary_logloss: 0.153324\n",
      "[4463]\ttraining's auc: 0.96248\ttraining's binary_logloss: 0.153309\n",
      "[4464]\ttraining's auc: 0.962498\ttraining's binary_logloss: 0.153294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4465]\ttraining's auc: 0.962514\ttraining's binary_logloss: 0.153279\n",
      "[4466]\ttraining's auc: 0.962528\ttraining's binary_logloss: 0.153271\n",
      "[4467]\ttraining's auc: 0.962545\ttraining's binary_logloss: 0.153255\n",
      "[4468]\ttraining's auc: 0.962564\ttraining's binary_logloss: 0.15324\n",
      "[4469]\ttraining's auc: 0.962573\ttraining's binary_logloss: 0.153229\n",
      "[4470]\ttraining's auc: 0.962588\ttraining's binary_logloss: 0.153215\n",
      "[4471]\ttraining's auc: 0.962606\ttraining's binary_logloss: 0.153197\n",
      "[4472]\ttraining's auc: 0.962622\ttraining's binary_logloss: 0.153184\n",
      "[4473]\ttraining's auc: 0.962639\ttraining's binary_logloss: 0.15317\n",
      "[4474]\ttraining's auc: 0.962667\ttraining's binary_logloss: 0.153153\n",
      "[4475]\ttraining's auc: 0.962682\ttraining's binary_logloss: 0.153142\n",
      "[4476]\ttraining's auc: 0.962704\ttraining's binary_logloss: 0.153125\n",
      "[4477]\ttraining's auc: 0.962718\ttraining's binary_logloss: 0.153109\n",
      "[4478]\ttraining's auc: 0.962741\ttraining's binary_logloss: 0.153095\n",
      "[4479]\ttraining's auc: 0.962758\ttraining's binary_logloss: 0.15308\n",
      "[4480]\ttraining's auc: 0.962779\ttraining's binary_logloss: 0.153062\n",
      "[4481]\ttraining's auc: 0.962797\ttraining's binary_logloss: 0.153048\n",
      "[4482]\ttraining's auc: 0.962816\ttraining's binary_logloss: 0.153034\n",
      "[4483]\ttraining's auc: 0.962825\ttraining's binary_logloss: 0.15302\n",
      "[4484]\ttraining's auc: 0.962843\ttraining's binary_logloss: 0.153006\n",
      "[4485]\ttraining's auc: 0.962857\ttraining's binary_logloss: 0.152991\n",
      "[4486]\ttraining's auc: 0.96287\ttraining's binary_logloss: 0.152979\n",
      "[4487]\ttraining's auc: 0.962888\ttraining's binary_logloss: 0.152963\n",
      "[4488]\ttraining's auc: 0.962909\ttraining's binary_logloss: 0.152949\n",
      "[4489]\ttraining's auc: 0.962919\ttraining's binary_logloss: 0.15294\n",
      "[4490]\ttraining's auc: 0.962929\ttraining's binary_logloss: 0.152928\n",
      "[4491]\ttraining's auc: 0.962934\ttraining's binary_logloss: 0.152921\n",
      "[4492]\ttraining's auc: 0.962935\ttraining's binary_logloss: 0.152919\n",
      "[4493]\ttraining's auc: 0.962955\ttraining's binary_logloss: 0.152899\n",
      "[4494]\ttraining's auc: 0.962976\ttraining's binary_logloss: 0.152884\n",
      "[4495]\ttraining's auc: 0.962994\ttraining's binary_logloss: 0.152868\n",
      "[4496]\ttraining's auc: 0.963012\ttraining's binary_logloss: 0.152852\n",
      "[4497]\ttraining's auc: 0.963027\ttraining's binary_logloss: 0.152836\n",
      "[4498]\ttraining's auc: 0.963043\ttraining's binary_logloss: 0.152822\n",
      "[4499]\ttraining's auc: 0.963063\ttraining's binary_logloss: 0.152808\n",
      "[4500]\ttraining's auc: 0.96308\ttraining's binary_logloss: 0.152792\n",
      "[4501]\ttraining's auc: 0.963097\ttraining's binary_logloss: 0.152777\n",
      "[4502]\ttraining's auc: 0.963117\ttraining's binary_logloss: 0.152762\n",
      "[4503]\ttraining's auc: 0.96313\ttraining's binary_logloss: 0.152744\n",
      "[4504]\ttraining's auc: 0.963143\ttraining's binary_logloss: 0.152729\n",
      "[4505]\ttraining's auc: 0.963157\ttraining's binary_logloss: 0.152715\n",
      "[4506]\ttraining's auc: 0.963175\ttraining's binary_logloss: 0.152699\n",
      "[4507]\ttraining's auc: 0.963197\ttraining's binary_logloss: 0.152685\n",
      "[4508]\ttraining's auc: 0.963196\ttraining's binary_logloss: 0.152682\n",
      "[4509]\ttraining's auc: 0.963203\ttraining's binary_logloss: 0.152666\n",
      "[4510]\ttraining's auc: 0.963215\ttraining's binary_logloss: 0.15265\n",
      "[4511]\ttraining's auc: 0.963232\ttraining's binary_logloss: 0.152637\n",
      "[4512]\ttraining's auc: 0.963251\ttraining's binary_logloss: 0.152622\n",
      "[4513]\ttraining's auc: 0.963263\ttraining's binary_logloss: 0.152607\n",
      "[4514]\ttraining's auc: 0.963271\ttraining's binary_logloss: 0.152593\n",
      "[4515]\ttraining's auc: 0.96329\ttraining's binary_logloss: 0.152576\n",
      "[4516]\ttraining's auc: 0.96331\ttraining's binary_logloss: 0.152559\n",
      "[4517]\ttraining's auc: 0.963329\ttraining's binary_logloss: 0.152543\n",
      "[4518]\ttraining's auc: 0.963353\ttraining's binary_logloss: 0.152527\n",
      "[4519]\ttraining's auc: 0.96337\ttraining's binary_logloss: 0.152512\n",
      "[4520]\ttraining's auc: 0.963387\ttraining's binary_logloss: 0.152496\n",
      "[4521]\ttraining's auc: 0.963401\ttraining's binary_logloss: 0.152482\n",
      "[4522]\ttraining's auc: 0.963415\ttraining's binary_logloss: 0.152468\n",
      "[4523]\ttraining's auc: 0.963435\ttraining's binary_logloss: 0.15245\n",
      "[4524]\ttraining's auc: 0.963453\ttraining's binary_logloss: 0.152432\n",
      "[4525]\ttraining's auc: 0.963454\ttraining's binary_logloss: 0.152431\n",
      "[4526]\ttraining's auc: 0.963468\ttraining's binary_logloss: 0.152418\n",
      "[4527]\ttraining's auc: 0.963488\ttraining's binary_logloss: 0.152403\n",
      "[4528]\ttraining's auc: 0.9635\ttraining's binary_logloss: 0.15239\n",
      "[4529]\ttraining's auc: 0.96352\ttraining's binary_logloss: 0.152373\n",
      "[4530]\ttraining's auc: 0.963524\ttraining's binary_logloss: 0.152368\n",
      "[4531]\ttraining's auc: 0.963543\ttraining's binary_logloss: 0.152355\n",
      "[4532]\ttraining's auc: 0.963551\ttraining's binary_logloss: 0.152347\n",
      "[4533]\ttraining's auc: 0.963573\ttraining's binary_logloss: 0.152332\n",
      "[4534]\ttraining's auc: 0.963585\ttraining's binary_logloss: 0.152318\n",
      "[4535]\ttraining's auc: 0.963603\ttraining's binary_logloss: 0.152301\n",
      "[4536]\ttraining's auc: 0.963619\ttraining's binary_logloss: 0.152285\n",
      "[4537]\ttraining's auc: 0.963631\ttraining's binary_logloss: 0.152271\n",
      "[4538]\ttraining's auc: 0.963646\ttraining's binary_logloss: 0.152258\n",
      "[4539]\ttraining's auc: 0.963668\ttraining's binary_logloss: 0.152243\n",
      "[4540]\ttraining's auc: 0.963678\ttraining's binary_logloss: 0.152234\n",
      "[4541]\ttraining's auc: 0.963697\ttraining's binary_logloss: 0.152221\n",
      "[4542]\ttraining's auc: 0.963706\ttraining's binary_logloss: 0.152208\n",
      "[4543]\ttraining's auc: 0.963718\ttraining's binary_logloss: 0.152194\n",
      "[4544]\ttraining's auc: 0.963741\ttraining's binary_logloss: 0.152178\n",
      "[4545]\ttraining's auc: 0.963754\ttraining's binary_logloss: 0.152164\n",
      "[4546]\ttraining's auc: 0.963774\ttraining's binary_logloss: 0.152149\n",
      "[4547]\ttraining's auc: 0.963787\ttraining's binary_logloss: 0.152135\n",
      "[4548]\ttraining's auc: 0.963789\ttraining's binary_logloss: 0.152133\n",
      "[4549]\ttraining's auc: 0.963808\ttraining's binary_logloss: 0.152117\n",
      "[4550]\ttraining's auc: 0.963817\ttraining's binary_logloss: 0.152104\n",
      "[4551]\ttraining's auc: 0.963839\ttraining's binary_logloss: 0.152088\n",
      "[4552]\ttraining's auc: 0.963857\ttraining's binary_logloss: 0.152074\n",
      "[4553]\ttraining's auc: 0.963874\ttraining's binary_logloss: 0.152062\n",
      "[4554]\ttraining's auc: 0.963891\ttraining's binary_logloss: 0.152048\n",
      "[4555]\ttraining's auc: 0.963907\ttraining's binary_logloss: 0.152033\n",
      "[4556]\ttraining's auc: 0.963925\ttraining's binary_logloss: 0.152016\n",
      "[4557]\ttraining's auc: 0.963926\ttraining's binary_logloss: 0.152015\n",
      "[4558]\ttraining's auc: 0.963938\ttraining's binary_logloss: 0.152002\n",
      "[4559]\ttraining's auc: 0.963955\ttraining's binary_logloss: 0.151989\n",
      "[4560]\ttraining's auc: 0.96397\ttraining's binary_logloss: 0.151975\n",
      "[4561]\ttraining's auc: 0.963984\ttraining's binary_logloss: 0.151963\n",
      "[4562]\ttraining's auc: 0.964006\ttraining's binary_logloss: 0.151947\n",
      "[4563]\ttraining's auc: 0.964021\ttraining's binary_logloss: 0.151931\n",
      "[4564]\ttraining's auc: 0.964036\ttraining's binary_logloss: 0.151916\n",
      "[4565]\ttraining's auc: 0.964051\ttraining's binary_logloss: 0.151902\n",
      "[4566]\ttraining's auc: 0.964062\ttraining's binary_logloss: 0.151887\n",
      "[4567]\ttraining's auc: 0.964083\ttraining's binary_logloss: 0.15187\n",
      "[4568]\ttraining's auc: 0.964105\ttraining's binary_logloss: 0.151855\n",
      "[4569]\ttraining's auc: 0.964123\ttraining's binary_logloss: 0.15184\n",
      "[4570]\ttraining's auc: 0.964145\ttraining's binary_logloss: 0.151821\n",
      "[4571]\ttraining's auc: 0.964162\ttraining's binary_logloss: 0.151806\n",
      "[4572]\ttraining's auc: 0.964178\ttraining's binary_logloss: 0.15179\n",
      "[4573]\ttraining's auc: 0.964195\ttraining's binary_logloss: 0.151775\n",
      "[4574]\ttraining's auc: 0.964203\ttraining's binary_logloss: 0.151763\n",
      "[4575]\ttraining's auc: 0.964222\ttraining's binary_logloss: 0.151748\n",
      "[4576]\ttraining's auc: 0.964241\ttraining's binary_logloss: 0.15173\n",
      "[4577]\ttraining's auc: 0.964257\ttraining's binary_logloss: 0.151712\n",
      "[4578]\ttraining's auc: 0.964275\ttraining's binary_logloss: 0.151696\n",
      "[4579]\ttraining's auc: 0.964285\ttraining's binary_logloss: 0.151684\n",
      "[4580]\ttraining's auc: 0.964297\ttraining's binary_logloss: 0.151669\n",
      "[4581]\ttraining's auc: 0.964303\ttraining's binary_logloss: 0.151655\n",
      "[4582]\ttraining's auc: 0.964324\ttraining's binary_logloss: 0.15164\n",
      "[4583]\ttraining's auc: 0.964334\ttraining's binary_logloss: 0.15163\n",
      "[4584]\ttraining's auc: 0.964352\ttraining's binary_logloss: 0.151615\n",
      "[4585]\ttraining's auc: 0.964364\ttraining's binary_logloss: 0.151599\n",
      "[4586]\ttraining's auc: 0.964376\ttraining's binary_logloss: 0.151586\n",
      "[4587]\ttraining's auc: 0.964388\ttraining's binary_logloss: 0.151572\n",
      "[4588]\ttraining's auc: 0.964399\ttraining's binary_logloss: 0.151559\n",
      "[4589]\ttraining's auc: 0.964415\ttraining's binary_logloss: 0.151547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4590]\ttraining's auc: 0.964424\ttraining's binary_logloss: 0.151532\n",
      "[4591]\ttraining's auc: 0.964438\ttraining's binary_logloss: 0.151519\n",
      "[4592]\ttraining's auc: 0.964455\ttraining's binary_logloss: 0.151506\n",
      "[4593]\ttraining's auc: 0.96447\ttraining's binary_logloss: 0.151492\n",
      "[4594]\ttraining's auc: 0.964485\ttraining's binary_logloss: 0.151478\n",
      "[4595]\ttraining's auc: 0.964495\ttraining's binary_logloss: 0.151464\n",
      "[4596]\ttraining's auc: 0.964508\ttraining's binary_logloss: 0.151449\n",
      "[4597]\ttraining's auc: 0.964532\ttraining's binary_logloss: 0.151434\n",
      "[4598]\ttraining's auc: 0.964551\ttraining's binary_logloss: 0.15142\n",
      "[4599]\ttraining's auc: 0.964552\ttraining's binary_logloss: 0.151419\n",
      "[4600]\ttraining's auc: 0.964573\ttraining's binary_logloss: 0.151403\n",
      "[4601]\ttraining's auc: 0.964592\ttraining's binary_logloss: 0.151389\n",
      "[4602]\ttraining's auc: 0.964597\ttraining's binary_logloss: 0.151382\n",
      "[4603]\ttraining's auc: 0.964607\ttraining's binary_logloss: 0.151369\n",
      "[4604]\ttraining's auc: 0.964618\ttraining's binary_logloss: 0.151355\n",
      "[4605]\ttraining's auc: 0.964636\ttraining's binary_logloss: 0.151338\n",
      "[4606]\ttraining's auc: 0.964654\ttraining's binary_logloss: 0.151324\n",
      "[4607]\ttraining's auc: 0.964662\ttraining's binary_logloss: 0.151315\n",
      "[4608]\ttraining's auc: 0.964673\ttraining's binary_logloss: 0.151305\n",
      "[4609]\ttraining's auc: 0.964689\ttraining's binary_logloss: 0.151291\n",
      "[4610]\ttraining's auc: 0.964706\ttraining's binary_logloss: 0.151274\n",
      "[4611]\ttraining's auc: 0.964711\ttraining's binary_logloss: 0.151267\n",
      "[4612]\ttraining's auc: 0.964721\ttraining's binary_logloss: 0.151255\n",
      "[4613]\ttraining's auc: 0.964731\ttraining's binary_logloss: 0.151247\n",
      "[4614]\ttraining's auc: 0.964741\ttraining's binary_logloss: 0.151238\n",
      "[4615]\ttraining's auc: 0.964753\ttraining's binary_logloss: 0.151224\n",
      "[4616]\ttraining's auc: 0.964764\ttraining's binary_logloss: 0.151208\n",
      "[4617]\ttraining's auc: 0.964781\ttraining's binary_logloss: 0.151194\n",
      "[4618]\ttraining's auc: 0.964803\ttraining's binary_logloss: 0.151179\n",
      "[4619]\ttraining's auc: 0.964817\ttraining's binary_logloss: 0.151164\n",
      "[4620]\ttraining's auc: 0.964831\ttraining's binary_logloss: 0.151148\n",
      "[4621]\ttraining's auc: 0.964843\ttraining's binary_logloss: 0.151137\n",
      "[4622]\ttraining's auc: 0.964852\ttraining's binary_logloss: 0.151128\n",
      "[4623]\ttraining's auc: 0.964857\ttraining's binary_logloss: 0.151123\n",
      "[4624]\ttraining's auc: 0.964874\ttraining's binary_logloss: 0.15111\n",
      "[4625]\ttraining's auc: 0.964887\ttraining's binary_logloss: 0.151098\n",
      "[4626]\ttraining's auc: 0.964899\ttraining's binary_logloss: 0.151084\n",
      "[4627]\ttraining's auc: 0.964909\ttraining's binary_logloss: 0.15107\n",
      "[4628]\ttraining's auc: 0.964929\ttraining's binary_logloss: 0.151056\n",
      "[4629]\ttraining's auc: 0.964944\ttraining's binary_logloss: 0.151043\n",
      "[4630]\ttraining's auc: 0.964968\ttraining's binary_logloss: 0.151024\n",
      "[4631]\ttraining's auc: 0.964983\ttraining's binary_logloss: 0.151008\n",
      "[4632]\ttraining's auc: 0.964994\ttraining's binary_logloss: 0.150994\n",
      "[4633]\ttraining's auc: 0.965006\ttraining's binary_logloss: 0.150981\n",
      "[4634]\ttraining's auc: 0.965019\ttraining's binary_logloss: 0.150967\n",
      "[4635]\ttraining's auc: 0.965028\ttraining's binary_logloss: 0.150953\n",
      "[4636]\ttraining's auc: 0.96503\ttraining's binary_logloss: 0.150951\n",
      "[4637]\ttraining's auc: 0.965042\ttraining's binary_logloss: 0.150936\n",
      "[4638]\ttraining's auc: 0.965049\ttraining's binary_logloss: 0.150931\n",
      "[4639]\ttraining's auc: 0.96507\ttraining's binary_logloss: 0.150915\n",
      "[4640]\ttraining's auc: 0.965089\ttraining's binary_logloss: 0.150897\n",
      "[4641]\ttraining's auc: 0.965103\ttraining's binary_logloss: 0.150883\n",
      "[4642]\ttraining's auc: 0.965119\ttraining's binary_logloss: 0.150867\n",
      "[4643]\ttraining's auc: 0.965133\ttraining's binary_logloss: 0.150852\n",
      "[4644]\ttraining's auc: 0.965151\ttraining's binary_logloss: 0.150838\n",
      "[4645]\ttraining's auc: 0.965161\ttraining's binary_logloss: 0.150826\n",
      "[4646]\ttraining's auc: 0.965176\ttraining's binary_logloss: 0.150812\n",
      "[4647]\ttraining's auc: 0.965195\ttraining's binary_logloss: 0.150796\n",
      "[4648]\ttraining's auc: 0.965213\ttraining's binary_logloss: 0.150783\n",
      "[4649]\ttraining's auc: 0.965226\ttraining's binary_logloss: 0.150769\n",
      "[4650]\ttraining's auc: 0.965241\ttraining's binary_logloss: 0.150753\n",
      "[4651]\ttraining's auc: 0.965254\ttraining's binary_logloss: 0.15074\n",
      "[4652]\ttraining's auc: 0.965263\ttraining's binary_logloss: 0.150726\n",
      "[4653]\ttraining's auc: 0.965264\ttraining's binary_logloss: 0.150724\n",
      "[4654]\ttraining's auc: 0.96527\ttraining's binary_logloss: 0.150716\n",
      "[4655]\ttraining's auc: 0.965284\ttraining's binary_logloss: 0.150705\n",
      "[4656]\ttraining's auc: 0.965296\ttraining's binary_logloss: 0.150692\n",
      "[4657]\ttraining's auc: 0.96531\ttraining's binary_logloss: 0.150677\n",
      "[4658]\ttraining's auc: 0.965322\ttraining's binary_logloss: 0.150664\n",
      "[4659]\ttraining's auc: 0.965333\ttraining's binary_logloss: 0.15065\n",
      "[4660]\ttraining's auc: 0.965352\ttraining's binary_logloss: 0.150634\n",
      "[4661]\ttraining's auc: 0.965367\ttraining's binary_logloss: 0.150618\n",
      "[4662]\ttraining's auc: 0.965383\ttraining's binary_logloss: 0.150603\n",
      "[4663]\ttraining's auc: 0.965396\ttraining's binary_logloss: 0.150589\n",
      "[4664]\ttraining's auc: 0.965411\ttraining's binary_logloss: 0.150574\n",
      "[4665]\ttraining's auc: 0.965432\ttraining's binary_logloss: 0.150561\n",
      "[4666]\ttraining's auc: 0.965446\ttraining's binary_logloss: 0.150548\n",
      "[4667]\ttraining's auc: 0.965456\ttraining's binary_logloss: 0.150535\n",
      "[4668]\ttraining's auc: 0.965469\ttraining's binary_logloss: 0.15052\n",
      "[4669]\ttraining's auc: 0.965476\ttraining's binary_logloss: 0.150514\n",
      "[4670]\ttraining's auc: 0.965497\ttraining's binary_logloss: 0.150498\n",
      "[4671]\ttraining's auc: 0.965509\ttraining's binary_logloss: 0.150482\n",
      "[4672]\ttraining's auc: 0.965527\ttraining's binary_logloss: 0.150466\n",
      "[4673]\ttraining's auc: 0.965526\ttraining's binary_logloss: 0.150462\n",
      "[4674]\ttraining's auc: 0.965551\ttraining's binary_logloss: 0.150444\n",
      "[4675]\ttraining's auc: 0.965576\ttraining's binary_logloss: 0.150428\n",
      "[4676]\ttraining's auc: 0.965586\ttraining's binary_logloss: 0.150416\n",
      "[4677]\ttraining's auc: 0.96559\ttraining's binary_logloss: 0.150411\n",
      "[4678]\ttraining's auc: 0.965604\ttraining's binary_logloss: 0.150397\n",
      "[4679]\ttraining's auc: 0.965615\ttraining's binary_logloss: 0.150383\n",
      "[4680]\ttraining's auc: 0.965637\ttraining's binary_logloss: 0.150366\n",
      "[4681]\ttraining's auc: 0.965647\ttraining's binary_logloss: 0.150359\n",
      "[4682]\ttraining's auc: 0.965662\ttraining's binary_logloss: 0.150347\n",
      "[4683]\ttraining's auc: 0.965682\ttraining's binary_logloss: 0.150329\n",
      "[4684]\ttraining's auc: 0.965693\ttraining's binary_logloss: 0.150315\n",
      "[4685]\ttraining's auc: 0.965711\ttraining's binary_logloss: 0.150299\n",
      "[4686]\ttraining's auc: 0.965721\ttraining's binary_logloss: 0.150285\n",
      "[4687]\ttraining's auc: 0.965742\ttraining's binary_logloss: 0.150269\n",
      "[4688]\ttraining's auc: 0.965753\ttraining's binary_logloss: 0.150255\n",
      "[4689]\ttraining's auc: 0.965772\ttraining's binary_logloss: 0.150239\n",
      "[4690]\ttraining's auc: 0.965789\ttraining's binary_logloss: 0.150225\n",
      "[4691]\ttraining's auc: 0.965811\ttraining's binary_logloss: 0.150209\n",
      "[4692]\ttraining's auc: 0.965824\ttraining's binary_logloss: 0.150196\n",
      "[4693]\ttraining's auc: 0.965836\ttraining's binary_logloss: 0.150185\n",
      "[4694]\ttraining's auc: 0.965848\ttraining's binary_logloss: 0.150173\n",
      "[4695]\ttraining's auc: 0.965869\ttraining's binary_logloss: 0.150156\n",
      "[4696]\ttraining's auc: 0.965887\ttraining's binary_logloss: 0.150142\n",
      "[4697]\ttraining's auc: 0.965906\ttraining's binary_logloss: 0.150128\n",
      "[4698]\ttraining's auc: 0.96592\ttraining's binary_logloss: 0.150113\n",
      "[4699]\ttraining's auc: 0.965935\ttraining's binary_logloss: 0.150101\n",
      "[4700]\ttraining's auc: 0.965951\ttraining's binary_logloss: 0.150087\n",
      "[4701]\ttraining's auc: 0.96597\ttraining's binary_logloss: 0.150072\n",
      "[4702]\ttraining's auc: 0.965986\ttraining's binary_logloss: 0.150056\n",
      "[4703]\ttraining's auc: 0.966004\ttraining's binary_logloss: 0.150041\n",
      "[4704]\ttraining's auc: 0.966018\ttraining's binary_logloss: 0.150027\n",
      "[4705]\ttraining's auc: 0.966034\ttraining's binary_logloss: 0.15001\n",
      "[4706]\ttraining's auc: 0.966038\ttraining's binary_logloss: 0.150005\n",
      "[4707]\ttraining's auc: 0.966058\ttraining's binary_logloss: 0.149987\n",
      "[4708]\ttraining's auc: 0.966078\ttraining's binary_logloss: 0.149971\n",
      "[4709]\ttraining's auc: 0.966083\ttraining's binary_logloss: 0.149963\n",
      "[4710]\ttraining's auc: 0.966099\ttraining's binary_logloss: 0.149948\n",
      "[4711]\ttraining's auc: 0.966117\ttraining's binary_logloss: 0.149928\n",
      "[4712]\ttraining's auc: 0.966138\ttraining's binary_logloss: 0.149912\n",
      "[4713]\ttraining's auc: 0.966139\ttraining's binary_logloss: 0.149908\n",
      "[4714]\ttraining's auc: 0.966152\ttraining's binary_logloss: 0.149895\n",
      "[4715]\ttraining's auc: 0.966174\ttraining's binary_logloss: 0.149877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4716]\ttraining's auc: 0.966186\ttraining's binary_logloss: 0.149863\n",
      "[4717]\ttraining's auc: 0.966199\ttraining's binary_logloss: 0.149847\n",
      "[4718]\ttraining's auc: 0.96621\ttraining's binary_logloss: 0.149837\n",
      "[4719]\ttraining's auc: 0.966214\ttraining's binary_logloss: 0.149833\n",
      "[4720]\ttraining's auc: 0.966239\ttraining's binary_logloss: 0.149814\n",
      "[4721]\ttraining's auc: 0.966258\ttraining's binary_logloss: 0.149797\n",
      "[4722]\ttraining's auc: 0.966271\ttraining's binary_logloss: 0.149782\n",
      "[4723]\ttraining's auc: 0.966285\ttraining's binary_logloss: 0.149767\n",
      "[4724]\ttraining's auc: 0.966302\ttraining's binary_logloss: 0.149752\n",
      "[4725]\ttraining's auc: 0.966314\ttraining's binary_logloss: 0.149741\n",
      "[4726]\ttraining's auc: 0.966322\ttraining's binary_logloss: 0.149731\n",
      "[4727]\ttraining's auc: 0.966335\ttraining's binary_logloss: 0.149717\n",
      "[4728]\ttraining's auc: 0.966345\ttraining's binary_logloss: 0.149704\n",
      "[4729]\ttraining's auc: 0.966362\ttraining's binary_logloss: 0.149687\n",
      "[4730]\ttraining's auc: 0.966374\ttraining's binary_logloss: 0.149673\n",
      "[4731]\ttraining's auc: 0.966388\ttraining's binary_logloss: 0.14966\n",
      "[4732]\ttraining's auc: 0.966403\ttraining's binary_logloss: 0.149646\n",
      "[4733]\ttraining's auc: 0.96642\ttraining's binary_logloss: 0.149632\n",
      "[4734]\ttraining's auc: 0.966439\ttraining's binary_logloss: 0.149616\n",
      "[4735]\ttraining's auc: 0.966449\ttraining's binary_logloss: 0.149603\n",
      "[4736]\ttraining's auc: 0.966455\ttraining's binary_logloss: 0.149588\n",
      "[4737]\ttraining's auc: 0.966456\ttraining's binary_logloss: 0.149585\n",
      "[4738]\ttraining's auc: 0.966476\ttraining's binary_logloss: 0.149571\n",
      "[4739]\ttraining's auc: 0.966495\ttraining's binary_logloss: 0.149553\n",
      "[4740]\ttraining's auc: 0.9665\ttraining's binary_logloss: 0.149545\n",
      "[4741]\ttraining's auc: 0.966513\ttraining's binary_logloss: 0.149534\n",
      "[4742]\ttraining's auc: 0.966524\ttraining's binary_logloss: 0.14952\n",
      "[4743]\ttraining's auc: 0.966542\ttraining's binary_logloss: 0.149506\n",
      "[4744]\ttraining's auc: 0.966564\ttraining's binary_logloss: 0.149489\n",
      "[4745]\ttraining's auc: 0.966588\ttraining's binary_logloss: 0.149471\n",
      "[4746]\ttraining's auc: 0.966609\ttraining's binary_logloss: 0.149457\n",
      "[4747]\ttraining's auc: 0.966621\ttraining's binary_logloss: 0.149442\n",
      "[4748]\ttraining's auc: 0.966637\ttraining's binary_logloss: 0.149429\n",
      "[4749]\ttraining's auc: 0.96665\ttraining's binary_logloss: 0.149417\n",
      "[4750]\ttraining's auc: 0.96667\ttraining's binary_logloss: 0.149399\n",
      "[4751]\ttraining's auc: 0.966681\ttraining's binary_logloss: 0.149389\n",
      "[4752]\ttraining's auc: 0.966693\ttraining's binary_logloss: 0.149379\n",
      "[4753]\ttraining's auc: 0.966712\ttraining's binary_logloss: 0.149362\n",
      "[4754]\ttraining's auc: 0.966718\ttraining's binary_logloss: 0.149353\n",
      "[4755]\ttraining's auc: 0.96673\ttraining's binary_logloss: 0.149339\n",
      "[4756]\ttraining's auc: 0.966747\ttraining's binary_logloss: 0.149324\n",
      "[4757]\ttraining's auc: 0.966763\ttraining's binary_logloss: 0.149309\n",
      "[4758]\ttraining's auc: 0.966781\ttraining's binary_logloss: 0.149293\n",
      "[4759]\ttraining's auc: 0.966792\ttraining's binary_logloss: 0.149282\n",
      "[4760]\ttraining's auc: 0.966805\ttraining's binary_logloss: 0.149269\n",
      "[4761]\ttraining's auc: 0.966821\ttraining's binary_logloss: 0.149254\n",
      "[4762]\ttraining's auc: 0.966836\ttraining's binary_logloss: 0.149239\n",
      "[4763]\ttraining's auc: 0.966851\ttraining's binary_logloss: 0.149223\n",
      "[4764]\ttraining's auc: 0.966866\ttraining's binary_logloss: 0.149209\n",
      "[4765]\ttraining's auc: 0.966884\ttraining's binary_logloss: 0.149193\n",
      "[4766]\ttraining's auc: 0.96689\ttraining's binary_logloss: 0.149187\n",
      "[4767]\ttraining's auc: 0.966905\ttraining's binary_logloss: 0.149172\n",
      "[4768]\ttraining's auc: 0.966904\ttraining's binary_logloss: 0.14917\n",
      "[4769]\ttraining's auc: 0.966922\ttraining's binary_logloss: 0.149156\n",
      "[4770]\ttraining's auc: 0.966938\ttraining's binary_logloss: 0.149141\n",
      "[4771]\ttraining's auc: 0.966951\ttraining's binary_logloss: 0.149127\n",
      "[4772]\ttraining's auc: 0.966969\ttraining's binary_logloss: 0.149113\n",
      "[4773]\ttraining's auc: 0.966979\ttraining's binary_logloss: 0.149101\n",
      "[4774]\ttraining's auc: 0.966997\ttraining's binary_logloss: 0.149085\n",
      "[4775]\ttraining's auc: 0.967002\ttraining's binary_logloss: 0.149073\n",
      "[4776]\ttraining's auc: 0.967015\ttraining's binary_logloss: 0.149057\n",
      "[4777]\ttraining's auc: 0.967028\ttraining's binary_logloss: 0.149044\n",
      "[4778]\ttraining's auc: 0.967031\ttraining's binary_logloss: 0.149041\n",
      "[4779]\ttraining's auc: 0.967052\ttraining's binary_logloss: 0.149026\n",
      "[4780]\ttraining's auc: 0.967059\ttraining's binary_logloss: 0.149013\n",
      "[4781]\ttraining's auc: 0.967076\ttraining's binary_logloss: 0.148998\n",
      "[4782]\ttraining's auc: 0.967086\ttraining's binary_logloss: 0.148987\n",
      "[4783]\ttraining's auc: 0.967104\ttraining's binary_logloss: 0.14897\n",
      "[4784]\ttraining's auc: 0.967112\ttraining's binary_logloss: 0.148958\n",
      "[4785]\ttraining's auc: 0.967118\ttraining's binary_logloss: 0.148951\n",
      "[4786]\ttraining's auc: 0.967137\ttraining's binary_logloss: 0.148933\n",
      "[4787]\ttraining's auc: 0.967147\ttraining's binary_logloss: 0.14892\n",
      "[4788]\ttraining's auc: 0.967156\ttraining's binary_logloss: 0.148907\n",
      "[4789]\ttraining's auc: 0.96717\ttraining's binary_logloss: 0.148891\n",
      "[4790]\ttraining's auc: 0.967179\ttraining's binary_logloss: 0.14888\n",
      "[4791]\ttraining's auc: 0.967202\ttraining's binary_logloss: 0.148862\n",
      "[4792]\ttraining's auc: 0.967222\ttraining's binary_logloss: 0.148846\n",
      "[4793]\ttraining's auc: 0.967244\ttraining's binary_logloss: 0.148831\n",
      "[4794]\ttraining's auc: 0.967257\ttraining's binary_logloss: 0.148819\n",
      "[4795]\ttraining's auc: 0.967269\ttraining's binary_logloss: 0.148807\n",
      "[4796]\ttraining's auc: 0.967278\ttraining's binary_logloss: 0.148799\n",
      "[4797]\ttraining's auc: 0.96728\ttraining's binary_logloss: 0.148796\n",
      "[4798]\ttraining's auc: 0.967292\ttraining's binary_logloss: 0.148783\n",
      "[4799]\ttraining's auc: 0.967304\ttraining's binary_logloss: 0.148771\n",
      "[4800]\ttraining's auc: 0.967308\ttraining's binary_logloss: 0.148766\n",
      "[4801]\ttraining's auc: 0.967316\ttraining's binary_logloss: 0.148755\n",
      "[4802]\ttraining's auc: 0.967331\ttraining's binary_logloss: 0.148738\n",
      "[4803]\ttraining's auc: 0.96734\ttraining's binary_logloss: 0.148729\n",
      "[4804]\ttraining's auc: 0.967356\ttraining's binary_logloss: 0.148715\n",
      "[4805]\ttraining's auc: 0.967373\ttraining's binary_logloss: 0.148699\n",
      "[4806]\ttraining's auc: 0.967394\ttraining's binary_logloss: 0.148683\n",
      "[4807]\ttraining's auc: 0.9674\ttraining's binary_logloss: 0.148672\n",
      "[4808]\ttraining's auc: 0.967415\ttraining's binary_logloss: 0.148657\n",
      "[4809]\ttraining's auc: 0.967429\ttraining's binary_logloss: 0.148643\n",
      "[4810]\ttraining's auc: 0.967441\ttraining's binary_logloss: 0.14863\n",
      "[4811]\ttraining's auc: 0.967445\ttraining's binary_logloss: 0.148625\n",
      "[4812]\ttraining's auc: 0.967453\ttraining's binary_logloss: 0.148614\n",
      "[4813]\ttraining's auc: 0.967468\ttraining's binary_logloss: 0.1486\n",
      "[4814]\ttraining's auc: 0.967484\ttraining's binary_logloss: 0.148585\n",
      "[4815]\ttraining's auc: 0.967498\ttraining's binary_logloss: 0.148571\n",
      "[4816]\ttraining's auc: 0.967507\ttraining's binary_logloss: 0.148558\n",
      "[4817]\ttraining's auc: 0.967516\ttraining's binary_logloss: 0.148549\n",
      "[4818]\ttraining's auc: 0.96753\ttraining's binary_logloss: 0.148534\n",
      "[4819]\ttraining's auc: 0.96754\ttraining's binary_logloss: 0.148522\n",
      "[4820]\ttraining's auc: 0.967553\ttraining's binary_logloss: 0.148507\n",
      "[4821]\ttraining's auc: 0.967561\ttraining's binary_logloss: 0.148494\n",
      "[4822]\ttraining's auc: 0.967579\ttraining's binary_logloss: 0.148479\n",
      "[4823]\ttraining's auc: 0.9676\ttraining's binary_logloss: 0.148462\n",
      "[4824]\ttraining's auc: 0.96761\ttraining's binary_logloss: 0.148452\n",
      "[4825]\ttraining's auc: 0.967622\ttraining's binary_logloss: 0.148436\n",
      "[4826]\ttraining's auc: 0.967641\ttraining's binary_logloss: 0.148421\n",
      "[4827]\ttraining's auc: 0.967659\ttraining's binary_logloss: 0.148406\n",
      "[4828]\ttraining's auc: 0.967673\ttraining's binary_logloss: 0.148392\n",
      "[4829]\ttraining's auc: 0.967686\ttraining's binary_logloss: 0.148379\n",
      "[4830]\ttraining's auc: 0.96769\ttraining's binary_logloss: 0.148373\n",
      "[4831]\ttraining's auc: 0.96771\ttraining's binary_logloss: 0.148356\n",
      "[4832]\ttraining's auc: 0.967712\ttraining's binary_logloss: 0.148352\n",
      "[4833]\ttraining's auc: 0.967725\ttraining's binary_logloss: 0.148343\n",
      "[4834]\ttraining's auc: 0.96774\ttraining's binary_logloss: 0.148328\n",
      "[4835]\ttraining's auc: 0.967757\ttraining's binary_logloss: 0.148313\n",
      "[4836]\ttraining's auc: 0.967762\ttraining's binary_logloss: 0.148308\n",
      "[4837]\ttraining's auc: 0.967765\ttraining's binary_logloss: 0.148304\n",
      "[4838]\ttraining's auc: 0.967783\ttraining's binary_logloss: 0.14829\n",
      "[4839]\ttraining's auc: 0.967804\ttraining's binary_logloss: 0.148272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4840]\ttraining's auc: 0.967819\ttraining's binary_logloss: 0.148255\n",
      "[4841]\ttraining's auc: 0.967826\ttraining's binary_logloss: 0.148243\n",
      "[4842]\ttraining's auc: 0.967841\ttraining's binary_logloss: 0.148227\n",
      "[4843]\ttraining's auc: 0.967851\ttraining's binary_logloss: 0.14822\n",
      "[4844]\ttraining's auc: 0.96787\ttraining's binary_logloss: 0.148204\n",
      "[4845]\ttraining's auc: 0.967884\ttraining's binary_logloss: 0.148191\n",
      "[4846]\ttraining's auc: 0.9679\ttraining's binary_logloss: 0.148175\n",
      "[4847]\ttraining's auc: 0.967916\ttraining's binary_logloss: 0.148159\n",
      "[4848]\ttraining's auc: 0.967933\ttraining's binary_logloss: 0.148144\n",
      "[4849]\ttraining's auc: 0.967939\ttraining's binary_logloss: 0.148137\n",
      "[4850]\ttraining's auc: 0.967953\ttraining's binary_logloss: 0.148122\n",
      "[4851]\ttraining's auc: 0.967956\ttraining's binary_logloss: 0.148119\n",
      "[4852]\ttraining's auc: 0.96796\ttraining's binary_logloss: 0.148116\n",
      "[4853]\ttraining's auc: 0.967978\ttraining's binary_logloss: 0.148102\n",
      "[4854]\ttraining's auc: 0.967983\ttraining's binary_logloss: 0.148097\n",
      "[4855]\ttraining's auc: 0.967996\ttraining's binary_logloss: 0.148086\n",
      "[4856]\ttraining's auc: 0.968012\ttraining's binary_logloss: 0.14807\n",
      "[4857]\ttraining's auc: 0.968025\ttraining's binary_logloss: 0.148056\n",
      "[4858]\ttraining's auc: 0.968038\ttraining's binary_logloss: 0.148043\n",
      "[4859]\ttraining's auc: 0.968041\ttraining's binary_logloss: 0.148038\n",
      "[4860]\ttraining's auc: 0.968054\ttraining's binary_logloss: 0.148025\n",
      "[4861]\ttraining's auc: 0.968068\ttraining's binary_logloss: 0.14801\n",
      "[4862]\ttraining's auc: 0.96807\ttraining's binary_logloss: 0.148008\n",
      "[4863]\ttraining's auc: 0.968072\ttraining's binary_logloss: 0.148006\n",
      "[4864]\ttraining's auc: 0.968077\ttraining's binary_logloss: 0.148001\n",
      "[4865]\ttraining's auc: 0.968091\ttraining's binary_logloss: 0.147988\n",
      "[4866]\ttraining's auc: 0.968109\ttraining's binary_logloss: 0.147974\n",
      "[4867]\ttraining's auc: 0.968124\ttraining's binary_logloss: 0.14796\n",
      "[4868]\ttraining's auc: 0.968129\ttraining's binary_logloss: 0.147952\n",
      "[4869]\ttraining's auc: 0.968136\ttraining's binary_logloss: 0.147945\n",
      "[4870]\ttraining's auc: 0.968148\ttraining's binary_logloss: 0.147931\n",
      "[4871]\ttraining's auc: 0.968161\ttraining's binary_logloss: 0.147913\n",
      "[4872]\ttraining's auc: 0.968163\ttraining's binary_logloss: 0.147908\n",
      "[4873]\ttraining's auc: 0.968178\ttraining's binary_logloss: 0.147892\n",
      "[4874]\ttraining's auc: 0.96819\ttraining's binary_logloss: 0.147878\n",
      "[4875]\ttraining's auc: 0.968207\ttraining's binary_logloss: 0.147864\n",
      "[4876]\ttraining's auc: 0.968216\ttraining's binary_logloss: 0.147854\n",
      "[4877]\ttraining's auc: 0.968225\ttraining's binary_logloss: 0.147843\n",
      "[4878]\ttraining's auc: 0.968241\ttraining's binary_logloss: 0.147829\n",
      "[4879]\ttraining's auc: 0.968254\ttraining's binary_logloss: 0.147815\n",
      "[4880]\ttraining's auc: 0.968268\ttraining's binary_logloss: 0.1478\n",
      "[4881]\ttraining's auc: 0.968288\ttraining's binary_logloss: 0.147784\n",
      "[4882]\ttraining's auc: 0.968305\ttraining's binary_logloss: 0.14777\n",
      "[4883]\ttraining's auc: 0.968313\ttraining's binary_logloss: 0.147756\n",
      "[4884]\ttraining's auc: 0.968331\ttraining's binary_logloss: 0.147741\n",
      "[4885]\ttraining's auc: 0.968355\ttraining's binary_logloss: 0.147726\n",
      "[4886]\ttraining's auc: 0.968357\ttraining's binary_logloss: 0.147721\n",
      "[4887]\ttraining's auc: 0.968366\ttraining's binary_logloss: 0.147712\n",
      "[4888]\ttraining's auc: 0.968376\ttraining's binary_logloss: 0.147698\n",
      "[4889]\ttraining's auc: 0.968394\ttraining's binary_logloss: 0.147684\n",
      "[4890]\ttraining's auc: 0.968395\ttraining's binary_logloss: 0.147682\n",
      "[4891]\ttraining's auc: 0.968399\ttraining's binary_logloss: 0.147678\n",
      "[4892]\ttraining's auc: 0.968405\ttraining's binary_logloss: 0.147668\n",
      "[4893]\ttraining's auc: 0.968409\ttraining's binary_logloss: 0.147665\n",
      "[4894]\ttraining's auc: 0.968412\ttraining's binary_logloss: 0.147661\n",
      "[4895]\ttraining's auc: 0.96843\ttraining's binary_logloss: 0.147645\n",
      "[4896]\ttraining's auc: 0.968442\ttraining's binary_logloss: 0.147629\n",
      "[4897]\ttraining's auc: 0.968459\ttraining's binary_logloss: 0.147616\n",
      "[4898]\ttraining's auc: 0.968477\ttraining's binary_logloss: 0.147601\n",
      "[4899]\ttraining's auc: 0.968478\ttraining's binary_logloss: 0.147597\n",
      "[4900]\ttraining's auc: 0.968482\ttraining's binary_logloss: 0.147593\n",
      "[4901]\ttraining's auc: 0.968496\ttraining's binary_logloss: 0.147576\n",
      "[4902]\ttraining's auc: 0.96851\ttraining's binary_logloss: 0.147562\n",
      "[4903]\ttraining's auc: 0.968514\ttraining's binary_logloss: 0.147559\n",
      "[4904]\ttraining's auc: 0.968517\ttraining's binary_logloss: 0.14755\n",
      "[4905]\ttraining's auc: 0.968532\ttraining's binary_logloss: 0.147533\n",
      "[4906]\ttraining's auc: 0.96854\ttraining's binary_logloss: 0.147524\n",
      "[4907]\ttraining's auc: 0.968561\ttraining's binary_logloss: 0.14751\n",
      "[4908]\ttraining's auc: 0.968573\ttraining's binary_logloss: 0.147497\n",
      "[4909]\ttraining's auc: 0.968586\ttraining's binary_logloss: 0.147483\n",
      "[4910]\ttraining's auc: 0.9686\ttraining's binary_logloss: 0.147468\n",
      "[4911]\ttraining's auc: 0.968614\ttraining's binary_logloss: 0.147454\n",
      "[4912]\ttraining's auc: 0.968631\ttraining's binary_logloss: 0.147438\n",
      "[4913]\ttraining's auc: 0.968643\ttraining's binary_logloss: 0.147424\n",
      "[4914]\ttraining's auc: 0.968654\ttraining's binary_logloss: 0.147413\n",
      "[4915]\ttraining's auc: 0.968661\ttraining's binary_logloss: 0.147403\n",
      "[4916]\ttraining's auc: 0.968674\ttraining's binary_logloss: 0.147389\n",
      "[4917]\ttraining's auc: 0.968686\ttraining's binary_logloss: 0.147375\n",
      "[4918]\ttraining's auc: 0.9687\ttraining's binary_logloss: 0.147362\n",
      "[4919]\ttraining's auc: 0.968707\ttraining's binary_logloss: 0.147354\n",
      "[4920]\ttraining's auc: 0.968711\ttraining's binary_logloss: 0.14735\n",
      "[4921]\ttraining's auc: 0.968733\ttraining's binary_logloss: 0.147334\n",
      "[4922]\ttraining's auc: 0.968739\ttraining's binary_logloss: 0.147325\n",
      "[4923]\ttraining's auc: 0.968752\ttraining's binary_logloss: 0.147311\n",
      "[4924]\ttraining's auc: 0.968768\ttraining's binary_logloss: 0.147297\n",
      "[4925]\ttraining's auc: 0.968776\ttraining's binary_logloss: 0.147284\n",
      "[4926]\ttraining's auc: 0.968793\ttraining's binary_logloss: 0.147267\n",
      "[4927]\ttraining's auc: 0.968812\ttraining's binary_logloss: 0.147252\n",
      "[4928]\ttraining's auc: 0.968827\ttraining's binary_logloss: 0.147238\n",
      "[4929]\ttraining's auc: 0.968834\ttraining's binary_logloss: 0.147232\n",
      "[4930]\ttraining's auc: 0.968845\ttraining's binary_logloss: 0.147219\n",
      "[4931]\ttraining's auc: 0.968864\ttraining's binary_logloss: 0.147204\n",
      "[4932]\ttraining's auc: 0.968883\ttraining's binary_logloss: 0.147189\n",
      "[4933]\ttraining's auc: 0.968886\ttraining's binary_logloss: 0.147187\n",
      "[4934]\ttraining's auc: 0.968894\ttraining's binary_logloss: 0.147181\n",
      "[4935]\ttraining's auc: 0.968897\ttraining's binary_logloss: 0.147178\n",
      "[4936]\ttraining's auc: 0.9689\ttraining's binary_logloss: 0.147174\n",
      "[4937]\ttraining's auc: 0.968908\ttraining's binary_logloss: 0.147168\n",
      "[4938]\ttraining's auc: 0.968919\ttraining's binary_logloss: 0.147152\n",
      "[4939]\ttraining's auc: 0.96894\ttraining's binary_logloss: 0.147136\n",
      "[4940]\ttraining's auc: 0.968951\ttraining's binary_logloss: 0.147124\n",
      "[4941]\ttraining's auc: 0.968967\ttraining's binary_logloss: 0.147109\n",
      "[4942]\ttraining's auc: 0.968985\ttraining's binary_logloss: 0.147093\n",
      "[4943]\ttraining's auc: 0.968987\ttraining's binary_logloss: 0.147091\n",
      "[4944]\ttraining's auc: 0.969\ttraining's binary_logloss: 0.147077\n",
      "[4945]\ttraining's auc: 0.969015\ttraining's binary_logloss: 0.147064\n",
      "[4946]\ttraining's auc: 0.969028\ttraining's binary_logloss: 0.147051\n",
      "[4947]\ttraining's auc: 0.969033\ttraining's binary_logloss: 0.147047\n",
      "[4948]\ttraining's auc: 0.969038\ttraining's binary_logloss: 0.147041\n",
      "[4949]\ttraining's auc: 0.96905\ttraining's binary_logloss: 0.147028\n",
      "[4950]\ttraining's auc: 0.969067\ttraining's binary_logloss: 0.147012\n",
      "[4951]\ttraining's auc: 0.969082\ttraining's binary_logloss: 0.146998\n",
      "[4952]\ttraining's auc: 0.969099\ttraining's binary_logloss: 0.146985\n",
      "[4953]\ttraining's auc: 0.969101\ttraining's binary_logloss: 0.146982\n",
      "[4954]\ttraining's auc: 0.969104\ttraining's binary_logloss: 0.146977\n",
      "[4955]\ttraining's auc: 0.969118\ttraining's binary_logloss: 0.146964\n",
      "[4956]\ttraining's auc: 0.969134\ttraining's binary_logloss: 0.146951\n",
      "[4957]\ttraining's auc: 0.96915\ttraining's binary_logloss: 0.146938\n",
      "[4958]\ttraining's auc: 0.969166\ttraining's binary_logloss: 0.146923\n",
      "[4959]\ttraining's auc: 0.969175\ttraining's binary_logloss: 0.146908\n",
      "[4960]\ttraining's auc: 0.969181\ttraining's binary_logloss: 0.146897\n",
      "[4961]\ttraining's auc: 0.969201\ttraining's binary_logloss: 0.14688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4962]\ttraining's auc: 0.969209\ttraining's binary_logloss: 0.146865\n",
      "[4963]\ttraining's auc: 0.969224\ttraining's binary_logloss: 0.146851\n",
      "[4964]\ttraining's auc: 0.969236\ttraining's binary_logloss: 0.146834\n",
      "[4965]\ttraining's auc: 0.969254\ttraining's binary_logloss: 0.146817\n",
      "[4966]\ttraining's auc: 0.969263\ttraining's binary_logloss: 0.146806\n",
      "[4967]\ttraining's auc: 0.969281\ttraining's binary_logloss: 0.146789\n",
      "[4968]\ttraining's auc: 0.969303\ttraining's binary_logloss: 0.146773\n",
      "[4969]\ttraining's auc: 0.969312\ttraining's binary_logloss: 0.146763\n",
      "[4970]\ttraining's auc: 0.969324\ttraining's binary_logloss: 0.146749\n",
      "[4971]\ttraining's auc: 0.969338\ttraining's binary_logloss: 0.146736\n",
      "[4972]\ttraining's auc: 0.96935\ttraining's binary_logloss: 0.146723\n",
      "[4973]\ttraining's auc: 0.969364\ttraining's binary_logloss: 0.14671\n",
      "[4974]\ttraining's auc: 0.969379\ttraining's binary_logloss: 0.146695\n",
      "[4975]\ttraining's auc: 0.96939\ttraining's binary_logloss: 0.146682\n",
      "[4976]\ttraining's auc: 0.969408\ttraining's binary_logloss: 0.146666\n",
      "[4977]\ttraining's auc: 0.96942\ttraining's binary_logloss: 0.146651\n",
      "[4978]\ttraining's auc: 0.969438\ttraining's binary_logloss: 0.146636\n",
      "[4979]\ttraining's auc: 0.969452\ttraining's binary_logloss: 0.14662\n",
      "[4980]\ttraining's auc: 0.969467\ttraining's binary_logloss: 0.146606\n",
      "[4981]\ttraining's auc: 0.969479\ttraining's binary_logloss: 0.146593\n",
      "[4982]\ttraining's auc: 0.969492\ttraining's binary_logloss: 0.146578\n",
      "[4983]\ttraining's auc: 0.969509\ttraining's binary_logloss: 0.146565\n",
      "[4984]\ttraining's auc: 0.969522\ttraining's binary_logloss: 0.146549\n",
      "[4985]\ttraining's auc: 0.969533\ttraining's binary_logloss: 0.146534\n",
      "[4986]\ttraining's auc: 0.969543\ttraining's binary_logloss: 0.14652\n",
      "[4987]\ttraining's auc: 0.969554\ttraining's binary_logloss: 0.146509\n",
      "[4988]\ttraining's auc: 0.969562\ttraining's binary_logloss: 0.146501\n",
      "[4989]\ttraining's auc: 0.969568\ttraining's binary_logloss: 0.146494\n",
      "[4990]\ttraining's auc: 0.969593\ttraining's binary_logloss: 0.146475\n",
      "[4991]\ttraining's auc: 0.969605\ttraining's binary_logloss: 0.146463\n",
      "[4992]\ttraining's auc: 0.969619\ttraining's binary_logloss: 0.14645\n",
      "[4993]\ttraining's auc: 0.969619\ttraining's binary_logloss: 0.146448\n",
      "[4994]\ttraining's auc: 0.969629\ttraining's binary_logloss: 0.146436\n",
      "[4995]\ttraining's auc: 0.969634\ttraining's binary_logloss: 0.146433\n",
      "[4996]\ttraining's auc: 0.969636\ttraining's binary_logloss: 0.146431\n",
      "[4997]\ttraining's auc: 0.96965\ttraining's binary_logloss: 0.146416\n",
      "[4998]\ttraining's auc: 0.969665\ttraining's binary_logloss: 0.146401\n",
      "[4999]\ttraining's auc: 0.969684\ttraining's binary_logloss: 0.146387\n",
      "[5000]\ttraining's auc: 0.969693\ttraining's binary_logloss: 0.146372\n",
      "[5001]\ttraining's auc: 0.96971\ttraining's binary_logloss: 0.146358\n",
      "[5002]\ttraining's auc: 0.969718\ttraining's binary_logloss: 0.146351\n",
      "[5003]\ttraining's auc: 0.969729\ttraining's binary_logloss: 0.146336\n",
      "[5004]\ttraining's auc: 0.969746\ttraining's binary_logloss: 0.146323\n",
      "[5005]\ttraining's auc: 0.969759\ttraining's binary_logloss: 0.14631\n",
      "[5006]\ttraining's auc: 0.969767\ttraining's binary_logloss: 0.146299\n",
      "[5007]\ttraining's auc: 0.969783\ttraining's binary_logloss: 0.146285\n",
      "[5008]\ttraining's auc: 0.969798\ttraining's binary_logloss: 0.146271\n",
      "[5009]\ttraining's auc: 0.969817\ttraining's binary_logloss: 0.146256\n",
      "[5010]\ttraining's auc: 0.969831\ttraining's binary_logloss: 0.146244\n",
      "[5011]\ttraining's auc: 0.969843\ttraining's binary_logloss: 0.146228\n",
      "[5012]\ttraining's auc: 0.96986\ttraining's binary_logloss: 0.146213\n",
      "[5013]\ttraining's auc: 0.969862\ttraining's binary_logloss: 0.14621\n",
      "[5014]\ttraining's auc: 0.96987\ttraining's binary_logloss: 0.1462\n",
      "[5015]\ttraining's auc: 0.969873\ttraining's binary_logloss: 0.146197\n",
      "[5016]\ttraining's auc: 0.969885\ttraining's binary_logloss: 0.146183\n",
      "[5017]\ttraining's auc: 0.969895\ttraining's binary_logloss: 0.146169\n",
      "[5018]\ttraining's auc: 0.969905\ttraining's binary_logloss: 0.146159\n",
      "[5019]\ttraining's auc: 0.969916\ttraining's binary_logloss: 0.146144\n",
      "[5020]\ttraining's auc: 0.969936\ttraining's binary_logloss: 0.146128\n",
      "[5021]\ttraining's auc: 0.969947\ttraining's binary_logloss: 0.146116\n",
      "[5022]\ttraining's auc: 0.969962\ttraining's binary_logloss: 0.146101\n",
      "[5023]\ttraining's auc: 0.969973\ttraining's binary_logloss: 0.146088\n",
      "[5024]\ttraining's auc: 0.969976\ttraining's binary_logloss: 0.146085\n",
      "[5025]\ttraining's auc: 0.969988\ttraining's binary_logloss: 0.146073\n",
      "[5026]\ttraining's auc: 0.969999\ttraining's binary_logloss: 0.146061\n",
      "[5027]\ttraining's auc: 0.970014\ttraining's binary_logloss: 0.146049\n",
      "[5028]\ttraining's auc: 0.970022\ttraining's binary_logloss: 0.146041\n",
      "[5029]\ttraining's auc: 0.97004\ttraining's binary_logloss: 0.146026\n",
      "[5030]\ttraining's auc: 0.970055\ttraining's binary_logloss: 0.146015\n",
      "[5031]\ttraining's auc: 0.970068\ttraining's binary_logloss: 0.146002\n",
      "[5032]\ttraining's auc: 0.970078\ttraining's binary_logloss: 0.145991\n",
      "[5033]\ttraining's auc: 0.970091\ttraining's binary_logloss: 0.145975\n",
      "[5034]\ttraining's auc: 0.970101\ttraining's binary_logloss: 0.145965\n",
      "[5035]\ttraining's auc: 0.970112\ttraining's binary_logloss: 0.145954\n",
      "[5036]\ttraining's auc: 0.970128\ttraining's binary_logloss: 0.145939\n",
      "[5037]\ttraining's auc: 0.970139\ttraining's binary_logloss: 0.145925\n",
      "[5038]\ttraining's auc: 0.970155\ttraining's binary_logloss: 0.145911\n",
      "[5039]\ttraining's auc: 0.970168\ttraining's binary_logloss: 0.145897\n",
      "[5040]\ttraining's auc: 0.970185\ttraining's binary_logloss: 0.145883\n",
      "[5041]\ttraining's auc: 0.970204\ttraining's binary_logloss: 0.145868\n",
      "[5042]\ttraining's auc: 0.970218\ttraining's binary_logloss: 0.145853\n",
      "[5043]\ttraining's auc: 0.970234\ttraining's binary_logloss: 0.145838\n",
      "[5044]\ttraining's auc: 0.970238\ttraining's binary_logloss: 0.145829\n",
      "[5045]\ttraining's auc: 0.97024\ttraining's binary_logloss: 0.145826\n",
      "[5046]\ttraining's auc: 0.970248\ttraining's binary_logloss: 0.14582\n",
      "[5047]\ttraining's auc: 0.970259\ttraining's binary_logloss: 0.145808\n",
      "[5048]\ttraining's auc: 0.97027\ttraining's binary_logloss: 0.145795\n",
      "[5049]\ttraining's auc: 0.970283\ttraining's binary_logloss: 0.145781\n",
      "[5050]\ttraining's auc: 0.970298\ttraining's binary_logloss: 0.145768\n",
      "[5051]\ttraining's auc: 0.970314\ttraining's binary_logloss: 0.145753\n",
      "[5052]\ttraining's auc: 0.970333\ttraining's binary_logloss: 0.145737\n",
      "[5053]\ttraining's auc: 0.970349\ttraining's binary_logloss: 0.145722\n",
      "[5054]\ttraining's auc: 0.970356\ttraining's binary_logloss: 0.145714\n",
      "[5055]\ttraining's auc: 0.970358\ttraining's binary_logloss: 0.14571\n",
      "[5056]\ttraining's auc: 0.97037\ttraining's binary_logloss: 0.145697\n",
      "[5057]\ttraining's auc: 0.970382\ttraining's binary_logloss: 0.145683\n",
      "[5058]\ttraining's auc: 0.970401\ttraining's binary_logloss: 0.145668\n",
      "[5059]\ttraining's auc: 0.970406\ttraining's binary_logloss: 0.145655\n",
      "[5060]\ttraining's auc: 0.97042\ttraining's binary_logloss: 0.145642\n",
      "[5061]\ttraining's auc: 0.970435\ttraining's binary_logloss: 0.14563\n",
      "[5062]\ttraining's auc: 0.970441\ttraining's binary_logloss: 0.145622\n",
      "[5063]\ttraining's auc: 0.970447\ttraining's binary_logloss: 0.145617\n",
      "[5064]\ttraining's auc: 0.970464\ttraining's binary_logloss: 0.145602\n",
      "[5065]\ttraining's auc: 0.970474\ttraining's binary_logloss: 0.145589\n",
      "[5066]\ttraining's auc: 0.970482\ttraining's binary_logloss: 0.145581\n",
      "[5067]\ttraining's auc: 0.970493\ttraining's binary_logloss: 0.145565\n",
      "[5068]\ttraining's auc: 0.970504\ttraining's binary_logloss: 0.145551\n",
      "[5069]\ttraining's auc: 0.970518\ttraining's binary_logloss: 0.145539\n",
      "[5070]\ttraining's auc: 0.970531\ttraining's binary_logloss: 0.145523\n",
      "[5071]\ttraining's auc: 0.970546\ttraining's binary_logloss: 0.145508\n",
      "[5072]\ttraining's auc: 0.970559\ttraining's binary_logloss: 0.145493\n",
      "[5073]\ttraining's auc: 0.970569\ttraining's binary_logloss: 0.14548\n",
      "[5074]\ttraining's auc: 0.970589\ttraining's binary_logloss: 0.145466\n",
      "[5075]\ttraining's auc: 0.970599\ttraining's binary_logloss: 0.145452\n",
      "[5076]\ttraining's auc: 0.970613\ttraining's binary_logloss: 0.145438\n",
      "[5077]\ttraining's auc: 0.970628\ttraining's binary_logloss: 0.145426\n",
      "[5078]\ttraining's auc: 0.97064\ttraining's binary_logloss: 0.145412\n",
      "[5079]\ttraining's auc: 0.970649\ttraining's binary_logloss: 0.145397\n",
      "[5080]\ttraining's auc: 0.970661\ttraining's binary_logloss: 0.145382\n",
      "[5081]\ttraining's auc: 0.970664\ttraining's binary_logloss: 0.145379\n",
      "[5082]\ttraining's auc: 0.970677\ttraining's binary_logloss: 0.145366\n",
      "[5083]\ttraining's auc: 0.970694\ttraining's binary_logloss: 0.145353\n",
      "[5084]\ttraining's auc: 0.970711\ttraining's binary_logloss: 0.145338\n",
      "[5085]\ttraining's auc: 0.97072\ttraining's binary_logloss: 0.145326\n",
      "[5086]\ttraining's auc: 0.970731\ttraining's binary_logloss: 0.145315\n",
      "[5087]\ttraining's auc: 0.970745\ttraining's binary_logloss: 0.1453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5088]\ttraining's auc: 0.97075\ttraining's binary_logloss: 0.145295\n",
      "[5089]\ttraining's auc: 0.970761\ttraining's binary_logloss: 0.145279\n",
      "[5090]\ttraining's auc: 0.970768\ttraining's binary_logloss: 0.145271\n",
      "[5091]\ttraining's auc: 0.970778\ttraining's binary_logloss: 0.145258\n",
      "[5092]\ttraining's auc: 0.970787\ttraining's binary_logloss: 0.145247\n",
      "[5093]\ttraining's auc: 0.970794\ttraining's binary_logloss: 0.145239\n",
      "[5094]\ttraining's auc: 0.970811\ttraining's binary_logloss: 0.145226\n",
      "[5095]\ttraining's auc: 0.970825\ttraining's binary_logloss: 0.145215\n",
      "[5096]\ttraining's auc: 0.970836\ttraining's binary_logloss: 0.145201\n",
      "[5097]\ttraining's auc: 0.97085\ttraining's binary_logloss: 0.145187\n",
      "[5098]\ttraining's auc: 0.970867\ttraining's binary_logloss: 0.145172\n",
      "[5099]\ttraining's auc: 0.970878\ttraining's binary_logloss: 0.145158\n",
      "[5100]\ttraining's auc: 0.970894\ttraining's binary_logloss: 0.145145\n",
      "[5101]\ttraining's auc: 0.970899\ttraining's binary_logloss: 0.14514\n",
      "[5102]\ttraining's auc: 0.970915\ttraining's binary_logloss: 0.145122\n",
      "[5103]\ttraining's auc: 0.970929\ttraining's binary_logloss: 0.14511\n",
      "[5104]\ttraining's auc: 0.970946\ttraining's binary_logloss: 0.145096\n",
      "[5105]\ttraining's auc: 0.970957\ttraining's binary_logloss: 0.145081\n",
      "[5106]\ttraining's auc: 0.970971\ttraining's binary_logloss: 0.145067\n",
      "[5107]\ttraining's auc: 0.970987\ttraining's binary_logloss: 0.145053\n",
      "[5108]\ttraining's auc: 0.971001\ttraining's binary_logloss: 0.145039\n",
      "[5109]\ttraining's auc: 0.971019\ttraining's binary_logloss: 0.145026\n",
      "[5110]\ttraining's auc: 0.971031\ttraining's binary_logloss: 0.145013\n",
      "[5111]\ttraining's auc: 0.971043\ttraining's binary_logloss: 0.144997\n",
      "[5112]\ttraining's auc: 0.971051\ttraining's binary_logloss: 0.144988\n",
      "[5113]\ttraining's auc: 0.971064\ttraining's binary_logloss: 0.144973\n",
      "[5114]\ttraining's auc: 0.971068\ttraining's binary_logloss: 0.144967\n",
      "[5115]\ttraining's auc: 0.971079\ttraining's binary_logloss: 0.144956\n",
      "[5116]\ttraining's auc: 0.971091\ttraining's binary_logloss: 0.144947\n",
      "[5117]\ttraining's auc: 0.971104\ttraining's binary_logloss: 0.144935\n",
      "[5118]\ttraining's auc: 0.97111\ttraining's binary_logloss: 0.144929\n",
      "[5119]\ttraining's auc: 0.971113\ttraining's binary_logloss: 0.144925\n",
      "[5120]\ttraining's auc: 0.971125\ttraining's binary_logloss: 0.144911\n",
      "[5121]\ttraining's auc: 0.971137\ttraining's binary_logloss: 0.144898\n",
      "[5122]\ttraining's auc: 0.97115\ttraining's binary_logloss: 0.144883\n",
      "[5123]\ttraining's auc: 0.971166\ttraining's binary_logloss: 0.144868\n",
      "[5124]\ttraining's auc: 0.971179\ttraining's binary_logloss: 0.144855\n",
      "[5125]\ttraining's auc: 0.971193\ttraining's binary_logloss: 0.144842\n",
      "[5126]\ttraining's auc: 0.971206\ttraining's binary_logloss: 0.144827\n",
      "[5127]\ttraining's auc: 0.971214\ttraining's binary_logloss: 0.144818\n",
      "[5128]\ttraining's auc: 0.971225\ttraining's binary_logloss: 0.144807\n",
      "[5129]\ttraining's auc: 0.97124\ttraining's binary_logloss: 0.144792\n",
      "[5130]\ttraining's auc: 0.971254\ttraining's binary_logloss: 0.144779\n",
      "[5131]\ttraining's auc: 0.971265\ttraining's binary_logloss: 0.144765\n",
      "[5132]\ttraining's auc: 0.971281\ttraining's binary_logloss: 0.14475\n",
      "[5133]\ttraining's auc: 0.971295\ttraining's binary_logloss: 0.144734\n",
      "[5134]\ttraining's auc: 0.97131\ttraining's binary_logloss: 0.144724\n",
      "[5135]\ttraining's auc: 0.971318\ttraining's binary_logloss: 0.144714\n",
      "[5136]\ttraining's auc: 0.971332\ttraining's binary_logloss: 0.144703\n",
      "[5137]\ttraining's auc: 0.971345\ttraining's binary_logloss: 0.144689\n",
      "[5138]\ttraining's auc: 0.971361\ttraining's binary_logloss: 0.144673\n",
      "[5139]\ttraining's auc: 0.971375\ttraining's binary_logloss: 0.144659\n",
      "[5140]\ttraining's auc: 0.971387\ttraining's binary_logloss: 0.144644\n",
      "[5141]\ttraining's auc: 0.971398\ttraining's binary_logloss: 0.144632\n",
      "[5142]\ttraining's auc: 0.971411\ttraining's binary_logloss: 0.144618\n",
      "[5143]\ttraining's auc: 0.971426\ttraining's binary_logloss: 0.144604\n",
      "[5144]\ttraining's auc: 0.971446\ttraining's binary_logloss: 0.14459\n",
      "[5145]\ttraining's auc: 0.971457\ttraining's binary_logloss: 0.144576\n",
      "[5146]\ttraining's auc: 0.971474\ttraining's binary_logloss: 0.144562\n",
      "[5147]\ttraining's auc: 0.971488\ttraining's binary_logloss: 0.144549\n",
      "[5148]\ttraining's auc: 0.9715\ttraining's binary_logloss: 0.144535\n",
      "[5149]\ttraining's auc: 0.97151\ttraining's binary_logloss: 0.144522\n",
      "[5150]\ttraining's auc: 0.971526\ttraining's binary_logloss: 0.144508\n",
      "[5151]\ttraining's auc: 0.971543\ttraining's binary_logloss: 0.144493\n",
      "[5152]\ttraining's auc: 0.971551\ttraining's binary_logloss: 0.144481\n",
      "[5153]\ttraining's auc: 0.971564\ttraining's binary_logloss: 0.144465\n",
      "[5154]\ttraining's auc: 0.97158\ttraining's binary_logloss: 0.144449\n",
      "[5155]\ttraining's auc: 0.971589\ttraining's binary_logloss: 0.14444\n",
      "[5156]\ttraining's auc: 0.971598\ttraining's binary_logloss: 0.144427\n",
      "[5157]\ttraining's auc: 0.971609\ttraining's binary_logloss: 0.144415\n",
      "[5158]\ttraining's auc: 0.971623\ttraining's binary_logloss: 0.144402\n",
      "[5159]\ttraining's auc: 0.971633\ttraining's binary_logloss: 0.144391\n",
      "[5160]\ttraining's auc: 0.971647\ttraining's binary_logloss: 0.144376\n",
      "[5161]\ttraining's auc: 0.97166\ttraining's binary_logloss: 0.144364\n",
      "[5162]\ttraining's auc: 0.971673\ttraining's binary_logloss: 0.144352\n",
      "[5163]\ttraining's auc: 0.971691\ttraining's binary_logloss: 0.144337\n",
      "[5164]\ttraining's auc: 0.971702\ttraining's binary_logloss: 0.144325\n",
      "[5165]\ttraining's auc: 0.971717\ttraining's binary_logloss: 0.144313\n",
      "[5166]\ttraining's auc: 0.971729\ttraining's binary_logloss: 0.144297\n",
      "[5167]\ttraining's auc: 0.971731\ttraining's binary_logloss: 0.144293\n",
      "[5168]\ttraining's auc: 0.971751\ttraining's binary_logloss: 0.144275\n",
      "[5169]\ttraining's auc: 0.971756\ttraining's binary_logloss: 0.144267\n",
      "[5170]\ttraining's auc: 0.971772\ttraining's binary_logloss: 0.144252\n",
      "[5171]\ttraining's auc: 0.971783\ttraining's binary_logloss: 0.144237\n",
      "[5172]\ttraining's auc: 0.9718\ttraining's binary_logloss: 0.144222\n",
      "[5173]\ttraining's auc: 0.971813\ttraining's binary_logloss: 0.144207\n",
      "[5174]\ttraining's auc: 0.971825\ttraining's binary_logloss: 0.144195\n",
      "[5175]\ttraining's auc: 0.971828\ttraining's binary_logloss: 0.144191\n",
      "[5176]\ttraining's auc: 0.97184\ttraining's binary_logloss: 0.144177\n",
      "[5177]\ttraining's auc: 0.971842\ttraining's binary_logloss: 0.14417\n",
      "[5178]\ttraining's auc: 0.971855\ttraining's binary_logloss: 0.144159\n",
      "[5179]\ttraining's auc: 0.971868\ttraining's binary_logloss: 0.144146\n",
      "[5180]\ttraining's auc: 0.971882\ttraining's binary_logloss: 0.144133\n",
      "[5181]\ttraining's auc: 0.971893\ttraining's binary_logloss: 0.14412\n",
      "[5182]\ttraining's auc: 0.971904\ttraining's binary_logloss: 0.144108\n",
      "[5183]\ttraining's auc: 0.971911\ttraining's binary_logloss: 0.144095\n",
      "[5184]\ttraining's auc: 0.971917\ttraining's binary_logloss: 0.144082\n",
      "[5185]\ttraining's auc: 0.971932\ttraining's binary_logloss: 0.144068\n",
      "[5186]\ttraining's auc: 0.971942\ttraining's binary_logloss: 0.144054\n",
      "[5187]\ttraining's auc: 0.971958\ttraining's binary_logloss: 0.144041\n",
      "[5188]\ttraining's auc: 0.971968\ttraining's binary_logloss: 0.144026\n",
      "[5189]\ttraining's auc: 0.971977\ttraining's binary_logloss: 0.144017\n",
      "[5190]\ttraining's auc: 0.971989\ttraining's binary_logloss: 0.144003\n",
      "[5191]\ttraining's auc: 0.971999\ttraining's binary_logloss: 0.14399\n",
      "[5192]\ttraining's auc: 0.972004\ttraining's binary_logloss: 0.143987\n",
      "[5193]\ttraining's auc: 0.972019\ttraining's binary_logloss: 0.143974\n",
      "[5194]\ttraining's auc: 0.97204\ttraining's binary_logloss: 0.143958\n",
      "[5195]\ttraining's auc: 0.972049\ttraining's binary_logloss: 0.143947\n",
      "[5196]\ttraining's auc: 0.972064\ttraining's binary_logloss: 0.143933\n",
      "[5197]\ttraining's auc: 0.972079\ttraining's binary_logloss: 0.143919\n",
      "[5198]\ttraining's auc: 0.972088\ttraining's binary_logloss: 0.143909\n",
      "[5199]\ttraining's auc: 0.972101\ttraining's binary_logloss: 0.143896\n",
      "[5200]\ttraining's auc: 0.972111\ttraining's binary_logloss: 0.143884\n",
      "[5201]\ttraining's auc: 0.972132\ttraining's binary_logloss: 0.14387\n",
      "[5202]\ttraining's auc: 0.97215\ttraining's binary_logloss: 0.143855\n",
      "[5203]\ttraining's auc: 0.97216\ttraining's binary_logloss: 0.143844\n",
      "[5204]\ttraining's auc: 0.972175\ttraining's binary_logloss: 0.143829\n",
      "[5205]\ttraining's auc: 0.972191\ttraining's binary_logloss: 0.143813\n",
      "[5206]\ttraining's auc: 0.972205\ttraining's binary_logloss: 0.143801\n",
      "[5207]\ttraining's auc: 0.972221\ttraining's binary_logloss: 0.143785\n",
      "[5208]\ttraining's auc: 0.972238\ttraining's binary_logloss: 0.143771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5209]\ttraining's auc: 0.972251\ttraining's binary_logloss: 0.143757\n",
      "[5210]\ttraining's auc: 0.972268\ttraining's binary_logloss: 0.143743\n",
      "[5211]\ttraining's auc: 0.972282\ttraining's binary_logloss: 0.143728\n",
      "[5212]\ttraining's auc: 0.972295\ttraining's binary_logloss: 0.143714\n",
      "[5213]\ttraining's auc: 0.9723\ttraining's binary_logloss: 0.143705\n",
      "[5214]\ttraining's auc: 0.972309\ttraining's binary_logloss: 0.143693\n",
      "[5215]\ttraining's auc: 0.972328\ttraining's binary_logloss: 0.143677\n",
      "[5216]\ttraining's auc: 0.972344\ttraining's binary_logloss: 0.143663\n",
      "[5217]\ttraining's auc: 0.972353\ttraining's binary_logloss: 0.143652\n",
      "[5218]\ttraining's auc: 0.972366\ttraining's binary_logloss: 0.143643\n",
      "[5219]\ttraining's auc: 0.97238\ttraining's binary_logloss: 0.14363\n",
      "[5220]\ttraining's auc: 0.972389\ttraining's binary_logloss: 0.143619\n",
      "[5221]\ttraining's auc: 0.972401\ttraining's binary_logloss: 0.143606\n",
      "[5222]\ttraining's auc: 0.972414\ttraining's binary_logloss: 0.143592\n",
      "[5223]\ttraining's auc: 0.972427\ttraining's binary_logloss: 0.14358\n",
      "[5224]\ttraining's auc: 0.972438\ttraining's binary_logloss: 0.143566\n",
      "[5225]\ttraining's auc: 0.972453\ttraining's binary_logloss: 0.143552\n",
      "[5226]\ttraining's auc: 0.972471\ttraining's binary_logloss: 0.143537\n",
      "[5227]\ttraining's auc: 0.97248\ttraining's binary_logloss: 0.143523\n",
      "[5228]\ttraining's auc: 0.972504\ttraining's binary_logloss: 0.143507\n",
      "[5229]\ttraining's auc: 0.972516\ttraining's binary_logloss: 0.143492\n",
      "[5230]\ttraining's auc: 0.972522\ttraining's binary_logloss: 0.143479\n",
      "[5231]\ttraining's auc: 0.972541\ttraining's binary_logloss: 0.143464\n",
      "[5232]\ttraining's auc: 0.972545\ttraining's binary_logloss: 0.143456\n",
      "[5233]\ttraining's auc: 0.972557\ttraining's binary_logloss: 0.143442\n",
      "[5234]\ttraining's auc: 0.972564\ttraining's binary_logloss: 0.143432\n",
      "[5235]\ttraining's auc: 0.972572\ttraining's binary_logloss: 0.14342\n",
      "[5236]\ttraining's auc: 0.972581\ttraining's binary_logloss: 0.14341\n",
      "[5237]\ttraining's auc: 0.972591\ttraining's binary_logloss: 0.143397\n",
      "[5238]\ttraining's auc: 0.972598\ttraining's binary_logloss: 0.143388\n",
      "[5239]\ttraining's auc: 0.972608\ttraining's binary_logloss: 0.143374\n",
      "[5240]\ttraining's auc: 0.972618\ttraining's binary_logloss: 0.14336\n",
      "[5241]\ttraining's auc: 0.972635\ttraining's binary_logloss: 0.143346\n",
      "[5242]\ttraining's auc: 0.972645\ttraining's binary_logloss: 0.143332\n",
      "[5243]\ttraining's auc: 0.972657\ttraining's binary_logloss: 0.143319\n",
      "[5244]\ttraining's auc: 0.972671\ttraining's binary_logloss: 0.143304\n",
      "[5245]\ttraining's auc: 0.972684\ttraining's binary_logloss: 0.14329\n",
      "[5246]\ttraining's auc: 0.972697\ttraining's binary_logloss: 0.143276\n",
      "[5247]\ttraining's auc: 0.972699\ttraining's binary_logloss: 0.143272\n",
      "[5248]\ttraining's auc: 0.972712\ttraining's binary_logloss: 0.143258\n",
      "[5249]\ttraining's auc: 0.972726\ttraining's binary_logloss: 0.143244\n",
      "[5250]\ttraining's auc: 0.972738\ttraining's binary_logloss: 0.143228\n",
      "[5251]\ttraining's auc: 0.972748\ttraining's binary_logloss: 0.143217\n",
      "[5252]\ttraining's auc: 0.97275\ttraining's binary_logloss: 0.143214\n",
      "[5253]\ttraining's auc: 0.972758\ttraining's binary_logloss: 0.1432\n",
      "[5254]\ttraining's auc: 0.972771\ttraining's binary_logloss: 0.143186\n",
      "[5255]\ttraining's auc: 0.972782\ttraining's binary_logloss: 0.143172\n",
      "[5256]\ttraining's auc: 0.972796\ttraining's binary_logloss: 0.143156\n",
      "[5257]\ttraining's auc: 0.972803\ttraining's binary_logloss: 0.143143\n",
      "[5258]\ttraining's auc: 0.972807\ttraining's binary_logloss: 0.143138\n",
      "[5259]\ttraining's auc: 0.972816\ttraining's binary_logloss: 0.14313\n",
      "[5260]\ttraining's auc: 0.972821\ttraining's binary_logloss: 0.143122\n",
      "[5261]\ttraining's auc: 0.972831\ttraining's binary_logloss: 0.14311\n",
      "[5262]\ttraining's auc: 0.972835\ttraining's binary_logloss: 0.143103\n",
      "[5263]\ttraining's auc: 0.972842\ttraining's binary_logloss: 0.143091\n",
      "[5264]\ttraining's auc: 0.972849\ttraining's binary_logloss: 0.143081\n",
      "[5265]\ttraining's auc: 0.972859\ttraining's binary_logloss: 0.143069\n",
      "[5266]\ttraining's auc: 0.972869\ttraining's binary_logloss: 0.143058\n",
      "[5267]\ttraining's auc: 0.972874\ttraining's binary_logloss: 0.143049\n",
      "[5268]\ttraining's auc: 0.972884\ttraining's binary_logloss: 0.143037\n",
      "[5269]\ttraining's auc: 0.972898\ttraining's binary_logloss: 0.143023\n",
      "[5270]\ttraining's auc: 0.972908\ttraining's binary_logloss: 0.143009\n",
      "[5271]\ttraining's auc: 0.972912\ttraining's binary_logloss: 0.143002\n",
      "[5272]\ttraining's auc: 0.972935\ttraining's binary_logloss: 0.142985\n",
      "[5273]\ttraining's auc: 0.972948\ttraining's binary_logloss: 0.142971\n",
      "[5274]\ttraining's auc: 0.972951\ttraining's binary_logloss: 0.142968\n",
      "[5275]\ttraining's auc: 0.972962\ttraining's binary_logloss: 0.142953\n",
      "[5276]\ttraining's auc: 0.972976\ttraining's binary_logloss: 0.142936\n",
      "[5277]\ttraining's auc: 0.972989\ttraining's binary_logloss: 0.142922\n",
      "[5278]\ttraining's auc: 0.973\ttraining's binary_logloss: 0.142909\n",
      "[5279]\ttraining's auc: 0.97301\ttraining's binary_logloss: 0.142895\n",
      "[5280]\ttraining's auc: 0.97302\ttraining's binary_logloss: 0.142884\n",
      "[5281]\ttraining's auc: 0.97302\ttraining's binary_logloss: 0.142881\n",
      "[5282]\ttraining's auc: 0.973036\ttraining's binary_logloss: 0.142867\n",
      "[5283]\ttraining's auc: 0.973036\ttraining's binary_logloss: 0.142863\n",
      "[5284]\ttraining's auc: 0.973053\ttraining's binary_logloss: 0.142849\n",
      "[5285]\ttraining's auc: 0.973067\ttraining's binary_logloss: 0.142837\n",
      "[5286]\ttraining's auc: 0.97308\ttraining's binary_logloss: 0.142823\n",
      "[5287]\ttraining's auc: 0.973094\ttraining's binary_logloss: 0.142806\n",
      "[5288]\ttraining's auc: 0.973096\ttraining's binary_logloss: 0.142803\n",
      "[5289]\ttraining's auc: 0.973111\ttraining's binary_logloss: 0.142788\n",
      "[5290]\ttraining's auc: 0.973127\ttraining's binary_logloss: 0.142775\n",
      "[5291]\ttraining's auc: 0.973139\ttraining's binary_logloss: 0.142763\n",
      "[5292]\ttraining's auc: 0.973142\ttraining's binary_logloss: 0.14276\n",
      "[5293]\ttraining's auc: 0.973145\ttraining's binary_logloss: 0.142757\n",
      "[5294]\ttraining's auc: 0.973152\ttraining's binary_logloss: 0.142748\n",
      "[5295]\ttraining's auc: 0.973153\ttraining's binary_logloss: 0.142745\n",
      "[5296]\ttraining's auc: 0.973159\ttraining's binary_logloss: 0.142732\n",
      "[5297]\ttraining's auc: 0.973169\ttraining's binary_logloss: 0.142719\n",
      "[5298]\ttraining's auc: 0.973187\ttraining's binary_logloss: 0.142703\n",
      "[5299]\ttraining's auc: 0.9732\ttraining's binary_logloss: 0.142691\n",
      "[5300]\ttraining's auc: 0.97321\ttraining's binary_logloss: 0.142677\n",
      "[5301]\ttraining's auc: 0.973217\ttraining's binary_logloss: 0.142664\n",
      "[5302]\ttraining's auc: 0.973229\ttraining's binary_logloss: 0.142654\n",
      "[5303]\ttraining's auc: 0.973231\ttraining's binary_logloss: 0.14265\n",
      "[5304]\ttraining's auc: 0.973245\ttraining's binary_logloss: 0.142637\n",
      "[5305]\ttraining's auc: 0.973259\ttraining's binary_logloss: 0.142623\n",
      "[5306]\ttraining's auc: 0.973272\ttraining's binary_logloss: 0.142608\n",
      "[5307]\ttraining's auc: 0.973276\ttraining's binary_logloss: 0.142601\n",
      "[5308]\ttraining's auc: 0.973289\ttraining's binary_logloss: 0.142587\n",
      "[5309]\ttraining's auc: 0.973295\ttraining's binary_logloss: 0.142573\n",
      "[5310]\ttraining's auc: 0.973306\ttraining's binary_logloss: 0.142561\n",
      "[5311]\ttraining's auc: 0.973318\ttraining's binary_logloss: 0.142547\n",
      "[5312]\ttraining's auc: 0.973331\ttraining's binary_logloss: 0.142532\n",
      "[5313]\ttraining's auc: 0.973336\ttraining's binary_logloss: 0.142522\n",
      "[5314]\ttraining's auc: 0.97334\ttraining's binary_logloss: 0.142517\n",
      "[5315]\ttraining's auc: 0.973361\ttraining's binary_logloss: 0.142498\n",
      "[5316]\ttraining's auc: 0.973368\ttraining's binary_logloss: 0.142485\n",
      "[5317]\ttraining's auc: 0.973383\ttraining's binary_logloss: 0.14247\n",
      "[5318]\ttraining's auc: 0.973396\ttraining's binary_logloss: 0.142457\n",
      "[5319]\ttraining's auc: 0.973411\ttraining's binary_logloss: 0.142443\n",
      "[5320]\ttraining's auc: 0.973424\ttraining's binary_logloss: 0.14243\n",
      "[5321]\ttraining's auc: 0.973426\ttraining's binary_logloss: 0.142427\n",
      "[5322]\ttraining's auc: 0.973447\ttraining's binary_logloss: 0.142412\n",
      "[5323]\ttraining's auc: 0.973467\ttraining's binary_logloss: 0.142397\n",
      "[5324]\ttraining's auc: 0.973475\ttraining's binary_logloss: 0.142386\n",
      "[5325]\ttraining's auc: 0.973485\ttraining's binary_logloss: 0.142372\n",
      "[5326]\ttraining's auc: 0.973497\ttraining's binary_logloss: 0.142359\n",
      "[5327]\ttraining's auc: 0.973508\ttraining's binary_logloss: 0.142346\n",
      "[5328]\ttraining's auc: 0.973522\ttraining's binary_logloss: 0.142332\n",
      "[5329]\ttraining's auc: 0.973539\ttraining's binary_logloss: 0.142318\n",
      "[5330]\ttraining's auc: 0.97355\ttraining's binary_logloss: 0.142303\n",
      "[5331]\ttraining's auc: 0.973568\ttraining's binary_logloss: 0.142287\n",
      "[5332]\ttraining's auc: 0.973582\ttraining's binary_logloss: 0.142272\n",
      "[5333]\ttraining's auc: 0.973593\ttraining's binary_logloss: 0.142259\n",
      "[5334]\ttraining's auc: 0.97361\ttraining's binary_logloss: 0.142244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5335]\ttraining's auc: 0.973614\ttraining's binary_logloss: 0.142236\n",
      "[5336]\ttraining's auc: 0.973618\ttraining's binary_logloss: 0.14223\n",
      "[5337]\ttraining's auc: 0.973629\ttraining's binary_logloss: 0.142219\n",
      "[5338]\ttraining's auc: 0.973644\ttraining's binary_logloss: 0.142206\n",
      "[5339]\ttraining's auc: 0.973652\ttraining's binary_logloss: 0.142193\n",
      "[5340]\ttraining's auc: 0.973666\ttraining's binary_logloss: 0.142178\n",
      "[5341]\ttraining's auc: 0.973684\ttraining's binary_logloss: 0.142162\n",
      "[5342]\ttraining's auc: 0.973698\ttraining's binary_logloss: 0.142147\n",
      "[5343]\ttraining's auc: 0.97371\ttraining's binary_logloss: 0.142135\n",
      "[5344]\ttraining's auc: 0.973713\ttraining's binary_logloss: 0.14213\n",
      "[5345]\ttraining's auc: 0.973723\ttraining's binary_logloss: 0.142118\n",
      "[5346]\ttraining's auc: 0.973727\ttraining's binary_logloss: 0.142111\n",
      "[5347]\ttraining's auc: 0.97374\ttraining's binary_logloss: 0.142098\n",
      "[5348]\ttraining's auc: 0.973752\ttraining's binary_logloss: 0.142084\n",
      "[5349]\ttraining's auc: 0.973762\ttraining's binary_logloss: 0.142075\n",
      "[5350]\ttraining's auc: 0.973768\ttraining's binary_logloss: 0.142063\n",
      "[5351]\ttraining's auc: 0.973779\ttraining's binary_logloss: 0.142048\n",
      "[5352]\ttraining's auc: 0.973791\ttraining's binary_logloss: 0.142035\n",
      "[5353]\ttraining's auc: 0.973803\ttraining's binary_logloss: 0.142021\n",
      "[5354]\ttraining's auc: 0.973803\ttraining's binary_logloss: 0.142017\n",
      "[5355]\ttraining's auc: 0.973816\ttraining's binary_logloss: 0.142003\n",
      "[5356]\ttraining's auc: 0.973827\ttraining's binary_logloss: 0.141994\n",
      "[5357]\ttraining's auc: 0.973841\ttraining's binary_logloss: 0.141981\n",
      "[5358]\ttraining's auc: 0.973855\ttraining's binary_logloss: 0.14197\n",
      "[5359]\ttraining's auc: 0.973867\ttraining's binary_logloss: 0.141953\n",
      "[5360]\ttraining's auc: 0.973876\ttraining's binary_logloss: 0.141942\n",
      "[5361]\ttraining's auc: 0.973885\ttraining's binary_logloss: 0.141932\n",
      "[5362]\ttraining's auc: 0.973895\ttraining's binary_logloss: 0.141919\n",
      "[5363]\ttraining's auc: 0.973911\ttraining's binary_logloss: 0.141904\n",
      "[5364]\ttraining's auc: 0.973916\ttraining's binary_logloss: 0.1419\n",
      "[5365]\ttraining's auc: 0.973923\ttraining's binary_logloss: 0.141891\n",
      "[5366]\ttraining's auc: 0.973931\ttraining's binary_logloss: 0.14188\n",
      "[5367]\ttraining's auc: 0.97395\ttraining's binary_logloss: 0.141865\n",
      "[5368]\ttraining's auc: 0.973965\ttraining's binary_logloss: 0.14185\n",
      "[5369]\ttraining's auc: 0.973972\ttraining's binary_logloss: 0.141837\n",
      "[5370]\ttraining's auc: 0.973974\ttraining's binary_logloss: 0.141833\n",
      "[5371]\ttraining's auc: 0.973981\ttraining's binary_logloss: 0.141824\n",
      "[5372]\ttraining's auc: 0.97399\ttraining's binary_logloss: 0.141812\n",
      "[5373]\ttraining's auc: 0.974005\ttraining's binary_logloss: 0.141798\n",
      "[5374]\ttraining's auc: 0.974016\ttraining's binary_logloss: 0.141784\n",
      "[5375]\ttraining's auc: 0.974026\ttraining's binary_logloss: 0.141771\n",
      "[5376]\ttraining's auc: 0.974038\ttraining's binary_logloss: 0.141757\n",
      "[5377]\ttraining's auc: 0.974051\ttraining's binary_logloss: 0.141739\n",
      "[5378]\ttraining's auc: 0.974053\ttraining's binary_logloss: 0.141736\n",
      "[5379]\ttraining's auc: 0.974065\ttraining's binary_logloss: 0.141722\n",
      "[5380]\ttraining's auc: 0.974076\ttraining's binary_logloss: 0.141708\n",
      "[5381]\ttraining's auc: 0.97408\ttraining's binary_logloss: 0.141701\n",
      "[5382]\ttraining's auc: 0.974095\ttraining's binary_logloss: 0.141689\n",
      "[5383]\ttraining's auc: 0.974097\ttraining's binary_logloss: 0.141684\n",
      "[5384]\ttraining's auc: 0.974105\ttraining's binary_logloss: 0.14167\n",
      "[5385]\ttraining's auc: 0.974115\ttraining's binary_logloss: 0.141663\n",
      "[5386]\ttraining's auc: 0.97413\ttraining's binary_logloss: 0.141647\n",
      "[5387]\ttraining's auc: 0.974138\ttraining's binary_logloss: 0.141635\n",
      "[5388]\ttraining's auc: 0.974149\ttraining's binary_logloss: 0.141622\n",
      "[5389]\ttraining's auc: 0.974158\ttraining's binary_logloss: 0.14161\n",
      "[5390]\ttraining's auc: 0.974172\ttraining's binary_logloss: 0.141596\n",
      "[5391]\ttraining's auc: 0.974182\ttraining's binary_logloss: 0.141582\n",
      "[5392]\ttraining's auc: 0.974185\ttraining's binary_logloss: 0.141578\n",
      "[5393]\ttraining's auc: 0.974187\ttraining's binary_logloss: 0.141573\n",
      "[5394]\ttraining's auc: 0.974196\ttraining's binary_logloss: 0.141561\n",
      "[5395]\ttraining's auc: 0.974204\ttraining's binary_logloss: 0.141549\n",
      "[5396]\ttraining's auc: 0.974206\ttraining's binary_logloss: 0.141545\n",
      "[5397]\ttraining's auc: 0.974224\ttraining's binary_logloss: 0.14153\n",
      "[5398]\ttraining's auc: 0.974238\ttraining's binary_logloss: 0.141517\n",
      "[5399]\ttraining's auc: 0.974248\ttraining's binary_logloss: 0.141504\n",
      "[5400]\ttraining's auc: 0.974253\ttraining's binary_logloss: 0.1415\n",
      "[5401]\ttraining's auc: 0.974263\ttraining's binary_logloss: 0.141484\n",
      "[5402]\ttraining's auc: 0.974276\ttraining's binary_logloss: 0.141469\n",
      "[5403]\ttraining's auc: 0.974284\ttraining's binary_logloss: 0.141456\n",
      "[5404]\ttraining's auc: 0.974297\ttraining's binary_logloss: 0.14144\n",
      "[5405]\ttraining's auc: 0.974307\ttraining's binary_logloss: 0.141429\n",
      "[5406]\ttraining's auc: 0.974318\ttraining's binary_logloss: 0.141415\n",
      "[5407]\ttraining's auc: 0.974327\ttraining's binary_logloss: 0.141403\n",
      "[5408]\ttraining's auc: 0.97433\ttraining's binary_logloss: 0.141394\n",
      "[5409]\ttraining's auc: 0.974335\ttraining's binary_logloss: 0.14139\n",
      "[5410]\ttraining's auc: 0.974337\ttraining's binary_logloss: 0.141386\n",
      "[5411]\ttraining's auc: 0.97435\ttraining's binary_logloss: 0.141369\n",
      "[5412]\ttraining's auc: 0.97436\ttraining's binary_logloss: 0.141355\n",
      "[5413]\ttraining's auc: 0.974371\ttraining's binary_logloss: 0.141342\n",
      "[5414]\ttraining's auc: 0.974372\ttraining's binary_logloss: 0.141339\n",
      "[5415]\ttraining's auc: 0.974384\ttraining's binary_logloss: 0.141325\n",
      "[5416]\ttraining's auc: 0.974388\ttraining's binary_logloss: 0.14132\n",
      "[5417]\ttraining's auc: 0.974397\ttraining's binary_logloss: 0.141307\n",
      "[5418]\ttraining's auc: 0.974403\ttraining's binary_logloss: 0.141299\n",
      "[5419]\ttraining's auc: 0.974408\ttraining's binary_logloss: 0.141291\n",
      "[5420]\ttraining's auc: 0.974422\ttraining's binary_logloss: 0.141278\n",
      "[5421]\ttraining's auc: 0.974428\ttraining's binary_logloss: 0.141271\n",
      "[5422]\ttraining's auc: 0.974451\ttraining's binary_logloss: 0.141253\n",
      "[5423]\ttraining's auc: 0.974451\ttraining's binary_logloss: 0.141251\n",
      "[5424]\ttraining's auc: 0.974468\ttraining's binary_logloss: 0.141233\n",
      "[5425]\ttraining's auc: 0.974481\ttraining's binary_logloss: 0.141221\n",
      "[5426]\ttraining's auc: 0.974493\ttraining's binary_logloss: 0.141207\n",
      "[5427]\ttraining's auc: 0.974506\ttraining's binary_logloss: 0.141195\n",
      "[5428]\ttraining's auc: 0.974519\ttraining's binary_logloss: 0.141182\n",
      "[5429]\ttraining's auc: 0.974529\ttraining's binary_logloss: 0.14117\n",
      "[5430]\ttraining's auc: 0.974544\ttraining's binary_logloss: 0.141155\n",
      "[5431]\ttraining's auc: 0.97455\ttraining's binary_logloss: 0.141151\n",
      "[5432]\ttraining's auc: 0.97456\ttraining's binary_logloss: 0.141137\n",
      "[5433]\ttraining's auc: 0.974573\ttraining's binary_logloss: 0.141125\n",
      "[5434]\ttraining's auc: 0.97458\ttraining's binary_logloss: 0.141114\n",
      "[5435]\ttraining's auc: 0.974591\ttraining's binary_logloss: 0.141102\n",
      "[5436]\ttraining's auc: 0.974607\ttraining's binary_logloss: 0.141086\n",
      "[5437]\ttraining's auc: 0.974618\ttraining's binary_logloss: 0.141072\n",
      "[5438]\ttraining's auc: 0.97463\ttraining's binary_logloss: 0.141058\n",
      "[5439]\ttraining's auc: 0.974639\ttraining's binary_logloss: 0.141044\n",
      "[5440]\ttraining's auc: 0.974651\ttraining's binary_logloss: 0.141032\n",
      "[5441]\ttraining's auc: 0.974659\ttraining's binary_logloss: 0.141018\n",
      "[5442]\ttraining's auc: 0.974669\ttraining's binary_logloss: 0.141007\n",
      "[5443]\ttraining's auc: 0.974675\ttraining's binary_logloss: 0.141\n",
      "[5444]\ttraining's auc: 0.974679\ttraining's binary_logloss: 0.140995\n",
      "[5445]\ttraining's auc: 0.974687\ttraining's binary_logloss: 0.14098\n",
      "[5446]\ttraining's auc: 0.974687\ttraining's binary_logloss: 0.140979\n",
      "[5447]\ttraining's auc: 0.974693\ttraining's binary_logloss: 0.140972\n",
      "[5448]\ttraining's auc: 0.974695\ttraining's binary_logloss: 0.140969\n",
      "[5449]\ttraining's auc: 0.974707\ttraining's binary_logloss: 0.140956\n",
      "[5450]\ttraining's auc: 0.974709\ttraining's binary_logloss: 0.140951\n",
      "[5451]\ttraining's auc: 0.974719\ttraining's binary_logloss: 0.140937\n",
      "[5452]\ttraining's auc: 0.974732\ttraining's binary_logloss: 0.140923\n",
      "[5453]\ttraining's auc: 0.974737\ttraining's binary_logloss: 0.140918\n",
      "[5454]\ttraining's auc: 0.974748\ttraining's binary_logloss: 0.140905\n",
      "[5455]\ttraining's auc: 0.97476\ttraining's binary_logloss: 0.140892\n",
      "[5456]\ttraining's auc: 0.974772\ttraining's binary_logloss: 0.140878\n",
      "[5457]\ttraining's auc: 0.974786\ttraining's binary_logloss: 0.140865\n",
      "[5458]\ttraining's auc: 0.974797\ttraining's binary_logloss: 0.140851\n",
      "[5459]\ttraining's auc: 0.974804\ttraining's binary_logloss: 0.140839\n",
      "[5460]\ttraining's auc: 0.974817\ttraining's binary_logloss: 0.140825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5461]\ttraining's auc: 0.974826\ttraining's binary_logloss: 0.140813\n",
      "[5462]\ttraining's auc: 0.97484\ttraining's binary_logloss: 0.140798\n",
      "[5463]\ttraining's auc: 0.974849\ttraining's binary_logloss: 0.140786\n",
      "[5464]\ttraining's auc: 0.974865\ttraining's binary_logloss: 0.140768\n",
      "[5465]\ttraining's auc: 0.974874\ttraining's binary_logloss: 0.140756\n",
      "[5466]\ttraining's auc: 0.974882\ttraining's binary_logloss: 0.140741\n",
      "[5467]\ttraining's auc: 0.974892\ttraining's binary_logloss: 0.140726\n",
      "[5468]\ttraining's auc: 0.974904\ttraining's binary_logloss: 0.140715\n",
      "[5469]\ttraining's auc: 0.974917\ttraining's binary_logloss: 0.140704\n",
      "[5470]\ttraining's auc: 0.974927\ttraining's binary_logloss: 0.140689\n",
      "[5471]\ttraining's auc: 0.974939\ttraining's binary_logloss: 0.140675\n",
      "[5472]\ttraining's auc: 0.974948\ttraining's binary_logloss: 0.140665\n",
      "[5473]\ttraining's auc: 0.974956\ttraining's binary_logloss: 0.140652\n",
      "[5474]\ttraining's auc: 0.974969\ttraining's binary_logloss: 0.140637\n",
      "[5475]\ttraining's auc: 0.974973\ttraining's binary_logloss: 0.140633\n",
      "[5476]\ttraining's auc: 0.974975\ttraining's binary_logloss: 0.140629\n",
      "[5477]\ttraining's auc: 0.974986\ttraining's binary_logloss: 0.140614\n",
      "[5478]\ttraining's auc: 0.975004\ttraining's binary_logloss: 0.140599\n",
      "[5479]\ttraining's auc: 0.975016\ttraining's binary_logloss: 0.140585\n",
      "[5480]\ttraining's auc: 0.97503\ttraining's binary_logloss: 0.140569\n",
      "[5481]\ttraining's auc: 0.975043\ttraining's binary_logloss: 0.140555\n",
      "[5482]\ttraining's auc: 0.97506\ttraining's binary_logloss: 0.140541\n",
      "[5483]\ttraining's auc: 0.975066\ttraining's binary_logloss: 0.140535\n",
      "[5484]\ttraining's auc: 0.975068\ttraining's binary_logloss: 0.140532\n",
      "[5485]\ttraining's auc: 0.975086\ttraining's binary_logloss: 0.140519\n",
      "[5486]\ttraining's auc: 0.975093\ttraining's binary_logloss: 0.140513\n",
      "[5487]\ttraining's auc: 0.975103\ttraining's binary_logloss: 0.140499\n",
      "[5488]\ttraining's auc: 0.975114\ttraining's binary_logloss: 0.140489\n",
      "[5489]\ttraining's auc: 0.975119\ttraining's binary_logloss: 0.140484\n",
      "[5490]\ttraining's auc: 0.975133\ttraining's binary_logloss: 0.140468\n",
      "[5491]\ttraining's auc: 0.975144\ttraining's binary_logloss: 0.140455\n",
      "[5492]\ttraining's auc: 0.975155\ttraining's binary_logloss: 0.140443\n",
      "[5493]\ttraining's auc: 0.975174\ttraining's binary_logloss: 0.140428\n",
      "[5494]\ttraining's auc: 0.975189\ttraining's binary_logloss: 0.140412\n",
      "[5495]\ttraining's auc: 0.9752\ttraining's binary_logloss: 0.140399\n",
      "[5496]\ttraining's auc: 0.975213\ttraining's binary_logloss: 0.140384\n",
      "[5497]\ttraining's auc: 0.975224\ttraining's binary_logloss: 0.140372\n",
      "[5498]\ttraining's auc: 0.97523\ttraining's binary_logloss: 0.140359\n",
      "[5499]\ttraining's auc: 0.97524\ttraining's binary_logloss: 0.140343\n",
      "[5500]\ttraining's auc: 0.975254\ttraining's binary_logloss: 0.140329\n",
      "[5501]\ttraining's auc: 0.975265\ttraining's binary_logloss: 0.140317\n",
      "[5502]\ttraining's auc: 0.975277\ttraining's binary_logloss: 0.140303\n",
      "[5503]\ttraining's auc: 0.975286\ttraining's binary_logloss: 0.14029\n",
      "[5504]\ttraining's auc: 0.975291\ttraining's binary_logloss: 0.140279\n",
      "[5505]\ttraining's auc: 0.975294\ttraining's binary_logloss: 0.140275\n",
      "[5506]\ttraining's auc: 0.975298\ttraining's binary_logloss: 0.140268\n",
      "[5507]\ttraining's auc: 0.975319\ttraining's binary_logloss: 0.140252\n",
      "[5508]\ttraining's auc: 0.975333\ttraining's binary_logloss: 0.140237\n",
      "[5509]\ttraining's auc: 0.975346\ttraining's binary_logloss: 0.140224\n",
      "[5510]\ttraining's auc: 0.975349\ttraining's binary_logloss: 0.140221\n",
      "[5511]\ttraining's auc: 0.975359\ttraining's binary_logloss: 0.140209\n",
      "[5512]\ttraining's auc: 0.975363\ttraining's binary_logloss: 0.140206\n",
      "[5513]\ttraining's auc: 0.975378\ttraining's binary_logloss: 0.140193\n",
      "[5514]\ttraining's auc: 0.975383\ttraining's binary_logloss: 0.140187\n",
      "[5515]\ttraining's auc: 0.975392\ttraining's binary_logloss: 0.140175\n",
      "[5516]\ttraining's auc: 0.975404\ttraining's binary_logloss: 0.140163\n",
      "[5517]\ttraining's auc: 0.975409\ttraining's binary_logloss: 0.140156\n",
      "[5518]\ttraining's auc: 0.975411\ttraining's binary_logloss: 0.140155\n",
      "[5519]\ttraining's auc: 0.975415\ttraining's binary_logloss: 0.140148\n",
      "[5520]\ttraining's auc: 0.975424\ttraining's binary_logloss: 0.140136\n",
      "[5521]\ttraining's auc: 0.975429\ttraining's binary_logloss: 0.140131\n",
      "[5522]\ttraining's auc: 0.975432\ttraining's binary_logloss: 0.140128\n",
      "[5523]\ttraining's auc: 0.97544\ttraining's binary_logloss: 0.140113\n",
      "[5524]\ttraining's auc: 0.975451\ttraining's binary_logloss: 0.140104\n",
      "[5525]\ttraining's auc: 0.975462\ttraining's binary_logloss: 0.140089\n",
      "[5526]\ttraining's auc: 0.975471\ttraining's binary_logloss: 0.140078\n",
      "[5527]\ttraining's auc: 0.975481\ttraining's binary_logloss: 0.140067\n",
      "[5528]\ttraining's auc: 0.975484\ttraining's binary_logloss: 0.140062\n",
      "[5529]\ttraining's auc: 0.975489\ttraining's binary_logloss: 0.140049\n",
      "[5530]\ttraining's auc: 0.97549\ttraining's binary_logloss: 0.140047\n",
      "[5531]\ttraining's auc: 0.975503\ttraining's binary_logloss: 0.140033\n",
      "[5532]\ttraining's auc: 0.975508\ttraining's binary_logloss: 0.140027\n",
      "[5533]\ttraining's auc: 0.975509\ttraining's binary_logloss: 0.140026\n",
      "[5534]\ttraining's auc: 0.975522\ttraining's binary_logloss: 0.140013\n",
      "[5535]\ttraining's auc: 0.975534\ttraining's binary_logloss: 0.140001\n",
      "[5536]\ttraining's auc: 0.975543\ttraining's binary_logloss: 0.139987\n",
      "[5537]\ttraining's auc: 0.975556\ttraining's binary_logloss: 0.139972\n",
      "[5538]\ttraining's auc: 0.97557\ttraining's binary_logloss: 0.139958\n",
      "[5539]\ttraining's auc: 0.975588\ttraining's binary_logloss: 0.13994\n",
      "[5540]\ttraining's auc: 0.975601\ttraining's binary_logloss: 0.139928\n",
      "[5541]\ttraining's auc: 0.975604\ttraining's binary_logloss: 0.139926\n",
      "[5542]\ttraining's auc: 0.975618\ttraining's binary_logloss: 0.139913\n",
      "[5543]\ttraining's auc: 0.975623\ttraining's binary_logloss: 0.139907\n",
      "[5544]\ttraining's auc: 0.975636\ttraining's binary_logloss: 0.139892\n",
      "[5545]\ttraining's auc: 0.975646\ttraining's binary_logloss: 0.139879\n",
      "[5546]\ttraining's auc: 0.975656\ttraining's binary_logloss: 0.139862\n",
      "[5547]\ttraining's auc: 0.975669\ttraining's binary_logloss: 0.139849\n",
      "[5548]\ttraining's auc: 0.975672\ttraining's binary_logloss: 0.139842\n",
      "[5549]\ttraining's auc: 0.975685\ttraining's binary_logloss: 0.139829\n",
      "[5550]\ttraining's auc: 0.9757\ttraining's binary_logloss: 0.139815\n",
      "[5551]\ttraining's auc: 0.975703\ttraining's binary_logloss: 0.13981\n",
      "[5552]\ttraining's auc: 0.975713\ttraining's binary_logloss: 0.139799\n",
      "[5553]\ttraining's auc: 0.975723\ttraining's binary_logloss: 0.139786\n",
      "[5554]\ttraining's auc: 0.975732\ttraining's binary_logloss: 0.139771\n",
      "[5555]\ttraining's auc: 0.975741\ttraining's binary_logloss: 0.139759\n",
      "[5556]\ttraining's auc: 0.975749\ttraining's binary_logloss: 0.13975\n",
      "[5557]\ttraining's auc: 0.975757\ttraining's binary_logloss: 0.139736\n",
      "[5558]\ttraining's auc: 0.975766\ttraining's binary_logloss: 0.139723\n",
      "[5559]\ttraining's auc: 0.975786\ttraining's binary_logloss: 0.139708\n",
      "[5560]\ttraining's auc: 0.975799\ttraining's binary_logloss: 0.139694\n",
      "[5561]\ttraining's auc: 0.975804\ttraining's binary_logloss: 0.139685\n",
      "[5562]\ttraining's auc: 0.975812\ttraining's binary_logloss: 0.139677\n",
      "[5563]\ttraining's auc: 0.97582\ttraining's binary_logloss: 0.139668\n",
      "[5564]\ttraining's auc: 0.975838\ttraining's binary_logloss: 0.139653\n",
      "[5565]\ttraining's auc: 0.97584\ttraining's binary_logloss: 0.139648\n",
      "[5566]\ttraining's auc: 0.975855\ttraining's binary_logloss: 0.139636\n",
      "[5567]\ttraining's auc: 0.975868\ttraining's binary_logloss: 0.139621\n",
      "[5568]\ttraining's auc: 0.975872\ttraining's binary_logloss: 0.139616\n",
      "[5569]\ttraining's auc: 0.975884\ttraining's binary_logloss: 0.1396\n",
      "[5570]\ttraining's auc: 0.975902\ttraining's binary_logloss: 0.139585\n",
      "[5571]\ttraining's auc: 0.975916\ttraining's binary_logloss: 0.139572\n",
      "[5572]\ttraining's auc: 0.975927\ttraining's binary_logloss: 0.139557\n",
      "[5573]\ttraining's auc: 0.975938\ttraining's binary_logloss: 0.139545\n",
      "[5574]\ttraining's auc: 0.975948\ttraining's binary_logloss: 0.139532\n",
      "[5575]\ttraining's auc: 0.975959\ttraining's binary_logloss: 0.139518\n",
      "[5576]\ttraining's auc: 0.975966\ttraining's binary_logloss: 0.139506\n",
      "[5577]\ttraining's auc: 0.975978\ttraining's binary_logloss: 0.139491\n",
      "[5578]\ttraining's auc: 0.975981\ttraining's binary_logloss: 0.139487\n",
      "[5579]\ttraining's auc: 0.975988\ttraining's binary_logloss: 0.139474\n",
      "[5580]\ttraining's auc: 0.976006\ttraining's binary_logloss: 0.139459\n",
      "[5581]\ttraining's auc: 0.976018\ttraining's binary_logloss: 0.139445\n",
      "[5582]\ttraining's auc: 0.976028\ttraining's binary_logloss: 0.13943\n",
      "[5583]\ttraining's auc: 0.976036\ttraining's binary_logloss: 0.139417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5584]\ttraining's auc: 0.976051\ttraining's binary_logloss: 0.139402\n",
      "[5585]\ttraining's auc: 0.97606\ttraining's binary_logloss: 0.139387\n",
      "[5586]\ttraining's auc: 0.976068\ttraining's binary_logloss: 0.139379\n",
      "[5587]\ttraining's auc: 0.97607\ttraining's binary_logloss: 0.139375\n",
      "[5588]\ttraining's auc: 0.976079\ttraining's binary_logloss: 0.139362\n",
      "[5589]\ttraining's auc: 0.976084\ttraining's binary_logloss: 0.139352\n",
      "[5590]\ttraining's auc: 0.976094\ttraining's binary_logloss: 0.139337\n",
      "[5591]\ttraining's auc: 0.976107\ttraining's binary_logloss: 0.139325\n",
      "[5592]\ttraining's auc: 0.976118\ttraining's binary_logloss: 0.139312\n",
      "[5593]\ttraining's auc: 0.976134\ttraining's binary_logloss: 0.139297\n",
      "[5594]\ttraining's auc: 0.976141\ttraining's binary_logloss: 0.139284\n",
      "[5595]\ttraining's auc: 0.976155\ttraining's binary_logloss: 0.139268\n",
      "[5596]\ttraining's auc: 0.976162\ttraining's binary_logloss: 0.139261\n",
      "[5597]\ttraining's auc: 0.976169\ttraining's binary_logloss: 0.13925\n",
      "[5598]\ttraining's auc: 0.976176\ttraining's binary_logloss: 0.139237\n",
      "[5599]\ttraining's auc: 0.976194\ttraining's binary_logloss: 0.139223\n",
      "[5600]\ttraining's auc: 0.976206\ttraining's binary_logloss: 0.139211\n",
      "[5601]\ttraining's auc: 0.976219\ttraining's binary_logloss: 0.139197\n",
      "[5602]\ttraining's auc: 0.976224\ttraining's binary_logloss: 0.139191\n",
      "[5603]\ttraining's auc: 0.976234\ttraining's binary_logloss: 0.139179\n",
      "[5604]\ttraining's auc: 0.976246\ttraining's binary_logloss: 0.139166\n",
      "[5605]\ttraining's auc: 0.976257\ttraining's binary_logloss: 0.139153\n",
      "[5606]\ttraining's auc: 0.97627\ttraining's binary_logloss: 0.139139\n",
      "[5607]\ttraining's auc: 0.97628\ttraining's binary_logloss: 0.139128\n",
      "[5608]\ttraining's auc: 0.976289\ttraining's binary_logloss: 0.139115\n",
      "[5609]\ttraining's auc: 0.976305\ttraining's binary_logloss: 0.139099\n",
      "[5610]\ttraining's auc: 0.976319\ttraining's binary_logloss: 0.139085\n",
      "[5611]\ttraining's auc: 0.976322\ttraining's binary_logloss: 0.139082\n",
      "[5612]\ttraining's auc: 0.976322\ttraining's binary_logloss: 0.139079\n",
      "[5613]\ttraining's auc: 0.976325\ttraining's binary_logloss: 0.139073\n",
      "[5614]\ttraining's auc: 0.976327\ttraining's binary_logloss: 0.139066\n",
      "[5615]\ttraining's auc: 0.976333\ttraining's binary_logloss: 0.139061\n",
      "[5616]\ttraining's auc: 0.976346\ttraining's binary_logloss: 0.139049\n",
      "[5617]\ttraining's auc: 0.976351\ttraining's binary_logloss: 0.139044\n",
      "[5618]\ttraining's auc: 0.976362\ttraining's binary_logloss: 0.139031\n",
      "[5619]\ttraining's auc: 0.97638\ttraining's binary_logloss: 0.139014\n",
      "[5620]\ttraining's auc: 0.976387\ttraining's binary_logloss: 0.139004\n",
      "[5621]\ttraining's auc: 0.976401\ttraining's binary_logloss: 0.138993\n",
      "[5622]\ttraining's auc: 0.976413\ttraining's binary_logloss: 0.13898\n",
      "[5623]\ttraining's auc: 0.976423\ttraining's binary_logloss: 0.138969\n",
      "[5624]\ttraining's auc: 0.976432\ttraining's binary_logloss: 0.138962\n",
      "[5625]\ttraining's auc: 0.97644\ttraining's binary_logloss: 0.138952\n",
      "[5626]\ttraining's auc: 0.976443\ttraining's binary_logloss: 0.138946\n",
      "[5627]\ttraining's auc: 0.976449\ttraining's binary_logloss: 0.138933\n",
      "[5628]\ttraining's auc: 0.976458\ttraining's binary_logloss: 0.138921\n",
      "[5629]\ttraining's auc: 0.976477\ttraining's binary_logloss: 0.138906\n",
      "[5630]\ttraining's auc: 0.976486\ttraining's binary_logloss: 0.138894\n",
      "[5631]\ttraining's auc: 0.976499\ttraining's binary_logloss: 0.138879\n",
      "[5632]\ttraining's auc: 0.976511\ttraining's binary_logloss: 0.138865\n",
      "[5633]\ttraining's auc: 0.976522\ttraining's binary_logloss: 0.138852\n",
      "[5634]\ttraining's auc: 0.976526\ttraining's binary_logloss: 0.138849\n",
      "[5635]\ttraining's auc: 0.976537\ttraining's binary_logloss: 0.138835\n",
      "[5636]\ttraining's auc: 0.976546\ttraining's binary_logloss: 0.138821\n",
      "[5637]\ttraining's auc: 0.976558\ttraining's binary_logloss: 0.138807\n",
      "[5638]\ttraining's auc: 0.976569\ttraining's binary_logloss: 0.138793\n",
      "[5639]\ttraining's auc: 0.976574\ttraining's binary_logloss: 0.13878\n",
      "[5640]\ttraining's auc: 0.976589\ttraining's binary_logloss: 0.138766\n",
      "[5641]\ttraining's auc: 0.976602\ttraining's binary_logloss: 0.138754\n",
      "[5642]\ttraining's auc: 0.97661\ttraining's binary_logloss: 0.138744\n",
      "[5643]\ttraining's auc: 0.976622\ttraining's binary_logloss: 0.138729\n",
      "[5644]\ttraining's auc: 0.97664\ttraining's binary_logloss: 0.138714\n",
      "[5645]\ttraining's auc: 0.97665\ttraining's binary_logloss: 0.1387\n",
      "[5646]\ttraining's auc: 0.976651\ttraining's binary_logloss: 0.138698\n",
      "[5647]\ttraining's auc: 0.976653\ttraining's binary_logloss: 0.138695\n",
      "[5648]\ttraining's auc: 0.976671\ttraining's binary_logloss: 0.138682\n",
      "[5649]\ttraining's auc: 0.976683\ttraining's binary_logloss: 0.138669\n",
      "[5650]\ttraining's auc: 0.976685\ttraining's binary_logloss: 0.138667\n",
      "[5651]\ttraining's auc: 0.976701\ttraining's binary_logloss: 0.138652\n",
      "[5652]\ttraining's auc: 0.976718\ttraining's binary_logloss: 0.138634\n",
      "[5653]\ttraining's auc: 0.976719\ttraining's binary_logloss: 0.138632\n",
      "[5654]\ttraining's auc: 0.976721\ttraining's binary_logloss: 0.138629\n",
      "[5655]\ttraining's auc: 0.976732\ttraining's binary_logloss: 0.138616\n",
      "[5656]\ttraining's auc: 0.976745\ttraining's binary_logloss: 0.138601\n",
      "[5657]\ttraining's auc: 0.976756\ttraining's binary_logloss: 0.138589\n",
      "[5658]\ttraining's auc: 0.976762\ttraining's binary_logloss: 0.138578\n",
      "[5659]\ttraining's auc: 0.976775\ttraining's binary_logloss: 0.138565\n",
      "[5660]\ttraining's auc: 0.976787\ttraining's binary_logloss: 0.13855\n",
      "[5661]\ttraining's auc: 0.976797\ttraining's binary_logloss: 0.138536\n",
      "[5662]\ttraining's auc: 0.976806\ttraining's binary_logloss: 0.138522\n",
      "[5663]\ttraining's auc: 0.976814\ttraining's binary_logloss: 0.138513\n",
      "[5664]\ttraining's auc: 0.97683\ttraining's binary_logloss: 0.138496\n",
      "[5665]\ttraining's auc: 0.976832\ttraining's binary_logloss: 0.13849\n",
      "[5666]\ttraining's auc: 0.976848\ttraining's binary_logloss: 0.138476\n",
      "[5667]\ttraining's auc: 0.976856\ttraining's binary_logloss: 0.138465\n",
      "[5668]\ttraining's auc: 0.976865\ttraining's binary_logloss: 0.138452\n",
      "[5669]\ttraining's auc: 0.976875\ttraining's binary_logloss: 0.13844\n",
      "[5670]\ttraining's auc: 0.976882\ttraining's binary_logloss: 0.138426\n",
      "[5671]\ttraining's auc: 0.976889\ttraining's binary_logloss: 0.138418\n",
      "[5672]\ttraining's auc: 0.976893\ttraining's binary_logloss: 0.138412\n",
      "[5673]\ttraining's auc: 0.9769\ttraining's binary_logloss: 0.138397\n",
      "[5674]\ttraining's auc: 0.976915\ttraining's binary_logloss: 0.138385\n",
      "[5675]\ttraining's auc: 0.976925\ttraining's binary_logloss: 0.138373\n",
      "[5676]\ttraining's auc: 0.976935\ttraining's binary_logloss: 0.13836\n",
      "[5677]\ttraining's auc: 0.976942\ttraining's binary_logloss: 0.138351\n",
      "[5678]\ttraining's auc: 0.976952\ttraining's binary_logloss: 0.138339\n",
      "[5679]\ttraining's auc: 0.976963\ttraining's binary_logloss: 0.13833\n",
      "[5680]\ttraining's auc: 0.976973\ttraining's binary_logloss: 0.138317\n",
      "[5681]\ttraining's auc: 0.976983\ttraining's binary_logloss: 0.138307\n",
      "[5682]\ttraining's auc: 0.976989\ttraining's binary_logloss: 0.138295\n",
      "[5683]\ttraining's auc: 0.977\ttraining's binary_logloss: 0.13828\n",
      "[5684]\ttraining's auc: 0.977007\ttraining's binary_logloss: 0.138269\n",
      "[5685]\ttraining's auc: 0.977018\ttraining's binary_logloss: 0.138259\n",
      "[5686]\ttraining's auc: 0.977028\ttraining's binary_logloss: 0.138245\n",
      "[5687]\ttraining's auc: 0.977052\ttraining's binary_logloss: 0.138229\n",
      "[5688]\ttraining's auc: 0.977061\ttraining's binary_logloss: 0.138217\n",
      "[5689]\ttraining's auc: 0.977069\ttraining's binary_logloss: 0.138203\n",
      "[5690]\ttraining's auc: 0.97708\ttraining's binary_logloss: 0.13819\n",
      "[5691]\ttraining's auc: 0.977087\ttraining's binary_logloss: 0.138181\n",
      "[5692]\ttraining's auc: 0.977099\ttraining's binary_logloss: 0.138168\n",
      "[5693]\ttraining's auc: 0.977108\ttraining's binary_logloss: 0.138162\n",
      "[5694]\ttraining's auc: 0.97712\ttraining's binary_logloss: 0.138147\n",
      "[5695]\ttraining's auc: 0.977129\ttraining's binary_logloss: 0.138134\n",
      "[5696]\ttraining's auc: 0.97714\ttraining's binary_logloss: 0.13812\n",
      "[5697]\ttraining's auc: 0.977151\ttraining's binary_logloss: 0.138106\n",
      "[5698]\ttraining's auc: 0.977158\ttraining's binary_logloss: 0.138093\n",
      "[5699]\ttraining's auc: 0.977173\ttraining's binary_logloss: 0.138077\n",
      "[5700]\ttraining's auc: 0.977185\ttraining's binary_logloss: 0.138062\n",
      "[5701]\ttraining's auc: 0.977196\ttraining's binary_logloss: 0.138048\n",
      "[5702]\ttraining's auc: 0.977209\ttraining's binary_logloss: 0.138032\n",
      "[5703]\ttraining's auc: 0.977219\ttraining's binary_logloss: 0.13802\n",
      "[5704]\ttraining's auc: 0.977235\ttraining's binary_logloss: 0.138006\n",
      "[5705]\ttraining's auc: 0.97725\ttraining's binary_logloss: 0.137991\n",
      "[5706]\ttraining's auc: 0.977262\ttraining's binary_logloss: 0.137976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5707]\ttraining's auc: 0.977277\ttraining's binary_logloss: 0.137963\n",
      "[5708]\ttraining's auc: 0.977288\ttraining's binary_logloss: 0.137949\n",
      "[5709]\ttraining's auc: 0.977305\ttraining's binary_logloss: 0.137935\n",
      "[5710]\ttraining's auc: 0.977315\ttraining's binary_logloss: 0.137922\n",
      "[5711]\ttraining's auc: 0.977323\ttraining's binary_logloss: 0.137914\n",
      "[5712]\ttraining's auc: 0.977334\ttraining's binary_logloss: 0.137902\n",
      "[5713]\ttraining's auc: 0.977343\ttraining's binary_logloss: 0.13789\n",
      "[5714]\ttraining's auc: 0.977351\ttraining's binary_logloss: 0.137877\n",
      "[5715]\ttraining's auc: 0.977359\ttraining's binary_logloss: 0.137865\n",
      "[5716]\ttraining's auc: 0.977374\ttraining's binary_logloss: 0.13785\n",
      "[5717]\ttraining's auc: 0.977381\ttraining's binary_logloss: 0.137842\n",
      "[5718]\ttraining's auc: 0.977397\ttraining's binary_logloss: 0.137827\n",
      "[5719]\ttraining's auc: 0.977407\ttraining's binary_logloss: 0.137814\n",
      "[5720]\ttraining's auc: 0.977416\ttraining's binary_logloss: 0.1378\n",
      "[5721]\ttraining's auc: 0.977419\ttraining's binary_logloss: 0.137793\n",
      "[5722]\ttraining's auc: 0.977429\ttraining's binary_logloss: 0.137778\n",
      "[5723]\ttraining's auc: 0.977443\ttraining's binary_logloss: 0.137764\n",
      "[5724]\ttraining's auc: 0.977452\ttraining's binary_logloss: 0.137753\n",
      "[5725]\ttraining's auc: 0.977469\ttraining's binary_logloss: 0.137738\n",
      "[5726]\ttraining's auc: 0.977483\ttraining's binary_logloss: 0.137725\n",
      "[5727]\ttraining's auc: 0.977502\ttraining's binary_logloss: 0.13771\n",
      "[5728]\ttraining's auc: 0.977519\ttraining's binary_logloss: 0.137695\n",
      "[5729]\ttraining's auc: 0.977533\ttraining's binary_logloss: 0.137681\n",
      "[5730]\ttraining's auc: 0.977542\ttraining's binary_logloss: 0.137668\n",
      "[5731]\ttraining's auc: 0.977549\ttraining's binary_logloss: 0.137655\n",
      "[5732]\ttraining's auc: 0.977554\ttraining's binary_logloss: 0.137647\n",
      "[5733]\ttraining's auc: 0.977559\ttraining's binary_logloss: 0.137642\n",
      "[5734]\ttraining's auc: 0.977567\ttraining's binary_logloss: 0.137627\n",
      "[5735]\ttraining's auc: 0.977573\ttraining's binary_logloss: 0.137616\n",
      "[5736]\ttraining's auc: 0.97758\ttraining's binary_logloss: 0.137604\n",
      "[5737]\ttraining's auc: 0.977589\ttraining's binary_logloss: 0.137591\n",
      "[5738]\ttraining's auc: 0.977605\ttraining's binary_logloss: 0.137573\n",
      "[5739]\ttraining's auc: 0.977607\ttraining's binary_logloss: 0.137569\n",
      "[5740]\ttraining's auc: 0.977613\ttraining's binary_logloss: 0.137558\n",
      "[5741]\ttraining's auc: 0.977618\ttraining's binary_logloss: 0.137547\n",
      "[5742]\ttraining's auc: 0.977633\ttraining's binary_logloss: 0.137534\n",
      "[5743]\ttraining's auc: 0.977644\ttraining's binary_logloss: 0.137519\n",
      "[5744]\ttraining's auc: 0.97765\ttraining's binary_logloss: 0.137513\n",
      "[5745]\ttraining's auc: 0.977658\ttraining's binary_logloss: 0.137502\n",
      "[5746]\ttraining's auc: 0.977669\ttraining's binary_logloss: 0.137487\n",
      "[5747]\ttraining's auc: 0.977678\ttraining's binary_logloss: 0.137474\n",
      "[5748]\ttraining's auc: 0.977684\ttraining's binary_logloss: 0.137462\n",
      "[5749]\ttraining's auc: 0.97769\ttraining's binary_logloss: 0.137448\n",
      "[5750]\ttraining's auc: 0.977701\ttraining's binary_logloss: 0.137436\n",
      "[5751]\ttraining's auc: 0.977709\ttraining's binary_logloss: 0.137424\n",
      "[5752]\ttraining's auc: 0.977714\ttraining's binary_logloss: 0.137412\n",
      "[5753]\ttraining's auc: 0.977724\ttraining's binary_logloss: 0.137401\n",
      "[5754]\ttraining's auc: 0.977727\ttraining's binary_logloss: 0.137397\n",
      "[5755]\ttraining's auc: 0.977735\ttraining's binary_logloss: 0.137387\n",
      "[5756]\ttraining's auc: 0.977747\ttraining's binary_logloss: 0.137374\n",
      "[5757]\ttraining's auc: 0.977759\ttraining's binary_logloss: 0.13736\n",
      "[5758]\ttraining's auc: 0.977763\ttraining's binary_logloss: 0.137352\n",
      "[5759]\ttraining's auc: 0.97778\ttraining's binary_logloss: 0.137338\n",
      "[5760]\ttraining's auc: 0.977791\ttraining's binary_logloss: 0.137325\n",
      "[5761]\ttraining's auc: 0.977804\ttraining's binary_logloss: 0.137311\n",
      "[5762]\ttraining's auc: 0.977814\ttraining's binary_logloss: 0.137296\n",
      "[5763]\ttraining's auc: 0.977829\ttraining's binary_logloss: 0.137284\n",
      "[5764]\ttraining's auc: 0.977838\ttraining's binary_logloss: 0.137271\n",
      "[5765]\ttraining's auc: 0.977847\ttraining's binary_logloss: 0.137259\n",
      "[5766]\ttraining's auc: 0.97786\ttraining's binary_logloss: 0.137245\n",
      "[5767]\ttraining's auc: 0.977876\ttraining's binary_logloss: 0.137228\n",
      "[5768]\ttraining's auc: 0.977884\ttraining's binary_logloss: 0.137218\n",
      "[5769]\ttraining's auc: 0.977892\ttraining's binary_logloss: 0.137204\n",
      "[5770]\ttraining's auc: 0.977898\ttraining's binary_logloss: 0.137191\n",
      "[5771]\ttraining's auc: 0.977902\ttraining's binary_logloss: 0.137178\n",
      "[5772]\ttraining's auc: 0.977918\ttraining's binary_logloss: 0.137164\n",
      "[5773]\ttraining's auc: 0.977927\ttraining's binary_logloss: 0.13715\n",
      "[5774]\ttraining's auc: 0.977938\ttraining's binary_logloss: 0.137136\n",
      "[5775]\ttraining's auc: 0.97795\ttraining's binary_logloss: 0.137123\n",
      "[5776]\ttraining's auc: 0.977962\ttraining's binary_logloss: 0.137112\n",
      "[5777]\ttraining's auc: 0.977969\ttraining's binary_logloss: 0.137099\n",
      "[5778]\ttraining's auc: 0.97798\ttraining's binary_logloss: 0.137086\n",
      "[5779]\ttraining's auc: 0.977991\ttraining's binary_logloss: 0.13707\n",
      "[5780]\ttraining's auc: 0.978\ttraining's binary_logloss: 0.137058\n",
      "[5781]\ttraining's auc: 0.978006\ttraining's binary_logloss: 0.13705\n",
      "[5782]\ttraining's auc: 0.978018\ttraining's binary_logloss: 0.137035\n",
      "[5783]\ttraining's auc: 0.978026\ttraining's binary_logloss: 0.137026\n",
      "[5784]\ttraining's auc: 0.978039\ttraining's binary_logloss: 0.137011\n",
      "[5785]\ttraining's auc: 0.978048\ttraining's binary_logloss: 0.137001\n",
      "[5786]\ttraining's auc: 0.978061\ttraining's binary_logloss: 0.136984\n",
      "[5787]\ttraining's auc: 0.978071\ttraining's binary_logloss: 0.136969\n",
      "[5788]\ttraining's auc: 0.978084\ttraining's binary_logloss: 0.136956\n",
      "[5789]\ttraining's auc: 0.978089\ttraining's binary_logloss: 0.136943\n",
      "[5790]\ttraining's auc: 0.978101\ttraining's binary_logloss: 0.136928\n",
      "[5791]\ttraining's auc: 0.978111\ttraining's binary_logloss: 0.136916\n",
      "[5792]\ttraining's auc: 0.978119\ttraining's binary_logloss: 0.136906\n",
      "[5793]\ttraining's auc: 0.978131\ttraining's binary_logloss: 0.136892\n",
      "[5794]\ttraining's auc: 0.978134\ttraining's binary_logloss: 0.136889\n",
      "[5795]\ttraining's auc: 0.978146\ttraining's binary_logloss: 0.136873\n",
      "[5796]\ttraining's auc: 0.978158\ttraining's binary_logloss: 0.136859\n",
      "[5797]\ttraining's auc: 0.978169\ttraining's binary_logloss: 0.136846\n",
      "[5798]\ttraining's auc: 0.978176\ttraining's binary_logloss: 0.136837\n",
      "[5799]\ttraining's auc: 0.978187\ttraining's binary_logloss: 0.136824\n",
      "[5800]\ttraining's auc: 0.978201\ttraining's binary_logloss: 0.13681\n",
      "[5801]\ttraining's auc: 0.978216\ttraining's binary_logloss: 0.136797\n",
      "[5802]\ttraining's auc: 0.97823\ttraining's binary_logloss: 0.136783\n",
      "[5803]\ttraining's auc: 0.978238\ttraining's binary_logloss: 0.136771\n",
      "[5804]\ttraining's auc: 0.97825\ttraining's binary_logloss: 0.136758\n",
      "[5805]\ttraining's auc: 0.97826\ttraining's binary_logloss: 0.136744\n",
      "[5806]\ttraining's auc: 0.97827\ttraining's binary_logloss: 0.13673\n",
      "[5807]\ttraining's auc: 0.97828\ttraining's binary_logloss: 0.136717\n",
      "[5808]\ttraining's auc: 0.97829\ttraining's binary_logloss: 0.136705\n",
      "[5809]\ttraining's auc: 0.978301\ttraining's binary_logloss: 0.136691\n",
      "[5810]\ttraining's auc: 0.978307\ttraining's binary_logloss: 0.136679\n",
      "[5811]\ttraining's auc: 0.978314\ttraining's binary_logloss: 0.136666\n",
      "[5812]\ttraining's auc: 0.978326\ttraining's binary_logloss: 0.136653\n",
      "[5813]\ttraining's auc: 0.978334\ttraining's binary_logloss: 0.136641\n",
      "[5814]\ttraining's auc: 0.978341\ttraining's binary_logloss: 0.136632\n",
      "[5815]\ttraining's auc: 0.978349\ttraining's binary_logloss: 0.136618\n",
      "[5816]\ttraining's auc: 0.978363\ttraining's binary_logloss: 0.136603\n",
      "[5817]\ttraining's auc: 0.978373\ttraining's binary_logloss: 0.13659\n",
      "[5818]\ttraining's auc: 0.97838\ttraining's binary_logloss: 0.136578\n",
      "[5819]\ttraining's auc: 0.978389\ttraining's binary_logloss: 0.136565\n",
      "[5820]\ttraining's auc: 0.978398\ttraining's binary_logloss: 0.136555\n",
      "[5821]\ttraining's auc: 0.978406\ttraining's binary_logloss: 0.136546\n",
      "[5822]\ttraining's auc: 0.978415\ttraining's binary_logloss: 0.136534\n",
      "[5823]\ttraining's auc: 0.97842\ttraining's binary_logloss: 0.136522\n",
      "[5824]\ttraining's auc: 0.978429\ttraining's binary_logloss: 0.136509\n",
      "[5825]\ttraining's auc: 0.978434\ttraining's binary_logloss: 0.136503\n",
      "[5826]\ttraining's auc: 0.978444\ttraining's binary_logloss: 0.136491\n",
      "[5827]\ttraining's auc: 0.978455\ttraining's binary_logloss: 0.136478\n",
      "[5828]\ttraining's auc: 0.978462\ttraining's binary_logloss: 0.136469\n",
      "[5829]\ttraining's auc: 0.978471\ttraining's binary_logloss: 0.136456\n",
      "[5830]\ttraining's auc: 0.97848\ttraining's binary_logloss: 0.136443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5831]\ttraining's auc: 0.978493\ttraining's binary_logloss: 0.136429\n",
      "[5832]\ttraining's auc: 0.97851\ttraining's binary_logloss: 0.136414\n",
      "[5833]\ttraining's auc: 0.978514\ttraining's binary_logloss: 0.136407\n",
      "[5834]\ttraining's auc: 0.978526\ttraining's binary_logloss: 0.136395\n",
      "[5835]\ttraining's auc: 0.978533\ttraining's binary_logloss: 0.136383\n",
      "[5836]\ttraining's auc: 0.97855\ttraining's binary_logloss: 0.136368\n",
      "[5837]\ttraining's auc: 0.978557\ttraining's binary_logloss: 0.136356\n",
      "[5838]\ttraining's auc: 0.978567\ttraining's binary_logloss: 0.136343\n",
      "[5839]\ttraining's auc: 0.97857\ttraining's binary_logloss: 0.136333\n",
      "[5840]\ttraining's auc: 0.97857\ttraining's binary_logloss: 0.136332\n",
      "[5841]\ttraining's auc: 0.978579\ttraining's binary_logloss: 0.136321\n",
      "[5842]\ttraining's auc: 0.978587\ttraining's binary_logloss: 0.136307\n",
      "[5843]\ttraining's auc: 0.978603\ttraining's binary_logloss: 0.136292\n",
      "[5844]\ttraining's auc: 0.978616\ttraining's binary_logloss: 0.136276\n",
      "[5845]\ttraining's auc: 0.978624\ttraining's binary_logloss: 0.136264\n",
      "[5846]\ttraining's auc: 0.978633\ttraining's binary_logloss: 0.136249\n",
      "[5847]\ttraining's auc: 0.97865\ttraining's binary_logloss: 0.136233\n",
      "[5848]\ttraining's auc: 0.978657\ttraining's binary_logloss: 0.136221\n",
      "[5849]\ttraining's auc: 0.978667\ttraining's binary_logloss: 0.136208\n",
      "[5850]\ttraining's auc: 0.978682\ttraining's binary_logloss: 0.136193\n",
      "[5851]\ttraining's auc: 0.978692\ttraining's binary_logloss: 0.136179\n",
      "[5852]\ttraining's auc: 0.978712\ttraining's binary_logloss: 0.136161\n",
      "[5853]\ttraining's auc: 0.978719\ttraining's binary_logloss: 0.136148\n",
      "[5854]\ttraining's auc: 0.978727\ttraining's binary_logloss: 0.136135\n",
      "[5855]\ttraining's auc: 0.978736\ttraining's binary_logloss: 0.136122\n",
      "[5856]\ttraining's auc: 0.978753\ttraining's binary_logloss: 0.136108\n",
      "[5857]\ttraining's auc: 0.97876\ttraining's binary_logloss: 0.136097\n",
      "[5858]\ttraining's auc: 0.978772\ttraining's binary_logloss: 0.136084\n",
      "[5859]\ttraining's auc: 0.978775\ttraining's binary_logloss: 0.13608\n",
      "[5860]\ttraining's auc: 0.978783\ttraining's binary_logloss: 0.136068\n",
      "[5861]\ttraining's auc: 0.978792\ttraining's binary_logloss: 0.136055\n",
      "[5862]\ttraining's auc: 0.978804\ttraining's binary_logloss: 0.136042\n",
      "[5863]\ttraining's auc: 0.978805\ttraining's binary_logloss: 0.136041\n",
      "[5864]\ttraining's auc: 0.97881\ttraining's binary_logloss: 0.136029\n",
      "[5865]\ttraining's auc: 0.978814\ttraining's binary_logloss: 0.13602\n",
      "[5866]\ttraining's auc: 0.978824\ttraining's binary_logloss: 0.136011\n",
      "[5867]\ttraining's auc: 0.978833\ttraining's binary_logloss: 0.136\n",
      "[5868]\ttraining's auc: 0.978844\ttraining's binary_logloss: 0.135988\n",
      "[5869]\ttraining's auc: 0.978856\ttraining's binary_logloss: 0.135974\n",
      "[5870]\ttraining's auc: 0.978867\ttraining's binary_logloss: 0.135962\n",
      "[5871]\ttraining's auc: 0.978872\ttraining's binary_logloss: 0.135958\n",
      "[5872]\ttraining's auc: 0.97888\ttraining's binary_logloss: 0.135947\n",
      "[5873]\ttraining's auc: 0.978888\ttraining's binary_logloss: 0.135935\n",
      "[5874]\ttraining's auc: 0.978894\ttraining's binary_logloss: 0.135926\n",
      "[5875]\ttraining's auc: 0.978902\ttraining's binary_logloss: 0.135914\n",
      "[5876]\ttraining's auc: 0.978915\ttraining's binary_logloss: 0.1359\n",
      "[5877]\ttraining's auc: 0.978919\ttraining's binary_logloss: 0.135893\n",
      "[5878]\ttraining's auc: 0.978924\ttraining's binary_logloss: 0.135882\n",
      "[5879]\ttraining's auc: 0.978933\ttraining's binary_logloss: 0.13587\n",
      "[5880]\ttraining's auc: 0.978943\ttraining's binary_logloss: 0.135858\n",
      "[5881]\ttraining's auc: 0.97895\ttraining's binary_logloss: 0.135847\n",
      "[5882]\ttraining's auc: 0.978958\ttraining's binary_logloss: 0.135834\n",
      "[5883]\ttraining's auc: 0.978963\ttraining's binary_logloss: 0.135824\n",
      "[5884]\ttraining's auc: 0.978974\ttraining's binary_logloss: 0.135812\n",
      "[5885]\ttraining's auc: 0.978986\ttraining's binary_logloss: 0.135796\n",
      "[5886]\ttraining's auc: 0.978996\ttraining's binary_logloss: 0.135784\n",
      "[5887]\ttraining's auc: 0.979007\ttraining's binary_logloss: 0.135769\n",
      "[5888]\ttraining's auc: 0.979025\ttraining's binary_logloss: 0.135756\n",
      "[5889]\ttraining's auc: 0.979026\ttraining's binary_logloss: 0.135752\n",
      "[5890]\ttraining's auc: 0.979029\ttraining's binary_logloss: 0.135747\n",
      "[5891]\ttraining's auc: 0.979039\ttraining's binary_logloss: 0.135735\n",
      "[5892]\ttraining's auc: 0.979049\ttraining's binary_logloss: 0.135724\n",
      "[5893]\ttraining's auc: 0.979048\ttraining's binary_logloss: 0.135722\n",
      "[5894]\ttraining's auc: 0.979055\ttraining's binary_logloss: 0.135715\n",
      "[5895]\ttraining's auc: 0.979062\ttraining's binary_logloss: 0.135704\n",
      "[5896]\ttraining's auc: 0.979071\ttraining's binary_logloss: 0.135691\n",
      "[5897]\ttraining's auc: 0.979074\ttraining's binary_logloss: 0.135688\n",
      "[5898]\ttraining's auc: 0.979079\ttraining's binary_logloss: 0.135681\n",
      "[5899]\ttraining's auc: 0.97909\ttraining's binary_logloss: 0.135667\n",
      "[5900]\ttraining's auc: 0.979101\ttraining's binary_logloss: 0.135653\n",
      "[5901]\ttraining's auc: 0.979107\ttraining's binary_logloss: 0.135643\n",
      "[5902]\ttraining's auc: 0.979115\ttraining's binary_logloss: 0.135632\n",
      "[5903]\ttraining's auc: 0.979126\ttraining's binary_logloss: 0.135622\n",
      "[5904]\ttraining's auc: 0.979127\ttraining's binary_logloss: 0.135618\n",
      "[5905]\ttraining's auc: 0.979135\ttraining's binary_logloss: 0.135605\n",
      "[5906]\ttraining's auc: 0.979137\ttraining's binary_logloss: 0.1356\n",
      "[5907]\ttraining's auc: 0.979151\ttraining's binary_logloss: 0.135586\n",
      "[5908]\ttraining's auc: 0.979151\ttraining's binary_logloss: 0.135583\n",
      "[5909]\ttraining's auc: 0.979161\ttraining's binary_logloss: 0.135568\n",
      "[5910]\ttraining's auc: 0.979173\ttraining's binary_logloss: 0.135556\n",
      "[5911]\ttraining's auc: 0.979179\ttraining's binary_logloss: 0.135545\n",
      "[5912]\ttraining's auc: 0.979183\ttraining's binary_logloss: 0.135535\n",
      "[5913]\ttraining's auc: 0.979192\ttraining's binary_logloss: 0.135526\n",
      "[5914]\ttraining's auc: 0.979202\ttraining's binary_logloss: 0.135513\n",
      "[5915]\ttraining's auc: 0.979213\ttraining's binary_logloss: 0.135499\n",
      "[5916]\ttraining's auc: 0.979222\ttraining's binary_logloss: 0.135486\n",
      "[5917]\ttraining's auc: 0.979237\ttraining's binary_logloss: 0.135473\n",
      "[5918]\ttraining's auc: 0.979243\ttraining's binary_logloss: 0.13546\n",
      "[5919]\ttraining's auc: 0.979253\ttraining's binary_logloss: 0.135448\n",
      "[5920]\ttraining's auc: 0.979261\ttraining's binary_logloss: 0.135435\n",
      "[5921]\ttraining's auc: 0.97927\ttraining's binary_logloss: 0.135423\n",
      "[5922]\ttraining's auc: 0.97928\ttraining's binary_logloss: 0.135409\n",
      "[5923]\ttraining's auc: 0.979283\ttraining's binary_logloss: 0.135404\n",
      "[5924]\ttraining's auc: 0.979286\ttraining's binary_logloss: 0.135395\n",
      "[5925]\ttraining's auc: 0.979294\ttraining's binary_logloss: 0.135382\n",
      "[5926]\ttraining's auc: 0.979307\ttraining's binary_logloss: 0.135369\n",
      "[5927]\ttraining's auc: 0.979316\ttraining's binary_logloss: 0.135356\n",
      "[5928]\ttraining's auc: 0.979326\ttraining's binary_logloss: 0.135342\n",
      "[5929]\ttraining's auc: 0.979338\ttraining's binary_logloss: 0.135331\n",
      "[5930]\ttraining's auc: 0.979342\ttraining's binary_logloss: 0.135319\n",
      "[5931]\ttraining's auc: 0.979354\ttraining's binary_logloss: 0.135307\n",
      "[5932]\ttraining's auc: 0.979357\ttraining's binary_logloss: 0.135303\n",
      "[5933]\ttraining's auc: 0.979368\ttraining's binary_logloss: 0.135292\n",
      "[5934]\ttraining's auc: 0.979368\ttraining's binary_logloss: 0.135291\n",
      "[5935]\ttraining's auc: 0.979375\ttraining's binary_logloss: 0.135278\n",
      "[5936]\ttraining's auc: 0.979383\ttraining's binary_logloss: 0.135265\n",
      "[5937]\ttraining's auc: 0.979395\ttraining's binary_logloss: 0.135252\n",
      "[5938]\ttraining's auc: 0.9794\ttraining's binary_logloss: 0.135239\n",
      "[5939]\ttraining's auc: 0.97941\ttraining's binary_logloss: 0.135226\n",
      "[5940]\ttraining's auc: 0.97942\ttraining's binary_logloss: 0.135215\n",
      "[5941]\ttraining's auc: 0.979432\ttraining's binary_logloss: 0.135201\n",
      "[5942]\ttraining's auc: 0.979442\ttraining's binary_logloss: 0.135188\n",
      "[5943]\ttraining's auc: 0.979453\ttraining's binary_logloss: 0.135177\n",
      "[5944]\ttraining's auc: 0.97946\ttraining's binary_logloss: 0.135167\n",
      "[5945]\ttraining's auc: 0.979468\ttraining's binary_logloss: 0.135157\n",
      "[5946]\ttraining's auc: 0.979476\ttraining's binary_logloss: 0.13515\n",
      "[5947]\ttraining's auc: 0.97948\ttraining's binary_logloss: 0.135143\n",
      "[5948]\ttraining's auc: 0.979485\ttraining's binary_logloss: 0.135139\n",
      "[5949]\ttraining's auc: 0.979487\ttraining's binary_logloss: 0.135136\n",
      "[5950]\ttraining's auc: 0.97949\ttraining's binary_logloss: 0.135132\n",
      "[5951]\ttraining's auc: 0.979497\ttraining's binary_logloss: 0.13512\n",
      "[5952]\ttraining's auc: 0.979506\ttraining's binary_logloss: 0.135107\n",
      "[5953]\ttraining's auc: 0.979513\ttraining's binary_logloss: 0.135097\n",
      "[5954]\ttraining's auc: 0.979524\ttraining's binary_logloss: 0.135083\n",
      "[5955]\ttraining's auc: 0.979533\ttraining's binary_logloss: 0.135068\n",
      "[5956]\ttraining's auc: 0.979539\ttraining's binary_logloss: 0.135059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5957]\ttraining's auc: 0.979548\ttraining's binary_logloss: 0.135046\n",
      "[5958]\ttraining's auc: 0.979556\ttraining's binary_logloss: 0.135033\n",
      "[5959]\ttraining's auc: 0.97956\ttraining's binary_logloss: 0.135028\n",
      "[5960]\ttraining's auc: 0.979571\ttraining's binary_logloss: 0.135014\n",
      "[5961]\ttraining's auc: 0.979578\ttraining's binary_logloss: 0.135002\n",
      "[5962]\ttraining's auc: 0.979587\ttraining's binary_logloss: 0.13499\n",
      "[5963]\ttraining's auc: 0.979599\ttraining's binary_logloss: 0.134976\n",
      "[5964]\ttraining's auc: 0.979608\ttraining's binary_logloss: 0.134963\n",
      "[5965]\ttraining's auc: 0.979618\ttraining's binary_logloss: 0.134949\n",
      "[5966]\ttraining's auc: 0.979629\ttraining's binary_logloss: 0.134935\n",
      "[5967]\ttraining's auc: 0.979643\ttraining's binary_logloss: 0.13492\n",
      "[5968]\ttraining's auc: 0.979655\ttraining's binary_logloss: 0.134907\n",
      "[5969]\ttraining's auc: 0.979664\ttraining's binary_logloss: 0.134893\n",
      "[5970]\ttraining's auc: 0.979675\ttraining's binary_logloss: 0.13488\n",
      "[5971]\ttraining's auc: 0.979688\ttraining's binary_logloss: 0.134865\n",
      "[5972]\ttraining's auc: 0.979696\ttraining's binary_logloss: 0.134851\n",
      "[5973]\ttraining's auc: 0.97971\ttraining's binary_logloss: 0.134836\n",
      "[5974]\ttraining's auc: 0.979719\ttraining's binary_logloss: 0.134823\n",
      "[5975]\ttraining's auc: 0.979733\ttraining's binary_logloss: 0.134811\n",
      "[5976]\ttraining's auc: 0.979741\ttraining's binary_logloss: 0.134797\n",
      "[5977]\ttraining's auc: 0.979749\ttraining's binary_logloss: 0.134785\n",
      "[5978]\ttraining's auc: 0.979751\ttraining's binary_logloss: 0.134782\n",
      "[5979]\ttraining's auc: 0.979761\ttraining's binary_logloss: 0.134771\n",
      "[5980]\ttraining's auc: 0.979772\ttraining's binary_logloss: 0.134758\n",
      "[5981]\ttraining's auc: 0.979772\ttraining's binary_logloss: 0.134755\n",
      "[5982]\ttraining's auc: 0.979781\ttraining's binary_logloss: 0.134743\n",
      "[5983]\ttraining's auc: 0.979793\ttraining's binary_logloss: 0.134729\n",
      "[5984]\ttraining's auc: 0.979801\ttraining's binary_logloss: 0.134715\n",
      "[5985]\ttraining's auc: 0.979809\ttraining's binary_logloss: 0.134707\n",
      "[5986]\ttraining's auc: 0.979809\ttraining's binary_logloss: 0.134706\n",
      "[5987]\ttraining's auc: 0.979822\ttraining's binary_logloss: 0.134691\n",
      "[5988]\ttraining's auc: 0.97983\ttraining's binary_logloss: 0.134677\n",
      "[5989]\ttraining's auc: 0.979841\ttraining's binary_logloss: 0.134664\n",
      "[5990]\ttraining's auc: 0.979852\ttraining's binary_logloss: 0.134651\n",
      "[5991]\ttraining's auc: 0.97986\ttraining's binary_logloss: 0.134637\n",
      "[5992]\ttraining's auc: 0.979866\ttraining's binary_logloss: 0.134626\n",
      "[5993]\ttraining's auc: 0.979875\ttraining's binary_logloss: 0.134611\n",
      "[5994]\ttraining's auc: 0.979881\ttraining's binary_logloss: 0.1346\n",
      "[5995]\ttraining's auc: 0.979893\ttraining's binary_logloss: 0.134585\n",
      "[5996]\ttraining's auc: 0.979898\ttraining's binary_logloss: 0.134579\n",
      "[5997]\ttraining's auc: 0.979907\ttraining's binary_logloss: 0.134567\n",
      "[5998]\ttraining's auc: 0.979911\ttraining's binary_logloss: 0.134555\n",
      "[5999]\ttraining's auc: 0.979925\ttraining's binary_logloss: 0.13454\n",
      "[6000]\ttraining's auc: 0.979933\ttraining's binary_logloss: 0.134528\n",
      "[6001]\ttraining's auc: 0.979943\ttraining's binary_logloss: 0.134515\n",
      "[6002]\ttraining's auc: 0.979953\ttraining's binary_logloss: 0.134501\n",
      "[6003]\ttraining's auc: 0.979964\ttraining's binary_logloss: 0.134486\n",
      "[6004]\ttraining's auc: 0.979971\ttraining's binary_logloss: 0.134471\n",
      "[6005]\ttraining's auc: 0.979979\ttraining's binary_logloss: 0.134459\n",
      "[6006]\ttraining's auc: 0.979989\ttraining's binary_logloss: 0.134445\n",
      "[6007]\ttraining's auc: 0.980003\ttraining's binary_logloss: 0.134432\n",
      "[6008]\ttraining's auc: 0.980011\ttraining's binary_logloss: 0.134418\n",
      "[6009]\ttraining's auc: 0.980021\ttraining's binary_logloss: 0.134406\n",
      "[6010]\ttraining's auc: 0.980035\ttraining's binary_logloss: 0.134392\n",
      "[6011]\ttraining's auc: 0.980043\ttraining's binary_logloss: 0.134379\n",
      "[6012]\ttraining's auc: 0.980048\ttraining's binary_logloss: 0.134372\n",
      "[6013]\ttraining's auc: 0.980052\ttraining's binary_logloss: 0.134365\n",
      "[6014]\ttraining's auc: 0.980061\ttraining's binary_logloss: 0.134355\n",
      "[6015]\ttraining's auc: 0.980075\ttraining's binary_logloss: 0.13434\n",
      "[6016]\ttraining's auc: 0.980082\ttraining's binary_logloss: 0.134327\n",
      "[6017]\ttraining's auc: 0.980095\ttraining's binary_logloss: 0.134311\n",
      "[6018]\ttraining's auc: 0.980104\ttraining's binary_logloss: 0.134301\n",
      "[6019]\ttraining's auc: 0.980105\ttraining's binary_logloss: 0.134299\n",
      "[6020]\ttraining's auc: 0.980116\ttraining's binary_logloss: 0.134287\n",
      "[6021]\ttraining's auc: 0.980124\ttraining's binary_logloss: 0.134275\n",
      "[6022]\ttraining's auc: 0.980136\ttraining's binary_logloss: 0.134261\n",
      "[6023]\ttraining's auc: 0.980143\ttraining's binary_logloss: 0.134251\n",
      "[6024]\ttraining's auc: 0.980151\ttraining's binary_logloss: 0.134242\n",
      "[6025]\ttraining's auc: 0.980159\ttraining's binary_logloss: 0.134229\n",
      "[6026]\ttraining's auc: 0.980173\ttraining's binary_logloss: 0.134212\n",
      "[6027]\ttraining's auc: 0.980181\ttraining's binary_logloss: 0.1342\n",
      "[6028]\ttraining's auc: 0.980188\ttraining's binary_logloss: 0.134187\n",
      "[6029]\ttraining's auc: 0.98019\ttraining's binary_logloss: 0.134185\n",
      "[6030]\ttraining's auc: 0.9802\ttraining's binary_logloss: 0.134172\n",
      "[6031]\ttraining's auc: 0.980215\ttraining's binary_logloss: 0.134158\n",
      "[6032]\ttraining's auc: 0.980223\ttraining's binary_logloss: 0.134146\n",
      "[6033]\ttraining's auc: 0.980231\ttraining's binary_logloss: 0.134133\n",
      "[6034]\ttraining's auc: 0.980244\ttraining's binary_logloss: 0.134118\n",
      "[6035]\ttraining's auc: 0.980255\ttraining's binary_logloss: 0.134104\n",
      "[6036]\ttraining's auc: 0.980264\ttraining's binary_logloss: 0.134093\n",
      "[6037]\ttraining's auc: 0.98027\ttraining's binary_logloss: 0.134081\n",
      "[6038]\ttraining's auc: 0.980277\ttraining's binary_logloss: 0.134068\n",
      "[6039]\ttraining's auc: 0.980289\ttraining's binary_logloss: 0.134057\n",
      "[6040]\ttraining's auc: 0.980295\ttraining's binary_logloss: 0.134044\n",
      "[6041]\ttraining's auc: 0.980306\ttraining's binary_logloss: 0.134029\n",
      "[6042]\ttraining's auc: 0.980316\ttraining's binary_logloss: 0.134019\n",
      "[6043]\ttraining's auc: 0.980325\ttraining's binary_logloss: 0.134007\n",
      "[6044]\ttraining's auc: 0.980335\ttraining's binary_logloss: 0.133995\n",
      "[6045]\ttraining's auc: 0.980341\ttraining's binary_logloss: 0.133983\n",
      "[6046]\ttraining's auc: 0.980351\ttraining's binary_logloss: 0.133969\n",
      "[6047]\ttraining's auc: 0.980364\ttraining's binary_logloss: 0.133956\n",
      "[6048]\ttraining's auc: 0.980374\ttraining's binary_logloss: 0.13394\n",
      "[6049]\ttraining's auc: 0.980374\ttraining's binary_logloss: 0.133938\n",
      "[6050]\ttraining's auc: 0.980384\ttraining's binary_logloss: 0.133925\n",
      "[6051]\ttraining's auc: 0.980388\ttraining's binary_logloss: 0.133912\n",
      "[6052]\ttraining's auc: 0.980397\ttraining's binary_logloss: 0.133898\n",
      "[6053]\ttraining's auc: 0.980403\ttraining's binary_logloss: 0.133886\n",
      "[6054]\ttraining's auc: 0.980412\ttraining's binary_logloss: 0.13387\n",
      "[6055]\ttraining's auc: 0.980421\ttraining's binary_logloss: 0.133859\n",
      "[6056]\ttraining's auc: 0.980427\ttraining's binary_logloss: 0.133847\n",
      "[6057]\ttraining's auc: 0.980437\ttraining's binary_logloss: 0.133834\n",
      "[6058]\ttraining's auc: 0.980448\ttraining's binary_logloss: 0.133818\n",
      "[6059]\ttraining's auc: 0.980454\ttraining's binary_logloss: 0.133805\n",
      "[6060]\ttraining's auc: 0.980461\ttraining's binary_logloss: 0.133793\n",
      "[6061]\ttraining's auc: 0.980469\ttraining's binary_logloss: 0.133782\n",
      "[6062]\ttraining's auc: 0.980478\ttraining's binary_logloss: 0.133768\n",
      "[6063]\ttraining's auc: 0.980485\ttraining's binary_logloss: 0.133757\n",
      "[6064]\ttraining's auc: 0.980493\ttraining's binary_logloss: 0.133744\n",
      "[6065]\ttraining's auc: 0.980502\ttraining's binary_logloss: 0.133731\n",
      "[6066]\ttraining's auc: 0.98051\ttraining's binary_logloss: 0.133718\n",
      "[6067]\ttraining's auc: 0.980523\ttraining's binary_logloss: 0.133705\n",
      "[6068]\ttraining's auc: 0.980535\ttraining's binary_logloss: 0.133692\n",
      "[6069]\ttraining's auc: 0.980543\ttraining's binary_logloss: 0.133679\n",
      "[6070]\ttraining's auc: 0.980553\ttraining's binary_logloss: 0.133667\n",
      "[6071]\ttraining's auc: 0.980565\ttraining's binary_logloss: 0.133654\n",
      "[6072]\ttraining's auc: 0.980577\ttraining's binary_logloss: 0.133639\n",
      "[6073]\ttraining's auc: 0.980591\ttraining's binary_logloss: 0.133627\n",
      "[6074]\ttraining's auc: 0.980596\ttraining's binary_logloss: 0.133613\n",
      "[6075]\ttraining's auc: 0.980602\ttraining's binary_logloss: 0.133605\n",
      "[6076]\ttraining's auc: 0.980608\ttraining's binary_logloss: 0.133596\n",
      "[6077]\ttraining's auc: 0.980616\ttraining's binary_logloss: 0.133585\n",
      "[6078]\ttraining's auc: 0.980627\ttraining's binary_logloss: 0.133571\n",
      "[6079]\ttraining's auc: 0.980638\ttraining's binary_logloss: 0.133557\n",
      "[6080]\ttraining's auc: 0.980647\ttraining's binary_logloss: 0.133549\n",
      "[6081]\ttraining's auc: 0.980657\ttraining's binary_logloss: 0.133534\n",
      "[6082]\ttraining's auc: 0.980665\ttraining's binary_logloss: 0.133523\n",
      "[6083]\ttraining's auc: 0.980674\ttraining's binary_logloss: 0.13351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6084]\ttraining's auc: 0.980682\ttraining's binary_logloss: 0.133496\n",
      "[6085]\ttraining's auc: 0.980685\ttraining's binary_logloss: 0.133484\n",
      "[6086]\ttraining's auc: 0.980698\ttraining's binary_logloss: 0.13347\n",
      "[6087]\ttraining's auc: 0.9807\ttraining's binary_logloss: 0.133466\n",
      "[6088]\ttraining's auc: 0.98071\ttraining's binary_logloss: 0.133453\n",
      "[6089]\ttraining's auc: 0.980715\ttraining's binary_logloss: 0.13344\n",
      "[6090]\ttraining's auc: 0.980723\ttraining's binary_logloss: 0.133429\n",
      "[6091]\ttraining's auc: 0.980729\ttraining's binary_logloss: 0.133418\n",
      "[6092]\ttraining's auc: 0.980738\ttraining's binary_logloss: 0.133403\n",
      "[6093]\ttraining's auc: 0.980752\ttraining's binary_logloss: 0.13339\n",
      "[6094]\ttraining's auc: 0.980754\ttraining's binary_logloss: 0.133387\n",
      "[6095]\ttraining's auc: 0.980761\ttraining's binary_logloss: 0.133376\n",
      "[6096]\ttraining's auc: 0.980775\ttraining's binary_logloss: 0.133364\n",
      "[6097]\ttraining's auc: 0.980781\ttraining's binary_logloss: 0.133355\n",
      "[6098]\ttraining's auc: 0.980788\ttraining's binary_logloss: 0.133343\n",
      "[6099]\ttraining's auc: 0.980798\ttraining's binary_logloss: 0.133329\n",
      "[6100]\ttraining's auc: 0.980808\ttraining's binary_logloss: 0.133317\n",
      "[6101]\ttraining's auc: 0.980819\ttraining's binary_logloss: 0.133302\n",
      "[6102]\ttraining's auc: 0.980824\ttraining's binary_logloss: 0.13329\n",
      "[6103]\ttraining's auc: 0.980836\ttraining's binary_logloss: 0.133277\n",
      "[6104]\ttraining's auc: 0.980847\ttraining's binary_logloss: 0.133265\n",
      "[6105]\ttraining's auc: 0.980859\ttraining's binary_logloss: 0.13325\n",
      "[6106]\ttraining's auc: 0.980871\ttraining's binary_logloss: 0.133235\n",
      "[6107]\ttraining's auc: 0.980879\ttraining's binary_logloss: 0.133226\n",
      "[6108]\ttraining's auc: 0.980889\ttraining's binary_logloss: 0.133213\n",
      "[6109]\ttraining's auc: 0.980898\ttraining's binary_logloss: 0.133198\n",
      "[6110]\ttraining's auc: 0.980906\ttraining's binary_logloss: 0.133186\n",
      "[6111]\ttraining's auc: 0.980913\ttraining's binary_logloss: 0.133174\n",
      "[6112]\ttraining's auc: 0.980922\ttraining's binary_logloss: 0.133161\n",
      "[6113]\ttraining's auc: 0.980939\ttraining's binary_logloss: 0.133147\n",
      "[6114]\ttraining's auc: 0.980946\ttraining's binary_logloss: 0.133135\n",
      "[6115]\ttraining's auc: 0.980956\ttraining's binary_logloss: 0.13312\n",
      "[6116]\ttraining's auc: 0.980962\ttraining's binary_logloss: 0.133109\n",
      "[6117]\ttraining's auc: 0.980967\ttraining's binary_logloss: 0.133096\n",
      "[6118]\ttraining's auc: 0.980984\ttraining's binary_logloss: 0.133081\n",
      "[6119]\ttraining's auc: 0.980994\ttraining's binary_logloss: 0.133068\n",
      "[6120]\ttraining's auc: 0.981005\ttraining's binary_logloss: 0.133054\n",
      "[6121]\ttraining's auc: 0.981016\ttraining's binary_logloss: 0.133039\n",
      "[6122]\ttraining's auc: 0.981023\ttraining's binary_logloss: 0.133027\n",
      "[6123]\ttraining's auc: 0.981034\ttraining's binary_logloss: 0.133013\n",
      "[6124]\ttraining's auc: 0.981042\ttraining's binary_logloss: 0.133\n",
      "[6125]\ttraining's auc: 0.981049\ttraining's binary_logloss: 0.132987\n",
      "[6126]\ttraining's auc: 0.981055\ttraining's binary_logloss: 0.13298\n",
      "[6127]\ttraining's auc: 0.981066\ttraining's binary_logloss: 0.132968\n",
      "[6128]\ttraining's auc: 0.981077\ttraining's binary_logloss: 0.132954\n",
      "[6129]\ttraining's auc: 0.98109\ttraining's binary_logloss: 0.13294\n",
      "[6130]\ttraining's auc: 0.981099\ttraining's binary_logloss: 0.132927\n",
      "[6131]\ttraining's auc: 0.98111\ttraining's binary_logloss: 0.132914\n",
      "[6132]\ttraining's auc: 0.981114\ttraining's binary_logloss: 0.13291\n",
      "[6133]\ttraining's auc: 0.981116\ttraining's binary_logloss: 0.132906\n",
      "[6134]\ttraining's auc: 0.98113\ttraining's binary_logloss: 0.132892\n",
      "[6135]\ttraining's auc: 0.981145\ttraining's binary_logloss: 0.132875\n",
      "[6136]\ttraining's auc: 0.981154\ttraining's binary_logloss: 0.132864\n",
      "[6137]\ttraining's auc: 0.981163\ttraining's binary_logloss: 0.13285\n",
      "[6138]\ttraining's auc: 0.981171\ttraining's binary_logloss: 0.132839\n",
      "[6139]\ttraining's auc: 0.98118\ttraining's binary_logloss: 0.132825\n",
      "[6140]\ttraining's auc: 0.981187\ttraining's binary_logloss: 0.132812\n",
      "[6141]\ttraining's auc: 0.981199\ttraining's binary_logloss: 0.132798\n",
      "[6142]\ttraining's auc: 0.981208\ttraining's binary_logloss: 0.132785\n",
      "[6143]\ttraining's auc: 0.981216\ttraining's binary_logloss: 0.132773\n",
      "[6144]\ttraining's auc: 0.981225\ttraining's binary_logloss: 0.132762\n",
      "[6145]\ttraining's auc: 0.981228\ttraining's binary_logloss: 0.132757\n",
      "[6146]\ttraining's auc: 0.98123\ttraining's binary_logloss: 0.132755\n",
      "[6147]\ttraining's auc: 0.981242\ttraining's binary_logloss: 0.132741\n",
      "[6148]\ttraining's auc: 0.981246\ttraining's binary_logloss: 0.132736\n",
      "[6149]\ttraining's auc: 0.98125\ttraining's binary_logloss: 0.132733\n",
      "[6150]\ttraining's auc: 0.981251\ttraining's binary_logloss: 0.132729\n",
      "[6151]\ttraining's auc: 0.981258\ttraining's binary_logloss: 0.132716\n",
      "[6152]\ttraining's auc: 0.981264\ttraining's binary_logloss: 0.132705\n",
      "[6153]\ttraining's auc: 0.981267\ttraining's binary_logloss: 0.132695\n",
      "[6154]\ttraining's auc: 0.981272\ttraining's binary_logloss: 0.132687\n",
      "[6155]\ttraining's auc: 0.981276\ttraining's binary_logloss: 0.13268\n",
      "[6156]\ttraining's auc: 0.981282\ttraining's binary_logloss: 0.132669\n",
      "[6157]\ttraining's auc: 0.981292\ttraining's binary_logloss: 0.132657\n",
      "[6158]\ttraining's auc: 0.981303\ttraining's binary_logloss: 0.132646\n",
      "[6159]\ttraining's auc: 0.981308\ttraining's binary_logloss: 0.132634\n",
      "[6160]\ttraining's auc: 0.981319\ttraining's binary_logloss: 0.132618\n",
      "[6161]\ttraining's auc: 0.981327\ttraining's binary_logloss: 0.132606\n",
      "[6162]\ttraining's auc: 0.981335\ttraining's binary_logloss: 0.132594\n",
      "[6163]\ttraining's auc: 0.981341\ttraining's binary_logloss: 0.132582\n",
      "[6164]\ttraining's auc: 0.981349\ttraining's binary_logloss: 0.132569\n",
      "[6165]\ttraining's auc: 0.981356\ttraining's binary_logloss: 0.132558\n",
      "[6166]\ttraining's auc: 0.98137\ttraining's binary_logloss: 0.132544\n",
      "[6167]\ttraining's auc: 0.981381\ttraining's binary_logloss: 0.132532\n",
      "[6168]\ttraining's auc: 0.981385\ttraining's binary_logloss: 0.132521\n",
      "[6169]\ttraining's auc: 0.981396\ttraining's binary_logloss: 0.132506\n",
      "[6170]\ttraining's auc: 0.981406\ttraining's binary_logloss: 0.132492\n",
      "[6171]\ttraining's auc: 0.981407\ttraining's binary_logloss: 0.132491\n",
      "[6172]\ttraining's auc: 0.98141\ttraining's binary_logloss: 0.132486\n",
      "[6173]\ttraining's auc: 0.981419\ttraining's binary_logloss: 0.132474\n",
      "[6174]\ttraining's auc: 0.981425\ttraining's binary_logloss: 0.132464\n",
      "[6175]\ttraining's auc: 0.981435\ttraining's binary_logloss: 0.132451\n",
      "[6176]\ttraining's auc: 0.981435\ttraining's binary_logloss: 0.132449\n",
      "[6177]\ttraining's auc: 0.981438\ttraining's binary_logloss: 0.132443\n",
      "[6178]\ttraining's auc: 0.981444\ttraining's binary_logloss: 0.132433\n",
      "[6179]\ttraining's auc: 0.981452\ttraining's binary_logloss: 0.13242\n",
      "[6180]\ttraining's auc: 0.98146\ttraining's binary_logloss: 0.132408\n",
      "[6181]\ttraining's auc: 0.98146\ttraining's binary_logloss: 0.132407\n",
      "[6182]\ttraining's auc: 0.981469\ttraining's binary_logloss: 0.132395\n",
      "[6183]\ttraining's auc: 0.981474\ttraining's binary_logloss: 0.132383\n",
      "[6184]\ttraining's auc: 0.981483\ttraining's binary_logloss: 0.13237\n",
      "[6185]\ttraining's auc: 0.981492\ttraining's binary_logloss: 0.132355\n",
      "[6186]\ttraining's auc: 0.9815\ttraining's binary_logloss: 0.13234\n",
      "[6187]\ttraining's auc: 0.981507\ttraining's binary_logloss: 0.132328\n",
      "[6188]\ttraining's auc: 0.981516\ttraining's binary_logloss: 0.132313\n",
      "[6189]\ttraining's auc: 0.981524\ttraining's binary_logloss: 0.132302\n",
      "[6190]\ttraining's auc: 0.981529\ttraining's binary_logloss: 0.13229\n",
      "[6191]\ttraining's auc: 0.981533\ttraining's binary_logloss: 0.132285\n",
      "[6192]\ttraining's auc: 0.981541\ttraining's binary_logloss: 0.132273\n",
      "[6193]\ttraining's auc: 0.981547\ttraining's binary_logloss: 0.132261\n",
      "[6194]\ttraining's auc: 0.981555\ttraining's binary_logloss: 0.132248\n",
      "[6195]\ttraining's auc: 0.981562\ttraining's binary_logloss: 0.132238\n",
      "[6196]\ttraining's auc: 0.98157\ttraining's binary_logloss: 0.132225\n",
      "[6197]\ttraining's auc: 0.981581\ttraining's binary_logloss: 0.132211\n",
      "[6198]\ttraining's auc: 0.981591\ttraining's binary_logloss: 0.132199\n",
      "[6199]\ttraining's auc: 0.981599\ttraining's binary_logloss: 0.132187\n",
      "[6200]\ttraining's auc: 0.981602\ttraining's binary_logloss: 0.132184\n",
      "[6201]\ttraining's auc: 0.981608\ttraining's binary_logloss: 0.132173\n",
      "[6202]\ttraining's auc: 0.981616\ttraining's binary_logloss: 0.13216\n",
      "[6203]\ttraining's auc: 0.98162\ttraining's binary_logloss: 0.132152\n",
      "[6204]\ttraining's auc: 0.981629\ttraining's binary_logloss: 0.132138\n",
      "[6205]\ttraining's auc: 0.981639\ttraining's binary_logloss: 0.132123\n",
      "[6206]\ttraining's auc: 0.981642\ttraining's binary_logloss: 0.132118\n",
      "[6207]\ttraining's auc: 0.981647\ttraining's binary_logloss: 0.13211\n",
      "[6208]\ttraining's auc: 0.981653\ttraining's binary_logloss: 0.132102\n",
      "[6209]\ttraining's auc: 0.981657\ttraining's binary_logloss: 0.13209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6210]\ttraining's auc: 0.981669\ttraining's binary_logloss: 0.132077\n",
      "[6211]\ttraining's auc: 0.981679\ttraining's binary_logloss: 0.132063\n",
      "[6212]\ttraining's auc: 0.981689\ttraining's binary_logloss: 0.132051\n",
      "[6213]\ttraining's auc: 0.981698\ttraining's binary_logloss: 0.132038\n",
      "[6214]\ttraining's auc: 0.981698\ttraining's binary_logloss: 0.132036\n",
      "[6215]\ttraining's auc: 0.981711\ttraining's binary_logloss: 0.132025\n",
      "[6216]\ttraining's auc: 0.981713\ttraining's binary_logloss: 0.13202\n",
      "[6217]\ttraining's auc: 0.981722\ttraining's binary_logloss: 0.132007\n",
      "[6218]\ttraining's auc: 0.981723\ttraining's binary_logloss: 0.132003\n",
      "[6219]\ttraining's auc: 0.981729\ttraining's binary_logloss: 0.131992\n",
      "[6220]\ttraining's auc: 0.981736\ttraining's binary_logloss: 0.131978\n",
      "[6221]\ttraining's auc: 0.981739\ttraining's binary_logloss: 0.131968\n",
      "[6222]\ttraining's auc: 0.981749\ttraining's binary_logloss: 0.131956\n",
      "[6223]\ttraining's auc: 0.981763\ttraining's binary_logloss: 0.131942\n",
      "[6224]\ttraining's auc: 0.981775\ttraining's binary_logloss: 0.131927\n",
      "[6225]\ttraining's auc: 0.981782\ttraining's binary_logloss: 0.131917\n",
      "[6226]\ttraining's auc: 0.981792\ttraining's binary_logloss: 0.131904\n",
      "[6227]\ttraining's auc: 0.981802\ttraining's binary_logloss: 0.131891\n",
      "[6228]\ttraining's auc: 0.981815\ttraining's binary_logloss: 0.131877\n",
      "[6229]\ttraining's auc: 0.981827\ttraining's binary_logloss: 0.131863\n",
      "[6230]\ttraining's auc: 0.981839\ttraining's binary_logloss: 0.13185\n",
      "[6231]\ttraining's auc: 0.981846\ttraining's binary_logloss: 0.13184\n",
      "[6232]\ttraining's auc: 0.981852\ttraining's binary_logloss: 0.131831\n",
      "[6233]\ttraining's auc: 0.981856\ttraining's binary_logloss: 0.131823\n",
      "[6234]\ttraining's auc: 0.981864\ttraining's binary_logloss: 0.131811\n",
      "[6235]\ttraining's auc: 0.98187\ttraining's binary_logloss: 0.1318\n",
      "[6236]\ttraining's auc: 0.981877\ttraining's binary_logloss: 0.131788\n",
      "[6237]\ttraining's auc: 0.981888\ttraining's binary_logloss: 0.131774\n",
      "[6238]\ttraining's auc: 0.981893\ttraining's binary_logloss: 0.131763\n",
      "[6239]\ttraining's auc: 0.981901\ttraining's binary_logloss: 0.131749\n",
      "[6240]\ttraining's auc: 0.981909\ttraining's binary_logloss: 0.131739\n",
      "[6241]\ttraining's auc: 0.981919\ttraining's binary_logloss: 0.131724\n",
      "[6242]\ttraining's auc: 0.981925\ttraining's binary_logloss: 0.131715\n",
      "[6243]\ttraining's auc: 0.981938\ttraining's binary_logloss: 0.1317\n",
      "[6244]\ttraining's auc: 0.981944\ttraining's binary_logloss: 0.131692\n",
      "[6245]\ttraining's auc: 0.981951\ttraining's binary_logloss: 0.131678\n",
      "[6246]\ttraining's auc: 0.981959\ttraining's binary_logloss: 0.131665\n",
      "[6247]\ttraining's auc: 0.981967\ttraining's binary_logloss: 0.131653\n",
      "[6248]\ttraining's auc: 0.981976\ttraining's binary_logloss: 0.131641\n",
      "[6249]\ttraining's auc: 0.981986\ttraining's binary_logloss: 0.131627\n",
      "[6250]\ttraining's auc: 0.981995\ttraining's binary_logloss: 0.131613\n",
      "[6251]\ttraining's auc: 0.982007\ttraining's binary_logloss: 0.131598\n",
      "[6252]\ttraining's auc: 0.982012\ttraining's binary_logloss: 0.13159\n",
      "[6253]\ttraining's auc: 0.982018\ttraining's binary_logloss: 0.131579\n",
      "[6254]\ttraining's auc: 0.982032\ttraining's binary_logloss: 0.131567\n",
      "[6255]\ttraining's auc: 0.982042\ttraining's binary_logloss: 0.131554\n",
      "[6256]\ttraining's auc: 0.982048\ttraining's binary_logloss: 0.131543\n",
      "[6257]\ttraining's auc: 0.982056\ttraining's binary_logloss: 0.13153\n",
      "[6258]\ttraining's auc: 0.982061\ttraining's binary_logloss: 0.131518\n",
      "[6259]\ttraining's auc: 0.982072\ttraining's binary_logloss: 0.131503\n",
      "[6260]\ttraining's auc: 0.98208\ttraining's binary_logloss: 0.131492\n",
      "[6261]\ttraining's auc: 0.982085\ttraining's binary_logloss: 0.13148\n",
      "[6262]\ttraining's auc: 0.982093\ttraining's binary_logloss: 0.131468\n",
      "[6263]\ttraining's auc: 0.982098\ttraining's binary_logloss: 0.131461\n",
      "[6264]\ttraining's auc: 0.982099\ttraining's binary_logloss: 0.131459\n",
      "[6265]\ttraining's auc: 0.982108\ttraining's binary_logloss: 0.131445\n",
      "[6266]\ttraining's auc: 0.982116\ttraining's binary_logloss: 0.13143\n",
      "[6267]\ttraining's auc: 0.982125\ttraining's binary_logloss: 0.131418\n",
      "[6268]\ttraining's auc: 0.982133\ttraining's binary_logloss: 0.131407\n",
      "[6269]\ttraining's auc: 0.982139\ttraining's binary_logloss: 0.131394\n",
      "[6270]\ttraining's auc: 0.982147\ttraining's binary_logloss: 0.131382\n",
      "[6271]\ttraining's auc: 0.982154\ttraining's binary_logloss: 0.13137\n",
      "[6272]\ttraining's auc: 0.98216\ttraining's binary_logloss: 0.131359\n",
      "[6273]\ttraining's auc: 0.982167\ttraining's binary_logloss: 0.131347\n",
      "[6274]\ttraining's auc: 0.982174\ttraining's binary_logloss: 0.131336\n",
      "[6275]\ttraining's auc: 0.982181\ttraining's binary_logloss: 0.131327\n",
      "[6276]\ttraining's auc: 0.982183\ttraining's binary_logloss: 0.131323\n",
      "[6277]\ttraining's auc: 0.98219\ttraining's binary_logloss: 0.131311\n",
      "[6278]\ttraining's auc: 0.982191\ttraining's binary_logloss: 0.131304\n",
      "[6279]\ttraining's auc: 0.9822\ttraining's binary_logloss: 0.131293\n",
      "[6280]\ttraining's auc: 0.982209\ttraining's binary_logloss: 0.13128\n",
      "[6281]\ttraining's auc: 0.982215\ttraining's binary_logloss: 0.131269\n",
      "[6282]\ttraining's auc: 0.982217\ttraining's binary_logloss: 0.131265\n",
      "[6283]\ttraining's auc: 0.982223\ttraining's binary_logloss: 0.131254\n",
      "[6284]\ttraining's auc: 0.982225\ttraining's binary_logloss: 0.131253\n",
      "[6285]\ttraining's auc: 0.982225\ttraining's binary_logloss: 0.13125\n",
      "[6286]\ttraining's auc: 0.982236\ttraining's binary_logloss: 0.131238\n",
      "[6287]\ttraining's auc: 0.982237\ttraining's binary_logloss: 0.131236\n",
      "[6288]\ttraining's auc: 0.982244\ttraining's binary_logloss: 0.131223\n",
      "[6289]\ttraining's auc: 0.982254\ttraining's binary_logloss: 0.131211\n",
      "[6290]\ttraining's auc: 0.982264\ttraining's binary_logloss: 0.131198\n",
      "[6291]\ttraining's auc: 0.982269\ttraining's binary_logloss: 0.131191\n",
      "[6292]\ttraining's auc: 0.982282\ttraining's binary_logloss: 0.131178\n",
      "[6293]\ttraining's auc: 0.982294\ttraining's binary_logloss: 0.131166\n",
      "[6294]\ttraining's auc: 0.982295\ttraining's binary_logloss: 0.131162\n",
      "[6295]\ttraining's auc: 0.982298\ttraining's binary_logloss: 0.131157\n",
      "[6296]\ttraining's auc: 0.982306\ttraining's binary_logloss: 0.131143\n",
      "[6297]\ttraining's auc: 0.982315\ttraining's binary_logloss: 0.13113\n",
      "[6298]\ttraining's auc: 0.982322\ttraining's binary_logloss: 0.131117\n",
      "[6299]\ttraining's auc: 0.982333\ttraining's binary_logloss: 0.131102\n",
      "[6300]\ttraining's auc: 0.982339\ttraining's binary_logloss: 0.131093\n",
      "[6301]\ttraining's auc: 0.982348\ttraining's binary_logloss: 0.131082\n",
      "[6302]\ttraining's auc: 0.982354\ttraining's binary_logloss: 0.131072\n",
      "[6303]\ttraining's auc: 0.982364\ttraining's binary_logloss: 0.131058\n",
      "[6304]\ttraining's auc: 0.982372\ttraining's binary_logloss: 0.131046\n",
      "[6305]\ttraining's auc: 0.98238\ttraining's binary_logloss: 0.131034\n",
      "[6306]\ttraining's auc: 0.982392\ttraining's binary_logloss: 0.13102\n",
      "[6307]\ttraining's auc: 0.982405\ttraining's binary_logloss: 0.131009\n",
      "[6308]\ttraining's auc: 0.982413\ttraining's binary_logloss: 0.130996\n",
      "[6309]\ttraining's auc: 0.982418\ttraining's binary_logloss: 0.130983\n",
      "[6310]\ttraining's auc: 0.982424\ttraining's binary_logloss: 0.130971\n",
      "[6311]\ttraining's auc: 0.982429\ttraining's binary_logloss: 0.130961\n",
      "[6312]\ttraining's auc: 0.982433\ttraining's binary_logloss: 0.130952\n",
      "[6313]\ttraining's auc: 0.98244\ttraining's binary_logloss: 0.13094\n",
      "[6314]\ttraining's auc: 0.982448\ttraining's binary_logloss: 0.130928\n",
      "[6315]\ttraining's auc: 0.982456\ttraining's binary_logloss: 0.130918\n",
      "[6316]\ttraining's auc: 0.982464\ttraining's binary_logloss: 0.130907\n",
      "[6317]\ttraining's auc: 0.982469\ttraining's binary_logloss: 0.1309\n",
      "[6318]\ttraining's auc: 0.982477\ttraining's binary_logloss: 0.130887\n",
      "[6319]\ttraining's auc: 0.982485\ttraining's binary_logloss: 0.130873\n",
      "[6320]\ttraining's auc: 0.982492\ttraining's binary_logloss: 0.130861\n",
      "[6321]\ttraining's auc: 0.982495\ttraining's binary_logloss: 0.130854\n",
      "[6322]\ttraining's auc: 0.982502\ttraining's binary_logloss: 0.130842\n",
      "[6323]\ttraining's auc: 0.982509\ttraining's binary_logloss: 0.130829\n",
      "[6324]\ttraining's auc: 0.982516\ttraining's binary_logloss: 0.130818\n",
      "[6325]\ttraining's auc: 0.982523\ttraining's binary_logloss: 0.130806\n",
      "[6326]\ttraining's auc: 0.982529\ttraining's binary_logloss: 0.130795\n",
      "[6327]\ttraining's auc: 0.982534\ttraining's binary_logloss: 0.130786\n",
      "[6328]\ttraining's auc: 0.982543\ttraining's binary_logloss: 0.130771\n",
      "[6329]\ttraining's auc: 0.982549\ttraining's binary_logloss: 0.130762\n",
      "[6330]\ttraining's auc: 0.982556\ttraining's binary_logloss: 0.130749\n",
      "[6331]\ttraining's auc: 0.982563\ttraining's binary_logloss: 0.13074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6332]\ttraining's auc: 0.982571\ttraining's binary_logloss: 0.130729\n",
      "[6333]\ttraining's auc: 0.982576\ttraining's binary_logloss: 0.130717\n",
      "[6334]\ttraining's auc: 0.982577\ttraining's binary_logloss: 0.13071\n",
      "[6335]\ttraining's auc: 0.982587\ttraining's binary_logloss: 0.130698\n",
      "[6336]\ttraining's auc: 0.982594\ttraining's binary_logloss: 0.130686\n",
      "[6337]\ttraining's auc: 0.982602\ttraining's binary_logloss: 0.130674\n",
      "[6338]\ttraining's auc: 0.982611\ttraining's binary_logloss: 0.13066\n",
      "[6339]\ttraining's auc: 0.982616\ttraining's binary_logloss: 0.13065\n",
      "[6340]\ttraining's auc: 0.982625\ttraining's binary_logloss: 0.130638\n",
      "[6341]\ttraining's auc: 0.982632\ttraining's binary_logloss: 0.130627\n",
      "[6342]\ttraining's auc: 0.982639\ttraining's binary_logloss: 0.130614\n",
      "[6343]\ttraining's auc: 0.982644\ttraining's binary_logloss: 0.130604\n",
      "[6344]\ttraining's auc: 0.982653\ttraining's binary_logloss: 0.130592\n",
      "[6345]\ttraining's auc: 0.982659\ttraining's binary_logloss: 0.130578\n",
      "[6346]\ttraining's auc: 0.98267\ttraining's binary_logloss: 0.130565\n",
      "[6347]\ttraining's auc: 0.982677\ttraining's binary_logloss: 0.130553\n",
      "[6348]\ttraining's auc: 0.98269\ttraining's binary_logloss: 0.130538\n",
      "[6349]\ttraining's auc: 0.982698\ttraining's binary_logloss: 0.130524\n",
      "[6350]\ttraining's auc: 0.982701\ttraining's binary_logloss: 0.130515\n",
      "[6351]\ttraining's auc: 0.98271\ttraining's binary_logloss: 0.130502\n",
      "[6352]\ttraining's auc: 0.982716\ttraining's binary_logloss: 0.130489\n",
      "[6353]\ttraining's auc: 0.982719\ttraining's binary_logloss: 0.130483\n",
      "[6354]\ttraining's auc: 0.982725\ttraining's binary_logloss: 0.130472\n",
      "[6355]\ttraining's auc: 0.982733\ttraining's binary_logloss: 0.13046\n",
      "[6356]\ttraining's auc: 0.982734\ttraining's binary_logloss: 0.130457\n",
      "[6357]\ttraining's auc: 0.982738\ttraining's binary_logloss: 0.130452\n",
      "[6358]\ttraining's auc: 0.982741\ttraining's binary_logloss: 0.130448\n",
      "[6359]\ttraining's auc: 0.982742\ttraining's binary_logloss: 0.130447\n",
      "[6360]\ttraining's auc: 0.982748\ttraining's binary_logloss: 0.130435\n",
      "[6361]\ttraining's auc: 0.982753\ttraining's binary_logloss: 0.130423\n",
      "[6362]\ttraining's auc: 0.982764\ttraining's binary_logloss: 0.130408\n",
      "[6363]\ttraining's auc: 0.982767\ttraining's binary_logloss: 0.130401\n",
      "[6364]\ttraining's auc: 0.982773\ttraining's binary_logloss: 0.130389\n",
      "[6365]\ttraining's auc: 0.98278\ttraining's binary_logloss: 0.130378\n",
      "[6366]\ttraining's auc: 0.982786\ttraining's binary_logloss: 0.13037\n",
      "[6367]\ttraining's auc: 0.982797\ttraining's binary_logloss: 0.130357\n",
      "[6368]\ttraining's auc: 0.982805\ttraining's binary_logloss: 0.130343\n",
      "[6369]\ttraining's auc: 0.98281\ttraining's binary_logloss: 0.130332\n",
      "[6370]\ttraining's auc: 0.982815\ttraining's binary_logloss: 0.130321\n",
      "[6371]\ttraining's auc: 0.982824\ttraining's binary_logloss: 0.130308\n",
      "[6372]\ttraining's auc: 0.98283\ttraining's binary_logloss: 0.130297\n",
      "[6373]\ttraining's auc: 0.982837\ttraining's binary_logloss: 0.130285\n",
      "[6374]\ttraining's auc: 0.982848\ttraining's binary_logloss: 0.13027\n",
      "[6375]\ttraining's auc: 0.98285\ttraining's binary_logloss: 0.130267\n",
      "[6376]\ttraining's auc: 0.982856\ttraining's binary_logloss: 0.130255\n",
      "[6377]\ttraining's auc: 0.982867\ttraining's binary_logloss: 0.130243\n",
      "[6378]\ttraining's auc: 0.982874\ttraining's binary_logloss: 0.130232\n",
      "[6379]\ttraining's auc: 0.982883\ttraining's binary_logloss: 0.130219\n",
      "[6380]\ttraining's auc: 0.982889\ttraining's binary_logloss: 0.130206\n",
      "[6381]\ttraining's auc: 0.98289\ttraining's binary_logloss: 0.130204\n",
      "[6382]\ttraining's auc: 0.982896\ttraining's binary_logloss: 0.130193\n",
      "[6383]\ttraining's auc: 0.982907\ttraining's binary_logloss: 0.130181\n",
      "[6384]\ttraining's auc: 0.982909\ttraining's binary_logloss: 0.130175\n",
      "[6385]\ttraining's auc: 0.982917\ttraining's binary_logloss: 0.130163\n",
      "[6386]\ttraining's auc: 0.982924\ttraining's binary_logloss: 0.130151\n",
      "[6387]\ttraining's auc: 0.982929\ttraining's binary_logloss: 0.13014\n",
      "[6388]\ttraining's auc: 0.982936\ttraining's binary_logloss: 0.130127\n",
      "[6389]\ttraining's auc: 0.982941\ttraining's binary_logloss: 0.130115\n",
      "[6390]\ttraining's auc: 0.982948\ttraining's binary_logloss: 0.130104\n",
      "[6391]\ttraining's auc: 0.982959\ttraining's binary_logloss: 0.130092\n",
      "[6392]\ttraining's auc: 0.982967\ttraining's binary_logloss: 0.13008\n",
      "[6393]\ttraining's auc: 0.982974\ttraining's binary_logloss: 0.130069\n",
      "[6394]\ttraining's auc: 0.982975\ttraining's binary_logloss: 0.130067\n",
      "[6395]\ttraining's auc: 0.982983\ttraining's binary_logloss: 0.130055\n",
      "[6396]\ttraining's auc: 0.98299\ttraining's binary_logloss: 0.130042\n",
      "[6397]\ttraining's auc: 0.983\ttraining's binary_logloss: 0.130026\n",
      "[6398]\ttraining's auc: 0.983006\ttraining's binary_logloss: 0.130015\n",
      "[6399]\ttraining's auc: 0.983013\ttraining's binary_logloss: 0.130004\n",
      "[6400]\ttraining's auc: 0.98302\ttraining's binary_logloss: 0.129991\n",
      "[6401]\ttraining's auc: 0.98303\ttraining's binary_logloss: 0.129979\n",
      "[6402]\ttraining's auc: 0.983036\ttraining's binary_logloss: 0.129967\n",
      "[6403]\ttraining's auc: 0.98304\ttraining's binary_logloss: 0.129962\n",
      "[6404]\ttraining's auc: 0.983044\ttraining's binary_logloss: 0.12995\n",
      "[6405]\ttraining's auc: 0.983056\ttraining's binary_logloss: 0.129936\n",
      "[6406]\ttraining's auc: 0.983066\ttraining's binary_logloss: 0.129925\n",
      "[6407]\ttraining's auc: 0.983074\ttraining's binary_logloss: 0.129914\n",
      "[6408]\ttraining's auc: 0.98308\ttraining's binary_logloss: 0.129908\n",
      "[6409]\ttraining's auc: 0.983091\ttraining's binary_logloss: 0.129894\n",
      "[6410]\ttraining's auc: 0.983099\ttraining's binary_logloss: 0.129883\n",
      "[6411]\ttraining's auc: 0.983107\ttraining's binary_logloss: 0.129872\n",
      "[6412]\ttraining's auc: 0.983113\ttraining's binary_logloss: 0.129859\n",
      "[6413]\ttraining's auc: 0.983121\ttraining's binary_logloss: 0.129847\n",
      "[6414]\ttraining's auc: 0.983124\ttraining's binary_logloss: 0.12984\n",
      "[6415]\ttraining's auc: 0.983131\ttraining's binary_logloss: 0.12983\n",
      "[6416]\ttraining's auc: 0.98314\ttraining's binary_logloss: 0.129816\n",
      "[6417]\ttraining's auc: 0.983148\ttraining's binary_logloss: 0.129805\n",
      "[6418]\ttraining's auc: 0.983152\ttraining's binary_logloss: 0.129795\n",
      "[6419]\ttraining's auc: 0.983152\ttraining's binary_logloss: 0.12979\n",
      "[6420]\ttraining's auc: 0.98316\ttraining's binary_logloss: 0.129777\n",
      "[6421]\ttraining's auc: 0.983168\ttraining's binary_logloss: 0.129767\n",
      "[6422]\ttraining's auc: 0.983173\ttraining's binary_logloss: 0.129757\n",
      "[6423]\ttraining's auc: 0.983179\ttraining's binary_logloss: 0.129744\n",
      "[6424]\ttraining's auc: 0.983186\ttraining's binary_logloss: 0.129731\n",
      "[6425]\ttraining's auc: 0.983187\ttraining's binary_logloss: 0.129727\n",
      "[6426]\ttraining's auc: 0.983196\ttraining's binary_logloss: 0.129714\n",
      "[6427]\ttraining's auc: 0.983207\ttraining's binary_logloss: 0.129702\n",
      "[6428]\ttraining's auc: 0.983208\ttraining's binary_logloss: 0.129698\n",
      "[6429]\ttraining's auc: 0.983209\ttraining's binary_logloss: 0.129696\n",
      "[6430]\ttraining's auc: 0.98322\ttraining's binary_logloss: 0.129683\n",
      "[6431]\ttraining's auc: 0.983225\ttraining's binary_logloss: 0.129675\n",
      "[6432]\ttraining's auc: 0.983234\ttraining's binary_logloss: 0.129662\n",
      "[6433]\ttraining's auc: 0.98324\ttraining's binary_logloss: 0.129649\n",
      "[6434]\ttraining's auc: 0.983242\ttraining's binary_logloss: 0.129646\n",
      "[6435]\ttraining's auc: 0.983252\ttraining's binary_logloss: 0.129633\n",
      "[6436]\ttraining's auc: 0.983259\ttraining's binary_logloss: 0.129619\n",
      "[6437]\ttraining's auc: 0.983266\ttraining's binary_logloss: 0.129606\n",
      "[6438]\ttraining's auc: 0.983276\ttraining's binary_logloss: 0.129593\n",
      "[6439]\ttraining's auc: 0.983285\ttraining's binary_logloss: 0.129581\n",
      "[6440]\ttraining's auc: 0.983292\ttraining's binary_logloss: 0.12957\n",
      "[6441]\ttraining's auc: 0.9833\ttraining's binary_logloss: 0.129559\n",
      "[6442]\ttraining's auc: 0.983309\ttraining's binary_logloss: 0.129546\n",
      "[6443]\ttraining's auc: 0.983319\ttraining's binary_logloss: 0.129533\n",
      "[6444]\ttraining's auc: 0.983324\ttraining's binary_logloss: 0.129522\n",
      "[6445]\ttraining's auc: 0.983333\ttraining's binary_logloss: 0.129511\n",
      "[6446]\ttraining's auc: 0.983335\ttraining's binary_logloss: 0.129506\n",
      "[6447]\ttraining's auc: 0.983341\ttraining's binary_logloss: 0.129494\n",
      "[6448]\ttraining's auc: 0.983345\ttraining's binary_logloss: 0.129488\n",
      "[6449]\ttraining's auc: 0.983355\ttraining's binary_logloss: 0.129474\n",
      "[6450]\ttraining's auc: 0.983365\ttraining's binary_logloss: 0.12946\n",
      "[6451]\ttraining's auc: 0.983369\ttraining's binary_logloss: 0.129455\n",
      "[6452]\ttraining's auc: 0.983373\ttraining's binary_logloss: 0.129443\n",
      "[6453]\ttraining's auc: 0.983376\ttraining's binary_logloss: 0.129438\n",
      "[6454]\ttraining's auc: 0.983383\ttraining's binary_logloss: 0.129428\n",
      "[6455]\ttraining's auc: 0.983388\ttraining's binary_logloss: 0.129418\n",
      "[6456]\ttraining's auc: 0.983393\ttraining's binary_logloss: 0.129406\n",
      "[6457]\ttraining's auc: 0.983402\ttraining's binary_logloss: 0.129394\n",
      "[6458]\ttraining's auc: 0.983403\ttraining's binary_logloss: 0.129392\n",
      "[6459]\ttraining's auc: 0.98341\ttraining's binary_logloss: 0.12938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6460]\ttraining's auc: 0.983413\ttraining's binary_logloss: 0.129373\n",
      "[6461]\ttraining's auc: 0.983414\ttraining's binary_logloss: 0.129371\n",
      "[6462]\ttraining's auc: 0.983422\ttraining's binary_logloss: 0.129361\n",
      "[6463]\ttraining's auc: 0.983429\ttraining's binary_logloss: 0.129348\n",
      "[6464]\ttraining's auc: 0.983435\ttraining's binary_logloss: 0.129336\n",
      "[6465]\ttraining's auc: 0.983442\ttraining's binary_logloss: 0.129325\n",
      "[6466]\ttraining's auc: 0.983443\ttraining's binary_logloss: 0.129323\n",
      "[6467]\ttraining's auc: 0.983453\ttraining's binary_logloss: 0.12931\n",
      "[6468]\ttraining's auc: 0.98346\ttraining's binary_logloss: 0.129298\n",
      "[6469]\ttraining's auc: 0.983466\ttraining's binary_logloss: 0.129285\n",
      "[6470]\ttraining's auc: 0.983471\ttraining's binary_logloss: 0.129273\n",
      "[6471]\ttraining's auc: 0.983474\ttraining's binary_logloss: 0.129266\n",
      "[6472]\ttraining's auc: 0.983481\ttraining's binary_logloss: 0.129256\n",
      "[6473]\ttraining's auc: 0.983492\ttraining's binary_logloss: 0.129242\n",
      "[6474]\ttraining's auc: 0.983501\ttraining's binary_logloss: 0.12923\n",
      "[6475]\ttraining's auc: 0.98351\ttraining's binary_logloss: 0.129216\n",
      "[6476]\ttraining's auc: 0.983512\ttraining's binary_logloss: 0.129213\n",
      "[6477]\ttraining's auc: 0.983522\ttraining's binary_logloss: 0.1292\n",
      "[6478]\ttraining's auc: 0.98353\ttraining's binary_logloss: 0.129188\n",
      "[6479]\ttraining's auc: 0.983539\ttraining's binary_logloss: 0.129176\n",
      "[6480]\ttraining's auc: 0.983542\ttraining's binary_logloss: 0.129171\n",
      "[6481]\ttraining's auc: 0.98355\ttraining's binary_logloss: 0.129159\n",
      "[6482]\ttraining's auc: 0.983557\ttraining's binary_logloss: 0.129146\n",
      "[6483]\ttraining's auc: 0.983565\ttraining's binary_logloss: 0.129133\n",
      "[6484]\ttraining's auc: 0.983569\ttraining's binary_logloss: 0.129127\n",
      "[6485]\ttraining's auc: 0.983579\ttraining's binary_logloss: 0.129116\n",
      "[6486]\ttraining's auc: 0.983586\ttraining's binary_logloss: 0.129106\n",
      "[6487]\ttraining's auc: 0.983591\ttraining's binary_logloss: 0.129095\n",
      "[6488]\ttraining's auc: 0.983599\ttraining's binary_logloss: 0.129084\n",
      "[6489]\ttraining's auc: 0.983605\ttraining's binary_logloss: 0.129075\n",
      "[6490]\ttraining's auc: 0.983615\ttraining's binary_logloss: 0.129062\n",
      "[6491]\ttraining's auc: 0.983626\ttraining's binary_logloss: 0.129048\n",
      "[6492]\ttraining's auc: 0.983632\ttraining's binary_logloss: 0.129037\n",
      "[6493]\ttraining's auc: 0.98364\ttraining's binary_logloss: 0.129027\n",
      "[6494]\ttraining's auc: 0.983644\ttraining's binary_logloss: 0.12902\n",
      "[6495]\ttraining's auc: 0.983656\ttraining's binary_logloss: 0.129007\n",
      "[6496]\ttraining's auc: 0.983661\ttraining's binary_logloss: 0.128997\n",
      "[6497]\ttraining's auc: 0.983669\ttraining's binary_logloss: 0.128986\n",
      "[6498]\ttraining's auc: 0.983677\ttraining's binary_logloss: 0.128973\n",
      "[6499]\ttraining's auc: 0.983686\ttraining's binary_logloss: 0.128961\n",
      "[6500]\ttraining's auc: 0.983694\ttraining's binary_logloss: 0.128951\n",
      "[6501]\ttraining's auc: 0.983699\ttraining's binary_logloss: 0.128939\n",
      "[6502]\ttraining's auc: 0.983705\ttraining's binary_logloss: 0.128929\n",
      "[6503]\ttraining's auc: 0.983716\ttraining's binary_logloss: 0.128916\n",
      "[6504]\ttraining's auc: 0.98372\ttraining's binary_logloss: 0.128904\n",
      "[6505]\ttraining's auc: 0.98373\ttraining's binary_logloss: 0.12889\n",
      "[6506]\ttraining's auc: 0.983738\ttraining's binary_logloss: 0.128879\n",
      "[6507]\ttraining's auc: 0.983739\ttraining's binary_logloss: 0.128876\n",
      "[6508]\ttraining's auc: 0.983746\ttraining's binary_logloss: 0.128862\n",
      "[6509]\ttraining's auc: 0.983752\ttraining's binary_logloss: 0.12885\n",
      "[6510]\ttraining's auc: 0.983757\ttraining's binary_logloss: 0.128837\n",
      "[6511]\ttraining's auc: 0.983765\ttraining's binary_logloss: 0.128825\n",
      "[6512]\ttraining's auc: 0.983772\ttraining's binary_logloss: 0.128812\n",
      "[6513]\ttraining's auc: 0.983777\ttraining's binary_logloss: 0.128806\n",
      "[6514]\ttraining's auc: 0.983784\ttraining's binary_logloss: 0.128795\n",
      "[6515]\ttraining's auc: 0.98379\ttraining's binary_logloss: 0.128782\n",
      "[6516]\ttraining's auc: 0.983796\ttraining's binary_logloss: 0.128767\n",
      "[6517]\ttraining's auc: 0.983803\ttraining's binary_logloss: 0.128756\n",
      "[6518]\ttraining's auc: 0.983809\ttraining's binary_logloss: 0.128745\n",
      "[6519]\ttraining's auc: 0.983817\ttraining's binary_logloss: 0.128736\n",
      "[6520]\ttraining's auc: 0.983824\ttraining's binary_logloss: 0.128723\n",
      "[6521]\ttraining's auc: 0.98383\ttraining's binary_logloss: 0.128712\n",
      "[6522]\ttraining's auc: 0.983838\ttraining's binary_logloss: 0.128701\n",
      "[6523]\ttraining's auc: 0.983842\ttraining's binary_logloss: 0.128688\n",
      "[6524]\ttraining's auc: 0.983851\ttraining's binary_logloss: 0.128675\n",
      "[6525]\ttraining's auc: 0.983857\ttraining's binary_logloss: 0.128665\n",
      "[6526]\ttraining's auc: 0.983862\ttraining's binary_logloss: 0.128653\n",
      "[6527]\ttraining's auc: 0.983871\ttraining's binary_logloss: 0.128639\n",
      "[6528]\ttraining's auc: 0.983879\ttraining's binary_logloss: 0.128629\n",
      "[6529]\ttraining's auc: 0.983886\ttraining's binary_logloss: 0.128617\n",
      "[6530]\ttraining's auc: 0.983894\ttraining's binary_logloss: 0.128604\n",
      "[6531]\ttraining's auc: 0.983899\ttraining's binary_logloss: 0.128593\n",
      "[6532]\ttraining's auc: 0.983901\ttraining's binary_logloss: 0.12859\n",
      "[6533]\ttraining's auc: 0.983908\ttraining's binary_logloss: 0.128577\n",
      "[6534]\ttraining's auc: 0.983913\ttraining's binary_logloss: 0.128572\n",
      "[6535]\ttraining's auc: 0.98392\ttraining's binary_logloss: 0.12856\n",
      "[6536]\ttraining's auc: 0.983932\ttraining's binary_logloss: 0.128548\n",
      "[6537]\ttraining's auc: 0.983937\ttraining's binary_logloss: 0.128537\n",
      "[6538]\ttraining's auc: 0.983944\ttraining's binary_logloss: 0.128524\n",
      "[6539]\ttraining's auc: 0.983951\ttraining's binary_logloss: 0.128513\n",
      "[6540]\ttraining's auc: 0.983959\ttraining's binary_logloss: 0.128502\n",
      "[6541]\ttraining's auc: 0.983968\ttraining's binary_logloss: 0.12849\n",
      "[6542]\ttraining's auc: 0.983975\ttraining's binary_logloss: 0.128479\n",
      "[6543]\ttraining's auc: 0.983976\ttraining's binary_logloss: 0.128476\n",
      "[6544]\ttraining's auc: 0.983979\ttraining's binary_logloss: 0.128468\n",
      "[6545]\ttraining's auc: 0.983984\ttraining's binary_logloss: 0.128458\n",
      "[6546]\ttraining's auc: 0.983989\ttraining's binary_logloss: 0.128447\n",
      "[6547]\ttraining's auc: 0.98399\ttraining's binary_logloss: 0.128445\n",
      "[6548]\ttraining's auc: 0.983997\ttraining's binary_logloss: 0.128432\n",
      "[6549]\ttraining's auc: 0.984002\ttraining's binary_logloss: 0.128423\n",
      "[6550]\ttraining's auc: 0.98401\ttraining's binary_logloss: 0.12841\n",
      "[6551]\ttraining's auc: 0.98402\ttraining's binary_logloss: 0.128398\n",
      "[6552]\ttraining's auc: 0.984027\ttraining's binary_logloss: 0.128386\n",
      "[6553]\ttraining's auc: 0.984041\ttraining's binary_logloss: 0.128373\n",
      "[6554]\ttraining's auc: 0.984048\ttraining's binary_logloss: 0.12836\n",
      "[6555]\ttraining's auc: 0.984057\ttraining's binary_logloss: 0.128348\n",
      "[6556]\ttraining's auc: 0.984064\ttraining's binary_logloss: 0.128338\n",
      "[6557]\ttraining's auc: 0.984072\ttraining's binary_logloss: 0.128325\n",
      "[6558]\ttraining's auc: 0.984073\ttraining's binary_logloss: 0.128322\n",
      "[6559]\ttraining's auc: 0.984076\ttraining's binary_logloss: 0.128314\n",
      "[6560]\ttraining's auc: 0.984081\ttraining's binary_logloss: 0.128303\n",
      "[6561]\ttraining's auc: 0.984089\ttraining's binary_logloss: 0.128292\n",
      "[6562]\ttraining's auc: 0.984092\ttraining's binary_logloss: 0.128285\n",
      "[6563]\ttraining's auc: 0.984093\ttraining's binary_logloss: 0.128284\n",
      "[6564]\ttraining's auc: 0.9841\ttraining's binary_logloss: 0.128272\n",
      "[6565]\ttraining's auc: 0.98411\ttraining's binary_logloss: 0.128259\n",
      "[6566]\ttraining's auc: 0.984117\ttraining's binary_logloss: 0.128252\n",
      "[6567]\ttraining's auc: 0.984126\ttraining's binary_logloss: 0.128238\n",
      "[6568]\ttraining's auc: 0.984133\ttraining's binary_logloss: 0.128225\n",
      "[6569]\ttraining's auc: 0.984137\ttraining's binary_logloss: 0.128213\n",
      "[6570]\ttraining's auc: 0.984144\ttraining's binary_logloss: 0.128201\n",
      "[6571]\ttraining's auc: 0.984152\ttraining's binary_logloss: 0.128188\n",
      "[6572]\ttraining's auc: 0.984158\ttraining's binary_logloss: 0.128176\n",
      "[6573]\ttraining's auc: 0.984163\ttraining's binary_logloss: 0.128168\n",
      "[6574]\ttraining's auc: 0.984177\ttraining's binary_logloss: 0.128155\n",
      "[6575]\ttraining's auc: 0.984185\ttraining's binary_logloss: 0.128142\n",
      "[6576]\ttraining's auc: 0.984194\ttraining's binary_logloss: 0.128131\n",
      "[6577]\ttraining's auc: 0.9842\ttraining's binary_logloss: 0.128116\n",
      "[6578]\ttraining's auc: 0.984206\ttraining's binary_logloss: 0.128103\n",
      "[6579]\ttraining's auc: 0.984212\ttraining's binary_logloss: 0.128091\n",
      "[6580]\ttraining's auc: 0.984219\ttraining's binary_logloss: 0.12808\n",
      "[6581]\ttraining's auc: 0.984222\ttraining's binary_logloss: 0.128077\n",
      "[6582]\ttraining's auc: 0.984229\ttraining's binary_logloss: 0.128065\n",
      "[6583]\ttraining's auc: 0.984236\ttraining's binary_logloss: 0.128054\n",
      "[6584]\ttraining's auc: 0.984244\ttraining's binary_logloss: 0.128044\n",
      "[6585]\ttraining's auc: 0.98425\ttraining's binary_logloss: 0.128031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6586]\ttraining's auc: 0.98426\ttraining's binary_logloss: 0.128021\n",
      "[6587]\ttraining's auc: 0.984264\ttraining's binary_logloss: 0.12801\n",
      "[6588]\ttraining's auc: 0.984265\ttraining's binary_logloss: 0.128008\n",
      "[6589]\ttraining's auc: 0.984273\ttraining's binary_logloss: 0.127997\n",
      "[6590]\ttraining's auc: 0.98428\ttraining's binary_logloss: 0.127984\n",
      "[6591]\ttraining's auc: 0.984283\ttraining's binary_logloss: 0.127977\n",
      "[6592]\ttraining's auc: 0.984289\ttraining's binary_logloss: 0.127966\n",
      "[6593]\ttraining's auc: 0.984294\ttraining's binary_logloss: 0.127954\n",
      "[6594]\ttraining's auc: 0.984301\ttraining's binary_logloss: 0.127943\n",
      "[6595]\ttraining's auc: 0.98431\ttraining's binary_logloss: 0.12793\n",
      "[6596]\ttraining's auc: 0.984316\ttraining's binary_logloss: 0.127921\n",
      "[6597]\ttraining's auc: 0.984324\ttraining's binary_logloss: 0.127909\n",
      "[6598]\ttraining's auc: 0.984331\ttraining's binary_logloss: 0.127902\n",
      "[6599]\ttraining's auc: 0.984337\ttraining's binary_logloss: 0.127892\n",
      "[6600]\ttraining's auc: 0.984343\ttraining's binary_logloss: 0.127885\n",
      "[6601]\ttraining's auc: 0.98435\ttraining's binary_logloss: 0.127872\n",
      "[6602]\ttraining's auc: 0.984357\ttraining's binary_logloss: 0.127861\n",
      "[6603]\ttraining's auc: 0.984364\ttraining's binary_logloss: 0.127849\n",
      "[6604]\ttraining's auc: 0.984371\ttraining's binary_logloss: 0.127835\n",
      "[6605]\ttraining's auc: 0.984377\ttraining's binary_logloss: 0.127823\n",
      "[6606]\ttraining's auc: 0.984383\ttraining's binary_logloss: 0.127814\n",
      "[6607]\ttraining's auc: 0.984391\ttraining's binary_logloss: 0.127803\n",
      "[6608]\ttraining's auc: 0.984399\ttraining's binary_logloss: 0.127792\n",
      "[6609]\ttraining's auc: 0.984408\ttraining's binary_logloss: 0.127779\n",
      "[6610]\ttraining's auc: 0.98441\ttraining's binary_logloss: 0.127772\n",
      "[6611]\ttraining's auc: 0.984422\ttraining's binary_logloss: 0.12776\n",
      "[6612]\ttraining's auc: 0.984423\ttraining's binary_logloss: 0.127755\n",
      "[6613]\ttraining's auc: 0.984431\ttraining's binary_logloss: 0.127742\n",
      "[6614]\ttraining's auc: 0.984442\ttraining's binary_logloss: 0.127728\n",
      "[6615]\ttraining's auc: 0.984451\ttraining's binary_logloss: 0.127716\n",
      "[6616]\ttraining's auc: 0.984458\ttraining's binary_logloss: 0.127707\n",
      "[6617]\ttraining's auc: 0.984461\ttraining's binary_logloss: 0.127698\n",
      "[6618]\ttraining's auc: 0.984468\ttraining's binary_logloss: 0.12769\n",
      "[6619]\ttraining's auc: 0.984476\ttraining's binary_logloss: 0.127677\n",
      "[6620]\ttraining's auc: 0.984477\ttraining's binary_logloss: 0.127673\n",
      "[6621]\ttraining's auc: 0.984483\ttraining's binary_logloss: 0.127663\n",
      "[6622]\ttraining's auc: 0.984494\ttraining's binary_logloss: 0.127652\n",
      "[6623]\ttraining's auc: 0.984498\ttraining's binary_logloss: 0.127639\n",
      "[6624]\ttraining's auc: 0.984503\ttraining's binary_logloss: 0.127628\n",
      "[6625]\ttraining's auc: 0.984511\ttraining's binary_logloss: 0.127614\n",
      "[6626]\ttraining's auc: 0.984517\ttraining's binary_logloss: 0.127601\n",
      "[6627]\ttraining's auc: 0.984522\ttraining's binary_logloss: 0.127589\n",
      "[6628]\ttraining's auc: 0.984528\ttraining's binary_logloss: 0.127577\n",
      "[6629]\ttraining's auc: 0.984536\ttraining's binary_logloss: 0.127567\n",
      "[6630]\ttraining's auc: 0.984543\ttraining's binary_logloss: 0.127556\n",
      "[6631]\ttraining's auc: 0.984545\ttraining's binary_logloss: 0.127549\n",
      "[6632]\ttraining's auc: 0.984553\ttraining's binary_logloss: 0.127537\n",
      "[6633]\ttraining's auc: 0.984556\ttraining's binary_logloss: 0.127529\n",
      "[6634]\ttraining's auc: 0.984561\ttraining's binary_logloss: 0.127517\n",
      "[6635]\ttraining's auc: 0.984575\ttraining's binary_logloss: 0.127503\n",
      "[6636]\ttraining's auc: 0.984582\ttraining's binary_logloss: 0.12749\n",
      "[6637]\ttraining's auc: 0.984589\ttraining's binary_logloss: 0.127483\n",
      "[6638]\ttraining's auc: 0.984595\ttraining's binary_logloss: 0.12747\n",
      "[6639]\ttraining's auc: 0.984602\ttraining's binary_logloss: 0.127458\n",
      "[6640]\ttraining's auc: 0.984609\ttraining's binary_logloss: 0.127446\n",
      "[6641]\ttraining's auc: 0.984615\ttraining's binary_logloss: 0.127433\n",
      "[6642]\ttraining's auc: 0.984619\ttraining's binary_logloss: 0.127424\n",
      "[6643]\ttraining's auc: 0.984628\ttraining's binary_logloss: 0.127411\n",
      "[6644]\ttraining's auc: 0.98464\ttraining's binary_logloss: 0.127399\n",
      "[6645]\ttraining's auc: 0.984641\ttraining's binary_logloss: 0.127397\n",
      "[6646]\ttraining's auc: 0.984649\ttraining's binary_logloss: 0.127388\n",
      "[6647]\ttraining's auc: 0.984658\ttraining's binary_logloss: 0.127375\n",
      "[6648]\ttraining's auc: 0.984663\ttraining's binary_logloss: 0.127365\n",
      "[6649]\ttraining's auc: 0.98467\ttraining's binary_logloss: 0.127353\n",
      "[6650]\ttraining's auc: 0.984682\ttraining's binary_logloss: 0.127339\n",
      "[6651]\ttraining's auc: 0.984688\ttraining's binary_logloss: 0.127327\n",
      "[6652]\ttraining's auc: 0.984692\ttraining's binary_logloss: 0.127316\n",
      "[6653]\ttraining's auc: 0.984698\ttraining's binary_logloss: 0.127303\n",
      "[6654]\ttraining's auc: 0.984702\ttraining's binary_logloss: 0.127293\n",
      "[6655]\ttraining's auc: 0.98471\ttraining's binary_logloss: 0.127281\n",
      "[6656]\ttraining's auc: 0.984717\ttraining's binary_logloss: 0.127266\n",
      "[6657]\ttraining's auc: 0.984722\ttraining's binary_logloss: 0.127256\n",
      "[6658]\ttraining's auc: 0.984726\ttraining's binary_logloss: 0.127244\n",
      "[6659]\ttraining's auc: 0.984732\ttraining's binary_logloss: 0.127234\n",
      "[6660]\ttraining's auc: 0.98474\ttraining's binary_logloss: 0.127222\n",
      "[6661]\ttraining's auc: 0.984749\ttraining's binary_logloss: 0.127209\n",
      "[6662]\ttraining's auc: 0.984756\ttraining's binary_logloss: 0.127197\n",
      "[6663]\ttraining's auc: 0.984766\ttraining's binary_logloss: 0.127183\n",
      "[6664]\ttraining's auc: 0.984772\ttraining's binary_logloss: 0.127172\n",
      "[6665]\ttraining's auc: 0.984778\ttraining's binary_logloss: 0.127165\n",
      "[6666]\ttraining's auc: 0.984789\ttraining's binary_logloss: 0.127152\n",
      "[6667]\ttraining's auc: 0.984796\ttraining's binary_logloss: 0.12714\n",
      "[6668]\ttraining's auc: 0.984804\ttraining's binary_logloss: 0.127129\n",
      "[6669]\ttraining's auc: 0.98481\ttraining's binary_logloss: 0.127117\n",
      "[6670]\ttraining's auc: 0.984814\ttraining's binary_logloss: 0.127106\n",
      "[6671]\ttraining's auc: 0.984824\ttraining's binary_logloss: 0.127094\n",
      "[6672]\ttraining's auc: 0.984831\ttraining's binary_logloss: 0.127083\n",
      "[6673]\ttraining's auc: 0.98484\ttraining's binary_logloss: 0.12707\n",
      "[6674]\ttraining's auc: 0.984847\ttraining's binary_logloss: 0.127058\n",
      "[6675]\ttraining's auc: 0.984851\ttraining's binary_logloss: 0.127046\n",
      "[6676]\ttraining's auc: 0.984856\ttraining's binary_logloss: 0.127035\n",
      "[6677]\ttraining's auc: 0.984862\ttraining's binary_logloss: 0.127024\n",
      "[6678]\ttraining's auc: 0.984872\ttraining's binary_logloss: 0.12701\n",
      "[6679]\ttraining's auc: 0.98488\ttraining's binary_logloss: 0.126996\n",
      "[6680]\ttraining's auc: 0.984889\ttraining's binary_logloss: 0.126985\n",
      "[6681]\ttraining's auc: 0.984895\ttraining's binary_logloss: 0.126974\n",
      "[6682]\ttraining's auc: 0.984905\ttraining's binary_logloss: 0.126962\n",
      "[6683]\ttraining's auc: 0.984906\ttraining's binary_logloss: 0.126958\n",
      "[6684]\ttraining's auc: 0.98491\ttraining's binary_logloss: 0.126951\n",
      "[6685]\ttraining's auc: 0.984916\ttraining's binary_logloss: 0.126939\n",
      "[6686]\ttraining's auc: 0.984919\ttraining's binary_logloss: 0.126931\n",
      "[6687]\ttraining's auc: 0.984925\ttraining's binary_logloss: 0.126925\n",
      "[6688]\ttraining's auc: 0.984932\ttraining's binary_logloss: 0.126914\n",
      "[6689]\ttraining's auc: 0.984938\ttraining's binary_logloss: 0.126905\n",
      "[6690]\ttraining's auc: 0.984943\ttraining's binary_logloss: 0.126895\n",
      "[6691]\ttraining's auc: 0.984952\ttraining's binary_logloss: 0.126886\n",
      "[6692]\ttraining's auc: 0.984959\ttraining's binary_logloss: 0.126874\n",
      "[6693]\ttraining's auc: 0.98496\ttraining's binary_logloss: 0.12687\n",
      "[6694]\ttraining's auc: 0.984969\ttraining's binary_logloss: 0.126859\n",
      "[6695]\ttraining's auc: 0.984972\ttraining's binary_logloss: 0.126852\n",
      "[6696]\ttraining's auc: 0.984978\ttraining's binary_logloss: 0.126841\n",
      "[6697]\ttraining's auc: 0.984979\ttraining's binary_logloss: 0.12684\n",
      "[6698]\ttraining's auc: 0.984986\ttraining's binary_logloss: 0.126828\n",
      "[6699]\ttraining's auc: 0.98499\ttraining's binary_logloss: 0.126814\n",
      "[6700]\ttraining's auc: 0.984998\ttraining's binary_logloss: 0.1268\n",
      "[6701]\ttraining's auc: 0.985003\ttraining's binary_logloss: 0.126793\n",
      "[6702]\ttraining's auc: 0.985009\ttraining's binary_logloss: 0.126784\n",
      "[6703]\ttraining's auc: 0.985019\ttraining's binary_logloss: 0.126771\n",
      "[6704]\ttraining's auc: 0.985027\ttraining's binary_logloss: 0.126759\n",
      "[6705]\ttraining's auc: 0.985034\ttraining's binary_logloss: 0.126747\n",
      "[6706]\ttraining's auc: 0.985039\ttraining's binary_logloss: 0.126736\n",
      "[6707]\ttraining's auc: 0.985044\ttraining's binary_logloss: 0.126727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6708]\ttraining's auc: 0.985051\ttraining's binary_logloss: 0.126715\n",
      "[6709]\ttraining's auc: 0.98506\ttraining's binary_logloss: 0.126702\n",
      "[6710]\ttraining's auc: 0.985062\ttraining's binary_logloss: 0.126698\n",
      "[6711]\ttraining's auc: 0.985069\ttraining's binary_logloss: 0.126687\n",
      "[6712]\ttraining's auc: 0.985077\ttraining's binary_logloss: 0.126675\n",
      "[6713]\ttraining's auc: 0.985085\ttraining's binary_logloss: 0.126664\n",
      "[6714]\ttraining's auc: 0.985094\ttraining's binary_logloss: 0.126651\n",
      "[6715]\ttraining's auc: 0.985102\ttraining's binary_logloss: 0.126639\n",
      "[6716]\ttraining's auc: 0.98511\ttraining's binary_logloss: 0.126627\n",
      "[6717]\ttraining's auc: 0.985114\ttraining's binary_logloss: 0.126619\n",
      "[6718]\ttraining's auc: 0.98512\ttraining's binary_logloss: 0.126608\n",
      "[6719]\ttraining's auc: 0.985128\ttraining's binary_logloss: 0.126595\n",
      "[6720]\ttraining's auc: 0.98513\ttraining's binary_logloss: 0.12659\n",
      "[6721]\ttraining's auc: 0.985137\ttraining's binary_logloss: 0.126579\n",
      "[6722]\ttraining's auc: 0.985144\ttraining's binary_logloss: 0.126566\n",
      "[6723]\ttraining's auc: 0.985152\ttraining's binary_logloss: 0.126555\n",
      "[6724]\ttraining's auc: 0.985161\ttraining's binary_logloss: 0.126544\n",
      "[6725]\ttraining's auc: 0.985169\ttraining's binary_logloss: 0.126532\n",
      "[6726]\ttraining's auc: 0.985173\ttraining's binary_logloss: 0.126522\n",
      "[6727]\ttraining's auc: 0.985179\ttraining's binary_logloss: 0.126512\n",
      "[6728]\ttraining's auc: 0.985185\ttraining's binary_logloss: 0.126499\n",
      "[6729]\ttraining's auc: 0.985196\ttraining's binary_logloss: 0.126485\n",
      "[6730]\ttraining's auc: 0.985202\ttraining's binary_logloss: 0.126472\n",
      "[6731]\ttraining's auc: 0.98521\ttraining's binary_logloss: 0.126463\n",
      "[6732]\ttraining's auc: 0.985211\ttraining's binary_logloss: 0.12646\n",
      "[6733]\ttraining's auc: 0.985221\ttraining's binary_logloss: 0.126444\n",
      "[6734]\ttraining's auc: 0.985227\ttraining's binary_logloss: 0.126435\n",
      "[6735]\ttraining's auc: 0.985231\ttraining's binary_logloss: 0.126429\n",
      "[6736]\ttraining's auc: 0.985233\ttraining's binary_logloss: 0.126424\n",
      "[6737]\ttraining's auc: 0.98524\ttraining's binary_logloss: 0.126411\n",
      "[6738]\ttraining's auc: 0.985245\ttraining's binary_logloss: 0.126401\n",
      "[6739]\ttraining's auc: 0.985254\ttraining's binary_logloss: 0.126389\n",
      "[6740]\ttraining's auc: 0.985261\ttraining's binary_logloss: 0.126378\n",
      "[6741]\ttraining's auc: 0.985264\ttraining's binary_logloss: 0.126373\n",
      "[6742]\ttraining's auc: 0.985264\ttraining's binary_logloss: 0.12637\n",
      "[6743]\ttraining's auc: 0.985273\ttraining's binary_logloss: 0.126356\n",
      "[6744]\ttraining's auc: 0.98528\ttraining's binary_logloss: 0.126343\n",
      "[6745]\ttraining's auc: 0.985287\ttraining's binary_logloss: 0.126333\n",
      "[6746]\ttraining's auc: 0.985291\ttraining's binary_logloss: 0.126322\n",
      "[6747]\ttraining's auc: 0.985295\ttraining's binary_logloss: 0.126312\n",
      "[6748]\ttraining's auc: 0.985305\ttraining's binary_logloss: 0.126299\n",
      "[6749]\ttraining's auc: 0.985315\ttraining's binary_logloss: 0.126287\n",
      "[6750]\ttraining's auc: 0.985318\ttraining's binary_logloss: 0.126275\n",
      "[6751]\ttraining's auc: 0.985324\ttraining's binary_logloss: 0.126264\n",
      "[6752]\ttraining's auc: 0.985324\ttraining's binary_logloss: 0.126261\n",
      "[6753]\ttraining's auc: 0.985332\ttraining's binary_logloss: 0.12625\n",
      "[6754]\ttraining's auc: 0.985342\ttraining's binary_logloss: 0.126236\n",
      "[6755]\ttraining's auc: 0.985347\ttraining's binary_logloss: 0.126225\n",
      "[6756]\ttraining's auc: 0.985352\ttraining's binary_logloss: 0.126214\n",
      "[6757]\ttraining's auc: 0.985362\ttraining's binary_logloss: 0.126201\n",
      "[6758]\ttraining's auc: 0.985373\ttraining's binary_logloss: 0.126189\n",
      "[6759]\ttraining's auc: 0.985374\ttraining's binary_logloss: 0.126186\n",
      "[6760]\ttraining's auc: 0.985379\ttraining's binary_logloss: 0.126175\n",
      "[6761]\ttraining's auc: 0.985385\ttraining's binary_logloss: 0.126166\n",
      "[6762]\ttraining's auc: 0.985388\ttraining's binary_logloss: 0.126159\n",
      "[6763]\ttraining's auc: 0.985389\ttraining's binary_logloss: 0.126157\n",
      "[6764]\ttraining's auc: 0.985397\ttraining's binary_logloss: 0.126147\n",
      "[6765]\ttraining's auc: 0.985398\ttraining's binary_logloss: 0.126146\n",
      "[6766]\ttraining's auc: 0.985399\ttraining's binary_logloss: 0.126143\n",
      "[6767]\ttraining's auc: 0.985408\ttraining's binary_logloss: 0.12613\n",
      "[6768]\ttraining's auc: 0.985416\ttraining's binary_logloss: 0.126119\n",
      "[6769]\ttraining's auc: 0.985421\ttraining's binary_logloss: 0.126111\n",
      "[6770]\ttraining's auc: 0.985426\ttraining's binary_logloss: 0.126102\n",
      "[6771]\ttraining's auc: 0.985432\ttraining's binary_logloss: 0.126094\n",
      "[6772]\ttraining's auc: 0.985439\ttraining's binary_logloss: 0.126083\n",
      "[6773]\ttraining's auc: 0.985445\ttraining's binary_logloss: 0.126071\n",
      "[6774]\ttraining's auc: 0.985452\ttraining's binary_logloss: 0.12606\n",
      "[6775]\ttraining's auc: 0.985461\ttraining's binary_logloss: 0.126048\n",
      "[6776]\ttraining's auc: 0.985467\ttraining's binary_logloss: 0.126038\n",
      "[6777]\ttraining's auc: 0.985475\ttraining's binary_logloss: 0.126027\n",
      "[6778]\ttraining's auc: 0.985479\ttraining's binary_logloss: 0.126016\n",
      "[6779]\ttraining's auc: 0.985487\ttraining's binary_logloss: 0.126005\n",
      "[6780]\ttraining's auc: 0.985489\ttraining's binary_logloss: 0.126002\n",
      "[6781]\ttraining's auc: 0.9855\ttraining's binary_logloss: 0.125986\n",
      "[6782]\ttraining's auc: 0.985513\ttraining's binary_logloss: 0.125971\n",
      "[6783]\ttraining's auc: 0.985521\ttraining's binary_logloss: 0.12596\n",
      "[6784]\ttraining's auc: 0.985525\ttraining's binary_logloss: 0.125949\n",
      "[6785]\ttraining's auc: 0.985532\ttraining's binary_logloss: 0.125937\n",
      "[6786]\ttraining's auc: 0.98554\ttraining's binary_logloss: 0.125925\n",
      "[6787]\ttraining's auc: 0.985546\ttraining's binary_logloss: 0.125912\n",
      "[6788]\ttraining's auc: 0.985554\ttraining's binary_logloss: 0.125901\n",
      "[6789]\ttraining's auc: 0.985564\ttraining's binary_logloss: 0.125888\n",
      "[6790]\ttraining's auc: 0.985565\ttraining's binary_logloss: 0.125885\n",
      "[6791]\ttraining's auc: 0.985568\ttraining's binary_logloss: 0.125876\n",
      "[6792]\ttraining's auc: 0.985573\ttraining's binary_logloss: 0.125865\n",
      "[6793]\ttraining's auc: 0.985579\ttraining's binary_logloss: 0.125854\n",
      "[6794]\ttraining's auc: 0.985585\ttraining's binary_logloss: 0.125845\n",
      "[6795]\ttraining's auc: 0.985587\ttraining's binary_logloss: 0.125843\n",
      "[6796]\ttraining's auc: 0.985594\ttraining's binary_logloss: 0.125832\n",
      "[6797]\ttraining's auc: 0.985603\ttraining's binary_logloss: 0.125819\n",
      "[6798]\ttraining's auc: 0.985608\ttraining's binary_logloss: 0.125808\n",
      "[6799]\ttraining's auc: 0.985617\ttraining's binary_logloss: 0.125796\n",
      "[6800]\ttraining's auc: 0.985625\ttraining's binary_logloss: 0.125784\n",
      "[6801]\ttraining's auc: 0.985628\ttraining's binary_logloss: 0.125777\n",
      "[6802]\ttraining's auc: 0.985636\ttraining's binary_logloss: 0.125764\n",
      "[6803]\ttraining's auc: 0.985641\ttraining's binary_logloss: 0.125757\n",
      "[6804]\ttraining's auc: 0.985646\ttraining's binary_logloss: 0.125748\n",
      "[6805]\ttraining's auc: 0.985654\ttraining's binary_logloss: 0.125736\n",
      "[6806]\ttraining's auc: 0.985659\ttraining's binary_logloss: 0.125725\n",
      "[6807]\ttraining's auc: 0.98566\ttraining's binary_logloss: 0.125723\n",
      "[6808]\ttraining's auc: 0.985669\ttraining's binary_logloss: 0.125709\n",
      "[6809]\ttraining's auc: 0.985676\ttraining's binary_logloss: 0.125698\n",
      "[6810]\ttraining's auc: 0.985678\ttraining's binary_logloss: 0.125694\n",
      "[6811]\ttraining's auc: 0.985686\ttraining's binary_logloss: 0.125682\n",
      "[6812]\ttraining's auc: 0.985689\ttraining's binary_logloss: 0.125678\n",
      "[6813]\ttraining's auc: 0.985693\ttraining's binary_logloss: 0.125666\n",
      "[6814]\ttraining's auc: 0.985697\ttraining's binary_logloss: 0.125656\n",
      "[6815]\ttraining's auc: 0.985705\ttraining's binary_logloss: 0.125645\n",
      "[6816]\ttraining's auc: 0.98571\ttraining's binary_logloss: 0.125634\n",
      "[6817]\ttraining's auc: 0.985712\ttraining's binary_logloss: 0.125627\n",
      "[6818]\ttraining's auc: 0.985719\ttraining's binary_logloss: 0.125617\n",
      "[6819]\ttraining's auc: 0.985725\ttraining's binary_logloss: 0.125606\n",
      "[6820]\ttraining's auc: 0.985733\ttraining's binary_logloss: 0.125594\n",
      "[6821]\ttraining's auc: 0.985739\ttraining's binary_logloss: 0.125582\n",
      "[6822]\ttraining's auc: 0.985747\ttraining's binary_logloss: 0.12557\n",
      "[6823]\ttraining's auc: 0.985754\ttraining's binary_logloss: 0.125558\n",
      "[6824]\ttraining's auc: 0.985759\ttraining's binary_logloss: 0.125548\n",
      "[6825]\ttraining's auc: 0.985766\ttraining's binary_logloss: 0.125536\n",
      "[6826]\ttraining's auc: 0.985771\ttraining's binary_logloss: 0.125526\n",
      "[6827]\ttraining's auc: 0.985775\ttraining's binary_logloss: 0.125516\n",
      "[6828]\ttraining's auc: 0.985782\ttraining's binary_logloss: 0.125505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6829]\ttraining's auc: 0.985788\ttraining's binary_logloss: 0.125491\n",
      "[6830]\ttraining's auc: 0.985793\ttraining's binary_logloss: 0.125481\n",
      "[6831]\ttraining's auc: 0.985802\ttraining's binary_logloss: 0.12547\n",
      "[6832]\ttraining's auc: 0.985808\ttraining's binary_logloss: 0.125459\n",
      "[6833]\ttraining's auc: 0.985811\ttraining's binary_logloss: 0.125453\n",
      "[6834]\ttraining's auc: 0.985812\ttraining's binary_logloss: 0.125451\n",
      "[6835]\ttraining's auc: 0.985816\ttraining's binary_logloss: 0.12544\n",
      "[6836]\ttraining's auc: 0.985824\ttraining's binary_logloss: 0.125427\n",
      "[6837]\ttraining's auc: 0.98583\ttraining's binary_logloss: 0.125416\n",
      "[6838]\ttraining's auc: 0.985835\ttraining's binary_logloss: 0.125405\n",
      "[6839]\ttraining's auc: 0.985839\ttraining's binary_logloss: 0.125398\n",
      "[6840]\ttraining's auc: 0.985842\ttraining's binary_logloss: 0.125394\n",
      "[6841]\ttraining's auc: 0.985849\ttraining's binary_logloss: 0.125384\n",
      "[6842]\ttraining's auc: 0.985859\ttraining's binary_logloss: 0.125371\n",
      "[6843]\ttraining's auc: 0.985864\ttraining's binary_logloss: 0.125359\n",
      "[6844]\ttraining's auc: 0.985871\ttraining's binary_logloss: 0.125347\n",
      "[6845]\ttraining's auc: 0.985878\ttraining's binary_logloss: 0.125336\n",
      "[6846]\ttraining's auc: 0.985887\ttraining's binary_logloss: 0.125325\n",
      "[6847]\ttraining's auc: 0.985895\ttraining's binary_logloss: 0.125313\n",
      "[6848]\ttraining's auc: 0.985896\ttraining's binary_logloss: 0.125309\n",
      "[6849]\ttraining's auc: 0.985903\ttraining's binary_logloss: 0.125301\n",
      "[6850]\ttraining's auc: 0.985912\ttraining's binary_logloss: 0.125289\n",
      "[6851]\ttraining's auc: 0.985918\ttraining's binary_logloss: 0.125278\n",
      "[6852]\ttraining's auc: 0.985924\ttraining's binary_logloss: 0.125267\n",
      "[6853]\ttraining's auc: 0.985928\ttraining's binary_logloss: 0.125257\n",
      "[6854]\ttraining's auc: 0.985935\ttraining's binary_logloss: 0.125246\n",
      "[6855]\ttraining's auc: 0.985945\ttraining's binary_logloss: 0.125235\n",
      "[6856]\ttraining's auc: 0.985952\ttraining's binary_logloss: 0.125225\n",
      "[6857]\ttraining's auc: 0.985953\ttraining's binary_logloss: 0.125224\n",
      "[6858]\ttraining's auc: 0.985959\ttraining's binary_logloss: 0.125212\n",
      "[6859]\ttraining's auc: 0.985966\ttraining's binary_logloss: 0.125202\n",
      "[6860]\ttraining's auc: 0.985971\ttraining's binary_logloss: 0.125195\n",
      "[6861]\ttraining's auc: 0.985971\ttraining's binary_logloss: 0.125194\n",
      "[6862]\ttraining's auc: 0.985977\ttraining's binary_logloss: 0.125182\n",
      "[6863]\ttraining's auc: 0.985981\ttraining's binary_logloss: 0.125171\n",
      "[6864]\ttraining's auc: 0.985988\ttraining's binary_logloss: 0.125159\n",
      "[6865]\ttraining's auc: 0.985993\ttraining's binary_logloss: 0.125148\n",
      "[6866]\ttraining's auc: 0.985996\ttraining's binary_logloss: 0.125142\n",
      "[6867]\ttraining's auc: 0.985999\ttraining's binary_logloss: 0.125138\n",
      "[6868]\ttraining's auc: 0.986005\ttraining's binary_logloss: 0.125126\n",
      "[6869]\ttraining's auc: 0.98601\ttraining's binary_logloss: 0.125115\n",
      "[6870]\ttraining's auc: 0.986013\ttraining's binary_logloss: 0.125109\n",
      "[6871]\ttraining's auc: 0.986017\ttraining's binary_logloss: 0.125098\n",
      "[6872]\ttraining's auc: 0.986023\ttraining's binary_logloss: 0.125087\n",
      "[6873]\ttraining's auc: 0.986028\ttraining's binary_logloss: 0.125076\n",
      "[6874]\ttraining's auc: 0.986036\ttraining's binary_logloss: 0.125062\n",
      "[6875]\ttraining's auc: 0.986045\ttraining's binary_logloss: 0.125049\n",
      "[6876]\ttraining's auc: 0.986052\ttraining's binary_logloss: 0.125038\n",
      "[6877]\ttraining's auc: 0.986057\ttraining's binary_logloss: 0.125028\n",
      "[6878]\ttraining's auc: 0.986062\ttraining's binary_logloss: 0.125016\n",
      "[6879]\ttraining's auc: 0.986069\ttraining's binary_logloss: 0.125006\n",
      "[6880]\ttraining's auc: 0.986075\ttraining's binary_logloss: 0.124996\n",
      "[6881]\ttraining's auc: 0.986079\ttraining's binary_logloss: 0.124985\n",
      "[6882]\ttraining's auc: 0.986088\ttraining's binary_logloss: 0.124972\n",
      "[6883]\ttraining's auc: 0.986096\ttraining's binary_logloss: 0.12496\n",
      "[6884]\ttraining's auc: 0.986102\ttraining's binary_logloss: 0.124946\n",
      "[6885]\ttraining's auc: 0.986109\ttraining's binary_logloss: 0.124936\n",
      "[6886]\ttraining's auc: 0.986117\ttraining's binary_logloss: 0.124928\n",
      "[6887]\ttraining's auc: 0.986127\ttraining's binary_logloss: 0.124917\n",
      "[6888]\ttraining's auc: 0.986135\ttraining's binary_logloss: 0.124904\n",
      "[6889]\ttraining's auc: 0.986136\ttraining's binary_logloss: 0.124902\n",
      "[6890]\ttraining's auc: 0.986143\ttraining's binary_logloss: 0.124892\n",
      "[6891]\ttraining's auc: 0.986145\ttraining's binary_logloss: 0.124889\n",
      "[6892]\ttraining's auc: 0.986152\ttraining's binary_logloss: 0.124879\n",
      "[6893]\ttraining's auc: 0.986154\ttraining's binary_logloss: 0.124874\n",
      "[6894]\ttraining's auc: 0.986155\ttraining's binary_logloss: 0.124871\n",
      "[6895]\ttraining's auc: 0.986162\ttraining's binary_logloss: 0.124859\n",
      "[6896]\ttraining's auc: 0.986169\ttraining's binary_logloss: 0.124847\n",
      "[6897]\ttraining's auc: 0.986175\ttraining's binary_logloss: 0.124836\n",
      "[6898]\ttraining's auc: 0.98618\ttraining's binary_logloss: 0.124822\n",
      "[6899]\ttraining's auc: 0.986187\ttraining's binary_logloss: 0.124809\n",
      "[6900]\ttraining's auc: 0.986187\ttraining's binary_logloss: 0.124807\n",
      "[6901]\ttraining's auc: 0.986193\ttraining's binary_logloss: 0.124799\n",
      "[6902]\ttraining's auc: 0.986199\ttraining's binary_logloss: 0.12479\n",
      "[6903]\ttraining's auc: 0.9862\ttraining's binary_logloss: 0.124787\n",
      "[6904]\ttraining's auc: 0.986208\ttraining's binary_logloss: 0.124776\n",
      "[6905]\ttraining's auc: 0.986216\ttraining's binary_logloss: 0.124764\n",
      "[6906]\ttraining's auc: 0.986226\ttraining's binary_logloss: 0.124752\n",
      "[6907]\ttraining's auc: 0.986232\ttraining's binary_logloss: 0.124743\n",
      "[6908]\ttraining's auc: 0.986239\ttraining's binary_logloss: 0.124731\n",
      "[6909]\ttraining's auc: 0.986242\ttraining's binary_logloss: 0.12472\n",
      "[6910]\ttraining's auc: 0.98625\ttraining's binary_logloss: 0.124708\n",
      "[6911]\ttraining's auc: 0.986256\ttraining's binary_logloss: 0.124694\n",
      "[6912]\ttraining's auc: 0.986264\ttraining's binary_logloss: 0.124682\n",
      "[6913]\ttraining's auc: 0.986266\ttraining's binary_logloss: 0.12467\n",
      "[6914]\ttraining's auc: 0.986271\ttraining's binary_logloss: 0.124658\n",
      "[6915]\ttraining's auc: 0.986276\ttraining's binary_logloss: 0.124648\n",
      "[6916]\ttraining's auc: 0.986282\ttraining's binary_logloss: 0.124636\n",
      "[6917]\ttraining's auc: 0.986287\ttraining's binary_logloss: 0.124622\n",
      "[6918]\ttraining's auc: 0.986296\ttraining's binary_logloss: 0.124611\n",
      "[6919]\ttraining's auc: 0.986299\ttraining's binary_logloss: 0.124602\n",
      "[6920]\ttraining's auc: 0.986304\ttraining's binary_logloss: 0.124593\n",
      "[6921]\ttraining's auc: 0.98631\ttraining's binary_logloss: 0.124578\n",
      "[6922]\ttraining's auc: 0.986316\ttraining's binary_logloss: 0.124567\n",
      "[6923]\ttraining's auc: 0.986326\ttraining's binary_logloss: 0.124554\n",
      "[6924]\ttraining's auc: 0.986334\ttraining's binary_logloss: 0.124541\n",
      "[6925]\ttraining's auc: 0.986339\ttraining's binary_logloss: 0.12453\n",
      "[6926]\ttraining's auc: 0.98635\ttraining's binary_logloss: 0.124519\n",
      "[6927]\ttraining's auc: 0.986351\ttraining's binary_logloss: 0.124516\n",
      "[6928]\ttraining's auc: 0.986351\ttraining's binary_logloss: 0.124514\n",
      "[6929]\ttraining's auc: 0.986357\ttraining's binary_logloss: 0.124501\n",
      "[6930]\ttraining's auc: 0.986365\ttraining's binary_logloss: 0.124489\n",
      "[6931]\ttraining's auc: 0.986371\ttraining's binary_logloss: 0.124475\n",
      "[6932]\ttraining's auc: 0.986377\ttraining's binary_logloss: 0.124464\n",
      "[6933]\ttraining's auc: 0.986382\ttraining's binary_logloss: 0.124454\n",
      "[6934]\ttraining's auc: 0.986388\ttraining's binary_logloss: 0.124444\n",
      "[6935]\ttraining's auc: 0.986389\ttraining's binary_logloss: 0.124441\n",
      "[6936]\ttraining's auc: 0.986393\ttraining's binary_logloss: 0.124435\n",
      "[6937]\ttraining's auc: 0.986394\ttraining's binary_logloss: 0.124432\n",
      "[6938]\ttraining's auc: 0.986402\ttraining's binary_logloss: 0.124419\n",
      "[6939]\ttraining's auc: 0.986402\ttraining's binary_logloss: 0.124418\n",
      "[6940]\ttraining's auc: 0.986408\ttraining's binary_logloss: 0.124409\n",
      "[6941]\ttraining's auc: 0.986412\ttraining's binary_logloss: 0.124402\n",
      "[6942]\ttraining's auc: 0.986418\ttraining's binary_logloss: 0.12439\n",
      "[6943]\ttraining's auc: 0.986424\ttraining's binary_logloss: 0.124379\n",
      "[6944]\ttraining's auc: 0.986424\ttraining's binary_logloss: 0.124377\n",
      "[6945]\ttraining's auc: 0.986429\ttraining's binary_logloss: 0.124365\n",
      "[6946]\ttraining's auc: 0.986436\ttraining's binary_logloss: 0.124353\n",
      "[6947]\ttraining's auc: 0.986436\ttraining's binary_logloss: 0.124351\n",
      "[6948]\ttraining's auc: 0.986445\ttraining's binary_logloss: 0.124339\n",
      "[6949]\ttraining's auc: 0.986451\ttraining's binary_logloss: 0.124327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6950]\ttraining's auc: 0.986458\ttraining's binary_logloss: 0.124315\n",
      "[6951]\ttraining's auc: 0.986461\ttraining's binary_logloss: 0.124309\n",
      "[6952]\ttraining's auc: 0.986466\ttraining's binary_logloss: 0.124303\n",
      "[6953]\ttraining's auc: 0.98647\ttraining's binary_logloss: 0.124293\n",
      "[6954]\ttraining's auc: 0.986477\ttraining's binary_logloss: 0.124281\n",
      "[6955]\ttraining's auc: 0.986483\ttraining's binary_logloss: 0.124272\n",
      "[6956]\ttraining's auc: 0.98649\ttraining's binary_logloss: 0.124262\n",
      "[6957]\ttraining's auc: 0.986499\ttraining's binary_logloss: 0.124249\n",
      "[6958]\ttraining's auc: 0.986504\ttraining's binary_logloss: 0.124237\n",
      "[6959]\ttraining's auc: 0.986508\ttraining's binary_logloss: 0.124225\n",
      "[6960]\ttraining's auc: 0.986514\ttraining's binary_logloss: 0.124214\n",
      "[6961]\ttraining's auc: 0.986525\ttraining's binary_logloss: 0.124201\n",
      "[6962]\ttraining's auc: 0.986532\ttraining's binary_logloss: 0.124187\n",
      "[6963]\ttraining's auc: 0.986539\ttraining's binary_logloss: 0.124175\n",
      "[6964]\ttraining's auc: 0.986546\ttraining's binary_logloss: 0.124162\n",
      "[6965]\ttraining's auc: 0.986546\ttraining's binary_logloss: 0.124161\n",
      "[6966]\ttraining's auc: 0.986555\ttraining's binary_logloss: 0.124149\n",
      "[6967]\ttraining's auc: 0.986561\ttraining's binary_logloss: 0.124137\n",
      "[6968]\ttraining's auc: 0.986564\ttraining's binary_logloss: 0.124126\n",
      "[6969]\ttraining's auc: 0.986573\ttraining's binary_logloss: 0.124112\n",
      "[6970]\ttraining's auc: 0.986577\ttraining's binary_logloss: 0.124105\n",
      "[6971]\ttraining's auc: 0.986587\ttraining's binary_logloss: 0.124094\n",
      "[6972]\ttraining's auc: 0.986592\ttraining's binary_logloss: 0.124082\n",
      "[6973]\ttraining's auc: 0.986598\ttraining's binary_logloss: 0.124071\n",
      "[6974]\ttraining's auc: 0.986602\ttraining's binary_logloss: 0.124061\n",
      "[6975]\ttraining's auc: 0.986607\ttraining's binary_logloss: 0.124052\n",
      "[6976]\ttraining's auc: 0.98661\ttraining's binary_logloss: 0.124047\n",
      "[6977]\ttraining's auc: 0.986611\ttraining's binary_logloss: 0.124045\n",
      "[6978]\ttraining's auc: 0.986617\ttraining's binary_logloss: 0.124034\n",
      "[6979]\ttraining's auc: 0.986625\ttraining's binary_logloss: 0.124023\n",
      "[6980]\ttraining's auc: 0.986636\ttraining's binary_logloss: 0.12401\n",
      "[6981]\ttraining's auc: 0.986643\ttraining's binary_logloss: 0.123999\n",
      "[6982]\ttraining's auc: 0.986647\ttraining's binary_logloss: 0.123988\n",
      "[6983]\ttraining's auc: 0.986649\ttraining's binary_logloss: 0.123982\n",
      "[6984]\ttraining's auc: 0.986652\ttraining's binary_logloss: 0.123973\n",
      "[6985]\ttraining's auc: 0.986657\ttraining's binary_logloss: 0.123962\n",
      "[6986]\ttraining's auc: 0.986661\ttraining's binary_logloss: 0.123953\n",
      "[6987]\ttraining's auc: 0.986668\ttraining's binary_logloss: 0.12394\n",
      "[6988]\ttraining's auc: 0.986668\ttraining's binary_logloss: 0.123938\n",
      "[6989]\ttraining's auc: 0.986674\ttraining's binary_logloss: 0.123926\n",
      "[6990]\ttraining's auc: 0.986678\ttraining's binary_logloss: 0.123915\n",
      "[6991]\ttraining's auc: 0.986683\ttraining's binary_logloss: 0.123905\n",
      "[6992]\ttraining's auc: 0.986691\ttraining's binary_logloss: 0.123893\n",
      "[6993]\ttraining's auc: 0.986697\ttraining's binary_logloss: 0.123882\n",
      "[6994]\ttraining's auc: 0.986702\ttraining's binary_logloss: 0.123871\n",
      "[6995]\ttraining's auc: 0.986708\ttraining's binary_logloss: 0.123861\n",
      "[6996]\ttraining's auc: 0.98671\ttraining's binary_logloss: 0.123855\n",
      "[6997]\ttraining's auc: 0.986715\ttraining's binary_logloss: 0.123846\n",
      "[6998]\ttraining's auc: 0.986719\ttraining's binary_logloss: 0.123837\n",
      "[6999]\ttraining's auc: 0.986723\ttraining's binary_logloss: 0.123825\n",
      "[7000]\ttraining's auc: 0.986727\ttraining's binary_logloss: 0.123814\n",
      "[7001]\ttraining's auc: 0.986734\ttraining's binary_logloss: 0.123802\n",
      "[7002]\ttraining's auc: 0.986739\ttraining's binary_logloss: 0.12379\n",
      "[7003]\ttraining's auc: 0.986745\ttraining's binary_logloss: 0.123778\n",
      "[7004]\ttraining's auc: 0.986755\ttraining's binary_logloss: 0.123765\n",
      "[7005]\ttraining's auc: 0.986762\ttraining's binary_logloss: 0.123752\n",
      "[7006]\ttraining's auc: 0.98677\ttraining's binary_logloss: 0.123739\n",
      "[7007]\ttraining's auc: 0.986776\ttraining's binary_logloss: 0.123731\n",
      "[7008]\ttraining's auc: 0.986782\ttraining's binary_logloss: 0.12372\n",
      "[7009]\ttraining's auc: 0.98679\ttraining's binary_logloss: 0.123707\n",
      "[7010]\ttraining's auc: 0.986799\ttraining's binary_logloss: 0.123694\n",
      "[7011]\ttraining's auc: 0.986805\ttraining's binary_logloss: 0.123684\n",
      "[7012]\ttraining's auc: 0.98681\ttraining's binary_logloss: 0.123672\n",
      "[7013]\ttraining's auc: 0.986815\ttraining's binary_logloss: 0.123662\n",
      "[7014]\ttraining's auc: 0.986818\ttraining's binary_logloss: 0.123659\n",
      "[7015]\ttraining's auc: 0.986827\ttraining's binary_logloss: 0.123648\n",
      "[7016]\ttraining's auc: 0.986831\ttraining's binary_logloss: 0.123639\n",
      "[7017]\ttraining's auc: 0.986836\ttraining's binary_logloss: 0.123631\n",
      "[7018]\ttraining's auc: 0.986845\ttraining's binary_logloss: 0.123621\n",
      "[7019]\ttraining's auc: 0.986855\ttraining's binary_logloss: 0.12361\n",
      "[7020]\ttraining's auc: 0.986861\ttraining's binary_logloss: 0.123601\n",
      "[7021]\ttraining's auc: 0.986866\ttraining's binary_logloss: 0.123591\n",
      "[7022]\ttraining's auc: 0.986871\ttraining's binary_logloss: 0.12358\n",
      "[7023]\ttraining's auc: 0.986878\ttraining's binary_logloss: 0.12357\n",
      "[7024]\ttraining's auc: 0.986885\ttraining's binary_logloss: 0.123558\n",
      "[7025]\ttraining's auc: 0.986891\ttraining's binary_logloss: 0.123544\n",
      "[7026]\ttraining's auc: 0.986897\ttraining's binary_logloss: 0.123534\n",
      "[7027]\ttraining's auc: 0.986898\ttraining's binary_logloss: 0.123522\n",
      "[7028]\ttraining's auc: 0.9869\ttraining's binary_logloss: 0.123512\n",
      "[7029]\ttraining's auc: 0.986909\ttraining's binary_logloss: 0.123501\n",
      "[7030]\ttraining's auc: 0.986915\ttraining's binary_logloss: 0.123489\n",
      "[7031]\ttraining's auc: 0.986917\ttraining's binary_logloss: 0.123484\n",
      "[7032]\ttraining's auc: 0.986924\ttraining's binary_logloss: 0.123472\n",
      "[7033]\ttraining's auc: 0.986928\ttraining's binary_logloss: 0.123467\n",
      "[7034]\ttraining's auc: 0.986929\ttraining's binary_logloss: 0.123466\n",
      "[7035]\ttraining's auc: 0.986936\ttraining's binary_logloss: 0.123453\n",
      "[7036]\ttraining's auc: 0.986942\ttraining's binary_logloss: 0.12344\n",
      "[7037]\ttraining's auc: 0.986949\ttraining's binary_logloss: 0.123428\n",
      "[7038]\ttraining's auc: 0.986955\ttraining's binary_logloss: 0.123416\n",
      "[7039]\ttraining's auc: 0.98696\ttraining's binary_logloss: 0.123406\n",
      "[7040]\ttraining's auc: 0.986965\ttraining's binary_logloss: 0.123396\n",
      "[7041]\ttraining's auc: 0.986967\ttraining's binary_logloss: 0.123394\n",
      "[7042]\ttraining's auc: 0.986976\ttraining's binary_logloss: 0.123381\n",
      "[7043]\ttraining's auc: 0.986988\ttraining's binary_logloss: 0.123368\n",
      "[7044]\ttraining's auc: 0.986992\ttraining's binary_logloss: 0.123359\n",
      "[7045]\ttraining's auc: 0.986997\ttraining's binary_logloss: 0.123348\n",
      "[7046]\ttraining's auc: 0.987002\ttraining's binary_logloss: 0.123337\n",
      "[7047]\ttraining's auc: 0.98701\ttraining's binary_logloss: 0.123327\n",
      "[7048]\ttraining's auc: 0.987019\ttraining's binary_logloss: 0.123314\n",
      "[7049]\ttraining's auc: 0.987026\ttraining's binary_logloss: 0.123302\n",
      "[7050]\ttraining's auc: 0.987028\ttraining's binary_logloss: 0.1233\n",
      "[7051]\ttraining's auc: 0.987034\ttraining's binary_logloss: 0.123288\n",
      "[7052]\ttraining's auc: 0.987039\ttraining's binary_logloss: 0.123276\n",
      "[7053]\ttraining's auc: 0.987051\ttraining's binary_logloss: 0.123264\n",
      "[7054]\ttraining's auc: 0.987054\ttraining's binary_logloss: 0.123254\n",
      "[7055]\ttraining's auc: 0.987062\ttraining's binary_logloss: 0.12324\n",
      "[7056]\ttraining's auc: 0.987066\ttraining's binary_logloss: 0.123229\n",
      "[7057]\ttraining's auc: 0.987072\ttraining's binary_logloss: 0.123215\n",
      "[7058]\ttraining's auc: 0.987079\ttraining's binary_logloss: 0.123205\n",
      "[7059]\ttraining's auc: 0.987087\ttraining's binary_logloss: 0.123193\n",
      "[7060]\ttraining's auc: 0.987094\ttraining's binary_logloss: 0.12318\n",
      "[7061]\ttraining's auc: 0.987098\ttraining's binary_logloss: 0.12317\n",
      "[7062]\ttraining's auc: 0.987101\ttraining's binary_logloss: 0.123168\n",
      "[7063]\ttraining's auc: 0.987103\ttraining's binary_logloss: 0.123157\n",
      "[7064]\ttraining's auc: 0.987108\ttraining's binary_logloss: 0.123146\n",
      "[7065]\ttraining's auc: 0.987116\ttraining's binary_logloss: 0.123134\n",
      "[7066]\ttraining's auc: 0.987121\ttraining's binary_logloss: 0.123122\n",
      "[7067]\ttraining's auc: 0.987127\ttraining's binary_logloss: 0.123113\n",
      "[7068]\ttraining's auc: 0.987132\ttraining's binary_logloss: 0.123101\n",
      "[7069]\ttraining's auc: 0.987138\ttraining's binary_logloss: 0.123088\n",
      "[7070]\ttraining's auc: 0.987146\ttraining's binary_logloss: 0.123073\n",
      "[7071]\ttraining's auc: 0.987149\ttraining's binary_logloss: 0.123062\n",
      "[7072]\ttraining's auc: 0.987154\ttraining's binary_logloss: 0.123058\n",
      "[7073]\ttraining's auc: 0.987164\ttraining's binary_logloss: 0.123048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7074]\ttraining's auc: 0.987172\ttraining's binary_logloss: 0.123034\n",
      "[7075]\ttraining's auc: 0.987175\ttraining's binary_logloss: 0.123024\n",
      "[7076]\ttraining's auc: 0.987184\ttraining's binary_logloss: 0.123011\n",
      "[7077]\ttraining's auc: 0.987188\ttraining's binary_logloss: 0.123002\n",
      "[7078]\ttraining's auc: 0.987191\ttraining's binary_logloss: 0.122993\n",
      "[7079]\ttraining's auc: 0.987198\ttraining's binary_logloss: 0.122982\n",
      "[7080]\ttraining's auc: 0.987199\ttraining's binary_logloss: 0.12298\n",
      "[7081]\ttraining's auc: 0.987203\ttraining's binary_logloss: 0.122969\n",
      "[7082]\ttraining's auc: 0.987208\ttraining's binary_logloss: 0.122961\n",
      "[7083]\ttraining's auc: 0.987216\ttraining's binary_logloss: 0.122947\n",
      "[7084]\ttraining's auc: 0.987221\ttraining's binary_logloss: 0.122936\n",
      "[7085]\ttraining's auc: 0.987226\ttraining's binary_logloss: 0.122925\n",
      "[7086]\ttraining's auc: 0.987229\ttraining's binary_logloss: 0.122915\n",
      "[7087]\ttraining's auc: 0.987236\ttraining's binary_logloss: 0.122903\n",
      "[7088]\ttraining's auc: 0.987241\ttraining's binary_logloss: 0.122892\n",
      "[7089]\ttraining's auc: 0.987247\ttraining's binary_logloss: 0.12288\n",
      "[7090]\ttraining's auc: 0.987254\ttraining's binary_logloss: 0.122871\n",
      "[7091]\ttraining's auc: 0.98726\ttraining's binary_logloss: 0.122858\n",
      "[7092]\ttraining's auc: 0.98726\ttraining's binary_logloss: 0.122856\n",
      "[7093]\ttraining's auc: 0.987266\ttraining's binary_logloss: 0.122848\n",
      "[7094]\ttraining's auc: 0.987269\ttraining's binary_logloss: 0.122843\n",
      "[7095]\ttraining's auc: 0.987269\ttraining's binary_logloss: 0.12284\n",
      "[7096]\ttraining's auc: 0.987276\ttraining's binary_logloss: 0.122829\n",
      "[7097]\ttraining's auc: 0.987276\ttraining's binary_logloss: 0.122827\n",
      "[7098]\ttraining's auc: 0.987283\ttraining's binary_logloss: 0.122817\n",
      "[7099]\ttraining's auc: 0.98729\ttraining's binary_logloss: 0.122807\n",
      "[7100]\ttraining's auc: 0.987295\ttraining's binary_logloss: 0.122797\n",
      "[7101]\ttraining's auc: 0.987303\ttraining's binary_logloss: 0.122783\n",
      "[7102]\ttraining's auc: 0.987307\ttraining's binary_logloss: 0.122775\n",
      "[7103]\ttraining's auc: 0.987309\ttraining's binary_logloss: 0.122764\n",
      "[7104]\ttraining's auc: 0.987318\ttraining's binary_logloss: 0.12275\n",
      "[7105]\ttraining's auc: 0.987326\ttraining's binary_logloss: 0.12274\n",
      "[7106]\ttraining's auc: 0.987332\ttraining's binary_logloss: 0.122728\n",
      "[7107]\ttraining's auc: 0.987338\ttraining's binary_logloss: 0.122719\n",
      "[7108]\ttraining's auc: 0.987343\ttraining's binary_logloss: 0.12271\n",
      "[7109]\ttraining's auc: 0.98735\ttraining's binary_logloss: 0.122698\n",
      "[7110]\ttraining's auc: 0.987353\ttraining's binary_logloss: 0.122695\n",
      "[7111]\ttraining's auc: 0.987358\ttraining's binary_logloss: 0.122683\n",
      "[7112]\ttraining's auc: 0.987361\ttraining's binary_logloss: 0.12268\n",
      "[7113]\ttraining's auc: 0.987367\ttraining's binary_logloss: 0.12267\n",
      "[7114]\ttraining's auc: 0.987367\ttraining's binary_logloss: 0.122668\n",
      "[7115]\ttraining's auc: 0.987373\ttraining's binary_logloss: 0.122656\n",
      "[7116]\ttraining's auc: 0.987376\ttraining's binary_logloss: 0.122647\n",
      "[7117]\ttraining's auc: 0.987383\ttraining's binary_logloss: 0.122636\n",
      "[7118]\ttraining's auc: 0.98739\ttraining's binary_logloss: 0.122625\n",
      "[7119]\ttraining's auc: 0.987399\ttraining's binary_logloss: 0.122614\n",
      "[7120]\ttraining's auc: 0.987404\ttraining's binary_logloss: 0.122606\n",
      "[7121]\ttraining's auc: 0.987409\ttraining's binary_logloss: 0.122594\n",
      "[7122]\ttraining's auc: 0.987416\ttraining's binary_logloss: 0.122582\n",
      "[7123]\ttraining's auc: 0.987417\ttraining's binary_logloss: 0.122572\n",
      "[7124]\ttraining's auc: 0.987421\ttraining's binary_logloss: 0.122564\n",
      "[7125]\ttraining's auc: 0.987428\ttraining's binary_logloss: 0.122554\n",
      "[7126]\ttraining's auc: 0.987437\ttraining's binary_logloss: 0.122543\n",
      "[7127]\ttraining's auc: 0.98744\ttraining's binary_logloss: 0.122532\n",
      "[7128]\ttraining's auc: 0.987446\ttraining's binary_logloss: 0.122521\n",
      "[7129]\ttraining's auc: 0.987452\ttraining's binary_logloss: 0.122509\n",
      "[7130]\ttraining's auc: 0.987461\ttraining's binary_logloss: 0.122497\n",
      "[7131]\ttraining's auc: 0.987463\ttraining's binary_logloss: 0.122493\n",
      "[7132]\ttraining's auc: 0.987468\ttraining's binary_logloss: 0.122482\n",
      "[7133]\ttraining's auc: 0.987473\ttraining's binary_logloss: 0.122469\n",
      "[7134]\ttraining's auc: 0.987481\ttraining's binary_logloss: 0.122457\n",
      "[7135]\ttraining's auc: 0.987488\ttraining's binary_logloss: 0.122444\n",
      "[7136]\ttraining's auc: 0.987495\ttraining's binary_logloss: 0.122431\n",
      "[7137]\ttraining's auc: 0.987504\ttraining's binary_logloss: 0.122418\n",
      "[7138]\ttraining's auc: 0.98751\ttraining's binary_logloss: 0.122408\n",
      "[7139]\ttraining's auc: 0.987515\ttraining's binary_logloss: 0.122396\n",
      "[7140]\ttraining's auc: 0.98752\ttraining's binary_logloss: 0.122384\n",
      "[7141]\ttraining's auc: 0.987526\ttraining's binary_logloss: 0.122371\n",
      "[7142]\ttraining's auc: 0.987533\ttraining's binary_logloss: 0.122359\n",
      "[7143]\ttraining's auc: 0.987539\ttraining's binary_logloss: 0.122348\n",
      "[7144]\ttraining's auc: 0.987544\ttraining's binary_logloss: 0.122335\n",
      "[7145]\ttraining's auc: 0.98755\ttraining's binary_logloss: 0.122325\n",
      "[7146]\ttraining's auc: 0.987556\ttraining's binary_logloss: 0.122316\n",
      "[7147]\ttraining's auc: 0.987563\ttraining's binary_logloss: 0.122304\n",
      "[7148]\ttraining's auc: 0.98757\ttraining's binary_logloss: 0.122292\n",
      "[7149]\ttraining's auc: 0.987574\ttraining's binary_logloss: 0.122282\n",
      "[7150]\ttraining's auc: 0.987577\ttraining's binary_logloss: 0.122271\n",
      "[7151]\ttraining's auc: 0.987584\ttraining's binary_logloss: 0.12226\n",
      "[7152]\ttraining's auc: 0.987585\ttraining's binary_logloss: 0.122258\n",
      "[7153]\ttraining's auc: 0.987588\ttraining's binary_logloss: 0.122248\n",
      "[7154]\ttraining's auc: 0.987593\ttraining's binary_logloss: 0.122237\n",
      "[7155]\ttraining's auc: 0.987597\ttraining's binary_logloss: 0.122224\n",
      "[7156]\ttraining's auc: 0.987605\ttraining's binary_logloss: 0.122211\n",
      "[7157]\ttraining's auc: 0.987613\ttraining's binary_logloss: 0.1222\n",
      "[7158]\ttraining's auc: 0.987619\ttraining's binary_logloss: 0.122186\n",
      "[7159]\ttraining's auc: 0.987624\ttraining's binary_logloss: 0.122176\n",
      "[7160]\ttraining's auc: 0.987628\ttraining's binary_logloss: 0.122165\n",
      "[7161]\ttraining's auc: 0.987635\ttraining's binary_logloss: 0.122154\n",
      "[7162]\ttraining's auc: 0.987642\ttraining's binary_logloss: 0.122142\n",
      "[7163]\ttraining's auc: 0.987647\ttraining's binary_logloss: 0.122131\n",
      "[7164]\ttraining's auc: 0.987653\ttraining's binary_logloss: 0.122122\n",
      "[7165]\ttraining's auc: 0.987661\ttraining's binary_logloss: 0.122107\n",
      "[7166]\ttraining's auc: 0.987665\ttraining's binary_logloss: 0.122095\n",
      "[7167]\ttraining's auc: 0.987673\ttraining's binary_logloss: 0.122083\n",
      "[7168]\ttraining's auc: 0.98768\ttraining's binary_logloss: 0.12207\n",
      "[7169]\ttraining's auc: 0.98768\ttraining's binary_logloss: 0.122068\n",
      "[7170]\ttraining's auc: 0.987689\ttraining's binary_logloss: 0.122056\n",
      "[7171]\ttraining's auc: 0.987694\ttraining's binary_logloss: 0.122045\n",
      "[7172]\ttraining's auc: 0.9877\ttraining's binary_logloss: 0.122034\n",
      "[7173]\ttraining's auc: 0.987708\ttraining's binary_logloss: 0.122024\n",
      "[7174]\ttraining's auc: 0.987713\ttraining's binary_logloss: 0.122013\n",
      "[7175]\ttraining's auc: 0.987717\ttraining's binary_logloss: 0.122004\n",
      "[7176]\ttraining's auc: 0.987723\ttraining's binary_logloss: 0.121993\n",
      "[7177]\ttraining's auc: 0.987727\ttraining's binary_logloss: 0.12198\n",
      "[7178]\ttraining's auc: 0.98773\ttraining's binary_logloss: 0.121974\n",
      "[7179]\ttraining's auc: 0.987734\ttraining's binary_logloss: 0.121963\n",
      "[7180]\ttraining's auc: 0.987738\ttraining's binary_logloss: 0.121951\n",
      "[7181]\ttraining's auc: 0.987743\ttraining's binary_logloss: 0.12194\n",
      "[7182]\ttraining's auc: 0.987754\ttraining's binary_logloss: 0.121927\n",
      "[7183]\ttraining's auc: 0.987761\ttraining's binary_logloss: 0.121915\n",
      "[7184]\ttraining's auc: 0.987768\ttraining's binary_logloss: 0.121903\n",
      "[7185]\ttraining's auc: 0.987773\ttraining's binary_logloss: 0.12189\n",
      "[7186]\ttraining's auc: 0.987782\ttraining's binary_logloss: 0.121876\n",
      "[7187]\ttraining's auc: 0.987783\ttraining's binary_logloss: 0.121868\n",
      "[7188]\ttraining's auc: 0.987784\ttraining's binary_logloss: 0.121864\n",
      "[7189]\ttraining's auc: 0.98779\ttraining's binary_logloss: 0.121853\n",
      "[7190]\ttraining's auc: 0.987795\ttraining's binary_logloss: 0.121841\n",
      "[7191]\ttraining's auc: 0.987798\ttraining's binary_logloss: 0.121838\n",
      "[7192]\ttraining's auc: 0.987804\ttraining's binary_logloss: 0.121826\n",
      "[7193]\ttraining's auc: 0.987808\ttraining's binary_logloss: 0.121817\n",
      "[7194]\ttraining's auc: 0.987815\ttraining's binary_logloss: 0.121804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7195]\ttraining's auc: 0.987821\ttraining's binary_logloss: 0.121791\n",
      "[7196]\ttraining's auc: 0.987828\ttraining's binary_logloss: 0.12178\n",
      "[7197]\ttraining's auc: 0.987832\ttraining's binary_logloss: 0.121768\n",
      "[7198]\ttraining's auc: 0.98784\ttraining's binary_logloss: 0.121754\n",
      "[7199]\ttraining's auc: 0.987846\ttraining's binary_logloss: 0.121744\n",
      "[7200]\ttraining's auc: 0.987848\ttraining's binary_logloss: 0.121739\n",
      "[7201]\ttraining's auc: 0.987855\ttraining's binary_logloss: 0.121728\n",
      "[7202]\ttraining's auc: 0.987861\ttraining's binary_logloss: 0.121717\n",
      "[7203]\ttraining's auc: 0.987868\ttraining's binary_logloss: 0.121704\n",
      "[7204]\ttraining's auc: 0.987874\ttraining's binary_logloss: 0.121692\n",
      "[7205]\ttraining's auc: 0.987878\ttraining's binary_logloss: 0.121681\n",
      "[7206]\ttraining's auc: 0.987884\ttraining's binary_logloss: 0.12167\n",
      "[7207]\ttraining's auc: 0.987892\ttraining's binary_logloss: 0.121657\n",
      "[7208]\ttraining's auc: 0.987899\ttraining's binary_logloss: 0.121646\n",
      "[7209]\ttraining's auc: 0.987901\ttraining's binary_logloss: 0.121643\n",
      "[7210]\ttraining's auc: 0.987905\ttraining's binary_logloss: 0.121633\n",
      "[7211]\ttraining's auc: 0.987911\ttraining's binary_logloss: 0.12162\n",
      "[7212]\ttraining's auc: 0.987918\ttraining's binary_logloss: 0.121609\n",
      "[7213]\ttraining's auc: 0.987925\ttraining's binary_logloss: 0.121598\n",
      "[7214]\ttraining's auc: 0.987928\ttraining's binary_logloss: 0.121588\n",
      "[7215]\ttraining's auc: 0.987934\ttraining's binary_logloss: 0.121577\n",
      "[7216]\ttraining's auc: 0.987937\ttraining's binary_logloss: 0.121575\n",
      "[7217]\ttraining's auc: 0.987942\ttraining's binary_logloss: 0.121565\n",
      "[7218]\ttraining's auc: 0.987948\ttraining's binary_logloss: 0.121553\n",
      "[7219]\ttraining's auc: 0.987955\ttraining's binary_logloss: 0.12154\n",
      "[7220]\ttraining's auc: 0.987964\ttraining's binary_logloss: 0.121527\n",
      "[7221]\ttraining's auc: 0.987971\ttraining's binary_logloss: 0.121515\n",
      "[7222]\ttraining's auc: 0.987972\ttraining's binary_logloss: 0.121512\n",
      "[7223]\ttraining's auc: 0.98798\ttraining's binary_logloss: 0.121499\n",
      "[7224]\ttraining's auc: 0.987989\ttraining's binary_logloss: 0.121487\n",
      "[7225]\ttraining's auc: 0.987996\ttraining's binary_logloss: 0.121475\n",
      "[7226]\ttraining's auc: 0.987997\ttraining's binary_logloss: 0.121472\n",
      "[7227]\ttraining's auc: 0.988003\ttraining's binary_logloss: 0.12146\n",
      "[7228]\ttraining's auc: 0.988008\ttraining's binary_logloss: 0.121446\n",
      "[7229]\ttraining's auc: 0.988015\ttraining's binary_logloss: 0.121436\n",
      "[7230]\ttraining's auc: 0.988018\ttraining's binary_logloss: 0.12143\n",
      "[7231]\ttraining's auc: 0.988024\ttraining's binary_logloss: 0.121418\n",
      "[7232]\ttraining's auc: 0.988029\ttraining's binary_logloss: 0.121408\n",
      "[7233]\ttraining's auc: 0.988036\ttraining's binary_logloss: 0.121397\n",
      "[7234]\ttraining's auc: 0.98804\ttraining's binary_logloss: 0.121386\n",
      "[7235]\ttraining's auc: 0.988044\ttraining's binary_logloss: 0.121374\n",
      "[7236]\ttraining's auc: 0.988045\ttraining's binary_logloss: 0.12137\n",
      "[7237]\ttraining's auc: 0.988049\ttraining's binary_logloss: 0.12136\n",
      "[7238]\ttraining's auc: 0.988053\ttraining's binary_logloss: 0.121347\n",
      "[7239]\ttraining's auc: 0.988057\ttraining's binary_logloss: 0.121337\n",
      "[7240]\ttraining's auc: 0.988066\ttraining's binary_logloss: 0.121327\n",
      "[7241]\ttraining's auc: 0.988073\ttraining's binary_logloss: 0.121315\n",
      "[7242]\ttraining's auc: 0.988079\ttraining's binary_logloss: 0.121303\n",
      "[7243]\ttraining's auc: 0.988083\ttraining's binary_logloss: 0.121295\n",
      "[7244]\ttraining's auc: 0.988087\ttraining's binary_logloss: 0.121286\n",
      "[7245]\ttraining's auc: 0.988091\ttraining's binary_logloss: 0.121274\n",
      "[7246]\ttraining's auc: 0.988093\ttraining's binary_logloss: 0.121272\n",
      "[7247]\ttraining's auc: 0.988097\ttraining's binary_logloss: 0.121265\n",
      "[7248]\ttraining's auc: 0.9881\ttraining's binary_logloss: 0.121253\n",
      "[7249]\ttraining's auc: 0.988101\ttraining's binary_logloss: 0.121251\n",
      "[7250]\ttraining's auc: 0.988103\ttraining's binary_logloss: 0.121245\n",
      "[7251]\ttraining's auc: 0.988113\ttraining's binary_logloss: 0.121233\n",
      "[7252]\ttraining's auc: 0.988119\ttraining's binary_logloss: 0.12122\n",
      "[7253]\ttraining's auc: 0.988121\ttraining's binary_logloss: 0.121209\n",
      "[7254]\ttraining's auc: 0.988126\ttraining's binary_logloss: 0.121198\n",
      "[7255]\ttraining's auc: 0.988131\ttraining's binary_logloss: 0.121187\n",
      "[7256]\ttraining's auc: 0.988137\ttraining's binary_logloss: 0.121177\n",
      "[7257]\ttraining's auc: 0.98814\ttraining's binary_logloss: 0.121165\n",
      "[7258]\ttraining's auc: 0.988147\ttraining's binary_logloss: 0.121155\n",
      "[7259]\ttraining's auc: 0.988156\ttraining's binary_logloss: 0.121144\n",
      "[7260]\ttraining's auc: 0.988162\ttraining's binary_logloss: 0.121133\n",
      "[7261]\ttraining's auc: 0.988166\ttraining's binary_logloss: 0.121122\n",
      "[7262]\ttraining's auc: 0.988174\ttraining's binary_logloss: 0.121108\n",
      "[7263]\ttraining's auc: 0.988176\ttraining's binary_logloss: 0.121101\n",
      "[7264]\ttraining's auc: 0.988179\ttraining's binary_logloss: 0.121094\n",
      "[7265]\ttraining's auc: 0.988185\ttraining's binary_logloss: 0.121082\n",
      "[7266]\ttraining's auc: 0.988196\ttraining's binary_logloss: 0.121069\n",
      "[7267]\ttraining's auc: 0.988202\ttraining's binary_logloss: 0.121056\n",
      "[7268]\ttraining's auc: 0.988207\ttraining's binary_logloss: 0.121044\n",
      "[7269]\ttraining's auc: 0.988214\ttraining's binary_logloss: 0.121032\n",
      "[7270]\ttraining's auc: 0.988221\ttraining's binary_logloss: 0.12102\n",
      "[7271]\ttraining's auc: 0.988228\ttraining's binary_logloss: 0.121008\n",
      "[7272]\ttraining's auc: 0.988234\ttraining's binary_logloss: 0.120997\n",
      "[7273]\ttraining's auc: 0.988239\ttraining's binary_logloss: 0.120985\n",
      "[7274]\ttraining's auc: 0.988244\ttraining's binary_logloss: 0.120974\n",
      "[7275]\ttraining's auc: 0.988246\ttraining's binary_logloss: 0.120968\n",
      "[7276]\ttraining's auc: 0.988255\ttraining's binary_logloss: 0.120954\n",
      "[7277]\ttraining's auc: 0.988262\ttraining's binary_logloss: 0.120941\n",
      "[7278]\ttraining's auc: 0.988265\ttraining's binary_logloss: 0.120933\n",
      "[7279]\ttraining's auc: 0.98827\ttraining's binary_logloss: 0.120922\n",
      "[7280]\ttraining's auc: 0.988277\ttraining's binary_logloss: 0.120911\n",
      "[7281]\ttraining's auc: 0.988285\ttraining's binary_logloss: 0.120898\n",
      "[7282]\ttraining's auc: 0.988292\ttraining's binary_logloss: 0.120888\n",
      "[7283]\ttraining's auc: 0.988294\ttraining's binary_logloss: 0.120881\n",
      "[7284]\ttraining's auc: 0.988297\ttraining's binary_logloss: 0.120878\n",
      "[7285]\ttraining's auc: 0.988304\ttraining's binary_logloss: 0.120867\n",
      "[7286]\ttraining's auc: 0.988308\ttraining's binary_logloss: 0.120856\n",
      "[7287]\ttraining's auc: 0.988314\ttraining's binary_logloss: 0.120845\n",
      "[7288]\ttraining's auc: 0.98832\ttraining's binary_logloss: 0.120835\n",
      "[7289]\ttraining's auc: 0.988326\ttraining's binary_logloss: 0.120824\n",
      "[7290]\ttraining's auc: 0.988329\ttraining's binary_logloss: 0.120813\n",
      "[7291]\ttraining's auc: 0.988331\ttraining's binary_logloss: 0.120803\n",
      "[7292]\ttraining's auc: 0.988336\ttraining's binary_logloss: 0.120792\n",
      "[7293]\ttraining's auc: 0.988342\ttraining's binary_logloss: 0.12078\n",
      "[7294]\ttraining's auc: 0.988348\ttraining's binary_logloss: 0.120768\n",
      "[7295]\ttraining's auc: 0.988349\ttraining's binary_logloss: 0.120764\n",
      "[7296]\ttraining's auc: 0.988355\ttraining's binary_logloss: 0.120752\n",
      "[7297]\ttraining's auc: 0.98836\ttraining's binary_logloss: 0.120741\n",
      "[7298]\ttraining's auc: 0.988369\ttraining's binary_logloss: 0.120728\n",
      "[7299]\ttraining's auc: 0.988375\ttraining's binary_logloss: 0.120717\n",
      "[7300]\ttraining's auc: 0.988379\ttraining's binary_logloss: 0.120705\n",
      "[7301]\ttraining's auc: 0.988383\ttraining's binary_logloss: 0.120697\n",
      "[7302]\ttraining's auc: 0.988386\ttraining's binary_logloss: 0.12069\n",
      "[7303]\ttraining's auc: 0.988394\ttraining's binary_logloss: 0.120678\n",
      "[7304]\ttraining's auc: 0.988398\ttraining's binary_logloss: 0.120667\n",
      "[7305]\ttraining's auc: 0.988402\ttraining's binary_logloss: 0.120659\n",
      "[7306]\ttraining's auc: 0.988408\ttraining's binary_logloss: 0.120648\n",
      "[7307]\ttraining's auc: 0.988411\ttraining's binary_logloss: 0.120642\n",
      "[7308]\ttraining's auc: 0.988417\ttraining's binary_logloss: 0.120632\n",
      "[7309]\ttraining's auc: 0.98842\ttraining's binary_logloss: 0.120621\n",
      "[7310]\ttraining's auc: 0.988424\ttraining's binary_logloss: 0.120611\n",
      "[7311]\ttraining's auc: 0.988426\ttraining's binary_logloss: 0.120604\n",
      "[7312]\ttraining's auc: 0.988435\ttraining's binary_logloss: 0.120592\n",
      "[7313]\ttraining's auc: 0.98844\ttraining's binary_logloss: 0.120581\n",
      "[7314]\ttraining's auc: 0.988449\ttraining's binary_logloss: 0.120568\n",
      "[7315]\ttraining's auc: 0.988449\ttraining's binary_logloss: 0.120565\n",
      "[7316]\ttraining's auc: 0.988453\ttraining's binary_logloss: 0.120555\n",
      "[7317]\ttraining's auc: 0.988454\ttraining's binary_logloss: 0.120552\n",
      "[7318]\ttraining's auc: 0.988457\ttraining's binary_logloss: 0.120545\n",
      "[7319]\ttraining's auc: 0.988463\ttraining's binary_logloss: 0.120535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7320]\ttraining's auc: 0.988468\ttraining's binary_logloss: 0.120523\n",
      "[7321]\ttraining's auc: 0.988475\ttraining's binary_logloss: 0.120511\n",
      "[7322]\ttraining's auc: 0.988477\ttraining's binary_logloss: 0.120506\n",
      "[7323]\ttraining's auc: 0.988485\ttraining's binary_logloss: 0.120495\n",
      "[7324]\ttraining's auc: 0.988488\ttraining's binary_logloss: 0.120485\n",
      "[7325]\ttraining's auc: 0.98849\ttraining's binary_logloss: 0.120473\n",
      "[7326]\ttraining's auc: 0.988493\ttraining's binary_logloss: 0.120468\n",
      "[7327]\ttraining's auc: 0.988496\ttraining's binary_logloss: 0.120462\n",
      "[7328]\ttraining's auc: 0.988499\ttraining's binary_logloss: 0.120452\n",
      "[7329]\ttraining's auc: 0.9885\ttraining's binary_logloss: 0.120447\n",
      "[7330]\ttraining's auc: 0.988504\ttraining's binary_logloss: 0.120437\n",
      "[7331]\ttraining's auc: 0.988509\ttraining's binary_logloss: 0.120427\n",
      "[7332]\ttraining's auc: 0.988516\ttraining's binary_logloss: 0.120416\n",
      "[7333]\ttraining's auc: 0.988523\ttraining's binary_logloss: 0.120405\n",
      "[7334]\ttraining's auc: 0.988527\ttraining's binary_logloss: 0.120395\n",
      "[7335]\ttraining's auc: 0.988534\ttraining's binary_logloss: 0.120383\n",
      "[7336]\ttraining's auc: 0.988538\ttraining's binary_logloss: 0.120373\n",
      "[7337]\ttraining's auc: 0.988546\ttraining's binary_logloss: 0.120362\n",
      "[7338]\ttraining's auc: 0.988551\ttraining's binary_logloss: 0.120351\n",
      "[7339]\ttraining's auc: 0.988559\ttraining's binary_logloss: 0.120341\n",
      "[7340]\ttraining's auc: 0.988565\ttraining's binary_logloss: 0.120331\n",
      "[7341]\ttraining's auc: 0.988567\ttraining's binary_logloss: 0.120327\n",
      "[7342]\ttraining's auc: 0.988572\ttraining's binary_logloss: 0.120316\n",
      "[7343]\ttraining's auc: 0.988575\ttraining's binary_logloss: 0.120309\n",
      "[7344]\ttraining's auc: 0.988582\ttraining's binary_logloss: 0.120297\n",
      "[7345]\ttraining's auc: 0.988588\ttraining's binary_logloss: 0.120284\n",
      "[7346]\ttraining's auc: 0.988589\ttraining's binary_logloss: 0.120283\n",
      "[7347]\ttraining's auc: 0.988596\ttraining's binary_logloss: 0.120271\n",
      "[7348]\ttraining's auc: 0.988596\ttraining's binary_logloss: 0.120268\n",
      "[7349]\ttraining's auc: 0.988605\ttraining's binary_logloss: 0.120256\n",
      "[7350]\ttraining's auc: 0.988613\ttraining's binary_logloss: 0.120245\n",
      "[7351]\ttraining's auc: 0.98862\ttraining's binary_logloss: 0.120235\n",
      "[7352]\ttraining's auc: 0.988626\ttraining's binary_logloss: 0.120224\n",
      "[7353]\ttraining's auc: 0.988629\ttraining's binary_logloss: 0.120213\n",
      "[7354]\ttraining's auc: 0.988629\ttraining's binary_logloss: 0.120209\n",
      "[7355]\ttraining's auc: 0.988631\ttraining's binary_logloss: 0.120207\n",
      "[7356]\ttraining's auc: 0.988632\ttraining's binary_logloss: 0.120204\n",
      "[7357]\ttraining's auc: 0.988635\ttraining's binary_logloss: 0.120198\n",
      "[7358]\ttraining's auc: 0.98864\ttraining's binary_logloss: 0.120187\n",
      "[7359]\ttraining's auc: 0.988642\ttraining's binary_logloss: 0.120183\n",
      "[7360]\ttraining's auc: 0.98865\ttraining's binary_logloss: 0.120172\n",
      "[7361]\ttraining's auc: 0.988654\ttraining's binary_logloss: 0.120161\n",
      "[7362]\ttraining's auc: 0.988658\ttraining's binary_logloss: 0.120149\n",
      "[7363]\ttraining's auc: 0.988662\ttraining's binary_logloss: 0.12014\n",
      "[7364]\ttraining's auc: 0.988668\ttraining's binary_logloss: 0.120131\n",
      "[7365]\ttraining's auc: 0.988672\ttraining's binary_logloss: 0.120121\n",
      "[7366]\ttraining's auc: 0.988679\ttraining's binary_logloss: 0.12011\n",
      "[7367]\ttraining's auc: 0.988683\ttraining's binary_logloss: 0.1201\n",
      "[7368]\ttraining's auc: 0.988687\ttraining's binary_logloss: 0.120092\n",
      "[7369]\ttraining's auc: 0.98869\ttraining's binary_logloss: 0.120081\n",
      "[7370]\ttraining's auc: 0.988691\ttraining's binary_logloss: 0.120076\n",
      "[7371]\ttraining's auc: 0.988694\ttraining's binary_logloss: 0.120072\n",
      "[7372]\ttraining's auc: 0.988701\ttraining's binary_logloss: 0.120061\n",
      "[7373]\ttraining's auc: 0.988705\ttraining's binary_logloss: 0.120053\n",
      "[7374]\ttraining's auc: 0.98871\ttraining's binary_logloss: 0.120041\n",
      "[7375]\ttraining's auc: 0.988714\ttraining's binary_logloss: 0.120033\n",
      "[7376]\ttraining's auc: 0.98872\ttraining's binary_logloss: 0.12002\n",
      "[7377]\ttraining's auc: 0.988723\ttraining's binary_logloss: 0.120014\n",
      "[7378]\ttraining's auc: 0.988731\ttraining's binary_logloss: 0.120002\n",
      "[7379]\ttraining's auc: 0.988734\ttraining's binary_logloss: 0.119996\n",
      "[7380]\ttraining's auc: 0.988734\ttraining's binary_logloss: 0.119995\n",
      "[7381]\ttraining's auc: 0.988737\ttraining's binary_logloss: 0.119986\n",
      "[7382]\ttraining's auc: 0.988741\ttraining's binary_logloss: 0.119975\n",
      "[7383]\ttraining's auc: 0.988746\ttraining's binary_logloss: 0.119969\n",
      "[7384]\ttraining's auc: 0.98875\ttraining's binary_logloss: 0.119961\n",
      "[7385]\ttraining's auc: 0.988757\ttraining's binary_logloss: 0.119949\n",
      "[7386]\ttraining's auc: 0.988762\ttraining's binary_logloss: 0.119937\n",
      "[7387]\ttraining's auc: 0.988767\ttraining's binary_logloss: 0.119927\n",
      "[7388]\ttraining's auc: 0.988773\ttraining's binary_logloss: 0.119915\n",
      "[7389]\ttraining's auc: 0.988778\ttraining's binary_logloss: 0.119905\n",
      "[7390]\ttraining's auc: 0.988784\ttraining's binary_logloss: 0.119894\n",
      "[7391]\ttraining's auc: 0.988789\ttraining's binary_logloss: 0.119884\n",
      "[7392]\ttraining's auc: 0.988791\ttraining's binary_logloss: 0.11988\n",
      "[7393]\ttraining's auc: 0.988793\ttraining's binary_logloss: 0.119877\n",
      "[7394]\ttraining's auc: 0.988796\ttraining's binary_logloss: 0.119867\n",
      "[7395]\ttraining's auc: 0.988802\ttraining's binary_logloss: 0.119857\n",
      "[7396]\ttraining's auc: 0.988807\ttraining's binary_logloss: 0.119845\n",
      "[7397]\ttraining's auc: 0.988809\ttraining's binary_logloss: 0.11984\n",
      "[7398]\ttraining's auc: 0.988809\ttraining's binary_logloss: 0.119839\n",
      "[7399]\ttraining's auc: 0.988814\ttraining's binary_logloss: 0.119829\n",
      "[7400]\ttraining's auc: 0.988817\ttraining's binary_logloss: 0.119817\n",
      "[7401]\ttraining's auc: 0.988817\ttraining's binary_logloss: 0.119815\n",
      "[7402]\ttraining's auc: 0.988822\ttraining's binary_logloss: 0.119804\n",
      "[7403]\ttraining's auc: 0.988825\ttraining's binary_logloss: 0.119799\n",
      "[7404]\ttraining's auc: 0.988832\ttraining's binary_logloss: 0.119788\n",
      "[7405]\ttraining's auc: 0.988834\ttraining's binary_logloss: 0.119786\n",
      "[7406]\ttraining's auc: 0.988843\ttraining's binary_logloss: 0.119774\n",
      "[7407]\ttraining's auc: 0.988845\ttraining's binary_logloss: 0.119767\n",
      "[7408]\ttraining's auc: 0.988848\ttraining's binary_logloss: 0.119756\n",
      "[7409]\ttraining's auc: 0.988852\ttraining's binary_logloss: 0.119744\n",
      "[7410]\ttraining's auc: 0.988855\ttraining's binary_logloss: 0.119738\n",
      "[7411]\ttraining's auc: 0.988858\ttraining's binary_logloss: 0.119733\n",
      "[7412]\ttraining's auc: 0.988861\ttraining's binary_logloss: 0.119724\n",
      "[7413]\ttraining's auc: 0.988863\ttraining's binary_logloss: 0.11972\n",
      "[7414]\ttraining's auc: 0.988868\ttraining's binary_logloss: 0.119709\n",
      "[7415]\ttraining's auc: 0.988873\ttraining's binary_logloss: 0.119699\n",
      "[7416]\ttraining's auc: 0.988878\ttraining's binary_logloss: 0.119689\n",
      "[7417]\ttraining's auc: 0.988882\ttraining's binary_logloss: 0.119678\n",
      "[7418]\ttraining's auc: 0.988886\ttraining's binary_logloss: 0.119669\n",
      "[7419]\ttraining's auc: 0.98889\ttraining's binary_logloss: 0.119657\n",
      "[7420]\ttraining's auc: 0.988894\ttraining's binary_logloss: 0.119647\n",
      "[7421]\ttraining's auc: 0.988898\ttraining's binary_logloss: 0.119637\n",
      "[7422]\ttraining's auc: 0.9889\ttraining's binary_logloss: 0.119629\n",
      "[7423]\ttraining's auc: 0.988904\ttraining's binary_logloss: 0.119617\n",
      "[7424]\ttraining's auc: 0.988907\ttraining's binary_logloss: 0.119607\n",
      "[7425]\ttraining's auc: 0.988913\ttraining's binary_logloss: 0.119596\n",
      "[7426]\ttraining's auc: 0.988918\ttraining's binary_logloss: 0.119584\n",
      "[7427]\ttraining's auc: 0.988926\ttraining's binary_logloss: 0.119571\n",
      "[7428]\ttraining's auc: 0.988928\ttraining's binary_logloss: 0.119564\n",
      "[7429]\ttraining's auc: 0.988933\ttraining's binary_logloss: 0.119555\n",
      "[7430]\ttraining's auc: 0.988936\ttraining's binary_logloss: 0.119544\n",
      "[7431]\ttraining's auc: 0.988943\ttraining's binary_logloss: 0.119532\n",
      "[7432]\ttraining's auc: 0.988951\ttraining's binary_logloss: 0.11952\n",
      "[7433]\ttraining's auc: 0.988955\ttraining's binary_logloss: 0.119512\n",
      "[7434]\ttraining's auc: 0.988958\ttraining's binary_logloss: 0.119501\n",
      "[7435]\ttraining's auc: 0.988961\ttraining's binary_logloss: 0.119495\n",
      "[7436]\ttraining's auc: 0.988967\ttraining's binary_logloss: 0.119484\n",
      "[7437]\ttraining's auc: 0.988974\ttraining's binary_logloss: 0.119472\n",
      "[7438]\ttraining's auc: 0.98898\ttraining's binary_logloss: 0.119461\n",
      "[7439]\ttraining's auc: 0.988988\ttraining's binary_logloss: 0.11945\n",
      "[7440]\ttraining's auc: 0.988992\ttraining's binary_logloss: 0.119443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7441]\ttraining's auc: 0.988995\ttraining's binary_logloss: 0.119433\n",
      "[7442]\ttraining's auc: 0.989003\ttraining's binary_logloss: 0.119422\n",
      "[7443]\ttraining's auc: 0.989006\ttraining's binary_logloss: 0.119412\n",
      "[7444]\ttraining's auc: 0.989011\ttraining's binary_logloss: 0.119401\n",
      "[7445]\ttraining's auc: 0.989013\ttraining's binary_logloss: 0.119395\n",
      "[7446]\ttraining's auc: 0.98902\ttraining's binary_logloss: 0.119385\n",
      "[7447]\ttraining's auc: 0.989024\ttraining's binary_logloss: 0.119379\n",
      "[7448]\ttraining's auc: 0.989026\ttraining's binary_logloss: 0.119374\n",
      "[7449]\ttraining's auc: 0.989035\ttraining's binary_logloss: 0.119358\n",
      "[7450]\ttraining's auc: 0.98904\ttraining's binary_logloss: 0.119353\n",
      "[7451]\ttraining's auc: 0.989046\ttraining's binary_logloss: 0.119339\n",
      "[7452]\ttraining's auc: 0.989047\ttraining's binary_logloss: 0.119337\n",
      "[7453]\ttraining's auc: 0.989053\ttraining's binary_logloss: 0.119325\n",
      "[7454]\ttraining's auc: 0.989056\ttraining's binary_logloss: 0.119319\n",
      "[7455]\ttraining's auc: 0.989057\ttraining's binary_logloss: 0.119317\n",
      "[7456]\ttraining's auc: 0.989062\ttraining's binary_logloss: 0.119306\n",
      "[7457]\ttraining's auc: 0.989065\ttraining's binary_logloss: 0.119297\n",
      "[7458]\ttraining's auc: 0.98907\ttraining's binary_logloss: 0.119286\n",
      "[7459]\ttraining's auc: 0.989077\ttraining's binary_logloss: 0.119273\n",
      "[7460]\ttraining's auc: 0.989081\ttraining's binary_logloss: 0.119262\n",
      "[7461]\ttraining's auc: 0.989088\ttraining's binary_logloss: 0.119251\n",
      "[7462]\ttraining's auc: 0.989094\ttraining's binary_logloss: 0.119239\n",
      "[7463]\ttraining's auc: 0.989095\ttraining's binary_logloss: 0.119236\n",
      "[7464]\ttraining's auc: 0.989099\ttraining's binary_logloss: 0.119227\n",
      "[7465]\ttraining's auc: 0.989103\ttraining's binary_logloss: 0.119219\n",
      "[7466]\ttraining's auc: 0.989109\ttraining's binary_logloss: 0.119206\n",
      "[7467]\ttraining's auc: 0.989118\ttraining's binary_logloss: 0.119192\n",
      "[7468]\ttraining's auc: 0.989124\ttraining's binary_logloss: 0.119181\n",
      "[7469]\ttraining's auc: 0.989127\ttraining's binary_logloss: 0.119172\n",
      "[7470]\ttraining's auc: 0.989131\ttraining's binary_logloss: 0.119161\n",
      "[7471]\ttraining's auc: 0.989134\ttraining's binary_logloss: 0.119149\n",
      "[7472]\ttraining's auc: 0.989139\ttraining's binary_logloss: 0.119139\n",
      "[7473]\ttraining's auc: 0.989145\ttraining's binary_logloss: 0.119127\n",
      "[7474]\ttraining's auc: 0.989148\ttraining's binary_logloss: 0.119116\n",
      "[7475]\ttraining's auc: 0.989154\ttraining's binary_logloss: 0.119105\n",
      "[7476]\ttraining's auc: 0.989161\ttraining's binary_logloss: 0.119093\n",
      "[7477]\ttraining's auc: 0.989168\ttraining's binary_logloss: 0.119081\n",
      "[7478]\ttraining's auc: 0.989171\ttraining's binary_logloss: 0.119072\n",
      "[7479]\ttraining's auc: 0.989175\ttraining's binary_logloss: 0.119061\n",
      "[7480]\ttraining's auc: 0.989179\ttraining's binary_logloss: 0.11905\n",
      "[7481]\ttraining's auc: 0.989183\ttraining's binary_logloss: 0.119041\n",
      "[7482]\ttraining's auc: 0.989187\ttraining's binary_logloss: 0.11903\n",
      "[7483]\ttraining's auc: 0.989193\ttraining's binary_logloss: 0.119019\n",
      "[7484]\ttraining's auc: 0.989197\ttraining's binary_logloss: 0.11901\n",
      "[7485]\ttraining's auc: 0.989199\ttraining's binary_logloss: 0.119001\n",
      "[7486]\ttraining's auc: 0.989205\ttraining's binary_logloss: 0.118988\n",
      "[7487]\ttraining's auc: 0.989208\ttraining's binary_logloss: 0.118982\n",
      "[7488]\ttraining's auc: 0.989216\ttraining's binary_logloss: 0.11897\n",
      "[7489]\ttraining's auc: 0.989221\ttraining's binary_logloss: 0.11896\n",
      "[7490]\ttraining's auc: 0.989226\ttraining's binary_logloss: 0.118948\n",
      "[7491]\ttraining's auc: 0.989232\ttraining's binary_logloss: 0.118935\n",
      "[7492]\ttraining's auc: 0.98924\ttraining's binary_logloss: 0.118922\n",
      "[7493]\ttraining's auc: 0.989245\ttraining's binary_logloss: 0.118913\n",
      "[7494]\ttraining's auc: 0.989248\ttraining's binary_logloss: 0.1189\n",
      "[7495]\ttraining's auc: 0.989254\ttraining's binary_logloss: 0.118889\n",
      "[7496]\ttraining's auc: 0.989262\ttraining's binary_logloss: 0.118876\n",
      "[7497]\ttraining's auc: 0.989266\ttraining's binary_logloss: 0.118868\n",
      "[7498]\ttraining's auc: 0.989271\ttraining's binary_logloss: 0.118858\n",
      "[7499]\ttraining's auc: 0.989274\ttraining's binary_logloss: 0.118851\n",
      "[7500]\ttraining's auc: 0.98928\ttraining's binary_logloss: 0.118837\n",
      "[7501]\ttraining's auc: 0.989285\ttraining's binary_logloss: 0.118823\n",
      "[7502]\ttraining's auc: 0.989289\ttraining's binary_logloss: 0.118813\n",
      "[7503]\ttraining's auc: 0.989295\ttraining's binary_logloss: 0.118802\n",
      "[7504]\ttraining's auc: 0.9893\ttraining's binary_logloss: 0.118789\n",
      "[7505]\ttraining's auc: 0.989304\ttraining's binary_logloss: 0.118781\n",
      "[7506]\ttraining's auc: 0.989304\ttraining's binary_logloss: 0.11878\n",
      "[7507]\ttraining's auc: 0.989308\ttraining's binary_logloss: 0.118768\n",
      "[7508]\ttraining's auc: 0.989312\ttraining's binary_logloss: 0.118758\n",
      "[7509]\ttraining's auc: 0.989321\ttraining's binary_logloss: 0.118746\n",
      "[7510]\ttraining's auc: 0.989326\ttraining's binary_logloss: 0.118736\n",
      "[7511]\ttraining's auc: 0.989332\ttraining's binary_logloss: 0.118726\n",
      "[7512]\ttraining's auc: 0.989338\ttraining's binary_logloss: 0.118713\n",
      "[7513]\ttraining's auc: 0.989342\ttraining's binary_logloss: 0.118706\n",
      "[7514]\ttraining's auc: 0.989345\ttraining's binary_logloss: 0.118695\n",
      "[7515]\ttraining's auc: 0.98935\ttraining's binary_logloss: 0.118685\n",
      "[7516]\ttraining's auc: 0.989355\ttraining's binary_logloss: 0.118675\n",
      "[7517]\ttraining's auc: 0.989361\ttraining's binary_logloss: 0.118667\n",
      "[7518]\ttraining's auc: 0.989364\ttraining's binary_logloss: 0.118656\n",
      "[7519]\ttraining's auc: 0.989369\ttraining's binary_logloss: 0.118646\n",
      "[7520]\ttraining's auc: 0.989373\ttraining's binary_logloss: 0.118635\n",
      "[7521]\ttraining's auc: 0.989375\ttraining's binary_logloss: 0.11863\n",
      "[7522]\ttraining's auc: 0.98938\ttraining's binary_logloss: 0.118618\n",
      "[7523]\ttraining's auc: 0.989381\ttraining's binary_logloss: 0.118612\n",
      "[7524]\ttraining's auc: 0.989383\ttraining's binary_logloss: 0.11861\n",
      "[7525]\ttraining's auc: 0.989384\ttraining's binary_logloss: 0.118608\n",
      "[7526]\ttraining's auc: 0.989387\ttraining's binary_logloss: 0.118599\n",
      "[7527]\ttraining's auc: 0.989392\ttraining's binary_logloss: 0.118587\n",
      "[7528]\ttraining's auc: 0.989397\ttraining's binary_logloss: 0.118577\n",
      "[7529]\ttraining's auc: 0.989401\ttraining's binary_logloss: 0.118565\n",
      "[7530]\ttraining's auc: 0.989403\ttraining's binary_logloss: 0.118557\n",
      "[7531]\ttraining's auc: 0.989407\ttraining's binary_logloss: 0.118546\n",
      "[7532]\ttraining's auc: 0.989412\ttraining's binary_logloss: 0.118537\n",
      "[7533]\ttraining's auc: 0.989418\ttraining's binary_logloss: 0.118525\n",
      "[7534]\ttraining's auc: 0.989422\ttraining's binary_logloss: 0.118512\n",
      "[7535]\ttraining's auc: 0.989427\ttraining's binary_logloss: 0.118504\n",
      "[7536]\ttraining's auc: 0.989437\ttraining's binary_logloss: 0.118493\n",
      "[7537]\ttraining's auc: 0.989437\ttraining's binary_logloss: 0.118483\n",
      "[7538]\ttraining's auc: 0.989443\ttraining's binary_logloss: 0.118472\n",
      "[7539]\ttraining's auc: 0.98945\ttraining's binary_logloss: 0.118461\n",
      "[7540]\ttraining's auc: 0.989451\ttraining's binary_logloss: 0.118457\n",
      "[7541]\ttraining's auc: 0.989454\ttraining's binary_logloss: 0.118448\n",
      "[7542]\ttraining's auc: 0.989459\ttraining's binary_logloss: 0.118437\n",
      "[7543]\ttraining's auc: 0.989464\ttraining's binary_logloss: 0.11843\n",
      "[7544]\ttraining's auc: 0.989469\ttraining's binary_logloss: 0.11842\n",
      "[7545]\ttraining's auc: 0.989471\ttraining's binary_logloss: 0.118414\n",
      "[7546]\ttraining's auc: 0.989474\ttraining's binary_logloss: 0.118406\n",
      "[7547]\ttraining's auc: 0.989477\ttraining's binary_logloss: 0.118397\n",
      "[7548]\ttraining's auc: 0.989485\ttraining's binary_logloss: 0.118386\n",
      "[7549]\ttraining's auc: 0.989487\ttraining's binary_logloss: 0.118384\n",
      "[7550]\ttraining's auc: 0.989488\ttraining's binary_logloss: 0.118376\n",
      "[7551]\ttraining's auc: 0.98949\ttraining's binary_logloss: 0.118374\n",
      "[7552]\ttraining's auc: 0.989497\ttraining's binary_logloss: 0.118364\n",
      "[7553]\ttraining's auc: 0.989502\ttraining's binary_logloss: 0.11835\n",
      "[7554]\ttraining's auc: 0.989504\ttraining's binary_logloss: 0.118345\n",
      "[7555]\ttraining's auc: 0.989509\ttraining's binary_logloss: 0.118336\n",
      "[7556]\ttraining's auc: 0.989513\ttraining's binary_logloss: 0.118326\n",
      "[7557]\ttraining's auc: 0.989515\ttraining's binary_logloss: 0.118324\n",
      "[7558]\ttraining's auc: 0.989518\ttraining's binary_logloss: 0.118314\n",
      "[7559]\ttraining's auc: 0.98952\ttraining's binary_logloss: 0.118303\n",
      "[7560]\ttraining's auc: 0.989524\ttraining's binary_logloss: 0.118294\n",
      "[7561]\ttraining's auc: 0.989527\ttraining's binary_logloss: 0.118288\n",
      "[7562]\ttraining's auc: 0.98953\ttraining's binary_logloss: 0.118282\n",
      "[7563]\ttraining's auc: 0.989534\ttraining's binary_logloss: 0.118272\n",
      "[7564]\ttraining's auc: 0.989541\ttraining's binary_logloss: 0.11826\n",
      "[7565]\ttraining's auc: 0.989544\ttraining's binary_logloss: 0.118253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7566]\ttraining's auc: 0.989549\ttraining's binary_logloss: 0.11824\n",
      "[7567]\ttraining's auc: 0.989551\ttraining's binary_logloss: 0.118235\n",
      "[7568]\ttraining's auc: 0.989555\ttraining's binary_logloss: 0.118225\n",
      "[7569]\ttraining's auc: 0.98956\ttraining's binary_logloss: 0.118212\n",
      "[7570]\ttraining's auc: 0.989567\ttraining's binary_logloss: 0.118201\n",
      "[7571]\ttraining's auc: 0.989567\ttraining's binary_logloss: 0.118199\n",
      "[7572]\ttraining's auc: 0.989573\ttraining's binary_logloss: 0.118187\n",
      "[7573]\ttraining's auc: 0.989581\ttraining's binary_logloss: 0.118176\n",
      "[7574]\ttraining's auc: 0.989584\ttraining's binary_logloss: 0.118166\n",
      "[7575]\ttraining's auc: 0.989591\ttraining's binary_logloss: 0.118154\n",
      "[7576]\ttraining's auc: 0.989594\ttraining's binary_logloss: 0.118144\n",
      "[7577]\ttraining's auc: 0.989596\ttraining's binary_logloss: 0.118134\n",
      "[7578]\ttraining's auc: 0.989605\ttraining's binary_logloss: 0.118118\n",
      "[7579]\ttraining's auc: 0.989607\ttraining's binary_logloss: 0.118111\n",
      "[7580]\ttraining's auc: 0.989607\ttraining's binary_logloss: 0.118108\n",
      "[7581]\ttraining's auc: 0.989614\ttraining's binary_logloss: 0.118096\n",
      "[7582]\ttraining's auc: 0.989617\ttraining's binary_logloss: 0.118089\n",
      "[7583]\ttraining's auc: 0.989618\ttraining's binary_logloss: 0.118086\n",
      "[7584]\ttraining's auc: 0.989621\ttraining's binary_logloss: 0.118077\n",
      "[7585]\ttraining's auc: 0.989627\ttraining's binary_logloss: 0.11807\n",
      "[7586]\ttraining's auc: 0.989629\ttraining's binary_logloss: 0.118064\n",
      "[7587]\ttraining's auc: 0.989632\ttraining's binary_logloss: 0.118053\n",
      "[7588]\ttraining's auc: 0.989634\ttraining's binary_logloss: 0.11805\n",
      "[7589]\ttraining's auc: 0.98964\ttraining's binary_logloss: 0.118038\n",
      "[7590]\ttraining's auc: 0.989642\ttraining's binary_logloss: 0.118036\n",
      "[7591]\ttraining's auc: 0.989646\ttraining's binary_logloss: 0.118026\n",
      "[7592]\ttraining's auc: 0.989647\ttraining's binary_logloss: 0.118023\n",
      "[7593]\ttraining's auc: 0.989652\ttraining's binary_logloss: 0.118009\n",
      "[7594]\ttraining's auc: 0.989655\ttraining's binary_logloss: 0.118003\n",
      "[7595]\ttraining's auc: 0.989656\ttraining's binary_logloss: 0.118002\n",
      "[7596]\ttraining's auc: 0.989662\ttraining's binary_logloss: 0.11799\n",
      "[7597]\ttraining's auc: 0.989666\ttraining's binary_logloss: 0.117979\n",
      "[7598]\ttraining's auc: 0.989672\ttraining's binary_logloss: 0.117968\n",
      "[7599]\ttraining's auc: 0.98968\ttraining's binary_logloss: 0.117956\n",
      "[7600]\ttraining's auc: 0.989686\ttraining's binary_logloss: 0.117947\n",
      "[7601]\ttraining's auc: 0.989693\ttraining's binary_logloss: 0.117931\n",
      "[7602]\ttraining's auc: 0.989698\ttraining's binary_logloss: 0.117921\n",
      "[7603]\ttraining's auc: 0.989703\ttraining's binary_logloss: 0.117908\n",
      "[7604]\ttraining's auc: 0.989708\ttraining's binary_logloss: 0.117897\n",
      "[7605]\ttraining's auc: 0.98971\ttraining's binary_logloss: 0.117888\n",
      "[7606]\ttraining's auc: 0.989719\ttraining's binary_logloss: 0.117876\n",
      "[7607]\ttraining's auc: 0.989723\ttraining's binary_logloss: 0.117866\n",
      "[7608]\ttraining's auc: 0.989724\ttraining's binary_logloss: 0.117863\n",
      "[7609]\ttraining's auc: 0.989732\ttraining's binary_logloss: 0.117851\n",
      "[7610]\ttraining's auc: 0.989738\ttraining's binary_logloss: 0.117839\n",
      "[7611]\ttraining's auc: 0.989744\ttraining's binary_logloss: 0.117829\n",
      "[7612]\ttraining's auc: 0.989747\ttraining's binary_logloss: 0.117821\n",
      "[7613]\ttraining's auc: 0.989751\ttraining's binary_logloss: 0.117813\n",
      "[7614]\ttraining's auc: 0.989758\ttraining's binary_logloss: 0.117801\n",
      "[7615]\ttraining's auc: 0.98976\ttraining's binary_logloss: 0.117798\n",
      "[7616]\ttraining's auc: 0.989766\ttraining's binary_logloss: 0.117786\n",
      "[7617]\ttraining's auc: 0.989773\ttraining's binary_logloss: 0.117774\n",
      "[7618]\ttraining's auc: 0.989777\ttraining's binary_logloss: 0.117765\n",
      "[7619]\ttraining's auc: 0.98978\ttraining's binary_logloss: 0.117757\n",
      "[7620]\ttraining's auc: 0.989784\ttraining's binary_logloss: 0.11775\n",
      "[7621]\ttraining's auc: 0.989785\ttraining's binary_logloss: 0.117747\n",
      "[7622]\ttraining's auc: 0.989788\ttraining's binary_logloss: 0.117741\n",
      "[7623]\ttraining's auc: 0.989793\ttraining's binary_logloss: 0.117733\n",
      "[7624]\ttraining's auc: 0.989797\ttraining's binary_logloss: 0.117725\n",
      "[7625]\ttraining's auc: 0.989802\ttraining's binary_logloss: 0.117713\n",
      "[7626]\ttraining's auc: 0.989805\ttraining's binary_logloss: 0.117704\n",
      "[7627]\ttraining's auc: 0.989807\ttraining's binary_logloss: 0.117695\n",
      "[7628]\ttraining's auc: 0.989811\ttraining's binary_logloss: 0.117685\n",
      "[7629]\ttraining's auc: 0.989817\ttraining's binary_logloss: 0.117677\n",
      "[7630]\ttraining's auc: 0.98982\ttraining's binary_logloss: 0.117668\n",
      "[7631]\ttraining's auc: 0.989823\ttraining's binary_logloss: 0.117659\n",
      "[7632]\ttraining's auc: 0.989826\ttraining's binary_logloss: 0.117651\n",
      "[7633]\ttraining's auc: 0.989826\ttraining's binary_logloss: 0.11765\n",
      "[7634]\ttraining's auc: 0.989831\ttraining's binary_logloss: 0.117638\n",
      "[7635]\ttraining's auc: 0.989836\ttraining's binary_logloss: 0.117627\n",
      "[7636]\ttraining's auc: 0.989841\ttraining's binary_logloss: 0.117618\n",
      "[7637]\ttraining's auc: 0.989848\ttraining's binary_logloss: 0.117607\n",
      "[7638]\ttraining's auc: 0.989853\ttraining's binary_logloss: 0.117596\n",
      "[7639]\ttraining's auc: 0.98986\ttraining's binary_logloss: 0.117585\n",
      "[7640]\ttraining's auc: 0.989865\ttraining's binary_logloss: 0.117575\n",
      "[7641]\ttraining's auc: 0.989868\ttraining's binary_logloss: 0.117565\n",
      "[7642]\ttraining's auc: 0.989869\ttraining's binary_logloss: 0.117562\n",
      "[7643]\ttraining's auc: 0.989874\ttraining's binary_logloss: 0.117551\n",
      "[7644]\ttraining's auc: 0.98988\ttraining's binary_logloss: 0.11754\n",
      "[7645]\ttraining's auc: 0.989886\ttraining's binary_logloss: 0.117527\n",
      "[7646]\ttraining's auc: 0.989888\ttraining's binary_logloss: 0.117517\n",
      "[7647]\ttraining's auc: 0.989889\ttraining's binary_logloss: 0.117514\n",
      "[7648]\ttraining's auc: 0.989897\ttraining's binary_logloss: 0.117503\n",
      "[7649]\ttraining's auc: 0.9899\ttraining's binary_logloss: 0.117494\n",
      "[7650]\ttraining's auc: 0.989904\ttraining's binary_logloss: 0.117484\n",
      "[7651]\ttraining's auc: 0.989907\ttraining's binary_logloss: 0.117478\n",
      "[7652]\ttraining's auc: 0.989914\ttraining's binary_logloss: 0.117467\n",
      "[7653]\ttraining's auc: 0.98992\ttraining's binary_logloss: 0.117459\n",
      "[7654]\ttraining's auc: 0.989924\ttraining's binary_logloss: 0.11745\n",
      "[7655]\ttraining's auc: 0.989929\ttraining's binary_logloss: 0.117439\n",
      "[7656]\ttraining's auc: 0.989933\ttraining's binary_logloss: 0.11743\n",
      "[7657]\ttraining's auc: 0.989938\ttraining's binary_logloss: 0.117418\n",
      "[7658]\ttraining's auc: 0.989942\ttraining's binary_logloss: 0.117407\n",
      "[7659]\ttraining's auc: 0.989947\ttraining's binary_logloss: 0.117399\n",
      "[7660]\ttraining's auc: 0.98995\ttraining's binary_logloss: 0.117392\n",
      "[7661]\ttraining's auc: 0.989953\ttraining's binary_logloss: 0.117386\n",
      "[7662]\ttraining's auc: 0.989957\ttraining's binary_logloss: 0.117376\n",
      "[7663]\ttraining's auc: 0.989961\ttraining's binary_logloss: 0.117365\n",
      "[7664]\ttraining's auc: 0.989967\ttraining's binary_logloss: 0.117353\n",
      "[7665]\ttraining's auc: 0.989973\ttraining's binary_logloss: 0.11734\n",
      "[7666]\ttraining's auc: 0.989978\ttraining's binary_logloss: 0.11733\n",
      "[7667]\ttraining's auc: 0.989979\ttraining's binary_logloss: 0.117328\n",
      "[7668]\ttraining's auc: 0.98998\ttraining's binary_logloss: 0.117326\n",
      "[7669]\ttraining's auc: 0.989983\ttraining's binary_logloss: 0.117318\n",
      "[7670]\ttraining's auc: 0.989988\ttraining's binary_logloss: 0.117308\n",
      "[7671]\ttraining's auc: 0.98999\ttraining's binary_logloss: 0.117305\n",
      "[7672]\ttraining's auc: 0.989991\ttraining's binary_logloss: 0.1173\n",
      "[7673]\ttraining's auc: 0.989996\ttraining's binary_logloss: 0.117289\n",
      "[7674]\ttraining's auc: 0.989998\ttraining's binary_logloss: 0.117282\n",
      "[7675]\ttraining's auc: 0.989999\ttraining's binary_logloss: 0.117279\n",
      "[7676]\ttraining's auc: 0.99\ttraining's binary_logloss: 0.117278\n",
      "[7677]\ttraining's auc: 0.990003\ttraining's binary_logloss: 0.117267\n",
      "[7678]\ttraining's auc: 0.990008\ttraining's binary_logloss: 0.117258\n",
      "[7679]\ttraining's auc: 0.990008\ttraining's binary_logloss: 0.117256\n",
      "[7680]\ttraining's auc: 0.990011\ttraining's binary_logloss: 0.117247\n",
      "[7681]\ttraining's auc: 0.990015\ttraining's binary_logloss: 0.117237\n",
      "[7682]\ttraining's auc: 0.990022\ttraining's binary_logloss: 0.117225\n",
      "[7683]\ttraining's auc: 0.990024\ttraining's binary_logloss: 0.117222\n",
      "[7684]\ttraining's auc: 0.990026\ttraining's binary_logloss: 0.117213\n",
      "[7685]\ttraining's auc: 0.99003\ttraining's binary_logloss: 0.117202\n",
      "[7686]\ttraining's auc: 0.990035\ttraining's binary_logloss: 0.117191\n",
      "[7687]\ttraining's auc: 0.990042\ttraining's binary_logloss: 0.117181\n",
      "[7688]\ttraining's auc: 0.990047\ttraining's binary_logloss: 0.117174\n",
      "[7689]\ttraining's auc: 0.990052\ttraining's binary_logloss: 0.117163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7690]\ttraining's auc: 0.990053\ttraining's binary_logloss: 0.117155\n",
      "[7691]\ttraining's auc: 0.990057\ttraining's binary_logloss: 0.117145\n",
      "[7692]\ttraining's auc: 0.99006\ttraining's binary_logloss: 0.117134\n",
      "[7693]\ttraining's auc: 0.990064\ttraining's binary_logloss: 0.117127\n",
      "[7694]\ttraining's auc: 0.990067\ttraining's binary_logloss: 0.117119\n",
      "[7695]\ttraining's auc: 0.990069\ttraining's binary_logloss: 0.117114\n",
      "[7696]\ttraining's auc: 0.990073\ttraining's binary_logloss: 0.117104\n",
      "[7697]\ttraining's auc: 0.990077\ttraining's binary_logloss: 0.117093\n",
      "[7698]\ttraining's auc: 0.990079\ttraining's binary_logloss: 0.11709\n",
      "[7699]\ttraining's auc: 0.990079\ttraining's binary_logloss: 0.117088\n",
      "[7700]\ttraining's auc: 0.990086\ttraining's binary_logloss: 0.117077\n",
      "[7701]\ttraining's auc: 0.990092\ttraining's binary_logloss: 0.117067\n",
      "[7702]\ttraining's auc: 0.990096\ttraining's binary_logloss: 0.117056\n",
      "[7703]\ttraining's auc: 0.990096\ttraining's binary_logloss: 0.117054\n",
      "[7704]\ttraining's auc: 0.990101\ttraining's binary_logloss: 0.117042\n",
      "[7705]\ttraining's auc: 0.990103\ttraining's binary_logloss: 0.117037\n",
      "[7706]\ttraining's auc: 0.990109\ttraining's binary_logloss: 0.117027\n",
      "[7707]\ttraining's auc: 0.990109\ttraining's binary_logloss: 0.117025\n",
      "[7708]\ttraining's auc: 0.99011\ttraining's binary_logloss: 0.117023\n",
      "[7709]\ttraining's auc: 0.990115\ttraining's binary_logloss: 0.117013\n",
      "[7710]\ttraining's auc: 0.99012\ttraining's binary_logloss: 0.117002\n",
      "[7711]\ttraining's auc: 0.99012\ttraining's binary_logloss: 0.116999\n",
      "[7712]\ttraining's auc: 0.990123\ttraining's binary_logloss: 0.11699\n",
      "[7713]\ttraining's auc: 0.990127\ttraining's binary_logloss: 0.11698\n",
      "[7714]\ttraining's auc: 0.990129\ttraining's binary_logloss: 0.116972\n",
      "[7715]\ttraining's auc: 0.990134\ttraining's binary_logloss: 0.116961\n",
      "[7716]\ttraining's auc: 0.990142\ttraining's binary_logloss: 0.116949\n",
      "[7717]\ttraining's auc: 0.990144\ttraining's binary_logloss: 0.11694\n",
      "[7718]\ttraining's auc: 0.990149\ttraining's binary_logloss: 0.116929\n",
      "[7719]\ttraining's auc: 0.990152\ttraining's binary_logloss: 0.116921\n",
      "[7720]\ttraining's auc: 0.990157\ttraining's binary_logloss: 0.116909\n",
      "[7721]\ttraining's auc: 0.99016\ttraining's binary_logloss: 0.116899\n",
      "[7722]\ttraining's auc: 0.990167\ttraining's binary_logloss: 0.116887\n",
      "[7723]\ttraining's auc: 0.990172\ttraining's binary_logloss: 0.116877\n",
      "[7724]\ttraining's auc: 0.990176\ttraining's binary_logloss: 0.116866\n",
      "[7725]\ttraining's auc: 0.990181\ttraining's binary_logloss: 0.116856\n",
      "[7726]\ttraining's auc: 0.990186\ttraining's binary_logloss: 0.116846\n",
      "[7727]\ttraining's auc: 0.990191\ttraining's binary_logloss: 0.116837\n",
      "[7728]\ttraining's auc: 0.990192\ttraining's binary_logloss: 0.11683\n",
      "[7729]\ttraining's auc: 0.990193\ttraining's binary_logloss: 0.116827\n",
      "[7730]\ttraining's auc: 0.990197\ttraining's binary_logloss: 0.116817\n",
      "[7731]\ttraining's auc: 0.990198\ttraining's binary_logloss: 0.116814\n",
      "[7732]\ttraining's auc: 0.990205\ttraining's binary_logloss: 0.116804\n",
      "[7733]\ttraining's auc: 0.990207\ttraining's binary_logloss: 0.116794\n",
      "[7734]\ttraining's auc: 0.990213\ttraining's binary_logloss: 0.116785\n",
      "[7735]\ttraining's auc: 0.990216\ttraining's binary_logloss: 0.116775\n",
      "[7736]\ttraining's auc: 0.99022\ttraining's binary_logloss: 0.116765\n",
      "[7737]\ttraining's auc: 0.990226\ttraining's binary_logloss: 0.116755\n",
      "[7738]\ttraining's auc: 0.990232\ttraining's binary_logloss: 0.116742\n",
      "[7739]\ttraining's auc: 0.990236\ttraining's binary_logloss: 0.116733\n",
      "[7740]\ttraining's auc: 0.99024\ttraining's binary_logloss: 0.116723\n",
      "[7741]\ttraining's auc: 0.990245\ttraining's binary_logloss: 0.116714\n",
      "[7742]\ttraining's auc: 0.990246\ttraining's binary_logloss: 0.116711\n",
      "[7743]\ttraining's auc: 0.990251\ttraining's binary_logloss: 0.116702\n",
      "[7744]\ttraining's auc: 0.990255\ttraining's binary_logloss: 0.116691\n",
      "[7745]\ttraining's auc: 0.990261\ttraining's binary_logloss: 0.116681\n",
      "[7746]\ttraining's auc: 0.990266\ttraining's binary_logloss: 0.11667\n",
      "[7747]\ttraining's auc: 0.990271\ttraining's binary_logloss: 0.116659\n",
      "[7748]\ttraining's auc: 0.990276\ttraining's binary_logloss: 0.116648\n",
      "[7749]\ttraining's auc: 0.990277\ttraining's binary_logloss: 0.116646\n",
      "[7750]\ttraining's auc: 0.990278\ttraining's binary_logloss: 0.116643\n",
      "[7751]\ttraining's auc: 0.990279\ttraining's binary_logloss: 0.116639\n",
      "[7752]\ttraining's auc: 0.990284\ttraining's binary_logloss: 0.116628\n",
      "[7753]\ttraining's auc: 0.990286\ttraining's binary_logloss: 0.116626\n",
      "[7754]\ttraining's auc: 0.990291\ttraining's binary_logloss: 0.116614\n",
      "[7755]\ttraining's auc: 0.990294\ttraining's binary_logloss: 0.116606\n",
      "[7756]\ttraining's auc: 0.990297\ttraining's binary_logloss: 0.116597\n",
      "[7757]\ttraining's auc: 0.990299\ttraining's binary_logloss: 0.11659\n",
      "[7758]\ttraining's auc: 0.990306\ttraining's binary_logloss: 0.116578\n",
      "[7759]\ttraining's auc: 0.990309\ttraining's binary_logloss: 0.116568\n",
      "[7760]\ttraining's auc: 0.990317\ttraining's binary_logloss: 0.116554\n",
      "[7761]\ttraining's auc: 0.990322\ttraining's binary_logloss: 0.116542\n",
      "[7762]\ttraining's auc: 0.990326\ttraining's binary_logloss: 0.116531\n",
      "[7763]\ttraining's auc: 0.99033\ttraining's binary_logloss: 0.116521\n",
      "[7764]\ttraining's auc: 0.990336\ttraining's binary_logloss: 0.11651\n",
      "[7765]\ttraining's auc: 0.990344\ttraining's binary_logloss: 0.116498\n",
      "[7766]\ttraining's auc: 0.990345\ttraining's binary_logloss: 0.116492\n",
      "[7767]\ttraining's auc: 0.990351\ttraining's binary_logloss: 0.116481\n",
      "[7768]\ttraining's auc: 0.990358\ttraining's binary_logloss: 0.116469\n",
      "[7769]\ttraining's auc: 0.990362\ttraining's binary_logloss: 0.116459\n",
      "[7770]\ttraining's auc: 0.990365\ttraining's binary_logloss: 0.116447\n",
      "[7771]\ttraining's auc: 0.99037\ttraining's binary_logloss: 0.116437\n",
      "[7772]\ttraining's auc: 0.990374\ttraining's binary_logloss: 0.116429\n",
      "[7773]\ttraining's auc: 0.990376\ttraining's binary_logloss: 0.116421\n",
      "[7774]\ttraining's auc: 0.990381\ttraining's binary_logloss: 0.11641\n",
      "[7775]\ttraining's auc: 0.990385\ttraining's binary_logloss: 0.1164\n",
      "[7776]\ttraining's auc: 0.990392\ttraining's binary_logloss: 0.116389\n",
      "[7777]\ttraining's auc: 0.990397\ttraining's binary_logloss: 0.11638\n",
      "[7778]\ttraining's auc: 0.990399\ttraining's binary_logloss: 0.116376\n",
      "[7779]\ttraining's auc: 0.990402\ttraining's binary_logloss: 0.116366\n",
      "[7780]\ttraining's auc: 0.990408\ttraining's binary_logloss: 0.116355\n",
      "[7781]\ttraining's auc: 0.990412\ttraining's binary_logloss: 0.116344\n",
      "[7782]\ttraining's auc: 0.990416\ttraining's binary_logloss: 0.116334\n",
      "[7783]\ttraining's auc: 0.990422\ttraining's binary_logloss: 0.116324\n",
      "[7784]\ttraining's auc: 0.990429\ttraining's binary_logloss: 0.116314\n",
      "[7785]\ttraining's auc: 0.99043\ttraining's binary_logloss: 0.116311\n",
      "[7786]\ttraining's auc: 0.990435\ttraining's binary_logloss: 0.116301\n",
      "[7787]\ttraining's auc: 0.990437\ttraining's binary_logloss: 0.116291\n",
      "[7788]\ttraining's auc: 0.990441\ttraining's binary_logloss: 0.116279\n",
      "[7789]\ttraining's auc: 0.990445\ttraining's binary_logloss: 0.116268\n",
      "[7790]\ttraining's auc: 0.990449\ttraining's binary_logloss: 0.116257\n",
      "[7791]\ttraining's auc: 0.990455\ttraining's binary_logloss: 0.116246\n",
      "[7792]\ttraining's auc: 0.990459\ttraining's binary_logloss: 0.116235\n",
      "[7793]\ttraining's auc: 0.990465\ttraining's binary_logloss: 0.116224\n",
      "[7794]\ttraining's auc: 0.990466\ttraining's binary_logloss: 0.116222\n",
      "[7795]\ttraining's auc: 0.990468\ttraining's binary_logloss: 0.116216\n",
      "[7796]\ttraining's auc: 0.990474\ttraining's binary_logloss: 0.116206\n",
      "[7797]\ttraining's auc: 0.990475\ttraining's binary_logloss: 0.116197\n",
      "[7798]\ttraining's auc: 0.99048\ttraining's binary_logloss: 0.116186\n",
      "[7799]\ttraining's auc: 0.990486\ttraining's binary_logloss: 0.116175\n",
      "[7800]\ttraining's auc: 0.99049\ttraining's binary_logloss: 0.116165\n",
      "[7801]\ttraining's auc: 0.990493\ttraining's binary_logloss: 0.116159\n",
      "[7802]\ttraining's auc: 0.990496\ttraining's binary_logloss: 0.116149\n",
      "[7803]\ttraining's auc: 0.9905\ttraining's binary_logloss: 0.116138\n",
      "[7804]\ttraining's auc: 0.990504\ttraining's binary_logloss: 0.116128\n",
      "[7805]\ttraining's auc: 0.990506\ttraining's binary_logloss: 0.116119\n",
      "[7806]\ttraining's auc: 0.990512\ttraining's binary_logloss: 0.116108\n",
      "[7807]\ttraining's auc: 0.990516\ttraining's binary_logloss: 0.116097\n",
      "[7808]\ttraining's auc: 0.99052\ttraining's binary_logloss: 0.116089\n",
      "[7809]\ttraining's auc: 0.990522\ttraining's binary_logloss: 0.11608\n",
      "[7810]\ttraining's auc: 0.990527\ttraining's binary_logloss: 0.11607\n",
      "[7811]\ttraining's auc: 0.990531\ttraining's binary_logloss: 0.116064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7812]\ttraining's auc: 0.990535\ttraining's binary_logloss: 0.116055\n",
      "[7813]\ttraining's auc: 0.99054\ttraining's binary_logloss: 0.116045\n",
      "[7814]\ttraining's auc: 0.990545\ttraining's binary_logloss: 0.116034\n",
      "[7815]\ttraining's auc: 0.990551\ttraining's binary_logloss: 0.11602\n",
      "[7816]\ttraining's auc: 0.990559\ttraining's binary_logloss: 0.116008\n",
      "[7817]\ttraining's auc: 0.990563\ttraining's binary_logloss: 0.115997\n",
      "[7818]\ttraining's auc: 0.990568\ttraining's binary_logloss: 0.115986\n",
      "[7819]\ttraining's auc: 0.990576\ttraining's binary_logloss: 0.115974\n",
      "[7820]\ttraining's auc: 0.990579\ttraining's binary_logloss: 0.115963\n",
      "[7821]\ttraining's auc: 0.990581\ttraining's binary_logloss: 0.115954\n",
      "[7822]\ttraining's auc: 0.990582\ttraining's binary_logloss: 0.115945\n",
      "[7823]\ttraining's auc: 0.990586\ttraining's binary_logloss: 0.115934\n",
      "[7824]\ttraining's auc: 0.990589\ttraining's binary_logloss: 0.115927\n",
      "[7825]\ttraining's auc: 0.990591\ttraining's binary_logloss: 0.115923\n",
      "[7826]\ttraining's auc: 0.990597\ttraining's binary_logloss: 0.115911\n",
      "[7827]\ttraining's auc: 0.990602\ttraining's binary_logloss: 0.115901\n",
      "[7828]\ttraining's auc: 0.990604\ttraining's binary_logloss: 0.115894\n",
      "[7829]\ttraining's auc: 0.99061\ttraining's binary_logloss: 0.115882\n",
      "[7830]\ttraining's auc: 0.990611\ttraining's binary_logloss: 0.115879\n",
      "[7831]\ttraining's auc: 0.990614\ttraining's binary_logloss: 0.115869\n",
      "[7832]\ttraining's auc: 0.990618\ttraining's binary_logloss: 0.115856\n",
      "[7833]\ttraining's auc: 0.990622\ttraining's binary_logloss: 0.115845\n",
      "[7834]\ttraining's auc: 0.990631\ttraining's binary_logloss: 0.115832\n",
      "[7835]\ttraining's auc: 0.990632\ttraining's binary_logloss: 0.115825\n",
      "[7836]\ttraining's auc: 0.990638\ttraining's binary_logloss: 0.115814\n",
      "[7837]\ttraining's auc: 0.99064\ttraining's binary_logloss: 0.115809\n",
      "[7838]\ttraining's auc: 0.990645\ttraining's binary_logloss: 0.115795\n",
      "[7839]\ttraining's auc: 0.990649\ttraining's binary_logloss: 0.115785\n",
      "[7840]\ttraining's auc: 0.990652\ttraining's binary_logloss: 0.115777\n",
      "[7841]\ttraining's auc: 0.990659\ttraining's binary_logloss: 0.115765\n",
      "[7842]\ttraining's auc: 0.990667\ttraining's binary_logloss: 0.115752\n",
      "[7843]\ttraining's auc: 0.990669\ttraining's binary_logloss: 0.115747\n",
      "[7844]\ttraining's auc: 0.990673\ttraining's binary_logloss: 0.115735\n",
      "[7845]\ttraining's auc: 0.990674\ttraining's binary_logloss: 0.115732\n",
      "[7846]\ttraining's auc: 0.990677\ttraining's binary_logloss: 0.115727\n",
      "[7847]\ttraining's auc: 0.99068\ttraining's binary_logloss: 0.115716\n",
      "[7848]\ttraining's auc: 0.990685\ttraining's binary_logloss: 0.115707\n",
      "[7849]\ttraining's auc: 0.990687\ttraining's binary_logloss: 0.1157\n",
      "[7850]\ttraining's auc: 0.990693\ttraining's binary_logloss: 0.115688\n",
      "[7851]\ttraining's auc: 0.990694\ttraining's binary_logloss: 0.115684\n",
      "[7852]\ttraining's auc: 0.990696\ttraining's binary_logloss: 0.115679\n",
      "[7853]\ttraining's auc: 0.990699\ttraining's binary_logloss: 0.115672\n",
      "[7854]\ttraining's auc: 0.990704\ttraining's binary_logloss: 0.115661\n",
      "[7855]\ttraining's auc: 0.990706\ttraining's binary_logloss: 0.115657\n",
      "[7856]\ttraining's auc: 0.990707\ttraining's binary_logloss: 0.115654\n",
      "[7857]\ttraining's auc: 0.990711\ttraining's binary_logloss: 0.115643\n",
      "[7858]\ttraining's auc: 0.990716\ttraining's binary_logloss: 0.115633\n",
      "[7859]\ttraining's auc: 0.99072\ttraining's binary_logloss: 0.115624\n",
      "[7860]\ttraining's auc: 0.990722\ttraining's binary_logloss: 0.115617\n",
      "[7861]\ttraining's auc: 0.990727\ttraining's binary_logloss: 0.115607\n",
      "[7862]\ttraining's auc: 0.990731\ttraining's binary_logloss: 0.115595\n",
      "[7863]\ttraining's auc: 0.990735\ttraining's binary_logloss: 0.115584\n",
      "[7864]\ttraining's auc: 0.990737\ttraining's binary_logloss: 0.115575\n",
      "[7865]\ttraining's auc: 0.990742\ttraining's binary_logloss: 0.115568\n",
      "[7866]\ttraining's auc: 0.990745\ttraining's binary_logloss: 0.115558\n",
      "[7867]\ttraining's auc: 0.99075\ttraining's binary_logloss: 0.115547\n",
      "[7868]\ttraining's auc: 0.990752\ttraining's binary_logloss: 0.115536\n",
      "[7869]\ttraining's auc: 0.990756\ttraining's binary_logloss: 0.115527\n",
      "[7870]\ttraining's auc: 0.99076\ttraining's binary_logloss: 0.115518\n",
      "[7871]\ttraining's auc: 0.990765\ttraining's binary_logloss: 0.115507\n",
      "[7872]\ttraining's auc: 0.99077\ttraining's binary_logloss: 0.115496\n",
      "[7873]\ttraining's auc: 0.990772\ttraining's binary_logloss: 0.115492\n",
      "[7874]\ttraining's auc: 0.990774\ttraining's binary_logloss: 0.115482\n",
      "[7875]\ttraining's auc: 0.990778\ttraining's binary_logloss: 0.115473\n",
      "[7876]\ttraining's auc: 0.990783\ttraining's binary_logloss: 0.115462\n",
      "[7877]\ttraining's auc: 0.990788\ttraining's binary_logloss: 0.115452\n",
      "[7878]\ttraining's auc: 0.990793\ttraining's binary_logloss: 0.11544\n",
      "[7879]\ttraining's auc: 0.990799\ttraining's binary_logloss: 0.115429\n",
      "[7880]\ttraining's auc: 0.990804\ttraining's binary_logloss: 0.115417\n",
      "[7881]\ttraining's auc: 0.990808\ttraining's binary_logloss: 0.115407\n",
      "[7882]\ttraining's auc: 0.990812\ttraining's binary_logloss: 0.115396\n",
      "[7883]\ttraining's auc: 0.990817\ttraining's binary_logloss: 0.115387\n",
      "[7884]\ttraining's auc: 0.99082\ttraining's binary_logloss: 0.115379\n",
      "[7885]\ttraining's auc: 0.990824\ttraining's binary_logloss: 0.115371\n",
      "[7886]\ttraining's auc: 0.990826\ttraining's binary_logloss: 0.115362\n",
      "[7887]\ttraining's auc: 0.99083\ttraining's binary_logloss: 0.115352\n",
      "[7888]\ttraining's auc: 0.990831\ttraining's binary_logloss: 0.115343\n",
      "[7889]\ttraining's auc: 0.990836\ttraining's binary_logloss: 0.115332\n",
      "[7890]\ttraining's auc: 0.990841\ttraining's binary_logloss: 0.115321\n",
      "[7891]\ttraining's auc: 0.990845\ttraining's binary_logloss: 0.11531\n",
      "[7892]\ttraining's auc: 0.990849\ttraining's binary_logloss: 0.115301\n",
      "[7893]\ttraining's auc: 0.990852\ttraining's binary_logloss: 0.115293\n",
      "[7894]\ttraining's auc: 0.990856\ttraining's binary_logloss: 0.115283\n",
      "[7895]\ttraining's auc: 0.990859\ttraining's binary_logloss: 0.115274\n",
      "[7896]\ttraining's auc: 0.990863\ttraining's binary_logloss: 0.115269\n",
      "[7897]\ttraining's auc: 0.990868\ttraining's binary_logloss: 0.115258\n",
      "[7898]\ttraining's auc: 0.990872\ttraining's binary_logloss: 0.115247\n",
      "[7899]\ttraining's auc: 0.990876\ttraining's binary_logloss: 0.115238\n",
      "[7900]\ttraining's auc: 0.99088\ttraining's binary_logloss: 0.115227\n",
      "[7901]\ttraining's auc: 0.990883\ttraining's binary_logloss: 0.115222\n",
      "[7902]\ttraining's auc: 0.990887\ttraining's binary_logloss: 0.115211\n",
      "[7903]\ttraining's auc: 0.990891\ttraining's binary_logloss: 0.115203\n",
      "[7904]\ttraining's auc: 0.990895\ttraining's binary_logloss: 0.115193\n",
      "[7905]\ttraining's auc: 0.990897\ttraining's binary_logloss: 0.115187\n",
      "[7906]\ttraining's auc: 0.990902\ttraining's binary_logloss: 0.115176\n",
      "[7907]\ttraining's auc: 0.990906\ttraining's binary_logloss: 0.115165\n",
      "[7908]\ttraining's auc: 0.990912\ttraining's binary_logloss: 0.115155\n",
      "[7909]\ttraining's auc: 0.990917\ttraining's binary_logloss: 0.115143\n",
      "[7910]\ttraining's auc: 0.990918\ttraining's binary_logloss: 0.115136\n",
      "[7911]\ttraining's auc: 0.990923\ttraining's binary_logloss: 0.115125\n",
      "[7912]\ttraining's auc: 0.990928\ttraining's binary_logloss: 0.115112\n",
      "[7913]\ttraining's auc: 0.990932\ttraining's binary_logloss: 0.115105\n",
      "[7914]\ttraining's auc: 0.990936\ttraining's binary_logloss: 0.115096\n",
      "[7915]\ttraining's auc: 0.990941\ttraining's binary_logloss: 0.115087\n",
      "[7916]\ttraining's auc: 0.990945\ttraining's binary_logloss: 0.115077\n",
      "[7917]\ttraining's auc: 0.990948\ttraining's binary_logloss: 0.115067\n",
      "[7918]\ttraining's auc: 0.990955\ttraining's binary_logloss: 0.115058\n",
      "[7919]\ttraining's auc: 0.990959\ttraining's binary_logloss: 0.115047\n",
      "[7920]\ttraining's auc: 0.99096\ttraining's binary_logloss: 0.11504\n",
      "[7921]\ttraining's auc: 0.990962\ttraining's binary_logloss: 0.11503\n",
      "[7922]\ttraining's auc: 0.990966\ttraining's binary_logloss: 0.115022\n",
      "[7923]\ttraining's auc: 0.99097\ttraining's binary_logloss: 0.115011\n",
      "[7924]\ttraining's auc: 0.990973\ttraining's binary_logloss: 0.115002\n",
      "[7925]\ttraining's auc: 0.99098\ttraining's binary_logloss: 0.11499\n",
      "[7926]\ttraining's auc: 0.990984\ttraining's binary_logloss: 0.114981\n",
      "[7927]\ttraining's auc: 0.990988\ttraining's binary_logloss: 0.114969\n",
      "[7928]\ttraining's auc: 0.99099\ttraining's binary_logloss: 0.114967\n",
      "[7929]\ttraining's auc: 0.990991\ttraining's binary_logloss: 0.114964\n",
      "[7930]\ttraining's auc: 0.990996\ttraining's binary_logloss: 0.114955\n",
      "[7931]\ttraining's auc: 0.990997\ttraining's binary_logloss: 0.114949\n",
      "[7932]\ttraining's auc: 0.990999\ttraining's binary_logloss: 0.114948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7933]\ttraining's auc: 0.991004\ttraining's binary_logloss: 0.114937\n",
      "[7934]\ttraining's auc: 0.991004\ttraining's binary_logloss: 0.114935\n",
      "[7935]\ttraining's auc: 0.991007\ttraining's binary_logloss: 0.114922\n",
      "[7936]\ttraining's auc: 0.99101\ttraining's binary_logloss: 0.114913\n",
      "[7937]\ttraining's auc: 0.991012\ttraining's binary_logloss: 0.114908\n",
      "[7938]\ttraining's auc: 0.991012\ttraining's binary_logloss: 0.114907\n",
      "[7939]\ttraining's auc: 0.991016\ttraining's binary_logloss: 0.114897\n",
      "[7940]\ttraining's auc: 0.991017\ttraining's binary_logloss: 0.114894\n",
      "[7941]\ttraining's auc: 0.991021\ttraining's binary_logloss: 0.114884\n",
      "[7942]\ttraining's auc: 0.991025\ttraining's binary_logloss: 0.114874\n",
      "[7943]\ttraining's auc: 0.991029\ttraining's binary_logloss: 0.114864\n",
      "[7944]\ttraining's auc: 0.991031\ttraining's binary_logloss: 0.114856\n",
      "[7945]\ttraining's auc: 0.991035\ttraining's binary_logloss: 0.114845\n",
      "[7946]\ttraining's auc: 0.991037\ttraining's binary_logloss: 0.114835\n",
      "[7947]\ttraining's auc: 0.991041\ttraining's binary_logloss: 0.114825\n",
      "[7948]\ttraining's auc: 0.991046\ttraining's binary_logloss: 0.114815\n",
      "[7949]\ttraining's auc: 0.991051\ttraining's binary_logloss: 0.114804\n",
      "[7950]\ttraining's auc: 0.991056\ttraining's binary_logloss: 0.114792\n",
      "[7951]\ttraining's auc: 0.991061\ttraining's binary_logloss: 0.11478\n",
      "[7952]\ttraining's auc: 0.991065\ttraining's binary_logloss: 0.114771\n",
      "[7953]\ttraining's auc: 0.991066\ttraining's binary_logloss: 0.114761\n",
      "[7954]\ttraining's auc: 0.991068\ttraining's binary_logloss: 0.114754\n",
      "[7955]\ttraining's auc: 0.99107\ttraining's binary_logloss: 0.114743\n",
      "[7956]\ttraining's auc: 0.991074\ttraining's binary_logloss: 0.114733\n",
      "[7957]\ttraining's auc: 0.991076\ttraining's binary_logloss: 0.114723\n",
      "[7958]\ttraining's auc: 0.991082\ttraining's binary_logloss: 0.114712\n",
      "[7959]\ttraining's auc: 0.991086\ttraining's binary_logloss: 0.114703\n",
      "[7960]\ttraining's auc: 0.991091\ttraining's binary_logloss: 0.114692\n",
      "[7961]\ttraining's auc: 0.991091\ttraining's binary_logloss: 0.114686\n",
      "[7962]\ttraining's auc: 0.991092\ttraining's binary_logloss: 0.114682\n",
      "[7963]\ttraining's auc: 0.991094\ttraining's binary_logloss: 0.114674\n",
      "[7964]\ttraining's auc: 0.991095\ttraining's binary_logloss: 0.114673\n",
      "[7965]\ttraining's auc: 0.991101\ttraining's binary_logloss: 0.114663\n",
      "[7966]\ttraining's auc: 0.991105\ttraining's binary_logloss: 0.114652\n",
      "[7967]\ttraining's auc: 0.99111\ttraining's binary_logloss: 0.114643\n",
      "[7968]\ttraining's auc: 0.991116\ttraining's binary_logloss: 0.114632\n",
      "[7969]\ttraining's auc: 0.991119\ttraining's binary_logloss: 0.114622\n",
      "[7970]\ttraining's auc: 0.991122\ttraining's binary_logloss: 0.114615\n",
      "[7971]\ttraining's auc: 0.991125\ttraining's binary_logloss: 0.114607\n",
      "[7972]\ttraining's auc: 0.99113\ttraining's binary_logloss: 0.114598\n",
      "[7973]\ttraining's auc: 0.991133\ttraining's binary_logloss: 0.114588\n",
      "[7974]\ttraining's auc: 0.991135\ttraining's binary_logloss: 0.114585\n",
      "[7975]\ttraining's auc: 0.991137\ttraining's binary_logloss: 0.114576\n",
      "[7976]\ttraining's auc: 0.99114\ttraining's binary_logloss: 0.114567\n",
      "[7977]\ttraining's auc: 0.991144\ttraining's binary_logloss: 0.114557\n",
      "[7978]\ttraining's auc: 0.991152\ttraining's binary_logloss: 0.114546\n",
      "[7979]\ttraining's auc: 0.991153\ttraining's binary_logloss: 0.114543\n",
      "[7980]\ttraining's auc: 0.991156\ttraining's binary_logloss: 0.114534\n",
      "[7981]\ttraining's auc: 0.99116\ttraining's binary_logloss: 0.114525\n",
      "[7982]\ttraining's auc: 0.991163\ttraining's binary_logloss: 0.114518\n",
      "[7983]\ttraining's auc: 0.991166\ttraining's binary_logloss: 0.114509\n",
      "[7984]\ttraining's auc: 0.991167\ttraining's binary_logloss: 0.114508\n",
      "[7985]\ttraining's auc: 0.991167\ttraining's binary_logloss: 0.114507\n",
      "[7986]\ttraining's auc: 0.991173\ttraining's binary_logloss: 0.114496\n",
      "[7987]\ttraining's auc: 0.991175\ttraining's binary_logloss: 0.114488\n",
      "[7988]\ttraining's auc: 0.99118\ttraining's binary_logloss: 0.114477\n",
      "[7989]\ttraining's auc: 0.991183\ttraining's binary_logloss: 0.114466\n",
      "[7990]\ttraining's auc: 0.991188\ttraining's binary_logloss: 0.114457\n",
      "[7991]\ttraining's auc: 0.991192\ttraining's binary_logloss: 0.114447\n",
      "[7992]\ttraining's auc: 0.991198\ttraining's binary_logloss: 0.114436\n",
      "[7993]\ttraining's auc: 0.9912\ttraining's binary_logloss: 0.114427\n",
      "[7994]\ttraining's auc: 0.991204\ttraining's binary_logloss: 0.114419\n",
      "[7995]\ttraining's auc: 0.991208\ttraining's binary_logloss: 0.11441\n",
      "[7996]\ttraining's auc: 0.99121\ttraining's binary_logloss: 0.114401\n",
      "[7997]\ttraining's auc: 0.991213\ttraining's binary_logloss: 0.11439\n",
      "[7998]\ttraining's auc: 0.991215\ttraining's binary_logloss: 0.114383\n",
      "[7999]\ttraining's auc: 0.99122\ttraining's binary_logloss: 0.114373\n",
      "[8000]\ttraining's auc: 0.991223\ttraining's binary_logloss: 0.114368\n",
      "[8001]\ttraining's auc: 0.991223\ttraining's binary_logloss: 0.114367\n",
      "[8002]\ttraining's auc: 0.991225\ttraining's binary_logloss: 0.114358\n",
      "[8003]\ttraining's auc: 0.991228\ttraining's binary_logloss: 0.114348\n",
      "[8004]\ttraining's auc: 0.991231\ttraining's binary_logloss: 0.114336\n",
      "[8005]\ttraining's auc: 0.991235\ttraining's binary_logloss: 0.114326\n",
      "[8006]\ttraining's auc: 0.991236\ttraining's binary_logloss: 0.114324\n",
      "[8007]\ttraining's auc: 0.991239\ttraining's binary_logloss: 0.114315\n",
      "[8008]\ttraining's auc: 0.991244\ttraining's binary_logloss: 0.114304\n",
      "[8009]\ttraining's auc: 0.991247\ttraining's binary_logloss: 0.114296\n",
      "[8010]\ttraining's auc: 0.991252\ttraining's binary_logloss: 0.114287\n",
      "[8011]\ttraining's auc: 0.991256\ttraining's binary_logloss: 0.114275\n",
      "[8012]\ttraining's auc: 0.991259\ttraining's binary_logloss: 0.114266\n",
      "[8013]\ttraining's auc: 0.991264\ttraining's binary_logloss: 0.114255\n",
      "[8014]\ttraining's auc: 0.991268\ttraining's binary_logloss: 0.114245\n",
      "[8015]\ttraining's auc: 0.99127\ttraining's binary_logloss: 0.114235\n",
      "[8016]\ttraining's auc: 0.991274\ttraining's binary_logloss: 0.114224\n",
      "[8017]\ttraining's auc: 0.991279\ttraining's binary_logloss: 0.114214\n",
      "[8018]\ttraining's auc: 0.991284\ttraining's binary_logloss: 0.114201\n",
      "[8019]\ttraining's auc: 0.991287\ttraining's binary_logloss: 0.114193\n",
      "[8020]\ttraining's auc: 0.991288\ttraining's binary_logloss: 0.11419\n",
      "[8021]\ttraining's auc: 0.99129\ttraining's binary_logloss: 0.114183\n",
      "[8022]\ttraining's auc: 0.991294\ttraining's binary_logloss: 0.114172\n",
      "[8023]\ttraining's auc: 0.991297\ttraining's binary_logloss: 0.114161\n",
      "[8024]\ttraining's auc: 0.991299\ttraining's binary_logloss: 0.114153\n",
      "[8025]\ttraining's auc: 0.991305\ttraining's binary_logloss: 0.114142\n",
      "[8026]\ttraining's auc: 0.991306\ttraining's binary_logloss: 0.114132\n",
      "[8027]\ttraining's auc: 0.991309\ttraining's binary_logloss: 0.114122\n",
      "[8028]\ttraining's auc: 0.991312\ttraining's binary_logloss: 0.114113\n",
      "[8029]\ttraining's auc: 0.991316\ttraining's binary_logloss: 0.114102\n",
      "[8030]\ttraining's auc: 0.991319\ttraining's binary_logloss: 0.114091\n",
      "[8031]\ttraining's auc: 0.991323\ttraining's binary_logloss: 0.11408\n",
      "[8032]\ttraining's auc: 0.991325\ttraining's binary_logloss: 0.114075\n",
      "[8033]\ttraining's auc: 0.991328\ttraining's binary_logloss: 0.114065\n",
      "[8034]\ttraining's auc: 0.99133\ttraining's binary_logloss: 0.114058\n",
      "[8035]\ttraining's auc: 0.991336\ttraining's binary_logloss: 0.114046\n",
      "[8036]\ttraining's auc: 0.99134\ttraining's binary_logloss: 0.114034\n",
      "[8037]\ttraining's auc: 0.991342\ttraining's binary_logloss: 0.114029\n",
      "[8038]\ttraining's auc: 0.991344\ttraining's binary_logloss: 0.114024\n",
      "[8039]\ttraining's auc: 0.991349\ttraining's binary_logloss: 0.114013\n",
      "[8040]\ttraining's auc: 0.991353\ttraining's binary_logloss: 0.114003\n",
      "[8041]\ttraining's auc: 0.991355\ttraining's binary_logloss: 0.113997\n",
      "[8042]\ttraining's auc: 0.991356\ttraining's binary_logloss: 0.113987\n",
      "[8043]\ttraining's auc: 0.991362\ttraining's binary_logloss: 0.113976\n",
      "[8044]\ttraining's auc: 0.991366\ttraining's binary_logloss: 0.113966\n",
      "[8045]\ttraining's auc: 0.991372\ttraining's binary_logloss: 0.113954\n",
      "[8046]\ttraining's auc: 0.991374\ttraining's binary_logloss: 0.113945\n",
      "[8047]\ttraining's auc: 0.991378\ttraining's binary_logloss: 0.113936\n",
      "[8048]\ttraining's auc: 0.991382\ttraining's binary_logloss: 0.113927\n",
      "[8049]\ttraining's auc: 0.991386\ttraining's binary_logloss: 0.113918\n",
      "[8050]\ttraining's auc: 0.99139\ttraining's binary_logloss: 0.113909\n",
      "[8051]\ttraining's auc: 0.991393\ttraining's binary_logloss: 0.1139\n",
      "[8052]\ttraining's auc: 0.991396\ttraining's binary_logloss: 0.113892\n",
      "[8053]\ttraining's auc: 0.991397\ttraining's binary_logloss: 0.113885\n",
      "[8054]\ttraining's auc: 0.991399\ttraining's binary_logloss: 0.113878\n",
      "[8055]\ttraining's auc: 0.991403\ttraining's binary_logloss: 0.113867\n",
      "[8056]\ttraining's auc: 0.991407\ttraining's binary_logloss: 0.113856\n",
      "[8057]\ttraining's auc: 0.991409\ttraining's binary_logloss: 0.113847\n",
      "[8058]\ttraining's auc: 0.991413\ttraining's binary_logloss: 0.113838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8059]\ttraining's auc: 0.991415\ttraining's binary_logloss: 0.113829\n",
      "[8060]\ttraining's auc: 0.991417\ttraining's binary_logloss: 0.113823\n",
      "[8061]\ttraining's auc: 0.991423\ttraining's binary_logloss: 0.113811\n",
      "[8062]\ttraining's auc: 0.991426\ttraining's binary_logloss: 0.113805\n",
      "[8063]\ttraining's auc: 0.991427\ttraining's binary_logloss: 0.113796\n",
      "[8064]\ttraining's auc: 0.99143\ttraining's binary_logloss: 0.113787\n",
      "[8065]\ttraining's auc: 0.991431\ttraining's binary_logloss: 0.113784\n",
      "[8066]\ttraining's auc: 0.991436\ttraining's binary_logloss: 0.113773\n",
      "[8067]\ttraining's auc: 0.991439\ttraining's binary_logloss: 0.113766\n",
      "[8068]\ttraining's auc: 0.991446\ttraining's binary_logloss: 0.113754\n",
      "[8069]\ttraining's auc: 0.991449\ttraining's binary_logloss: 0.113744\n",
      "[8070]\ttraining's auc: 0.991453\ttraining's binary_logloss: 0.113732\n",
      "[8071]\ttraining's auc: 0.991456\ttraining's binary_logloss: 0.113722\n",
      "[8072]\ttraining's auc: 0.991458\ttraining's binary_logloss: 0.113718\n",
      "[8073]\ttraining's auc: 0.991461\ttraining's binary_logloss: 0.113707\n",
      "[8074]\ttraining's auc: 0.991467\ttraining's binary_logloss: 0.113696\n",
      "[8075]\ttraining's auc: 0.99147\ttraining's binary_logloss: 0.113685\n",
      "[8076]\ttraining's auc: 0.991475\ttraining's binary_logloss: 0.113674\n",
      "[8077]\ttraining's auc: 0.99148\ttraining's binary_logloss: 0.113663\n",
      "[8078]\ttraining's auc: 0.991485\ttraining's binary_logloss: 0.113652\n",
      "[8079]\ttraining's auc: 0.99149\ttraining's binary_logloss: 0.113641\n",
      "[8080]\ttraining's auc: 0.991494\ttraining's binary_logloss: 0.113631\n",
      "[8081]\ttraining's auc: 0.991496\ttraining's binary_logloss: 0.113623\n",
      "[8082]\ttraining's auc: 0.991499\ttraining's binary_logloss: 0.113613\n",
      "[8083]\ttraining's auc: 0.991505\ttraining's binary_logloss: 0.113601\n",
      "[8084]\ttraining's auc: 0.991509\ttraining's binary_logloss: 0.113594\n",
      "[8085]\ttraining's auc: 0.991513\ttraining's binary_logloss: 0.113584\n",
      "[8086]\ttraining's auc: 0.991516\ttraining's binary_logloss: 0.113574\n",
      "[8087]\ttraining's auc: 0.99152\ttraining's binary_logloss: 0.113563\n",
      "[8088]\ttraining's auc: 0.991523\ttraining's binary_logloss: 0.113554\n",
      "[8089]\ttraining's auc: 0.991526\ttraining's binary_logloss: 0.113545\n",
      "[8090]\ttraining's auc: 0.991529\ttraining's binary_logloss: 0.113536\n",
      "[8091]\ttraining's auc: 0.991534\ttraining's binary_logloss: 0.113526\n",
      "[8092]\ttraining's auc: 0.991534\ttraining's binary_logloss: 0.113525\n",
      "[8093]\ttraining's auc: 0.991538\ttraining's binary_logloss: 0.113514\n",
      "[8094]\ttraining's auc: 0.991542\ttraining's binary_logloss: 0.113504\n",
      "[8095]\ttraining's auc: 0.991547\ttraining's binary_logloss: 0.113493\n",
      "[8096]\ttraining's auc: 0.991553\ttraining's binary_logloss: 0.113483\n",
      "[8097]\ttraining's auc: 0.991559\ttraining's binary_logloss: 0.113473\n",
      "[8098]\ttraining's auc: 0.991561\ttraining's binary_logloss: 0.113466\n",
      "[8099]\ttraining's auc: 0.991562\ttraining's binary_logloss: 0.113463\n",
      "[8100]\ttraining's auc: 0.991566\ttraining's binary_logloss: 0.113457\n",
      "[8101]\ttraining's auc: 0.991571\ttraining's binary_logloss: 0.113444\n",
      "[8102]\ttraining's auc: 0.991575\ttraining's binary_logloss: 0.113434\n",
      "[8103]\ttraining's auc: 0.991579\ttraining's binary_logloss: 0.113423\n",
      "[8104]\ttraining's auc: 0.991583\ttraining's binary_logloss: 0.113412\n",
      "[8105]\ttraining's auc: 0.991584\ttraining's binary_logloss: 0.113409\n",
      "[8106]\ttraining's auc: 0.991586\ttraining's binary_logloss: 0.113399\n",
      "[8107]\ttraining's auc: 0.99159\ttraining's binary_logloss: 0.113389\n",
      "[8108]\ttraining's auc: 0.991595\ttraining's binary_logloss: 0.113378\n",
      "[8109]\ttraining's auc: 0.991596\ttraining's binary_logloss: 0.113372\n",
      "[8110]\ttraining's auc: 0.991599\ttraining's binary_logloss: 0.113359\n",
      "[8111]\ttraining's auc: 0.991605\ttraining's binary_logloss: 0.113349\n",
      "[8112]\ttraining's auc: 0.991608\ttraining's binary_logloss: 0.113339\n",
      "[8113]\ttraining's auc: 0.991613\ttraining's binary_logloss: 0.113328\n",
      "[8114]\ttraining's auc: 0.991615\ttraining's binary_logloss: 0.113319\n",
      "[8115]\ttraining's auc: 0.99162\ttraining's binary_logloss: 0.113309\n",
      "[8116]\ttraining's auc: 0.991622\ttraining's binary_logloss: 0.1133\n",
      "[8117]\ttraining's auc: 0.991625\ttraining's binary_logloss: 0.113293\n",
      "[8118]\ttraining's auc: 0.991625\ttraining's binary_logloss: 0.113286\n",
      "[8119]\ttraining's auc: 0.991628\ttraining's binary_logloss: 0.113281\n",
      "[8120]\ttraining's auc: 0.991631\ttraining's binary_logloss: 0.113277\n",
      "[8121]\ttraining's auc: 0.991634\ttraining's binary_logloss: 0.113268\n",
      "[8122]\ttraining's auc: 0.99164\ttraining's binary_logloss: 0.113256\n",
      "[8123]\ttraining's auc: 0.991643\ttraining's binary_logloss: 0.113246\n",
      "[8124]\ttraining's auc: 0.991647\ttraining's binary_logloss: 0.113236\n",
      "[8125]\ttraining's auc: 0.991652\ttraining's binary_logloss: 0.113226\n",
      "[8126]\ttraining's auc: 0.991654\ttraining's binary_logloss: 0.113215\n",
      "[8127]\ttraining's auc: 0.991658\ttraining's binary_logloss: 0.113204\n",
      "[8128]\ttraining's auc: 0.991661\ttraining's binary_logloss: 0.113197\n",
      "[8129]\ttraining's auc: 0.991666\ttraining's binary_logloss: 0.113186\n",
      "[8130]\ttraining's auc: 0.99167\ttraining's binary_logloss: 0.113176\n",
      "[8131]\ttraining's auc: 0.991673\ttraining's binary_logloss: 0.113169\n",
      "[8132]\ttraining's auc: 0.991679\ttraining's binary_logloss: 0.11316\n",
      "[8133]\ttraining's auc: 0.991682\ttraining's binary_logloss: 0.113149\n",
      "[8134]\ttraining's auc: 0.991685\ttraining's binary_logloss: 0.113138\n",
      "[8135]\ttraining's auc: 0.991687\ttraining's binary_logloss: 0.11313\n",
      "[8136]\ttraining's auc: 0.99169\ttraining's binary_logloss: 0.113119\n",
      "[8137]\ttraining's auc: 0.991693\ttraining's binary_logloss: 0.113109\n",
      "[8138]\ttraining's auc: 0.991694\ttraining's binary_logloss: 0.113108\n",
      "[8139]\ttraining's auc: 0.991695\ttraining's binary_logloss: 0.113106\n",
      "[8140]\ttraining's auc: 0.991698\ttraining's binary_logloss: 0.113099\n",
      "[8141]\ttraining's auc: 0.991703\ttraining's binary_logloss: 0.113087\n",
      "[8142]\ttraining's auc: 0.991705\ttraining's binary_logloss: 0.113083\n",
      "[8143]\ttraining's auc: 0.991711\ttraining's binary_logloss: 0.113074\n",
      "[8144]\ttraining's auc: 0.991712\ttraining's binary_logloss: 0.113071\n",
      "[8145]\ttraining's auc: 0.991715\ttraining's binary_logloss: 0.11306\n",
      "[8146]\ttraining's auc: 0.991716\ttraining's binary_logloss: 0.113054\n",
      "[8147]\ttraining's auc: 0.991723\ttraining's binary_logloss: 0.113043\n",
      "[8148]\ttraining's auc: 0.991728\ttraining's binary_logloss: 0.113032\n",
      "[8149]\ttraining's auc: 0.991728\ttraining's binary_logloss: 0.11303\n",
      "[8150]\ttraining's auc: 0.991732\ttraining's binary_logloss: 0.113021\n",
      "[8151]\ttraining's auc: 0.991734\ttraining's binary_logloss: 0.113013\n",
      "[8152]\ttraining's auc: 0.991738\ttraining's binary_logloss: 0.113006\n",
      "[8153]\ttraining's auc: 0.991741\ttraining's binary_logloss: 0.112996\n",
      "[8154]\ttraining's auc: 0.991743\ttraining's binary_logloss: 0.112988\n",
      "[8155]\ttraining's auc: 0.991746\ttraining's binary_logloss: 0.112984\n",
      "[8156]\ttraining's auc: 0.991749\ttraining's binary_logloss: 0.112979\n",
      "[8157]\ttraining's auc: 0.99175\ttraining's binary_logloss: 0.112976\n",
      "[8158]\ttraining's auc: 0.99175\ttraining's binary_logloss: 0.112974\n",
      "[8159]\ttraining's auc: 0.99175\ttraining's binary_logloss: 0.112972\n",
      "[8160]\ttraining's auc: 0.991753\ttraining's binary_logloss: 0.112968\n",
      "[8161]\ttraining's auc: 0.991755\ttraining's binary_logloss: 0.112958\n",
      "[8162]\ttraining's auc: 0.991758\ttraining's binary_logloss: 0.112947\n",
      "[8163]\ttraining's auc: 0.991764\ttraining's binary_logloss: 0.112934\n",
      "[8164]\ttraining's auc: 0.991769\ttraining's binary_logloss: 0.112922\n",
      "[8165]\ttraining's auc: 0.991774\ttraining's binary_logloss: 0.112913\n",
      "[8166]\ttraining's auc: 0.991777\ttraining's binary_logloss: 0.112902\n",
      "[8167]\ttraining's auc: 0.991783\ttraining's binary_logloss: 0.11289\n",
      "[8168]\ttraining's auc: 0.991787\ttraining's binary_logloss: 0.112881\n",
      "[8169]\ttraining's auc: 0.99179\ttraining's binary_logloss: 0.112873\n",
      "[8170]\ttraining's auc: 0.991794\ttraining's binary_logloss: 0.112864\n",
      "[8171]\ttraining's auc: 0.991798\ttraining's binary_logloss: 0.112853\n",
      "[8172]\ttraining's auc: 0.991803\ttraining's binary_logloss: 0.112841\n",
      "[8173]\ttraining's auc: 0.991806\ttraining's binary_logloss: 0.11283\n",
      "[8174]\ttraining's auc: 0.991811\ttraining's binary_logloss: 0.11282\n",
      "[8175]\ttraining's auc: 0.991811\ttraining's binary_logloss: 0.112818\n",
      "[8176]\ttraining's auc: 0.991811\ttraining's binary_logloss: 0.112816\n",
      "[8177]\ttraining's auc: 0.991816\ttraining's binary_logloss: 0.112804\n",
      "[8178]\ttraining's auc: 0.991821\ttraining's binary_logloss: 0.11279\n",
      "[8179]\ttraining's auc: 0.991825\ttraining's binary_logloss: 0.112778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8180]\ttraining's auc: 0.991829\ttraining's binary_logloss: 0.112767\n",
      "[8181]\ttraining's auc: 0.991834\ttraining's binary_logloss: 0.112756\n",
      "[8182]\ttraining's auc: 0.991836\ttraining's binary_logloss: 0.112748\n",
      "[8183]\ttraining's auc: 0.991841\ttraining's binary_logloss: 0.112736\n",
      "[8184]\ttraining's auc: 0.991846\ttraining's binary_logloss: 0.112727\n",
      "[8185]\ttraining's auc: 0.991851\ttraining's binary_logloss: 0.112713\n",
      "[8186]\ttraining's auc: 0.991853\ttraining's binary_logloss: 0.112702\n",
      "[8187]\ttraining's auc: 0.991857\ttraining's binary_logloss: 0.112692\n",
      "[8188]\ttraining's auc: 0.991859\ttraining's binary_logloss: 0.112687\n",
      "[8189]\ttraining's auc: 0.991862\ttraining's binary_logloss: 0.112678\n",
      "[8190]\ttraining's auc: 0.991865\ttraining's binary_logloss: 0.112668\n",
      "[8191]\ttraining's auc: 0.991866\ttraining's binary_logloss: 0.112662\n",
      "[8192]\ttraining's auc: 0.991866\ttraining's binary_logloss: 0.112653\n",
      "[8193]\ttraining's auc: 0.99187\ttraining's binary_logloss: 0.112644\n",
      "[8194]\ttraining's auc: 0.991872\ttraining's binary_logloss: 0.112639\n",
      "[8195]\ttraining's auc: 0.991874\ttraining's binary_logloss: 0.112634\n",
      "[8196]\ttraining's auc: 0.991874\ttraining's binary_logloss: 0.112633\n",
      "[8197]\ttraining's auc: 0.991876\ttraining's binary_logloss: 0.112622\n",
      "[8198]\ttraining's auc: 0.99188\ttraining's binary_logloss: 0.112614\n",
      "[8199]\ttraining's auc: 0.991883\ttraining's binary_logloss: 0.112607\n",
      "[8200]\ttraining's auc: 0.991886\ttraining's binary_logloss: 0.112597\n",
      "[8201]\ttraining's auc: 0.991889\ttraining's binary_logloss: 0.112588\n",
      "[8202]\ttraining's auc: 0.991892\ttraining's binary_logloss: 0.112579\n",
      "[8203]\ttraining's auc: 0.991897\ttraining's binary_logloss: 0.11257\n",
      "[8204]\ttraining's auc: 0.991901\ttraining's binary_logloss: 0.112561\n",
      "[8205]\ttraining's auc: 0.991906\ttraining's binary_logloss: 0.11255\n",
      "[8206]\ttraining's auc: 0.99191\ttraining's binary_logloss: 0.112543\n",
      "[8207]\ttraining's auc: 0.991911\ttraining's binary_logloss: 0.112538\n",
      "[8208]\ttraining's auc: 0.991914\ttraining's binary_logloss: 0.112531\n",
      "[8209]\ttraining's auc: 0.991915\ttraining's binary_logloss: 0.112528\n",
      "[8210]\ttraining's auc: 0.991916\ttraining's binary_logloss: 0.112525\n",
      "[8211]\ttraining's auc: 0.991917\ttraining's binary_logloss: 0.112522\n",
      "[8212]\ttraining's auc: 0.991918\ttraining's binary_logloss: 0.112519\n",
      "[8213]\ttraining's auc: 0.991922\ttraining's binary_logloss: 0.112509\n",
      "[8214]\ttraining's auc: 0.991925\ttraining's binary_logloss: 0.112501\n",
      "[8215]\ttraining's auc: 0.991928\ttraining's binary_logloss: 0.112494\n",
      "[8216]\ttraining's auc: 0.991929\ttraining's binary_logloss: 0.112489\n",
      "[8217]\ttraining's auc: 0.991935\ttraining's binary_logloss: 0.112478\n",
      "[8218]\ttraining's auc: 0.99194\ttraining's binary_logloss: 0.112466\n",
      "[8219]\ttraining's auc: 0.991942\ttraining's binary_logloss: 0.112461\n",
      "[8220]\ttraining's auc: 0.991943\ttraining's binary_logloss: 0.112454\n",
      "[8221]\ttraining's auc: 0.99195\ttraining's binary_logloss: 0.112443\n",
      "[8222]\ttraining's auc: 0.991954\ttraining's binary_logloss: 0.112431\n",
      "[8223]\ttraining's auc: 0.991957\ttraining's binary_logloss: 0.112418\n",
      "[8224]\ttraining's auc: 0.99196\ttraining's binary_logloss: 0.112412\n",
      "[8225]\ttraining's auc: 0.991963\ttraining's binary_logloss: 0.112402\n",
      "[8226]\ttraining's auc: 0.991968\ttraining's binary_logloss: 0.11239\n",
      "[8227]\ttraining's auc: 0.991971\ttraining's binary_logloss: 0.112385\n",
      "[8228]\ttraining's auc: 0.991977\ttraining's binary_logloss: 0.112374\n",
      "[8229]\ttraining's auc: 0.991981\ttraining's binary_logloss: 0.112363\n",
      "[8230]\ttraining's auc: 0.991982\ttraining's binary_logloss: 0.112353\n",
      "[8231]\ttraining's auc: 0.991987\ttraining's binary_logloss: 0.112341\n",
      "[8232]\ttraining's auc: 0.99199\ttraining's binary_logloss: 0.112332\n",
      "[8233]\ttraining's auc: 0.991995\ttraining's binary_logloss: 0.112322\n",
      "[8234]\ttraining's auc: 0.991998\ttraining's binary_logloss: 0.11231\n",
      "[8235]\ttraining's auc: 0.992001\ttraining's binary_logloss: 0.1123\n",
      "[8236]\ttraining's auc: 0.992004\ttraining's binary_logloss: 0.11229\n",
      "[8237]\ttraining's auc: 0.992006\ttraining's binary_logloss: 0.112282\n",
      "[8238]\ttraining's auc: 0.99201\ttraining's binary_logloss: 0.112272\n",
      "[8239]\ttraining's auc: 0.992015\ttraining's binary_logloss: 0.11226\n",
      "[8240]\ttraining's auc: 0.99202\ttraining's binary_logloss: 0.112249\n",
      "[8241]\ttraining's auc: 0.99202\ttraining's binary_logloss: 0.112244\n",
      "[8242]\ttraining's auc: 0.992023\ttraining's binary_logloss: 0.112233\n",
      "[8243]\ttraining's auc: 0.992025\ttraining's binary_logloss: 0.112223\n",
      "[8244]\ttraining's auc: 0.992027\ttraining's binary_logloss: 0.11222\n",
      "[8245]\ttraining's auc: 0.992031\ttraining's binary_logloss: 0.112214\n",
      "[8246]\ttraining's auc: 0.992033\ttraining's binary_logloss: 0.112204\n",
      "[8247]\ttraining's auc: 0.992036\ttraining's binary_logloss: 0.112197\n",
      "[8248]\ttraining's auc: 0.992039\ttraining's binary_logloss: 0.112188\n",
      "[8249]\ttraining's auc: 0.99204\ttraining's binary_logloss: 0.112185\n",
      "[8250]\ttraining's auc: 0.992041\ttraining's binary_logloss: 0.112183\n",
      "[8251]\ttraining's auc: 0.992044\ttraining's binary_logloss: 0.112174\n",
      "[8252]\ttraining's auc: 0.992047\ttraining's binary_logloss: 0.112167\n",
      "[8253]\ttraining's auc: 0.992052\ttraining's binary_logloss: 0.112156\n",
      "[8254]\ttraining's auc: 0.992054\ttraining's binary_logloss: 0.112148\n",
      "[8255]\ttraining's auc: 0.992055\ttraining's binary_logloss: 0.112136\n",
      "[8256]\ttraining's auc: 0.992057\ttraining's binary_logloss: 0.112134\n",
      "[8257]\ttraining's auc: 0.992063\ttraining's binary_logloss: 0.112123\n",
      "[8258]\ttraining's auc: 0.992068\ttraining's binary_logloss: 0.112114\n",
      "[8259]\ttraining's auc: 0.992073\ttraining's binary_logloss: 0.112102\n",
      "[8260]\ttraining's auc: 0.992078\ttraining's binary_logloss: 0.112091\n",
      "[8261]\ttraining's auc: 0.992084\ttraining's binary_logloss: 0.11208\n",
      "[8262]\ttraining's auc: 0.992088\ttraining's binary_logloss: 0.112069\n",
      "[8263]\ttraining's auc: 0.992091\ttraining's binary_logloss: 0.112061\n",
      "[8264]\ttraining's auc: 0.992095\ttraining's binary_logloss: 0.112049\n",
      "[8265]\ttraining's auc: 0.992101\ttraining's binary_logloss: 0.112039\n",
      "[8266]\ttraining's auc: 0.992105\ttraining's binary_logloss: 0.112029\n",
      "[8267]\ttraining's auc: 0.992108\ttraining's binary_logloss: 0.112022\n",
      "[8268]\ttraining's auc: 0.992116\ttraining's binary_logloss: 0.11201\n",
      "[8269]\ttraining's auc: 0.99212\ttraining's binary_logloss: 0.112002\n",
      "[8270]\ttraining's auc: 0.992125\ttraining's binary_logloss: 0.111992\n",
      "[8271]\ttraining's auc: 0.992128\ttraining's binary_logloss: 0.111986\n",
      "[8272]\ttraining's auc: 0.992131\ttraining's binary_logloss: 0.111977\n",
      "[8273]\ttraining's auc: 0.992133\ttraining's binary_logloss: 0.111972\n",
      "[8274]\ttraining's auc: 0.992136\ttraining's binary_logloss: 0.111961\n",
      "[8275]\ttraining's auc: 0.99214\ttraining's binary_logloss: 0.111951\n",
      "[8276]\ttraining's auc: 0.992143\ttraining's binary_logloss: 0.11194\n",
      "[8277]\ttraining's auc: 0.992147\ttraining's binary_logloss: 0.111933\n",
      "[8278]\ttraining's auc: 0.992149\ttraining's binary_logloss: 0.111925\n",
      "[8279]\ttraining's auc: 0.992154\ttraining's binary_logloss: 0.111915\n",
      "[8280]\ttraining's auc: 0.992158\ttraining's binary_logloss: 0.111906\n",
      "[8281]\ttraining's auc: 0.992162\ttraining's binary_logloss: 0.111897\n",
      "[8282]\ttraining's auc: 0.992162\ttraining's binary_logloss: 0.111894\n",
      "[8283]\ttraining's auc: 0.992163\ttraining's binary_logloss: 0.111885\n",
      "[8284]\ttraining's auc: 0.992165\ttraining's binary_logloss: 0.11188\n",
      "[8285]\ttraining's auc: 0.992168\ttraining's binary_logloss: 0.11187\n",
      "[8286]\ttraining's auc: 0.992171\ttraining's binary_logloss: 0.111861\n",
      "[8287]\ttraining's auc: 0.992174\ttraining's binary_logloss: 0.111854\n",
      "[8288]\ttraining's auc: 0.992177\ttraining's binary_logloss: 0.111849\n",
      "[8289]\ttraining's auc: 0.992179\ttraining's binary_logloss: 0.111844\n",
      "[8290]\ttraining's auc: 0.992181\ttraining's binary_logloss: 0.111833\n",
      "[8291]\ttraining's auc: 0.992186\ttraining's binary_logloss: 0.11182\n",
      "[8292]\ttraining's auc: 0.99219\ttraining's binary_logloss: 0.111809\n",
      "[8293]\ttraining's auc: 0.992194\ttraining's binary_logloss: 0.111799\n",
      "[8294]\ttraining's auc: 0.992199\ttraining's binary_logloss: 0.111786\n",
      "[8295]\ttraining's auc: 0.992203\ttraining's binary_logloss: 0.111775\n",
      "[8296]\ttraining's auc: 0.992206\ttraining's binary_logloss: 0.111763\n",
      "[8297]\ttraining's auc: 0.992211\ttraining's binary_logloss: 0.111753\n",
      "[8298]\ttraining's auc: 0.992215\ttraining's binary_logloss: 0.111742\n",
      "[8299]\ttraining's auc: 0.992219\ttraining's binary_logloss: 0.111735\n",
      "[8300]\ttraining's auc: 0.992223\ttraining's binary_logloss: 0.111725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8301]\ttraining's auc: 0.992226\ttraining's binary_logloss: 0.111717\n",
      "[8302]\ttraining's auc: 0.99223\ttraining's binary_logloss: 0.111708\n",
      "[8303]\ttraining's auc: 0.992234\ttraining's binary_logloss: 0.111698\n",
      "[8304]\ttraining's auc: 0.992237\ttraining's binary_logloss: 0.111692\n",
      "[8305]\ttraining's auc: 0.992242\ttraining's binary_logloss: 0.111682\n",
      "[8306]\ttraining's auc: 0.992244\ttraining's binary_logloss: 0.111675\n",
      "[8307]\ttraining's auc: 0.992249\ttraining's binary_logloss: 0.111663\n",
      "[8308]\ttraining's auc: 0.992254\ttraining's binary_logloss: 0.111653\n",
      "[8309]\ttraining's auc: 0.992255\ttraining's binary_logloss: 0.111645\n",
      "[8310]\ttraining's auc: 0.992256\ttraining's binary_logloss: 0.111636\n",
      "[8311]\ttraining's auc: 0.992257\ttraining's binary_logloss: 0.111634\n",
      "[8312]\ttraining's auc: 0.992257\ttraining's binary_logloss: 0.111633\n",
      "[8313]\ttraining's auc: 0.992259\ttraining's binary_logloss: 0.111622\n",
      "[8314]\ttraining's auc: 0.992265\ttraining's binary_logloss: 0.111609\n",
      "[8315]\ttraining's auc: 0.992267\ttraining's binary_logloss: 0.111604\n",
      "[8316]\ttraining's auc: 0.992267\ttraining's binary_logloss: 0.1116\n",
      "[8317]\ttraining's auc: 0.992269\ttraining's binary_logloss: 0.111595\n",
      "[8318]\ttraining's auc: 0.992274\ttraining's binary_logloss: 0.111585\n",
      "[8319]\ttraining's auc: 0.99228\ttraining's binary_logloss: 0.111572\n",
      "[8320]\ttraining's auc: 0.992283\ttraining's binary_logloss: 0.111563\n",
      "[8321]\ttraining's auc: 0.992283\ttraining's binary_logloss: 0.111562\n",
      "[8322]\ttraining's auc: 0.992288\ttraining's binary_logloss: 0.111552\n",
      "[8323]\ttraining's auc: 0.992291\ttraining's binary_logloss: 0.111539\n",
      "[8324]\ttraining's auc: 0.992295\ttraining's binary_logloss: 0.111528\n",
      "[8325]\ttraining's auc: 0.992297\ttraining's binary_logloss: 0.111521\n",
      "[8326]\ttraining's auc: 0.992298\ttraining's binary_logloss: 0.11152\n",
      "[8327]\ttraining's auc: 0.992299\ttraining's binary_logloss: 0.111518\n",
      "[8328]\ttraining's auc: 0.992302\ttraining's binary_logloss: 0.11151\n",
      "[8329]\ttraining's auc: 0.992306\ttraining's binary_logloss: 0.111499\n",
      "[8330]\ttraining's auc: 0.99231\ttraining's binary_logloss: 0.111489\n",
      "[8331]\ttraining's auc: 0.99231\ttraining's binary_logloss: 0.111487\n",
      "[8332]\ttraining's auc: 0.992311\ttraining's binary_logloss: 0.111484\n",
      "[8333]\ttraining's auc: 0.992313\ttraining's binary_logloss: 0.111481\n",
      "[8334]\ttraining's auc: 0.992318\ttraining's binary_logloss: 0.111471\n",
      "[8335]\ttraining's auc: 0.992321\ttraining's binary_logloss: 0.11146\n",
      "[8336]\ttraining's auc: 0.992321\ttraining's binary_logloss: 0.111459\n",
      "[8337]\ttraining's auc: 0.992324\ttraining's binary_logloss: 0.111451\n",
      "[8338]\ttraining's auc: 0.992328\ttraining's binary_logloss: 0.111439\n",
      "[8339]\ttraining's auc: 0.992333\ttraining's binary_logloss: 0.111428\n",
      "[8340]\ttraining's auc: 0.992337\ttraining's binary_logloss: 0.111417\n",
      "[8341]\ttraining's auc: 0.992339\ttraining's binary_logloss: 0.111408\n",
      "[8342]\ttraining's auc: 0.992345\ttraining's binary_logloss: 0.111396\n",
      "[8343]\ttraining's auc: 0.992346\ttraining's binary_logloss: 0.111394\n",
      "[8344]\ttraining's auc: 0.992346\ttraining's binary_logloss: 0.111391\n",
      "[8345]\ttraining's auc: 0.99235\ttraining's binary_logloss: 0.111382\n",
      "[8346]\ttraining's auc: 0.992351\ttraining's binary_logloss: 0.11138\n",
      "[8347]\ttraining's auc: 0.992352\ttraining's binary_logloss: 0.111376\n",
      "[8348]\ttraining's auc: 0.992352\ttraining's binary_logloss: 0.111374\n",
      "[8349]\ttraining's auc: 0.992353\ttraining's binary_logloss: 0.111373\n",
      "[8350]\ttraining's auc: 0.992359\ttraining's binary_logloss: 0.111361\n",
      "[8351]\ttraining's auc: 0.992364\ttraining's binary_logloss: 0.11135\n",
      "[8352]\ttraining's auc: 0.992368\ttraining's binary_logloss: 0.11134\n",
      "[8353]\ttraining's auc: 0.992372\ttraining's binary_logloss: 0.11133\n",
      "[8354]\ttraining's auc: 0.992374\ttraining's binary_logloss: 0.11132\n",
      "[8355]\ttraining's auc: 0.992376\ttraining's binary_logloss: 0.11131\n",
      "[8356]\ttraining's auc: 0.992379\ttraining's binary_logloss: 0.111299\n",
      "[8357]\ttraining's auc: 0.992382\ttraining's binary_logloss: 0.111289\n",
      "[8358]\ttraining's auc: 0.992385\ttraining's binary_logloss: 0.111278\n",
      "[8359]\ttraining's auc: 0.992387\ttraining's binary_logloss: 0.111269\n",
      "[8360]\ttraining's auc: 0.992391\ttraining's binary_logloss: 0.111256\n",
      "[8361]\ttraining's auc: 0.992395\ttraining's binary_logloss: 0.111246\n",
      "[8362]\ttraining's auc: 0.9924\ttraining's binary_logloss: 0.111235\n",
      "[8363]\ttraining's auc: 0.992402\ttraining's binary_logloss: 0.111225\n",
      "[8364]\ttraining's auc: 0.992407\ttraining's binary_logloss: 0.111213\n",
      "[8365]\ttraining's auc: 0.99241\ttraining's binary_logloss: 0.111203\n",
      "[8366]\ttraining's auc: 0.992414\ttraining's binary_logloss: 0.111192\n",
      "[8367]\ttraining's auc: 0.992417\ttraining's binary_logloss: 0.111182\n",
      "[8368]\ttraining's auc: 0.992423\ttraining's binary_logloss: 0.111169\n",
      "[8369]\ttraining's auc: 0.992426\ttraining's binary_logloss: 0.111159\n",
      "[8370]\ttraining's auc: 0.992429\ttraining's binary_logloss: 0.111154\n",
      "[8371]\ttraining's auc: 0.992432\ttraining's binary_logloss: 0.111148\n",
      "[8372]\ttraining's auc: 0.992436\ttraining's binary_logloss: 0.111137\n",
      "[8373]\ttraining's auc: 0.992439\ttraining's binary_logloss: 0.111127\n",
      "[8374]\ttraining's auc: 0.992441\ttraining's binary_logloss: 0.111116\n",
      "[8375]\ttraining's auc: 0.992444\ttraining's binary_logloss: 0.111105\n",
      "[8376]\ttraining's auc: 0.992448\ttraining's binary_logloss: 0.111094\n",
      "[8377]\ttraining's auc: 0.992452\ttraining's binary_logloss: 0.111084\n",
      "[8378]\ttraining's auc: 0.992454\ttraining's binary_logloss: 0.111074\n",
      "[8379]\ttraining's auc: 0.992459\ttraining's binary_logloss: 0.111063\n",
      "[8380]\ttraining's auc: 0.992462\ttraining's binary_logloss: 0.111055\n",
      "[8381]\ttraining's auc: 0.992465\ttraining's binary_logloss: 0.111046\n",
      "[8382]\ttraining's auc: 0.992471\ttraining's binary_logloss: 0.111035\n",
      "[8383]\ttraining's auc: 0.992476\ttraining's binary_logloss: 0.111024\n",
      "[8384]\ttraining's auc: 0.99248\ttraining's binary_logloss: 0.111013\n",
      "[8385]\ttraining's auc: 0.992483\ttraining's binary_logloss: 0.111004\n",
      "[8386]\ttraining's auc: 0.992489\ttraining's binary_logloss: 0.110991\n",
      "[8387]\ttraining's auc: 0.992491\ttraining's binary_logloss: 0.110984\n",
      "[8388]\ttraining's auc: 0.992495\ttraining's binary_logloss: 0.110977\n",
      "[8389]\ttraining's auc: 0.992496\ttraining's binary_logloss: 0.110974\n",
      "[8390]\ttraining's auc: 0.9925\ttraining's binary_logloss: 0.110965\n",
      "[8391]\ttraining's auc: 0.992502\ttraining's binary_logloss: 0.110958\n",
      "[8392]\ttraining's auc: 0.992507\ttraining's binary_logloss: 0.110946\n",
      "[8393]\ttraining's auc: 0.99251\ttraining's binary_logloss: 0.110935\n",
      "[8394]\ttraining's auc: 0.992513\ttraining's binary_logloss: 0.110926\n",
      "[8395]\ttraining's auc: 0.992516\ttraining's binary_logloss: 0.110917\n",
      "[8396]\ttraining's auc: 0.992519\ttraining's binary_logloss: 0.110907\n",
      "[8397]\ttraining's auc: 0.992523\ttraining's binary_logloss: 0.110895\n",
      "[8398]\ttraining's auc: 0.992528\ttraining's binary_logloss: 0.110884\n",
      "[8399]\ttraining's auc: 0.992531\ttraining's binary_logloss: 0.110874\n",
      "[8400]\ttraining's auc: 0.992533\ttraining's binary_logloss: 0.110864\n",
      "[8401]\ttraining's auc: 0.992537\ttraining's binary_logloss: 0.110853\n",
      "[8402]\ttraining's auc: 0.992541\ttraining's binary_logloss: 0.110841\n",
      "[8403]\ttraining's auc: 0.992546\ttraining's binary_logloss: 0.11083\n",
      "[8404]\ttraining's auc: 0.99255\ttraining's binary_logloss: 0.110819\n",
      "[8405]\ttraining's auc: 0.992554\ttraining's binary_logloss: 0.110809\n",
      "[8406]\ttraining's auc: 0.992557\ttraining's binary_logloss: 0.110798\n",
      "[8407]\ttraining's auc: 0.99256\ttraining's binary_logloss: 0.110788\n",
      "[8408]\ttraining's auc: 0.992565\ttraining's binary_logloss: 0.110777\n",
      "[8409]\ttraining's auc: 0.992567\ttraining's binary_logloss: 0.110769\n",
      "[8410]\ttraining's auc: 0.99257\ttraining's binary_logloss: 0.110758\n",
      "[8411]\ttraining's auc: 0.992573\ttraining's binary_logloss: 0.110748\n",
      "[8412]\ttraining's auc: 0.992578\ttraining's binary_logloss: 0.110736\n",
      "[8413]\ttraining's auc: 0.992583\ttraining's binary_logloss: 0.110727\n",
      "[8414]\ttraining's auc: 0.992587\ttraining's binary_logloss: 0.110717\n",
      "[8415]\ttraining's auc: 0.992592\ttraining's binary_logloss: 0.110706\n",
      "[8416]\ttraining's auc: 0.992595\ttraining's binary_logloss: 0.1107\n",
      "[8417]\ttraining's auc: 0.992598\ttraining's binary_logloss: 0.110693\n",
      "[8418]\ttraining's auc: 0.9926\ttraining's binary_logloss: 0.110688\n",
      "[8419]\ttraining's auc: 0.992604\ttraining's binary_logloss: 0.110678\n",
      "[8420]\ttraining's auc: 0.992607\ttraining's binary_logloss: 0.110668\n",
      "[8421]\ttraining's auc: 0.99261\ttraining's binary_logloss: 0.110659\n",
      "[8422]\ttraining's auc: 0.992612\ttraining's binary_logloss: 0.110649\n",
      "[8423]\ttraining's auc: 0.992615\ttraining's binary_logloss: 0.110638\n",
      "[8424]\ttraining's auc: 0.992619\ttraining's binary_logloss: 0.110629\n",
      "[8425]\ttraining's auc: 0.992623\ttraining's binary_logloss: 0.110619\n",
      "[8426]\ttraining's auc: 0.992626\ttraining's binary_logloss: 0.110609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8427]\ttraining's auc: 0.992627\ttraining's binary_logloss: 0.110602\n",
      "[8428]\ttraining's auc: 0.992628\ttraining's binary_logloss: 0.110592\n",
      "[8429]\ttraining's auc: 0.992632\ttraining's binary_logloss: 0.110582\n",
      "[8430]\ttraining's auc: 0.992635\ttraining's binary_logloss: 0.110574\n",
      "[8431]\ttraining's auc: 0.992637\ttraining's binary_logloss: 0.110567\n",
      "[8432]\ttraining's auc: 0.99264\ttraining's binary_logloss: 0.110559\n",
      "[8433]\ttraining's auc: 0.992643\ttraining's binary_logloss: 0.110549\n",
      "[8434]\ttraining's auc: 0.992647\ttraining's binary_logloss: 0.110539\n",
      "[8435]\ttraining's auc: 0.99265\ttraining's binary_logloss: 0.110531\n",
      "[8436]\ttraining's auc: 0.992653\ttraining's binary_logloss: 0.11052\n",
      "[8437]\ttraining's auc: 0.992655\ttraining's binary_logloss: 0.11051\n",
      "[8438]\ttraining's auc: 0.99266\ttraining's binary_logloss: 0.110501\n",
      "[8439]\ttraining's auc: 0.992664\ttraining's binary_logloss: 0.11049\n",
      "[8440]\ttraining's auc: 0.992666\ttraining's binary_logloss: 0.110482\n",
      "[8441]\ttraining's auc: 0.992667\ttraining's binary_logloss: 0.110478\n",
      "[8442]\ttraining's auc: 0.992673\ttraining's binary_logloss: 0.110467\n",
      "[8443]\ttraining's auc: 0.992678\ttraining's binary_logloss: 0.110458\n",
      "[8444]\ttraining's auc: 0.992681\ttraining's binary_logloss: 0.110446\n",
      "[8445]\ttraining's auc: 0.992682\ttraining's binary_logloss: 0.11044\n",
      "[8446]\ttraining's auc: 0.992683\ttraining's binary_logloss: 0.110436\n",
      "[8447]\ttraining's auc: 0.992686\ttraining's binary_logloss: 0.110425\n",
      "[8448]\ttraining's auc: 0.992691\ttraining's binary_logloss: 0.110414\n",
      "[8449]\ttraining's auc: 0.992694\ttraining's binary_logloss: 0.110403\n",
      "[8450]\ttraining's auc: 0.992697\ttraining's binary_logloss: 0.110395\n",
      "[8451]\ttraining's auc: 0.992701\ttraining's binary_logloss: 0.110385\n",
      "[8452]\ttraining's auc: 0.992704\ttraining's binary_logloss: 0.110375\n",
      "[8453]\ttraining's auc: 0.99271\ttraining's binary_logloss: 0.110365\n",
      "[8454]\ttraining's auc: 0.992712\ttraining's binary_logloss: 0.110356\n",
      "[8455]\ttraining's auc: 0.992717\ttraining's binary_logloss: 0.110345\n",
      "[8456]\ttraining's auc: 0.992719\ttraining's binary_logloss: 0.110335\n",
      "[8457]\ttraining's auc: 0.992724\ttraining's binary_logloss: 0.110325\n",
      "[8458]\ttraining's auc: 0.992726\ttraining's binary_logloss: 0.110316\n",
      "[8459]\ttraining's auc: 0.992729\ttraining's binary_logloss: 0.110308\n",
      "[8460]\ttraining's auc: 0.992732\ttraining's binary_logloss: 0.110299\n",
      "[8461]\ttraining's auc: 0.992734\ttraining's binary_logloss: 0.110296\n",
      "[8462]\ttraining's auc: 0.992735\ttraining's binary_logloss: 0.110292\n",
      "[8463]\ttraining's auc: 0.992736\ttraining's binary_logloss: 0.110289\n",
      "[8464]\ttraining's auc: 0.992738\ttraining's binary_logloss: 0.110279\n",
      "[8465]\ttraining's auc: 0.992741\ttraining's binary_logloss: 0.110268\n",
      "[8466]\ttraining's auc: 0.992743\ttraining's binary_logloss: 0.11026\n",
      "[8467]\ttraining's auc: 0.992746\ttraining's binary_logloss: 0.110253\n",
      "[8468]\ttraining's auc: 0.992753\ttraining's binary_logloss: 0.110242\n",
      "[8469]\ttraining's auc: 0.992754\ttraining's binary_logloss: 0.11024\n",
      "[8470]\ttraining's auc: 0.992756\ttraining's binary_logloss: 0.110231\n",
      "[8471]\ttraining's auc: 0.99276\ttraining's binary_logloss: 0.110221\n",
      "[8472]\ttraining's auc: 0.992764\ttraining's binary_logloss: 0.110212\n",
      "[8473]\ttraining's auc: 0.992766\ttraining's binary_logloss: 0.110209\n",
      "[8474]\ttraining's auc: 0.992768\ttraining's binary_logloss: 0.110202\n",
      "[8475]\ttraining's auc: 0.992769\ttraining's binary_logloss: 0.110193\n",
      "[8476]\ttraining's auc: 0.992773\ttraining's binary_logloss: 0.110183\n",
      "[8477]\ttraining's auc: 0.992778\ttraining's binary_logloss: 0.110173\n",
      "[8478]\ttraining's auc: 0.99278\ttraining's binary_logloss: 0.110166\n",
      "[8479]\ttraining's auc: 0.992782\ttraining's binary_logloss: 0.110159\n",
      "[8480]\ttraining's auc: 0.992786\ttraining's binary_logloss: 0.110148\n",
      "[8481]\ttraining's auc: 0.992789\ttraining's binary_logloss: 0.110138\n",
      "[8482]\ttraining's auc: 0.992791\ttraining's binary_logloss: 0.110128\n",
      "[8483]\ttraining's auc: 0.992794\ttraining's binary_logloss: 0.110117\n",
      "[8484]\ttraining's auc: 0.992797\ttraining's binary_logloss: 0.110107\n",
      "[8485]\ttraining's auc: 0.992801\ttraining's binary_logloss: 0.110097\n",
      "[8486]\ttraining's auc: 0.992805\ttraining's binary_logloss: 0.110085\n",
      "[8487]\ttraining's auc: 0.992811\ttraining's binary_logloss: 0.110074\n",
      "[8488]\ttraining's auc: 0.992814\ttraining's binary_logloss: 0.110064\n",
      "[8489]\ttraining's auc: 0.992817\ttraining's binary_logloss: 0.110055\n",
      "[8490]\ttraining's auc: 0.992822\ttraining's binary_logloss: 0.110044\n",
      "[8491]\ttraining's auc: 0.992825\ttraining's binary_logloss: 0.110032\n",
      "[8492]\ttraining's auc: 0.992829\ttraining's binary_logloss: 0.110022\n",
      "[8493]\ttraining's auc: 0.99283\ttraining's binary_logloss: 0.110019\n",
      "[8494]\ttraining's auc: 0.992831\ttraining's binary_logloss: 0.110017\n",
      "[8495]\ttraining's auc: 0.992833\ttraining's binary_logloss: 0.110009\n",
      "[8496]\ttraining's auc: 0.992837\ttraining's binary_logloss: 0.110001\n",
      "[8497]\ttraining's auc: 0.992841\ttraining's binary_logloss: 0.10999\n",
      "[8498]\ttraining's auc: 0.992842\ttraining's binary_logloss: 0.109988\n",
      "[8499]\ttraining's auc: 0.992843\ttraining's binary_logloss: 0.109979\n",
      "[8500]\ttraining's auc: 0.992846\ttraining's binary_logloss: 0.109969\n",
      "[8501]\ttraining's auc: 0.992851\ttraining's binary_logloss: 0.10996\n",
      "[8502]\ttraining's auc: 0.992853\ttraining's binary_logloss: 0.109956\n",
      "[8503]\ttraining's auc: 0.992858\ttraining's binary_logloss: 0.109947\n",
      "[8504]\ttraining's auc: 0.992858\ttraining's binary_logloss: 0.109945\n",
      "[8505]\ttraining's auc: 0.992864\ttraining's binary_logloss: 0.109933\n",
      "[8506]\ttraining's auc: 0.992865\ttraining's binary_logloss: 0.109928\n",
      "[8507]\ttraining's auc: 0.992865\ttraining's binary_logloss: 0.109925\n",
      "[8508]\ttraining's auc: 0.992866\ttraining's binary_logloss: 0.109923\n",
      "[8509]\ttraining's auc: 0.992873\ttraining's binary_logloss: 0.109913\n",
      "[8510]\ttraining's auc: 0.992877\ttraining's binary_logloss: 0.109902\n",
      "[8511]\ttraining's auc: 0.992878\ttraining's binary_logloss: 0.109898\n",
      "[8512]\ttraining's auc: 0.992882\ttraining's binary_logloss: 0.109889\n",
      "[8513]\ttraining's auc: 0.992888\ttraining's binary_logloss: 0.109879\n",
      "[8514]\ttraining's auc: 0.99289\ttraining's binary_logloss: 0.10987\n",
      "[8515]\ttraining's auc: 0.992894\ttraining's binary_logloss: 0.10986\n",
      "[8516]\ttraining's auc: 0.992896\ttraining's binary_logloss: 0.109851\n",
      "[8517]\ttraining's auc: 0.992895\ttraining's binary_logloss: 0.10985\n",
      "[8518]\ttraining's auc: 0.992901\ttraining's binary_logloss: 0.109837\n",
      "[8519]\ttraining's auc: 0.992903\ttraining's binary_logloss: 0.109828\n",
      "[8520]\ttraining's auc: 0.992906\ttraining's binary_logloss: 0.109817\n",
      "[8521]\ttraining's auc: 0.992909\ttraining's binary_logloss: 0.109808\n",
      "[8522]\ttraining's auc: 0.992914\ttraining's binary_logloss: 0.109799\n",
      "[8523]\ttraining's auc: 0.992916\ttraining's binary_logloss: 0.109789\n",
      "[8524]\ttraining's auc: 0.992919\ttraining's binary_logloss: 0.109779\n",
      "[8525]\ttraining's auc: 0.992922\ttraining's binary_logloss: 0.109768\n",
      "[8526]\ttraining's auc: 0.992925\ttraining's binary_logloss: 0.109758\n",
      "[8527]\ttraining's auc: 0.992929\ttraining's binary_logloss: 0.109748\n",
      "[8528]\ttraining's auc: 0.992932\ttraining's binary_logloss: 0.109738\n",
      "[8529]\ttraining's auc: 0.992936\ttraining's binary_logloss: 0.109726\n",
      "[8530]\ttraining's auc: 0.99294\ttraining's binary_logloss: 0.109714\n",
      "[8531]\ttraining's auc: 0.992943\ttraining's binary_logloss: 0.109704\n",
      "[8532]\ttraining's auc: 0.992946\ttraining's binary_logloss: 0.109694\n",
      "[8533]\ttraining's auc: 0.992947\ttraining's binary_logloss: 0.109692\n",
      "[8534]\ttraining's auc: 0.992952\ttraining's binary_logloss: 0.109681\n",
      "[8535]\ttraining's auc: 0.992955\ttraining's binary_logloss: 0.109674\n",
      "[8536]\ttraining's auc: 0.992958\ttraining's binary_logloss: 0.109664\n",
      "[8537]\ttraining's auc: 0.992963\ttraining's binary_logloss: 0.109652\n",
      "[8538]\ttraining's auc: 0.992964\ttraining's binary_logloss: 0.109643\n",
      "[8539]\ttraining's auc: 0.992965\ttraining's binary_logloss: 0.109638\n",
      "[8540]\ttraining's auc: 0.992969\ttraining's binary_logloss: 0.109628\n",
      "[8541]\ttraining's auc: 0.992974\ttraining's binary_logloss: 0.109618\n",
      "[8542]\ttraining's auc: 0.992977\ttraining's binary_logloss: 0.109609\n",
      "[8543]\ttraining's auc: 0.99298\ttraining's binary_logloss: 0.109599\n",
      "[8544]\ttraining's auc: 0.992984\ttraining's binary_logloss: 0.109586\n",
      "[8545]\ttraining's auc: 0.992987\ttraining's binary_logloss: 0.109576\n",
      "[8546]\ttraining's auc: 0.992989\ttraining's binary_logloss: 0.109572\n",
      "[8547]\ttraining's auc: 0.992995\ttraining's binary_logloss: 0.10956\n",
      "[8548]\ttraining's auc: 0.992995\ttraining's binary_logloss: 0.109557\n",
      "[8549]\ttraining's auc: 0.992995\ttraining's binary_logloss: 0.109555\n",
      "[8550]\ttraining's auc: 0.993003\ttraining's binary_logloss: 0.109542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8551]\ttraining's auc: 0.993006\ttraining's binary_logloss: 0.109533\n",
      "[8552]\ttraining's auc: 0.993007\ttraining's binary_logloss: 0.109531\n",
      "[8553]\ttraining's auc: 0.993011\ttraining's binary_logloss: 0.10952\n",
      "[8554]\ttraining's auc: 0.993014\ttraining's binary_logloss: 0.109512\n",
      "[8555]\ttraining's auc: 0.993016\ttraining's binary_logloss: 0.109503\n",
      "[8556]\ttraining's auc: 0.993019\ttraining's binary_logloss: 0.109493\n",
      "[8557]\ttraining's auc: 0.99302\ttraining's binary_logloss: 0.109488\n",
      "[8558]\ttraining's auc: 0.993023\ttraining's binary_logloss: 0.109478\n",
      "[8559]\ttraining's auc: 0.993025\ttraining's binary_logloss: 0.109467\n",
      "[8560]\ttraining's auc: 0.993027\ttraining's binary_logloss: 0.109457\n",
      "[8561]\ttraining's auc: 0.993031\ttraining's binary_logloss: 0.109447\n",
      "[8562]\ttraining's auc: 0.993033\ttraining's binary_logloss: 0.10944\n",
      "[8563]\ttraining's auc: 0.993035\ttraining's binary_logloss: 0.109432\n",
      "[8564]\ttraining's auc: 0.99304\ttraining's binary_logloss: 0.109421\n",
      "[8565]\ttraining's auc: 0.993043\ttraining's binary_logloss: 0.109411\n",
      "[8566]\ttraining's auc: 0.993045\ttraining's binary_logloss: 0.109402\n",
      "[8567]\ttraining's auc: 0.993047\ttraining's binary_logloss: 0.109395\n",
      "[8568]\ttraining's auc: 0.993051\ttraining's binary_logloss: 0.109384\n",
      "[8569]\ttraining's auc: 0.993054\ttraining's binary_logloss: 0.109375\n",
      "[8570]\ttraining's auc: 0.993058\ttraining's binary_logloss: 0.109364\n",
      "[8571]\ttraining's auc: 0.993064\ttraining's binary_logloss: 0.109355\n",
      "[8572]\ttraining's auc: 0.993067\ttraining's binary_logloss: 0.109345\n",
      "[8573]\ttraining's auc: 0.993072\ttraining's binary_logloss: 0.109333\n",
      "[8574]\ttraining's auc: 0.993074\ttraining's binary_logloss: 0.109324\n",
      "[8575]\ttraining's auc: 0.99308\ttraining's binary_logloss: 0.109315\n",
      "[8576]\ttraining's auc: 0.993082\ttraining's binary_logloss: 0.109305\n",
      "[8577]\ttraining's auc: 0.993087\ttraining's binary_logloss: 0.109294\n",
      "[8578]\ttraining's auc: 0.99309\ttraining's binary_logloss: 0.109287\n",
      "[8579]\ttraining's auc: 0.993094\ttraining's binary_logloss: 0.109275\n",
      "[8580]\ttraining's auc: 0.993097\ttraining's binary_logloss: 0.109266\n",
      "[8581]\ttraining's auc: 0.993101\ttraining's binary_logloss: 0.109254\n",
      "[8582]\ttraining's auc: 0.993104\ttraining's binary_logloss: 0.109243\n",
      "[8583]\ttraining's auc: 0.993107\ttraining's binary_logloss: 0.109233\n",
      "[8584]\ttraining's auc: 0.993108\ttraining's binary_logloss: 0.109223\n",
      "[8585]\ttraining's auc: 0.993112\ttraining's binary_logloss: 0.109213\n",
      "[8586]\ttraining's auc: 0.993115\ttraining's binary_logloss: 0.109203\n",
      "[8587]\ttraining's auc: 0.993119\ttraining's binary_logloss: 0.109194\n",
      "[8588]\ttraining's auc: 0.993123\ttraining's binary_logloss: 0.109185\n",
      "[8589]\ttraining's auc: 0.993124\ttraining's binary_logloss: 0.109182\n",
      "[8590]\ttraining's auc: 0.993126\ttraining's binary_logloss: 0.109172\n",
      "[8591]\ttraining's auc: 0.993131\ttraining's binary_logloss: 0.109161\n",
      "[8592]\ttraining's auc: 0.993134\ttraining's binary_logloss: 0.109151\n",
      "[8593]\ttraining's auc: 0.993137\ttraining's binary_logloss: 0.10914\n",
      "[8594]\ttraining's auc: 0.993139\ttraining's binary_logloss: 0.109131\n",
      "[8595]\ttraining's auc: 0.993139\ttraining's binary_logloss: 0.109129\n",
      "[8596]\ttraining's auc: 0.993142\ttraining's binary_logloss: 0.109118\n",
      "[8597]\ttraining's auc: 0.993146\ttraining's binary_logloss: 0.109108\n",
      "[8598]\ttraining's auc: 0.993149\ttraining's binary_logloss: 0.109099\n",
      "[8599]\ttraining's auc: 0.993153\ttraining's binary_logloss: 0.109088\n",
      "[8600]\ttraining's auc: 0.993154\ttraining's binary_logloss: 0.109078\n",
      "[8601]\ttraining's auc: 0.993157\ttraining's binary_logloss: 0.109068\n",
      "[8602]\ttraining's auc: 0.99316\ttraining's binary_logloss: 0.109057\n",
      "[8603]\ttraining's auc: 0.993162\ttraining's binary_logloss: 0.109053\n",
      "[8604]\ttraining's auc: 0.993164\ttraining's binary_logloss: 0.109049\n",
      "[8605]\ttraining's auc: 0.993165\ttraining's binary_logloss: 0.109045\n",
      "[8606]\ttraining's auc: 0.993168\ttraining's binary_logloss: 0.109035\n",
      "[8607]\ttraining's auc: 0.993169\ttraining's binary_logloss: 0.109028\n",
      "[8608]\ttraining's auc: 0.993171\ttraining's binary_logloss: 0.109017\n",
      "[8609]\ttraining's auc: 0.993174\ttraining's binary_logloss: 0.109007\n",
      "[8610]\ttraining's auc: 0.99318\ttraining's binary_logloss: 0.108995\n",
      "[8611]\ttraining's auc: 0.993185\ttraining's binary_logloss: 0.108985\n",
      "[8612]\ttraining's auc: 0.99319\ttraining's binary_logloss: 0.108972\n",
      "[8613]\ttraining's auc: 0.993192\ttraining's binary_logloss: 0.108969\n",
      "[8614]\ttraining's auc: 0.993197\ttraining's binary_logloss: 0.108957\n",
      "[8615]\ttraining's auc: 0.9932\ttraining's binary_logloss: 0.108947\n",
      "[8616]\ttraining's auc: 0.993201\ttraining's binary_logloss: 0.108937\n",
      "[8617]\ttraining's auc: 0.993203\ttraining's binary_logloss: 0.108926\n",
      "[8618]\ttraining's auc: 0.99321\ttraining's binary_logloss: 0.108915\n",
      "[8619]\ttraining's auc: 0.993213\ttraining's binary_logloss: 0.108905\n",
      "[8620]\ttraining's auc: 0.993216\ttraining's binary_logloss: 0.108895\n",
      "[8621]\ttraining's auc: 0.993219\ttraining's binary_logloss: 0.108885\n",
      "[8622]\ttraining's auc: 0.993223\ttraining's binary_logloss: 0.108874\n",
      "[8623]\ttraining's auc: 0.993225\ttraining's binary_logloss: 0.108866\n",
      "[8624]\ttraining's auc: 0.99323\ttraining's binary_logloss: 0.108854\n",
      "[8625]\ttraining's auc: 0.993234\ttraining's binary_logloss: 0.108846\n",
      "[8626]\ttraining's auc: 0.99324\ttraining's binary_logloss: 0.108834\n",
      "[8627]\ttraining's auc: 0.993242\ttraining's binary_logloss: 0.108829\n",
      "[8628]\ttraining's auc: 0.993243\ttraining's binary_logloss: 0.108823\n",
      "[8629]\ttraining's auc: 0.993247\ttraining's binary_logloss: 0.108813\n",
      "[8630]\ttraining's auc: 0.993248\ttraining's binary_logloss: 0.10881\n",
      "[8631]\ttraining's auc: 0.993253\ttraining's binary_logloss: 0.108801\n",
      "[8632]\ttraining's auc: 0.993255\ttraining's binary_logloss: 0.10879\n",
      "[8633]\ttraining's auc: 0.993258\ttraining's binary_logloss: 0.108783\n",
      "[8634]\ttraining's auc: 0.993262\ttraining's binary_logloss: 0.108773\n",
      "[8635]\ttraining's auc: 0.993269\ttraining's binary_logloss: 0.108762\n",
      "[8636]\ttraining's auc: 0.993272\ttraining's binary_logloss: 0.108754\n",
      "[8637]\ttraining's auc: 0.993275\ttraining's binary_logloss: 0.108744\n",
      "[8638]\ttraining's auc: 0.993279\ttraining's binary_logloss: 0.108732\n",
      "[8639]\ttraining's auc: 0.993283\ttraining's binary_logloss: 0.108721\n",
      "[8640]\ttraining's auc: 0.993286\ttraining's binary_logloss: 0.108711\n",
      "[8641]\ttraining's auc: 0.99329\ttraining's binary_logloss: 0.108701\n",
      "[8642]\ttraining's auc: 0.993295\ttraining's binary_logloss: 0.108688\n",
      "[8643]\ttraining's auc: 0.993297\ttraining's binary_logloss: 0.10868\n",
      "[8644]\ttraining's auc: 0.993299\ttraining's binary_logloss: 0.108675\n",
      "[8645]\ttraining's auc: 0.993302\ttraining's binary_logloss: 0.108665\n",
      "[8646]\ttraining's auc: 0.993305\ttraining's binary_logloss: 0.108655\n",
      "[8647]\ttraining's auc: 0.993307\ttraining's binary_logloss: 0.108645\n",
      "[8648]\ttraining's auc: 0.993311\ttraining's binary_logloss: 0.108633\n",
      "[8649]\ttraining's auc: 0.993315\ttraining's binary_logloss: 0.108623\n",
      "[8650]\ttraining's auc: 0.993319\ttraining's binary_logloss: 0.108612\n",
      "[8651]\ttraining's auc: 0.993321\ttraining's binary_logloss: 0.108602\n",
      "[8652]\ttraining's auc: 0.993328\ttraining's binary_logloss: 0.108591\n",
      "[8653]\ttraining's auc: 0.993331\ttraining's binary_logloss: 0.108582\n",
      "[8654]\ttraining's auc: 0.993334\ttraining's binary_logloss: 0.108572\n",
      "[8655]\ttraining's auc: 0.99334\ttraining's binary_logloss: 0.108561\n",
      "[8656]\ttraining's auc: 0.993341\ttraining's binary_logloss: 0.10855\n",
      "[8657]\ttraining's auc: 0.993346\ttraining's binary_logloss: 0.108541\n",
      "[8658]\ttraining's auc: 0.993349\ttraining's binary_logloss: 0.10853\n",
      "[8659]\ttraining's auc: 0.993351\ttraining's binary_logloss: 0.108523\n",
      "[8660]\ttraining's auc: 0.993354\ttraining's binary_logloss: 0.108515\n",
      "[8661]\ttraining's auc: 0.993358\ttraining's binary_logloss: 0.108507\n",
      "[8662]\ttraining's auc: 0.993362\ttraining's binary_logloss: 0.108497\n",
      "[8663]\ttraining's auc: 0.993363\ttraining's binary_logloss: 0.108494\n",
      "[8664]\ttraining's auc: 0.993365\ttraining's binary_logloss: 0.108485\n",
      "[8665]\ttraining's auc: 0.993368\ttraining's binary_logloss: 0.108474\n",
      "[8666]\ttraining's auc: 0.99337\ttraining's binary_logloss: 0.108465\n",
      "[8667]\ttraining's auc: 0.993374\ttraining's binary_logloss: 0.108455\n",
      "[8668]\ttraining's auc: 0.99338\ttraining's binary_logloss: 0.108442\n",
      "[8669]\ttraining's auc: 0.993383\ttraining's binary_logloss: 0.108432\n",
      "[8670]\ttraining's auc: 0.993387\ttraining's binary_logloss: 0.108423\n",
      "[8671]\ttraining's auc: 0.993389\ttraining's binary_logloss: 0.108415\n",
      "[8672]\ttraining's auc: 0.993392\ttraining's binary_logloss: 0.108405\n",
      "[8673]\ttraining's auc: 0.993396\ttraining's binary_logloss: 0.108394\n",
      "[8674]\ttraining's auc: 0.9934\ttraining's binary_logloss: 0.108383\n",
      "[8675]\ttraining's auc: 0.993403\ttraining's binary_logloss: 0.108373\n",
      "[8676]\ttraining's auc: 0.993404\ttraining's binary_logloss: 0.108364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8677]\ttraining's auc: 0.993407\ttraining's binary_logloss: 0.108357\n",
      "[8678]\ttraining's auc: 0.993411\ttraining's binary_logloss: 0.108347\n",
      "[8679]\ttraining's auc: 0.993415\ttraining's binary_logloss: 0.108337\n",
      "[8680]\ttraining's auc: 0.993417\ttraining's binary_logloss: 0.108326\n",
      "[8681]\ttraining's auc: 0.993419\ttraining's binary_logloss: 0.10832\n",
      "[8682]\ttraining's auc: 0.993421\ttraining's binary_logloss: 0.10831\n",
      "[8683]\ttraining's auc: 0.993423\ttraining's binary_logloss: 0.108302\n",
      "[8684]\ttraining's auc: 0.993426\ttraining's binary_logloss: 0.108294\n",
      "[8685]\ttraining's auc: 0.993429\ttraining's binary_logloss: 0.108285\n",
      "[8686]\ttraining's auc: 0.993432\ttraining's binary_logloss: 0.108276\n",
      "[8687]\ttraining's auc: 0.993435\ttraining's binary_logloss: 0.108267\n",
      "[8688]\ttraining's auc: 0.993441\ttraining's binary_logloss: 0.108256\n",
      "[8689]\ttraining's auc: 0.993443\ttraining's binary_logloss: 0.108246\n",
      "[8690]\ttraining's auc: 0.993446\ttraining's binary_logloss: 0.108236\n",
      "[8691]\ttraining's auc: 0.993449\ttraining's binary_logloss: 0.108226\n",
      "[8692]\ttraining's auc: 0.993453\ttraining's binary_logloss: 0.108216\n",
      "[8693]\ttraining's auc: 0.993457\ttraining's binary_logloss: 0.108209\n",
      "[8694]\ttraining's auc: 0.993461\ttraining's binary_logloss: 0.108199\n",
      "[8695]\ttraining's auc: 0.993464\ttraining's binary_logloss: 0.108193\n",
      "[8696]\ttraining's auc: 0.993468\ttraining's binary_logloss: 0.108182\n",
      "[8697]\ttraining's auc: 0.99347\ttraining's binary_logloss: 0.108174\n",
      "[8698]\ttraining's auc: 0.993471\ttraining's binary_logloss: 0.108166\n",
      "[8699]\ttraining's auc: 0.993475\ttraining's binary_logloss: 0.108156\n",
      "[8700]\ttraining's auc: 0.993478\ttraining's binary_logloss: 0.108147\n",
      "[8701]\ttraining's auc: 0.993483\ttraining's binary_logloss: 0.108137\n",
      "[8702]\ttraining's auc: 0.993485\ttraining's binary_logloss: 0.108127\n",
      "[8703]\ttraining's auc: 0.993488\ttraining's binary_logloss: 0.108119\n",
      "[8704]\ttraining's auc: 0.99349\ttraining's binary_logloss: 0.10811\n",
      "[8705]\ttraining's auc: 0.993493\ttraining's binary_logloss: 0.1081\n",
      "[8706]\ttraining's auc: 0.993498\ttraining's binary_logloss: 0.108091\n",
      "[8707]\ttraining's auc: 0.993499\ttraining's binary_logloss: 0.108082\n",
      "[8708]\ttraining's auc: 0.993501\ttraining's binary_logloss: 0.108071\n",
      "[8709]\ttraining's auc: 0.993504\ttraining's binary_logloss: 0.108062\n",
      "[8710]\ttraining's auc: 0.993505\ttraining's binary_logloss: 0.108053\n",
      "[8711]\ttraining's auc: 0.993509\ttraining's binary_logloss: 0.108045\n",
      "[8712]\ttraining's auc: 0.993512\ttraining's binary_logloss: 0.108037\n",
      "[8713]\ttraining's auc: 0.993516\ttraining's binary_logloss: 0.108027\n",
      "[8714]\ttraining's auc: 0.993519\ttraining's binary_logloss: 0.108017\n",
      "[8715]\ttraining's auc: 0.993521\ttraining's binary_logloss: 0.108007\n",
      "[8716]\ttraining's auc: 0.993524\ttraining's binary_logloss: 0.107998\n",
      "[8717]\ttraining's auc: 0.993526\ttraining's binary_logloss: 0.107988\n",
      "[8718]\ttraining's auc: 0.99353\ttraining's binary_logloss: 0.107977\n",
      "[8719]\ttraining's auc: 0.993532\ttraining's binary_logloss: 0.107968\n",
      "[8720]\ttraining's auc: 0.993536\ttraining's binary_logloss: 0.107958\n",
      "[8721]\ttraining's auc: 0.993539\ttraining's binary_logloss: 0.107948\n",
      "[8722]\ttraining's auc: 0.99354\ttraining's binary_logloss: 0.107937\n",
      "[8723]\ttraining's auc: 0.993545\ttraining's binary_logloss: 0.107925\n",
      "[8724]\ttraining's auc: 0.993546\ttraining's binary_logloss: 0.107917\n",
      "[8725]\ttraining's auc: 0.993551\ttraining's binary_logloss: 0.107904\n",
      "[8726]\ttraining's auc: 0.993555\ttraining's binary_logloss: 0.107895\n",
      "[8727]\ttraining's auc: 0.993556\ttraining's binary_logloss: 0.107888\n",
      "[8728]\ttraining's auc: 0.993559\ttraining's binary_logloss: 0.107878\n",
      "[8729]\ttraining's auc: 0.993563\ttraining's binary_logloss: 0.107868\n",
      "[8730]\ttraining's auc: 0.993568\ttraining's binary_logloss: 0.107859\n",
      "[8731]\ttraining's auc: 0.99357\ttraining's binary_logloss: 0.107852\n",
      "[8732]\ttraining's auc: 0.993572\ttraining's binary_logloss: 0.107842\n",
      "[8733]\ttraining's auc: 0.993575\ttraining's binary_logloss: 0.107831\n",
      "[8734]\ttraining's auc: 0.993577\ttraining's binary_logloss: 0.107822\n",
      "[8735]\ttraining's auc: 0.99358\ttraining's binary_logloss: 0.107812\n",
      "[8736]\ttraining's auc: 0.993584\ttraining's binary_logloss: 0.107801\n",
      "[8737]\ttraining's auc: 0.993589\ttraining's binary_logloss: 0.10779\n",
      "[8738]\ttraining's auc: 0.993591\ttraining's binary_logloss: 0.107781\n",
      "[8739]\ttraining's auc: 0.993595\ttraining's binary_logloss: 0.107771\n",
      "[8740]\ttraining's auc: 0.993598\ttraining's binary_logloss: 0.10776\n",
      "[8741]\ttraining's auc: 0.993602\ttraining's binary_logloss: 0.10775\n",
      "[8742]\ttraining's auc: 0.993604\ttraining's binary_logloss: 0.107741\n",
      "[8743]\ttraining's auc: 0.993608\ttraining's binary_logloss: 0.10773\n",
      "[8744]\ttraining's auc: 0.99361\ttraining's binary_logloss: 0.107719\n",
      "[8745]\ttraining's auc: 0.993611\ttraining's binary_logloss: 0.107712\n",
      "[8746]\ttraining's auc: 0.993614\ttraining's binary_logloss: 0.107702\n",
      "[8747]\ttraining's auc: 0.993617\ttraining's binary_logloss: 0.107693\n",
      "[8748]\ttraining's auc: 0.993621\ttraining's binary_logloss: 0.107682\n",
      "[8749]\ttraining's auc: 0.993622\ttraining's binary_logloss: 0.107675\n",
      "[8750]\ttraining's auc: 0.993624\ttraining's binary_logloss: 0.107666\n",
      "[8751]\ttraining's auc: 0.993627\ttraining's binary_logloss: 0.107656\n",
      "[8752]\ttraining's auc: 0.993633\ttraining's binary_logloss: 0.107646\n",
      "[8753]\ttraining's auc: 0.993634\ttraining's binary_logloss: 0.107639\n",
      "[8754]\ttraining's auc: 0.993636\ttraining's binary_logloss: 0.107629\n",
      "[8755]\ttraining's auc: 0.99364\ttraining's binary_logloss: 0.10762\n",
      "[8756]\ttraining's auc: 0.993643\ttraining's binary_logloss: 0.107611\n",
      "[8757]\ttraining's auc: 0.993646\ttraining's binary_logloss: 0.107602\n",
      "[8758]\ttraining's auc: 0.993649\ttraining's binary_logloss: 0.107592\n",
      "[8759]\ttraining's auc: 0.993652\ttraining's binary_logloss: 0.107583\n",
      "[8760]\ttraining's auc: 0.993653\ttraining's binary_logloss: 0.107578\n",
      "[8761]\ttraining's auc: 0.993656\ttraining's binary_logloss: 0.107568\n",
      "[8762]\ttraining's auc: 0.993658\ttraining's binary_logloss: 0.10756\n",
      "[8763]\ttraining's auc: 0.99366\ttraining's binary_logloss: 0.107553\n",
      "[8764]\ttraining's auc: 0.993664\ttraining's binary_logloss: 0.107543\n",
      "[8765]\ttraining's auc: 0.993667\ttraining's binary_logloss: 0.107534\n",
      "[8766]\ttraining's auc: 0.993667\ttraining's binary_logloss: 0.107533\n",
      "[8767]\ttraining's auc: 0.993669\ttraining's binary_logloss: 0.107523\n",
      "[8768]\ttraining's auc: 0.993673\ttraining's binary_logloss: 0.107514\n",
      "[8769]\ttraining's auc: 0.993676\ttraining's binary_logloss: 0.107503\n",
      "[8770]\ttraining's auc: 0.993676\ttraining's binary_logloss: 0.107493\n",
      "[8771]\ttraining's auc: 0.993678\ttraining's binary_logloss: 0.107483\n",
      "[8772]\ttraining's auc: 0.993681\ttraining's binary_logloss: 0.107474\n",
      "[8773]\ttraining's auc: 0.993684\ttraining's binary_logloss: 0.107464\n",
      "[8774]\ttraining's auc: 0.993686\ttraining's binary_logloss: 0.107457\n",
      "[8775]\ttraining's auc: 0.993689\ttraining's binary_logloss: 0.107446\n",
      "[8776]\ttraining's auc: 0.993692\ttraining's binary_logloss: 0.107436\n",
      "[8777]\ttraining's auc: 0.993695\ttraining's binary_logloss: 0.107426\n",
      "[8778]\ttraining's auc: 0.993697\ttraining's binary_logloss: 0.107417\n",
      "[8779]\ttraining's auc: 0.9937\ttraining's binary_logloss: 0.107408\n",
      "[8780]\ttraining's auc: 0.993704\ttraining's binary_logloss: 0.107399\n",
      "[8781]\ttraining's auc: 0.993708\ttraining's binary_logloss: 0.10739\n",
      "[8782]\ttraining's auc: 0.993711\ttraining's binary_logloss: 0.10738\n",
      "[8783]\ttraining's auc: 0.993713\ttraining's binary_logloss: 0.107372\n",
      "[8784]\ttraining's auc: 0.993716\ttraining's binary_logloss: 0.107362\n",
      "[8785]\ttraining's auc: 0.993718\ttraining's binary_logloss: 0.10735\n",
      "[8786]\ttraining's auc: 0.993721\ttraining's binary_logloss: 0.107341\n",
      "[8787]\ttraining's auc: 0.993724\ttraining's binary_logloss: 0.107332\n",
      "[8788]\ttraining's auc: 0.993726\ttraining's binary_logloss: 0.107323\n",
      "[8789]\ttraining's auc: 0.993728\ttraining's binary_logloss: 0.107319\n",
      "[8790]\ttraining's auc: 0.993731\ttraining's binary_logloss: 0.107308\n",
      "[8791]\ttraining's auc: 0.993731\ttraining's binary_logloss: 0.107304\n",
      "[8792]\ttraining's auc: 0.993731\ttraining's binary_logloss: 0.107302\n",
      "[8793]\ttraining's auc: 0.993734\ttraining's binary_logloss: 0.107292\n",
      "[8794]\ttraining's auc: 0.993736\ttraining's binary_logloss: 0.107281\n",
      "[8795]\ttraining's auc: 0.993739\ttraining's binary_logloss: 0.107272\n",
      "[8796]\ttraining's auc: 0.993742\ttraining's binary_logloss: 0.107262\n",
      "[8797]\ttraining's auc: 0.993746\ttraining's binary_logloss: 0.107251\n",
      "[8798]\ttraining's auc: 0.993748\ttraining's binary_logloss: 0.10724\n",
      "[8799]\ttraining's auc: 0.99375\ttraining's binary_logloss: 0.107231\n",
      "[8800]\ttraining's auc: 0.993753\ttraining's binary_logloss: 0.107221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8801]\ttraining's auc: 0.993757\ttraining's binary_logloss: 0.107208\n",
      "[8802]\ttraining's auc: 0.993759\ttraining's binary_logloss: 0.107202\n",
      "[8803]\ttraining's auc: 0.993758\ttraining's binary_logloss: 0.107193\n",
      "[8804]\ttraining's auc: 0.993762\ttraining's binary_logloss: 0.107183\n",
      "[8805]\ttraining's auc: 0.993765\ttraining's binary_logloss: 0.107173\n",
      "[8806]\ttraining's auc: 0.993768\ttraining's binary_logloss: 0.107163\n",
      "[8807]\ttraining's auc: 0.993772\ttraining's binary_logloss: 0.107151\n",
      "[8808]\ttraining's auc: 0.993775\ttraining's binary_logloss: 0.107143\n",
      "[8809]\ttraining's auc: 0.993776\ttraining's binary_logloss: 0.107135\n",
      "[8810]\ttraining's auc: 0.993779\ttraining's binary_logloss: 0.107128\n",
      "[8811]\ttraining's auc: 0.993779\ttraining's binary_logloss: 0.107123\n",
      "[8812]\ttraining's auc: 0.99378\ttraining's binary_logloss: 0.10712\n",
      "[8813]\ttraining's auc: 0.993784\ttraining's binary_logloss: 0.10711\n",
      "[8814]\ttraining's auc: 0.993789\ttraining's binary_logloss: 0.1071\n",
      "[8815]\ttraining's auc: 0.993793\ttraining's binary_logloss: 0.10709\n",
      "[8816]\ttraining's auc: 0.993796\ttraining's binary_logloss: 0.107082\n",
      "[8817]\ttraining's auc: 0.993798\ttraining's binary_logloss: 0.107073\n",
      "[8818]\ttraining's auc: 0.993801\ttraining's binary_logloss: 0.107064\n",
      "[8819]\ttraining's auc: 0.993804\ttraining's binary_logloss: 0.107054\n",
      "[8820]\ttraining's auc: 0.993807\ttraining's binary_logloss: 0.107044\n",
      "[8821]\ttraining's auc: 0.993811\ttraining's binary_logloss: 0.107034\n",
      "[8822]\ttraining's auc: 0.993813\ttraining's binary_logloss: 0.107026\n",
      "[8823]\ttraining's auc: 0.993815\ttraining's binary_logloss: 0.107017\n",
      "[8824]\ttraining's auc: 0.993818\ttraining's binary_logloss: 0.107008\n",
      "[8825]\ttraining's auc: 0.993822\ttraining's binary_logloss: 0.106996\n",
      "[8826]\ttraining's auc: 0.993826\ttraining's binary_logloss: 0.106986\n",
      "[8827]\ttraining's auc: 0.99383\ttraining's binary_logloss: 0.106976\n",
      "[8828]\ttraining's auc: 0.993835\ttraining's binary_logloss: 0.106965\n",
      "[8829]\ttraining's auc: 0.993839\ttraining's binary_logloss: 0.106955\n",
      "[8830]\ttraining's auc: 0.993841\ttraining's binary_logloss: 0.106946\n",
      "[8831]\ttraining's auc: 0.993845\ttraining's binary_logloss: 0.106936\n",
      "[8832]\ttraining's auc: 0.993849\ttraining's binary_logloss: 0.106927\n",
      "[8833]\ttraining's auc: 0.993851\ttraining's binary_logloss: 0.106918\n",
      "[8834]\ttraining's auc: 0.993854\ttraining's binary_logloss: 0.106908\n",
      "[8835]\ttraining's auc: 0.993856\ttraining's binary_logloss: 0.106896\n",
      "[8836]\ttraining's auc: 0.993858\ttraining's binary_logloss: 0.106889\n",
      "[8837]\ttraining's auc: 0.993862\ttraining's binary_logloss: 0.106879\n",
      "[8838]\ttraining's auc: 0.993864\ttraining's binary_logloss: 0.106871\n",
      "[8839]\ttraining's auc: 0.993867\ttraining's binary_logloss: 0.106861\n",
      "[8840]\ttraining's auc: 0.993868\ttraining's binary_logloss: 0.106851\n",
      "[8841]\ttraining's auc: 0.99387\ttraining's binary_logloss: 0.106842\n",
      "[8842]\ttraining's auc: 0.993872\ttraining's binary_logloss: 0.106833\n",
      "[8843]\ttraining's auc: 0.993874\ttraining's binary_logloss: 0.106822\n",
      "[8844]\ttraining's auc: 0.993877\ttraining's binary_logloss: 0.106814\n",
      "[8845]\ttraining's auc: 0.993878\ttraining's binary_logloss: 0.106808\n",
      "[8846]\ttraining's auc: 0.993881\ttraining's binary_logloss: 0.106799\n",
      "[8847]\ttraining's auc: 0.993881\ttraining's binary_logloss: 0.106797\n",
      "[8848]\ttraining's auc: 0.993883\ttraining's binary_logloss: 0.10679\n",
      "[8849]\ttraining's auc: 0.993888\ttraining's binary_logloss: 0.10678\n",
      "[8850]\ttraining's auc: 0.993893\ttraining's binary_logloss: 0.106769\n",
      "[8851]\ttraining's auc: 0.993896\ttraining's binary_logloss: 0.10676\n",
      "[8852]\ttraining's auc: 0.993897\ttraining's binary_logloss: 0.106754\n",
      "[8853]\ttraining's auc: 0.993899\ttraining's binary_logloss: 0.106747\n",
      "[8854]\ttraining's auc: 0.993901\ttraining's binary_logloss: 0.106746\n",
      "[8855]\ttraining's auc: 0.993901\ttraining's binary_logloss: 0.106744\n",
      "[8856]\ttraining's auc: 0.993904\ttraining's binary_logloss: 0.106733\n",
      "[8857]\ttraining's auc: 0.993905\ttraining's binary_logloss: 0.106729\n",
      "[8858]\ttraining's auc: 0.993906\ttraining's binary_logloss: 0.106724\n",
      "[8859]\ttraining's auc: 0.993909\ttraining's binary_logloss: 0.106716\n",
      "[8860]\ttraining's auc: 0.993913\ttraining's binary_logloss: 0.106705\n",
      "[8861]\ttraining's auc: 0.993915\ttraining's binary_logloss: 0.106696\n",
      "[8862]\ttraining's auc: 0.993918\ttraining's binary_logloss: 0.106686\n",
      "[8863]\ttraining's auc: 0.99392\ttraining's binary_logloss: 0.106677\n",
      "[8864]\ttraining's auc: 0.993923\ttraining's binary_logloss: 0.106667\n",
      "[8865]\ttraining's auc: 0.993926\ttraining's binary_logloss: 0.106658\n",
      "[8866]\ttraining's auc: 0.993929\ttraining's binary_logloss: 0.106648\n",
      "[8867]\ttraining's auc: 0.993932\ttraining's binary_logloss: 0.106638\n",
      "[8868]\ttraining's auc: 0.993935\ttraining's binary_logloss: 0.106628\n",
      "[8869]\ttraining's auc: 0.993939\ttraining's binary_logloss: 0.106618\n",
      "[8870]\ttraining's auc: 0.993942\ttraining's binary_logloss: 0.106606\n",
      "[8871]\ttraining's auc: 0.993944\ttraining's binary_logloss: 0.106597\n",
      "[8872]\ttraining's auc: 0.993948\ttraining's binary_logloss: 0.106586\n",
      "[8873]\ttraining's auc: 0.993948\ttraining's binary_logloss: 0.106583\n",
      "[8874]\ttraining's auc: 0.993953\ttraining's binary_logloss: 0.106573\n",
      "[8875]\ttraining's auc: 0.993954\ttraining's binary_logloss: 0.106572\n",
      "[8876]\ttraining's auc: 0.993956\ttraining's binary_logloss: 0.106565\n",
      "[8877]\ttraining's auc: 0.993958\ttraining's binary_logloss: 0.106556\n",
      "[8878]\ttraining's auc: 0.993961\ttraining's binary_logloss: 0.106546\n",
      "[8879]\ttraining's auc: 0.993963\ttraining's binary_logloss: 0.106538\n",
      "[8880]\ttraining's auc: 0.993966\ttraining's binary_logloss: 0.106527\n",
      "[8881]\ttraining's auc: 0.993967\ttraining's binary_logloss: 0.106526\n",
      "[8882]\ttraining's auc: 0.993971\ttraining's binary_logloss: 0.106518\n",
      "[8883]\ttraining's auc: 0.993973\ttraining's binary_logloss: 0.106514\n",
      "[8884]\ttraining's auc: 0.993974\ttraining's binary_logloss: 0.10651\n",
      "[8885]\ttraining's auc: 0.993975\ttraining's binary_logloss: 0.106507\n",
      "[8886]\ttraining's auc: 0.993978\ttraining's binary_logloss: 0.106497\n",
      "[8887]\ttraining's auc: 0.993979\ttraining's binary_logloss: 0.106488\n",
      "[8888]\ttraining's auc: 0.993984\ttraining's binary_logloss: 0.106476\n",
      "[8889]\ttraining's auc: 0.993987\ttraining's binary_logloss: 0.106467\n",
      "[8890]\ttraining's auc: 0.993991\ttraining's binary_logloss: 0.106457\n",
      "[8891]\ttraining's auc: 0.993995\ttraining's binary_logloss: 0.10645\n",
      "[8892]\ttraining's auc: 0.993998\ttraining's binary_logloss: 0.10644\n",
      "[8893]\ttraining's auc: 0.993999\ttraining's binary_logloss: 0.106436\n",
      "[8894]\ttraining's auc: 0.994003\ttraining's binary_logloss: 0.106425\n",
      "[8895]\ttraining's auc: 0.994006\ttraining's binary_logloss: 0.106414\n",
      "[8896]\ttraining's auc: 0.994008\ttraining's binary_logloss: 0.106404\n",
      "[8897]\ttraining's auc: 0.994011\ttraining's binary_logloss: 0.106393\n",
      "[8898]\ttraining's auc: 0.994014\ttraining's binary_logloss: 0.106384\n",
      "[8899]\ttraining's auc: 0.994018\ttraining's binary_logloss: 0.106378\n",
      "[8900]\ttraining's auc: 0.99402\ttraining's binary_logloss: 0.106368\n",
      "[8901]\ttraining's auc: 0.994025\ttraining's binary_logloss: 0.106355\n",
      "[8902]\ttraining's auc: 0.994026\ttraining's binary_logloss: 0.106346\n",
      "[8903]\ttraining's auc: 0.99403\ttraining's binary_logloss: 0.106337\n",
      "[8904]\ttraining's auc: 0.994033\ttraining's binary_logloss: 0.106329\n",
      "[8905]\ttraining's auc: 0.994034\ttraining's binary_logloss: 0.106327\n",
      "[8906]\ttraining's auc: 0.994035\ttraining's binary_logloss: 0.106321\n",
      "[8907]\ttraining's auc: 0.994037\ttraining's binary_logloss: 0.106312\n",
      "[8908]\ttraining's auc: 0.99404\ttraining's binary_logloss: 0.106302\n",
      "[8909]\ttraining's auc: 0.994042\ttraining's binary_logloss: 0.106294\n",
      "[8910]\ttraining's auc: 0.994044\ttraining's binary_logloss: 0.106285\n",
      "[8911]\ttraining's auc: 0.994045\ttraining's binary_logloss: 0.106277\n",
      "[8912]\ttraining's auc: 0.994046\ttraining's binary_logloss: 0.106267\n",
      "[8913]\ttraining's auc: 0.99405\ttraining's binary_logloss: 0.106257\n",
      "[8914]\ttraining's auc: 0.994053\ttraining's binary_logloss: 0.106248\n",
      "[8915]\ttraining's auc: 0.994057\ttraining's binary_logloss: 0.106238\n",
      "[8916]\ttraining's auc: 0.99406\ttraining's binary_logloss: 0.106228\n",
      "[8917]\ttraining's auc: 0.994062\ttraining's binary_logloss: 0.10622\n",
      "[8918]\ttraining's auc: 0.994066\ttraining's binary_logloss: 0.106211\n",
      "[8919]\ttraining's auc: 0.994068\ttraining's binary_logloss: 0.106203\n",
      "[8920]\ttraining's auc: 0.994069\ttraining's binary_logloss: 0.106196\n",
      "[8921]\ttraining's auc: 0.99407\ttraining's binary_logloss: 0.106188\n",
      "[8922]\ttraining's auc: 0.994072\ttraining's binary_logloss: 0.10618\n",
      "[8923]\ttraining's auc: 0.994073\ttraining's binary_logloss: 0.106172\n",
      "[8924]\ttraining's auc: 0.994076\ttraining's binary_logloss: 0.106162\n",
      "[8925]\ttraining's auc: 0.994078\ttraining's binary_logloss: 0.106154\n",
      "[8926]\ttraining's auc: 0.994081\ttraining's binary_logloss: 0.106144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8927]\ttraining's auc: 0.994085\ttraining's binary_logloss: 0.106133\n",
      "[8928]\ttraining's auc: 0.994088\ttraining's binary_logloss: 0.106124\n",
      "[8929]\ttraining's auc: 0.99409\ttraining's binary_logloss: 0.106115\n",
      "[8930]\ttraining's auc: 0.994092\ttraining's binary_logloss: 0.106106\n",
      "[8931]\ttraining's auc: 0.994093\ttraining's binary_logloss: 0.106102\n",
      "[8932]\ttraining's auc: 0.994094\ttraining's binary_logloss: 0.106095\n",
      "[8933]\ttraining's auc: 0.994097\ttraining's binary_logloss: 0.106086\n",
      "[8934]\ttraining's auc: 0.994099\ttraining's binary_logloss: 0.106079\n",
      "[8935]\ttraining's auc: 0.994102\ttraining's binary_logloss: 0.106069\n",
      "[8936]\ttraining's auc: 0.994103\ttraining's binary_logloss: 0.106067\n",
      "[8937]\ttraining's auc: 0.994105\ttraining's binary_logloss: 0.106059\n",
      "[8938]\ttraining's auc: 0.994105\ttraining's binary_logloss: 0.106056\n",
      "[8939]\ttraining's auc: 0.994108\ttraining's binary_logloss: 0.106045\n",
      "[8940]\ttraining's auc: 0.994109\ttraining's binary_logloss: 0.106036\n",
      "[8941]\ttraining's auc: 0.994111\ttraining's binary_logloss: 0.106026\n",
      "[8942]\ttraining's auc: 0.994114\ttraining's binary_logloss: 0.106016\n",
      "[8943]\ttraining's auc: 0.994118\ttraining's binary_logloss: 0.106006\n",
      "[8944]\ttraining's auc: 0.99412\ttraining's binary_logloss: 0.105997\n",
      "[8945]\ttraining's auc: 0.994121\ttraining's binary_logloss: 0.105989\n",
      "[8946]\ttraining's auc: 0.994121\ttraining's binary_logloss: 0.105987\n",
      "[8947]\ttraining's auc: 0.994124\ttraining's binary_logloss: 0.105978\n",
      "[8948]\ttraining's auc: 0.994126\ttraining's binary_logloss: 0.105968\n",
      "[8949]\ttraining's auc: 0.994129\ttraining's binary_logloss: 0.105958\n",
      "[8950]\ttraining's auc: 0.994131\ttraining's binary_logloss: 0.105951\n",
      "[8951]\ttraining's auc: 0.994133\ttraining's binary_logloss: 0.105942\n",
      "[8952]\ttraining's auc: 0.994136\ttraining's binary_logloss: 0.105932\n",
      "[8953]\ttraining's auc: 0.994138\ttraining's binary_logloss: 0.105926\n",
      "[8954]\ttraining's auc: 0.99414\ttraining's binary_logloss: 0.105917\n",
      "[8955]\ttraining's auc: 0.994143\ttraining's binary_logloss: 0.105909\n",
      "[8956]\ttraining's auc: 0.994144\ttraining's binary_logloss: 0.105903\n",
      "[8957]\ttraining's auc: 0.994146\ttraining's binary_logloss: 0.105894\n",
      "[8958]\ttraining's auc: 0.994149\ttraining's binary_logloss: 0.105883\n",
      "[8959]\ttraining's auc: 0.994153\ttraining's binary_logloss: 0.105874\n",
      "[8960]\ttraining's auc: 0.994155\ttraining's binary_logloss: 0.105864\n",
      "[8961]\ttraining's auc: 0.994162\ttraining's binary_logloss: 0.105853\n",
      "[8962]\ttraining's auc: 0.994164\ttraining's binary_logloss: 0.105844\n",
      "[8963]\ttraining's auc: 0.994166\ttraining's binary_logloss: 0.105838\n",
      "[8964]\ttraining's auc: 0.994169\ttraining's binary_logloss: 0.105831\n",
      "[8965]\ttraining's auc: 0.99417\ttraining's binary_logloss: 0.105822\n",
      "[8966]\ttraining's auc: 0.994171\ttraining's binary_logloss: 0.105815\n",
      "[8967]\ttraining's auc: 0.994172\ttraining's binary_logloss: 0.105806\n",
      "[8968]\ttraining's auc: 0.994175\ttraining's binary_logloss: 0.105796\n",
      "[8969]\ttraining's auc: 0.994177\ttraining's binary_logloss: 0.105789\n",
      "[8970]\ttraining's auc: 0.994181\ttraining's binary_logloss: 0.105775\n",
      "[8971]\ttraining's auc: 0.994184\ttraining's binary_logloss: 0.105764\n",
      "[8972]\ttraining's auc: 0.994186\ttraining's binary_logloss: 0.105754\n",
      "[8973]\ttraining's auc: 0.994191\ttraining's binary_logloss: 0.105745\n",
      "[8974]\ttraining's auc: 0.994193\ttraining's binary_logloss: 0.105739\n",
      "[8975]\ttraining's auc: 0.994195\ttraining's binary_logloss: 0.105728\n",
      "[8976]\ttraining's auc: 0.9942\ttraining's binary_logloss: 0.105717\n",
      "[8977]\ttraining's auc: 0.994203\ttraining's binary_logloss: 0.105707\n",
      "[8978]\ttraining's auc: 0.994205\ttraining's binary_logloss: 0.105696\n",
      "[8979]\ttraining's auc: 0.994208\ttraining's binary_logloss: 0.105686\n",
      "[8980]\ttraining's auc: 0.994211\ttraining's binary_logloss: 0.105676\n",
      "[8981]\ttraining's auc: 0.994213\ttraining's binary_logloss: 0.105667\n",
      "[8982]\ttraining's auc: 0.994215\ttraining's binary_logloss: 0.105659\n",
      "[8983]\ttraining's auc: 0.994218\ttraining's binary_logloss: 0.105649\n",
      "[8984]\ttraining's auc: 0.994222\ttraining's binary_logloss: 0.10564\n",
      "[8985]\ttraining's auc: 0.994226\ttraining's binary_logloss: 0.105631\n",
      "[8986]\ttraining's auc: 0.994226\ttraining's binary_logloss: 0.105624\n",
      "[8987]\ttraining's auc: 0.994228\ttraining's binary_logloss: 0.10562\n",
      "[8988]\ttraining's auc: 0.994231\ttraining's binary_logloss: 0.105607\n",
      "[8989]\ttraining's auc: 0.994234\ttraining's binary_logloss: 0.105598\n",
      "[8990]\ttraining's auc: 0.994237\ttraining's binary_logloss: 0.105588\n",
      "[8991]\ttraining's auc: 0.99424\ttraining's binary_logloss: 0.105579\n",
      "[8992]\ttraining's auc: 0.994242\ttraining's binary_logloss: 0.105569\n",
      "[8993]\ttraining's auc: 0.994246\ttraining's binary_logloss: 0.105558\n",
      "[8994]\ttraining's auc: 0.994249\ttraining's binary_logloss: 0.105549\n",
      "[8995]\ttraining's auc: 0.994249\ttraining's binary_logloss: 0.105547\n",
      "[8996]\ttraining's auc: 0.994252\ttraining's binary_logloss: 0.105538\n",
      "[8997]\ttraining's auc: 0.994252\ttraining's binary_logloss: 0.105536\n",
      "[8998]\ttraining's auc: 0.994254\ttraining's binary_logloss: 0.105527\n",
      "[8999]\ttraining's auc: 0.994256\ttraining's binary_logloss: 0.105518\n",
      "[9000]\ttraining's auc: 0.994258\ttraining's binary_logloss: 0.105511\n",
      "[9001]\ttraining's auc: 0.99426\ttraining's binary_logloss: 0.105503\n",
      "[9002]\ttraining's auc: 0.994261\ttraining's binary_logloss: 0.105498\n",
      "[9003]\ttraining's auc: 0.994263\ttraining's binary_logloss: 0.10549\n",
      "[9004]\ttraining's auc: 0.994265\ttraining's binary_logloss: 0.10548\n",
      "[9005]\ttraining's auc: 0.994266\ttraining's binary_logloss: 0.105473\n",
      "[9006]\ttraining's auc: 0.994266\ttraining's binary_logloss: 0.105472\n",
      "[9007]\ttraining's auc: 0.994269\ttraining's binary_logloss: 0.105462\n",
      "[9008]\ttraining's auc: 0.994272\ttraining's binary_logloss: 0.105452\n",
      "[9009]\ttraining's auc: 0.994275\ttraining's binary_logloss: 0.105445\n",
      "[9010]\ttraining's auc: 0.994277\ttraining's binary_logloss: 0.105435\n",
      "[9011]\ttraining's auc: 0.994278\ttraining's binary_logloss: 0.105433\n",
      "[9012]\ttraining's auc: 0.994281\ttraining's binary_logloss: 0.105424\n",
      "[9013]\ttraining's auc: 0.994283\ttraining's binary_logloss: 0.105419\n",
      "[9014]\ttraining's auc: 0.994285\ttraining's binary_logloss: 0.105412\n",
      "[9015]\ttraining's auc: 0.994287\ttraining's binary_logloss: 0.105403\n",
      "[9016]\ttraining's auc: 0.994288\ttraining's binary_logloss: 0.1054\n",
      "[9017]\ttraining's auc: 0.994291\ttraining's binary_logloss: 0.105391\n",
      "[9018]\ttraining's auc: 0.994293\ttraining's binary_logloss: 0.105384\n",
      "[9019]\ttraining's auc: 0.994294\ttraining's binary_logloss: 0.105379\n",
      "[9020]\ttraining's auc: 0.994297\ttraining's binary_logloss: 0.105368\n",
      "[9021]\ttraining's auc: 0.9943\ttraining's binary_logloss: 0.105358\n",
      "[9022]\ttraining's auc: 0.994301\ttraining's binary_logloss: 0.105353\n",
      "[9023]\ttraining's auc: 0.994302\ttraining's binary_logloss: 0.105345\n",
      "[9024]\ttraining's auc: 0.994304\ttraining's binary_logloss: 0.105339\n",
      "[9025]\ttraining's auc: 0.994307\ttraining's binary_logloss: 0.105329\n",
      "[9026]\ttraining's auc: 0.994308\ttraining's binary_logloss: 0.105327\n",
      "[9027]\ttraining's auc: 0.99431\ttraining's binary_logloss: 0.105316\n",
      "[9028]\ttraining's auc: 0.994314\ttraining's binary_logloss: 0.105306\n",
      "[9029]\ttraining's auc: 0.994317\ttraining's binary_logloss: 0.105297\n",
      "[9030]\ttraining's auc: 0.994317\ttraining's binary_logloss: 0.105295\n",
      "[9031]\ttraining's auc: 0.994317\ttraining's binary_logloss: 0.105292\n",
      "[9032]\ttraining's auc: 0.99432\ttraining's binary_logloss: 0.105283\n",
      "[9033]\ttraining's auc: 0.994322\ttraining's binary_logloss: 0.105274\n",
      "[9034]\ttraining's auc: 0.994326\ttraining's binary_logloss: 0.105265\n",
      "[9035]\ttraining's auc: 0.994327\ttraining's binary_logloss: 0.105259\n",
      "[9036]\ttraining's auc: 0.994328\ttraining's binary_logloss: 0.105256\n",
      "[9037]\ttraining's auc: 0.99433\ttraining's binary_logloss: 0.105251\n",
      "[9038]\ttraining's auc: 0.994332\ttraining's binary_logloss: 0.105242\n",
      "[9039]\ttraining's auc: 0.994334\ttraining's binary_logloss: 0.105233\n",
      "[9040]\ttraining's auc: 0.994335\ttraining's binary_logloss: 0.105231\n",
      "[9041]\ttraining's auc: 0.994337\ttraining's binary_logloss: 0.105222\n",
      "[9042]\ttraining's auc: 0.994339\ttraining's binary_logloss: 0.105213\n",
      "[9043]\ttraining's auc: 0.994342\ttraining's binary_logloss: 0.105202\n",
      "[9044]\ttraining's auc: 0.994345\ttraining's binary_logloss: 0.105191\n",
      "[9045]\ttraining's auc: 0.994348\ttraining's binary_logloss: 0.105182\n",
      "[9046]\ttraining's auc: 0.994349\ttraining's binary_logloss: 0.105172\n",
      "[9047]\ttraining's auc: 0.994351\ttraining's binary_logloss: 0.105165\n",
      "[9048]\ttraining's auc: 0.994356\ttraining's binary_logloss: 0.105154\n",
      "[9049]\ttraining's auc: 0.994356\ttraining's binary_logloss: 0.10515\n",
      "[9050]\ttraining's auc: 0.994359\ttraining's binary_logloss: 0.10514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9051]\ttraining's auc: 0.994362\ttraining's binary_logloss: 0.105131\n",
      "[9052]\ttraining's auc: 0.994363\ttraining's binary_logloss: 0.105125\n",
      "[9053]\ttraining's auc: 0.994365\ttraining's binary_logloss: 0.105123\n",
      "[9054]\ttraining's auc: 0.994367\ttraining's binary_logloss: 0.105114\n",
      "[9055]\ttraining's auc: 0.994369\ttraining's binary_logloss: 0.105105\n",
      "[9056]\ttraining's auc: 0.994372\ttraining's binary_logloss: 0.105098\n",
      "[9057]\ttraining's auc: 0.994375\ttraining's binary_logloss: 0.105088\n",
      "[9058]\ttraining's auc: 0.994376\ttraining's binary_logloss: 0.105087\n",
      "[9059]\ttraining's auc: 0.994378\ttraining's binary_logloss: 0.105078\n",
      "[9060]\ttraining's auc: 0.99438\ttraining's binary_logloss: 0.105071\n",
      "[9061]\ttraining's auc: 0.99438\ttraining's binary_logloss: 0.105068\n",
      "[9062]\ttraining's auc: 0.994382\ttraining's binary_logloss: 0.105058\n",
      "[9063]\ttraining's auc: 0.994384\ttraining's binary_logloss: 0.10505\n",
      "[9064]\ttraining's auc: 0.994386\ttraining's binary_logloss: 0.10504\n",
      "[9065]\ttraining's auc: 0.994389\ttraining's binary_logloss: 0.105033\n",
      "[9066]\ttraining's auc: 0.994391\ttraining's binary_logloss: 0.105028\n",
      "[9067]\ttraining's auc: 0.994391\ttraining's binary_logloss: 0.105026\n",
      "[9068]\ttraining's auc: 0.994396\ttraining's binary_logloss: 0.105016\n",
      "[9069]\ttraining's auc: 0.994399\ttraining's binary_logloss: 0.105007\n",
      "[9070]\ttraining's auc: 0.9944\ttraining's binary_logloss: 0.105\n",
      "[9071]\ttraining's auc: 0.994401\ttraining's binary_logloss: 0.10499\n",
      "[9072]\ttraining's auc: 0.994403\ttraining's binary_logloss: 0.10498\n",
      "[9073]\ttraining's auc: 0.994405\ttraining's binary_logloss: 0.104973\n",
      "[9074]\ttraining's auc: 0.994407\ttraining's binary_logloss: 0.104964\n",
      "[9075]\ttraining's auc: 0.994409\ttraining's binary_logloss: 0.104953\n",
      "[9076]\ttraining's auc: 0.994413\ttraining's binary_logloss: 0.104943\n",
      "[9077]\ttraining's auc: 0.994416\ttraining's binary_logloss: 0.104932\n",
      "[9078]\ttraining's auc: 0.994419\ttraining's binary_logloss: 0.104924\n",
      "[9079]\ttraining's auc: 0.994422\ttraining's binary_logloss: 0.104914\n",
      "[9080]\ttraining's auc: 0.994424\ttraining's binary_logloss: 0.104906\n",
      "[9081]\ttraining's auc: 0.994426\ttraining's binary_logloss: 0.104897\n",
      "[9082]\ttraining's auc: 0.994426\ttraining's binary_logloss: 0.104896\n",
      "[9083]\ttraining's auc: 0.994426\ttraining's binary_logloss: 0.104895\n",
      "[9084]\ttraining's auc: 0.994428\ttraining's binary_logloss: 0.104886\n",
      "[9085]\ttraining's auc: 0.99443\ttraining's binary_logloss: 0.104878\n",
      "[9086]\ttraining's auc: 0.994433\ttraining's binary_logloss: 0.104872\n",
      "[9087]\ttraining's auc: 0.994436\ttraining's binary_logloss: 0.104862\n",
      "[9088]\ttraining's auc: 0.994438\ttraining's binary_logloss: 0.104854\n",
      "[9089]\ttraining's auc: 0.99444\ttraining's binary_logloss: 0.104849\n",
      "[9090]\ttraining's auc: 0.994441\ttraining's binary_logloss: 0.104844\n",
      "[9091]\ttraining's auc: 0.994445\ttraining's binary_logloss: 0.104834\n",
      "[9092]\ttraining's auc: 0.99445\ttraining's binary_logloss: 0.104827\n",
      "[9093]\ttraining's auc: 0.994452\ttraining's binary_logloss: 0.104819\n",
      "[9094]\ttraining's auc: 0.994454\ttraining's binary_logloss: 0.10481\n",
      "[9095]\ttraining's auc: 0.994461\ttraining's binary_logloss: 0.104797\n",
      "[9096]\ttraining's auc: 0.994462\ttraining's binary_logloss: 0.10479\n",
      "[9097]\ttraining's auc: 0.994465\ttraining's binary_logloss: 0.10478\n",
      "[9098]\ttraining's auc: 0.994466\ttraining's binary_logloss: 0.104779\n",
      "[9099]\ttraining's auc: 0.994467\ttraining's binary_logloss: 0.104774\n",
      "[9100]\ttraining's auc: 0.994467\ttraining's binary_logloss: 0.104771\n",
      "[9101]\ttraining's auc: 0.994468\ttraining's binary_logloss: 0.104767\n",
      "[9102]\ttraining's auc: 0.994471\ttraining's binary_logloss: 0.104757\n",
      "[9103]\ttraining's auc: 0.994472\ttraining's binary_logloss: 0.104753\n",
      "[9104]\ttraining's auc: 0.994475\ttraining's binary_logloss: 0.104746\n",
      "[9105]\ttraining's auc: 0.994477\ttraining's binary_logloss: 0.104735\n",
      "[9106]\ttraining's auc: 0.994481\ttraining's binary_logloss: 0.104725\n",
      "[9107]\ttraining's auc: 0.994483\ttraining's binary_logloss: 0.104716\n",
      "[9108]\ttraining's auc: 0.994485\ttraining's binary_logloss: 0.104706\n",
      "[9109]\ttraining's auc: 0.994486\ttraining's binary_logloss: 0.104697\n",
      "[9110]\ttraining's auc: 0.994489\ttraining's binary_logloss: 0.104687\n",
      "[9111]\ttraining's auc: 0.994493\ttraining's binary_logloss: 0.104676\n",
      "[9112]\ttraining's auc: 0.994496\ttraining's binary_logloss: 0.104667\n",
      "[9113]\ttraining's auc: 0.994498\ttraining's binary_logloss: 0.104657\n",
      "[9114]\ttraining's auc: 0.994499\ttraining's binary_logloss: 0.104647\n",
      "[9115]\ttraining's auc: 0.994502\ttraining's binary_logloss: 0.104641\n",
      "[9116]\ttraining's auc: 0.994504\ttraining's binary_logloss: 0.104631\n",
      "[9117]\ttraining's auc: 0.994507\ttraining's binary_logloss: 0.104621\n",
      "[9118]\ttraining's auc: 0.994508\ttraining's binary_logloss: 0.104613\n",
      "[9119]\ttraining's auc: 0.994508\ttraining's binary_logloss: 0.10461\n",
      "[9120]\ttraining's auc: 0.99451\ttraining's binary_logloss: 0.104605\n",
      "[9121]\ttraining's auc: 0.994512\ttraining's binary_logloss: 0.104599\n",
      "[9122]\ttraining's auc: 0.994514\ttraining's binary_logloss: 0.104593\n",
      "[9123]\ttraining's auc: 0.994516\ttraining's binary_logloss: 0.104589\n",
      "[9124]\ttraining's auc: 0.994517\ttraining's binary_logloss: 0.104581\n",
      "[9125]\ttraining's auc: 0.994521\ttraining's binary_logloss: 0.104571\n",
      "[9126]\ttraining's auc: 0.994523\ttraining's binary_logloss: 0.104565\n",
      "[9127]\ttraining's auc: 0.994526\ttraining's binary_logloss: 0.104555\n",
      "[9128]\ttraining's auc: 0.99453\ttraining's binary_logloss: 0.104546\n",
      "[9129]\ttraining's auc: 0.994533\ttraining's binary_logloss: 0.104537\n",
      "[9130]\ttraining's auc: 0.994535\ttraining's binary_logloss: 0.104526\n",
      "[9131]\ttraining's auc: 0.994537\ttraining's binary_logloss: 0.104519\n",
      "[9132]\ttraining's auc: 0.994538\ttraining's binary_logloss: 0.104509\n",
      "[9133]\ttraining's auc: 0.994543\ttraining's binary_logloss: 0.104498\n",
      "[9134]\ttraining's auc: 0.994545\ttraining's binary_logloss: 0.10449\n",
      "[9135]\ttraining's auc: 0.994547\ttraining's binary_logloss: 0.104479\n",
      "[9136]\ttraining's auc: 0.994549\ttraining's binary_logloss: 0.104471\n",
      "[9137]\ttraining's auc: 0.994552\ttraining's binary_logloss: 0.104461\n",
      "[9138]\ttraining's auc: 0.994556\ttraining's binary_logloss: 0.104451\n",
      "[9139]\ttraining's auc: 0.99456\ttraining's binary_logloss: 0.104442\n",
      "[9140]\ttraining's auc: 0.994561\ttraining's binary_logloss: 0.104433\n",
      "[9141]\ttraining's auc: 0.994564\ttraining's binary_logloss: 0.104424\n",
      "[9142]\ttraining's auc: 0.994566\ttraining's binary_logloss: 0.104416\n",
      "[9143]\ttraining's auc: 0.994567\ttraining's binary_logloss: 0.10441\n",
      "[9144]\ttraining's auc: 0.994568\ttraining's binary_logloss: 0.104401\n",
      "[9145]\ttraining's auc: 0.994571\ttraining's binary_logloss: 0.104392\n",
      "[9146]\ttraining's auc: 0.994574\ttraining's binary_logloss: 0.104383\n",
      "[9147]\ttraining's auc: 0.994576\ttraining's binary_logloss: 0.104377\n",
      "[9148]\ttraining's auc: 0.994578\ttraining's binary_logloss: 0.104369\n",
      "[9149]\ttraining's auc: 0.994579\ttraining's binary_logloss: 0.104359\n",
      "[9150]\ttraining's auc: 0.994581\ttraining's binary_logloss: 0.104352\n",
      "[9151]\ttraining's auc: 0.994585\ttraining's binary_logloss: 0.104342\n",
      "[9152]\ttraining's auc: 0.994587\ttraining's binary_logloss: 0.104333\n",
      "[9153]\ttraining's auc: 0.994591\ttraining's binary_logloss: 0.104322\n",
      "[9154]\ttraining's auc: 0.994594\ttraining's binary_logloss: 0.104313\n",
      "[9155]\ttraining's auc: 0.994597\ttraining's binary_logloss: 0.104302\n",
      "[9156]\ttraining's auc: 0.994597\ttraining's binary_logloss: 0.1043\n",
      "[9157]\ttraining's auc: 0.994597\ttraining's binary_logloss: 0.104298\n",
      "[9158]\ttraining's auc: 0.994602\ttraining's binary_logloss: 0.104288\n",
      "[9159]\ttraining's auc: 0.994602\ttraining's binary_logloss: 0.104285\n",
      "[9160]\ttraining's auc: 0.994605\ttraining's binary_logloss: 0.104276\n",
      "[9161]\ttraining's auc: 0.994607\ttraining's binary_logloss: 0.104267\n",
      "[9162]\ttraining's auc: 0.994608\ttraining's binary_logloss: 0.104264\n",
      "[9163]\ttraining's auc: 0.994609\ttraining's binary_logloss: 0.104262\n",
      "[9164]\ttraining's auc: 0.994611\ttraining's binary_logloss: 0.104251\n",
      "[9165]\ttraining's auc: 0.994614\ttraining's binary_logloss: 0.104241\n",
      "[9166]\ttraining's auc: 0.994614\ttraining's binary_logloss: 0.104235\n",
      "[9167]\ttraining's auc: 0.994618\ttraining's binary_logloss: 0.104224\n",
      "[9168]\ttraining's auc: 0.994621\ttraining's binary_logloss: 0.104214\n",
      "[9169]\ttraining's auc: 0.994621\ttraining's binary_logloss: 0.104213\n",
      "[9170]\ttraining's auc: 0.994625\ttraining's binary_logloss: 0.104201\n",
      "[9171]\ttraining's auc: 0.994627\ttraining's binary_logloss: 0.104195\n",
      "[9172]\ttraining's auc: 0.994629\ttraining's binary_logloss: 0.104185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9173]\ttraining's auc: 0.994632\ttraining's binary_logloss: 0.104175\n",
      "[9174]\ttraining's auc: 0.994632\ttraining's binary_logloss: 0.104172\n",
      "[9175]\ttraining's auc: 0.994633\ttraining's binary_logloss: 0.104171\n",
      "[9176]\ttraining's auc: 0.994634\ttraining's binary_logloss: 0.104165\n",
      "[9177]\ttraining's auc: 0.994636\ttraining's binary_logloss: 0.104159\n",
      "[9178]\ttraining's auc: 0.994639\ttraining's binary_logloss: 0.104149\n",
      "[9179]\ttraining's auc: 0.994641\ttraining's binary_logloss: 0.104146\n",
      "[9180]\ttraining's auc: 0.994644\ttraining's binary_logloss: 0.104134\n",
      "[9181]\ttraining's auc: 0.994647\ttraining's binary_logloss: 0.104123\n",
      "[9182]\ttraining's auc: 0.994649\ttraining's binary_logloss: 0.104116\n",
      "[9183]\ttraining's auc: 0.99465\ttraining's binary_logloss: 0.104108\n",
      "[9184]\ttraining's auc: 0.994653\ttraining's binary_logloss: 0.104099\n",
      "[9185]\ttraining's auc: 0.994653\ttraining's binary_logloss: 0.104097\n",
      "[9186]\ttraining's auc: 0.994655\ttraining's binary_logloss: 0.104089\n",
      "[9187]\ttraining's auc: 0.99466\ttraining's binary_logloss: 0.104076\n",
      "[9188]\ttraining's auc: 0.994661\ttraining's binary_logloss: 0.104068\n",
      "[9189]\ttraining's auc: 0.994663\ttraining's binary_logloss: 0.104059\n",
      "[9190]\ttraining's auc: 0.994665\ttraining's binary_logloss: 0.104051\n",
      "[9191]\ttraining's auc: 0.994666\ttraining's binary_logloss: 0.104048\n",
      "[9192]\ttraining's auc: 0.994669\ttraining's binary_logloss: 0.104039\n",
      "[9193]\ttraining's auc: 0.994671\ttraining's binary_logloss: 0.10403\n",
      "[9194]\ttraining's auc: 0.994675\ttraining's binary_logloss: 0.10402\n",
      "[9195]\ttraining's auc: 0.994675\ttraining's binary_logloss: 0.104016\n",
      "[9196]\ttraining's auc: 0.994678\ttraining's binary_logloss: 0.104006\n",
      "[9197]\ttraining's auc: 0.994682\ttraining's binary_logloss: 0.103993\n",
      "[9198]\ttraining's auc: 0.994683\ttraining's binary_logloss: 0.103986\n",
      "[9199]\ttraining's auc: 0.994688\ttraining's binary_logloss: 0.103974\n",
      "[9200]\ttraining's auc: 0.99469\ttraining's binary_logloss: 0.103965\n",
      "[9201]\ttraining's auc: 0.994693\ttraining's binary_logloss: 0.103956\n",
      "[9202]\ttraining's auc: 0.994695\ttraining's binary_logloss: 0.103946\n",
      "[9203]\ttraining's auc: 0.994697\ttraining's binary_logloss: 0.10394\n",
      "[9204]\ttraining's auc: 0.994698\ttraining's binary_logloss: 0.10393\n",
      "[9205]\ttraining's auc: 0.994699\ttraining's binary_logloss: 0.103922\n",
      "[9206]\ttraining's auc: 0.994705\ttraining's binary_logloss: 0.10391\n",
      "[9207]\ttraining's auc: 0.994708\ttraining's binary_logloss: 0.103898\n",
      "[9208]\ttraining's auc: 0.994712\ttraining's binary_logloss: 0.103887\n",
      "[9209]\ttraining's auc: 0.994715\ttraining's binary_logloss: 0.103878\n",
      "[9210]\ttraining's auc: 0.994717\ttraining's binary_logloss: 0.103868\n",
      "[9211]\ttraining's auc: 0.99472\ttraining's binary_logloss: 0.10386\n",
      "[9212]\ttraining's auc: 0.994722\ttraining's binary_logloss: 0.103853\n",
      "[9213]\ttraining's auc: 0.994724\ttraining's binary_logloss: 0.103843\n",
      "[9214]\ttraining's auc: 0.994729\ttraining's binary_logloss: 0.103832\n",
      "[9215]\ttraining's auc: 0.994731\ttraining's binary_logloss: 0.103822\n",
      "[9216]\ttraining's auc: 0.994735\ttraining's binary_logloss: 0.103811\n",
      "[9217]\ttraining's auc: 0.994737\ttraining's binary_logloss: 0.103803\n",
      "[9218]\ttraining's auc: 0.994741\ttraining's binary_logloss: 0.10379\n",
      "[9219]\ttraining's auc: 0.994743\ttraining's binary_logloss: 0.10378\n",
      "[9220]\ttraining's auc: 0.994745\ttraining's binary_logloss: 0.103771\n",
      "[9221]\ttraining's auc: 0.994748\ttraining's binary_logloss: 0.10376\n",
      "[9222]\ttraining's auc: 0.99475\ttraining's binary_logloss: 0.103752\n",
      "[9223]\ttraining's auc: 0.994754\ttraining's binary_logloss: 0.103742\n",
      "[9224]\ttraining's auc: 0.994756\ttraining's binary_logloss: 0.103731\n",
      "[9225]\ttraining's auc: 0.994759\ttraining's binary_logloss: 0.103721\n",
      "[9226]\ttraining's auc: 0.994762\ttraining's binary_logloss: 0.10371\n",
      "[9227]\ttraining's auc: 0.994765\ttraining's binary_logloss: 0.103702\n",
      "[9228]\ttraining's auc: 0.994767\ttraining's binary_logloss: 0.103694\n",
      "[9229]\ttraining's auc: 0.994768\ttraining's binary_logloss: 0.103685\n",
      "[9230]\ttraining's auc: 0.994773\ttraining's binary_logloss: 0.103673\n",
      "[9231]\ttraining's auc: 0.994774\ttraining's binary_logloss: 0.103665\n",
      "[9232]\ttraining's auc: 0.994775\ttraining's binary_logloss: 0.103661\n",
      "[9233]\ttraining's auc: 0.994778\ttraining's binary_logloss: 0.103652\n",
      "[9234]\ttraining's auc: 0.994782\ttraining's binary_logloss: 0.103641\n",
      "[9235]\ttraining's auc: 0.994784\ttraining's binary_logloss: 0.103635\n",
      "[9236]\ttraining's auc: 0.994784\ttraining's binary_logloss: 0.103634\n",
      "[9237]\ttraining's auc: 0.994788\ttraining's binary_logloss: 0.103623\n",
      "[9238]\ttraining's auc: 0.99479\ttraining's binary_logloss: 0.103613\n",
      "[9239]\ttraining's auc: 0.994796\ttraining's binary_logloss: 0.103602\n",
      "[9240]\ttraining's auc: 0.994798\ttraining's binary_logloss: 0.103593\n",
      "[9241]\ttraining's auc: 0.994802\ttraining's binary_logloss: 0.103583\n",
      "[9242]\ttraining's auc: 0.994805\ttraining's binary_logloss: 0.103571\n",
      "[9243]\ttraining's auc: 0.994809\ttraining's binary_logloss: 0.10356\n",
      "[9244]\ttraining's auc: 0.99481\ttraining's binary_logloss: 0.103558\n",
      "[9245]\ttraining's auc: 0.994813\ttraining's binary_logloss: 0.103545\n",
      "[9246]\ttraining's auc: 0.994815\ttraining's binary_logloss: 0.103537\n",
      "[9247]\ttraining's auc: 0.994816\ttraining's binary_logloss: 0.10353\n",
      "[9248]\ttraining's auc: 0.994818\ttraining's binary_logloss: 0.103524\n",
      "[9249]\ttraining's auc: 0.994824\ttraining's binary_logloss: 0.103512\n",
      "[9250]\ttraining's auc: 0.994826\ttraining's binary_logloss: 0.103507\n",
      "[9251]\ttraining's auc: 0.994828\ttraining's binary_logloss: 0.103495\n",
      "[9252]\ttraining's auc: 0.994828\ttraining's binary_logloss: 0.103491\n",
      "[9253]\ttraining's auc: 0.994834\ttraining's binary_logloss: 0.103481\n",
      "[9254]\ttraining's auc: 0.994837\ttraining's binary_logloss: 0.103471\n",
      "[9255]\ttraining's auc: 0.994837\ttraining's binary_logloss: 0.103467\n",
      "[9256]\ttraining's auc: 0.994837\ttraining's binary_logloss: 0.103464\n",
      "[9257]\ttraining's auc: 0.994839\ttraining's binary_logloss: 0.103456\n",
      "[9258]\ttraining's auc: 0.994842\ttraining's binary_logloss: 0.103444\n",
      "[9259]\ttraining's auc: 0.994847\ttraining's binary_logloss: 0.103434\n",
      "[9260]\ttraining's auc: 0.99485\ttraining's binary_logloss: 0.103422\n",
      "[9261]\ttraining's auc: 0.994854\ttraining's binary_logloss: 0.103411\n",
      "[9262]\ttraining's auc: 0.994857\ttraining's binary_logloss: 0.103403\n",
      "[9263]\ttraining's auc: 0.994858\ttraining's binary_logloss: 0.103398\n",
      "[9264]\ttraining's auc: 0.994861\ttraining's binary_logloss: 0.103389\n",
      "[9265]\ttraining's auc: 0.994864\ttraining's binary_logloss: 0.103378\n",
      "[9266]\ttraining's auc: 0.994866\ttraining's binary_logloss: 0.103368\n",
      "[9267]\ttraining's auc: 0.994868\ttraining's binary_logloss: 0.103358\n",
      "[9268]\ttraining's auc: 0.99487\ttraining's binary_logloss: 0.10335\n",
      "[9269]\ttraining's auc: 0.994871\ttraining's binary_logloss: 0.103341\n",
      "[9270]\ttraining's auc: 0.994874\ttraining's binary_logloss: 0.103332\n",
      "[9271]\ttraining's auc: 0.994877\ttraining's binary_logloss: 0.103323\n",
      "[9272]\ttraining's auc: 0.994879\ttraining's binary_logloss: 0.103314\n",
      "[9273]\ttraining's auc: 0.994879\ttraining's binary_logloss: 0.103311\n",
      "[9274]\ttraining's auc: 0.994883\ttraining's binary_logloss: 0.103302\n",
      "[9275]\ttraining's auc: 0.994884\ttraining's binary_logloss: 0.103295\n",
      "[9276]\ttraining's auc: 0.994885\ttraining's binary_logloss: 0.103292\n",
      "[9277]\ttraining's auc: 0.994887\ttraining's binary_logloss: 0.103283\n",
      "[9278]\ttraining's auc: 0.99489\ttraining's binary_logloss: 0.103275\n",
      "[9279]\ttraining's auc: 0.994892\ttraining's binary_logloss: 0.103265\n",
      "[9280]\ttraining's auc: 0.994893\ttraining's binary_logloss: 0.103262\n",
      "[9281]\ttraining's auc: 0.994896\ttraining's binary_logloss: 0.103252\n",
      "[9282]\ttraining's auc: 0.9949\ttraining's binary_logloss: 0.103243\n",
      "[9283]\ttraining's auc: 0.994903\ttraining's binary_logloss: 0.103235\n",
      "[9284]\ttraining's auc: 0.994904\ttraining's binary_logloss: 0.103233\n",
      "[9285]\ttraining's auc: 0.994908\ttraining's binary_logloss: 0.103221\n",
      "[9286]\ttraining's auc: 0.994911\ttraining's binary_logloss: 0.103211\n",
      "[9287]\ttraining's auc: 0.994913\ttraining's binary_logloss: 0.103202\n",
      "[9288]\ttraining's auc: 0.994913\ttraining's binary_logloss: 0.103199\n",
      "[9289]\ttraining's auc: 0.994915\ttraining's binary_logloss: 0.103195\n",
      "[9290]\ttraining's auc: 0.994918\ttraining's binary_logloss: 0.103186\n",
      "[9291]\ttraining's auc: 0.99492\ttraining's binary_logloss: 0.103177\n",
      "[9292]\ttraining's auc: 0.994921\ttraining's binary_logloss: 0.103174\n",
      "[9293]\ttraining's auc: 0.994921\ttraining's binary_logloss: 0.103173\n",
      "[9294]\ttraining's auc: 0.994922\ttraining's binary_logloss: 0.103167\n",
      "[9295]\ttraining's auc: 0.994926\ttraining's binary_logloss: 0.103159\n",
      "[9296]\ttraining's auc: 0.994929\ttraining's binary_logloss: 0.103149\n",
      "[9297]\ttraining's auc: 0.994931\ttraining's binary_logloss: 0.103142\n",
      "[9298]\ttraining's auc: 0.994935\ttraining's binary_logloss: 0.103131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9299]\ttraining's auc: 0.994939\ttraining's binary_logloss: 0.103119\n",
      "[9300]\ttraining's auc: 0.994939\ttraining's binary_logloss: 0.103117\n",
      "[9301]\ttraining's auc: 0.994943\ttraining's binary_logloss: 0.103106\n",
      "[9302]\ttraining's auc: 0.994946\ttraining's binary_logloss: 0.103096\n",
      "[9303]\ttraining's auc: 0.994948\ttraining's binary_logloss: 0.103087\n",
      "[9304]\ttraining's auc: 0.99495\ttraining's binary_logloss: 0.103079\n",
      "[9305]\ttraining's auc: 0.994952\ttraining's binary_logloss: 0.103074\n",
      "[9306]\ttraining's auc: 0.994956\ttraining's binary_logloss: 0.103064\n",
      "[9307]\ttraining's auc: 0.99496\ttraining's binary_logloss: 0.103053\n",
      "[9308]\ttraining's auc: 0.994963\ttraining's binary_logloss: 0.103043\n",
      "[9309]\ttraining's auc: 0.994966\ttraining's binary_logloss: 0.103034\n",
      "[9310]\ttraining's auc: 0.994966\ttraining's binary_logloss: 0.103033\n",
      "[9311]\ttraining's auc: 0.99497\ttraining's binary_logloss: 0.103022\n",
      "[9312]\ttraining's auc: 0.994972\ttraining's binary_logloss: 0.103013\n",
      "[9313]\ttraining's auc: 0.994975\ttraining's binary_logloss: 0.103004\n",
      "[9314]\ttraining's auc: 0.99498\ttraining's binary_logloss: 0.102994\n",
      "[9315]\ttraining's auc: 0.994984\ttraining's binary_logloss: 0.102983\n",
      "[9316]\ttraining's auc: 0.994986\ttraining's binary_logloss: 0.102975\n",
      "[9317]\ttraining's auc: 0.994988\ttraining's binary_logloss: 0.102966\n",
      "[9318]\ttraining's auc: 0.99499\ttraining's binary_logloss: 0.102957\n",
      "[9319]\ttraining's auc: 0.994992\ttraining's binary_logloss: 0.102952\n",
      "[9320]\ttraining's auc: 0.994993\ttraining's binary_logloss: 0.102943\n",
      "[9321]\ttraining's auc: 0.994996\ttraining's binary_logloss: 0.102934\n",
      "[9322]\ttraining's auc: 0.995\ttraining's binary_logloss: 0.102923\n",
      "[9323]\ttraining's auc: 0.995003\ttraining's binary_logloss: 0.102914\n",
      "[9324]\ttraining's auc: 0.995006\ttraining's binary_logloss: 0.102904\n",
      "[9325]\ttraining's auc: 0.995008\ttraining's binary_logloss: 0.102895\n",
      "[9326]\ttraining's auc: 0.995011\ttraining's binary_logloss: 0.102885\n",
      "[9327]\ttraining's auc: 0.995014\ttraining's binary_logloss: 0.102875\n",
      "[9328]\ttraining's auc: 0.995016\ttraining's binary_logloss: 0.102866\n",
      "[9329]\ttraining's auc: 0.995018\ttraining's binary_logloss: 0.102861\n",
      "[9330]\ttraining's auc: 0.995021\ttraining's binary_logloss: 0.102852\n",
      "[9331]\ttraining's auc: 0.995025\ttraining's binary_logloss: 0.102841\n",
      "[9332]\ttraining's auc: 0.995026\ttraining's binary_logloss: 0.102832\n",
      "[9333]\ttraining's auc: 0.99503\ttraining's binary_logloss: 0.102822\n",
      "[9334]\ttraining's auc: 0.995032\ttraining's binary_logloss: 0.102815\n",
      "[9335]\ttraining's auc: 0.995034\ttraining's binary_logloss: 0.102807\n",
      "[9336]\ttraining's auc: 0.995037\ttraining's binary_logloss: 0.102797\n",
      "[9337]\ttraining's auc: 0.995039\ttraining's binary_logloss: 0.102789\n",
      "[9338]\ttraining's auc: 0.995041\ttraining's binary_logloss: 0.102779\n",
      "[9339]\ttraining's auc: 0.995044\ttraining's binary_logloss: 0.102769\n",
      "[9340]\ttraining's auc: 0.995048\ttraining's binary_logloss: 0.102758\n",
      "[9341]\ttraining's auc: 0.99505\ttraining's binary_logloss: 0.102751\n",
      "[9342]\ttraining's auc: 0.995053\ttraining's binary_logloss: 0.102743\n",
      "[9343]\ttraining's auc: 0.995056\ttraining's binary_logloss: 0.102734\n",
      "[9344]\ttraining's auc: 0.995058\ttraining's binary_logloss: 0.102724\n",
      "[9345]\ttraining's auc: 0.995061\ttraining's binary_logloss: 0.102714\n",
      "[9346]\ttraining's auc: 0.995062\ttraining's binary_logloss: 0.102704\n",
      "[9347]\ttraining's auc: 0.995063\ttraining's binary_logloss: 0.102695\n",
      "[9348]\ttraining's auc: 0.995065\ttraining's binary_logloss: 0.102685\n",
      "[9349]\ttraining's auc: 0.995065\ttraining's binary_logloss: 0.102684\n",
      "[9350]\ttraining's auc: 0.995065\ttraining's binary_logloss: 0.102682\n",
      "[9351]\ttraining's auc: 0.995066\ttraining's binary_logloss: 0.102678\n",
      "[9352]\ttraining's auc: 0.995067\ttraining's binary_logloss: 0.102673\n",
      "[9353]\ttraining's auc: 0.995068\ttraining's binary_logloss: 0.102672\n",
      "[9354]\ttraining's auc: 0.995069\ttraining's binary_logloss: 0.102668\n",
      "[9355]\ttraining's auc: 0.99507\ttraining's binary_logloss: 0.102663\n",
      "[9356]\ttraining's auc: 0.995073\ttraining's binary_logloss: 0.102654\n",
      "[9357]\ttraining's auc: 0.995074\ttraining's binary_logloss: 0.10265\n",
      "[9358]\ttraining's auc: 0.995076\ttraining's binary_logloss: 0.102641\n",
      "[9359]\ttraining's auc: 0.995076\ttraining's binary_logloss: 0.102633\n",
      "[9360]\ttraining's auc: 0.995077\ttraining's binary_logloss: 0.102623\n",
      "[9361]\ttraining's auc: 0.99508\ttraining's binary_logloss: 0.102615\n",
      "[9362]\ttraining's auc: 0.99508\ttraining's binary_logloss: 0.102614\n",
      "[9363]\ttraining's auc: 0.995082\ttraining's binary_logloss: 0.102609\n",
      "[9364]\ttraining's auc: 0.995083\ttraining's binary_logloss: 0.102602\n",
      "[9365]\ttraining's auc: 0.995086\ttraining's binary_logloss: 0.102594\n",
      "[9366]\ttraining's auc: 0.995089\ttraining's binary_logloss: 0.102584\n",
      "[9367]\ttraining's auc: 0.99509\ttraining's binary_logloss: 0.10258\n",
      "[9368]\ttraining's auc: 0.995091\ttraining's binary_logloss: 0.102571\n",
      "[9369]\ttraining's auc: 0.995093\ttraining's binary_logloss: 0.102564\n",
      "[9370]\ttraining's auc: 0.995094\ttraining's binary_logloss: 0.102563\n",
      "[9371]\ttraining's auc: 0.995095\ttraining's binary_logloss: 0.102558\n",
      "[9372]\ttraining's auc: 0.995096\ttraining's binary_logloss: 0.102549\n",
      "[9373]\ttraining's auc: 0.995099\ttraining's binary_logloss: 0.102539\n",
      "[9374]\ttraining's auc: 0.9951\ttraining's binary_logloss: 0.102537\n",
      "[9375]\ttraining's auc: 0.995102\ttraining's binary_logloss: 0.102527\n",
      "[9376]\ttraining's auc: 0.995104\ttraining's binary_logloss: 0.102517\n",
      "[9377]\ttraining's auc: 0.995106\ttraining's binary_logloss: 0.102507\n",
      "[9378]\ttraining's auc: 0.995108\ttraining's binary_logloss: 0.102498\n",
      "[9379]\ttraining's auc: 0.995111\ttraining's binary_logloss: 0.102491\n",
      "[9380]\ttraining's auc: 0.995114\ttraining's binary_logloss: 0.102482\n",
      "[9381]\ttraining's auc: 0.995114\ttraining's binary_logloss: 0.10248\n",
      "[9382]\ttraining's auc: 0.99512\ttraining's binary_logloss: 0.102469\n",
      "[9383]\ttraining's auc: 0.995121\ttraining's binary_logloss: 0.102462\n",
      "[9384]\ttraining's auc: 0.995122\ttraining's binary_logloss: 0.102453\n",
      "[9385]\ttraining's auc: 0.995123\ttraining's binary_logloss: 0.102444\n",
      "[9386]\ttraining's auc: 0.995126\ttraining's binary_logloss: 0.102435\n",
      "[9387]\ttraining's auc: 0.995128\ttraining's binary_logloss: 0.102425\n",
      "[9388]\ttraining's auc: 0.995131\ttraining's binary_logloss: 0.102416\n",
      "[9389]\ttraining's auc: 0.995132\ttraining's binary_logloss: 0.102408\n",
      "[9390]\ttraining's auc: 0.995135\ttraining's binary_logloss: 0.102399\n",
      "[9391]\ttraining's auc: 0.995136\ttraining's binary_logloss: 0.102395\n",
      "[9392]\ttraining's auc: 0.995141\ttraining's binary_logloss: 0.102384\n",
      "[9393]\ttraining's auc: 0.995142\ttraining's binary_logloss: 0.10238\n",
      "[9394]\ttraining's auc: 0.995144\ttraining's binary_logloss: 0.102374\n",
      "[9395]\ttraining's auc: 0.995145\ttraining's binary_logloss: 0.102366\n",
      "[9396]\ttraining's auc: 0.995148\ttraining's binary_logloss: 0.102357\n",
      "[9397]\ttraining's auc: 0.99515\ttraining's binary_logloss: 0.102349\n",
      "[9398]\ttraining's auc: 0.995154\ttraining's binary_logloss: 0.102338\n",
      "[9399]\ttraining's auc: 0.995156\ttraining's binary_logloss: 0.102328\n",
      "[9400]\ttraining's auc: 0.995157\ttraining's binary_logloss: 0.10232\n",
      "[9401]\ttraining's auc: 0.995159\ttraining's binary_logloss: 0.102312\n",
      "[9402]\ttraining's auc: 0.99516\ttraining's binary_logloss: 0.102304\n",
      "[9403]\ttraining's auc: 0.995162\ttraining's binary_logloss: 0.102295\n",
      "[9404]\ttraining's auc: 0.995166\ttraining's binary_logloss: 0.102285\n",
      "[9405]\ttraining's auc: 0.995168\ttraining's binary_logloss: 0.102276\n",
      "[9406]\ttraining's auc: 0.99517\ttraining's binary_logloss: 0.102267\n",
      "[9407]\ttraining's auc: 0.995171\ttraining's binary_logloss: 0.102262\n",
      "[9408]\ttraining's auc: 0.995171\ttraining's binary_logloss: 0.10226\n",
      "[9409]\ttraining's auc: 0.995173\ttraining's binary_logloss: 0.102252\n",
      "[9410]\ttraining's auc: 0.995174\ttraining's binary_logloss: 0.102247\n",
      "[9411]\ttraining's auc: 0.995175\ttraining's binary_logloss: 0.102245\n",
      "[9412]\ttraining's auc: 0.995177\ttraining's binary_logloss: 0.102235\n",
      "[9413]\ttraining's auc: 0.995179\ttraining's binary_logloss: 0.102226\n",
      "[9414]\ttraining's auc: 0.995182\ttraining's binary_logloss: 0.102215\n",
      "[9415]\ttraining's auc: 0.995185\ttraining's binary_logloss: 0.102205\n",
      "[9416]\ttraining's auc: 0.995187\ttraining's binary_logloss: 0.102196\n",
      "[9417]\ttraining's auc: 0.99519\ttraining's binary_logloss: 0.102188\n",
      "[9418]\ttraining's auc: 0.995191\ttraining's binary_logloss: 0.102181\n",
      "[9419]\ttraining's auc: 0.995193\ttraining's binary_logloss: 0.102175\n",
      "[9420]\ttraining's auc: 0.995195\ttraining's binary_logloss: 0.102167\n",
      "[9421]\ttraining's auc: 0.995197\ttraining's binary_logloss: 0.102161\n",
      "[9422]\ttraining's auc: 0.995199\ttraining's binary_logloss: 0.102153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9423]\ttraining's auc: 0.995201\ttraining's binary_logloss: 0.102143\n",
      "[9424]\ttraining's auc: 0.995203\ttraining's binary_logloss: 0.102133\n",
      "[9425]\ttraining's auc: 0.995206\ttraining's binary_logloss: 0.102123\n",
      "[9426]\ttraining's auc: 0.995208\ttraining's binary_logloss: 0.102114\n",
      "[9427]\ttraining's auc: 0.995209\ttraining's binary_logloss: 0.102104\n",
      "[9428]\ttraining's auc: 0.99521\ttraining's binary_logloss: 0.102095\n",
      "[9429]\ttraining's auc: 0.995211\ttraining's binary_logloss: 0.102089\n",
      "[9430]\ttraining's auc: 0.995214\ttraining's binary_logloss: 0.102082\n",
      "[9431]\ttraining's auc: 0.995216\ttraining's binary_logloss: 0.102072\n",
      "[9432]\ttraining's auc: 0.995218\ttraining's binary_logloss: 0.102063\n",
      "[9433]\ttraining's auc: 0.995219\ttraining's binary_logloss: 0.102058\n",
      "[9434]\ttraining's auc: 0.995223\ttraining's binary_logloss: 0.10205\n",
      "[9435]\ttraining's auc: 0.995226\ttraining's binary_logloss: 0.102042\n",
      "[9436]\ttraining's auc: 0.995226\ttraining's binary_logloss: 0.10204\n",
      "[9437]\ttraining's auc: 0.995226\ttraining's binary_logloss: 0.102039\n",
      "[9438]\ttraining's auc: 0.995231\ttraining's binary_logloss: 0.102026\n",
      "[9439]\ttraining's auc: 0.995232\ttraining's binary_logloss: 0.102023\n",
      "[9440]\ttraining's auc: 0.995235\ttraining's binary_logloss: 0.102014\n",
      "[9441]\ttraining's auc: 0.995237\ttraining's binary_logloss: 0.102004\n",
      "[9442]\ttraining's auc: 0.995237\ttraining's binary_logloss: 0.102003\n",
      "[9443]\ttraining's auc: 0.995243\ttraining's binary_logloss: 0.10199\n",
      "[9444]\ttraining's auc: 0.995244\ttraining's binary_logloss: 0.101985\n",
      "[9445]\ttraining's auc: 0.995247\ttraining's binary_logloss: 0.101976\n",
      "[9446]\ttraining's auc: 0.995248\ttraining's binary_logloss: 0.101968\n",
      "[9447]\ttraining's auc: 0.995251\ttraining's binary_logloss: 0.101958\n",
      "[9448]\ttraining's auc: 0.995253\ttraining's binary_logloss: 0.101949\n",
      "[9449]\ttraining's auc: 0.995255\ttraining's binary_logloss: 0.101942\n",
      "[9450]\ttraining's auc: 0.995255\ttraining's binary_logloss: 0.10194\n",
      "[9451]\ttraining's auc: 0.995257\ttraining's binary_logloss: 0.101931\n",
      "[9452]\ttraining's auc: 0.99526\ttraining's binary_logloss: 0.101921\n",
      "[9453]\ttraining's auc: 0.995261\ttraining's binary_logloss: 0.101912\n",
      "[9454]\ttraining's auc: 0.995265\ttraining's binary_logloss: 0.101902\n",
      "[9455]\ttraining's auc: 0.995268\ttraining's binary_logloss: 0.101893\n",
      "[9456]\ttraining's auc: 0.995268\ttraining's binary_logloss: 0.101891\n",
      "[9457]\ttraining's auc: 0.995269\ttraining's binary_logloss: 0.101889\n",
      "[9458]\ttraining's auc: 0.99527\ttraining's binary_logloss: 0.101882\n",
      "[9459]\ttraining's auc: 0.995272\ttraining's binary_logloss: 0.101873\n",
      "[9460]\ttraining's auc: 0.995275\ttraining's binary_logloss: 0.101864\n",
      "[9461]\ttraining's auc: 0.995277\ttraining's binary_logloss: 0.101855\n",
      "[9462]\ttraining's auc: 0.995278\ttraining's binary_logloss: 0.101849\n",
      "[9463]\ttraining's auc: 0.99528\ttraining's binary_logloss: 0.101842\n",
      "[9464]\ttraining's auc: 0.99528\ttraining's binary_logloss: 0.101838\n",
      "[9465]\ttraining's auc: 0.995282\ttraining's binary_logloss: 0.10183\n",
      "[9466]\ttraining's auc: 0.995283\ttraining's binary_logloss: 0.101826\n",
      "[9467]\ttraining's auc: 0.995283\ttraining's binary_logloss: 0.101825\n",
      "[9468]\ttraining's auc: 0.995286\ttraining's binary_logloss: 0.101815\n",
      "[9469]\ttraining's auc: 0.995288\ttraining's binary_logloss: 0.101806\n",
      "[9470]\ttraining's auc: 0.995289\ttraining's binary_logloss: 0.101798\n",
      "[9471]\ttraining's auc: 0.995291\ttraining's binary_logloss: 0.101788\n",
      "[9472]\ttraining's auc: 0.995294\ttraining's binary_logloss: 0.101778\n",
      "[9473]\ttraining's auc: 0.995296\ttraining's binary_logloss: 0.101772\n",
      "[9474]\ttraining's auc: 0.995298\ttraining's binary_logloss: 0.101763\n",
      "[9475]\ttraining's auc: 0.9953\ttraining's binary_logloss: 0.101756\n",
      "[9476]\ttraining's auc: 0.995302\ttraining's binary_logloss: 0.10175\n",
      "[9477]\ttraining's auc: 0.995304\ttraining's binary_logloss: 0.101742\n",
      "[9478]\ttraining's auc: 0.995307\ttraining's binary_logloss: 0.101732\n",
      "[9479]\ttraining's auc: 0.99531\ttraining's binary_logloss: 0.101722\n",
      "[9480]\ttraining's auc: 0.995312\ttraining's binary_logloss: 0.101718\n",
      "[9481]\ttraining's auc: 0.995315\ttraining's binary_logloss: 0.101709\n",
      "[9482]\ttraining's auc: 0.995317\ttraining's binary_logloss: 0.101699\n",
      "[9483]\ttraining's auc: 0.99532\ttraining's binary_logloss: 0.101691\n",
      "[9484]\ttraining's auc: 0.995322\ttraining's binary_logloss: 0.101683\n",
      "[9485]\ttraining's auc: 0.995323\ttraining's binary_logloss: 0.101678\n",
      "[9486]\ttraining's auc: 0.995325\ttraining's binary_logloss: 0.101671\n",
      "[9487]\ttraining's auc: 0.995328\ttraining's binary_logloss: 0.101662\n",
      "[9488]\ttraining's auc: 0.995331\ttraining's binary_logloss: 0.101653\n",
      "[9489]\ttraining's auc: 0.995332\ttraining's binary_logloss: 0.101644\n",
      "[9490]\ttraining's auc: 0.995335\ttraining's binary_logloss: 0.101634\n",
      "[9491]\ttraining's auc: 0.995337\ttraining's binary_logloss: 0.101624\n",
      "[9492]\ttraining's auc: 0.995338\ttraining's binary_logloss: 0.101621\n",
      "[9493]\ttraining's auc: 0.995339\ttraining's binary_logloss: 0.101614\n",
      "[9494]\ttraining's auc: 0.995339\ttraining's binary_logloss: 0.10161\n",
      "[9495]\ttraining's auc: 0.99534\ttraining's binary_logloss: 0.101609\n",
      "[9496]\ttraining's auc: 0.995342\ttraining's binary_logloss: 0.1016\n",
      "[9497]\ttraining's auc: 0.995345\ttraining's binary_logloss: 0.10159\n",
      "[9498]\ttraining's auc: 0.995347\ttraining's binary_logloss: 0.10158\n",
      "[9499]\ttraining's auc: 0.995349\ttraining's binary_logloss: 0.101572\n",
      "[9500]\ttraining's auc: 0.995352\ttraining's binary_logloss: 0.101564\n",
      "[9501]\ttraining's auc: 0.995354\ttraining's binary_logloss: 0.101554\n",
      "[9502]\ttraining's auc: 0.995356\ttraining's binary_logloss: 0.101546\n",
      "[9503]\ttraining's auc: 0.995358\ttraining's binary_logloss: 0.101537\n",
      "[9504]\ttraining's auc: 0.995361\ttraining's binary_logloss: 0.101528\n",
      "[9505]\ttraining's auc: 0.995363\ttraining's binary_logloss: 0.101519\n",
      "[9506]\ttraining's auc: 0.995364\ttraining's binary_logloss: 0.101515\n",
      "[9507]\ttraining's auc: 0.995367\ttraining's binary_logloss: 0.101506\n",
      "[9508]\ttraining's auc: 0.995371\ttraining's binary_logloss: 0.101494\n",
      "[9509]\ttraining's auc: 0.995372\ttraining's binary_logloss: 0.101485\n",
      "[9510]\ttraining's auc: 0.995374\ttraining's binary_logloss: 0.101476\n",
      "[9511]\ttraining's auc: 0.995375\ttraining's binary_logloss: 0.101466\n",
      "[9512]\ttraining's auc: 0.995378\ttraining's binary_logloss: 0.101456\n",
      "[9513]\ttraining's auc: 0.995382\ttraining's binary_logloss: 0.101444\n",
      "[9514]\ttraining's auc: 0.995383\ttraining's binary_logloss: 0.101437\n",
      "[9515]\ttraining's auc: 0.995385\ttraining's binary_logloss: 0.101427\n",
      "[9516]\ttraining's auc: 0.995389\ttraining's binary_logloss: 0.101418\n",
      "[9517]\ttraining's auc: 0.995392\ttraining's binary_logloss: 0.101408\n",
      "[9518]\ttraining's auc: 0.995394\ttraining's binary_logloss: 0.101397\n",
      "[9519]\ttraining's auc: 0.995396\ttraining's binary_logloss: 0.101387\n",
      "[9520]\ttraining's auc: 0.995397\ttraining's binary_logloss: 0.101379\n",
      "[9521]\ttraining's auc: 0.995401\ttraining's binary_logloss: 0.10137\n",
      "[9522]\ttraining's auc: 0.995403\ttraining's binary_logloss: 0.101361\n",
      "[9523]\ttraining's auc: 0.995405\ttraining's binary_logloss: 0.101352\n",
      "[9524]\ttraining's auc: 0.995407\ttraining's binary_logloss: 0.101343\n",
      "[9525]\ttraining's auc: 0.995409\ttraining's binary_logloss: 0.101333\n",
      "[9526]\ttraining's auc: 0.995412\ttraining's binary_logloss: 0.101324\n",
      "[9527]\ttraining's auc: 0.995413\ttraining's binary_logloss: 0.101319\n",
      "[9528]\ttraining's auc: 0.995414\ttraining's binary_logloss: 0.101313\n",
      "[9529]\ttraining's auc: 0.995416\ttraining's binary_logloss: 0.101303\n",
      "[9530]\ttraining's auc: 0.995417\ttraining's binary_logloss: 0.101301\n",
      "[9531]\ttraining's auc: 0.995419\ttraining's binary_logloss: 0.101291\n",
      "[9532]\ttraining's auc: 0.995419\ttraining's binary_logloss: 0.101288\n",
      "[9533]\ttraining's auc: 0.99542\ttraining's binary_logloss: 0.101281\n",
      "[9534]\ttraining's auc: 0.995424\ttraining's binary_logloss: 0.101269\n",
      "[9535]\ttraining's auc: 0.995427\ttraining's binary_logloss: 0.101259\n",
      "[9536]\ttraining's auc: 0.99543\ttraining's binary_logloss: 0.101247\n",
      "[9537]\ttraining's auc: 0.995433\ttraining's binary_logloss: 0.101237\n",
      "[9538]\ttraining's auc: 0.995435\ttraining's binary_logloss: 0.101227\n",
      "[9539]\ttraining's auc: 0.995437\ttraining's binary_logloss: 0.101218\n",
      "[9540]\ttraining's auc: 0.995439\ttraining's binary_logloss: 0.101208\n",
      "[9541]\ttraining's auc: 0.995442\ttraining's binary_logloss: 0.101198\n",
      "[9542]\ttraining's auc: 0.995445\ttraining's binary_logloss: 0.101186\n",
      "[9543]\ttraining's auc: 0.995448\ttraining's binary_logloss: 0.101178\n",
      "[9544]\ttraining's auc: 0.995449\ttraining's binary_logloss: 0.101167\n",
      "[9545]\ttraining's auc: 0.995452\ttraining's binary_logloss: 0.101157\n",
      "[9546]\ttraining's auc: 0.995454\ttraining's binary_logloss: 0.101149\n",
      "[9547]\ttraining's auc: 0.995457\ttraining's binary_logloss: 0.101139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9548]\ttraining's auc: 0.995459\ttraining's binary_logloss: 0.101129\n",
      "[9549]\ttraining's auc: 0.99546\ttraining's binary_logloss: 0.101127\n",
      "[9550]\ttraining's auc: 0.995461\ttraining's binary_logloss: 0.101121\n",
      "[9551]\ttraining's auc: 0.995464\ttraining's binary_logloss: 0.101114\n",
      "[9552]\ttraining's auc: 0.995466\ttraining's binary_logloss: 0.101104\n",
      "[9553]\ttraining's auc: 0.995467\ttraining's binary_logloss: 0.101095\n",
      "[9554]\ttraining's auc: 0.99547\ttraining's binary_logloss: 0.101086\n",
      "[9555]\ttraining's auc: 0.995472\ttraining's binary_logloss: 0.101076\n",
      "[9556]\ttraining's auc: 0.995473\ttraining's binary_logloss: 0.101071\n",
      "[9557]\ttraining's auc: 0.995476\ttraining's binary_logloss: 0.101063\n",
      "[9558]\ttraining's auc: 0.995477\ttraining's binary_logloss: 0.101054\n",
      "[9559]\ttraining's auc: 0.995478\ttraining's binary_logloss: 0.101045\n",
      "[9560]\ttraining's auc: 0.99548\ttraining's binary_logloss: 0.101037\n",
      "[9561]\ttraining's auc: 0.995484\ttraining's binary_logloss: 0.101029\n",
      "[9562]\ttraining's auc: 0.995484\ttraining's binary_logloss: 0.101019\n",
      "[9563]\ttraining's auc: 0.995486\ttraining's binary_logloss: 0.101013\n",
      "[9564]\ttraining's auc: 0.995487\ttraining's binary_logloss: 0.101005\n",
      "[9565]\ttraining's auc: 0.99549\ttraining's binary_logloss: 0.100996\n",
      "[9566]\ttraining's auc: 0.995492\ttraining's binary_logloss: 0.100987\n",
      "[9567]\ttraining's auc: 0.995496\ttraining's binary_logloss: 0.100976\n",
      "[9568]\ttraining's auc: 0.995499\ttraining's binary_logloss: 0.100965\n",
      "[9569]\ttraining's auc: 0.995501\ttraining's binary_logloss: 0.100956\n",
      "[9570]\ttraining's auc: 0.995504\ttraining's binary_logloss: 0.100947\n",
      "[9571]\ttraining's auc: 0.995506\ttraining's binary_logloss: 0.100938\n",
      "[9572]\ttraining's auc: 0.995506\ttraining's binary_logloss: 0.100936\n",
      "[9573]\ttraining's auc: 0.995507\ttraining's binary_logloss: 0.100929\n",
      "[9574]\ttraining's auc: 0.995508\ttraining's binary_logloss: 0.100921\n",
      "[9575]\ttraining's auc: 0.995509\ttraining's binary_logloss: 0.100916\n",
      "[9576]\ttraining's auc: 0.995511\ttraining's binary_logloss: 0.100909\n",
      "[9577]\ttraining's auc: 0.995513\ttraining's binary_logloss: 0.100901\n",
      "[9578]\ttraining's auc: 0.995515\ttraining's binary_logloss: 0.100892\n",
      "[9579]\ttraining's auc: 0.995515\ttraining's binary_logloss: 0.100883\n",
      "[9580]\ttraining's auc: 0.995517\ttraining's binary_logloss: 0.100874\n",
      "[9581]\ttraining's auc: 0.995519\ttraining's binary_logloss: 0.100865\n",
      "[9582]\ttraining's auc: 0.99552\ttraining's binary_logloss: 0.100859\n",
      "[9583]\ttraining's auc: 0.995523\ttraining's binary_logloss: 0.100852\n",
      "[9584]\ttraining's auc: 0.995525\ttraining's binary_logloss: 0.100842\n",
      "[9585]\ttraining's auc: 0.995527\ttraining's binary_logloss: 0.100832\n",
      "[9586]\ttraining's auc: 0.995529\ttraining's binary_logloss: 0.100823\n",
      "[9587]\ttraining's auc: 0.99553\ttraining's binary_logloss: 0.100816\n",
      "[9588]\ttraining's auc: 0.995533\ttraining's binary_logloss: 0.100807\n",
      "[9589]\ttraining's auc: 0.995537\ttraining's binary_logloss: 0.100796\n",
      "[9590]\ttraining's auc: 0.995537\ttraining's binary_logloss: 0.100788\n",
      "[9591]\ttraining's auc: 0.995541\ttraining's binary_logloss: 0.100779\n",
      "[9592]\ttraining's auc: 0.995544\ttraining's binary_logloss: 0.10077\n",
      "[9593]\ttraining's auc: 0.995546\ttraining's binary_logloss: 0.100761\n",
      "[9594]\ttraining's auc: 0.995548\ttraining's binary_logloss: 0.100752\n",
      "[9595]\ttraining's auc: 0.99555\ttraining's binary_logloss: 0.100748\n",
      "[9596]\ttraining's auc: 0.995554\ttraining's binary_logloss: 0.100737\n",
      "[9597]\ttraining's auc: 0.995557\ttraining's binary_logloss: 0.100731\n",
      "[9598]\ttraining's auc: 0.995559\ttraining's binary_logloss: 0.100722\n",
      "[9599]\ttraining's auc: 0.995561\ttraining's binary_logloss: 0.100713\n",
      "[9600]\ttraining's auc: 0.995564\ttraining's binary_logloss: 0.100703\n",
      "[9601]\ttraining's auc: 0.995565\ttraining's binary_logloss: 0.100698\n",
      "[9602]\ttraining's auc: 0.995565\ttraining's binary_logloss: 0.100694\n",
      "[9603]\ttraining's auc: 0.995568\ttraining's binary_logloss: 0.100685\n",
      "[9604]\ttraining's auc: 0.99557\ttraining's binary_logloss: 0.100674\n",
      "[9605]\ttraining's auc: 0.995572\ttraining's binary_logloss: 0.100666\n",
      "[9606]\ttraining's auc: 0.995573\ttraining's binary_logloss: 0.100657\n",
      "[9607]\ttraining's auc: 0.995575\ttraining's binary_logloss: 0.10065\n",
      "[9608]\ttraining's auc: 0.995577\ttraining's binary_logloss: 0.100642\n",
      "[9609]\ttraining's auc: 0.995578\ttraining's binary_logloss: 0.100636\n",
      "[9610]\ttraining's auc: 0.995582\ttraining's binary_logloss: 0.100625\n",
      "[9611]\ttraining's auc: 0.995584\ttraining's binary_logloss: 0.100615\n",
      "[9612]\ttraining's auc: 0.995587\ttraining's binary_logloss: 0.100604\n",
      "[9613]\ttraining's auc: 0.995588\ttraining's binary_logloss: 0.100595\n",
      "[9614]\ttraining's auc: 0.995591\ttraining's binary_logloss: 0.100585\n",
      "[9615]\ttraining's auc: 0.995592\ttraining's binary_logloss: 0.100576\n",
      "[9616]\ttraining's auc: 0.995595\ttraining's binary_logloss: 0.100566\n",
      "[9617]\ttraining's auc: 0.995595\ttraining's binary_logloss: 0.100566\n",
      "[9618]\ttraining's auc: 0.995597\ttraining's binary_logloss: 0.100556\n",
      "[9619]\ttraining's auc: 0.995599\ttraining's binary_logloss: 0.100548\n",
      "[9620]\ttraining's auc: 0.995602\ttraining's binary_logloss: 0.100538\n",
      "[9621]\ttraining's auc: 0.995604\ttraining's binary_logloss: 0.100528\n",
      "[9622]\ttraining's auc: 0.995606\ttraining's binary_logloss: 0.100519\n",
      "[9623]\ttraining's auc: 0.995608\ttraining's binary_logloss: 0.100511\n",
      "[9624]\ttraining's auc: 0.995609\ttraining's binary_logloss: 0.100502\n",
      "[9625]\ttraining's auc: 0.995612\ttraining's binary_logloss: 0.100493\n",
      "[9626]\ttraining's auc: 0.995615\ttraining's binary_logloss: 0.100485\n",
      "[9627]\ttraining's auc: 0.995618\ttraining's binary_logloss: 0.100476\n",
      "[9628]\ttraining's auc: 0.99562\ttraining's binary_logloss: 0.100465\n",
      "[9629]\ttraining's auc: 0.995622\ttraining's binary_logloss: 0.100457\n",
      "[9630]\ttraining's auc: 0.995622\ttraining's binary_logloss: 0.100451\n",
      "[9631]\ttraining's auc: 0.995625\ttraining's binary_logloss: 0.100442\n",
      "[9632]\ttraining's auc: 0.995628\ttraining's binary_logloss: 0.100432\n",
      "[9633]\ttraining's auc: 0.995631\ttraining's binary_logloss: 0.100422\n",
      "[9634]\ttraining's auc: 0.995633\ttraining's binary_logloss: 0.100412\n",
      "[9635]\ttraining's auc: 0.995636\ttraining's binary_logloss: 0.100402\n",
      "[9636]\ttraining's auc: 0.995638\ttraining's binary_logloss: 0.100394\n",
      "[9637]\ttraining's auc: 0.995639\ttraining's binary_logloss: 0.100389\n",
      "[9638]\ttraining's auc: 0.995642\ttraining's binary_logloss: 0.100378\n",
      "[9639]\ttraining's auc: 0.995644\ttraining's binary_logloss: 0.10037\n",
      "[9640]\ttraining's auc: 0.995644\ttraining's binary_logloss: 0.100368\n",
      "[9641]\ttraining's auc: 0.995645\ttraining's binary_logloss: 0.10036\n",
      "[9642]\ttraining's auc: 0.995647\ttraining's binary_logloss: 0.100352\n",
      "[9643]\ttraining's auc: 0.995649\ttraining's binary_logloss: 0.100344\n",
      "[9644]\ttraining's auc: 0.995651\ttraining's binary_logloss: 0.100334\n",
      "[9645]\ttraining's auc: 0.995654\ttraining's binary_logloss: 0.100324\n",
      "[9646]\ttraining's auc: 0.995655\ttraining's binary_logloss: 0.100319\n",
      "[9647]\ttraining's auc: 0.995655\ttraining's binary_logloss: 0.100318\n",
      "[9648]\ttraining's auc: 0.995658\ttraining's binary_logloss: 0.100308\n",
      "[9649]\ttraining's auc: 0.995659\ttraining's binary_logloss: 0.100299\n",
      "[9650]\ttraining's auc: 0.995661\ttraining's binary_logloss: 0.100292\n",
      "[9651]\ttraining's auc: 0.995662\ttraining's binary_logloss: 0.100291\n",
      "[9652]\ttraining's auc: 0.995662\ttraining's binary_logloss: 0.100286\n",
      "[9653]\ttraining's auc: 0.995665\ttraining's binary_logloss: 0.100276\n",
      "[9654]\ttraining's auc: 0.995666\ttraining's binary_logloss: 0.100268\n",
      "[9655]\ttraining's auc: 0.995669\ttraining's binary_logloss: 0.100258\n",
      "[9656]\ttraining's auc: 0.99567\ttraining's binary_logloss: 0.10025\n",
      "[9657]\ttraining's auc: 0.995672\ttraining's binary_logloss: 0.100241\n",
      "[9658]\ttraining's auc: 0.995673\ttraining's binary_logloss: 0.100234\n",
      "[9659]\ttraining's auc: 0.995675\ttraining's binary_logloss: 0.100223\n",
      "[9660]\ttraining's auc: 0.995678\ttraining's binary_logloss: 0.100214\n",
      "[9661]\ttraining's auc: 0.99568\ttraining's binary_logloss: 0.100204\n",
      "[9662]\ttraining's auc: 0.995681\ttraining's binary_logloss: 0.100198\n",
      "[9663]\ttraining's auc: 0.995683\ttraining's binary_logloss: 0.100189\n",
      "[9664]\ttraining's auc: 0.995685\ttraining's binary_logloss: 0.100182\n",
      "[9665]\ttraining's auc: 0.995689\ttraining's binary_logloss: 0.100172\n",
      "[9666]\ttraining's auc: 0.995693\ttraining's binary_logloss: 0.100163\n",
      "[9667]\ttraining's auc: 0.995695\ttraining's binary_logloss: 0.100154\n",
      "[9668]\ttraining's auc: 0.995698\ttraining's binary_logloss: 0.100145\n",
      "[9669]\ttraining's auc: 0.995699\ttraining's binary_logloss: 0.100137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9670]\ttraining's auc: 0.9957\ttraining's binary_logloss: 0.100128\n",
      "[9671]\ttraining's auc: 0.995702\ttraining's binary_logloss: 0.100118\n",
      "[9672]\ttraining's auc: 0.995705\ttraining's binary_logloss: 0.100107\n",
      "[9673]\ttraining's auc: 0.995707\ttraining's binary_logloss: 0.100099\n",
      "[9674]\ttraining's auc: 0.995707\ttraining's binary_logloss: 0.100097\n",
      "[9675]\ttraining's auc: 0.995708\ttraining's binary_logloss: 0.10009\n",
      "[9676]\ttraining's auc: 0.99571\ttraining's binary_logloss: 0.100081\n",
      "[9677]\ttraining's auc: 0.995711\ttraining's binary_logloss: 0.100071\n",
      "[9678]\ttraining's auc: 0.995712\ttraining's binary_logloss: 0.100066\n",
      "[9679]\ttraining's auc: 0.995714\ttraining's binary_logloss: 0.100056\n",
      "[9680]\ttraining's auc: 0.995716\ttraining's binary_logloss: 0.100047\n",
      "[9681]\ttraining's auc: 0.995717\ttraining's binary_logloss: 0.10004\n",
      "[9682]\ttraining's auc: 0.99572\ttraining's binary_logloss: 0.100031\n",
      "[9683]\ttraining's auc: 0.995721\ttraining's binary_logloss: 0.100024\n",
      "[9684]\ttraining's auc: 0.995724\ttraining's binary_logloss: 0.100014\n",
      "[9685]\ttraining's auc: 0.995725\ttraining's binary_logloss: 0.100004\n",
      "[9686]\ttraining's auc: 0.995729\ttraining's binary_logloss: 0.0999917\n",
      "[9687]\ttraining's auc: 0.995732\ttraining's binary_logloss: 0.0999818\n",
      "[9688]\ttraining's auc: 0.995733\ttraining's binary_logloss: 0.0999726\n",
      "[9689]\ttraining's auc: 0.995735\ttraining's binary_logloss: 0.0999639\n",
      "[9690]\ttraining's auc: 0.995736\ttraining's binary_logloss: 0.0999554\n",
      "[9691]\ttraining's auc: 0.995738\ttraining's binary_logloss: 0.0999463\n",
      "[9692]\ttraining's auc: 0.99574\ttraining's binary_logloss: 0.0999402\n",
      "[9693]\ttraining's auc: 0.995741\ttraining's binary_logloss: 0.0999305\n",
      "[9694]\ttraining's auc: 0.995743\ttraining's binary_logloss: 0.0999218\n",
      "[9695]\ttraining's auc: 0.995746\ttraining's binary_logloss: 0.0999131\n",
      "[9696]\ttraining's auc: 0.995746\ttraining's binary_logloss: 0.0999091\n",
      "[9697]\ttraining's auc: 0.995748\ttraining's binary_logloss: 0.0999028\n",
      "[9698]\ttraining's auc: 0.99575\ttraining's binary_logloss: 0.0998964\n",
      "[9699]\ttraining's auc: 0.995752\ttraining's binary_logloss: 0.0998875\n",
      "[9700]\ttraining's auc: 0.995752\ttraining's binary_logloss: 0.0998787\n",
      "[9701]\ttraining's auc: 0.995756\ttraining's binary_logloss: 0.0998673\n",
      "[9702]\ttraining's auc: 0.995757\ttraining's binary_logloss: 0.0998599\n",
      "[9703]\ttraining's auc: 0.995759\ttraining's binary_logloss: 0.0998515\n",
      "[9704]\ttraining's auc: 0.995761\ttraining's binary_logloss: 0.0998412\n",
      "[9705]\ttraining's auc: 0.995762\ttraining's binary_logloss: 0.0998341\n",
      "[9706]\ttraining's auc: 0.995765\ttraining's binary_logloss: 0.0998246\n",
      "[9707]\ttraining's auc: 0.995766\ttraining's binary_logloss: 0.0998164\n",
      "[9708]\ttraining's auc: 0.995767\ttraining's binary_logloss: 0.0998112\n",
      "[9709]\ttraining's auc: 0.995769\ttraining's binary_logloss: 0.0998022\n",
      "[9710]\ttraining's auc: 0.995772\ttraining's binary_logloss: 0.099793\n",
      "[9711]\ttraining's auc: 0.995775\ttraining's binary_logloss: 0.0997841\n",
      "[9712]\ttraining's auc: 0.995776\ttraining's binary_logloss: 0.0997782\n",
      "[9713]\ttraining's auc: 0.995779\ttraining's binary_logloss: 0.0997688\n",
      "[9714]\ttraining's auc: 0.995781\ttraining's binary_logloss: 0.0997613\n",
      "[9715]\ttraining's auc: 0.995784\ttraining's binary_logloss: 0.0997526\n",
      "[9716]\ttraining's auc: 0.995786\ttraining's binary_logloss: 0.0997442\n",
      "[9717]\ttraining's auc: 0.995788\ttraining's binary_logloss: 0.0997349\n",
      "[9718]\ttraining's auc: 0.99579\ttraining's binary_logloss: 0.0997299\n",
      "[9719]\ttraining's auc: 0.995792\ttraining's binary_logloss: 0.0997201\n",
      "[9720]\ttraining's auc: 0.995794\ttraining's binary_logloss: 0.0997127\n",
      "[9721]\ttraining's auc: 0.995796\ttraining's binary_logloss: 0.0997011\n",
      "[9722]\ttraining's auc: 0.995798\ttraining's binary_logloss: 0.0996918\n",
      "[9723]\ttraining's auc: 0.995801\ttraining's binary_logloss: 0.0996814\n",
      "[9724]\ttraining's auc: 0.995803\ttraining's binary_logloss: 0.0996742\n",
      "[9725]\ttraining's auc: 0.995805\ttraining's binary_logloss: 0.0996633\n",
      "[9726]\ttraining's auc: 0.995806\ttraining's binary_logloss: 0.0996547\n",
      "[9727]\ttraining's auc: 0.995808\ttraining's binary_logloss: 0.0996456\n",
      "[9728]\ttraining's auc: 0.995811\ttraining's binary_logloss: 0.0996361\n",
      "[9729]\ttraining's auc: 0.995813\ttraining's binary_logloss: 0.0996261\n",
      "[9730]\ttraining's auc: 0.995818\ttraining's binary_logloss: 0.0996153\n",
      "[9731]\ttraining's auc: 0.995821\ttraining's binary_logloss: 0.0996048\n",
      "[9732]\ttraining's auc: 0.995822\ttraining's binary_logloss: 0.0995955\n",
      "[9733]\ttraining's auc: 0.995825\ttraining's binary_logloss: 0.0995862\n",
      "[9734]\ttraining's auc: 0.995827\ttraining's binary_logloss: 0.0995761\n",
      "[9735]\ttraining's auc: 0.995827\ttraining's binary_logloss: 0.0995747\n",
      "[9736]\ttraining's auc: 0.995829\ttraining's binary_logloss: 0.099567\n",
      "[9737]\ttraining's auc: 0.995831\ttraining's binary_logloss: 0.099558\n",
      "[9738]\ttraining's auc: 0.995833\ttraining's binary_logloss: 0.0995491\n",
      "[9739]\ttraining's auc: 0.995837\ttraining's binary_logloss: 0.0995376\n",
      "[9740]\ttraining's auc: 0.995838\ttraining's binary_logloss: 0.0995288\n",
      "[9741]\ttraining's auc: 0.99584\ttraining's binary_logloss: 0.0995205\n",
      "[9742]\ttraining's auc: 0.995842\ttraining's binary_logloss: 0.0995118\n",
      "[9743]\ttraining's auc: 0.995845\ttraining's binary_logloss: 0.0995028\n",
      "[9744]\ttraining's auc: 0.995845\ttraining's binary_logloss: 0.0994974\n",
      "[9745]\ttraining's auc: 0.995847\ttraining's binary_logloss: 0.0994879\n",
      "[9746]\ttraining's auc: 0.995849\ttraining's binary_logloss: 0.0994796\n",
      "[9747]\ttraining's auc: 0.995851\ttraining's binary_logloss: 0.0994705\n",
      "[9748]\ttraining's auc: 0.995853\ttraining's binary_logloss: 0.0994608\n",
      "[9749]\ttraining's auc: 0.995852\ttraining's binary_logloss: 0.0994593\n",
      "[9750]\ttraining's auc: 0.995855\ttraining's binary_logloss: 0.0994496\n",
      "[9751]\ttraining's auc: 0.995857\ttraining's binary_logloss: 0.0994418\n",
      "[9752]\ttraining's auc: 0.995857\ttraining's binary_logloss: 0.0994398\n",
      "[9753]\ttraining's auc: 0.995858\ttraining's binary_logloss: 0.0994313\n",
      "[9754]\ttraining's auc: 0.99586\ttraining's binary_logloss: 0.0994235\n",
      "[9755]\ttraining's auc: 0.995861\ttraining's binary_logloss: 0.0994151\n",
      "[9756]\ttraining's auc: 0.995863\ttraining's binary_logloss: 0.099405\n",
      "[9757]\ttraining's auc: 0.995865\ttraining's binary_logloss: 0.0993956\n",
      "[9758]\ttraining's auc: 0.995867\ttraining's binary_logloss: 0.0993853\n",
      "[9759]\ttraining's auc: 0.995869\ttraining's binary_logloss: 0.0993798\n",
      "[9760]\ttraining's auc: 0.995871\ttraining's binary_logloss: 0.0993719\n",
      "[9761]\ttraining's auc: 0.995873\ttraining's binary_logloss: 0.0993617\n",
      "[9762]\ttraining's auc: 0.995875\ttraining's binary_logloss: 0.0993543\n",
      "[9763]\ttraining's auc: 0.995878\ttraining's binary_logloss: 0.0993449\n",
      "[9764]\ttraining's auc: 0.995878\ttraining's binary_logloss: 0.0993442\n",
      "[9765]\ttraining's auc: 0.995881\ttraining's binary_logloss: 0.0993363\n",
      "[9766]\ttraining's auc: 0.995883\ttraining's binary_logloss: 0.0993273\n",
      "[9767]\ttraining's auc: 0.995885\ttraining's binary_logloss: 0.0993186\n",
      "[9768]\ttraining's auc: 0.995887\ttraining's binary_logloss: 0.0993096\n",
      "[9769]\ttraining's auc: 0.995889\ttraining's binary_logloss: 0.0993016\n",
      "[9770]\ttraining's auc: 0.99589\ttraining's binary_logloss: 0.0992968\n",
      "[9771]\ttraining's auc: 0.995893\ttraining's binary_logloss: 0.0992878\n",
      "[9772]\ttraining's auc: 0.995896\ttraining's binary_logloss: 0.0992776\n",
      "[9773]\ttraining's auc: 0.995898\ttraining's binary_logloss: 0.0992681\n",
      "[9774]\ttraining's auc: 0.995898\ttraining's binary_logloss: 0.0992618\n",
      "[9775]\ttraining's auc: 0.9959\ttraining's binary_logloss: 0.0992556\n",
      "[9776]\ttraining's auc: 0.995904\ttraining's binary_logloss: 0.099244\n",
      "[9777]\ttraining's auc: 0.995905\ttraining's binary_logloss: 0.0992353\n",
      "[9778]\ttraining's auc: 0.995909\ttraining's binary_logloss: 0.0992244\n",
      "[9779]\ttraining's auc: 0.995911\ttraining's binary_logloss: 0.0992134\n",
      "[9780]\ttraining's auc: 0.995912\ttraining's binary_logloss: 0.0992056\n",
      "[9781]\ttraining's auc: 0.995916\ttraining's binary_logloss: 0.099195\n",
      "[9782]\ttraining's auc: 0.995917\ttraining's binary_logloss: 0.0991886\n",
      "[9783]\ttraining's auc: 0.995917\ttraining's binary_logloss: 0.0991876\n",
      "[9784]\ttraining's auc: 0.99592\ttraining's binary_logloss: 0.0991785\n",
      "[9785]\ttraining's auc: 0.995923\ttraining's binary_logloss: 0.0991687\n",
      "[9786]\ttraining's auc: 0.995923\ttraining's binary_logloss: 0.0991602\n",
      "[9787]\ttraining's auc: 0.995926\ttraining's binary_logloss: 0.0991533\n",
      "[9788]\ttraining's auc: 0.995928\ttraining's binary_logloss: 0.0991436\n",
      "[9789]\ttraining's auc: 0.995929\ttraining's binary_logloss: 0.0991392\n",
      "[9790]\ttraining's auc: 0.99593\ttraining's binary_logloss: 0.0991345\n",
      "[9791]\ttraining's auc: 0.995932\ttraining's binary_logloss: 0.0991242\n",
      "[9792]\ttraining's auc: 0.995933\ttraining's binary_logloss: 0.0991186\n",
      "[9793]\ttraining's auc: 0.995937\ttraining's binary_logloss: 0.0991078\n",
      "[9794]\ttraining's auc: 0.995939\ttraining's binary_logloss: 0.0991003\n",
      "[9795]\ttraining's auc: 0.995939\ttraining's binary_logloss: 0.0990994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9796]\ttraining's auc: 0.99594\ttraining's binary_logloss: 0.0990908\n",
      "[9797]\ttraining's auc: 0.995942\ttraining's binary_logloss: 0.0990877\n",
      "[9798]\ttraining's auc: 0.995944\ttraining's binary_logloss: 0.0990785\n",
      "[9799]\ttraining's auc: 0.995945\ttraining's binary_logloss: 0.0990715\n",
      "[9800]\ttraining's auc: 0.995949\ttraining's binary_logloss: 0.0990609\n",
      "[9801]\ttraining's auc: 0.995951\ttraining's binary_logloss: 0.099051\n",
      "[9802]\ttraining's auc: 0.995952\ttraining's binary_logloss: 0.0990419\n",
      "[9803]\ttraining's auc: 0.995955\ttraining's binary_logloss: 0.0990327\n",
      "[9804]\ttraining's auc: 0.995957\ttraining's binary_logloss: 0.0990228\n",
      "[9805]\ttraining's auc: 0.995959\ttraining's binary_logloss: 0.0990141\n",
      "[9806]\ttraining's auc: 0.995961\ttraining's binary_logloss: 0.0990063\n",
      "[9807]\ttraining's auc: 0.995965\ttraining's binary_logloss: 0.098995\n",
      "[9808]\ttraining's auc: 0.995966\ttraining's binary_logloss: 0.0989889\n",
      "[9809]\ttraining's auc: 0.995969\ttraining's binary_logloss: 0.0989795\n",
      "[9810]\ttraining's auc: 0.995971\ttraining's binary_logloss: 0.0989702\n",
      "[9811]\ttraining's auc: 0.995972\ttraining's binary_logloss: 0.0989627\n",
      "[9812]\ttraining's auc: 0.995975\ttraining's binary_logloss: 0.0989528\n",
      "[9813]\ttraining's auc: 0.995978\ttraining's binary_logloss: 0.0989423\n",
      "[9814]\ttraining's auc: 0.995979\ttraining's binary_logloss: 0.098936\n",
      "[9815]\ttraining's auc: 0.99598\ttraining's binary_logloss: 0.0989269\n",
      "[9816]\ttraining's auc: 0.995981\ttraining's binary_logloss: 0.0989178\n",
      "[9817]\ttraining's auc: 0.995982\ttraining's binary_logloss: 0.0989102\n",
      "[9818]\ttraining's auc: 0.995984\ttraining's binary_logloss: 0.0989023\n",
      "[9819]\ttraining's auc: 0.995987\ttraining's binary_logloss: 0.0988934\n",
      "[9820]\ttraining's auc: 0.995987\ttraining's binary_logloss: 0.0988908\n",
      "[9821]\ttraining's auc: 0.995987\ttraining's binary_logloss: 0.0988882\n",
      "[9822]\ttraining's auc: 0.995989\ttraining's binary_logloss: 0.0988801\n",
      "[9823]\ttraining's auc: 0.995992\ttraining's binary_logloss: 0.0988709\n",
      "[9824]\ttraining's auc: 0.995994\ttraining's binary_logloss: 0.0988621\n",
      "[9825]\ttraining's auc: 0.995998\ttraining's binary_logloss: 0.0988508\n",
      "[9826]\ttraining's auc: 0.996\ttraining's binary_logloss: 0.098843\n",
      "[9827]\ttraining's auc: 0.996001\ttraining's binary_logloss: 0.0988372\n",
      "[9828]\ttraining's auc: 0.996002\ttraining's binary_logloss: 0.0988315\n",
      "[9829]\ttraining's auc: 0.996004\ttraining's binary_logloss: 0.0988221\n",
      "[9830]\ttraining's auc: 0.996005\ttraining's binary_logloss: 0.0988131\n",
      "[9831]\ttraining's auc: 0.996007\ttraining's binary_logloss: 0.0988051\n",
      "[9832]\ttraining's auc: 0.996009\ttraining's binary_logloss: 0.0987989\n",
      "[9833]\ttraining's auc: 0.996011\ttraining's binary_logloss: 0.0987907\n",
      "[9834]\ttraining's auc: 0.996012\ttraining's binary_logloss: 0.0987823\n",
      "[9835]\ttraining's auc: 0.996013\ttraining's binary_logloss: 0.0987764\n",
      "[9836]\ttraining's auc: 0.996015\ttraining's binary_logloss: 0.0987678\n",
      "[9837]\ttraining's auc: 0.996016\ttraining's binary_logloss: 0.0987606\n",
      "[9838]\ttraining's auc: 0.996016\ttraining's binary_logloss: 0.0987589\n",
      "[9839]\ttraining's auc: 0.996016\ttraining's binary_logloss: 0.0987575\n",
      "[9840]\ttraining's auc: 0.996019\ttraining's binary_logloss: 0.0987479\n",
      "[9841]\ttraining's auc: 0.996022\ttraining's binary_logloss: 0.0987387\n",
      "[9842]\ttraining's auc: 0.996023\ttraining's binary_logloss: 0.0987324\n",
      "[9843]\ttraining's auc: 0.996024\ttraining's binary_logloss: 0.0987243\n",
      "[9844]\ttraining's auc: 0.996026\ttraining's binary_logloss: 0.0987172\n",
      "[9845]\ttraining's auc: 0.996028\ttraining's binary_logloss: 0.0987085\n",
      "[9846]\ttraining's auc: 0.99603\ttraining's binary_logloss: 0.0987013\n",
      "[9847]\ttraining's auc: 0.996032\ttraining's binary_logloss: 0.0986931\n",
      "[9848]\ttraining's auc: 0.996033\ttraining's binary_logloss: 0.0986849\n",
      "[9849]\ttraining's auc: 0.996034\ttraining's binary_logloss: 0.0986765\n",
      "[9850]\ttraining's auc: 0.996037\ttraining's binary_logloss: 0.0986679\n",
      "[9851]\ttraining's auc: 0.996038\ttraining's binary_logloss: 0.0986592\n",
      "[9852]\ttraining's auc: 0.996039\ttraining's binary_logloss: 0.0986547\n",
      "[9853]\ttraining's auc: 0.99604\ttraining's binary_logloss: 0.0986491\n",
      "[9854]\ttraining's auc: 0.99604\ttraining's binary_logloss: 0.0986472\n",
      "[9855]\ttraining's auc: 0.99604\ttraining's binary_logloss: 0.0986457\n",
      "[9856]\ttraining's auc: 0.996041\ttraining's binary_logloss: 0.0986406\n",
      "[9857]\ttraining's auc: 0.996045\ttraining's binary_logloss: 0.0986295\n",
      "[9858]\ttraining's auc: 0.996047\ttraining's binary_logloss: 0.0986216\n",
      "[9859]\ttraining's auc: 0.99605\ttraining's binary_logloss: 0.0986128\n",
      "[9860]\ttraining's auc: 0.99605\ttraining's binary_logloss: 0.0986121\n",
      "[9861]\ttraining's auc: 0.996051\ttraining's binary_logloss: 0.0986072\n",
      "[9862]\ttraining's auc: 0.996053\ttraining's binary_logloss: 0.0986003\n",
      "[9863]\ttraining's auc: 0.996056\ttraining's binary_logloss: 0.0985897\n",
      "[9864]\ttraining's auc: 0.996057\ttraining's binary_logloss: 0.0985812\n",
      "[9865]\ttraining's auc: 0.996059\ttraining's binary_logloss: 0.0985719\n",
      "[9866]\ttraining's auc: 0.996059\ttraining's binary_logloss: 0.098571\n",
      "[9867]\ttraining's auc: 0.99606\ttraining's binary_logloss: 0.0985668\n",
      "[9868]\ttraining's auc: 0.996062\ttraining's binary_logloss: 0.0985602\n",
      "[9869]\ttraining's auc: 0.996062\ttraining's binary_logloss: 0.098557\n",
      "[9870]\ttraining's auc: 0.996062\ttraining's binary_logloss: 0.098555\n",
      "[9871]\ttraining's auc: 0.996064\ttraining's binary_logloss: 0.0985461\n",
      "[9872]\ttraining's auc: 0.996067\ttraining's binary_logloss: 0.0985363\n",
      "[9873]\ttraining's auc: 0.996068\ttraining's binary_logloss: 0.098533\n",
      "[9874]\ttraining's auc: 0.996069\ttraining's binary_logloss: 0.0985268\n",
      "[9875]\ttraining's auc: 0.99607\ttraining's binary_logloss: 0.0985188\n",
      "[9876]\ttraining's auc: 0.996072\ttraining's binary_logloss: 0.0985118\n",
      "[9877]\ttraining's auc: 0.996072\ttraining's binary_logloss: 0.0985109\n",
      "[9878]\ttraining's auc: 0.996072\ttraining's binary_logloss: 0.0985097\n",
      "[9879]\ttraining's auc: 0.996073\ttraining's binary_logloss: 0.0985076\n",
      "[9880]\ttraining's auc: 0.996075\ttraining's binary_logloss: 0.0984984\n",
      "[9881]\ttraining's auc: 0.996076\ttraining's binary_logloss: 0.0984896\n",
      "[9882]\ttraining's auc: 0.996077\ttraining's binary_logloss: 0.0984803\n",
      "[9883]\ttraining's auc: 0.996079\ttraining's binary_logloss: 0.0984738\n",
      "[9884]\ttraining's auc: 0.996081\ttraining's binary_logloss: 0.0984653\n",
      "[9885]\ttraining's auc: 0.996083\ttraining's binary_logloss: 0.0984606\n",
      "[9886]\ttraining's auc: 0.996084\ttraining's binary_logloss: 0.098451\n",
      "[9887]\ttraining's auc: 0.996086\ttraining's binary_logloss: 0.0984419\n",
      "[9888]\ttraining's auc: 0.996087\ttraining's binary_logloss: 0.0984374\n",
      "[9889]\ttraining's auc: 0.996088\ttraining's binary_logloss: 0.0984298\n",
      "[9890]\ttraining's auc: 0.996089\ttraining's binary_logloss: 0.0984209\n",
      "[9891]\ttraining's auc: 0.996089\ttraining's binary_logloss: 0.0984173\n",
      "[9892]\ttraining's auc: 0.996091\ttraining's binary_logloss: 0.0984088\n",
      "[9893]\ttraining's auc: 0.996092\ttraining's binary_logloss: 0.0984032\n",
      "[9894]\ttraining's auc: 0.996093\ttraining's binary_logloss: 0.0983964\n",
      "[9895]\ttraining's auc: 0.996095\ttraining's binary_logloss: 0.0983878\n",
      "[9896]\ttraining's auc: 0.996096\ttraining's binary_logloss: 0.0983781\n",
      "[9897]\ttraining's auc: 0.996098\ttraining's binary_logloss: 0.0983704\n",
      "[9898]\ttraining's auc: 0.9961\ttraining's binary_logloss: 0.0983637\n",
      "[9899]\ttraining's auc: 0.996102\ttraining's binary_logloss: 0.0983542\n",
      "[9900]\ttraining's auc: 0.996104\ttraining's binary_logloss: 0.0983456\n",
      "[9901]\ttraining's auc: 0.996105\ttraining's binary_logloss: 0.0983388\n",
      "[9902]\ttraining's auc: 0.996107\ttraining's binary_logloss: 0.0983308\n",
      "[9903]\ttraining's auc: 0.996108\ttraining's binary_logloss: 0.0983276\n",
      "[9904]\ttraining's auc: 0.99611\ttraining's binary_logloss: 0.0983182\n",
      "[9905]\ttraining's auc: 0.996111\ttraining's binary_logloss: 0.0983145\n",
      "[9906]\ttraining's auc: 0.996112\ttraining's binary_logloss: 0.0983061\n",
      "[9907]\ttraining's auc: 0.996113\ttraining's binary_logloss: 0.0982999\n",
      "[9908]\ttraining's auc: 0.996114\ttraining's binary_logloss: 0.0982934\n",
      "[9909]\ttraining's auc: 0.996115\ttraining's binary_logloss: 0.0982922\n",
      "[9910]\ttraining's auc: 0.996116\ttraining's binary_logloss: 0.0982847\n",
      "[9911]\ttraining's auc: 0.996118\ttraining's binary_logloss: 0.0982749\n",
      "[9912]\ttraining's auc: 0.996118\ttraining's binary_logloss: 0.0982727\n",
      "[9913]\ttraining's auc: 0.99612\ttraining's binary_logloss: 0.0982648\n",
      "[9914]\ttraining's auc: 0.996121\ttraining's binary_logloss: 0.0982588\n",
      "[9915]\ttraining's auc: 0.996121\ttraining's binary_logloss: 0.0982568\n",
      "[9916]\ttraining's auc: 0.996122\ttraining's binary_logloss: 0.0982516\n",
      "[9917]\ttraining's auc: 0.996124\ttraining's binary_logloss: 0.0982428\n",
      "[9918]\ttraining's auc: 0.996126\ttraining's binary_logloss: 0.0982342\n",
      "[9919]\ttraining's auc: 0.996128\ttraining's binary_logloss: 0.0982257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9920]\ttraining's auc: 0.996131\ttraining's binary_logloss: 0.0982149\n",
      "[9921]\ttraining's auc: 0.996133\ttraining's binary_logloss: 0.0982054\n",
      "[9922]\ttraining's auc: 0.996135\ttraining's binary_logloss: 0.0981957\n",
      "[9923]\ttraining's auc: 0.996136\ttraining's binary_logloss: 0.0981873\n",
      "[9924]\ttraining's auc: 0.996138\ttraining's binary_logloss: 0.0981782\n",
      "[9925]\ttraining's auc: 0.99614\ttraining's binary_logloss: 0.098167\n",
      "[9926]\ttraining's auc: 0.996141\ttraining's binary_logloss: 0.0981586\n",
      "[9927]\ttraining's auc: 0.996143\ttraining's binary_logloss: 0.0981511\n",
      "[9928]\ttraining's auc: 0.996144\ttraining's binary_logloss: 0.0981428\n",
      "[9929]\ttraining's auc: 0.996147\ttraining's binary_logloss: 0.0981343\n",
      "[9930]\ttraining's auc: 0.996147\ttraining's binary_logloss: 0.0981317\n",
      "[9931]\ttraining's auc: 0.996148\ttraining's binary_logloss: 0.0981271\n",
      "[9932]\ttraining's auc: 0.996148\ttraining's binary_logloss: 0.0981256\n",
      "[9933]\ttraining's auc: 0.99615\ttraining's binary_logloss: 0.0981148\n",
      "[9934]\ttraining's auc: 0.99615\ttraining's binary_logloss: 0.0981125\n",
      "[9935]\ttraining's auc: 0.996153\ttraining's binary_logloss: 0.0981031\n",
      "[9936]\ttraining's auc: 0.996154\ttraining's binary_logloss: 0.0980955\n",
      "[9937]\ttraining's auc: 0.996156\ttraining's binary_logloss: 0.0980852\n",
      "[9938]\ttraining's auc: 0.996157\ttraining's binary_logloss: 0.0980795\n",
      "[9939]\ttraining's auc: 0.996159\ttraining's binary_logloss: 0.0980707\n",
      "[9940]\ttraining's auc: 0.996159\ttraining's binary_logloss: 0.0980681\n",
      "[9941]\ttraining's auc: 0.996162\ttraining's binary_logloss: 0.0980583\n",
      "[9942]\ttraining's auc: 0.996165\ttraining's binary_logloss: 0.0980492\n",
      "[9943]\ttraining's auc: 0.996166\ttraining's binary_logloss: 0.0980415\n",
      "[9944]\ttraining's auc: 0.996169\ttraining's binary_logloss: 0.0980341\n",
      "[9945]\ttraining's auc: 0.99617\ttraining's binary_logloss: 0.0980248\n",
      "[9946]\ttraining's auc: 0.996171\ttraining's binary_logloss: 0.0980176\n",
      "[9947]\ttraining's auc: 0.996174\ttraining's binary_logloss: 0.0980088\n",
      "[9948]\ttraining's auc: 0.996176\ttraining's binary_logloss: 0.0980017\n",
      "[9949]\ttraining's auc: 0.996177\ttraining's binary_logloss: 0.0979936\n",
      "[9950]\ttraining's auc: 0.996179\ttraining's binary_logloss: 0.0979852\n",
      "[9951]\ttraining's auc: 0.996182\ttraining's binary_logloss: 0.0979768\n",
      "[9952]\ttraining's auc: 0.996183\ttraining's binary_logloss: 0.0979713\n",
      "[9953]\ttraining's auc: 0.996185\ttraining's binary_logloss: 0.0979611\n",
      "[9954]\ttraining's auc: 0.996185\ttraining's binary_logloss: 0.0979563\n",
      "[9955]\ttraining's auc: 0.996187\ttraining's binary_logloss: 0.0979517\n",
      "[9956]\ttraining's auc: 0.996189\ttraining's binary_logloss: 0.0979434\n",
      "[9957]\ttraining's auc: 0.996192\ttraining's binary_logloss: 0.0979325\n",
      "[9958]\ttraining's auc: 0.996193\ttraining's binary_logloss: 0.0979232\n",
      "[9959]\ttraining's auc: 0.996195\ttraining's binary_logloss: 0.0979169\n",
      "[9960]\ttraining's auc: 0.996197\ttraining's binary_logloss: 0.0979098\n",
      "[9961]\ttraining's auc: 0.9962\ttraining's binary_logloss: 0.0979011\n",
      "[9962]\ttraining's auc: 0.996203\ttraining's binary_logloss: 0.0978918\n",
      "[9963]\ttraining's auc: 0.996204\ttraining's binary_logloss: 0.0978841\n",
      "[9964]\ttraining's auc: 0.996205\ttraining's binary_logloss: 0.0978767\n",
      "[9965]\ttraining's auc: 0.996207\ttraining's binary_logloss: 0.0978682\n",
      "[9966]\ttraining's auc: 0.996207\ttraining's binary_logloss: 0.0978674\n",
      "[9967]\ttraining's auc: 0.996209\ttraining's binary_logloss: 0.0978588\n",
      "[9968]\ttraining's auc: 0.996211\ttraining's binary_logloss: 0.0978486\n",
      "[9969]\ttraining's auc: 0.996212\ttraining's binary_logloss: 0.097843\n",
      "[9970]\ttraining's auc: 0.996213\ttraining's binary_logloss: 0.0978387\n",
      "[9971]\ttraining's auc: 0.996215\ttraining's binary_logloss: 0.0978297\n",
      "[9972]\ttraining's auc: 0.996215\ttraining's binary_logloss: 0.097822\n",
      "[9973]\ttraining's auc: 0.996216\ttraining's binary_logloss: 0.0978182\n",
      "[9974]\ttraining's auc: 0.996217\ttraining's binary_logloss: 0.0978138\n",
      "[9975]\ttraining's auc: 0.996219\ttraining's binary_logloss: 0.0978047\n",
      "[9976]\ttraining's auc: 0.996223\ttraining's binary_logloss: 0.0977945\n",
      "[9977]\ttraining's auc: 0.996224\ttraining's binary_logloss: 0.0977917\n",
      "[9978]\ttraining's auc: 0.996226\ttraining's binary_logloss: 0.0977836\n",
      "[9979]\ttraining's auc: 0.996227\ttraining's binary_logloss: 0.0977789\n",
      "[9980]\ttraining's auc: 0.99623\ttraining's binary_logloss: 0.0977694\n",
      "[9981]\ttraining's auc: 0.996231\ttraining's binary_logloss: 0.0977602\n",
      "[9982]\ttraining's auc: 0.996233\ttraining's binary_logloss: 0.0977509\n",
      "[9983]\ttraining's auc: 0.996234\ttraining's binary_logloss: 0.0977449\n",
      "[9984]\ttraining's auc: 0.996234\ttraining's binary_logloss: 0.097742\n",
      "[9985]\ttraining's auc: 0.996235\ttraining's binary_logloss: 0.0977377\n",
      "[9986]\ttraining's auc: 0.996236\ttraining's binary_logloss: 0.0977337\n",
      "[9987]\ttraining's auc: 0.996237\ttraining's binary_logloss: 0.0977252\n",
      "[9988]\ttraining's auc: 0.996239\ttraining's binary_logloss: 0.0977164\n",
      "[9989]\ttraining's auc: 0.996241\ttraining's binary_logloss: 0.0977084\n",
      "[9990]\ttraining's auc: 0.996242\ttraining's binary_logloss: 0.0977026\n",
      "[9991]\ttraining's auc: 0.996242\ttraining's binary_logloss: 0.0976985\n",
      "[9992]\ttraining's auc: 0.996244\ttraining's binary_logloss: 0.0976902\n",
      "[9993]\ttraining's auc: 0.996244\ttraining's binary_logloss: 0.0976891\n",
      "[9994]\ttraining's auc: 0.996245\ttraining's binary_logloss: 0.0976876\n",
      "[9995]\ttraining's auc: 0.996246\ttraining's binary_logloss: 0.0976803\n",
      "[9996]\ttraining's auc: 0.996246\ttraining's binary_logloss: 0.0976713\n",
      "[9997]\ttraining's auc: 0.996247\ttraining's binary_logloss: 0.0976696\n",
      "[9998]\ttraining's auc: 0.996248\ttraining's binary_logloss: 0.0976654\n",
      "[9999]\ttraining's auc: 0.996249\ttraining's binary_logloss: 0.0976587\n",
      "[10000]\ttraining's auc: 0.99625\ttraining's binary_logloss: 0.0976499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    nthread=4,\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=34,\n",
    "    colsample_bytree=0.9497036,\n",
    "    subsample=0.8715623,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.041545473,\n",
    "    reg_lambda=0.0735294,\n",
    "    min_split_gain=0.0222415,\n",
    "    min_child_weight=39.3259775,\n",
    "    silent=-1,)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric='auc')\n",
    "proba_preds= clf.predict_proba(X_hide_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b49bcca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculez la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_hide_test, proba_preds[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Tracez la courbe ROC\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53f96c",
   "metadata": {},
   "source": [
    "# Score F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a445a8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n",
      "[1]\ttraining's binary_logloss: 0.279387\n",
      "[2]\ttraining's binary_logloss: 0.278305\n",
      "[3]\ttraining's binary_logloss: 0.27728\n",
      "[4]\ttraining's binary_logloss: 0.276315\n",
      "[5]\ttraining's binary_logloss: 0.275401\n",
      "[6]\ttraining's binary_logloss: 0.274538\n",
      "[7]\ttraining's binary_logloss: 0.273717\n",
      "[8]\ttraining's binary_logloss: 0.272926\n",
      "[9]\ttraining's binary_logloss: 0.272165\n",
      "[10]\ttraining's binary_logloss: 0.271441\n",
      "[11]\ttraining's binary_logloss: 0.270741\n",
      "[12]\ttraining's binary_logloss: 0.270064\n",
      "[13]\ttraining's binary_logloss: 0.269498\n",
      "[14]\ttraining's binary_logloss: 0.268954\n",
      "[15]\ttraining's binary_logloss: 0.26835\n",
      "[16]\ttraining's binary_logloss: 0.267775\n",
      "[17]\ttraining's binary_logloss: 0.267206\n",
      "[18]\ttraining's binary_logloss: 0.266663\n",
      "[19]\ttraining's binary_logloss: 0.266135\n",
      "[20]\ttraining's binary_logloss: 0.265636\n",
      "[21]\ttraining's binary_logloss: 0.26517\n",
      "[22]\ttraining's binary_logloss: 0.264695\n",
      "[23]\ttraining's binary_logloss: 0.26424\n",
      "[24]\ttraining's binary_logloss: 0.263785\n",
      "[25]\ttraining's binary_logloss: 0.263357\n",
      "[26]\ttraining's binary_logloss: 0.262958\n",
      "[27]\ttraining's binary_logloss: 0.262547\n",
      "[28]\ttraining's binary_logloss: 0.262154\n",
      "[29]\ttraining's binary_logloss: 0.261769\n",
      "[30]\ttraining's binary_logloss: 0.261396\n",
      "[31]\ttraining's binary_logloss: 0.26103\n",
      "[32]\ttraining's binary_logloss: 0.260682\n",
      "[33]\ttraining's binary_logloss: 0.260342\n",
      "[34]\ttraining's binary_logloss: 0.260013\n",
      "[35]\ttraining's binary_logloss: 0.25969\n",
      "[36]\ttraining's binary_logloss: 0.25936\n",
      "[37]\ttraining's binary_logloss: 0.259036\n",
      "[38]\ttraining's binary_logloss: 0.258725\n",
      "[39]\ttraining's binary_logloss: 0.258437\n",
      "[40]\ttraining's binary_logloss: 0.258126\n",
      "[41]\ttraining's binary_logloss: 0.257822\n",
      "[42]\ttraining's binary_logloss: 0.257523\n",
      "[43]\ttraining's binary_logloss: 0.257236\n",
      "[44]\ttraining's binary_logloss: 0.256947\n",
      "[45]\ttraining's binary_logloss: 0.256677\n",
      "[46]\ttraining's binary_logloss: 0.256399\n",
      "[47]\ttraining's binary_logloss: 0.256142\n",
      "[48]\ttraining's binary_logloss: 0.255886\n",
      "[49]\ttraining's binary_logloss: 0.255643\n",
      "[50]\ttraining's binary_logloss: 0.255409\n",
      "[51]\ttraining's binary_logloss: 0.255151\n",
      "[52]\ttraining's binary_logloss: 0.254915\n",
      "[53]\ttraining's binary_logloss: 0.254687\n",
      "[54]\ttraining's binary_logloss: 0.254449\n",
      "[55]\ttraining's binary_logloss: 0.254238\n",
      "[56]\ttraining's binary_logloss: 0.254034\n",
      "[57]\ttraining's binary_logloss: 0.253791\n",
      "[58]\ttraining's binary_logloss: 0.253585\n",
      "[59]\ttraining's binary_logloss: 0.253377\n",
      "[60]\ttraining's binary_logloss: 0.253166\n",
      "[61]\ttraining's binary_logloss: 0.252965\n",
      "[62]\ttraining's binary_logloss: 0.252765\n",
      "[63]\ttraining's binary_logloss: 0.252565\n",
      "[64]\ttraining's binary_logloss: 0.252375\n",
      "[65]\ttraining's binary_logloss: 0.252183\n",
      "[66]\ttraining's binary_logloss: 0.251984\n",
      "[67]\ttraining's binary_logloss: 0.251797\n",
      "[68]\ttraining's binary_logloss: 0.251618\n",
      "[69]\ttraining's binary_logloss: 0.251421\n",
      "[70]\ttraining's binary_logloss: 0.251244\n",
      "[71]\ttraining's binary_logloss: 0.251055\n",
      "[72]\ttraining's binary_logloss: 0.250852\n",
      "[73]\ttraining's binary_logloss: 0.250657\n",
      "[74]\ttraining's binary_logloss: 0.250488\n",
      "[75]\ttraining's binary_logloss: 0.250304\n",
      "[76]\ttraining's binary_logloss: 0.250144\n",
      "[77]\ttraining's binary_logloss: 0.249981\n",
      "[78]\ttraining's binary_logloss: 0.249825\n",
      "[79]\ttraining's binary_logloss: 0.24966\n",
      "[80]\ttraining's binary_logloss: 0.249499\n",
      "[81]\ttraining's binary_logloss: 0.249341\n",
      "[82]\ttraining's binary_logloss: 0.249188\n",
      "[83]\ttraining's binary_logloss: 0.249033\n",
      "[84]\ttraining's binary_logloss: 0.24888\n",
      "[85]\ttraining's binary_logloss: 0.248735\n",
      "[86]\ttraining's binary_logloss: 0.248598\n",
      "[87]\ttraining's binary_logloss: 0.248432\n",
      "[88]\ttraining's binary_logloss: 0.248286\n",
      "[89]\ttraining's binary_logloss: 0.248133\n",
      "[90]\ttraining's binary_logloss: 0.248001\n",
      "[91]\ttraining's binary_logloss: 0.247833\n",
      "[92]\ttraining's binary_logloss: 0.247689\n",
      "[93]\ttraining's binary_logloss: 0.247557\n",
      "[94]\ttraining's binary_logloss: 0.247414\n",
      "[95]\ttraining's binary_logloss: 0.247265\n",
      "[96]\ttraining's binary_logloss: 0.247128\n",
      "[97]\ttraining's binary_logloss: 0.246992\n",
      "[98]\ttraining's binary_logloss: 0.246842\n",
      "[99]\ttraining's binary_logloss: 0.246716\n",
      "[100]\ttraining's binary_logloss: 0.246561\n",
      "[101]\ttraining's binary_logloss: 0.246428\n",
      "[102]\ttraining's binary_logloss: 0.246293\n",
      "[103]\ttraining's binary_logloss: 0.246175\n",
      "[104]\ttraining's binary_logloss: 0.246056\n",
      "[105]\ttraining's binary_logloss: 0.245933\n",
      "[106]\ttraining's binary_logloss: 0.245803\n",
      "[107]\ttraining's binary_logloss: 0.245669\n",
      "[108]\ttraining's binary_logloss: 0.245553\n",
      "[109]\ttraining's binary_logloss: 0.245438\n",
      "[110]\ttraining's binary_logloss: 0.245324\n",
      "[111]\ttraining's binary_logloss: 0.245211\n",
      "[112]\ttraining's binary_logloss: 0.245105\n",
      "[113]\ttraining's binary_logloss: 0.244985\n",
      "[114]\ttraining's binary_logloss: 0.244869\n",
      "[115]\ttraining's binary_logloss: 0.244768\n",
      "[116]\ttraining's binary_logloss: 0.244665\n",
      "[117]\ttraining's binary_logloss: 0.244555\n",
      "[118]\ttraining's binary_logloss: 0.244444\n",
      "[119]\ttraining's binary_logloss: 0.244336\n",
      "[120]\ttraining's binary_logloss: 0.244224\n",
      "[121]\ttraining's binary_logloss: 0.244117\n",
      "[122]\ttraining's binary_logloss: 0.244014\n",
      "[123]\ttraining's binary_logloss: 0.243915\n",
      "[124]\ttraining's binary_logloss: 0.24381\n",
      "[125]\ttraining's binary_logloss: 0.243686\n",
      "[126]\ttraining's binary_logloss: 0.243585\n",
      "[127]\ttraining's binary_logloss: 0.243486\n",
      "[128]\ttraining's binary_logloss: 0.243389\n",
      "[129]\ttraining's binary_logloss: 0.243293\n",
      "[130]\ttraining's binary_logloss: 0.243177\n",
      "[131]\ttraining's binary_logloss: 0.243083\n",
      "[132]\ttraining's binary_logloss: 0.24299\n",
      "[133]\ttraining's binary_logloss: 0.24289\n",
      "[134]\ttraining's binary_logloss: 0.242795\n",
      "[135]\ttraining's binary_logloss: 0.242705\n",
      "[136]\ttraining's binary_logloss: 0.242601\n",
      "[137]\ttraining's binary_logloss: 0.242506\n",
      "[138]\ttraining's binary_logloss: 0.2424\n",
      "[139]\ttraining's binary_logloss: 0.242303\n",
      "[140]\ttraining's binary_logloss: 0.242207\n",
      "[141]\ttraining's binary_logloss: 0.242119\n",
      "[142]\ttraining's binary_logloss: 0.242018\n",
      "[143]\ttraining's binary_logloss: 0.241925\n",
      "[144]\ttraining's binary_logloss: 0.241845\n",
      "[145]\ttraining's binary_logloss: 0.241749\n",
      "[146]\ttraining's binary_logloss: 0.241653\n",
      "[147]\ttraining's binary_logloss: 0.241567\n",
      "[148]\ttraining's binary_logloss: 0.241476\n",
      "[149]\ttraining's binary_logloss: 0.241395\n",
      "[150]\ttraining's binary_logloss: 0.24131\n",
      "[151]\ttraining's binary_logloss: 0.241238\n",
      "[152]\ttraining's binary_logloss: 0.241143\n",
      "[153]\ttraining's binary_logloss: 0.241067\n",
      "[154]\ttraining's binary_logloss: 0.240981\n",
      "[155]\ttraining's binary_logloss: 0.240891\n",
      "[156]\ttraining's binary_logloss: 0.240807\n",
      "[157]\ttraining's binary_logloss: 0.240732\n",
      "[158]\ttraining's binary_logloss: 0.240654\n",
      "[159]\ttraining's binary_logloss: 0.24057\n",
      "[160]\ttraining's binary_logloss: 0.240487\n",
      "[161]\ttraining's binary_logloss: 0.240407\n",
      "[162]\ttraining's binary_logloss: 0.24033\n",
      "[163]\ttraining's binary_logloss: 0.240256\n",
      "[164]\ttraining's binary_logloss: 0.240175\n",
      "[165]\ttraining's binary_logloss: 0.240104\n",
      "[166]\ttraining's binary_logloss: 0.240026\n",
      "[167]\ttraining's binary_logloss: 0.239951\n",
      "[168]\ttraining's binary_logloss: 0.239884\n",
      "[169]\ttraining's binary_logloss: 0.239809\n",
      "[170]\ttraining's binary_logloss: 0.239728\n",
      "[171]\ttraining's binary_logloss: 0.239658\n",
      "[172]\ttraining's binary_logloss: 0.239582\n",
      "[173]\ttraining's binary_logloss: 0.239515\n",
      "[174]\ttraining's binary_logloss: 0.239442\n",
      "[175]\ttraining's binary_logloss: 0.23937\n",
      "[176]\ttraining's binary_logloss: 0.2393\n",
      "[177]\ttraining's binary_logloss: 0.239229\n",
      "[178]\ttraining's binary_logloss: 0.239152\n",
      "[179]\ttraining's binary_logloss: 0.239082\n",
      "[180]\ttraining's binary_logloss: 0.239013\n",
      "[181]\ttraining's binary_logloss: 0.238942\n",
      "[182]\ttraining's binary_logloss: 0.238868\n",
      "[183]\ttraining's binary_logloss: 0.238801\n",
      "[184]\ttraining's binary_logloss: 0.238737\n",
      "[185]\ttraining's binary_logloss: 0.238673\n",
      "[186]\ttraining's binary_logloss: 0.238603\n",
      "[187]\ttraining's binary_logloss: 0.238539\n",
      "[188]\ttraining's binary_logloss: 0.238471\n",
      "[189]\ttraining's binary_logloss: 0.238407\n",
      "[190]\ttraining's binary_logloss: 0.238344\n",
      "[191]\ttraining's binary_logloss: 0.238285\n",
      "[192]\ttraining's binary_logloss: 0.238222\n",
      "[193]\ttraining's binary_logloss: 0.23816\n",
      "[194]\ttraining's binary_logloss: 0.238094\n",
      "[195]\ttraining's binary_logloss: 0.238029\n",
      "[196]\ttraining's binary_logloss: 0.237964\n",
      "[197]\ttraining's binary_logloss: 0.237904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198]\ttraining's binary_logloss: 0.237844\n",
      "[199]\ttraining's binary_logloss: 0.237778\n",
      "[200]\ttraining's binary_logloss: 0.237709\n",
      "[201]\ttraining's binary_logloss: 0.23765\n",
      "[202]\ttraining's binary_logloss: 0.237586\n",
      "[203]\ttraining's binary_logloss: 0.237533\n",
      "[204]\ttraining's binary_logloss: 0.237471\n",
      "[205]\ttraining's binary_logloss: 0.237413\n",
      "[206]\ttraining's binary_logloss: 0.237354\n",
      "[207]\ttraining's binary_logloss: 0.237292\n",
      "[208]\ttraining's binary_logloss: 0.23723\n",
      "[209]\ttraining's binary_logloss: 0.23717\n",
      "[210]\ttraining's binary_logloss: 0.237113\n",
      "[211]\ttraining's binary_logloss: 0.237058\n",
      "[212]\ttraining's binary_logloss: 0.236999\n",
      "[213]\ttraining's binary_logloss: 0.236935\n",
      "[214]\ttraining's binary_logloss: 0.236879\n",
      "[215]\ttraining's binary_logloss: 0.236816\n",
      "[216]\ttraining's binary_logloss: 0.23675\n",
      "[217]\ttraining's binary_logloss: 0.236696\n",
      "[218]\ttraining's binary_logloss: 0.236644\n",
      "[219]\ttraining's binary_logloss: 0.236583\n",
      "[220]\ttraining's binary_logloss: 0.236529\n",
      "[221]\ttraining's binary_logloss: 0.236463\n",
      "[222]\ttraining's binary_logloss: 0.236404\n",
      "[223]\ttraining's binary_logloss: 0.236354\n",
      "[224]\ttraining's binary_logloss: 0.236292\n",
      "[225]\ttraining's binary_logloss: 0.236233\n",
      "[226]\ttraining's binary_logloss: 0.236177\n",
      "[227]\ttraining's binary_logloss: 0.236121\n",
      "[228]\ttraining's binary_logloss: 0.236065\n",
      "[229]\ttraining's binary_logloss: 0.236005\n",
      "[230]\ttraining's binary_logloss: 0.235955\n",
      "[231]\ttraining's binary_logloss: 0.235907\n",
      "[232]\ttraining's binary_logloss: 0.23585\n",
      "[233]\ttraining's binary_logloss: 0.235796\n",
      "[234]\ttraining's binary_logloss: 0.235751\n",
      "[235]\ttraining's binary_logloss: 0.235697\n",
      "[236]\ttraining's binary_logloss: 0.235644\n",
      "[237]\ttraining's binary_logloss: 0.23559\n",
      "[238]\ttraining's binary_logloss: 0.235537\n",
      "[239]\ttraining's binary_logloss: 0.235485\n",
      "[240]\ttraining's binary_logloss: 0.235437\n",
      "[241]\ttraining's binary_logloss: 0.235386\n",
      "[242]\ttraining's binary_logloss: 0.235331\n",
      "[243]\ttraining's binary_logloss: 0.235281\n",
      "[244]\ttraining's binary_logloss: 0.235231\n",
      "[245]\ttraining's binary_logloss: 0.235183\n",
      "[246]\ttraining's binary_logloss: 0.23513\n",
      "[247]\ttraining's binary_logloss: 0.235077\n",
      "[248]\ttraining's binary_logloss: 0.235019\n",
      "[249]\ttraining's binary_logloss: 0.234969\n",
      "[250]\ttraining's binary_logloss: 0.23492\n",
      "[251]\ttraining's binary_logloss: 0.234869\n",
      "[252]\ttraining's binary_logloss: 0.234823\n",
      "[253]\ttraining's binary_logloss: 0.234773\n",
      "[254]\ttraining's binary_logloss: 0.23473\n",
      "[255]\ttraining's binary_logloss: 0.234675\n",
      "[256]\ttraining's binary_logloss: 0.234626\n",
      "[257]\ttraining's binary_logloss: 0.234583\n",
      "[258]\ttraining's binary_logloss: 0.234529\n",
      "[259]\ttraining's binary_logloss: 0.234477\n",
      "[260]\ttraining's binary_logloss: 0.234432\n",
      "[261]\ttraining's binary_logloss: 0.234388\n",
      "[262]\ttraining's binary_logloss: 0.234336\n",
      "[263]\ttraining's binary_logloss: 0.234287\n",
      "[264]\ttraining's binary_logloss: 0.234242\n",
      "[265]\ttraining's binary_logloss: 0.23419\n",
      "[266]\ttraining's binary_logloss: 0.234145\n",
      "[267]\ttraining's binary_logloss: 0.234102\n",
      "[268]\ttraining's binary_logloss: 0.234047\n",
      "[269]\ttraining's binary_logloss: 0.233999\n",
      "[270]\ttraining's binary_logloss: 0.233943\n",
      "[271]\ttraining's binary_logloss: 0.233894\n",
      "[272]\ttraining's binary_logloss: 0.233843\n",
      "[273]\ttraining's binary_logloss: 0.233801\n",
      "[274]\ttraining's binary_logloss: 0.233747\n",
      "[275]\ttraining's binary_logloss: 0.233701\n",
      "[276]\ttraining's binary_logloss: 0.233652\n",
      "[277]\ttraining's binary_logloss: 0.233605\n",
      "[278]\ttraining's binary_logloss: 0.233559\n",
      "[279]\ttraining's binary_logloss: 0.233512\n",
      "[280]\ttraining's binary_logloss: 0.233459\n",
      "[281]\ttraining's binary_logloss: 0.233412\n",
      "[282]\ttraining's binary_logloss: 0.233366\n",
      "[283]\ttraining's binary_logloss: 0.233328\n",
      "[284]\ttraining's binary_logloss: 0.233279\n",
      "[285]\ttraining's binary_logloss: 0.233237\n",
      "[286]\ttraining's binary_logloss: 0.233193\n",
      "[287]\ttraining's binary_logloss: 0.233149\n",
      "[288]\ttraining's binary_logloss: 0.23309\n",
      "[289]\ttraining's binary_logloss: 0.233042\n",
      "[290]\ttraining's binary_logloss: 0.232995\n",
      "[291]\ttraining's binary_logloss: 0.232946\n",
      "[292]\ttraining's binary_logloss: 0.232906\n",
      "[293]\ttraining's binary_logloss: 0.232863\n",
      "[294]\ttraining's binary_logloss: 0.232823\n",
      "[295]\ttraining's binary_logloss: 0.232775\n",
      "[296]\ttraining's binary_logloss: 0.23274\n",
      "[297]\ttraining's binary_logloss: 0.2327\n",
      "[298]\ttraining's binary_logloss: 0.232655\n",
      "[299]\ttraining's binary_logloss: 0.232611\n",
      "[300]\ttraining's binary_logloss: 0.23257\n",
      "[301]\ttraining's binary_logloss: 0.232517\n",
      "[302]\ttraining's binary_logloss: 0.232469\n",
      "[303]\ttraining's binary_logloss: 0.232434\n",
      "[304]\ttraining's binary_logloss: 0.232392\n",
      "[305]\ttraining's binary_logloss: 0.232337\n",
      "[306]\ttraining's binary_logloss: 0.232295\n",
      "[307]\ttraining's binary_logloss: 0.232248\n",
      "[308]\ttraining's binary_logloss: 0.232202\n",
      "[309]\ttraining's binary_logloss: 0.232164\n",
      "[310]\ttraining's binary_logloss: 0.232123\n",
      "[311]\ttraining's binary_logloss: 0.232078\n",
      "[312]\ttraining's binary_logloss: 0.232037\n",
      "[313]\ttraining's binary_logloss: 0.231992\n",
      "[314]\ttraining's binary_logloss: 0.231956\n",
      "[315]\ttraining's binary_logloss: 0.231919\n",
      "[316]\ttraining's binary_logloss: 0.231876\n",
      "[317]\ttraining's binary_logloss: 0.231836\n",
      "[318]\ttraining's binary_logloss: 0.231793\n",
      "[319]\ttraining's binary_logloss: 0.231751\n",
      "[320]\ttraining's binary_logloss: 0.231713\n",
      "[321]\ttraining's binary_logloss: 0.231663\n",
      "[322]\ttraining's binary_logloss: 0.231624\n",
      "[323]\ttraining's binary_logloss: 0.231586\n",
      "[324]\ttraining's binary_logloss: 0.231544\n",
      "[325]\ttraining's binary_logloss: 0.231502\n",
      "[326]\ttraining's binary_logloss: 0.231459\n",
      "[327]\ttraining's binary_logloss: 0.23142\n",
      "[328]\ttraining's binary_logloss: 0.231383\n",
      "[329]\ttraining's binary_logloss: 0.231342\n",
      "[330]\ttraining's binary_logloss: 0.2313\n",
      "[331]\ttraining's binary_logloss: 0.231261\n",
      "[332]\ttraining's binary_logloss: 0.23122\n",
      "[333]\ttraining's binary_logloss: 0.231176\n",
      "[334]\ttraining's binary_logloss: 0.231135\n",
      "[335]\ttraining's binary_logloss: 0.231099\n",
      "[336]\ttraining's binary_logloss: 0.231062\n",
      "[337]\ttraining's binary_logloss: 0.231026\n",
      "[338]\ttraining's binary_logloss: 0.230988\n",
      "[339]\ttraining's binary_logloss: 0.230949\n",
      "[340]\ttraining's binary_logloss: 0.230911\n",
      "[341]\ttraining's binary_logloss: 0.23087\n",
      "[342]\ttraining's binary_logloss: 0.230834\n",
      "[343]\ttraining's binary_logloss: 0.230799\n",
      "[344]\ttraining's binary_logloss: 0.23076\n",
      "[345]\ttraining's binary_logloss: 0.230712\n",
      "[346]\ttraining's binary_logloss: 0.230677\n",
      "[347]\ttraining's binary_logloss: 0.230636\n",
      "[348]\ttraining's binary_logloss: 0.230595\n",
      "[349]\ttraining's binary_logloss: 0.230552\n",
      "[350]\ttraining's binary_logloss: 0.230516\n",
      "[351]\ttraining's binary_logloss: 0.230476\n",
      "[352]\ttraining's binary_logloss: 0.230432\n",
      "[353]\ttraining's binary_logloss: 0.230397\n",
      "[354]\ttraining's binary_logloss: 0.230366\n",
      "[355]\ttraining's binary_logloss: 0.230332\n",
      "[356]\ttraining's binary_logloss: 0.230291\n",
      "[357]\ttraining's binary_logloss: 0.230251\n",
      "[358]\ttraining's binary_logloss: 0.230213\n",
      "[359]\ttraining's binary_logloss: 0.230175\n",
      "[360]\ttraining's binary_logloss: 0.230142\n",
      "[361]\ttraining's binary_logloss: 0.230102\n",
      "[362]\ttraining's binary_logloss: 0.230062\n",
      "[363]\ttraining's binary_logloss: 0.230023\n",
      "[364]\ttraining's binary_logloss: 0.229982\n",
      "[365]\ttraining's binary_logloss: 0.229945\n",
      "[366]\ttraining's binary_logloss: 0.229904\n",
      "[367]\ttraining's binary_logloss: 0.229859\n",
      "[368]\ttraining's binary_logloss: 0.229813\n",
      "[369]\ttraining's binary_logloss: 0.229773\n",
      "[370]\ttraining's binary_logloss: 0.229737\n",
      "[371]\ttraining's binary_logloss: 0.229699\n",
      "[372]\ttraining's binary_logloss: 0.229657\n",
      "[373]\ttraining's binary_logloss: 0.22962\n",
      "[374]\ttraining's binary_logloss: 0.229584\n",
      "[375]\ttraining's binary_logloss: 0.229546\n",
      "[376]\ttraining's binary_logloss: 0.229514\n",
      "[377]\ttraining's binary_logloss: 0.22948\n",
      "[378]\ttraining's binary_logloss: 0.229436\n",
      "[379]\ttraining's binary_logloss: 0.229389\n",
      "[380]\ttraining's binary_logloss: 0.229348\n",
      "[381]\ttraining's binary_logloss: 0.229311\n",
      "[382]\ttraining's binary_logloss: 0.229274\n",
      "[383]\ttraining's binary_logloss: 0.22925\n",
      "[384]\ttraining's binary_logloss: 0.229209\n",
      "[385]\ttraining's binary_logloss: 0.229172\n",
      "[386]\ttraining's binary_logloss: 0.229138\n",
      "[387]\ttraining's binary_logloss: 0.229112\n",
      "[388]\ttraining's binary_logloss: 0.22908\n",
      "[389]\ttraining's binary_logloss: 0.229055\n",
      "[390]\ttraining's binary_logloss: 0.229016\n",
      "[391]\ttraining's binary_logloss: 0.228978\n",
      "[392]\ttraining's binary_logloss: 0.228937\n",
      "[393]\ttraining's binary_logloss: 0.228903\n",
      "[394]\ttraining's binary_logloss: 0.228865\n",
      "[395]\ttraining's binary_logloss: 0.228829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.228798\n",
      "[397]\ttraining's binary_logloss: 0.228758\n",
      "[398]\ttraining's binary_logloss: 0.228724\n",
      "[399]\ttraining's binary_logloss: 0.228692\n",
      "[400]\ttraining's binary_logloss: 0.228656\n",
      "[401]\ttraining's binary_logloss: 0.228612\n",
      "[402]\ttraining's binary_logloss: 0.228578\n",
      "[403]\ttraining's binary_logloss: 0.228543\n",
      "[404]\ttraining's binary_logloss: 0.228507\n",
      "[405]\ttraining's binary_logloss: 0.228477\n",
      "[406]\ttraining's binary_logloss: 0.228433\n",
      "[407]\ttraining's binary_logloss: 0.228401\n",
      "[408]\ttraining's binary_logloss: 0.228368\n",
      "[409]\ttraining's binary_logloss: 0.228323\n",
      "[410]\ttraining's binary_logloss: 0.228289\n",
      "[411]\ttraining's binary_logloss: 0.228255\n",
      "[412]\ttraining's binary_logloss: 0.228226\n",
      "[413]\ttraining's binary_logloss: 0.228192\n",
      "[414]\ttraining's binary_logloss: 0.228158\n",
      "[415]\ttraining's binary_logloss: 0.22812\n",
      "[416]\ttraining's binary_logloss: 0.228083\n",
      "[417]\ttraining's binary_logloss: 0.228046\n",
      "[418]\ttraining's binary_logloss: 0.228005\n",
      "[419]\ttraining's binary_logloss: 0.227972\n",
      "[420]\ttraining's binary_logloss: 0.227936\n",
      "[421]\ttraining's binary_logloss: 0.227901\n",
      "[422]\ttraining's binary_logloss: 0.22787\n",
      "[423]\ttraining's binary_logloss: 0.227838\n",
      "[424]\ttraining's binary_logloss: 0.227801\n",
      "[425]\ttraining's binary_logloss: 0.227766\n",
      "[426]\ttraining's binary_logloss: 0.227725\n",
      "[427]\ttraining's binary_logloss: 0.227691\n",
      "[428]\ttraining's binary_logloss: 0.227657\n",
      "[429]\ttraining's binary_logloss: 0.227627\n",
      "[430]\ttraining's binary_logloss: 0.227593\n",
      "[431]\ttraining's binary_logloss: 0.227564\n",
      "[432]\ttraining's binary_logloss: 0.227528\n",
      "[433]\ttraining's binary_logloss: 0.227492\n",
      "[434]\ttraining's binary_logloss: 0.227458\n",
      "[435]\ttraining's binary_logloss: 0.227435\n",
      "[436]\ttraining's binary_logloss: 0.227392\n",
      "[437]\ttraining's binary_logloss: 0.227356\n",
      "[438]\ttraining's binary_logloss: 0.227321\n",
      "[439]\ttraining's binary_logloss: 0.227284\n",
      "[440]\ttraining's binary_logloss: 0.227247\n",
      "[441]\ttraining's binary_logloss: 0.227213\n",
      "[442]\ttraining's binary_logloss: 0.227181\n",
      "[443]\ttraining's binary_logloss: 0.227153\n",
      "[444]\ttraining's binary_logloss: 0.227119\n",
      "[445]\ttraining's binary_logloss: 0.227084\n",
      "[446]\ttraining's binary_logloss: 0.227049\n",
      "[447]\ttraining's binary_logloss: 0.227019\n",
      "[448]\ttraining's binary_logloss: 0.226986\n",
      "[449]\ttraining's binary_logloss: 0.226954\n",
      "[450]\ttraining's binary_logloss: 0.226922\n",
      "[451]\ttraining's binary_logloss: 0.226886\n",
      "[452]\ttraining's binary_logloss: 0.226849\n",
      "[453]\ttraining's binary_logloss: 0.226818\n",
      "[454]\ttraining's binary_logloss: 0.226785\n",
      "[455]\ttraining's binary_logloss: 0.226746\n",
      "[456]\ttraining's binary_logloss: 0.226712\n",
      "[457]\ttraining's binary_logloss: 0.22668\n",
      "[458]\ttraining's binary_logloss: 0.22665\n",
      "[459]\ttraining's binary_logloss: 0.226618\n",
      "[460]\ttraining's binary_logloss: 0.226591\n",
      "[461]\ttraining's binary_logloss: 0.22655\n",
      "[462]\ttraining's binary_logloss: 0.226516\n",
      "[463]\ttraining's binary_logloss: 0.226488\n",
      "[464]\ttraining's binary_logloss: 0.22645\n",
      "[465]\ttraining's binary_logloss: 0.226417\n",
      "[466]\ttraining's binary_logloss: 0.22638\n",
      "[467]\ttraining's binary_logloss: 0.226346\n",
      "[468]\ttraining's binary_logloss: 0.22631\n",
      "[469]\ttraining's binary_logloss: 0.226276\n",
      "[470]\ttraining's binary_logloss: 0.226247\n",
      "[471]\ttraining's binary_logloss: 0.226213\n",
      "[472]\ttraining's binary_logloss: 0.226179\n",
      "[473]\ttraining's binary_logloss: 0.226145\n",
      "[474]\ttraining's binary_logloss: 0.226111\n",
      "[475]\ttraining's binary_logloss: 0.226076\n",
      "[476]\ttraining's binary_logloss: 0.226042\n",
      "[477]\ttraining's binary_logloss: 0.22602\n",
      "[478]\ttraining's binary_logloss: 0.225991\n",
      "[479]\ttraining's binary_logloss: 0.225958\n",
      "[480]\ttraining's binary_logloss: 0.225925\n",
      "[481]\ttraining's binary_logloss: 0.22589\n",
      "[482]\ttraining's binary_logloss: 0.225856\n",
      "[483]\ttraining's binary_logloss: 0.225819\n",
      "[484]\ttraining's binary_logloss: 0.225786\n",
      "[485]\ttraining's binary_logloss: 0.225755\n",
      "[486]\ttraining's binary_logloss: 0.225725\n",
      "[487]\ttraining's binary_logloss: 0.225695\n",
      "[488]\ttraining's binary_logloss: 0.225664\n",
      "[489]\ttraining's binary_logloss: 0.225624\n",
      "[490]\ttraining's binary_logloss: 0.22561\n",
      "[491]\ttraining's binary_logloss: 0.225587\n",
      "[492]\ttraining's binary_logloss: 0.225554\n",
      "[493]\ttraining's binary_logloss: 0.22552\n",
      "[494]\ttraining's binary_logloss: 0.225483\n",
      "[495]\ttraining's binary_logloss: 0.22545\n",
      "[496]\ttraining's binary_logloss: 0.225415\n",
      "[497]\ttraining's binary_logloss: 0.22538\n",
      "[498]\ttraining's binary_logloss: 0.225347\n",
      "[499]\ttraining's binary_logloss: 0.225316\n",
      "[500]\ttraining's binary_logloss: 0.225287\n",
      "[501]\ttraining's binary_logloss: 0.225273\n",
      "[502]\ttraining's binary_logloss: 0.225241\n",
      "[503]\ttraining's binary_logloss: 0.225211\n",
      "[504]\ttraining's binary_logloss: 0.225177\n",
      "[505]\ttraining's binary_logloss: 0.225146\n",
      "[506]\ttraining's binary_logloss: 0.225108\n",
      "[507]\ttraining's binary_logloss: 0.225069\n",
      "[508]\ttraining's binary_logloss: 0.225044\n",
      "[509]\ttraining's binary_logloss: 0.225011\n",
      "[510]\ttraining's binary_logloss: 0.224977\n",
      "[511]\ttraining's binary_logloss: 0.224946\n",
      "[512]\ttraining's binary_logloss: 0.224914\n",
      "[513]\ttraining's binary_logloss: 0.224887\n",
      "[514]\ttraining's binary_logloss: 0.224863\n",
      "[515]\ttraining's binary_logloss: 0.224836\n",
      "[516]\ttraining's binary_logloss: 0.224806\n",
      "[517]\ttraining's binary_logloss: 0.224776\n",
      "[518]\ttraining's binary_logloss: 0.224745\n",
      "[519]\ttraining's binary_logloss: 0.224707\n",
      "[520]\ttraining's binary_logloss: 0.224676\n",
      "[521]\ttraining's binary_logloss: 0.224646\n",
      "[522]\ttraining's binary_logloss: 0.224612\n",
      "[523]\ttraining's binary_logloss: 0.22459\n",
      "[524]\ttraining's binary_logloss: 0.224557\n",
      "[525]\ttraining's binary_logloss: 0.224536\n",
      "[526]\ttraining's binary_logloss: 0.224503\n",
      "[527]\ttraining's binary_logloss: 0.224474\n",
      "[528]\ttraining's binary_logloss: 0.224448\n",
      "[529]\ttraining's binary_logloss: 0.224417\n",
      "[530]\ttraining's binary_logloss: 0.224396\n",
      "[531]\ttraining's binary_logloss: 0.224368\n",
      "[532]\ttraining's binary_logloss: 0.224344\n",
      "[533]\ttraining's binary_logloss: 0.224311\n",
      "[534]\ttraining's binary_logloss: 0.224283\n",
      "[535]\ttraining's binary_logloss: 0.224257\n",
      "[536]\ttraining's binary_logloss: 0.22423\n",
      "[537]\ttraining's binary_logloss: 0.224211\n",
      "[538]\ttraining's binary_logloss: 0.224189\n",
      "[539]\ttraining's binary_logloss: 0.224159\n",
      "[540]\ttraining's binary_logloss: 0.22413\n",
      "[541]\ttraining's binary_logloss: 0.224099\n",
      "[542]\ttraining's binary_logloss: 0.224082\n",
      "[543]\ttraining's binary_logloss: 0.224052\n",
      "[544]\ttraining's binary_logloss: 0.224018\n",
      "[545]\ttraining's binary_logloss: 0.22399\n",
      "[546]\ttraining's binary_logloss: 0.223959\n",
      "[547]\ttraining's binary_logloss: 0.223925\n",
      "[548]\ttraining's binary_logloss: 0.22389\n",
      "[549]\ttraining's binary_logloss: 0.223864\n",
      "[550]\ttraining's binary_logloss: 0.223833\n",
      "[551]\ttraining's binary_logloss: 0.223804\n",
      "[552]\ttraining's binary_logloss: 0.223775\n",
      "[553]\ttraining's binary_logloss: 0.223746\n",
      "[554]\ttraining's binary_logloss: 0.223716\n",
      "[555]\ttraining's binary_logloss: 0.22369\n",
      "[556]\ttraining's binary_logloss: 0.223657\n",
      "[557]\ttraining's binary_logloss: 0.22363\n",
      "[558]\ttraining's binary_logloss: 0.2236\n",
      "[559]\ttraining's binary_logloss: 0.223571\n",
      "[560]\ttraining's binary_logloss: 0.223542\n",
      "[561]\ttraining's binary_logloss: 0.223508\n",
      "[562]\ttraining's binary_logloss: 0.223477\n",
      "[563]\ttraining's binary_logloss: 0.223445\n",
      "[564]\ttraining's binary_logloss: 0.223416\n",
      "[565]\ttraining's binary_logloss: 0.223387\n",
      "[566]\ttraining's binary_logloss: 0.223362\n",
      "[567]\ttraining's binary_logloss: 0.223331\n",
      "[568]\ttraining's binary_logloss: 0.223302\n",
      "[569]\ttraining's binary_logloss: 0.223271\n",
      "[570]\ttraining's binary_logloss: 0.223238\n",
      "[571]\ttraining's binary_logloss: 0.2232\n",
      "[572]\ttraining's binary_logloss: 0.223168\n",
      "[573]\ttraining's binary_logloss: 0.22314\n",
      "[574]\ttraining's binary_logloss: 0.223125\n",
      "[575]\ttraining's binary_logloss: 0.223099\n",
      "[576]\ttraining's binary_logloss: 0.223083\n",
      "[577]\ttraining's binary_logloss: 0.223054\n",
      "[578]\ttraining's binary_logloss: 0.223022\n",
      "[579]\ttraining's binary_logloss: 0.22299\n",
      "[580]\ttraining's binary_logloss: 0.222961\n",
      "[581]\ttraining's binary_logloss: 0.222925\n",
      "[582]\ttraining's binary_logloss: 0.222897\n",
      "[583]\ttraining's binary_logloss: 0.22287\n",
      "[584]\ttraining's binary_logloss: 0.222843\n",
      "[585]\ttraining's binary_logloss: 0.222817\n",
      "[586]\ttraining's binary_logloss: 0.222785\n",
      "[587]\ttraining's binary_logloss: 0.222757\n",
      "[588]\ttraining's binary_logloss: 0.222727\n",
      "[589]\ttraining's binary_logloss: 0.222699\n",
      "[590]\ttraining's binary_logloss: 0.222667\n",
      "[591]\ttraining's binary_logloss: 0.222636\n",
      "[592]\ttraining's binary_logloss: 0.222608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[593]\ttraining's binary_logloss: 0.222572\n",
      "[594]\ttraining's binary_logloss: 0.222547\n",
      "[595]\ttraining's binary_logloss: 0.222518\n",
      "[596]\ttraining's binary_logloss: 0.22249\n",
      "[597]\ttraining's binary_logloss: 0.222459\n",
      "[598]\ttraining's binary_logloss: 0.222423\n",
      "[599]\ttraining's binary_logloss: 0.222392\n",
      "[600]\ttraining's binary_logloss: 0.222363\n",
      "[601]\ttraining's binary_logloss: 0.222335\n",
      "[602]\ttraining's binary_logloss: 0.222307\n",
      "[603]\ttraining's binary_logloss: 0.222287\n",
      "[604]\ttraining's binary_logloss: 0.222258\n",
      "[605]\ttraining's binary_logloss: 0.222224\n",
      "[606]\ttraining's binary_logloss: 0.222194\n",
      "[607]\ttraining's binary_logloss: 0.222159\n",
      "[608]\ttraining's binary_logloss: 0.222128\n",
      "[609]\ttraining's binary_logloss: 0.222109\n",
      "[610]\ttraining's binary_logloss: 0.222075\n",
      "[611]\ttraining's binary_logloss: 0.222045\n",
      "[612]\ttraining's binary_logloss: 0.222015\n",
      "[613]\ttraining's binary_logloss: 0.221986\n",
      "[614]\ttraining's binary_logloss: 0.221951\n",
      "[615]\ttraining's binary_logloss: 0.221921\n",
      "[616]\ttraining's binary_logloss: 0.221891\n",
      "[617]\ttraining's binary_logloss: 0.221861\n",
      "[618]\ttraining's binary_logloss: 0.221835\n",
      "[619]\ttraining's binary_logloss: 0.221803\n",
      "[620]\ttraining's binary_logloss: 0.22177\n",
      "[621]\ttraining's binary_logloss: 0.221741\n",
      "[622]\ttraining's binary_logloss: 0.221724\n",
      "[623]\ttraining's binary_logloss: 0.221701\n",
      "[624]\ttraining's binary_logloss: 0.221672\n",
      "[625]\ttraining's binary_logloss: 0.221642\n",
      "[626]\ttraining's binary_logloss: 0.221629\n",
      "[627]\ttraining's binary_logloss: 0.221601\n",
      "[628]\ttraining's binary_logloss: 0.221568\n",
      "[629]\ttraining's binary_logloss: 0.221537\n",
      "[630]\ttraining's binary_logloss: 0.221509\n",
      "[631]\ttraining's binary_logloss: 0.221483\n",
      "[632]\ttraining's binary_logloss: 0.221466\n",
      "[633]\ttraining's binary_logloss: 0.221439\n",
      "[634]\ttraining's binary_logloss: 0.221411\n",
      "[635]\ttraining's binary_logloss: 0.221385\n",
      "[636]\ttraining's binary_logloss: 0.221368\n",
      "[637]\ttraining's binary_logloss: 0.221336\n",
      "[638]\ttraining's binary_logloss: 0.221308\n",
      "[639]\ttraining's binary_logloss: 0.221278\n",
      "[640]\ttraining's binary_logloss: 0.221259\n",
      "[641]\ttraining's binary_logloss: 0.221231\n",
      "[642]\ttraining's binary_logloss: 0.221206\n",
      "[643]\ttraining's binary_logloss: 0.221177\n",
      "[644]\ttraining's binary_logloss: 0.221148\n",
      "[645]\ttraining's binary_logloss: 0.22111\n",
      "[646]\ttraining's binary_logloss: 0.221076\n",
      "[647]\ttraining's binary_logloss: 0.221045\n",
      "[648]\ttraining's binary_logloss: 0.22102\n",
      "[649]\ttraining's binary_logloss: 0.220994\n",
      "[650]\ttraining's binary_logloss: 0.220976\n",
      "[651]\ttraining's binary_logloss: 0.220948\n",
      "[652]\ttraining's binary_logloss: 0.220922\n",
      "[653]\ttraining's binary_logloss: 0.220894\n",
      "[654]\ttraining's binary_logloss: 0.220865\n",
      "[655]\ttraining's binary_logloss: 0.220833\n",
      "[656]\ttraining's binary_logloss: 0.220805\n",
      "[657]\ttraining's binary_logloss: 0.220778\n",
      "[658]\ttraining's binary_logloss: 0.220752\n",
      "[659]\ttraining's binary_logloss: 0.220726\n",
      "[660]\ttraining's binary_logloss: 0.220697\n",
      "[661]\ttraining's binary_logloss: 0.220672\n",
      "[662]\ttraining's binary_logloss: 0.220643\n",
      "[663]\ttraining's binary_logloss: 0.220616\n",
      "[664]\ttraining's binary_logloss: 0.220601\n",
      "[665]\ttraining's binary_logloss: 0.220569\n",
      "[666]\ttraining's binary_logloss: 0.220542\n",
      "[667]\ttraining's binary_logloss: 0.220525\n",
      "[668]\ttraining's binary_logloss: 0.220501\n",
      "[669]\ttraining's binary_logloss: 0.220477\n",
      "[670]\ttraining's binary_logloss: 0.22045\n",
      "[671]\ttraining's binary_logloss: 0.220432\n",
      "[672]\ttraining's binary_logloss: 0.2204\n",
      "[673]\ttraining's binary_logloss: 0.22037\n",
      "[674]\ttraining's binary_logloss: 0.220343\n",
      "[675]\ttraining's binary_logloss: 0.220331\n",
      "[676]\ttraining's binary_logloss: 0.220303\n",
      "[677]\ttraining's binary_logloss: 0.220275\n",
      "[678]\ttraining's binary_logloss: 0.220243\n",
      "[679]\ttraining's binary_logloss: 0.220213\n",
      "[680]\ttraining's binary_logloss: 0.220186\n",
      "[681]\ttraining's binary_logloss: 0.220157\n",
      "[682]\ttraining's binary_logloss: 0.220131\n",
      "[683]\ttraining's binary_logloss: 0.220102\n",
      "[684]\ttraining's binary_logloss: 0.220072\n",
      "[685]\ttraining's binary_logloss: 0.220041\n",
      "[686]\ttraining's binary_logloss: 0.22001\n",
      "[687]\ttraining's binary_logloss: 0.219982\n",
      "[688]\ttraining's binary_logloss: 0.219957\n",
      "[689]\ttraining's binary_logloss: 0.219931\n",
      "[690]\ttraining's binary_logloss: 0.219901\n",
      "[691]\ttraining's binary_logloss: 0.219885\n",
      "[692]\ttraining's binary_logloss: 0.219858\n",
      "[693]\ttraining's binary_logloss: 0.219838\n",
      "[694]\ttraining's binary_logloss: 0.219806\n",
      "[695]\ttraining's binary_logloss: 0.219788\n",
      "[696]\ttraining's binary_logloss: 0.21976\n",
      "[697]\ttraining's binary_logloss: 0.219732\n",
      "[698]\ttraining's binary_logloss: 0.219708\n",
      "[699]\ttraining's binary_logloss: 0.219689\n",
      "[700]\ttraining's binary_logloss: 0.219664\n",
      "[701]\ttraining's binary_logloss: 0.219639\n",
      "[702]\ttraining's binary_logloss: 0.219611\n",
      "[703]\ttraining's binary_logloss: 0.219579\n",
      "[704]\ttraining's binary_logloss: 0.219553\n",
      "[705]\ttraining's binary_logloss: 0.219526\n",
      "[706]\ttraining's binary_logloss: 0.219499\n",
      "[707]\ttraining's binary_logloss: 0.219475\n",
      "[708]\ttraining's binary_logloss: 0.219445\n",
      "[709]\ttraining's binary_logloss: 0.219422\n",
      "[710]\ttraining's binary_logloss: 0.219394\n",
      "[711]\ttraining's binary_logloss: 0.219367\n",
      "[712]\ttraining's binary_logloss: 0.219356\n",
      "[713]\ttraining's binary_logloss: 0.219337\n",
      "[714]\ttraining's binary_logloss: 0.219307\n",
      "[715]\ttraining's binary_logloss: 0.21928\n",
      "[716]\ttraining's binary_logloss: 0.21925\n",
      "[717]\ttraining's binary_logloss: 0.219227\n",
      "[718]\ttraining's binary_logloss: 0.21921\n",
      "[719]\ttraining's binary_logloss: 0.219181\n",
      "[720]\ttraining's binary_logloss: 0.219154\n",
      "[721]\ttraining's binary_logloss: 0.219131\n",
      "[722]\ttraining's binary_logloss: 0.219102\n",
      "[723]\ttraining's binary_logloss: 0.219076\n",
      "[724]\ttraining's binary_logloss: 0.219054\n",
      "[725]\ttraining's binary_logloss: 0.219028\n",
      "[726]\ttraining's binary_logloss: 0.219001\n",
      "[727]\ttraining's binary_logloss: 0.218973\n",
      "[728]\ttraining's binary_logloss: 0.218946\n",
      "[729]\ttraining's binary_logloss: 0.218919\n",
      "[730]\ttraining's binary_logloss: 0.218908\n",
      "[731]\ttraining's binary_logloss: 0.218892\n",
      "[732]\ttraining's binary_logloss: 0.218866\n",
      "[733]\ttraining's binary_logloss: 0.218838\n",
      "[734]\ttraining's binary_logloss: 0.218811\n",
      "[735]\ttraining's binary_logloss: 0.218785\n",
      "[736]\ttraining's binary_logloss: 0.218763\n",
      "[737]\ttraining's binary_logloss: 0.21874\n",
      "[738]\ttraining's binary_logloss: 0.218729\n",
      "[739]\ttraining's binary_logloss: 0.218703\n",
      "[740]\ttraining's binary_logloss: 0.218673\n",
      "[741]\ttraining's binary_logloss: 0.218648\n",
      "[742]\ttraining's binary_logloss: 0.218632\n",
      "[743]\ttraining's binary_logloss: 0.218603\n",
      "[744]\ttraining's binary_logloss: 0.218577\n",
      "[745]\ttraining's binary_logloss: 0.218547\n",
      "[746]\ttraining's binary_logloss: 0.218522\n",
      "[747]\ttraining's binary_logloss: 0.218512\n",
      "[748]\ttraining's binary_logloss: 0.218494\n",
      "[749]\ttraining's binary_logloss: 0.218464\n",
      "[750]\ttraining's binary_logloss: 0.218438\n",
      "[751]\ttraining's binary_logloss: 0.218427\n",
      "[752]\ttraining's binary_logloss: 0.2184\n",
      "[753]\ttraining's binary_logloss: 0.218372\n",
      "[754]\ttraining's binary_logloss: 0.218346\n",
      "[755]\ttraining's binary_logloss: 0.218318\n",
      "[756]\ttraining's binary_logloss: 0.218302\n",
      "[757]\ttraining's binary_logloss: 0.218287\n",
      "[758]\ttraining's binary_logloss: 0.218263\n",
      "[759]\ttraining's binary_logloss: 0.218232\n",
      "[760]\ttraining's binary_logloss: 0.218205\n",
      "[761]\ttraining's binary_logloss: 0.218181\n",
      "[762]\ttraining's binary_logloss: 0.218163\n",
      "[763]\ttraining's binary_logloss: 0.218137\n",
      "[764]\ttraining's binary_logloss: 0.218117\n",
      "[765]\ttraining's binary_logloss: 0.218102\n",
      "[766]\ttraining's binary_logloss: 0.218076\n",
      "[767]\ttraining's binary_logloss: 0.218047\n",
      "[768]\ttraining's binary_logloss: 0.218022\n",
      "[769]\ttraining's binary_logloss: 0.217995\n",
      "[770]\ttraining's binary_logloss: 0.217969\n",
      "[771]\ttraining's binary_logloss: 0.217941\n",
      "[772]\ttraining's binary_logloss: 0.217913\n",
      "[773]\ttraining's binary_logloss: 0.217902\n",
      "[774]\ttraining's binary_logloss: 0.217875\n",
      "[775]\ttraining's binary_logloss: 0.217852\n",
      "[776]\ttraining's binary_logloss: 0.217825\n",
      "[777]\ttraining's binary_logloss: 0.217798\n",
      "[778]\ttraining's binary_logloss: 0.217783\n",
      "[779]\ttraining's binary_logloss: 0.217754\n",
      "[780]\ttraining's binary_logloss: 0.217728\n",
      "[781]\ttraining's binary_logloss: 0.217702\n",
      "[782]\ttraining's binary_logloss: 0.217679\n",
      "[783]\ttraining's binary_logloss: 0.217647\n",
      "[784]\ttraining's binary_logloss: 0.217622\n",
      "[785]\ttraining's binary_logloss: 0.217592\n",
      "[786]\ttraining's binary_logloss: 0.217562\n",
      "[787]\ttraining's binary_logloss: 0.217541\n",
      "[788]\ttraining's binary_logloss: 0.21753\n",
      "[789]\ttraining's binary_logloss: 0.217504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[790]\ttraining's binary_logloss: 0.217481\n",
      "[791]\ttraining's binary_logloss: 0.217454\n",
      "[792]\ttraining's binary_logloss: 0.217431\n",
      "[793]\ttraining's binary_logloss: 0.217407\n",
      "[794]\ttraining's binary_logloss: 0.217381\n",
      "[795]\ttraining's binary_logloss: 0.217357\n",
      "[796]\ttraining's binary_logloss: 0.21733\n",
      "[797]\ttraining's binary_logloss: 0.217316\n",
      "[798]\ttraining's binary_logloss: 0.217292\n",
      "[799]\ttraining's binary_logloss: 0.217265\n",
      "[800]\ttraining's binary_logloss: 0.217236\n",
      "[801]\ttraining's binary_logloss: 0.217205\n",
      "[802]\ttraining's binary_logloss: 0.217177\n",
      "[803]\ttraining's binary_logloss: 0.217151\n",
      "[804]\ttraining's binary_logloss: 0.217122\n",
      "[805]\ttraining's binary_logloss: 0.217099\n",
      "[806]\ttraining's binary_logloss: 0.217091\n",
      "[807]\ttraining's binary_logloss: 0.217074\n",
      "[808]\ttraining's binary_logloss: 0.217064\n",
      "[809]\ttraining's binary_logloss: 0.217039\n",
      "[810]\ttraining's binary_logloss: 0.217014\n",
      "[811]\ttraining's binary_logloss: 0.21699\n",
      "[812]\ttraining's binary_logloss: 0.216959\n",
      "[813]\ttraining's binary_logloss: 0.216933\n",
      "[814]\ttraining's binary_logloss: 0.216909\n",
      "[815]\ttraining's binary_logloss: 0.216898\n",
      "[816]\ttraining's binary_logloss: 0.216873\n",
      "[817]\ttraining's binary_logloss: 0.21686\n",
      "[818]\ttraining's binary_logloss: 0.216837\n",
      "[819]\ttraining's binary_logloss: 0.216816\n",
      "[820]\ttraining's binary_logloss: 0.216787\n",
      "[821]\ttraining's binary_logloss: 0.216768\n",
      "[822]\ttraining's binary_logloss: 0.216745\n",
      "[823]\ttraining's binary_logloss: 0.216716\n",
      "[824]\ttraining's binary_logloss: 0.216694\n",
      "[825]\ttraining's binary_logloss: 0.216672\n",
      "[826]\ttraining's binary_logloss: 0.216648\n",
      "[827]\ttraining's binary_logloss: 0.216624\n",
      "[828]\ttraining's binary_logloss: 0.216609\n",
      "[829]\ttraining's binary_logloss: 0.216581\n",
      "[830]\ttraining's binary_logloss: 0.21657\n",
      "[831]\ttraining's binary_logloss: 0.216546\n",
      "[832]\ttraining's binary_logloss: 0.216532\n",
      "[833]\ttraining's binary_logloss: 0.216518\n",
      "[834]\ttraining's binary_logloss: 0.216493\n",
      "[835]\ttraining's binary_logloss: 0.216466\n",
      "[836]\ttraining's binary_logloss: 0.216441\n",
      "[837]\ttraining's binary_logloss: 0.216416\n",
      "[838]\ttraining's binary_logloss: 0.216392\n",
      "[839]\ttraining's binary_logloss: 0.216367\n",
      "[840]\ttraining's binary_logloss: 0.216351\n",
      "[841]\ttraining's binary_logloss: 0.216327\n",
      "[842]\ttraining's binary_logloss: 0.2163\n",
      "[843]\ttraining's binary_logloss: 0.216278\n",
      "[844]\ttraining's binary_logloss: 0.216252\n",
      "[845]\ttraining's binary_logloss: 0.21623\n",
      "[846]\ttraining's binary_logloss: 0.216204\n",
      "[847]\ttraining's binary_logloss: 0.216179\n",
      "[848]\ttraining's binary_logloss: 0.216154\n",
      "[849]\ttraining's binary_logloss: 0.216127\n",
      "[850]\ttraining's binary_logloss: 0.216104\n",
      "[851]\ttraining's binary_logloss: 0.216076\n",
      "[852]\ttraining's binary_logloss: 0.21606\n",
      "[853]\ttraining's binary_logloss: 0.216033\n",
      "[854]\ttraining's binary_logloss: 0.216006\n",
      "[855]\ttraining's binary_logloss: 0.21598\n",
      "[856]\ttraining's binary_logloss: 0.215958\n",
      "[857]\ttraining's binary_logloss: 0.215942\n",
      "[858]\ttraining's binary_logloss: 0.215937\n",
      "[859]\ttraining's binary_logloss: 0.215912\n",
      "[860]\ttraining's binary_logloss: 0.215884\n",
      "[861]\ttraining's binary_logloss: 0.215857\n",
      "[862]\ttraining's binary_logloss: 0.215834\n",
      "[863]\ttraining's binary_logloss: 0.215808\n",
      "[864]\ttraining's binary_logloss: 0.215784\n",
      "[865]\ttraining's binary_logloss: 0.215768\n",
      "[866]\ttraining's binary_logloss: 0.215743\n",
      "[867]\ttraining's binary_logloss: 0.21572\n",
      "[868]\ttraining's binary_logloss: 0.215692\n",
      "[869]\ttraining's binary_logloss: 0.215674\n",
      "[870]\ttraining's binary_logloss: 0.215646\n",
      "[871]\ttraining's binary_logloss: 0.21562\n",
      "[872]\ttraining's binary_logloss: 0.215595\n",
      "[873]\ttraining's binary_logloss: 0.215569\n",
      "[874]\ttraining's binary_logloss: 0.215543\n",
      "[875]\ttraining's binary_logloss: 0.215535\n",
      "[876]\ttraining's binary_logloss: 0.215513\n",
      "[877]\ttraining's binary_logloss: 0.215489\n",
      "[878]\ttraining's binary_logloss: 0.215473\n",
      "[879]\ttraining's binary_logloss: 0.215448\n",
      "[880]\ttraining's binary_logloss: 0.215429\n",
      "[881]\ttraining's binary_logloss: 0.215404\n",
      "[882]\ttraining's binary_logloss: 0.215393\n",
      "[883]\ttraining's binary_logloss: 0.215369\n",
      "[884]\ttraining's binary_logloss: 0.215345\n",
      "[885]\ttraining's binary_logloss: 0.215322\n",
      "[886]\ttraining's binary_logloss: 0.215288\n",
      "[887]\ttraining's binary_logloss: 0.215264\n",
      "[888]\ttraining's binary_logloss: 0.215238\n",
      "[889]\ttraining's binary_logloss: 0.215212\n",
      "[890]\ttraining's binary_logloss: 0.215191\n",
      "[891]\ttraining's binary_logloss: 0.21517\n",
      "[892]\ttraining's binary_logloss: 0.215144\n",
      "[893]\ttraining's binary_logloss: 0.215118\n",
      "[894]\ttraining's binary_logloss: 0.215084\n",
      "[895]\ttraining's binary_logloss: 0.215071\n",
      "[896]\ttraining's binary_logloss: 0.215045\n",
      "[897]\ttraining's binary_logloss: 0.215012\n",
      "[898]\ttraining's binary_logloss: 0.214988\n",
      "[899]\ttraining's binary_logloss: 0.21496\n",
      "[900]\ttraining's binary_logloss: 0.214943\n",
      "[901]\ttraining's binary_logloss: 0.214921\n",
      "[902]\ttraining's binary_logloss: 0.214896\n",
      "[903]\ttraining's binary_logloss: 0.214867\n",
      "[904]\ttraining's binary_logloss: 0.21485\n",
      "[905]\ttraining's binary_logloss: 0.214839\n",
      "[906]\ttraining's binary_logloss: 0.214811\n",
      "[907]\ttraining's binary_logloss: 0.214783\n",
      "[908]\ttraining's binary_logloss: 0.214768\n",
      "[909]\ttraining's binary_logloss: 0.214744\n",
      "[910]\ttraining's binary_logloss: 0.214721\n",
      "[911]\ttraining's binary_logloss: 0.214698\n",
      "[912]\ttraining's binary_logloss: 0.214677\n",
      "[913]\ttraining's binary_logloss: 0.21466\n",
      "[914]\ttraining's binary_logloss: 0.214633\n",
      "[915]\ttraining's binary_logloss: 0.214607\n",
      "[916]\ttraining's binary_logloss: 0.214579\n",
      "[917]\ttraining's binary_logloss: 0.214551\n",
      "[918]\ttraining's binary_logloss: 0.214529\n",
      "[919]\ttraining's binary_logloss: 0.214502\n",
      "[920]\ttraining's binary_logloss: 0.214476\n",
      "[921]\ttraining's binary_logloss: 0.214453\n",
      "[922]\ttraining's binary_logloss: 0.214437\n",
      "[923]\ttraining's binary_logloss: 0.214411\n",
      "[924]\ttraining's binary_logloss: 0.214386\n",
      "[925]\ttraining's binary_logloss: 0.214359\n",
      "[926]\ttraining's binary_logloss: 0.214335\n",
      "[927]\ttraining's binary_logloss: 0.21431\n",
      "[928]\ttraining's binary_logloss: 0.214288\n",
      "[929]\ttraining's binary_logloss: 0.214268\n",
      "[930]\ttraining's binary_logloss: 0.214244\n",
      "[931]\ttraining's binary_logloss: 0.214218\n",
      "[932]\ttraining's binary_logloss: 0.214195\n",
      "[933]\ttraining's binary_logloss: 0.214172\n",
      "[934]\ttraining's binary_logloss: 0.214148\n",
      "[935]\ttraining's binary_logloss: 0.214123\n",
      "[936]\ttraining's binary_logloss: 0.2141\n",
      "[937]\ttraining's binary_logloss: 0.214084\n",
      "[938]\ttraining's binary_logloss: 0.214061\n",
      "[939]\ttraining's binary_logloss: 0.214033\n",
      "[940]\ttraining's binary_logloss: 0.214008\n",
      "[941]\ttraining's binary_logloss: 0.213983\n",
      "[942]\ttraining's binary_logloss: 0.213974\n",
      "[943]\ttraining's binary_logloss: 0.213953\n",
      "[944]\ttraining's binary_logloss: 0.213929\n",
      "[945]\ttraining's binary_logloss: 0.213903\n",
      "[946]\ttraining's binary_logloss: 0.213879\n",
      "[947]\ttraining's binary_logloss: 0.213851\n",
      "[948]\ttraining's binary_logloss: 0.213829\n",
      "[949]\ttraining's binary_logloss: 0.213804\n",
      "[950]\ttraining's binary_logloss: 0.213775\n",
      "[951]\ttraining's binary_logloss: 0.213753\n",
      "[952]\ttraining's binary_logloss: 0.213724\n",
      "[953]\ttraining's binary_logloss: 0.213697\n",
      "[954]\ttraining's binary_logloss: 0.213688\n",
      "[955]\ttraining's binary_logloss: 0.213665\n",
      "[956]\ttraining's binary_logloss: 0.21365\n",
      "[957]\ttraining's binary_logloss: 0.213628\n",
      "[958]\ttraining's binary_logloss: 0.213604\n",
      "[959]\ttraining's binary_logloss: 0.213576\n",
      "[960]\ttraining's binary_logloss: 0.213566\n",
      "[961]\ttraining's binary_logloss: 0.213542\n",
      "[962]\ttraining's binary_logloss: 0.21353\n",
      "[963]\ttraining's binary_logloss: 0.213503\n",
      "[964]\ttraining's binary_logloss: 0.213477\n",
      "[965]\ttraining's binary_logloss: 0.213449\n",
      "[966]\ttraining's binary_logloss: 0.213427\n",
      "[967]\ttraining's binary_logloss: 0.213414\n",
      "[968]\ttraining's binary_logloss: 0.213394\n",
      "[969]\ttraining's binary_logloss: 0.213372\n",
      "[970]\ttraining's binary_logloss: 0.213347\n",
      "[971]\ttraining's binary_logloss: 0.213335\n",
      "[972]\ttraining's binary_logloss: 0.213317\n",
      "[973]\ttraining's binary_logloss: 0.21329\n",
      "[974]\ttraining's binary_logloss: 0.213267\n",
      "[975]\ttraining's binary_logloss: 0.213242\n",
      "[976]\ttraining's binary_logloss: 0.213219\n",
      "[977]\ttraining's binary_logloss: 0.213195\n",
      "[978]\ttraining's binary_logloss: 0.213183\n",
      "[979]\ttraining's binary_logloss: 0.213157\n",
      "[980]\ttraining's binary_logloss: 0.213133\n",
      "[981]\ttraining's binary_logloss: 0.213109\n",
      "[982]\ttraining's binary_logloss: 0.213085\n",
      "[983]\ttraining's binary_logloss: 0.213065\n",
      "[984]\ttraining's binary_logloss: 0.213042\n",
      "[985]\ttraining's binary_logloss: 0.213015\n",
      "[986]\ttraining's binary_logloss: 0.212989\n",
      "[987]\ttraining's binary_logloss: 0.212971\n",
      "[988]\ttraining's binary_logloss: 0.212945\n",
      "[989]\ttraining's binary_logloss: 0.212917\n",
      "[990]\ttraining's binary_logloss: 0.212901\n",
      "[991]\ttraining's binary_logloss: 0.212876\n",
      "[992]\ttraining's binary_logloss: 0.212856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993]\ttraining's binary_logloss: 0.212834\n",
      "[994]\ttraining's binary_logloss: 0.212805\n",
      "[995]\ttraining's binary_logloss: 0.212781\n",
      "[996]\ttraining's binary_logloss: 0.212756\n",
      "[997]\ttraining's binary_logloss: 0.212732\n",
      "[998]\ttraining's binary_logloss: 0.212707\n",
      "[999]\ttraining's binary_logloss: 0.212684\n",
      "[1000]\ttraining's binary_logloss: 0.212659\n",
      "[1001]\ttraining's binary_logloss: 0.212636\n",
      "[1002]\ttraining's binary_logloss: 0.212614\n",
      "[1003]\ttraining's binary_logloss: 0.212589\n",
      "[1004]\ttraining's binary_logloss: 0.212562\n",
      "[1005]\ttraining's binary_logloss: 0.212538\n",
      "[1006]\ttraining's binary_logloss: 0.212513\n",
      "[1007]\ttraining's binary_logloss: 0.212486\n",
      "[1008]\ttraining's binary_logloss: 0.212464\n",
      "[1009]\ttraining's binary_logloss: 0.212439\n",
      "[1010]\ttraining's binary_logloss: 0.212416\n",
      "[1011]\ttraining's binary_logloss: 0.212396\n",
      "[1012]\ttraining's binary_logloss: 0.212373\n",
      "[1013]\ttraining's binary_logloss: 0.212353\n",
      "[1014]\ttraining's binary_logloss: 0.21233\n",
      "[1015]\ttraining's binary_logloss: 0.212302\n",
      "[1016]\ttraining's binary_logloss: 0.212276\n",
      "[1017]\ttraining's binary_logloss: 0.212261\n",
      "[1018]\ttraining's binary_logloss: 0.212243\n",
      "[1019]\ttraining's binary_logloss: 0.212224\n",
      "[1020]\ttraining's binary_logloss: 0.212219\n",
      "[1021]\ttraining's binary_logloss: 0.212195\n",
      "[1022]\ttraining's binary_logloss: 0.212168\n",
      "[1023]\ttraining's binary_logloss: 0.212142\n",
      "[1024]\ttraining's binary_logloss: 0.212119\n",
      "[1025]\ttraining's binary_logloss: 0.212093\n",
      "[1026]\ttraining's binary_logloss: 0.212084\n",
      "[1027]\ttraining's binary_logloss: 0.212056\n",
      "[1028]\ttraining's binary_logloss: 0.212034\n",
      "[1029]\ttraining's binary_logloss: 0.212015\n",
      "[1030]\ttraining's binary_logloss: 0.211988\n",
      "[1031]\ttraining's binary_logloss: 0.211968\n",
      "[1032]\ttraining's binary_logloss: 0.211944\n",
      "[1033]\ttraining's binary_logloss: 0.211918\n",
      "[1034]\ttraining's binary_logloss: 0.211896\n",
      "[1035]\ttraining's binary_logloss: 0.211871\n",
      "[1036]\ttraining's binary_logloss: 0.211845\n",
      "[1037]\ttraining's binary_logloss: 0.211819\n",
      "[1038]\ttraining's binary_logloss: 0.211797\n",
      "[1039]\ttraining's binary_logloss: 0.211771\n",
      "[1040]\ttraining's binary_logloss: 0.211762\n",
      "[1041]\ttraining's binary_logloss: 0.211739\n",
      "[1042]\ttraining's binary_logloss: 0.211717\n",
      "[1043]\ttraining's binary_logloss: 0.211693\n",
      "[1044]\ttraining's binary_logloss: 0.211669\n",
      "[1045]\ttraining's binary_logloss: 0.211653\n",
      "[1046]\ttraining's binary_logloss: 0.211629\n",
      "[1047]\ttraining's binary_logloss: 0.211607\n",
      "[1048]\ttraining's binary_logloss: 0.211582\n",
      "[1049]\ttraining's binary_logloss: 0.211555\n",
      "[1050]\ttraining's binary_logloss: 0.211527\n",
      "[1051]\ttraining's binary_logloss: 0.211503\n",
      "[1052]\ttraining's binary_logloss: 0.211482\n",
      "[1053]\ttraining's binary_logloss: 0.211459\n",
      "[1054]\ttraining's binary_logloss: 0.211437\n",
      "[1055]\ttraining's binary_logloss: 0.211408\n",
      "[1056]\ttraining's binary_logloss: 0.211388\n",
      "[1057]\ttraining's binary_logloss: 0.211365\n",
      "[1058]\ttraining's binary_logloss: 0.211345\n",
      "[1059]\ttraining's binary_logloss: 0.211321\n",
      "[1060]\ttraining's binary_logloss: 0.211299\n",
      "[1061]\ttraining's binary_logloss: 0.211273\n",
      "[1062]\ttraining's binary_logloss: 0.211249\n",
      "[1063]\ttraining's binary_logloss: 0.211228\n",
      "[1064]\ttraining's binary_logloss: 0.211213\n",
      "[1065]\ttraining's binary_logloss: 0.211203\n",
      "[1066]\ttraining's binary_logloss: 0.211177\n",
      "[1067]\ttraining's binary_logloss: 0.211166\n",
      "[1068]\ttraining's binary_logloss: 0.21114\n",
      "[1069]\ttraining's binary_logloss: 0.211114\n",
      "[1070]\ttraining's binary_logloss: 0.211094\n",
      "[1071]\ttraining's binary_logloss: 0.211069\n",
      "[1072]\ttraining's binary_logloss: 0.211049\n",
      "[1073]\ttraining's binary_logloss: 0.211035\n",
      "[1074]\ttraining's binary_logloss: 0.211012\n",
      "[1075]\ttraining's binary_logloss: 0.210989\n",
      "[1076]\ttraining's binary_logloss: 0.210963\n",
      "[1077]\ttraining's binary_logloss: 0.210941\n",
      "[1078]\ttraining's binary_logloss: 0.210929\n",
      "[1079]\ttraining's binary_logloss: 0.210904\n",
      "[1080]\ttraining's binary_logloss: 0.21088\n",
      "[1081]\ttraining's binary_logloss: 0.210858\n",
      "[1082]\ttraining's binary_logloss: 0.210833\n",
      "[1083]\ttraining's binary_logloss: 0.210808\n",
      "[1084]\ttraining's binary_logloss: 0.210785\n",
      "[1085]\ttraining's binary_logloss: 0.210761\n",
      "[1086]\ttraining's binary_logloss: 0.210735\n",
      "[1087]\ttraining's binary_logloss: 0.210714\n",
      "[1088]\ttraining's binary_logloss: 0.210691\n",
      "[1089]\ttraining's binary_logloss: 0.210668\n",
      "[1090]\ttraining's binary_logloss: 0.210645\n",
      "[1091]\ttraining's binary_logloss: 0.210621\n",
      "[1092]\ttraining's binary_logloss: 0.210598\n",
      "[1093]\ttraining's binary_logloss: 0.210573\n",
      "[1094]\ttraining's binary_logloss: 0.210549\n",
      "[1095]\ttraining's binary_logloss: 0.210523\n",
      "[1096]\ttraining's binary_logloss: 0.210501\n",
      "[1097]\ttraining's binary_logloss: 0.210478\n",
      "[1098]\ttraining's binary_logloss: 0.210455\n",
      "[1099]\ttraining's binary_logloss: 0.21044\n",
      "[1100]\ttraining's binary_logloss: 0.210418\n",
      "[1101]\ttraining's binary_logloss: 0.210392\n",
      "[1102]\ttraining's binary_logloss: 0.210381\n",
      "[1103]\ttraining's binary_logloss: 0.210355\n",
      "[1104]\ttraining's binary_logloss: 0.210327\n",
      "[1105]\ttraining's binary_logloss: 0.210301\n",
      "[1106]\ttraining's binary_logloss: 0.210284\n",
      "[1107]\ttraining's binary_logloss: 0.210258\n",
      "[1108]\ttraining's binary_logloss: 0.210232\n",
      "[1109]\ttraining's binary_logloss: 0.21021\n",
      "[1110]\ttraining's binary_logloss: 0.210205\n",
      "[1111]\ttraining's binary_logloss: 0.210181\n",
      "[1112]\ttraining's binary_logloss: 0.210155\n",
      "[1113]\ttraining's binary_logloss: 0.210132\n",
      "[1114]\ttraining's binary_logloss: 0.210104\n",
      "[1115]\ttraining's binary_logloss: 0.210078\n",
      "[1116]\ttraining's binary_logloss: 0.210052\n",
      "[1117]\ttraining's binary_logloss: 0.210027\n",
      "[1118]\ttraining's binary_logloss: 0.210005\n",
      "[1119]\ttraining's binary_logloss: 0.209999\n",
      "[1120]\ttraining's binary_logloss: 0.209974\n",
      "[1121]\ttraining's binary_logloss: 0.20995\n",
      "[1122]\ttraining's binary_logloss: 0.209927\n",
      "[1123]\ttraining's binary_logloss: 0.209905\n",
      "[1124]\ttraining's binary_logloss: 0.209879\n",
      "[1125]\ttraining's binary_logloss: 0.209855\n",
      "[1126]\ttraining's binary_logloss: 0.209833\n",
      "[1127]\ttraining's binary_logloss: 0.209821\n",
      "[1128]\ttraining's binary_logloss: 0.209799\n",
      "[1129]\ttraining's binary_logloss: 0.209776\n",
      "[1130]\ttraining's binary_logloss: 0.20975\n",
      "[1131]\ttraining's binary_logloss: 0.209726\n",
      "[1132]\ttraining's binary_logloss: 0.209701\n",
      "[1133]\ttraining's binary_logloss: 0.209674\n",
      "[1134]\ttraining's binary_logloss: 0.209652\n",
      "[1135]\ttraining's binary_logloss: 0.209629\n",
      "[1136]\ttraining's binary_logloss: 0.20962\n",
      "[1137]\ttraining's binary_logloss: 0.209614\n",
      "[1138]\ttraining's binary_logloss: 0.209591\n",
      "[1139]\ttraining's binary_logloss: 0.209584\n",
      "[1140]\ttraining's binary_logloss: 0.209561\n",
      "[1141]\ttraining's binary_logloss: 0.209538\n",
      "[1142]\ttraining's binary_logloss: 0.20952\n",
      "[1143]\ttraining's binary_logloss: 0.209492\n",
      "[1144]\ttraining's binary_logloss: 0.20947\n",
      "[1145]\ttraining's binary_logloss: 0.20945\n",
      "[1146]\ttraining's binary_logloss: 0.209424\n",
      "[1147]\ttraining's binary_logloss: 0.209403\n",
      "[1148]\ttraining's binary_logloss: 0.209378\n",
      "[1149]\ttraining's binary_logloss: 0.209351\n",
      "[1150]\ttraining's binary_logloss: 0.209326\n",
      "[1151]\ttraining's binary_logloss: 0.209304\n",
      "[1152]\ttraining's binary_logloss: 0.209287\n",
      "[1153]\ttraining's binary_logloss: 0.209267\n",
      "[1154]\ttraining's binary_logloss: 0.209241\n",
      "[1155]\ttraining's binary_logloss: 0.20922\n",
      "[1156]\ttraining's binary_logloss: 0.2092\n",
      "[1157]\ttraining's binary_logloss: 0.209181\n",
      "[1158]\ttraining's binary_logloss: 0.209156\n",
      "[1159]\ttraining's binary_logloss: 0.209149\n",
      "[1160]\ttraining's binary_logloss: 0.209124\n",
      "[1161]\ttraining's binary_logloss: 0.209099\n",
      "[1162]\ttraining's binary_logloss: 0.209074\n",
      "[1163]\ttraining's binary_logloss: 0.209048\n",
      "[1164]\ttraining's binary_logloss: 0.209027\n",
      "[1165]\ttraining's binary_logloss: 0.209001\n",
      "[1166]\ttraining's binary_logloss: 0.208977\n",
      "[1167]\ttraining's binary_logloss: 0.208954\n",
      "[1168]\ttraining's binary_logloss: 0.208928\n",
      "[1169]\ttraining's binary_logloss: 0.208907\n",
      "[1170]\ttraining's binary_logloss: 0.208896\n",
      "[1171]\ttraining's binary_logloss: 0.20887\n",
      "[1172]\ttraining's binary_logloss: 0.208845\n",
      "[1173]\ttraining's binary_logloss: 0.208823\n",
      "[1174]\ttraining's binary_logloss: 0.208799\n",
      "[1175]\ttraining's binary_logloss: 0.208775\n",
      "[1176]\ttraining's binary_logloss: 0.20875\n",
      "[1177]\ttraining's binary_logloss: 0.208723\n",
      "[1178]\ttraining's binary_logloss: 0.208697\n",
      "[1179]\ttraining's binary_logloss: 0.208674\n",
      "[1180]\ttraining's binary_logloss: 0.208664\n",
      "[1181]\ttraining's binary_logloss: 0.208637\n",
      "[1182]\ttraining's binary_logloss: 0.208616\n",
      "[1183]\ttraining's binary_logloss: 0.208593\n",
      "[1184]\ttraining's binary_logloss: 0.208569\n",
      "[1185]\ttraining's binary_logloss: 0.208555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1186]\ttraining's binary_logloss: 0.208531\n",
      "[1187]\ttraining's binary_logloss: 0.208506\n",
      "[1188]\ttraining's binary_logloss: 0.208479\n",
      "[1189]\ttraining's binary_logloss: 0.208457\n",
      "[1190]\ttraining's binary_logloss: 0.208432\n",
      "[1191]\ttraining's binary_logloss: 0.208424\n",
      "[1192]\ttraining's binary_logloss: 0.208401\n",
      "[1193]\ttraining's binary_logloss: 0.208374\n",
      "[1194]\ttraining's binary_logloss: 0.208347\n",
      "[1195]\ttraining's binary_logloss: 0.208324\n",
      "[1196]\ttraining's binary_logloss: 0.208299\n",
      "[1197]\ttraining's binary_logloss: 0.20827\n",
      "[1198]\ttraining's binary_logloss: 0.208247\n",
      "[1199]\ttraining's binary_logloss: 0.208222\n",
      "[1200]\ttraining's binary_logloss: 0.208214\n",
      "[1201]\ttraining's binary_logloss: 0.208204\n",
      "[1202]\ttraining's binary_logloss: 0.208178\n",
      "[1203]\ttraining's binary_logloss: 0.20816\n",
      "[1204]\ttraining's binary_logloss: 0.208136\n",
      "[1205]\ttraining's binary_logloss: 0.208111\n",
      "[1206]\ttraining's binary_logloss: 0.208084\n",
      "[1207]\ttraining's binary_logloss: 0.208063\n",
      "[1208]\ttraining's binary_logloss: 0.208039\n",
      "[1209]\ttraining's binary_logloss: 0.208013\n",
      "[1210]\ttraining's binary_logloss: 0.207988\n",
      "[1211]\ttraining's binary_logloss: 0.207965\n",
      "[1212]\ttraining's binary_logloss: 0.207952\n",
      "[1213]\ttraining's binary_logloss: 0.207931\n",
      "[1214]\ttraining's binary_logloss: 0.207905\n",
      "[1215]\ttraining's binary_logloss: 0.207885\n",
      "[1216]\ttraining's binary_logloss: 0.207863\n",
      "[1217]\ttraining's binary_logloss: 0.207841\n",
      "[1218]\ttraining's binary_logloss: 0.207834\n",
      "[1219]\ttraining's binary_logloss: 0.207815\n",
      "[1220]\ttraining's binary_logloss: 0.20779\n",
      "[1221]\ttraining's binary_logloss: 0.207765\n",
      "[1222]\ttraining's binary_logloss: 0.207741\n",
      "[1223]\ttraining's binary_logloss: 0.207719\n",
      "[1224]\ttraining's binary_logloss: 0.207694\n",
      "[1225]\ttraining's binary_logloss: 0.207669\n",
      "[1226]\ttraining's binary_logloss: 0.207645\n",
      "[1227]\ttraining's binary_logloss: 0.207639\n",
      "[1228]\ttraining's binary_logloss: 0.207614\n",
      "[1229]\ttraining's binary_logloss: 0.207604\n",
      "[1230]\ttraining's binary_logloss: 0.207579\n",
      "[1231]\ttraining's binary_logloss: 0.207558\n",
      "[1232]\ttraining's binary_logloss: 0.207548\n",
      "[1233]\ttraining's binary_logloss: 0.207523\n",
      "[1234]\ttraining's binary_logloss: 0.207503\n",
      "[1235]\ttraining's binary_logloss: 0.207478\n",
      "[1236]\ttraining's binary_logloss: 0.207453\n",
      "[1237]\ttraining's binary_logloss: 0.207431\n",
      "[1238]\ttraining's binary_logloss: 0.207408\n",
      "[1239]\ttraining's binary_logloss: 0.207385\n",
      "[1240]\ttraining's binary_logloss: 0.207379\n",
      "[1241]\ttraining's binary_logloss: 0.207355\n",
      "[1242]\ttraining's binary_logloss: 0.207326\n",
      "[1243]\ttraining's binary_logloss: 0.207307\n",
      "[1244]\ttraining's binary_logloss: 0.207283\n",
      "[1245]\ttraining's binary_logloss: 0.207262\n",
      "[1246]\ttraining's binary_logloss: 0.207239\n",
      "[1247]\ttraining's binary_logloss: 0.207216\n",
      "[1248]\ttraining's binary_logloss: 0.207191\n",
      "[1249]\ttraining's binary_logloss: 0.207169\n",
      "[1250]\ttraining's binary_logloss: 0.207143\n",
      "[1251]\ttraining's binary_logloss: 0.207123\n",
      "[1252]\ttraining's binary_logloss: 0.207105\n",
      "[1253]\ttraining's binary_logloss: 0.207094\n",
      "[1254]\ttraining's binary_logloss: 0.207073\n",
      "[1255]\ttraining's binary_logloss: 0.207048\n",
      "[1256]\ttraining's binary_logloss: 0.207024\n",
      "[1257]\ttraining's binary_logloss: 0.207\n",
      "[1258]\ttraining's binary_logloss: 0.206979\n",
      "[1259]\ttraining's binary_logloss: 0.206957\n",
      "[1260]\ttraining's binary_logloss: 0.206948\n",
      "[1261]\ttraining's binary_logloss: 0.206923\n",
      "[1262]\ttraining's binary_logloss: 0.206899\n",
      "[1263]\ttraining's binary_logloss: 0.206876\n",
      "[1264]\ttraining's binary_logloss: 0.206854\n",
      "[1265]\ttraining's binary_logloss: 0.206833\n",
      "[1266]\ttraining's binary_logloss: 0.206808\n",
      "[1267]\ttraining's binary_logloss: 0.206786\n",
      "[1268]\ttraining's binary_logloss: 0.20676\n",
      "[1269]\ttraining's binary_logloss: 0.206735\n",
      "[1270]\ttraining's binary_logloss: 0.206709\n",
      "[1271]\ttraining's binary_logloss: 0.206688\n",
      "[1272]\ttraining's binary_logloss: 0.206665\n",
      "[1273]\ttraining's binary_logloss: 0.206641\n",
      "[1274]\ttraining's binary_logloss: 0.206617\n",
      "[1275]\ttraining's binary_logloss: 0.206599\n",
      "[1276]\ttraining's binary_logloss: 0.206576\n",
      "[1277]\ttraining's binary_logloss: 0.206553\n",
      "[1278]\ttraining's binary_logloss: 0.206529\n",
      "[1279]\ttraining's binary_logloss: 0.206504\n",
      "[1280]\ttraining's binary_logloss: 0.206484\n",
      "[1281]\ttraining's binary_logloss: 0.206462\n",
      "[1282]\ttraining's binary_logloss: 0.20644\n",
      "[1283]\ttraining's binary_logloss: 0.206417\n",
      "[1284]\ttraining's binary_logloss: 0.206399\n",
      "[1285]\ttraining's binary_logloss: 0.206374\n",
      "[1286]\ttraining's binary_logloss: 0.206349\n",
      "[1287]\ttraining's binary_logloss: 0.206327\n",
      "[1288]\ttraining's binary_logloss: 0.206304\n",
      "[1289]\ttraining's binary_logloss: 0.206282\n",
      "[1290]\ttraining's binary_logloss: 0.206258\n",
      "[1291]\ttraining's binary_logloss: 0.206233\n",
      "[1292]\ttraining's binary_logloss: 0.206214\n",
      "[1293]\ttraining's binary_logloss: 0.20619\n",
      "[1294]\ttraining's binary_logloss: 0.206182\n",
      "[1295]\ttraining's binary_logloss: 0.20616\n",
      "[1296]\ttraining's binary_logloss: 0.206136\n",
      "[1297]\ttraining's binary_logloss: 0.206113\n",
      "[1298]\ttraining's binary_logloss: 0.206087\n",
      "[1299]\ttraining's binary_logloss: 0.20606\n",
      "[1300]\ttraining's binary_logloss: 0.206039\n",
      "[1301]\ttraining's binary_logloss: 0.206014\n",
      "[1302]\ttraining's binary_logloss: 0.205994\n",
      "[1303]\ttraining's binary_logloss: 0.205972\n",
      "[1304]\ttraining's binary_logloss: 0.205953\n",
      "[1305]\ttraining's binary_logloss: 0.205927\n",
      "[1306]\ttraining's binary_logloss: 0.205909\n",
      "[1307]\ttraining's binary_logloss: 0.205889\n",
      "[1308]\ttraining's binary_logloss: 0.205866\n",
      "[1309]\ttraining's binary_logloss: 0.205845\n",
      "[1310]\ttraining's binary_logloss: 0.205836\n",
      "[1311]\ttraining's binary_logloss: 0.205811\n",
      "[1312]\ttraining's binary_logloss: 0.20579\n",
      "[1313]\ttraining's binary_logloss: 0.205765\n",
      "[1314]\ttraining's binary_logloss: 0.20574\n",
      "[1315]\ttraining's binary_logloss: 0.20573\n",
      "[1316]\ttraining's binary_logloss: 0.205706\n",
      "[1317]\ttraining's binary_logloss: 0.205684\n",
      "[1318]\ttraining's binary_logloss: 0.205661\n",
      "[1319]\ttraining's binary_logloss: 0.205638\n",
      "[1320]\ttraining's binary_logloss: 0.205616\n",
      "[1321]\ttraining's binary_logloss: 0.205595\n",
      "[1322]\ttraining's binary_logloss: 0.205575\n",
      "[1323]\ttraining's binary_logloss: 0.205552\n",
      "[1324]\ttraining's binary_logloss: 0.205524\n",
      "[1325]\ttraining's binary_logloss: 0.205503\n",
      "[1326]\ttraining's binary_logloss: 0.205474\n",
      "[1327]\ttraining's binary_logloss: 0.205468\n",
      "[1328]\ttraining's binary_logloss: 0.205448\n",
      "[1329]\ttraining's binary_logloss: 0.205424\n",
      "[1330]\ttraining's binary_logloss: 0.205402\n",
      "[1331]\ttraining's binary_logloss: 0.205381\n",
      "[1332]\ttraining's binary_logloss: 0.205359\n",
      "[1333]\ttraining's binary_logloss: 0.205336\n",
      "[1334]\ttraining's binary_logloss: 0.205314\n",
      "[1335]\ttraining's binary_logloss: 0.205289\n",
      "[1336]\ttraining's binary_logloss: 0.20526\n",
      "[1337]\ttraining's binary_logloss: 0.205239\n",
      "[1338]\ttraining's binary_logloss: 0.205215\n",
      "[1339]\ttraining's binary_logloss: 0.205191\n",
      "[1340]\ttraining's binary_logloss: 0.205169\n",
      "[1341]\ttraining's binary_logloss: 0.205145\n",
      "[1342]\ttraining's binary_logloss: 0.205122\n",
      "[1343]\ttraining's binary_logloss: 0.205106\n",
      "[1344]\ttraining's binary_logloss: 0.205078\n",
      "[1345]\ttraining's binary_logloss: 0.205052\n",
      "[1346]\ttraining's binary_logloss: 0.205027\n",
      "[1347]\ttraining's binary_logloss: 0.205022\n",
      "[1348]\ttraining's binary_logloss: 0.205004\n",
      "[1349]\ttraining's binary_logloss: 0.204982\n",
      "[1350]\ttraining's binary_logloss: 0.204953\n",
      "[1351]\ttraining's binary_logloss: 0.20493\n",
      "[1352]\ttraining's binary_logloss: 0.204909\n",
      "[1353]\ttraining's binary_logloss: 0.204898\n",
      "[1354]\ttraining's binary_logloss: 0.20488\n",
      "[1355]\ttraining's binary_logloss: 0.204857\n",
      "[1356]\ttraining's binary_logloss: 0.204831\n",
      "[1357]\ttraining's binary_logloss: 0.204809\n",
      "[1358]\ttraining's binary_logloss: 0.204795\n",
      "[1359]\ttraining's binary_logloss: 0.204791\n",
      "[1360]\ttraining's binary_logloss: 0.204771\n",
      "[1361]\ttraining's binary_logloss: 0.204745\n",
      "[1362]\ttraining's binary_logloss: 0.204729\n",
      "[1363]\ttraining's binary_logloss: 0.204721\n",
      "[1364]\ttraining's binary_logloss: 0.204695\n",
      "[1365]\ttraining's binary_logloss: 0.204672\n",
      "[1366]\ttraining's binary_logloss: 0.204647\n",
      "[1367]\ttraining's binary_logloss: 0.204624\n",
      "[1368]\ttraining's binary_logloss: 0.204601\n",
      "[1369]\ttraining's binary_logloss: 0.20459\n",
      "[1370]\ttraining's binary_logloss: 0.204581\n",
      "[1371]\ttraining's binary_logloss: 0.204554\n",
      "[1372]\ttraining's binary_logloss: 0.20453\n",
      "[1373]\ttraining's binary_logloss: 0.20451\n",
      "[1374]\ttraining's binary_logloss: 0.204488\n",
      "[1375]\ttraining's binary_logloss: 0.204471\n",
      "[1376]\ttraining's binary_logloss: 0.204448\n",
      "[1377]\ttraining's binary_logloss: 0.204427\n",
      "[1378]\ttraining's binary_logloss: 0.204404\n",
      "[1379]\ttraining's binary_logloss: 0.204374\n",
      "[1380]\ttraining's binary_logloss: 0.204353\n",
      "[1381]\ttraining's binary_logloss: 0.204333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1382]\ttraining's binary_logloss: 0.204311\n",
      "[1383]\ttraining's binary_logloss: 0.204289\n",
      "[1384]\ttraining's binary_logloss: 0.204261\n",
      "[1385]\ttraining's binary_logloss: 0.204235\n",
      "[1386]\ttraining's binary_logloss: 0.204214\n",
      "[1387]\ttraining's binary_logloss: 0.204187\n",
      "[1388]\ttraining's binary_logloss: 0.204174\n",
      "[1389]\ttraining's binary_logloss: 0.204149\n",
      "[1390]\ttraining's binary_logloss: 0.204127\n",
      "[1391]\ttraining's binary_logloss: 0.204105\n",
      "[1392]\ttraining's binary_logloss: 0.204084\n",
      "[1393]\ttraining's binary_logloss: 0.204058\n",
      "[1394]\ttraining's binary_logloss: 0.204032\n",
      "[1395]\ttraining's binary_logloss: 0.204011\n",
      "[1396]\ttraining's binary_logloss: 0.203987\n",
      "[1397]\ttraining's binary_logloss: 0.203962\n",
      "[1398]\ttraining's binary_logloss: 0.203941\n",
      "[1399]\ttraining's binary_logloss: 0.203919\n",
      "[1400]\ttraining's binary_logloss: 0.203896\n",
      "[1401]\ttraining's binary_logloss: 0.203876\n",
      "[1402]\ttraining's binary_logloss: 0.203855\n",
      "[1403]\ttraining's binary_logloss: 0.203831\n",
      "[1404]\ttraining's binary_logloss: 0.20381\n",
      "[1405]\ttraining's binary_logloss: 0.203782\n",
      "[1406]\ttraining's binary_logloss: 0.203765\n",
      "[1407]\ttraining's binary_logloss: 0.203743\n",
      "[1408]\ttraining's binary_logloss: 0.203717\n",
      "[1409]\ttraining's binary_logloss: 0.203699\n",
      "[1410]\ttraining's binary_logloss: 0.203678\n",
      "[1411]\ttraining's binary_logloss: 0.203655\n",
      "[1412]\ttraining's binary_logloss: 0.203632\n",
      "[1413]\ttraining's binary_logloss: 0.203609\n",
      "[1414]\ttraining's binary_logloss: 0.203584\n",
      "[1415]\ttraining's binary_logloss: 0.20357\n",
      "[1416]\ttraining's binary_logloss: 0.203552\n",
      "[1417]\ttraining's binary_logloss: 0.203526\n",
      "[1418]\ttraining's binary_logloss: 0.203503\n",
      "[1419]\ttraining's binary_logloss: 0.203481\n",
      "[1420]\ttraining's binary_logloss: 0.203473\n",
      "[1421]\ttraining's binary_logloss: 0.203446\n",
      "[1422]\ttraining's binary_logloss: 0.203424\n",
      "[1423]\ttraining's binary_logloss: 0.203401\n",
      "[1424]\ttraining's binary_logloss: 0.203377\n",
      "[1425]\ttraining's binary_logloss: 0.203372\n",
      "[1426]\ttraining's binary_logloss: 0.203353\n",
      "[1427]\ttraining's binary_logloss: 0.203334\n",
      "[1428]\ttraining's binary_logloss: 0.20331\n",
      "[1429]\ttraining's binary_logloss: 0.203296\n",
      "[1430]\ttraining's binary_logloss: 0.203275\n",
      "[1431]\ttraining's binary_logloss: 0.20325\n",
      "[1432]\ttraining's binary_logloss: 0.203229\n",
      "[1433]\ttraining's binary_logloss: 0.203203\n",
      "[1434]\ttraining's binary_logloss: 0.20319\n",
      "[1435]\ttraining's binary_logloss: 0.203184\n",
      "[1436]\ttraining's binary_logloss: 0.203159\n",
      "[1437]\ttraining's binary_logloss: 0.20314\n",
      "[1438]\ttraining's binary_logloss: 0.203117\n",
      "[1439]\ttraining's binary_logloss: 0.203096\n",
      "[1440]\ttraining's binary_logloss: 0.20307\n",
      "[1441]\ttraining's binary_logloss: 0.203064\n",
      "[1442]\ttraining's binary_logloss: 0.203042\n",
      "[1443]\ttraining's binary_logloss: 0.20302\n",
      "[1444]\ttraining's binary_logloss: 0.202997\n",
      "[1445]\ttraining's binary_logloss: 0.202985\n",
      "[1446]\ttraining's binary_logloss: 0.202959\n",
      "[1447]\ttraining's binary_logloss: 0.202938\n",
      "[1448]\ttraining's binary_logloss: 0.202912\n",
      "[1449]\ttraining's binary_logloss: 0.20289\n",
      "[1450]\ttraining's binary_logloss: 0.202867\n",
      "[1451]\ttraining's binary_logloss: 0.202843\n",
      "[1452]\ttraining's binary_logloss: 0.202823\n",
      "[1453]\ttraining's binary_logloss: 0.202811\n",
      "[1454]\ttraining's binary_logloss: 0.202803\n",
      "[1455]\ttraining's binary_logloss: 0.202778\n",
      "[1456]\ttraining's binary_logloss: 0.202757\n",
      "[1457]\ttraining's binary_logloss: 0.202735\n",
      "[1458]\ttraining's binary_logloss: 0.202712\n",
      "[1459]\ttraining's binary_logloss: 0.202687\n",
      "[1460]\ttraining's binary_logloss: 0.202662\n",
      "[1461]\ttraining's binary_logloss: 0.202649\n",
      "[1462]\ttraining's binary_logloss: 0.202641\n",
      "[1463]\ttraining's binary_logloss: 0.202616\n",
      "[1464]\ttraining's binary_logloss: 0.202597\n",
      "[1465]\ttraining's binary_logloss: 0.202572\n",
      "[1466]\ttraining's binary_logloss: 0.202548\n",
      "[1467]\ttraining's binary_logloss: 0.202523\n",
      "[1468]\ttraining's binary_logloss: 0.202499\n",
      "[1469]\ttraining's binary_logloss: 0.202477\n",
      "[1470]\ttraining's binary_logloss: 0.202467\n",
      "[1471]\ttraining's binary_logloss: 0.202447\n",
      "[1472]\ttraining's binary_logloss: 0.202428\n",
      "[1473]\ttraining's binary_logloss: 0.202419\n",
      "[1474]\ttraining's binary_logloss: 0.202409\n",
      "[1475]\ttraining's binary_logloss: 0.202389\n",
      "[1476]\ttraining's binary_logloss: 0.202368\n",
      "[1477]\ttraining's binary_logloss: 0.202349\n",
      "[1478]\ttraining's binary_logloss: 0.202325\n",
      "[1479]\ttraining's binary_logloss: 0.202303\n",
      "[1480]\ttraining's binary_logloss: 0.20228\n",
      "[1481]\ttraining's binary_logloss: 0.202255\n",
      "[1482]\ttraining's binary_logloss: 0.202233\n",
      "[1483]\ttraining's binary_logloss: 0.202225\n",
      "[1484]\ttraining's binary_logloss: 0.202203\n",
      "[1485]\ttraining's binary_logloss: 0.202179\n",
      "[1486]\ttraining's binary_logloss: 0.202156\n",
      "[1487]\ttraining's binary_logloss: 0.202134\n",
      "[1488]\ttraining's binary_logloss: 0.202105\n",
      "[1489]\ttraining's binary_logloss: 0.202085\n",
      "[1490]\ttraining's binary_logloss: 0.202065\n",
      "[1491]\ttraining's binary_logloss: 0.202042\n",
      "[1492]\ttraining's binary_logloss: 0.202022\n",
      "[1493]\ttraining's binary_logloss: 0.202009\n",
      "[1494]\ttraining's binary_logloss: 0.201995\n",
      "[1495]\ttraining's binary_logloss: 0.201973\n",
      "[1496]\ttraining's binary_logloss: 0.201964\n",
      "[1497]\ttraining's binary_logloss: 0.201942\n",
      "[1498]\ttraining's binary_logloss: 0.201934\n",
      "[1499]\ttraining's binary_logloss: 0.201913\n",
      "[1500]\ttraining's binary_logloss: 0.201901\n",
      "[1501]\ttraining's binary_logloss: 0.201883\n",
      "[1502]\ttraining's binary_logloss: 0.201857\n",
      "[1503]\ttraining's binary_logloss: 0.201834\n",
      "[1504]\ttraining's binary_logloss: 0.201811\n",
      "[1505]\ttraining's binary_logloss: 0.2018\n",
      "[1506]\ttraining's binary_logloss: 0.201781\n",
      "[1507]\ttraining's binary_logloss: 0.201758\n",
      "[1508]\ttraining's binary_logloss: 0.201735\n",
      "[1509]\ttraining's binary_logloss: 0.201711\n",
      "[1510]\ttraining's binary_logloss: 0.20169\n",
      "[1511]\ttraining's binary_logloss: 0.201668\n",
      "[1512]\ttraining's binary_logloss: 0.201648\n",
      "[1513]\ttraining's binary_logloss: 0.201621\n",
      "[1514]\ttraining's binary_logloss: 0.201597\n",
      "[1515]\ttraining's binary_logloss: 0.201575\n",
      "[1516]\ttraining's binary_logloss: 0.201554\n",
      "[1517]\ttraining's binary_logloss: 0.201533\n",
      "[1518]\ttraining's binary_logloss: 0.201528\n",
      "[1519]\ttraining's binary_logloss: 0.20152\n",
      "[1520]\ttraining's binary_logloss: 0.201495\n",
      "[1521]\ttraining's binary_logloss: 0.201466\n",
      "[1522]\ttraining's binary_logloss: 0.201443\n",
      "[1523]\ttraining's binary_logloss: 0.201438\n",
      "[1524]\ttraining's binary_logloss: 0.20142\n",
      "[1525]\ttraining's binary_logloss: 0.2014\n",
      "[1526]\ttraining's binary_logloss: 0.20138\n",
      "[1527]\ttraining's binary_logloss: 0.201364\n",
      "[1528]\ttraining's binary_logloss: 0.201339\n",
      "[1529]\ttraining's binary_logloss: 0.201315\n",
      "[1530]\ttraining's binary_logloss: 0.201302\n",
      "[1531]\ttraining's binary_logloss: 0.201283\n",
      "[1532]\ttraining's binary_logloss: 0.201277\n",
      "[1533]\ttraining's binary_logloss: 0.201255\n",
      "[1534]\ttraining's binary_logloss: 0.201228\n",
      "[1535]\ttraining's binary_logloss: 0.201206\n",
      "[1536]\ttraining's binary_logloss: 0.201184\n",
      "[1537]\ttraining's binary_logloss: 0.201162\n",
      "[1538]\ttraining's binary_logloss: 0.201141\n",
      "[1539]\ttraining's binary_logloss: 0.201128\n",
      "[1540]\ttraining's binary_logloss: 0.201108\n",
      "[1541]\ttraining's binary_logloss: 0.201085\n",
      "[1542]\ttraining's binary_logloss: 0.20106\n",
      "[1543]\ttraining's binary_logloss: 0.20104\n",
      "[1544]\ttraining's binary_logloss: 0.201026\n",
      "[1545]\ttraining's binary_logloss: 0.201009\n",
      "[1546]\ttraining's binary_logloss: 0.200988\n",
      "[1547]\ttraining's binary_logloss: 0.200981\n",
      "[1548]\ttraining's binary_logloss: 0.200958\n",
      "[1549]\ttraining's binary_logloss: 0.200942\n",
      "[1550]\ttraining's binary_logloss: 0.200919\n",
      "[1551]\ttraining's binary_logloss: 0.200894\n",
      "[1552]\ttraining's binary_logloss: 0.200872\n",
      "[1553]\ttraining's binary_logloss: 0.200852\n",
      "[1554]\ttraining's binary_logloss: 0.200828\n",
      "[1555]\ttraining's binary_logloss: 0.200807\n",
      "[1556]\ttraining's binary_logloss: 0.200784\n",
      "[1557]\ttraining's binary_logloss: 0.20076\n",
      "[1558]\ttraining's binary_logloss: 0.200738\n",
      "[1559]\ttraining's binary_logloss: 0.200712\n",
      "[1560]\ttraining's binary_logloss: 0.200689\n",
      "[1561]\ttraining's binary_logloss: 0.200669\n",
      "[1562]\ttraining's binary_logloss: 0.200647\n",
      "[1563]\ttraining's binary_logloss: 0.200625\n",
      "[1564]\ttraining's binary_logloss: 0.200602\n",
      "[1565]\ttraining's binary_logloss: 0.20058\n",
      "[1566]\ttraining's binary_logloss: 0.20057\n",
      "[1567]\ttraining's binary_logloss: 0.200549\n",
      "[1568]\ttraining's binary_logloss: 0.20052\n",
      "[1569]\ttraining's binary_logloss: 0.200495\n",
      "[1570]\ttraining's binary_logloss: 0.200473\n",
      "[1571]\ttraining's binary_logloss: 0.200457\n",
      "[1572]\ttraining's binary_logloss: 0.200435\n",
      "[1573]\ttraining's binary_logloss: 0.200424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1574]\ttraining's binary_logloss: 0.200401\n",
      "[1575]\ttraining's binary_logloss: 0.200374\n",
      "[1576]\ttraining's binary_logloss: 0.200349\n",
      "[1577]\ttraining's binary_logloss: 0.200328\n",
      "[1578]\ttraining's binary_logloss: 0.200308\n",
      "[1579]\ttraining's binary_logloss: 0.200302\n",
      "[1580]\ttraining's binary_logloss: 0.20028\n",
      "[1581]\ttraining's binary_logloss: 0.200256\n",
      "[1582]\ttraining's binary_logloss: 0.200231\n",
      "[1583]\ttraining's binary_logloss: 0.200206\n",
      "[1584]\ttraining's binary_logloss: 0.200187\n",
      "[1585]\ttraining's binary_logloss: 0.20018\n",
      "[1586]\ttraining's binary_logloss: 0.200172\n",
      "[1587]\ttraining's binary_logloss: 0.200166\n",
      "[1588]\ttraining's binary_logloss: 0.200139\n",
      "[1589]\ttraining's binary_logloss: 0.200115\n",
      "[1590]\ttraining's binary_logloss: 0.200094\n",
      "[1591]\ttraining's binary_logloss: 0.200071\n",
      "[1592]\ttraining's binary_logloss: 0.200063\n",
      "[1593]\ttraining's binary_logloss: 0.200039\n",
      "[1594]\ttraining's binary_logloss: 0.200017\n",
      "[1595]\ttraining's binary_logloss: 0.199997\n",
      "[1596]\ttraining's binary_logloss: 0.199973\n",
      "[1597]\ttraining's binary_logloss: 0.199948\n",
      "[1598]\ttraining's binary_logloss: 0.199937\n",
      "[1599]\ttraining's binary_logloss: 0.199924\n",
      "[1600]\ttraining's binary_logloss: 0.199901\n",
      "[1601]\ttraining's binary_logloss: 0.19988\n",
      "[1602]\ttraining's binary_logloss: 0.199857\n",
      "[1603]\ttraining's binary_logloss: 0.199834\n",
      "[1604]\ttraining's binary_logloss: 0.19981\n",
      "[1605]\ttraining's binary_logloss: 0.199794\n",
      "[1606]\ttraining's binary_logloss: 0.199773\n",
      "[1607]\ttraining's binary_logloss: 0.199757\n",
      "[1608]\ttraining's binary_logloss: 0.199734\n",
      "[1609]\ttraining's binary_logloss: 0.199712\n",
      "[1610]\ttraining's binary_logloss: 0.199688\n",
      "[1611]\ttraining's binary_logloss: 0.199668\n",
      "[1612]\ttraining's binary_logloss: 0.199647\n",
      "[1613]\ttraining's binary_logloss: 0.199631\n",
      "[1614]\ttraining's binary_logloss: 0.199607\n",
      "[1615]\ttraining's binary_logloss: 0.199586\n",
      "[1616]\ttraining's binary_logloss: 0.199566\n",
      "[1617]\ttraining's binary_logloss: 0.199544\n",
      "[1618]\ttraining's binary_logloss: 0.199521\n",
      "[1619]\ttraining's binary_logloss: 0.199502\n",
      "[1620]\ttraining's binary_logloss: 0.199477\n",
      "[1621]\ttraining's binary_logloss: 0.199456\n",
      "[1622]\ttraining's binary_logloss: 0.199437\n",
      "[1623]\ttraining's binary_logloss: 0.199421\n",
      "[1624]\ttraining's binary_logloss: 0.1994\n",
      "[1625]\ttraining's binary_logloss: 0.199378\n",
      "[1626]\ttraining's binary_logloss: 0.199368\n",
      "[1627]\ttraining's binary_logloss: 0.199348\n",
      "[1628]\ttraining's binary_logloss: 0.199327\n",
      "[1629]\ttraining's binary_logloss: 0.199303\n",
      "[1630]\ttraining's binary_logloss: 0.199278\n",
      "[1631]\ttraining's binary_logloss: 0.19926\n",
      "[1632]\ttraining's binary_logloss: 0.199236\n",
      "[1633]\ttraining's binary_logloss: 0.199213\n",
      "[1634]\ttraining's binary_logloss: 0.199188\n",
      "[1635]\ttraining's binary_logloss: 0.199168\n",
      "[1636]\ttraining's binary_logloss: 0.199146\n",
      "[1637]\ttraining's binary_logloss: 0.199125\n",
      "[1638]\ttraining's binary_logloss: 0.199109\n",
      "[1639]\ttraining's binary_logloss: 0.199087\n",
      "[1640]\ttraining's binary_logloss: 0.199061\n",
      "[1641]\ttraining's binary_logloss: 0.199039\n",
      "[1642]\ttraining's binary_logloss: 0.199024\n",
      "[1643]\ttraining's binary_logloss: 0.199003\n",
      "[1644]\ttraining's binary_logloss: 0.198986\n",
      "[1645]\ttraining's binary_logloss: 0.198962\n",
      "[1646]\ttraining's binary_logloss: 0.19894\n",
      "[1647]\ttraining's binary_logloss: 0.198918\n",
      "[1648]\ttraining's binary_logloss: 0.198894\n",
      "[1649]\ttraining's binary_logloss: 0.198871\n",
      "[1650]\ttraining's binary_logloss: 0.19885\n",
      "[1651]\ttraining's binary_logloss: 0.198829\n",
      "[1652]\ttraining's binary_logloss: 0.198807\n",
      "[1653]\ttraining's binary_logloss: 0.198795\n",
      "[1654]\ttraining's binary_logloss: 0.198773\n",
      "[1655]\ttraining's binary_logloss: 0.198754\n",
      "[1656]\ttraining's binary_logloss: 0.198732\n",
      "[1657]\ttraining's binary_logloss: 0.19871\n",
      "[1658]\ttraining's binary_logloss: 0.198687\n",
      "[1659]\ttraining's binary_logloss: 0.198665\n",
      "[1660]\ttraining's binary_logloss: 0.198644\n",
      "[1661]\ttraining's binary_logloss: 0.198622\n",
      "[1662]\ttraining's binary_logloss: 0.198601\n",
      "[1663]\ttraining's binary_logloss: 0.19858\n",
      "[1664]\ttraining's binary_logloss: 0.198557\n",
      "[1665]\ttraining's binary_logloss: 0.198539\n",
      "[1666]\ttraining's binary_logloss: 0.198515\n",
      "[1667]\ttraining's binary_logloss: 0.198505\n",
      "[1668]\ttraining's binary_logloss: 0.198497\n",
      "[1669]\ttraining's binary_logloss: 0.198475\n",
      "[1670]\ttraining's binary_logloss: 0.198454\n",
      "[1671]\ttraining's binary_logloss: 0.198433\n",
      "[1672]\ttraining's binary_logloss: 0.198412\n",
      "[1673]\ttraining's binary_logloss: 0.198403\n",
      "[1674]\ttraining's binary_logloss: 0.198379\n",
      "[1675]\ttraining's binary_logloss: 0.198356\n",
      "[1676]\ttraining's binary_logloss: 0.198337\n",
      "[1677]\ttraining's binary_logloss: 0.198315\n",
      "[1678]\ttraining's binary_logloss: 0.198297\n",
      "[1679]\ttraining's binary_logloss: 0.198276\n",
      "[1680]\ttraining's binary_logloss: 0.198269\n",
      "[1681]\ttraining's binary_logloss: 0.198249\n",
      "[1682]\ttraining's binary_logloss: 0.198228\n",
      "[1683]\ttraining's binary_logloss: 0.198205\n",
      "[1684]\ttraining's binary_logloss: 0.19818\n",
      "[1685]\ttraining's binary_logloss: 0.198158\n",
      "[1686]\ttraining's binary_logloss: 0.198139\n",
      "[1687]\ttraining's binary_logloss: 0.198125\n",
      "[1688]\ttraining's binary_logloss: 0.198105\n",
      "[1689]\ttraining's binary_logloss: 0.198084\n",
      "[1690]\ttraining's binary_logloss: 0.19806\n",
      "[1691]\ttraining's binary_logloss: 0.198047\n",
      "[1692]\ttraining's binary_logloss: 0.198025\n",
      "[1693]\ttraining's binary_logloss: 0.198001\n",
      "[1694]\ttraining's binary_logloss: 0.197981\n",
      "[1695]\ttraining's binary_logloss: 0.197959\n",
      "[1696]\ttraining's binary_logloss: 0.197951\n",
      "[1697]\ttraining's binary_logloss: 0.19793\n",
      "[1698]\ttraining's binary_logloss: 0.197923\n",
      "[1699]\ttraining's binary_logloss: 0.197903\n",
      "[1700]\ttraining's binary_logloss: 0.197889\n",
      "[1701]\ttraining's binary_logloss: 0.197866\n",
      "[1702]\ttraining's binary_logloss: 0.197855\n",
      "[1703]\ttraining's binary_logloss: 0.197831\n",
      "[1704]\ttraining's binary_logloss: 0.197808\n",
      "[1705]\ttraining's binary_logloss: 0.197789\n",
      "[1706]\ttraining's binary_logloss: 0.197773\n",
      "[1707]\ttraining's binary_logloss: 0.19775\n",
      "[1708]\ttraining's binary_logloss: 0.197729\n",
      "[1709]\ttraining's binary_logloss: 0.197704\n",
      "[1710]\ttraining's binary_logloss: 0.19768\n",
      "[1711]\ttraining's binary_logloss: 0.197662\n",
      "[1712]\ttraining's binary_logloss: 0.197641\n",
      "[1713]\ttraining's binary_logloss: 0.19762\n",
      "[1714]\ttraining's binary_logloss: 0.1976\n",
      "[1715]\ttraining's binary_logloss: 0.197578\n",
      "[1716]\ttraining's binary_logloss: 0.197563\n",
      "[1717]\ttraining's binary_logloss: 0.19754\n",
      "[1718]\ttraining's binary_logloss: 0.197517\n",
      "[1719]\ttraining's binary_logloss: 0.197503\n",
      "[1720]\ttraining's binary_logloss: 0.19748\n",
      "[1721]\ttraining's binary_logloss: 0.19746\n",
      "[1722]\ttraining's binary_logloss: 0.197436\n",
      "[1723]\ttraining's binary_logloss: 0.19742\n",
      "[1724]\ttraining's binary_logloss: 0.197396\n",
      "[1725]\ttraining's binary_logloss: 0.197375\n",
      "[1726]\ttraining's binary_logloss: 0.197351\n",
      "[1727]\ttraining's binary_logloss: 0.197329\n",
      "[1728]\ttraining's binary_logloss: 0.197308\n",
      "[1729]\ttraining's binary_logloss: 0.197302\n",
      "[1730]\ttraining's binary_logloss: 0.197282\n",
      "[1731]\ttraining's binary_logloss: 0.19726\n",
      "[1732]\ttraining's binary_logloss: 0.197239\n",
      "[1733]\ttraining's binary_logloss: 0.197217\n",
      "[1734]\ttraining's binary_logloss: 0.197198\n",
      "[1735]\ttraining's binary_logloss: 0.197175\n",
      "[1736]\ttraining's binary_logloss: 0.197155\n",
      "[1737]\ttraining's binary_logloss: 0.197132\n",
      "[1738]\ttraining's binary_logloss: 0.19711\n",
      "[1739]\ttraining's binary_logloss: 0.197096\n",
      "[1740]\ttraining's binary_logloss: 0.197074\n",
      "[1741]\ttraining's binary_logloss: 0.197054\n",
      "[1742]\ttraining's binary_logloss: 0.19703\n",
      "[1743]\ttraining's binary_logloss: 0.197009\n",
      "[1744]\ttraining's binary_logloss: 0.196989\n",
      "[1745]\ttraining's binary_logloss: 0.196969\n",
      "[1746]\ttraining's binary_logloss: 0.196948\n",
      "[1747]\ttraining's binary_logloss: 0.196926\n",
      "[1748]\ttraining's binary_logloss: 0.196901\n",
      "[1749]\ttraining's binary_logloss: 0.19688\n",
      "[1750]\ttraining's binary_logloss: 0.196861\n",
      "[1751]\ttraining's binary_logloss: 0.196839\n",
      "[1752]\ttraining's binary_logloss: 0.196819\n",
      "[1753]\ttraining's binary_logloss: 0.196799\n",
      "[1754]\ttraining's binary_logloss: 0.196777\n",
      "[1755]\ttraining's binary_logloss: 0.196758\n",
      "[1756]\ttraining's binary_logloss: 0.196733\n",
      "[1757]\ttraining's binary_logloss: 0.196724\n",
      "[1758]\ttraining's binary_logloss: 0.196702\n",
      "[1759]\ttraining's binary_logloss: 0.19668\n",
      "[1760]\ttraining's binary_logloss: 0.196657\n",
      "[1761]\ttraining's binary_logloss: 0.196638\n",
      "[1762]\ttraining's binary_logloss: 0.196614\n",
      "[1763]\ttraining's binary_logloss: 0.196594\n",
      "[1764]\ttraining's binary_logloss: 0.196572\n",
      "[1765]\ttraining's binary_logloss: 0.196551\n",
      "[1766]\ttraining's binary_logloss: 0.196543\n",
      "[1767]\ttraining's binary_logloss: 0.196522\n",
      "[1768]\ttraining's binary_logloss: 0.196501\n",
      "[1769]\ttraining's binary_logloss: 0.196475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1770]\ttraining's binary_logloss: 0.196455\n",
      "[1771]\ttraining's binary_logloss: 0.196434\n",
      "[1772]\ttraining's binary_logloss: 0.196414\n",
      "[1773]\ttraining's binary_logloss: 0.196395\n",
      "[1774]\ttraining's binary_logloss: 0.196388\n",
      "[1775]\ttraining's binary_logloss: 0.196369\n",
      "[1776]\ttraining's binary_logloss: 0.196348\n",
      "[1777]\ttraining's binary_logloss: 0.196326\n",
      "[1778]\ttraining's binary_logloss: 0.196305\n",
      "[1779]\ttraining's binary_logloss: 0.196286\n",
      "[1780]\ttraining's binary_logloss: 0.196264\n",
      "[1781]\ttraining's binary_logloss: 0.196243\n",
      "[1782]\ttraining's binary_logloss: 0.196224\n",
      "[1783]\ttraining's binary_logloss: 0.196201\n",
      "[1784]\ttraining's binary_logloss: 0.196179\n",
      "[1785]\ttraining's binary_logloss: 0.19616\n",
      "[1786]\ttraining's binary_logloss: 0.196138\n",
      "[1787]\ttraining's binary_logloss: 0.196119\n",
      "[1788]\ttraining's binary_logloss: 0.1961\n",
      "[1789]\ttraining's binary_logloss: 0.19608\n",
      "[1790]\ttraining's binary_logloss: 0.196058\n",
      "[1791]\ttraining's binary_logloss: 0.196039\n",
      "[1792]\ttraining's binary_logloss: 0.196019\n",
      "[1793]\ttraining's binary_logloss: 0.195999\n",
      "[1794]\ttraining's binary_logloss: 0.195976\n",
      "[1795]\ttraining's binary_logloss: 0.195967\n",
      "[1796]\ttraining's binary_logloss: 0.195946\n",
      "[1797]\ttraining's binary_logloss: 0.195925\n",
      "[1798]\ttraining's binary_logloss: 0.195904\n",
      "[1799]\ttraining's binary_logloss: 0.195884\n",
      "[1800]\ttraining's binary_logloss: 0.195865\n",
      "[1801]\ttraining's binary_logloss: 0.195843\n",
      "[1802]\ttraining's binary_logloss: 0.195822\n",
      "[1803]\ttraining's binary_logloss: 0.195795\n",
      "[1804]\ttraining's binary_logloss: 0.195787\n",
      "[1805]\ttraining's binary_logloss: 0.195781\n",
      "[1806]\ttraining's binary_logloss: 0.195758\n",
      "[1807]\ttraining's binary_logloss: 0.195737\n",
      "[1808]\ttraining's binary_logloss: 0.195716\n",
      "[1809]\ttraining's binary_logloss: 0.195697\n",
      "[1810]\ttraining's binary_logloss: 0.195678\n",
      "[1811]\ttraining's binary_logloss: 0.195656\n",
      "[1812]\ttraining's binary_logloss: 0.195633\n",
      "[1813]\ttraining's binary_logloss: 0.195613\n",
      "[1814]\ttraining's binary_logloss: 0.195593\n",
      "[1815]\ttraining's binary_logloss: 0.195573\n",
      "[1816]\ttraining's binary_logloss: 0.195556\n",
      "[1817]\ttraining's binary_logloss: 0.195536\n",
      "[1818]\ttraining's binary_logloss: 0.195511\n",
      "[1819]\ttraining's binary_logloss: 0.19549\n",
      "[1820]\ttraining's binary_logloss: 0.195463\n",
      "[1821]\ttraining's binary_logloss: 0.195438\n",
      "[1822]\ttraining's binary_logloss: 0.195414\n",
      "[1823]\ttraining's binary_logloss: 0.195394\n",
      "[1824]\ttraining's binary_logloss: 0.195374\n",
      "[1825]\ttraining's binary_logloss: 0.195351\n",
      "[1826]\ttraining's binary_logloss: 0.195338\n",
      "[1827]\ttraining's binary_logloss: 0.195319\n",
      "[1828]\ttraining's binary_logloss: 0.195309\n",
      "[1829]\ttraining's binary_logloss: 0.195287\n",
      "[1830]\ttraining's binary_logloss: 0.195269\n",
      "[1831]\ttraining's binary_logloss: 0.195249\n",
      "[1832]\ttraining's binary_logloss: 0.195231\n",
      "[1833]\ttraining's binary_logloss: 0.195207\n",
      "[1834]\ttraining's binary_logloss: 0.195195\n",
      "[1835]\ttraining's binary_logloss: 0.195172\n",
      "[1836]\ttraining's binary_logloss: 0.195147\n",
      "[1837]\ttraining's binary_logloss: 0.195126\n",
      "[1838]\ttraining's binary_logloss: 0.195105\n",
      "[1839]\ttraining's binary_logloss: 0.195084\n",
      "[1840]\ttraining's binary_logloss: 0.19506\n",
      "[1841]\ttraining's binary_logloss: 0.195055\n",
      "[1842]\ttraining's binary_logloss: 0.195035\n",
      "[1843]\ttraining's binary_logloss: 0.195014\n",
      "[1844]\ttraining's binary_logloss: 0.194993\n",
      "[1845]\ttraining's binary_logloss: 0.194971\n",
      "[1846]\ttraining's binary_logloss: 0.194947\n",
      "[1847]\ttraining's binary_logloss: 0.194925\n",
      "[1848]\ttraining's binary_logloss: 0.194904\n",
      "[1849]\ttraining's binary_logloss: 0.194884\n",
      "[1850]\ttraining's binary_logloss: 0.194863\n",
      "[1851]\ttraining's binary_logloss: 0.194841\n",
      "[1852]\ttraining's binary_logloss: 0.194834\n",
      "[1853]\ttraining's binary_logloss: 0.194816\n",
      "[1854]\ttraining's binary_logloss: 0.194798\n",
      "[1855]\ttraining's binary_logloss: 0.194775\n",
      "[1856]\ttraining's binary_logloss: 0.194755\n",
      "[1857]\ttraining's binary_logloss: 0.194736\n",
      "[1858]\ttraining's binary_logloss: 0.19473\n",
      "[1859]\ttraining's binary_logloss: 0.194713\n",
      "[1860]\ttraining's binary_logloss: 0.194706\n",
      "[1861]\ttraining's binary_logloss: 0.194697\n",
      "[1862]\ttraining's binary_logloss: 0.194675\n",
      "[1863]\ttraining's binary_logloss: 0.194666\n",
      "[1864]\ttraining's binary_logloss: 0.194648\n",
      "[1865]\ttraining's binary_logloss: 0.194628\n",
      "[1866]\ttraining's binary_logloss: 0.194607\n",
      "[1867]\ttraining's binary_logloss: 0.194584\n",
      "[1868]\ttraining's binary_logloss: 0.194565\n",
      "[1869]\ttraining's binary_logloss: 0.194545\n",
      "[1870]\ttraining's binary_logloss: 0.194525\n",
      "[1871]\ttraining's binary_logloss: 0.194505\n",
      "[1872]\ttraining's binary_logloss: 0.194499\n",
      "[1873]\ttraining's binary_logloss: 0.194478\n",
      "[1874]\ttraining's binary_logloss: 0.194454\n",
      "[1875]\ttraining's binary_logloss: 0.194433\n",
      "[1876]\ttraining's binary_logloss: 0.194427\n",
      "[1877]\ttraining's binary_logloss: 0.194415\n",
      "[1878]\ttraining's binary_logloss: 0.194409\n",
      "[1879]\ttraining's binary_logloss: 0.194399\n",
      "[1880]\ttraining's binary_logloss: 0.194379\n",
      "[1881]\ttraining's binary_logloss: 0.194375\n",
      "[1882]\ttraining's binary_logloss: 0.194353\n",
      "[1883]\ttraining's binary_logloss: 0.194332\n",
      "[1884]\ttraining's binary_logloss: 0.194308\n",
      "[1885]\ttraining's binary_logloss: 0.194288\n",
      "[1886]\ttraining's binary_logloss: 0.194283\n",
      "[1887]\ttraining's binary_logloss: 0.194261\n",
      "[1888]\ttraining's binary_logloss: 0.19424\n",
      "[1889]\ttraining's binary_logloss: 0.194221\n",
      "[1890]\ttraining's binary_logloss: 0.194199\n",
      "[1891]\ttraining's binary_logloss: 0.194177\n",
      "[1892]\ttraining's binary_logloss: 0.194168\n",
      "[1893]\ttraining's binary_logloss: 0.194154\n",
      "[1894]\ttraining's binary_logloss: 0.194132\n",
      "[1895]\ttraining's binary_logloss: 0.194112\n",
      "[1896]\ttraining's binary_logloss: 0.194106\n",
      "[1897]\ttraining's binary_logloss: 0.194084\n",
      "[1898]\ttraining's binary_logloss: 0.194065\n",
      "[1899]\ttraining's binary_logloss: 0.194045\n",
      "[1900]\ttraining's binary_logloss: 0.194029\n",
      "[1901]\ttraining's binary_logloss: 0.194008\n",
      "[1902]\ttraining's binary_logloss: 0.193986\n",
      "[1903]\ttraining's binary_logloss: 0.193968\n",
      "[1904]\ttraining's binary_logloss: 0.193961\n",
      "[1905]\ttraining's binary_logloss: 0.193949\n",
      "[1906]\ttraining's binary_logloss: 0.19393\n",
      "[1907]\ttraining's binary_logloss: 0.193925\n",
      "[1908]\ttraining's binary_logloss: 0.193907\n",
      "[1909]\ttraining's binary_logloss: 0.193887\n",
      "[1910]\ttraining's binary_logloss: 0.193865\n",
      "[1911]\ttraining's binary_logloss: 0.193851\n",
      "[1912]\ttraining's binary_logloss: 0.193832\n",
      "[1913]\ttraining's binary_logloss: 0.193805\n",
      "[1914]\ttraining's binary_logloss: 0.193782\n",
      "[1915]\ttraining's binary_logloss: 0.193772\n",
      "[1916]\ttraining's binary_logloss: 0.193757\n",
      "[1917]\ttraining's binary_logloss: 0.193733\n",
      "[1918]\ttraining's binary_logloss: 0.193714\n",
      "[1919]\ttraining's binary_logloss: 0.193694\n",
      "[1920]\ttraining's binary_logloss: 0.193675\n",
      "[1921]\ttraining's binary_logloss: 0.193652\n",
      "[1922]\ttraining's binary_logloss: 0.19363\n",
      "[1923]\ttraining's binary_logloss: 0.193609\n",
      "[1924]\ttraining's binary_logloss: 0.193595\n",
      "[1925]\ttraining's binary_logloss: 0.193584\n",
      "[1926]\ttraining's binary_logloss: 0.193577\n",
      "[1927]\ttraining's binary_logloss: 0.193564\n",
      "[1928]\ttraining's binary_logloss: 0.193544\n",
      "[1929]\ttraining's binary_logloss: 0.193522\n",
      "[1930]\ttraining's binary_logloss: 0.19352\n",
      "[1931]\ttraining's binary_logloss: 0.193501\n",
      "[1932]\ttraining's binary_logloss: 0.19348\n",
      "[1933]\ttraining's binary_logloss: 0.193459\n",
      "[1934]\ttraining's binary_logloss: 0.193448\n",
      "[1935]\ttraining's binary_logloss: 0.193437\n",
      "[1936]\ttraining's binary_logloss: 0.193418\n",
      "[1937]\ttraining's binary_logloss: 0.1934\n",
      "[1938]\ttraining's binary_logloss: 0.193375\n",
      "[1939]\ttraining's binary_logloss: 0.193354\n",
      "[1940]\ttraining's binary_logloss: 0.193332\n",
      "[1941]\ttraining's binary_logloss: 0.193315\n",
      "[1942]\ttraining's binary_logloss: 0.193294\n",
      "[1943]\ttraining's binary_logloss: 0.193271\n",
      "[1944]\ttraining's binary_logloss: 0.19325\n",
      "[1945]\ttraining's binary_logloss: 0.193232\n",
      "[1946]\ttraining's binary_logloss: 0.19321\n",
      "[1947]\ttraining's binary_logloss: 0.193189\n",
      "[1948]\ttraining's binary_logloss: 0.193171\n",
      "[1949]\ttraining's binary_logloss: 0.193149\n",
      "[1950]\ttraining's binary_logloss: 0.193131\n",
      "[1951]\ttraining's binary_logloss: 0.193107\n",
      "[1952]\ttraining's binary_logloss: 0.193093\n",
      "[1953]\ttraining's binary_logloss: 0.193074\n",
      "[1954]\ttraining's binary_logloss: 0.193052\n",
      "[1955]\ttraining's binary_logloss: 0.193033\n",
      "[1956]\ttraining's binary_logloss: 0.193014\n",
      "[1957]\ttraining's binary_logloss: 0.193\n",
      "[1958]\ttraining's binary_logloss: 0.19298\n",
      "[1959]\ttraining's binary_logloss: 0.192961\n",
      "[1960]\ttraining's binary_logloss: 0.192959\n",
      "[1961]\ttraining's binary_logloss: 0.192939\n",
      "[1962]\ttraining's binary_logloss: 0.192921\n",
      "[1963]\ttraining's binary_logloss: 0.192896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1964]\ttraining's binary_logloss: 0.192876\n",
      "[1965]\ttraining's binary_logloss: 0.192856\n",
      "[1966]\ttraining's binary_logloss: 0.192837\n",
      "[1967]\ttraining's binary_logloss: 0.192818\n",
      "[1968]\ttraining's binary_logloss: 0.192798\n",
      "[1969]\ttraining's binary_logloss: 0.192775\n",
      "[1970]\ttraining's binary_logloss: 0.192752\n",
      "[1971]\ttraining's binary_logloss: 0.192735\n",
      "[1972]\ttraining's binary_logloss: 0.192715\n",
      "[1973]\ttraining's binary_logloss: 0.192692\n",
      "[1974]\ttraining's binary_logloss: 0.192671\n",
      "[1975]\ttraining's binary_logloss: 0.192649\n",
      "[1976]\ttraining's binary_logloss: 0.192627\n",
      "[1977]\ttraining's binary_logloss: 0.192608\n",
      "[1978]\ttraining's binary_logloss: 0.192589\n",
      "[1979]\ttraining's binary_logloss: 0.192566\n",
      "[1980]\ttraining's binary_logloss: 0.192548\n",
      "[1981]\ttraining's binary_logloss: 0.192538\n",
      "[1982]\ttraining's binary_logloss: 0.192516\n",
      "[1983]\ttraining's binary_logloss: 0.192499\n",
      "[1984]\ttraining's binary_logloss: 0.192477\n",
      "[1985]\ttraining's binary_logloss: 0.192465\n",
      "[1986]\ttraining's binary_logloss: 0.192456\n",
      "[1987]\ttraining's binary_logloss: 0.192437\n",
      "[1988]\ttraining's binary_logloss: 0.192417\n",
      "[1989]\ttraining's binary_logloss: 0.192397\n",
      "[1990]\ttraining's binary_logloss: 0.192394\n",
      "[1991]\ttraining's binary_logloss: 0.192372\n",
      "[1992]\ttraining's binary_logloss: 0.192353\n",
      "[1993]\ttraining's binary_logloss: 0.192331\n",
      "[1994]\ttraining's binary_logloss: 0.192309\n",
      "[1995]\ttraining's binary_logloss: 0.192288\n",
      "[1996]\ttraining's binary_logloss: 0.192267\n",
      "[1997]\ttraining's binary_logloss: 0.192245\n",
      "[1998]\ttraining's binary_logloss: 0.192225\n",
      "[1999]\ttraining's binary_logloss: 0.192205\n",
      "[2000]\ttraining's binary_logloss: 0.192184\n",
      "[2001]\ttraining's binary_logloss: 0.192166\n",
      "[2002]\ttraining's binary_logloss: 0.19214\n",
      "[2003]\ttraining's binary_logloss: 0.192119\n",
      "[2004]\ttraining's binary_logloss: 0.192096\n",
      "[2005]\ttraining's binary_logloss: 0.19208\n",
      "[2006]\ttraining's binary_logloss: 0.192075\n",
      "[2007]\ttraining's binary_logloss: 0.192066\n",
      "[2008]\ttraining's binary_logloss: 0.192047\n",
      "[2009]\ttraining's binary_logloss: 0.192029\n",
      "[2010]\ttraining's binary_logloss: 0.192004\n",
      "[2011]\ttraining's binary_logloss: 0.191981\n",
      "[2012]\ttraining's binary_logloss: 0.191959\n",
      "[2013]\ttraining's binary_logloss: 0.19194\n",
      "[2014]\ttraining's binary_logloss: 0.191919\n",
      "[2015]\ttraining's binary_logloss: 0.191896\n",
      "[2016]\ttraining's binary_logloss: 0.191873\n",
      "[2017]\ttraining's binary_logloss: 0.191853\n",
      "[2018]\ttraining's binary_logloss: 0.191834\n",
      "[2019]\ttraining's binary_logloss: 0.191815\n",
      "[2020]\ttraining's binary_logloss: 0.191796\n",
      "[2021]\ttraining's binary_logloss: 0.191773\n",
      "[2022]\ttraining's binary_logloss: 0.191756\n",
      "[2023]\ttraining's binary_logloss: 0.191737\n",
      "[2024]\ttraining's binary_logloss: 0.191719\n",
      "[2025]\ttraining's binary_logloss: 0.191699\n",
      "[2026]\ttraining's binary_logloss: 0.191685\n",
      "[2027]\ttraining's binary_logloss: 0.191666\n",
      "[2028]\ttraining's binary_logloss: 0.191644\n",
      "[2029]\ttraining's binary_logloss: 0.191624\n",
      "[2030]\ttraining's binary_logloss: 0.191602\n",
      "[2031]\ttraining's binary_logloss: 0.191587\n",
      "[2032]\ttraining's binary_logloss: 0.191567\n",
      "[2033]\ttraining's binary_logloss: 0.191547\n",
      "[2034]\ttraining's binary_logloss: 0.191525\n",
      "[2035]\ttraining's binary_logloss: 0.191507\n",
      "[2036]\ttraining's binary_logloss: 0.191487\n",
      "[2037]\ttraining's binary_logloss: 0.191464\n",
      "[2038]\ttraining's binary_logloss: 0.191443\n",
      "[2039]\ttraining's binary_logloss: 0.191424\n",
      "[2040]\ttraining's binary_logloss: 0.191403\n",
      "[2041]\ttraining's binary_logloss: 0.19139\n",
      "[2042]\ttraining's binary_logloss: 0.191371\n",
      "[2043]\ttraining's binary_logloss: 0.191353\n",
      "[2044]\ttraining's binary_logloss: 0.191334\n",
      "[2045]\ttraining's binary_logloss: 0.191315\n",
      "[2046]\ttraining's binary_logloss: 0.191296\n",
      "[2047]\ttraining's binary_logloss: 0.191276\n",
      "[2048]\ttraining's binary_logloss: 0.191272\n",
      "[2049]\ttraining's binary_logloss: 0.191257\n",
      "[2050]\ttraining's binary_logloss: 0.191237\n",
      "[2051]\ttraining's binary_logloss: 0.191221\n",
      "[2052]\ttraining's binary_logloss: 0.191209\n",
      "[2053]\ttraining's binary_logloss: 0.191185\n",
      "[2054]\ttraining's binary_logloss: 0.191166\n",
      "[2055]\ttraining's binary_logloss: 0.191155\n",
      "[2056]\ttraining's binary_logloss: 0.191133\n",
      "[2057]\ttraining's binary_logloss: 0.191112\n",
      "[2058]\ttraining's binary_logloss: 0.191101\n",
      "[2059]\ttraining's binary_logloss: 0.191079\n",
      "[2060]\ttraining's binary_logloss: 0.191064\n",
      "[2061]\ttraining's binary_logloss: 0.191051\n",
      "[2062]\ttraining's binary_logloss: 0.191028\n",
      "[2063]\ttraining's binary_logloss: 0.191006\n",
      "[2064]\ttraining's binary_logloss: 0.190989\n",
      "[2065]\ttraining's binary_logloss: 0.19097\n",
      "[2066]\ttraining's binary_logloss: 0.19095\n",
      "[2067]\ttraining's binary_logloss: 0.190927\n",
      "[2068]\ttraining's binary_logloss: 0.190908\n",
      "[2069]\ttraining's binary_logloss: 0.190887\n",
      "[2070]\ttraining's binary_logloss: 0.190869\n",
      "[2071]\ttraining's binary_logloss: 0.19085\n",
      "[2072]\ttraining's binary_logloss: 0.190829\n",
      "[2073]\ttraining's binary_logloss: 0.190806\n",
      "[2074]\ttraining's binary_logloss: 0.190787\n",
      "[2075]\ttraining's binary_logloss: 0.190762\n",
      "[2076]\ttraining's binary_logloss: 0.190746\n",
      "[2077]\ttraining's binary_logloss: 0.190723\n",
      "[2078]\ttraining's binary_logloss: 0.190704\n",
      "[2079]\ttraining's binary_logloss: 0.190684\n",
      "[2080]\ttraining's binary_logloss: 0.19066\n",
      "[2081]\ttraining's binary_logloss: 0.190646\n",
      "[2082]\ttraining's binary_logloss: 0.190636\n",
      "[2083]\ttraining's binary_logloss: 0.190612\n",
      "[2084]\ttraining's binary_logloss: 0.190591\n",
      "[2085]\ttraining's binary_logloss: 0.19057\n",
      "[2086]\ttraining's binary_logloss: 0.190551\n",
      "[2087]\ttraining's binary_logloss: 0.190532\n",
      "[2088]\ttraining's binary_logloss: 0.19051\n",
      "[2089]\ttraining's binary_logloss: 0.190487\n",
      "[2090]\ttraining's binary_logloss: 0.190462\n",
      "[2091]\ttraining's binary_logloss: 0.190444\n",
      "[2092]\ttraining's binary_logloss: 0.190424\n",
      "[2093]\ttraining's binary_logloss: 0.190406\n",
      "[2094]\ttraining's binary_logloss: 0.190383\n",
      "[2095]\ttraining's binary_logloss: 0.190369\n",
      "[2096]\ttraining's binary_logloss: 0.19035\n",
      "[2097]\ttraining's binary_logloss: 0.190326\n",
      "[2098]\ttraining's binary_logloss: 0.190308\n",
      "[2099]\ttraining's binary_logloss: 0.190287\n",
      "[2100]\ttraining's binary_logloss: 0.190266\n",
      "[2101]\ttraining's binary_logloss: 0.190242\n",
      "[2102]\ttraining's binary_logloss: 0.19022\n",
      "[2103]\ttraining's binary_logloss: 0.190219\n",
      "[2104]\ttraining's binary_logloss: 0.190192\n",
      "[2105]\ttraining's binary_logloss: 0.190172\n",
      "[2106]\ttraining's binary_logloss: 0.190149\n",
      "[2107]\ttraining's binary_logloss: 0.190128\n",
      "[2108]\ttraining's binary_logloss: 0.190119\n",
      "[2109]\ttraining's binary_logloss: 0.190098\n",
      "[2110]\ttraining's binary_logloss: 0.190081\n",
      "[2111]\ttraining's binary_logloss: 0.190057\n",
      "[2112]\ttraining's binary_logloss: 0.190039\n",
      "[2113]\ttraining's binary_logloss: 0.190017\n",
      "[2114]\ttraining's binary_logloss: 0.189997\n",
      "[2115]\ttraining's binary_logloss: 0.189978\n",
      "[2116]\ttraining's binary_logloss: 0.189958\n",
      "[2117]\ttraining's binary_logloss: 0.189935\n",
      "[2118]\ttraining's binary_logloss: 0.189916\n",
      "[2119]\ttraining's binary_logloss: 0.189898\n",
      "[2120]\ttraining's binary_logloss: 0.189876\n",
      "[2121]\ttraining's binary_logloss: 0.189854\n",
      "[2122]\ttraining's binary_logloss: 0.189832\n",
      "[2123]\ttraining's binary_logloss: 0.189813\n",
      "[2124]\ttraining's binary_logloss: 0.189793\n",
      "[2125]\ttraining's binary_logloss: 0.189772\n",
      "[2126]\ttraining's binary_logloss: 0.189757\n",
      "[2127]\ttraining's binary_logloss: 0.189739\n",
      "[2128]\ttraining's binary_logloss: 0.189718\n",
      "[2129]\ttraining's binary_logloss: 0.189698\n",
      "[2130]\ttraining's binary_logloss: 0.189679\n",
      "[2131]\ttraining's binary_logloss: 0.18967\n",
      "[2132]\ttraining's binary_logloss: 0.189664\n",
      "[2133]\ttraining's binary_logloss: 0.189642\n",
      "[2134]\ttraining's binary_logloss: 0.18962\n",
      "[2135]\ttraining's binary_logloss: 0.189599\n",
      "[2136]\ttraining's binary_logloss: 0.189579\n",
      "[2137]\ttraining's binary_logloss: 0.189557\n",
      "[2138]\ttraining's binary_logloss: 0.189537\n",
      "[2139]\ttraining's binary_logloss: 0.189519\n",
      "[2140]\ttraining's binary_logloss: 0.189515\n",
      "[2141]\ttraining's binary_logloss: 0.189498\n",
      "[2142]\ttraining's binary_logloss: 0.18948\n",
      "[2143]\ttraining's binary_logloss: 0.189462\n",
      "[2144]\ttraining's binary_logloss: 0.189455\n",
      "[2145]\ttraining's binary_logloss: 0.189439\n",
      "[2146]\ttraining's binary_logloss: 0.189421\n",
      "[2147]\ttraining's binary_logloss: 0.189404\n",
      "[2148]\ttraining's binary_logloss: 0.189383\n",
      "[2149]\ttraining's binary_logloss: 0.189361\n",
      "[2150]\ttraining's binary_logloss: 0.189346\n",
      "[2151]\ttraining's binary_logloss: 0.189327\n",
      "[2152]\ttraining's binary_logloss: 0.189308\n",
      "[2153]\ttraining's binary_logloss: 0.189288\n",
      "[2154]\ttraining's binary_logloss: 0.189268\n",
      "[2155]\ttraining's binary_logloss: 0.189249\n",
      "[2156]\ttraining's binary_logloss: 0.18923\n",
      "[2157]\ttraining's binary_logloss: 0.189211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2158]\ttraining's binary_logloss: 0.189191\n",
      "[2159]\ttraining's binary_logloss: 0.189172\n",
      "[2160]\ttraining's binary_logloss: 0.189152\n",
      "[2161]\ttraining's binary_logloss: 0.189135\n",
      "[2162]\ttraining's binary_logloss: 0.189118\n",
      "[2163]\ttraining's binary_logloss: 0.189098\n",
      "[2164]\ttraining's binary_logloss: 0.189079\n",
      "[2165]\ttraining's binary_logloss: 0.18906\n",
      "[2166]\ttraining's binary_logloss: 0.189039\n",
      "[2167]\ttraining's binary_logloss: 0.189019\n",
      "[2168]\ttraining's binary_logloss: 0.189\n",
      "[2169]\ttraining's binary_logloss: 0.188979\n",
      "[2170]\ttraining's binary_logloss: 0.188961\n",
      "[2171]\ttraining's binary_logloss: 0.188957\n",
      "[2172]\ttraining's binary_logloss: 0.188938\n",
      "[2173]\ttraining's binary_logloss: 0.188917\n",
      "[2174]\ttraining's binary_logloss: 0.188897\n",
      "[2175]\ttraining's binary_logloss: 0.188877\n",
      "[2176]\ttraining's binary_logloss: 0.188855\n",
      "[2177]\ttraining's binary_logloss: 0.188835\n",
      "[2178]\ttraining's binary_logloss: 0.188823\n",
      "[2179]\ttraining's binary_logloss: 0.188806\n",
      "[2180]\ttraining's binary_logloss: 0.188784\n",
      "[2181]\ttraining's binary_logloss: 0.188763\n",
      "[2182]\ttraining's binary_logloss: 0.18874\n",
      "[2183]\ttraining's binary_logloss: 0.18872\n",
      "[2184]\ttraining's binary_logloss: 0.188702\n",
      "[2185]\ttraining's binary_logloss: 0.188684\n",
      "[2186]\ttraining's binary_logloss: 0.188665\n",
      "[2187]\ttraining's binary_logloss: 0.188646\n",
      "[2188]\ttraining's binary_logloss: 0.188626\n",
      "[2189]\ttraining's binary_logloss: 0.188607\n",
      "[2190]\ttraining's binary_logloss: 0.188583\n",
      "[2191]\ttraining's binary_logloss: 0.188565\n",
      "[2192]\ttraining's binary_logloss: 0.188544\n",
      "[2193]\ttraining's binary_logloss: 0.188534\n",
      "[2194]\ttraining's binary_logloss: 0.188521\n",
      "[2195]\ttraining's binary_logloss: 0.188501\n",
      "[2196]\ttraining's binary_logloss: 0.188481\n",
      "[2197]\ttraining's binary_logloss: 0.188457\n",
      "[2198]\ttraining's binary_logloss: 0.18844\n",
      "[2199]\ttraining's binary_logloss: 0.188436\n",
      "[2200]\ttraining's binary_logloss: 0.18842\n",
      "[2201]\ttraining's binary_logloss: 0.188398\n",
      "[2202]\ttraining's binary_logloss: 0.188376\n",
      "[2203]\ttraining's binary_logloss: 0.188358\n",
      "[2204]\ttraining's binary_logloss: 0.188336\n",
      "[2205]\ttraining's binary_logloss: 0.188316\n",
      "[2206]\ttraining's binary_logloss: 0.188296\n",
      "[2207]\ttraining's binary_logloss: 0.188274\n",
      "[2208]\ttraining's binary_logloss: 0.188254\n",
      "[2209]\ttraining's binary_logloss: 0.188231\n",
      "[2210]\ttraining's binary_logloss: 0.188212\n",
      "[2211]\ttraining's binary_logloss: 0.188191\n",
      "[2212]\ttraining's binary_logloss: 0.188187\n",
      "[2213]\ttraining's binary_logloss: 0.188165\n",
      "[2214]\ttraining's binary_logloss: 0.188144\n",
      "[2215]\ttraining's binary_logloss: 0.188121\n",
      "[2216]\ttraining's binary_logloss: 0.1881\n",
      "[2217]\ttraining's binary_logloss: 0.188078\n",
      "[2218]\ttraining's binary_logloss: 0.188057\n",
      "[2219]\ttraining's binary_logloss: 0.188037\n",
      "[2220]\ttraining's binary_logloss: 0.188014\n",
      "[2221]\ttraining's binary_logloss: 0.187993\n",
      "[2222]\ttraining's binary_logloss: 0.18797\n",
      "[2223]\ttraining's binary_logloss: 0.187952\n",
      "[2224]\ttraining's binary_logloss: 0.187947\n",
      "[2225]\ttraining's binary_logloss: 0.187927\n",
      "[2226]\ttraining's binary_logloss: 0.187909\n",
      "[2227]\ttraining's binary_logloss: 0.187891\n",
      "[2228]\ttraining's binary_logloss: 0.18787\n",
      "[2229]\ttraining's binary_logloss: 0.187858\n",
      "[2230]\ttraining's binary_logloss: 0.187839\n",
      "[2231]\ttraining's binary_logloss: 0.187821\n",
      "[2232]\ttraining's binary_logloss: 0.1878\n",
      "[2233]\ttraining's binary_logloss: 0.187781\n",
      "[2234]\ttraining's binary_logloss: 0.18776\n",
      "[2235]\ttraining's binary_logloss: 0.18774\n",
      "[2236]\ttraining's binary_logloss: 0.18772\n",
      "[2237]\ttraining's binary_logloss: 0.187702\n",
      "[2238]\ttraining's binary_logloss: 0.187678\n",
      "[2239]\ttraining's binary_logloss: 0.187657\n",
      "[2240]\ttraining's binary_logloss: 0.187634\n",
      "[2241]\ttraining's binary_logloss: 0.187619\n",
      "[2242]\ttraining's binary_logloss: 0.1876\n",
      "[2243]\ttraining's binary_logloss: 0.18758\n",
      "[2244]\ttraining's binary_logloss: 0.187559\n",
      "[2245]\ttraining's binary_logloss: 0.18754\n",
      "[2246]\ttraining's binary_logloss: 0.187517\n",
      "[2247]\ttraining's binary_logloss: 0.187505\n",
      "[2248]\ttraining's binary_logloss: 0.187487\n",
      "[2249]\ttraining's binary_logloss: 0.187473\n",
      "[2250]\ttraining's binary_logloss: 0.187452\n",
      "[2251]\ttraining's binary_logloss: 0.187434\n",
      "[2252]\ttraining's binary_logloss: 0.187424\n",
      "[2253]\ttraining's binary_logloss: 0.187401\n",
      "[2254]\ttraining's binary_logloss: 0.18738\n",
      "[2255]\ttraining's binary_logloss: 0.187358\n",
      "[2256]\ttraining's binary_logloss: 0.187337\n",
      "[2257]\ttraining's binary_logloss: 0.187331\n",
      "[2258]\ttraining's binary_logloss: 0.187318\n",
      "[2259]\ttraining's binary_logloss: 0.1873\n",
      "[2260]\ttraining's binary_logloss: 0.187281\n",
      "[2261]\ttraining's binary_logloss: 0.18726\n",
      "[2262]\ttraining's binary_logloss: 0.187239\n",
      "[2263]\ttraining's binary_logloss: 0.187217\n",
      "[2264]\ttraining's binary_logloss: 0.187206\n",
      "[2265]\ttraining's binary_logloss: 0.187184\n",
      "[2266]\ttraining's binary_logloss: 0.187164\n",
      "[2267]\ttraining's binary_logloss: 0.187143\n",
      "[2268]\ttraining's binary_logloss: 0.187124\n",
      "[2269]\ttraining's binary_logloss: 0.187104\n",
      "[2270]\ttraining's binary_logloss: 0.187083\n",
      "[2271]\ttraining's binary_logloss: 0.187064\n",
      "[2272]\ttraining's binary_logloss: 0.187045\n",
      "[2273]\ttraining's binary_logloss: 0.187024\n",
      "[2274]\ttraining's binary_logloss: 0.187004\n",
      "[2275]\ttraining's binary_logloss: 0.186982\n",
      "[2276]\ttraining's binary_logloss: 0.186965\n",
      "[2277]\ttraining's binary_logloss: 0.18696\n",
      "[2278]\ttraining's binary_logloss: 0.18695\n",
      "[2279]\ttraining's binary_logloss: 0.186932\n",
      "[2280]\ttraining's binary_logloss: 0.186914\n",
      "[2281]\ttraining's binary_logloss: 0.186894\n",
      "[2282]\ttraining's binary_logloss: 0.186884\n",
      "[2283]\ttraining's binary_logloss: 0.186866\n",
      "[2284]\ttraining's binary_logloss: 0.186846\n",
      "[2285]\ttraining's binary_logloss: 0.186827\n",
      "[2286]\ttraining's binary_logloss: 0.186818\n",
      "[2287]\ttraining's binary_logloss: 0.186799\n",
      "[2288]\ttraining's binary_logloss: 0.186778\n",
      "[2289]\ttraining's binary_logloss: 0.186765\n",
      "[2290]\ttraining's binary_logloss: 0.186747\n",
      "[2291]\ttraining's binary_logloss: 0.186734\n",
      "[2292]\ttraining's binary_logloss: 0.186715\n",
      "[2293]\ttraining's binary_logloss: 0.186694\n",
      "[2294]\ttraining's binary_logloss: 0.18667\n",
      "[2295]\ttraining's binary_logloss: 0.18665\n",
      "[2296]\ttraining's binary_logloss: 0.186626\n",
      "[2297]\ttraining's binary_logloss: 0.186606\n",
      "[2298]\ttraining's binary_logloss: 0.186587\n",
      "[2299]\ttraining's binary_logloss: 0.186568\n",
      "[2300]\ttraining's binary_logloss: 0.186548\n",
      "[2301]\ttraining's binary_logloss: 0.18653\n",
      "[2302]\ttraining's binary_logloss: 0.186509\n",
      "[2303]\ttraining's binary_logloss: 0.186494\n",
      "[2304]\ttraining's binary_logloss: 0.18648\n",
      "[2305]\ttraining's binary_logloss: 0.186468\n",
      "[2306]\ttraining's binary_logloss: 0.186447\n",
      "[2307]\ttraining's binary_logloss: 0.186429\n",
      "[2308]\ttraining's binary_logloss: 0.186411\n",
      "[2309]\ttraining's binary_logloss: 0.186391\n",
      "[2310]\ttraining's binary_logloss: 0.186372\n",
      "[2311]\ttraining's binary_logloss: 0.186353\n",
      "[2312]\ttraining's binary_logloss: 0.186333\n",
      "[2313]\ttraining's binary_logloss: 0.186313\n",
      "[2314]\ttraining's binary_logloss: 0.186291\n",
      "[2315]\ttraining's binary_logloss: 0.186273\n",
      "[2316]\ttraining's binary_logloss: 0.186252\n",
      "[2317]\ttraining's binary_logloss: 0.186228\n",
      "[2318]\ttraining's binary_logloss: 0.186207\n",
      "[2319]\ttraining's binary_logloss: 0.186191\n",
      "[2320]\ttraining's binary_logloss: 0.186173\n",
      "[2321]\ttraining's binary_logloss: 0.186153\n",
      "[2322]\ttraining's binary_logloss: 0.186133\n",
      "[2323]\ttraining's binary_logloss: 0.186112\n",
      "[2324]\ttraining's binary_logloss: 0.186092\n",
      "[2325]\ttraining's binary_logloss: 0.186073\n",
      "[2326]\ttraining's binary_logloss: 0.18605\n",
      "[2327]\ttraining's binary_logloss: 0.18603\n",
      "[2328]\ttraining's binary_logloss: 0.186012\n",
      "[2329]\ttraining's binary_logloss: 0.18599\n",
      "[2330]\ttraining's binary_logloss: 0.18597\n",
      "[2331]\ttraining's binary_logloss: 0.185951\n",
      "[2332]\ttraining's binary_logloss: 0.185932\n",
      "[2333]\ttraining's binary_logloss: 0.185915\n",
      "[2334]\ttraining's binary_logloss: 0.185893\n",
      "[2335]\ttraining's binary_logloss: 0.185875\n",
      "[2336]\ttraining's binary_logloss: 0.185856\n",
      "[2337]\ttraining's binary_logloss: 0.185836\n",
      "[2338]\ttraining's binary_logloss: 0.185818\n",
      "[2339]\ttraining's binary_logloss: 0.1858\n",
      "[2340]\ttraining's binary_logloss: 0.185779\n",
      "[2341]\ttraining's binary_logloss: 0.185761\n",
      "[2342]\ttraining's binary_logloss: 0.185742\n",
      "[2343]\ttraining's binary_logloss: 0.185722\n",
      "[2344]\ttraining's binary_logloss: 0.185704\n",
      "[2345]\ttraining's binary_logloss: 0.185684\n",
      "[2346]\ttraining's binary_logloss: 0.185665\n",
      "[2347]\ttraining's binary_logloss: 0.185642\n",
      "[2348]\ttraining's binary_logloss: 0.185619\n",
      "[2349]\ttraining's binary_logloss: 0.185597\n",
      "[2350]\ttraining's binary_logloss: 0.18558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2351]\ttraining's binary_logloss: 0.185559\n",
      "[2352]\ttraining's binary_logloss: 0.185542\n",
      "[2353]\ttraining's binary_logloss: 0.185522\n",
      "[2354]\ttraining's binary_logloss: 0.1855\n",
      "[2355]\ttraining's binary_logloss: 0.185478\n",
      "[2356]\ttraining's binary_logloss: 0.185457\n",
      "[2357]\ttraining's binary_logloss: 0.185438\n",
      "[2358]\ttraining's binary_logloss: 0.185417\n",
      "[2359]\ttraining's binary_logloss: 0.185399\n",
      "[2360]\ttraining's binary_logloss: 0.185378\n",
      "[2361]\ttraining's binary_logloss: 0.185358\n",
      "[2362]\ttraining's binary_logloss: 0.185337\n",
      "[2363]\ttraining's binary_logloss: 0.185315\n",
      "[2364]\ttraining's binary_logloss: 0.185293\n",
      "[2365]\ttraining's binary_logloss: 0.185274\n",
      "[2366]\ttraining's binary_logloss: 0.185254\n",
      "[2367]\ttraining's binary_logloss: 0.185235\n",
      "[2368]\ttraining's binary_logloss: 0.185218\n",
      "[2369]\ttraining's binary_logloss: 0.1852\n",
      "[2370]\ttraining's binary_logloss: 0.185177\n",
      "[2371]\ttraining's binary_logloss: 0.185156\n",
      "[2372]\ttraining's binary_logloss: 0.185137\n",
      "[2373]\ttraining's binary_logloss: 0.185117\n",
      "[2374]\ttraining's binary_logloss: 0.185096\n",
      "[2375]\ttraining's binary_logloss: 0.185075\n",
      "[2376]\ttraining's binary_logloss: 0.185057\n",
      "[2377]\ttraining's binary_logloss: 0.185038\n",
      "[2378]\ttraining's binary_logloss: 0.185017\n",
      "[2379]\ttraining's binary_logloss: 0.184997\n",
      "[2380]\ttraining's binary_logloss: 0.184978\n",
      "[2381]\ttraining's binary_logloss: 0.184974\n",
      "[2382]\ttraining's binary_logloss: 0.184954\n",
      "[2383]\ttraining's binary_logloss: 0.184934\n",
      "[2384]\ttraining's binary_logloss: 0.184928\n",
      "[2385]\ttraining's binary_logloss: 0.184909\n",
      "[2386]\ttraining's binary_logloss: 0.184891\n",
      "[2387]\ttraining's binary_logloss: 0.184873\n",
      "[2388]\ttraining's binary_logloss: 0.184856\n",
      "[2389]\ttraining's binary_logloss: 0.184833\n",
      "[2390]\ttraining's binary_logloss: 0.184814\n",
      "[2391]\ttraining's binary_logloss: 0.184795\n",
      "[2392]\ttraining's binary_logloss: 0.184773\n",
      "[2393]\ttraining's binary_logloss: 0.184752\n",
      "[2394]\ttraining's binary_logloss: 0.184733\n",
      "[2395]\ttraining's binary_logloss: 0.184711\n",
      "[2396]\ttraining's binary_logloss: 0.18469\n",
      "[2397]\ttraining's binary_logloss: 0.18467\n",
      "[2398]\ttraining's binary_logloss: 0.184652\n",
      "[2399]\ttraining's binary_logloss: 0.184632\n",
      "[2400]\ttraining's binary_logloss: 0.184613\n",
      "[2401]\ttraining's binary_logloss: 0.18459\n",
      "[2402]\ttraining's binary_logloss: 0.18458\n",
      "[2403]\ttraining's binary_logloss: 0.18456\n",
      "[2404]\ttraining's binary_logloss: 0.184538\n",
      "[2405]\ttraining's binary_logloss: 0.18452\n",
      "[2406]\ttraining's binary_logloss: 0.184501\n",
      "[2407]\ttraining's binary_logloss: 0.184483\n",
      "[2408]\ttraining's binary_logloss: 0.184462\n",
      "[2409]\ttraining's binary_logloss: 0.184441\n",
      "[2410]\ttraining's binary_logloss: 0.184422\n",
      "[2411]\ttraining's binary_logloss: 0.184403\n",
      "[2412]\ttraining's binary_logloss: 0.184398\n",
      "[2413]\ttraining's binary_logloss: 0.184379\n",
      "[2414]\ttraining's binary_logloss: 0.18436\n",
      "[2415]\ttraining's binary_logloss: 0.184339\n",
      "[2416]\ttraining's binary_logloss: 0.184322\n",
      "[2417]\ttraining's binary_logloss: 0.184319\n",
      "[2418]\ttraining's binary_logloss: 0.184307\n",
      "[2419]\ttraining's binary_logloss: 0.184286\n",
      "[2420]\ttraining's binary_logloss: 0.184265\n",
      "[2421]\ttraining's binary_logloss: 0.184247\n",
      "[2422]\ttraining's binary_logloss: 0.184231\n",
      "[2423]\ttraining's binary_logloss: 0.184206\n",
      "[2424]\ttraining's binary_logloss: 0.184187\n",
      "[2425]\ttraining's binary_logloss: 0.184164\n",
      "[2426]\ttraining's binary_logloss: 0.184146\n",
      "[2427]\ttraining's binary_logloss: 0.184126\n",
      "[2428]\ttraining's binary_logloss: 0.184107\n",
      "[2429]\ttraining's binary_logloss: 0.184089\n",
      "[2430]\ttraining's binary_logloss: 0.184071\n",
      "[2431]\ttraining's binary_logloss: 0.184049\n",
      "[2432]\ttraining's binary_logloss: 0.18403\n",
      "[2433]\ttraining's binary_logloss: 0.184013\n",
      "[2434]\ttraining's binary_logloss: 0.183997\n",
      "[2435]\ttraining's binary_logloss: 0.183977\n",
      "[2436]\ttraining's binary_logloss: 0.183962\n",
      "[2437]\ttraining's binary_logloss: 0.183944\n",
      "[2438]\ttraining's binary_logloss: 0.183922\n",
      "[2439]\ttraining's binary_logloss: 0.183909\n",
      "[2440]\ttraining's binary_logloss: 0.183891\n",
      "[2441]\ttraining's binary_logloss: 0.183874\n",
      "[2442]\ttraining's binary_logloss: 0.183855\n",
      "[2443]\ttraining's binary_logloss: 0.183838\n",
      "[2444]\ttraining's binary_logloss: 0.183825\n",
      "[2445]\ttraining's binary_logloss: 0.183808\n",
      "[2446]\ttraining's binary_logloss: 0.183789\n",
      "[2447]\ttraining's binary_logloss: 0.183772\n",
      "[2448]\ttraining's binary_logloss: 0.183763\n",
      "[2449]\ttraining's binary_logloss: 0.183754\n",
      "[2450]\ttraining's binary_logloss: 0.183752\n",
      "[2451]\ttraining's binary_logloss: 0.183734\n",
      "[2452]\ttraining's binary_logloss: 0.183714\n",
      "[2453]\ttraining's binary_logloss: 0.183692\n",
      "[2454]\ttraining's binary_logloss: 0.183672\n",
      "[2455]\ttraining's binary_logloss: 0.183657\n",
      "[2456]\ttraining's binary_logloss: 0.183636\n",
      "[2457]\ttraining's binary_logloss: 0.183614\n",
      "[2458]\ttraining's binary_logloss: 0.183599\n",
      "[2459]\ttraining's binary_logloss: 0.183581\n",
      "[2460]\ttraining's binary_logloss: 0.183565\n",
      "[2461]\ttraining's binary_logloss: 0.183546\n",
      "[2462]\ttraining's binary_logloss: 0.183531\n",
      "[2463]\ttraining's binary_logloss: 0.183512\n",
      "[2464]\ttraining's binary_logloss: 0.183492\n",
      "[2465]\ttraining's binary_logloss: 0.183472\n",
      "[2466]\ttraining's binary_logloss: 0.183453\n",
      "[2467]\ttraining's binary_logloss: 0.183437\n",
      "[2468]\ttraining's binary_logloss: 0.183416\n",
      "[2469]\ttraining's binary_logloss: 0.183398\n",
      "[2470]\ttraining's binary_logloss: 0.183386\n",
      "[2471]\ttraining's binary_logloss: 0.183365\n",
      "[2472]\ttraining's binary_logloss: 0.183346\n",
      "[2473]\ttraining's binary_logloss: 0.183323\n",
      "[2474]\ttraining's binary_logloss: 0.18331\n",
      "[2475]\ttraining's binary_logloss: 0.183294\n",
      "[2476]\ttraining's binary_logloss: 0.183276\n",
      "[2477]\ttraining's binary_logloss: 0.183264\n",
      "[2478]\ttraining's binary_logloss: 0.183244\n",
      "[2479]\ttraining's binary_logloss: 0.183228\n",
      "[2480]\ttraining's binary_logloss: 0.183209\n",
      "[2481]\ttraining's binary_logloss: 0.183194\n",
      "[2482]\ttraining's binary_logloss: 0.183187\n",
      "[2483]\ttraining's binary_logloss: 0.183167\n",
      "[2484]\ttraining's binary_logloss: 0.183149\n",
      "[2485]\ttraining's binary_logloss: 0.183136\n",
      "[2486]\ttraining's binary_logloss: 0.183128\n",
      "[2487]\ttraining's binary_logloss: 0.183109\n",
      "[2488]\ttraining's binary_logloss: 0.183088\n",
      "[2489]\ttraining's binary_logloss: 0.183065\n",
      "[2490]\ttraining's binary_logloss: 0.183046\n",
      "[2491]\ttraining's binary_logloss: 0.183028\n",
      "[2492]\ttraining's binary_logloss: 0.18301\n",
      "[2493]\ttraining's binary_logloss: 0.182997\n",
      "[2494]\ttraining's binary_logloss: 0.182978\n",
      "[2495]\ttraining's binary_logloss: 0.18296\n",
      "[2496]\ttraining's binary_logloss: 0.182939\n",
      "[2497]\ttraining's binary_logloss: 0.18292\n",
      "[2498]\ttraining's binary_logloss: 0.182908\n",
      "[2499]\ttraining's binary_logloss: 0.182887\n",
      "[2500]\ttraining's binary_logloss: 0.182866\n",
      "[2501]\ttraining's binary_logloss: 0.182848\n",
      "[2502]\ttraining's binary_logloss: 0.182825\n",
      "[2503]\ttraining's binary_logloss: 0.182804\n",
      "[2504]\ttraining's binary_logloss: 0.182783\n",
      "[2505]\ttraining's binary_logloss: 0.182761\n",
      "[2506]\ttraining's binary_logloss: 0.182741\n",
      "[2507]\ttraining's binary_logloss: 0.182723\n",
      "[2508]\ttraining's binary_logloss: 0.182714\n",
      "[2509]\ttraining's binary_logloss: 0.182701\n",
      "[2510]\ttraining's binary_logloss: 0.182683\n",
      "[2511]\ttraining's binary_logloss: 0.182662\n",
      "[2512]\ttraining's binary_logloss: 0.182641\n",
      "[2513]\ttraining's binary_logloss: 0.182626\n",
      "[2514]\ttraining's binary_logloss: 0.182614\n",
      "[2515]\ttraining's binary_logloss: 0.182594\n",
      "[2516]\ttraining's binary_logloss: 0.182576\n",
      "[2517]\ttraining's binary_logloss: 0.182557\n",
      "[2518]\ttraining's binary_logloss: 0.182534\n",
      "[2519]\ttraining's binary_logloss: 0.182527\n",
      "[2520]\ttraining's binary_logloss: 0.182506\n",
      "[2521]\ttraining's binary_logloss: 0.182487\n",
      "[2522]\ttraining's binary_logloss: 0.18247\n",
      "[2523]\ttraining's binary_logloss: 0.182453\n",
      "[2524]\ttraining's binary_logloss: 0.182433\n",
      "[2525]\ttraining's binary_logloss: 0.182415\n",
      "[2526]\ttraining's binary_logloss: 0.182403\n",
      "[2527]\ttraining's binary_logloss: 0.182385\n",
      "[2528]\ttraining's binary_logloss: 0.182367\n",
      "[2529]\ttraining's binary_logloss: 0.182349\n",
      "[2530]\ttraining's binary_logloss: 0.182336\n",
      "[2531]\ttraining's binary_logloss: 0.182325\n",
      "[2532]\ttraining's binary_logloss: 0.182307\n",
      "[2533]\ttraining's binary_logloss: 0.182287\n",
      "[2534]\ttraining's binary_logloss: 0.18227\n",
      "[2535]\ttraining's binary_logloss: 0.182252\n",
      "[2536]\ttraining's binary_logloss: 0.182234\n",
      "[2537]\ttraining's binary_logloss: 0.182216\n",
      "[2538]\ttraining's binary_logloss: 0.1822\n",
      "[2539]\ttraining's binary_logloss: 0.182179\n",
      "[2540]\ttraining's binary_logloss: 0.182156\n",
      "[2541]\ttraining's binary_logloss: 0.182135\n",
      "[2542]\ttraining's binary_logloss: 0.182122\n",
      "[2543]\ttraining's binary_logloss: 0.182102\n",
      "[2544]\ttraining's binary_logloss: 0.182081\n",
      "[2545]\ttraining's binary_logloss: 0.182064\n",
      "[2546]\ttraining's binary_logloss: 0.182053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2547]\ttraining's binary_logloss: 0.182035\n",
      "[2548]\ttraining's binary_logloss: 0.182018\n",
      "[2549]\ttraining's binary_logloss: 0.181999\n",
      "[2550]\ttraining's binary_logloss: 0.181982\n",
      "[2551]\ttraining's binary_logloss: 0.181964\n",
      "[2552]\ttraining's binary_logloss: 0.181946\n",
      "[2553]\ttraining's binary_logloss: 0.181925\n",
      "[2554]\ttraining's binary_logloss: 0.181908\n",
      "[2555]\ttraining's binary_logloss: 0.181901\n",
      "[2556]\ttraining's binary_logloss: 0.181888\n",
      "[2557]\ttraining's binary_logloss: 0.181868\n",
      "[2558]\ttraining's binary_logloss: 0.181849\n",
      "[2559]\ttraining's binary_logloss: 0.181834\n",
      "[2560]\ttraining's binary_logloss: 0.181814\n",
      "[2561]\ttraining's binary_logloss: 0.181808\n",
      "[2562]\ttraining's binary_logloss: 0.181803\n",
      "[2563]\ttraining's binary_logloss: 0.181786\n",
      "[2564]\ttraining's binary_logloss: 0.181777\n",
      "[2565]\ttraining's binary_logloss: 0.181759\n",
      "[2566]\ttraining's binary_logloss: 0.181751\n",
      "[2567]\ttraining's binary_logloss: 0.181745\n",
      "[2568]\ttraining's binary_logloss: 0.181727\n",
      "[2569]\ttraining's binary_logloss: 0.181714\n",
      "[2570]\ttraining's binary_logloss: 0.181696\n",
      "[2571]\ttraining's binary_logloss: 0.181677\n",
      "[2572]\ttraining's binary_logloss: 0.181661\n",
      "[2573]\ttraining's binary_logloss: 0.181641\n",
      "[2574]\ttraining's binary_logloss: 0.181627\n",
      "[2575]\ttraining's binary_logloss: 0.181609\n",
      "[2576]\ttraining's binary_logloss: 0.181586\n",
      "[2577]\ttraining's binary_logloss: 0.181573\n",
      "[2578]\ttraining's binary_logloss: 0.181554\n",
      "[2579]\ttraining's binary_logloss: 0.181533\n",
      "[2580]\ttraining's binary_logloss: 0.181525\n",
      "[2581]\ttraining's binary_logloss: 0.181508\n",
      "[2582]\ttraining's binary_logloss: 0.181492\n",
      "[2583]\ttraining's binary_logloss: 0.181473\n",
      "[2584]\ttraining's binary_logloss: 0.181453\n",
      "[2585]\ttraining's binary_logloss: 0.181435\n",
      "[2586]\ttraining's binary_logloss: 0.181418\n",
      "[2587]\ttraining's binary_logloss: 0.181396\n",
      "[2588]\ttraining's binary_logloss: 0.181378\n",
      "[2589]\ttraining's binary_logloss: 0.181361\n",
      "[2590]\ttraining's binary_logloss: 0.181343\n",
      "[2591]\ttraining's binary_logloss: 0.181325\n",
      "[2592]\ttraining's binary_logloss: 0.181308\n",
      "[2593]\ttraining's binary_logloss: 0.181288\n",
      "[2594]\ttraining's binary_logloss: 0.181275\n",
      "[2595]\ttraining's binary_logloss: 0.181255\n",
      "[2596]\ttraining's binary_logloss: 0.181238\n",
      "[2597]\ttraining's binary_logloss: 0.181216\n",
      "[2598]\ttraining's binary_logloss: 0.181211\n",
      "[2599]\ttraining's binary_logloss: 0.181197\n",
      "[2600]\ttraining's binary_logloss: 0.181181\n",
      "[2601]\ttraining's binary_logloss: 0.181173\n",
      "[2602]\ttraining's binary_logloss: 0.181157\n",
      "[2603]\ttraining's binary_logloss: 0.181138\n",
      "[2604]\ttraining's binary_logloss: 0.181115\n",
      "[2605]\ttraining's binary_logloss: 0.181099\n",
      "[2606]\ttraining's binary_logloss: 0.181081\n",
      "[2607]\ttraining's binary_logloss: 0.181075\n",
      "[2608]\ttraining's binary_logloss: 0.181061\n",
      "[2609]\ttraining's binary_logloss: 0.181045\n",
      "[2610]\ttraining's binary_logloss: 0.181027\n",
      "[2611]\ttraining's binary_logloss: 0.181009\n",
      "[2612]\ttraining's binary_logloss: 0.180993\n",
      "[2613]\ttraining's binary_logloss: 0.180981\n",
      "[2614]\ttraining's binary_logloss: 0.180966\n",
      "[2615]\ttraining's binary_logloss: 0.180949\n",
      "[2616]\ttraining's binary_logloss: 0.180937\n",
      "[2617]\ttraining's binary_logloss: 0.180926\n",
      "[2618]\ttraining's binary_logloss: 0.180907\n",
      "[2619]\ttraining's binary_logloss: 0.180895\n",
      "[2620]\ttraining's binary_logloss: 0.180878\n",
      "[2621]\ttraining's binary_logloss: 0.180856\n",
      "[2622]\ttraining's binary_logloss: 0.180845\n",
      "[2623]\ttraining's binary_logloss: 0.180828\n",
      "[2624]\ttraining's binary_logloss: 0.180824\n",
      "[2625]\ttraining's binary_logloss: 0.180804\n",
      "[2626]\ttraining's binary_logloss: 0.180786\n",
      "[2627]\ttraining's binary_logloss: 0.180771\n",
      "[2628]\ttraining's binary_logloss: 0.18076\n",
      "[2629]\ttraining's binary_logloss: 0.180741\n",
      "[2630]\ttraining's binary_logloss: 0.180723\n",
      "[2631]\ttraining's binary_logloss: 0.180705\n",
      "[2632]\ttraining's binary_logloss: 0.180695\n",
      "[2633]\ttraining's binary_logloss: 0.180675\n",
      "[2634]\ttraining's binary_logloss: 0.180668\n",
      "[2635]\ttraining's binary_logloss: 0.180651\n",
      "[2636]\ttraining's binary_logloss: 0.180631\n",
      "[2637]\ttraining's binary_logloss: 0.180616\n",
      "[2638]\ttraining's binary_logloss: 0.180597\n",
      "[2639]\ttraining's binary_logloss: 0.180577\n",
      "[2640]\ttraining's binary_logloss: 0.180557\n",
      "[2641]\ttraining's binary_logloss: 0.180536\n",
      "[2642]\ttraining's binary_logloss: 0.180531\n",
      "[2643]\ttraining's binary_logloss: 0.180517\n",
      "[2644]\ttraining's binary_logloss: 0.180513\n",
      "[2645]\ttraining's binary_logloss: 0.180504\n",
      "[2646]\ttraining's binary_logloss: 0.180488\n",
      "[2647]\ttraining's binary_logloss: 0.180465\n",
      "[2648]\ttraining's binary_logloss: 0.180454\n",
      "[2649]\ttraining's binary_logloss: 0.180437\n",
      "[2650]\ttraining's binary_logloss: 0.180416\n",
      "[2651]\ttraining's binary_logloss: 0.180399\n",
      "[2652]\ttraining's binary_logloss: 0.180379\n",
      "[2653]\ttraining's binary_logloss: 0.180359\n",
      "[2654]\ttraining's binary_logloss: 0.18034\n",
      "[2655]\ttraining's binary_logloss: 0.180321\n",
      "[2656]\ttraining's binary_logloss: 0.1803\n",
      "[2657]\ttraining's binary_logloss: 0.18029\n",
      "[2658]\ttraining's binary_logloss: 0.18028\n",
      "[2659]\ttraining's binary_logloss: 0.180262\n",
      "[2660]\ttraining's binary_logloss: 0.180244\n",
      "[2661]\ttraining's binary_logloss: 0.180226\n",
      "[2662]\ttraining's binary_logloss: 0.180207\n",
      "[2663]\ttraining's binary_logloss: 0.180204\n",
      "[2664]\ttraining's binary_logloss: 0.180182\n",
      "[2665]\ttraining's binary_logloss: 0.180165\n",
      "[2666]\ttraining's binary_logloss: 0.180146\n",
      "[2667]\ttraining's binary_logloss: 0.180127\n",
      "[2668]\ttraining's binary_logloss: 0.180107\n",
      "[2669]\ttraining's binary_logloss: 0.180086\n",
      "[2670]\ttraining's binary_logloss: 0.180067\n",
      "[2671]\ttraining's binary_logloss: 0.180059\n",
      "[2672]\ttraining's binary_logloss: 0.180039\n",
      "[2673]\ttraining's binary_logloss: 0.180019\n",
      "[2674]\ttraining's binary_logloss: 0.179999\n",
      "[2675]\ttraining's binary_logloss: 0.179982\n",
      "[2676]\ttraining's binary_logloss: 0.179966\n",
      "[2677]\ttraining's binary_logloss: 0.179959\n",
      "[2678]\ttraining's binary_logloss: 0.179943\n",
      "[2679]\ttraining's binary_logloss: 0.179927\n",
      "[2680]\ttraining's binary_logloss: 0.179908\n",
      "[2681]\ttraining's binary_logloss: 0.179897\n",
      "[2682]\ttraining's binary_logloss: 0.179882\n",
      "[2683]\ttraining's binary_logloss: 0.179875\n",
      "[2684]\ttraining's binary_logloss: 0.179856\n",
      "[2685]\ttraining's binary_logloss: 0.17984\n",
      "[2686]\ttraining's binary_logloss: 0.179819\n",
      "[2687]\ttraining's binary_logloss: 0.1798\n",
      "[2688]\ttraining's binary_logloss: 0.179783\n",
      "[2689]\ttraining's binary_logloss: 0.179765\n",
      "[2690]\ttraining's binary_logloss: 0.179745\n",
      "[2691]\ttraining's binary_logloss: 0.179723\n",
      "[2692]\ttraining's binary_logloss: 0.179704\n",
      "[2693]\ttraining's binary_logloss: 0.179697\n",
      "[2694]\ttraining's binary_logloss: 0.179679\n",
      "[2695]\ttraining's binary_logloss: 0.179659\n",
      "[2696]\ttraining's binary_logloss: 0.179641\n",
      "[2697]\ttraining's binary_logloss: 0.179622\n",
      "[2698]\ttraining's binary_logloss: 0.179604\n",
      "[2699]\ttraining's binary_logloss: 0.179585\n",
      "[2700]\ttraining's binary_logloss: 0.179568\n",
      "[2701]\ttraining's binary_logloss: 0.179549\n",
      "[2702]\ttraining's binary_logloss: 0.179529\n",
      "[2703]\ttraining's binary_logloss: 0.17951\n",
      "[2704]\ttraining's binary_logloss: 0.179494\n",
      "[2705]\ttraining's binary_logloss: 0.179474\n",
      "[2706]\ttraining's binary_logloss: 0.179456\n",
      "[2707]\ttraining's binary_logloss: 0.179447\n",
      "[2708]\ttraining's binary_logloss: 0.179435\n",
      "[2709]\ttraining's binary_logloss: 0.179413\n",
      "[2710]\ttraining's binary_logloss: 0.179404\n",
      "[2711]\ttraining's binary_logloss: 0.179385\n",
      "[2712]\ttraining's binary_logloss: 0.179369\n",
      "[2713]\ttraining's binary_logloss: 0.179355\n",
      "[2714]\ttraining's binary_logloss: 0.179336\n",
      "[2715]\ttraining's binary_logloss: 0.179317\n",
      "[2716]\ttraining's binary_logloss: 0.179307\n",
      "[2717]\ttraining's binary_logloss: 0.179289\n",
      "[2718]\ttraining's binary_logloss: 0.179269\n",
      "[2719]\ttraining's binary_logloss: 0.179253\n",
      "[2720]\ttraining's binary_logloss: 0.179234\n",
      "[2721]\ttraining's binary_logloss: 0.179219\n",
      "[2722]\ttraining's binary_logloss: 0.179199\n",
      "[2723]\ttraining's binary_logloss: 0.17918\n",
      "[2724]\ttraining's binary_logloss: 0.179163\n",
      "[2725]\ttraining's binary_logloss: 0.179148\n",
      "[2726]\ttraining's binary_logloss: 0.179131\n",
      "[2727]\ttraining's binary_logloss: 0.179112\n",
      "[2728]\ttraining's binary_logloss: 0.179103\n",
      "[2729]\ttraining's binary_logloss: 0.179084\n",
      "[2730]\ttraining's binary_logloss: 0.17907\n",
      "[2731]\ttraining's binary_logloss: 0.179054\n",
      "[2732]\ttraining's binary_logloss: 0.179036\n",
      "[2733]\ttraining's binary_logloss: 0.179023\n",
      "[2734]\ttraining's binary_logloss: 0.179009\n",
      "[2735]\ttraining's binary_logloss: 0.178992\n",
      "[2736]\ttraining's binary_logloss: 0.178975\n",
      "[2737]\ttraining's binary_logloss: 0.178959\n",
      "[2738]\ttraining's binary_logloss: 0.17894\n",
      "[2739]\ttraining's binary_logloss: 0.178922\n",
      "[2740]\ttraining's binary_logloss: 0.178904\n",
      "[2741]\ttraining's binary_logloss: 0.178893\n",
      "[2742]\ttraining's binary_logloss: 0.178875\n",
      "[2743]\ttraining's binary_logloss: 0.178859\n",
      "[2744]\ttraining's binary_logloss: 0.178841\n",
      "[2745]\ttraining's binary_logloss: 0.178825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746]\ttraining's binary_logloss: 0.178804\n",
      "[2747]\ttraining's binary_logloss: 0.178798\n",
      "[2748]\ttraining's binary_logloss: 0.17878\n",
      "[2749]\ttraining's binary_logloss: 0.178763\n",
      "[2750]\ttraining's binary_logloss: 0.178744\n",
      "[2751]\ttraining's binary_logloss: 0.178724\n",
      "[2752]\ttraining's binary_logloss: 0.178706\n",
      "[2753]\ttraining's binary_logloss: 0.178686\n",
      "[2754]\ttraining's binary_logloss: 0.178668\n",
      "[2755]\ttraining's binary_logloss: 0.178648\n",
      "[2756]\ttraining's binary_logloss: 0.178634\n",
      "[2757]\ttraining's binary_logloss: 0.178619\n",
      "[2758]\ttraining's binary_logloss: 0.178599\n",
      "[2759]\ttraining's binary_logloss: 0.178578\n",
      "[2760]\ttraining's binary_logloss: 0.178558\n",
      "[2761]\ttraining's binary_logloss: 0.178539\n",
      "[2762]\ttraining's binary_logloss: 0.178534\n",
      "[2763]\ttraining's binary_logloss: 0.178524\n",
      "[2764]\ttraining's binary_logloss: 0.178519\n",
      "[2765]\ttraining's binary_logloss: 0.178501\n",
      "[2766]\ttraining's binary_logloss: 0.178484\n",
      "[2767]\ttraining's binary_logloss: 0.178469\n",
      "[2768]\ttraining's binary_logloss: 0.178458\n",
      "[2769]\ttraining's binary_logloss: 0.178439\n",
      "[2770]\ttraining's binary_logloss: 0.178433\n",
      "[2771]\ttraining's binary_logloss: 0.178414\n",
      "[2772]\ttraining's binary_logloss: 0.178396\n",
      "[2773]\ttraining's binary_logloss: 0.178376\n",
      "[2774]\ttraining's binary_logloss: 0.178366\n",
      "[2775]\ttraining's binary_logloss: 0.178346\n",
      "[2776]\ttraining's binary_logloss: 0.178328\n",
      "[2777]\ttraining's binary_logloss: 0.178312\n",
      "[2778]\ttraining's binary_logloss: 0.178294\n",
      "[2779]\ttraining's binary_logloss: 0.178277\n",
      "[2780]\ttraining's binary_logloss: 0.178259\n",
      "[2781]\ttraining's binary_logloss: 0.178242\n",
      "[2782]\ttraining's binary_logloss: 0.17823\n",
      "[2783]\ttraining's binary_logloss: 0.178209\n",
      "[2784]\ttraining's binary_logloss: 0.178192\n",
      "[2785]\ttraining's binary_logloss: 0.178173\n",
      "[2786]\ttraining's binary_logloss: 0.178155\n",
      "[2787]\ttraining's binary_logloss: 0.178135\n",
      "[2788]\ttraining's binary_logloss: 0.17812\n",
      "[2789]\ttraining's binary_logloss: 0.178107\n",
      "[2790]\ttraining's binary_logloss: 0.17809\n",
      "[2791]\ttraining's binary_logloss: 0.178071\n",
      "[2792]\ttraining's binary_logloss: 0.178055\n",
      "[2793]\ttraining's binary_logloss: 0.178034\n",
      "[2794]\ttraining's binary_logloss: 0.178018\n",
      "[2795]\ttraining's binary_logloss: 0.178005\n",
      "[2796]\ttraining's binary_logloss: 0.17799\n",
      "[2797]\ttraining's binary_logloss: 0.177973\n",
      "[2798]\ttraining's binary_logloss: 0.177961\n",
      "[2799]\ttraining's binary_logloss: 0.177943\n",
      "[2800]\ttraining's binary_logloss: 0.177923\n",
      "[2801]\ttraining's binary_logloss: 0.177915\n",
      "[2802]\ttraining's binary_logloss: 0.177912\n",
      "[2803]\ttraining's binary_logloss: 0.177893\n",
      "[2804]\ttraining's binary_logloss: 0.177874\n",
      "[2805]\ttraining's binary_logloss: 0.177855\n",
      "[2806]\ttraining's binary_logloss: 0.177837\n",
      "[2807]\ttraining's binary_logloss: 0.177827\n",
      "[2808]\ttraining's binary_logloss: 0.177811\n",
      "[2809]\ttraining's binary_logloss: 0.177794\n",
      "[2810]\ttraining's binary_logloss: 0.177775\n",
      "[2811]\ttraining's binary_logloss: 0.177755\n",
      "[2812]\ttraining's binary_logloss: 0.177738\n",
      "[2813]\ttraining's binary_logloss: 0.177722\n",
      "[2814]\ttraining's binary_logloss: 0.177702\n",
      "[2815]\ttraining's binary_logloss: 0.177694\n",
      "[2816]\ttraining's binary_logloss: 0.177675\n",
      "[2817]\ttraining's binary_logloss: 0.177659\n",
      "[2818]\ttraining's binary_logloss: 0.177641\n",
      "[2819]\ttraining's binary_logloss: 0.177622\n",
      "[2820]\ttraining's binary_logloss: 0.1776\n",
      "[2821]\ttraining's binary_logloss: 0.177582\n",
      "[2822]\ttraining's binary_logloss: 0.177572\n",
      "[2823]\ttraining's binary_logloss: 0.177554\n",
      "[2824]\ttraining's binary_logloss: 0.177545\n",
      "[2825]\ttraining's binary_logloss: 0.177529\n",
      "[2826]\ttraining's binary_logloss: 0.17752\n",
      "[2827]\ttraining's binary_logloss: 0.177504\n",
      "[2828]\ttraining's binary_logloss: 0.177483\n",
      "[2829]\ttraining's binary_logloss: 0.177465\n",
      "[2830]\ttraining's binary_logloss: 0.177446\n",
      "[2831]\ttraining's binary_logloss: 0.177428\n",
      "[2832]\ttraining's binary_logloss: 0.177414\n",
      "[2833]\ttraining's binary_logloss: 0.17741\n",
      "[2834]\ttraining's binary_logloss: 0.177391\n",
      "[2835]\ttraining's binary_logloss: 0.177373\n",
      "[2836]\ttraining's binary_logloss: 0.177355\n",
      "[2837]\ttraining's binary_logloss: 0.177335\n",
      "[2838]\ttraining's binary_logloss: 0.177314\n",
      "[2839]\ttraining's binary_logloss: 0.177302\n",
      "[2840]\ttraining's binary_logloss: 0.177282\n",
      "[2841]\ttraining's binary_logloss: 0.177264\n",
      "[2842]\ttraining's binary_logloss: 0.177242\n",
      "[2843]\ttraining's binary_logloss: 0.177224\n",
      "[2844]\ttraining's binary_logloss: 0.177207\n",
      "[2845]\ttraining's binary_logloss: 0.177188\n",
      "[2846]\ttraining's binary_logloss: 0.177169\n",
      "[2847]\ttraining's binary_logloss: 0.177151\n",
      "[2848]\ttraining's binary_logloss: 0.177138\n",
      "[2849]\ttraining's binary_logloss: 0.177117\n",
      "[2850]\ttraining's binary_logloss: 0.177099\n",
      "[2851]\ttraining's binary_logloss: 0.177084\n",
      "[2852]\ttraining's binary_logloss: 0.177067\n",
      "[2853]\ttraining's binary_logloss: 0.177062\n",
      "[2854]\ttraining's binary_logloss: 0.177045\n",
      "[2855]\ttraining's binary_logloss: 0.177025\n",
      "[2856]\ttraining's binary_logloss: 0.177007\n",
      "[2857]\ttraining's binary_logloss: 0.17699\n",
      "[2858]\ttraining's binary_logloss: 0.176972\n",
      "[2859]\ttraining's binary_logloss: 0.176956\n",
      "[2860]\ttraining's binary_logloss: 0.176938\n",
      "[2861]\ttraining's binary_logloss: 0.176929\n",
      "[2862]\ttraining's binary_logloss: 0.17692\n",
      "[2863]\ttraining's binary_logloss: 0.176912\n",
      "[2864]\ttraining's binary_logloss: 0.176892\n",
      "[2865]\ttraining's binary_logloss: 0.176876\n",
      "[2866]\ttraining's binary_logloss: 0.176868\n",
      "[2867]\ttraining's binary_logloss: 0.176851\n",
      "[2868]\ttraining's binary_logloss: 0.176841\n",
      "[2869]\ttraining's binary_logloss: 0.176822\n",
      "[2870]\ttraining's binary_logloss: 0.176813\n",
      "[2871]\ttraining's binary_logloss: 0.176802\n",
      "[2872]\ttraining's binary_logloss: 0.176781\n",
      "[2873]\ttraining's binary_logloss: 0.176768\n",
      "[2874]\ttraining's binary_logloss: 0.176757\n",
      "[2875]\ttraining's binary_logloss: 0.176742\n",
      "[2876]\ttraining's binary_logloss: 0.176735\n",
      "[2877]\ttraining's binary_logloss: 0.176722\n",
      "[2878]\ttraining's binary_logloss: 0.176703\n",
      "[2879]\ttraining's binary_logloss: 0.176687\n",
      "[2880]\ttraining's binary_logloss: 0.176673\n",
      "[2881]\ttraining's binary_logloss: 0.176663\n",
      "[2882]\ttraining's binary_logloss: 0.176649\n",
      "[2883]\ttraining's binary_logloss: 0.176634\n",
      "[2884]\ttraining's binary_logloss: 0.176617\n",
      "[2885]\ttraining's binary_logloss: 0.1766\n",
      "[2886]\ttraining's binary_logloss: 0.176583\n",
      "[2887]\ttraining's binary_logloss: 0.176565\n",
      "[2888]\ttraining's binary_logloss: 0.176552\n",
      "[2889]\ttraining's binary_logloss: 0.176542\n",
      "[2890]\ttraining's binary_logloss: 0.176525\n",
      "[2891]\ttraining's binary_logloss: 0.176504\n",
      "[2892]\ttraining's binary_logloss: 0.17649\n",
      "[2893]\ttraining's binary_logloss: 0.176478\n",
      "[2894]\ttraining's binary_logloss: 0.176462\n",
      "[2895]\ttraining's binary_logloss: 0.176456\n",
      "[2896]\ttraining's binary_logloss: 0.17644\n",
      "[2897]\ttraining's binary_logloss: 0.176422\n",
      "[2898]\ttraining's binary_logloss: 0.176406\n",
      "[2899]\ttraining's binary_logloss: 0.176396\n",
      "[2900]\ttraining's binary_logloss: 0.176384\n",
      "[2901]\ttraining's binary_logloss: 0.176366\n",
      "[2902]\ttraining's binary_logloss: 0.176349\n",
      "[2903]\ttraining's binary_logloss: 0.176337\n",
      "[2904]\ttraining's binary_logloss: 0.176315\n",
      "[2905]\ttraining's binary_logloss: 0.1763\n",
      "[2906]\ttraining's binary_logloss: 0.17628\n",
      "[2907]\ttraining's binary_logloss: 0.176264\n",
      "[2908]\ttraining's binary_logloss: 0.176246\n",
      "[2909]\ttraining's binary_logloss: 0.176227\n",
      "[2910]\ttraining's binary_logloss: 0.176208\n",
      "[2911]\ttraining's binary_logloss: 0.176189\n",
      "[2912]\ttraining's binary_logloss: 0.176183\n",
      "[2913]\ttraining's binary_logloss: 0.176165\n",
      "[2914]\ttraining's binary_logloss: 0.176151\n",
      "[2915]\ttraining's binary_logloss: 0.176145\n",
      "[2916]\ttraining's binary_logloss: 0.176135\n",
      "[2917]\ttraining's binary_logloss: 0.176117\n",
      "[2918]\ttraining's binary_logloss: 0.176099\n",
      "[2919]\ttraining's binary_logloss: 0.176088\n",
      "[2920]\ttraining's binary_logloss: 0.176075\n",
      "[2921]\ttraining's binary_logloss: 0.176058\n",
      "[2922]\ttraining's binary_logloss: 0.17604\n",
      "[2923]\ttraining's binary_logloss: 0.17602\n",
      "[2924]\ttraining's binary_logloss: 0.176002\n",
      "[2925]\ttraining's binary_logloss: 0.175984\n",
      "[2926]\ttraining's binary_logloss: 0.175967\n",
      "[2927]\ttraining's binary_logloss: 0.175946\n",
      "[2928]\ttraining's binary_logloss: 0.175942\n",
      "[2929]\ttraining's binary_logloss: 0.175922\n",
      "[2930]\ttraining's binary_logloss: 0.175905\n",
      "[2931]\ttraining's binary_logloss: 0.175887\n",
      "[2932]\ttraining's binary_logloss: 0.175869\n",
      "[2933]\ttraining's binary_logloss: 0.17585\n",
      "[2934]\ttraining's binary_logloss: 0.175834\n",
      "[2935]\ttraining's binary_logloss: 0.175816\n",
      "[2936]\ttraining's binary_logloss: 0.175799\n",
      "[2937]\ttraining's binary_logloss: 0.175788\n",
      "[2938]\ttraining's binary_logloss: 0.175765\n",
      "[2939]\ttraining's binary_logloss: 0.175753\n",
      "[2940]\ttraining's binary_logloss: 0.175746\n",
      "[2941]\ttraining's binary_logloss: 0.175726\n",
      "[2942]\ttraining's binary_logloss: 0.175707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2943]\ttraining's binary_logloss: 0.175688\n",
      "[2944]\ttraining's binary_logloss: 0.17567\n",
      "[2945]\ttraining's binary_logloss: 0.175655\n",
      "[2946]\ttraining's binary_logloss: 0.175636\n",
      "[2947]\ttraining's binary_logloss: 0.17562\n",
      "[2948]\ttraining's binary_logloss: 0.175603\n",
      "[2949]\ttraining's binary_logloss: 0.175593\n",
      "[2950]\ttraining's binary_logloss: 0.175575\n",
      "[2951]\ttraining's binary_logloss: 0.175556\n",
      "[2952]\ttraining's binary_logloss: 0.175533\n",
      "[2953]\ttraining's binary_logloss: 0.175511\n",
      "[2954]\ttraining's binary_logloss: 0.175493\n",
      "[2955]\ttraining's binary_logloss: 0.175475\n",
      "[2956]\ttraining's binary_logloss: 0.175458\n",
      "[2957]\ttraining's binary_logloss: 0.175442\n",
      "[2958]\ttraining's binary_logloss: 0.175425\n",
      "[2959]\ttraining's binary_logloss: 0.175404\n",
      "[2960]\ttraining's binary_logloss: 0.175386\n",
      "[2961]\ttraining's binary_logloss: 0.175368\n",
      "[2962]\ttraining's binary_logloss: 0.175347\n",
      "[2963]\ttraining's binary_logloss: 0.175327\n",
      "[2964]\ttraining's binary_logloss: 0.175309\n",
      "[2965]\ttraining's binary_logloss: 0.175292\n",
      "[2966]\ttraining's binary_logloss: 0.175274\n",
      "[2967]\ttraining's binary_logloss: 0.175258\n",
      "[2968]\ttraining's binary_logloss: 0.175253\n",
      "[2969]\ttraining's binary_logloss: 0.175235\n",
      "[2970]\ttraining's binary_logloss: 0.175217\n",
      "[2971]\ttraining's binary_logloss: 0.175201\n",
      "[2972]\ttraining's binary_logloss: 0.175183\n",
      "[2973]\ttraining's binary_logloss: 0.175164\n",
      "[2974]\ttraining's binary_logloss: 0.175145\n",
      "[2975]\ttraining's binary_logloss: 0.175127\n",
      "[2976]\ttraining's binary_logloss: 0.175114\n",
      "[2977]\ttraining's binary_logloss: 0.175097\n",
      "[2978]\ttraining's binary_logloss: 0.175082\n",
      "[2979]\ttraining's binary_logloss: 0.175065\n",
      "[2980]\ttraining's binary_logloss: 0.175047\n",
      "[2981]\ttraining's binary_logloss: 0.175027\n",
      "[2982]\ttraining's binary_logloss: 0.175008\n",
      "[2983]\ttraining's binary_logloss: 0.174991\n",
      "[2984]\ttraining's binary_logloss: 0.174971\n",
      "[2985]\ttraining's binary_logloss: 0.174957\n",
      "[2986]\ttraining's binary_logloss: 0.17494\n",
      "[2987]\ttraining's binary_logloss: 0.174921\n",
      "[2988]\ttraining's binary_logloss: 0.174902\n",
      "[2989]\ttraining's binary_logloss: 0.174899\n",
      "[2990]\ttraining's binary_logloss: 0.174882\n",
      "[2991]\ttraining's binary_logloss: 0.174865\n",
      "[2992]\ttraining's binary_logloss: 0.174845\n",
      "[2993]\ttraining's binary_logloss: 0.174824\n",
      "[2994]\ttraining's binary_logloss: 0.174805\n",
      "[2995]\ttraining's binary_logloss: 0.174787\n",
      "[2996]\ttraining's binary_logloss: 0.174769\n",
      "[2997]\ttraining's binary_logloss: 0.17475\n",
      "[2998]\ttraining's binary_logloss: 0.174731\n",
      "[2999]\ttraining's binary_logloss: 0.174714\n",
      "[3000]\ttraining's binary_logloss: 0.174705\n",
      "[3001]\ttraining's binary_logloss: 0.174688\n",
      "[3002]\ttraining's binary_logloss: 0.174671\n",
      "[3003]\ttraining's binary_logloss: 0.174651\n",
      "[3004]\ttraining's binary_logloss: 0.174635\n",
      "[3005]\ttraining's binary_logloss: 0.174623\n",
      "[3006]\ttraining's binary_logloss: 0.174608\n",
      "[3007]\ttraining's binary_logloss: 0.174593\n",
      "[3008]\ttraining's binary_logloss: 0.174573\n",
      "[3009]\ttraining's binary_logloss: 0.174555\n",
      "[3010]\ttraining's binary_logloss: 0.174546\n",
      "[3011]\ttraining's binary_logloss: 0.174531\n",
      "[3012]\ttraining's binary_logloss: 0.174513\n",
      "[3013]\ttraining's binary_logloss: 0.174491\n",
      "[3014]\ttraining's binary_logloss: 0.174472\n",
      "[3015]\ttraining's binary_logloss: 0.174464\n",
      "[3016]\ttraining's binary_logloss: 0.174445\n",
      "[3017]\ttraining's binary_logloss: 0.174426\n",
      "[3018]\ttraining's binary_logloss: 0.174418\n",
      "[3019]\ttraining's binary_logloss: 0.174408\n",
      "[3020]\ttraining's binary_logloss: 0.174395\n",
      "[3021]\ttraining's binary_logloss: 0.174378\n",
      "[3022]\ttraining's binary_logloss: 0.174359\n",
      "[3023]\ttraining's binary_logloss: 0.17434\n",
      "[3024]\ttraining's binary_logloss: 0.17432\n",
      "[3025]\ttraining's binary_logloss: 0.174303\n",
      "[3026]\ttraining's binary_logloss: 0.174286\n",
      "[3027]\ttraining's binary_logloss: 0.174268\n",
      "[3028]\ttraining's binary_logloss: 0.174249\n",
      "[3029]\ttraining's binary_logloss: 0.174232\n",
      "[3030]\ttraining's binary_logloss: 0.174211\n",
      "[3031]\ttraining's binary_logloss: 0.174193\n",
      "[3032]\ttraining's binary_logloss: 0.174176\n",
      "[3033]\ttraining's binary_logloss: 0.174159\n",
      "[3034]\ttraining's binary_logloss: 0.174141\n",
      "[3035]\ttraining's binary_logloss: 0.174123\n",
      "[3036]\ttraining's binary_logloss: 0.174107\n",
      "[3037]\ttraining's binary_logloss: 0.174089\n",
      "[3038]\ttraining's binary_logloss: 0.174076\n",
      "[3039]\ttraining's binary_logloss: 0.174073\n",
      "[3040]\ttraining's binary_logloss: 0.174055\n",
      "[3041]\ttraining's binary_logloss: 0.17404\n",
      "[3042]\ttraining's binary_logloss: 0.174037\n",
      "[3043]\ttraining's binary_logloss: 0.174019\n",
      "[3044]\ttraining's binary_logloss: 0.174001\n",
      "[3045]\ttraining's binary_logloss: 0.173989\n",
      "[3046]\ttraining's binary_logloss: 0.17397\n",
      "[3047]\ttraining's binary_logloss: 0.173951\n",
      "[3048]\ttraining's binary_logloss: 0.173933\n",
      "[3049]\ttraining's binary_logloss: 0.173917\n",
      "[3050]\ttraining's binary_logloss: 0.173896\n",
      "[3051]\ttraining's binary_logloss: 0.173878\n",
      "[3052]\ttraining's binary_logloss: 0.173861\n",
      "[3053]\ttraining's binary_logloss: 0.173843\n",
      "[3054]\ttraining's binary_logloss: 0.173834\n",
      "[3055]\ttraining's binary_logloss: 0.173817\n",
      "[3056]\ttraining's binary_logloss: 0.173804\n",
      "[3057]\ttraining's binary_logloss: 0.173796\n",
      "[3058]\ttraining's binary_logloss: 0.173777\n",
      "[3059]\ttraining's binary_logloss: 0.17376\n",
      "[3060]\ttraining's binary_logloss: 0.173742\n",
      "[3061]\ttraining's binary_logloss: 0.173724\n",
      "[3062]\ttraining's binary_logloss: 0.173715\n",
      "[3063]\ttraining's binary_logloss: 0.173699\n",
      "[3064]\ttraining's binary_logloss: 0.173691\n",
      "[3065]\ttraining's binary_logloss: 0.173676\n",
      "[3066]\ttraining's binary_logloss: 0.173658\n",
      "[3067]\ttraining's binary_logloss: 0.173642\n",
      "[3068]\ttraining's binary_logloss: 0.173625\n",
      "[3069]\ttraining's binary_logloss: 0.173606\n",
      "[3070]\ttraining's binary_logloss: 0.173586\n",
      "[3071]\ttraining's binary_logloss: 0.173571\n",
      "[3072]\ttraining's binary_logloss: 0.173551\n",
      "[3073]\ttraining's binary_logloss: 0.173535\n",
      "[3074]\ttraining's binary_logloss: 0.173514\n",
      "[3075]\ttraining's binary_logloss: 0.173496\n",
      "[3076]\ttraining's binary_logloss: 0.173477\n",
      "[3077]\ttraining's binary_logloss: 0.173462\n",
      "[3078]\ttraining's binary_logloss: 0.173447\n",
      "[3079]\ttraining's binary_logloss: 0.173432\n",
      "[3080]\ttraining's binary_logloss: 0.173427\n",
      "[3081]\ttraining's binary_logloss: 0.173408\n",
      "[3082]\ttraining's binary_logloss: 0.17339\n",
      "[3083]\ttraining's binary_logloss: 0.173385\n",
      "[3084]\ttraining's binary_logloss: 0.173374\n",
      "[3085]\ttraining's binary_logloss: 0.173357\n",
      "[3086]\ttraining's binary_logloss: 0.173345\n",
      "[3087]\ttraining's binary_logloss: 0.173325\n",
      "[3088]\ttraining's binary_logloss: 0.173307\n",
      "[3089]\ttraining's binary_logloss: 0.173288\n",
      "[3090]\ttraining's binary_logloss: 0.17327\n",
      "[3091]\ttraining's binary_logloss: 0.173256\n",
      "[3092]\ttraining's binary_logloss: 0.173239\n",
      "[3093]\ttraining's binary_logloss: 0.173218\n",
      "[3094]\ttraining's binary_logloss: 0.1732\n",
      "[3095]\ttraining's binary_logloss: 0.173184\n",
      "[3096]\ttraining's binary_logloss: 0.173167\n",
      "[3097]\ttraining's binary_logloss: 0.17315\n",
      "[3098]\ttraining's binary_logloss: 0.173129\n",
      "[3099]\ttraining's binary_logloss: 0.173121\n",
      "[3100]\ttraining's binary_logloss: 0.173104\n",
      "[3101]\ttraining's binary_logloss: 0.173086\n",
      "[3102]\ttraining's binary_logloss: 0.173079\n",
      "[3103]\ttraining's binary_logloss: 0.173059\n",
      "[3104]\ttraining's binary_logloss: 0.173043\n",
      "[3105]\ttraining's binary_logloss: 0.17303\n",
      "[3106]\ttraining's binary_logloss: 0.173012\n",
      "[3107]\ttraining's binary_logloss: 0.173001\n",
      "[3108]\ttraining's binary_logloss: 0.17299\n",
      "[3109]\ttraining's binary_logloss: 0.172981\n",
      "[3110]\ttraining's binary_logloss: 0.172972\n",
      "[3111]\ttraining's binary_logloss: 0.172961\n",
      "[3112]\ttraining's binary_logloss: 0.172954\n",
      "[3113]\ttraining's binary_logloss: 0.172935\n",
      "[3114]\ttraining's binary_logloss: 0.172917\n",
      "[3115]\ttraining's binary_logloss: 0.172899\n",
      "[3116]\ttraining's binary_logloss: 0.17289\n",
      "[3117]\ttraining's binary_logloss: 0.172872\n",
      "[3118]\ttraining's binary_logloss: 0.172853\n",
      "[3119]\ttraining's binary_logloss: 0.172837\n",
      "[3120]\ttraining's binary_logloss: 0.172821\n",
      "[3121]\ttraining's binary_logloss: 0.172802\n",
      "[3122]\ttraining's binary_logloss: 0.172786\n",
      "[3123]\ttraining's binary_logloss: 0.172769\n",
      "[3124]\ttraining's binary_logloss: 0.17276\n",
      "[3125]\ttraining's binary_logloss: 0.172742\n",
      "[3126]\ttraining's binary_logloss: 0.172735\n",
      "[3127]\ttraining's binary_logloss: 0.172717\n",
      "[3128]\ttraining's binary_logloss: 0.172704\n",
      "[3129]\ttraining's binary_logloss: 0.17269\n",
      "[3130]\ttraining's binary_logloss: 0.172672\n",
      "[3131]\ttraining's binary_logloss: 0.172666\n",
      "[3132]\ttraining's binary_logloss: 0.172651\n",
      "[3133]\ttraining's binary_logloss: 0.172635\n",
      "[3134]\ttraining's binary_logloss: 0.172631\n",
      "[3135]\ttraining's binary_logloss: 0.172616\n",
      "[3136]\ttraining's binary_logloss: 0.1726\n",
      "[3137]\ttraining's binary_logloss: 0.172583\n",
      "[3138]\ttraining's binary_logloss: 0.172567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3139]\ttraining's binary_logloss: 0.172549\n",
      "[3140]\ttraining's binary_logloss: 0.172529\n",
      "[3141]\ttraining's binary_logloss: 0.172511\n",
      "[3142]\ttraining's binary_logloss: 0.172495\n",
      "[3143]\ttraining's binary_logloss: 0.172476\n",
      "[3144]\ttraining's binary_logloss: 0.172457\n",
      "[3145]\ttraining's binary_logloss: 0.172441\n",
      "[3146]\ttraining's binary_logloss: 0.17243\n",
      "[3147]\ttraining's binary_logloss: 0.172418\n",
      "[3148]\ttraining's binary_logloss: 0.172406\n",
      "[3149]\ttraining's binary_logloss: 0.172389\n",
      "[3150]\ttraining's binary_logloss: 0.172373\n",
      "[3151]\ttraining's binary_logloss: 0.172355\n",
      "[3152]\ttraining's binary_logloss: 0.172336\n",
      "[3153]\ttraining's binary_logloss: 0.172319\n",
      "[3154]\ttraining's binary_logloss: 0.172304\n",
      "[3155]\ttraining's binary_logloss: 0.172288\n",
      "[3156]\ttraining's binary_logloss: 0.172272\n",
      "[3157]\ttraining's binary_logloss: 0.172253\n",
      "[3158]\ttraining's binary_logloss: 0.172237\n",
      "[3159]\ttraining's binary_logloss: 0.17222\n",
      "[3160]\ttraining's binary_logloss: 0.172202\n",
      "[3161]\ttraining's binary_logloss: 0.172183\n",
      "[3162]\ttraining's binary_logloss: 0.172166\n",
      "[3163]\ttraining's binary_logloss: 0.172148\n",
      "[3164]\ttraining's binary_logloss: 0.172131\n",
      "[3165]\ttraining's binary_logloss: 0.172117\n",
      "[3166]\ttraining's binary_logloss: 0.172099\n",
      "[3167]\ttraining's binary_logloss: 0.172082\n",
      "[3168]\ttraining's binary_logloss: 0.172063\n",
      "[3169]\ttraining's binary_logloss: 0.172046\n",
      "[3170]\ttraining's binary_logloss: 0.17203\n",
      "[3171]\ttraining's binary_logloss: 0.172012\n",
      "[3172]\ttraining's binary_logloss: 0.171998\n",
      "[3173]\ttraining's binary_logloss: 0.171981\n",
      "[3174]\ttraining's binary_logloss: 0.171964\n",
      "[3175]\ttraining's binary_logloss: 0.171946\n",
      "[3176]\ttraining's binary_logloss: 0.171928\n",
      "[3177]\ttraining's binary_logloss: 0.171919\n",
      "[3178]\ttraining's binary_logloss: 0.171903\n",
      "[3179]\ttraining's binary_logloss: 0.171882\n",
      "[3180]\ttraining's binary_logloss: 0.171868\n",
      "[3181]\ttraining's binary_logloss: 0.171851\n",
      "[3182]\ttraining's binary_logloss: 0.171834\n",
      "[3183]\ttraining's binary_logloss: 0.171815\n",
      "[3184]\ttraining's binary_logloss: 0.171795\n",
      "[3185]\ttraining's binary_logloss: 0.171775\n",
      "[3186]\ttraining's binary_logloss: 0.171758\n",
      "[3187]\ttraining's binary_logloss: 0.171737\n",
      "[3188]\ttraining's binary_logloss: 0.171719\n",
      "[3189]\ttraining's binary_logloss: 0.17171\n",
      "[3190]\ttraining's binary_logloss: 0.171697\n",
      "[3191]\ttraining's binary_logloss: 0.171681\n",
      "[3192]\ttraining's binary_logloss: 0.171663\n",
      "[3193]\ttraining's binary_logloss: 0.171644\n",
      "[3194]\ttraining's binary_logloss: 0.17163\n",
      "[3195]\ttraining's binary_logloss: 0.171612\n",
      "[3196]\ttraining's binary_logloss: 0.171595\n",
      "[3197]\ttraining's binary_logloss: 0.171579\n",
      "[3198]\ttraining's binary_logloss: 0.171563\n",
      "[3199]\ttraining's binary_logloss: 0.171546\n",
      "[3200]\ttraining's binary_logloss: 0.171535\n",
      "[3201]\ttraining's binary_logloss: 0.171516\n",
      "[3202]\ttraining's binary_logloss: 0.171497\n",
      "[3203]\ttraining's binary_logloss: 0.171489\n",
      "[3204]\ttraining's binary_logloss: 0.171477\n",
      "[3205]\ttraining's binary_logloss: 0.171461\n",
      "[3206]\ttraining's binary_logloss: 0.171442\n",
      "[3207]\ttraining's binary_logloss: 0.171427\n",
      "[3208]\ttraining's binary_logloss: 0.171407\n",
      "[3209]\ttraining's binary_logloss: 0.171388\n",
      "[3210]\ttraining's binary_logloss: 0.171368\n",
      "[3211]\ttraining's binary_logloss: 0.17135\n",
      "[3212]\ttraining's binary_logloss: 0.171332\n",
      "[3213]\ttraining's binary_logloss: 0.171313\n",
      "[3214]\ttraining's binary_logloss: 0.171298\n",
      "[3215]\ttraining's binary_logloss: 0.171278\n",
      "[3216]\ttraining's binary_logloss: 0.171263\n",
      "[3217]\ttraining's binary_logloss: 0.171243\n",
      "[3218]\ttraining's binary_logloss: 0.171221\n",
      "[3219]\ttraining's binary_logloss: 0.171203\n",
      "[3220]\ttraining's binary_logloss: 0.171183\n",
      "[3221]\ttraining's binary_logloss: 0.171163\n",
      "[3222]\ttraining's binary_logloss: 0.171146\n",
      "[3223]\ttraining's binary_logloss: 0.171131\n",
      "[3224]\ttraining's binary_logloss: 0.171115\n",
      "[3225]\ttraining's binary_logloss: 0.171098\n",
      "[3226]\ttraining's binary_logloss: 0.171081\n",
      "[3227]\ttraining's binary_logloss: 0.171063\n",
      "[3228]\ttraining's binary_logloss: 0.171051\n",
      "[3229]\ttraining's binary_logloss: 0.171036\n",
      "[3230]\ttraining's binary_logloss: 0.171017\n",
      "[3231]\ttraining's binary_logloss: 0.171001\n",
      "[3232]\ttraining's binary_logloss: 0.170983\n",
      "[3233]\ttraining's binary_logloss: 0.170966\n",
      "[3234]\ttraining's binary_logloss: 0.170956\n",
      "[3235]\ttraining's binary_logloss: 0.170939\n",
      "[3236]\ttraining's binary_logloss: 0.170921\n",
      "[3237]\ttraining's binary_logloss: 0.170903\n",
      "[3238]\ttraining's binary_logloss: 0.170887\n",
      "[3239]\ttraining's binary_logloss: 0.170873\n",
      "[3240]\ttraining's binary_logloss: 0.170868\n",
      "[3241]\ttraining's binary_logloss: 0.170856\n",
      "[3242]\ttraining's binary_logloss: 0.17085\n",
      "[3243]\ttraining's binary_logloss: 0.170833\n",
      "[3244]\ttraining's binary_logloss: 0.170815\n",
      "[3245]\ttraining's binary_logloss: 0.170797\n",
      "[3246]\ttraining's binary_logloss: 0.17078\n",
      "[3247]\ttraining's binary_logloss: 0.170774\n",
      "[3248]\ttraining's binary_logloss: 0.170759\n",
      "[3249]\ttraining's binary_logloss: 0.170741\n",
      "[3250]\ttraining's binary_logloss: 0.170724\n",
      "[3251]\ttraining's binary_logloss: 0.170712\n",
      "[3252]\ttraining's binary_logloss: 0.170695\n",
      "[3253]\ttraining's binary_logloss: 0.170677\n",
      "[3254]\ttraining's binary_logloss: 0.170661\n",
      "[3255]\ttraining's binary_logloss: 0.170642\n",
      "[3256]\ttraining's binary_logloss: 0.170622\n",
      "[3257]\ttraining's binary_logloss: 0.170604\n",
      "[3258]\ttraining's binary_logloss: 0.170587\n",
      "[3259]\ttraining's binary_logloss: 0.170569\n",
      "[3260]\ttraining's binary_logloss: 0.170552\n",
      "[3261]\ttraining's binary_logloss: 0.170534\n",
      "[3262]\ttraining's binary_logloss: 0.170519\n",
      "[3263]\ttraining's binary_logloss: 0.170512\n",
      "[3264]\ttraining's binary_logloss: 0.170498\n",
      "[3265]\ttraining's binary_logloss: 0.170492\n",
      "[3266]\ttraining's binary_logloss: 0.170487\n",
      "[3267]\ttraining's binary_logloss: 0.170469\n",
      "[3268]\ttraining's binary_logloss: 0.170449\n",
      "[3269]\ttraining's binary_logloss: 0.170429\n",
      "[3270]\ttraining's binary_logloss: 0.170413\n",
      "[3271]\ttraining's binary_logloss: 0.170397\n",
      "[3272]\ttraining's binary_logloss: 0.170378\n",
      "[3273]\ttraining's binary_logloss: 0.170362\n",
      "[3274]\ttraining's binary_logloss: 0.17034\n",
      "[3275]\ttraining's binary_logloss: 0.170325\n",
      "[3276]\ttraining's binary_logloss: 0.170309\n",
      "[3277]\ttraining's binary_logloss: 0.170299\n",
      "[3278]\ttraining's binary_logloss: 0.170283\n",
      "[3279]\ttraining's binary_logloss: 0.170275\n",
      "[3280]\ttraining's binary_logloss: 0.170257\n",
      "[3281]\ttraining's binary_logloss: 0.170243\n",
      "[3282]\ttraining's binary_logloss: 0.170225\n",
      "[3283]\ttraining's binary_logloss: 0.170216\n",
      "[3284]\ttraining's binary_logloss: 0.1702\n",
      "[3285]\ttraining's binary_logloss: 0.170183\n",
      "[3286]\ttraining's binary_logloss: 0.170168\n",
      "[3287]\ttraining's binary_logloss: 0.17015\n",
      "[3288]\ttraining's binary_logloss: 0.170134\n",
      "[3289]\ttraining's binary_logloss: 0.170125\n",
      "[3290]\ttraining's binary_logloss: 0.170114\n",
      "[3291]\ttraining's binary_logloss: 0.170108\n",
      "[3292]\ttraining's binary_logloss: 0.170093\n",
      "[3293]\ttraining's binary_logloss: 0.170077\n",
      "[3294]\ttraining's binary_logloss: 0.170069\n",
      "[3295]\ttraining's binary_logloss: 0.170054\n",
      "[3296]\ttraining's binary_logloss: 0.17005\n",
      "[3297]\ttraining's binary_logloss: 0.170038\n",
      "[3298]\ttraining's binary_logloss: 0.170025\n",
      "[3299]\ttraining's binary_logloss: 0.170009\n",
      "[3300]\ttraining's binary_logloss: 0.169997\n",
      "[3301]\ttraining's binary_logloss: 0.16998\n",
      "[3302]\ttraining's binary_logloss: 0.169966\n",
      "[3303]\ttraining's binary_logloss: 0.169953\n",
      "[3304]\ttraining's binary_logloss: 0.169936\n",
      "[3305]\ttraining's binary_logloss: 0.169922\n",
      "[3306]\ttraining's binary_logloss: 0.16991\n",
      "[3307]\ttraining's binary_logloss: 0.169894\n",
      "[3308]\ttraining's binary_logloss: 0.169881\n",
      "[3309]\ttraining's binary_logloss: 0.169866\n",
      "[3310]\ttraining's binary_logloss: 0.16985\n",
      "[3311]\ttraining's binary_logloss: 0.169828\n",
      "[3312]\ttraining's binary_logloss: 0.169809\n",
      "[3313]\ttraining's binary_logloss: 0.169798\n",
      "[3314]\ttraining's binary_logloss: 0.169788\n",
      "[3315]\ttraining's binary_logloss: 0.169771\n",
      "[3316]\ttraining's binary_logloss: 0.169753\n",
      "[3317]\ttraining's binary_logloss: 0.169737\n",
      "[3318]\ttraining's binary_logloss: 0.169717\n",
      "[3319]\ttraining's binary_logloss: 0.169698\n",
      "[3320]\ttraining's binary_logloss: 0.16968\n",
      "[3321]\ttraining's binary_logloss: 0.169661\n",
      "[3322]\ttraining's binary_logloss: 0.169643\n",
      "[3323]\ttraining's binary_logloss: 0.169621\n",
      "[3324]\ttraining's binary_logloss: 0.169605\n",
      "[3325]\ttraining's binary_logloss: 0.169589\n",
      "[3326]\ttraining's binary_logloss: 0.169585\n",
      "[3327]\ttraining's binary_logloss: 0.169569\n",
      "[3328]\ttraining's binary_logloss: 0.169554\n",
      "[3329]\ttraining's binary_logloss: 0.169536\n",
      "[3330]\ttraining's binary_logloss: 0.169517\n",
      "[3331]\ttraining's binary_logloss: 0.169503\n",
      "[3332]\ttraining's binary_logloss: 0.169485\n",
      "[3333]\ttraining's binary_logloss: 0.169479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3334]\ttraining's binary_logloss: 0.169466\n",
      "[3335]\ttraining's binary_logloss: 0.169458\n",
      "[3336]\ttraining's binary_logloss: 0.169449\n",
      "[3337]\ttraining's binary_logloss: 0.169431\n",
      "[3338]\ttraining's binary_logloss: 0.16942\n",
      "[3339]\ttraining's binary_logloss: 0.169402\n",
      "[3340]\ttraining's binary_logloss: 0.169385\n",
      "[3341]\ttraining's binary_logloss: 0.16937\n",
      "[3342]\ttraining's binary_logloss: 0.169351\n",
      "[3343]\ttraining's binary_logloss: 0.169335\n",
      "[3344]\ttraining's binary_logloss: 0.169321\n",
      "[3345]\ttraining's binary_logloss: 0.169302\n",
      "[3346]\ttraining's binary_logloss: 0.169285\n",
      "[3347]\ttraining's binary_logloss: 0.16927\n",
      "[3348]\ttraining's binary_logloss: 0.169257\n",
      "[3349]\ttraining's binary_logloss: 0.16925\n",
      "[3350]\ttraining's binary_logloss: 0.169234\n",
      "[3351]\ttraining's binary_logloss: 0.169217\n",
      "[3352]\ttraining's binary_logloss: 0.169201\n",
      "[3353]\ttraining's binary_logloss: 0.169192\n",
      "[3354]\ttraining's binary_logloss: 0.169174\n",
      "[3355]\ttraining's binary_logloss: 0.169166\n",
      "[3356]\ttraining's binary_logloss: 0.16916\n",
      "[3357]\ttraining's binary_logloss: 0.169139\n",
      "[3358]\ttraining's binary_logloss: 0.169122\n",
      "[3359]\ttraining's binary_logloss: 0.169105\n",
      "[3360]\ttraining's binary_logloss: 0.169088\n",
      "[3361]\ttraining's binary_logloss: 0.16908\n",
      "[3362]\ttraining's binary_logloss: 0.169064\n",
      "[3363]\ttraining's binary_logloss: 0.169047\n",
      "[3364]\ttraining's binary_logloss: 0.16903\n",
      "[3365]\ttraining's binary_logloss: 0.169021\n",
      "[3366]\ttraining's binary_logloss: 0.169006\n",
      "[3367]\ttraining's binary_logloss: 0.168988\n",
      "[3368]\ttraining's binary_logloss: 0.168971\n",
      "[3369]\ttraining's binary_logloss: 0.168956\n",
      "[3370]\ttraining's binary_logloss: 0.168947\n",
      "[3371]\ttraining's binary_logloss: 0.168931\n",
      "[3372]\ttraining's binary_logloss: 0.16892\n",
      "[3373]\ttraining's binary_logloss: 0.168907\n",
      "[3374]\ttraining's binary_logloss: 0.168889\n",
      "[3375]\ttraining's binary_logloss: 0.168873\n",
      "[3376]\ttraining's binary_logloss: 0.168856\n",
      "[3377]\ttraining's binary_logloss: 0.168839\n",
      "[3378]\ttraining's binary_logloss: 0.168821\n",
      "[3379]\ttraining's binary_logloss: 0.168804\n",
      "[3380]\ttraining's binary_logloss: 0.168787\n",
      "[3381]\ttraining's binary_logloss: 0.168773\n",
      "[3382]\ttraining's binary_logloss: 0.168755\n",
      "[3383]\ttraining's binary_logloss: 0.168736\n",
      "[3384]\ttraining's binary_logloss: 0.168716\n",
      "[3385]\ttraining's binary_logloss: 0.168703\n",
      "[3386]\ttraining's binary_logloss: 0.168687\n",
      "[3387]\ttraining's binary_logloss: 0.16867\n",
      "[3388]\ttraining's binary_logloss: 0.168652\n",
      "[3389]\ttraining's binary_logloss: 0.168634\n",
      "[3390]\ttraining's binary_logloss: 0.168618\n",
      "[3391]\ttraining's binary_logloss: 0.1686\n",
      "[3392]\ttraining's binary_logloss: 0.168585\n",
      "[3393]\ttraining's binary_logloss: 0.168567\n",
      "[3394]\ttraining's binary_logloss: 0.16855\n",
      "[3395]\ttraining's binary_logloss: 0.168533\n",
      "[3396]\ttraining's binary_logloss: 0.168517\n",
      "[3397]\ttraining's binary_logloss: 0.168503\n",
      "[3398]\ttraining's binary_logloss: 0.168487\n",
      "[3399]\ttraining's binary_logloss: 0.168471\n",
      "[3400]\ttraining's binary_logloss: 0.168455\n",
      "[3401]\ttraining's binary_logloss: 0.168436\n",
      "[3402]\ttraining's binary_logloss: 0.16842\n",
      "[3403]\ttraining's binary_logloss: 0.168413\n",
      "[3404]\ttraining's binary_logloss: 0.168398\n",
      "[3405]\ttraining's binary_logloss: 0.168382\n",
      "[3406]\ttraining's binary_logloss: 0.168364\n",
      "[3407]\ttraining's binary_logloss: 0.16835\n",
      "[3408]\ttraining's binary_logloss: 0.168336\n",
      "[3409]\ttraining's binary_logloss: 0.168334\n",
      "[3410]\ttraining's binary_logloss: 0.168319\n",
      "[3411]\ttraining's binary_logloss: 0.168303\n",
      "[3412]\ttraining's binary_logloss: 0.168298\n",
      "[3413]\ttraining's binary_logloss: 0.168288\n",
      "[3414]\ttraining's binary_logloss: 0.168272\n",
      "[3415]\ttraining's binary_logloss: 0.168255\n",
      "[3416]\ttraining's binary_logloss: 0.168234\n",
      "[3417]\ttraining's binary_logloss: 0.168217\n",
      "[3418]\ttraining's binary_logloss: 0.168209\n",
      "[3419]\ttraining's binary_logloss: 0.168202\n",
      "[3420]\ttraining's binary_logloss: 0.168195\n",
      "[3421]\ttraining's binary_logloss: 0.168178\n",
      "[3422]\ttraining's binary_logloss: 0.168163\n",
      "[3423]\ttraining's binary_logloss: 0.168143\n",
      "[3424]\ttraining's binary_logloss: 0.16813\n",
      "[3425]\ttraining's binary_logloss: 0.168124\n",
      "[3426]\ttraining's binary_logloss: 0.168106\n",
      "[3427]\ttraining's binary_logloss: 0.168089\n",
      "[3428]\ttraining's binary_logloss: 0.16808\n",
      "[3429]\ttraining's binary_logloss: 0.168068\n",
      "[3430]\ttraining's binary_logloss: 0.168055\n",
      "[3431]\ttraining's binary_logloss: 0.16804\n",
      "[3432]\ttraining's binary_logloss: 0.168023\n",
      "[3433]\ttraining's binary_logloss: 0.168005\n",
      "[3434]\ttraining's binary_logloss: 0.167991\n",
      "[3435]\ttraining's binary_logloss: 0.167985\n",
      "[3436]\ttraining's binary_logloss: 0.167969\n",
      "[3437]\ttraining's binary_logloss: 0.167954\n",
      "[3438]\ttraining's binary_logloss: 0.167937\n",
      "[3439]\ttraining's binary_logloss: 0.16792\n",
      "[3440]\ttraining's binary_logloss: 0.167914\n",
      "[3441]\ttraining's binary_logloss: 0.1679\n",
      "[3442]\ttraining's binary_logloss: 0.167882\n",
      "[3443]\ttraining's binary_logloss: 0.167866\n",
      "[3444]\ttraining's binary_logloss: 0.167847\n",
      "[3445]\ttraining's binary_logloss: 0.167845\n",
      "[3446]\ttraining's binary_logloss: 0.167828\n",
      "[3447]\ttraining's binary_logloss: 0.167811\n",
      "[3448]\ttraining's binary_logloss: 0.167793\n",
      "[3449]\ttraining's binary_logloss: 0.167775\n",
      "[3450]\ttraining's binary_logloss: 0.167759\n",
      "[3451]\ttraining's binary_logloss: 0.16774\n",
      "[3452]\ttraining's binary_logloss: 0.16773\n",
      "[3453]\ttraining's binary_logloss: 0.167716\n",
      "[3454]\ttraining's binary_logloss: 0.167701\n",
      "[3455]\ttraining's binary_logloss: 0.167684\n",
      "[3456]\ttraining's binary_logloss: 0.167666\n",
      "[3457]\ttraining's binary_logloss: 0.167651\n",
      "[3458]\ttraining's binary_logloss: 0.167632\n",
      "[3459]\ttraining's binary_logloss: 0.167615\n",
      "[3460]\ttraining's binary_logloss: 0.167599\n",
      "[3461]\ttraining's binary_logloss: 0.167582\n",
      "[3462]\ttraining's binary_logloss: 0.167565\n",
      "[3463]\ttraining's binary_logloss: 0.167547\n",
      "[3464]\ttraining's binary_logloss: 0.167533\n",
      "[3465]\ttraining's binary_logloss: 0.167519\n",
      "[3466]\ttraining's binary_logloss: 0.1675\n",
      "[3467]\ttraining's binary_logloss: 0.167484\n",
      "[3468]\ttraining's binary_logloss: 0.167469\n",
      "[3469]\ttraining's binary_logloss: 0.167452\n",
      "[3470]\ttraining's binary_logloss: 0.167436\n",
      "[3471]\ttraining's binary_logloss: 0.167418\n",
      "[3472]\ttraining's binary_logloss: 0.167413\n",
      "[3473]\ttraining's binary_logloss: 0.167398\n",
      "[3474]\ttraining's binary_logloss: 0.167393\n",
      "[3475]\ttraining's binary_logloss: 0.167383\n",
      "[3476]\ttraining's binary_logloss: 0.167381\n",
      "[3477]\ttraining's binary_logloss: 0.167361\n",
      "[3478]\ttraining's binary_logloss: 0.167346\n",
      "[3479]\ttraining's binary_logloss: 0.167332\n",
      "[3480]\ttraining's binary_logloss: 0.167315\n",
      "[3481]\ttraining's binary_logloss: 0.167297\n",
      "[3482]\ttraining's binary_logloss: 0.16728\n",
      "[3483]\ttraining's binary_logloss: 0.167262\n",
      "[3484]\ttraining's binary_logloss: 0.167245\n",
      "[3485]\ttraining's binary_logloss: 0.167228\n",
      "[3486]\ttraining's binary_logloss: 0.167212\n",
      "[3487]\ttraining's binary_logloss: 0.167197\n",
      "[3488]\ttraining's binary_logloss: 0.167181\n",
      "[3489]\ttraining's binary_logloss: 0.167175\n",
      "[3490]\ttraining's binary_logloss: 0.167159\n",
      "[3491]\ttraining's binary_logloss: 0.167145\n",
      "[3492]\ttraining's binary_logloss: 0.167127\n",
      "[3493]\ttraining's binary_logloss: 0.167108\n",
      "[3494]\ttraining's binary_logloss: 0.167092\n",
      "[3495]\ttraining's binary_logloss: 0.167079\n",
      "[3496]\ttraining's binary_logloss: 0.167064\n",
      "[3497]\ttraining's binary_logloss: 0.167047\n",
      "[3498]\ttraining's binary_logloss: 0.16703\n",
      "[3499]\ttraining's binary_logloss: 0.167013\n",
      "[3500]\ttraining's binary_logloss: 0.166999\n",
      "[3501]\ttraining's binary_logloss: 0.166981\n",
      "[3502]\ttraining's binary_logloss: 0.166964\n",
      "[3503]\ttraining's binary_logloss: 0.166947\n",
      "[3504]\ttraining's binary_logloss: 0.16693\n",
      "[3505]\ttraining's binary_logloss: 0.166912\n",
      "[3506]\ttraining's binary_logloss: 0.166894\n",
      "[3507]\ttraining's binary_logloss: 0.166878\n",
      "[3508]\ttraining's binary_logloss: 0.166861\n",
      "[3509]\ttraining's binary_logloss: 0.166845\n",
      "[3510]\ttraining's binary_logloss: 0.166825\n",
      "[3511]\ttraining's binary_logloss: 0.166809\n",
      "[3512]\ttraining's binary_logloss: 0.16679\n",
      "[3513]\ttraining's binary_logloss: 0.166774\n",
      "[3514]\ttraining's binary_logloss: 0.166768\n",
      "[3515]\ttraining's binary_logloss: 0.166748\n",
      "[3516]\ttraining's binary_logloss: 0.16673\n",
      "[3517]\ttraining's binary_logloss: 0.166712\n",
      "[3518]\ttraining's binary_logloss: 0.166696\n",
      "[3519]\ttraining's binary_logloss: 0.166678\n",
      "[3520]\ttraining's binary_logloss: 0.166658\n",
      "[3521]\ttraining's binary_logloss: 0.166641\n",
      "[3522]\ttraining's binary_logloss: 0.166626\n",
      "[3523]\ttraining's binary_logloss: 0.166612\n",
      "[3524]\ttraining's binary_logloss: 0.166594\n",
      "[3525]\ttraining's binary_logloss: 0.166578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3526]\ttraining's binary_logloss: 0.166562\n",
      "[3527]\ttraining's binary_logloss: 0.166545\n",
      "[3528]\ttraining's binary_logloss: 0.16653\n",
      "[3529]\ttraining's binary_logloss: 0.166514\n",
      "[3530]\ttraining's binary_logloss: 0.166509\n",
      "[3531]\ttraining's binary_logloss: 0.166491\n",
      "[3532]\ttraining's binary_logloss: 0.166476\n",
      "[3533]\ttraining's binary_logloss: 0.166459\n",
      "[3534]\ttraining's binary_logloss: 0.166443\n",
      "[3535]\ttraining's binary_logloss: 0.166427\n",
      "[3536]\ttraining's binary_logloss: 0.16641\n",
      "[3537]\ttraining's binary_logloss: 0.166393\n",
      "[3538]\ttraining's binary_logloss: 0.166375\n",
      "[3539]\ttraining's binary_logloss: 0.166358\n",
      "[3540]\ttraining's binary_logloss: 0.166343\n",
      "[3541]\ttraining's binary_logloss: 0.166326\n",
      "[3542]\ttraining's binary_logloss: 0.16631\n",
      "[3543]\ttraining's binary_logloss: 0.166296\n",
      "[3544]\ttraining's binary_logloss: 0.166281\n",
      "[3545]\ttraining's binary_logloss: 0.166265\n",
      "[3546]\ttraining's binary_logloss: 0.16625\n",
      "[3547]\ttraining's binary_logloss: 0.166231\n",
      "[3548]\ttraining's binary_logloss: 0.166214\n",
      "[3549]\ttraining's binary_logloss: 0.166198\n",
      "[3550]\ttraining's binary_logloss: 0.166179\n",
      "[3551]\ttraining's binary_logloss: 0.166176\n",
      "[3552]\ttraining's binary_logloss: 0.16616\n",
      "[3553]\ttraining's binary_logloss: 0.166141\n",
      "[3554]\ttraining's binary_logloss: 0.166125\n",
      "[3555]\ttraining's binary_logloss: 0.166108\n",
      "[3556]\ttraining's binary_logloss: 0.166092\n",
      "[3557]\ttraining's binary_logloss: 0.16608\n",
      "[3558]\ttraining's binary_logloss: 0.166066\n",
      "[3559]\ttraining's binary_logloss: 0.16605\n",
      "[3560]\ttraining's binary_logloss: 0.166041\n",
      "[3561]\ttraining's binary_logloss: 0.166025\n",
      "[3562]\ttraining's binary_logloss: 0.16601\n",
      "[3563]\ttraining's binary_logloss: 0.165995\n",
      "[3564]\ttraining's binary_logloss: 0.165977\n",
      "[3565]\ttraining's binary_logloss: 0.165957\n",
      "[3566]\ttraining's binary_logloss: 0.165945\n",
      "[3567]\ttraining's binary_logloss: 0.16593\n",
      "[3568]\ttraining's binary_logloss: 0.165914\n",
      "[3569]\ttraining's binary_logloss: 0.165899\n",
      "[3570]\ttraining's binary_logloss: 0.165886\n",
      "[3571]\ttraining's binary_logloss: 0.165873\n",
      "[3572]\ttraining's binary_logloss: 0.165858\n",
      "[3573]\ttraining's binary_logloss: 0.165842\n",
      "[3574]\ttraining's binary_logloss: 0.165824\n",
      "[3575]\ttraining's binary_logloss: 0.165806\n",
      "[3576]\ttraining's binary_logloss: 0.165789\n",
      "[3577]\ttraining's binary_logloss: 0.165774\n",
      "[3578]\ttraining's binary_logloss: 0.16576\n",
      "[3579]\ttraining's binary_logloss: 0.165749\n",
      "[3580]\ttraining's binary_logloss: 0.165735\n",
      "[3581]\ttraining's binary_logloss: 0.165717\n",
      "[3582]\ttraining's binary_logloss: 0.165696\n",
      "[3583]\ttraining's binary_logloss: 0.165681\n",
      "[3584]\ttraining's binary_logloss: 0.165672\n",
      "[3585]\ttraining's binary_logloss: 0.165661\n",
      "[3586]\ttraining's binary_logloss: 0.165644\n",
      "[3587]\ttraining's binary_logloss: 0.165625\n",
      "[3588]\ttraining's binary_logloss: 0.165611\n",
      "[3589]\ttraining's binary_logloss: 0.165596\n",
      "[3590]\ttraining's binary_logloss: 0.16558\n",
      "[3591]\ttraining's binary_logloss: 0.165568\n",
      "[3592]\ttraining's binary_logloss: 0.165553\n",
      "[3593]\ttraining's binary_logloss: 0.165533\n",
      "[3594]\ttraining's binary_logloss: 0.165516\n",
      "[3595]\ttraining's binary_logloss: 0.1655\n",
      "[3596]\ttraining's binary_logloss: 0.165481\n",
      "[3597]\ttraining's binary_logloss: 0.165465\n",
      "[3598]\ttraining's binary_logloss: 0.16545\n",
      "[3599]\ttraining's binary_logloss: 0.165435\n",
      "[3600]\ttraining's binary_logloss: 0.165419\n",
      "[3601]\ttraining's binary_logloss: 0.165413\n",
      "[3602]\ttraining's binary_logloss: 0.165397\n",
      "[3603]\ttraining's binary_logloss: 0.165383\n",
      "[3604]\ttraining's binary_logloss: 0.165364\n",
      "[3605]\ttraining's binary_logloss: 0.165348\n",
      "[3606]\ttraining's binary_logloss: 0.16533\n",
      "[3607]\ttraining's binary_logloss: 0.165314\n",
      "[3608]\ttraining's binary_logloss: 0.165293\n",
      "[3609]\ttraining's binary_logloss: 0.165284\n",
      "[3610]\ttraining's binary_logloss: 0.165269\n",
      "[3611]\ttraining's binary_logloss: 0.165254\n",
      "[3612]\ttraining's binary_logloss: 0.165239\n",
      "[3613]\ttraining's binary_logloss: 0.165222\n",
      "[3614]\ttraining's binary_logloss: 0.165202\n",
      "[3615]\ttraining's binary_logloss: 0.165186\n",
      "[3616]\ttraining's binary_logloss: 0.165174\n",
      "[3617]\ttraining's binary_logloss: 0.16516\n",
      "[3618]\ttraining's binary_logloss: 0.16515\n",
      "[3619]\ttraining's binary_logloss: 0.165136\n",
      "[3620]\ttraining's binary_logloss: 0.165121\n",
      "[3621]\ttraining's binary_logloss: 0.165104\n",
      "[3622]\ttraining's binary_logloss: 0.16509\n",
      "[3623]\ttraining's binary_logloss: 0.165072\n",
      "[3624]\ttraining's binary_logloss: 0.165056\n",
      "[3625]\ttraining's binary_logloss: 0.16504\n",
      "[3626]\ttraining's binary_logloss: 0.165024\n",
      "[3627]\ttraining's binary_logloss: 0.165012\n",
      "[3628]\ttraining's binary_logloss: 0.165003\n",
      "[3629]\ttraining's binary_logloss: 0.164986\n",
      "[3630]\ttraining's binary_logloss: 0.164976\n",
      "[3631]\ttraining's binary_logloss: 0.164961\n",
      "[3632]\ttraining's binary_logloss: 0.164945\n",
      "[3633]\ttraining's binary_logloss: 0.164925\n",
      "[3634]\ttraining's binary_logloss: 0.164907\n",
      "[3635]\ttraining's binary_logloss: 0.164893\n",
      "[3636]\ttraining's binary_logloss: 0.16488\n",
      "[3637]\ttraining's binary_logloss: 0.164864\n",
      "[3638]\ttraining's binary_logloss: 0.164861\n",
      "[3639]\ttraining's binary_logloss: 0.164841\n",
      "[3640]\ttraining's binary_logloss: 0.164831\n",
      "[3641]\ttraining's binary_logloss: 0.164813\n",
      "[3642]\ttraining's binary_logloss: 0.164797\n",
      "[3643]\ttraining's binary_logloss: 0.164779\n",
      "[3644]\ttraining's binary_logloss: 0.164764\n",
      "[3645]\ttraining's binary_logloss: 0.164746\n",
      "[3646]\ttraining's binary_logloss: 0.164728\n",
      "[3647]\ttraining's binary_logloss: 0.164712\n",
      "[3648]\ttraining's binary_logloss: 0.164698\n",
      "[3649]\ttraining's binary_logloss: 0.164683\n",
      "[3650]\ttraining's binary_logloss: 0.164665\n",
      "[3651]\ttraining's binary_logloss: 0.164647\n",
      "[3652]\ttraining's binary_logloss: 0.164631\n",
      "[3653]\ttraining's binary_logloss: 0.164614\n",
      "[3654]\ttraining's binary_logloss: 0.164597\n",
      "[3655]\ttraining's binary_logloss: 0.16458\n",
      "[3656]\ttraining's binary_logloss: 0.164566\n",
      "[3657]\ttraining's binary_logloss: 0.164552\n",
      "[3658]\ttraining's binary_logloss: 0.16454\n",
      "[3659]\ttraining's binary_logloss: 0.164523\n",
      "[3660]\ttraining's binary_logloss: 0.164506\n",
      "[3661]\ttraining's binary_logloss: 0.16449\n",
      "[3662]\ttraining's binary_logloss: 0.164474\n",
      "[3663]\ttraining's binary_logloss: 0.164456\n",
      "[3664]\ttraining's binary_logloss: 0.164439\n",
      "[3665]\ttraining's binary_logloss: 0.164425\n",
      "[3666]\ttraining's binary_logloss: 0.16441\n",
      "[3667]\ttraining's binary_logloss: 0.164392\n",
      "[3668]\ttraining's binary_logloss: 0.164376\n",
      "[3669]\ttraining's binary_logloss: 0.164359\n",
      "[3670]\ttraining's binary_logloss: 0.164344\n",
      "[3671]\ttraining's binary_logloss: 0.164324\n",
      "[3672]\ttraining's binary_logloss: 0.164307\n",
      "[3673]\ttraining's binary_logloss: 0.16429\n",
      "[3674]\ttraining's binary_logloss: 0.164274\n",
      "[3675]\ttraining's binary_logloss: 0.164261\n",
      "[3676]\ttraining's binary_logloss: 0.16424\n",
      "[3677]\ttraining's binary_logloss: 0.16423\n",
      "[3678]\ttraining's binary_logloss: 0.164218\n",
      "[3679]\ttraining's binary_logloss: 0.164209\n",
      "[3680]\ttraining's binary_logloss: 0.164192\n",
      "[3681]\ttraining's binary_logloss: 0.164178\n",
      "[3682]\ttraining's binary_logloss: 0.164159\n",
      "[3683]\ttraining's binary_logloss: 0.164143\n",
      "[3684]\ttraining's binary_logloss: 0.164126\n",
      "[3685]\ttraining's binary_logloss: 0.164115\n",
      "[3686]\ttraining's binary_logloss: 0.164104\n",
      "[3687]\ttraining's binary_logloss: 0.164087\n",
      "[3688]\ttraining's binary_logloss: 0.164079\n",
      "[3689]\ttraining's binary_logloss: 0.164067\n",
      "[3690]\ttraining's binary_logloss: 0.164057\n",
      "[3691]\ttraining's binary_logloss: 0.164041\n",
      "[3692]\ttraining's binary_logloss: 0.164025\n",
      "[3693]\ttraining's binary_logloss: 0.164008\n",
      "[3694]\ttraining's binary_logloss: 0.163993\n",
      "[3695]\ttraining's binary_logloss: 0.16398\n",
      "[3696]\ttraining's binary_logloss: 0.163961\n",
      "[3697]\ttraining's binary_logloss: 0.163941\n",
      "[3698]\ttraining's binary_logloss: 0.163925\n",
      "[3699]\ttraining's binary_logloss: 0.163909\n",
      "[3700]\ttraining's binary_logloss: 0.163893\n",
      "[3701]\ttraining's binary_logloss: 0.163876\n",
      "[3702]\ttraining's binary_logloss: 0.163856\n",
      "[3703]\ttraining's binary_logloss: 0.163836\n",
      "[3704]\ttraining's binary_logloss: 0.16382\n",
      "[3705]\ttraining's binary_logloss: 0.163801\n",
      "[3706]\ttraining's binary_logloss: 0.16379\n",
      "[3707]\ttraining's binary_logloss: 0.163782\n",
      "[3708]\ttraining's binary_logloss: 0.163764\n",
      "[3709]\ttraining's binary_logloss: 0.163748\n",
      "[3710]\ttraining's binary_logloss: 0.163745\n",
      "[3711]\ttraining's binary_logloss: 0.163741\n",
      "[3712]\ttraining's binary_logloss: 0.163726\n",
      "[3713]\ttraining's binary_logloss: 0.163707\n",
      "[3714]\ttraining's binary_logloss: 0.163702\n",
      "[3715]\ttraining's binary_logloss: 0.163686\n",
      "[3716]\ttraining's binary_logloss: 0.163668\n",
      "[3717]\ttraining's binary_logloss: 0.163658\n",
      "[3718]\ttraining's binary_logloss: 0.163641\n",
      "[3719]\ttraining's binary_logloss: 0.163627\n",
      "[3720]\ttraining's binary_logloss: 0.163608\n",
      "[3721]\ttraining's binary_logloss: 0.163592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3722]\ttraining's binary_logloss: 0.163577\n",
      "[3723]\ttraining's binary_logloss: 0.16356\n",
      "[3724]\ttraining's binary_logloss: 0.163547\n",
      "[3725]\ttraining's binary_logloss: 0.163533\n",
      "[3726]\ttraining's binary_logloss: 0.163519\n",
      "[3727]\ttraining's binary_logloss: 0.163503\n",
      "[3728]\ttraining's binary_logloss: 0.163485\n",
      "[3729]\ttraining's binary_logloss: 0.163479\n",
      "[3730]\ttraining's binary_logloss: 0.163464\n",
      "[3731]\ttraining's binary_logloss: 0.16346\n",
      "[3732]\ttraining's binary_logloss: 0.16344\n",
      "[3733]\ttraining's binary_logloss: 0.163426\n",
      "[3734]\ttraining's binary_logloss: 0.163409\n",
      "[3735]\ttraining's binary_logloss: 0.163391\n",
      "[3736]\ttraining's binary_logloss: 0.163375\n",
      "[3737]\ttraining's binary_logloss: 0.163373\n",
      "[3738]\ttraining's binary_logloss: 0.163355\n",
      "[3739]\ttraining's binary_logloss: 0.16334\n",
      "[3740]\ttraining's binary_logloss: 0.163323\n",
      "[3741]\ttraining's binary_logloss: 0.163306\n",
      "[3742]\ttraining's binary_logloss: 0.163297\n",
      "[3743]\ttraining's binary_logloss: 0.163288\n",
      "[3744]\ttraining's binary_logloss: 0.163272\n",
      "[3745]\ttraining's binary_logloss: 0.163256\n",
      "[3746]\ttraining's binary_logloss: 0.163239\n",
      "[3747]\ttraining's binary_logloss: 0.163223\n",
      "[3748]\ttraining's binary_logloss: 0.163203\n",
      "[3749]\ttraining's binary_logloss: 0.163201\n",
      "[3750]\ttraining's binary_logloss: 0.163188\n",
      "[3751]\ttraining's binary_logloss: 0.163186\n",
      "[3752]\ttraining's binary_logloss: 0.163169\n",
      "[3753]\ttraining's binary_logloss: 0.163152\n",
      "[3754]\ttraining's binary_logloss: 0.163142\n",
      "[3755]\ttraining's binary_logloss: 0.163125\n",
      "[3756]\ttraining's binary_logloss: 0.163112\n",
      "[3757]\ttraining's binary_logloss: 0.163096\n",
      "[3758]\ttraining's binary_logloss: 0.163079\n",
      "[3759]\ttraining's binary_logloss: 0.163069\n",
      "[3760]\ttraining's binary_logloss: 0.16306\n",
      "[3761]\ttraining's binary_logloss: 0.163046\n",
      "[3762]\ttraining's binary_logloss: 0.163038\n",
      "[3763]\ttraining's binary_logloss: 0.163023\n",
      "[3764]\ttraining's binary_logloss: 0.163007\n",
      "[3765]\ttraining's binary_logloss: 0.163004\n",
      "[3766]\ttraining's binary_logloss: 0.162988\n",
      "[3767]\ttraining's binary_logloss: 0.16297\n",
      "[3768]\ttraining's binary_logloss: 0.162954\n",
      "[3769]\ttraining's binary_logloss: 0.162938\n",
      "[3770]\ttraining's binary_logloss: 0.162931\n",
      "[3771]\ttraining's binary_logloss: 0.162915\n",
      "[3772]\ttraining's binary_logloss: 0.162902\n",
      "[3773]\ttraining's binary_logloss: 0.162886\n",
      "[3774]\ttraining's binary_logloss: 0.162874\n",
      "[3775]\ttraining's binary_logloss: 0.162855\n",
      "[3776]\ttraining's binary_logloss: 0.162839\n",
      "[3777]\ttraining's binary_logloss: 0.162834\n",
      "[3778]\ttraining's binary_logloss: 0.162815\n",
      "[3779]\ttraining's binary_logloss: 0.162797\n",
      "[3780]\ttraining's binary_logloss: 0.162782\n",
      "[3781]\ttraining's binary_logloss: 0.162766\n",
      "[3782]\ttraining's binary_logloss: 0.162749\n",
      "[3783]\ttraining's binary_logloss: 0.162732\n",
      "[3784]\ttraining's binary_logloss: 0.16272\n",
      "[3785]\ttraining's binary_logloss: 0.162705\n",
      "[3786]\ttraining's binary_logloss: 0.162701\n",
      "[3787]\ttraining's binary_logloss: 0.162693\n",
      "[3788]\ttraining's binary_logloss: 0.162678\n",
      "[3789]\ttraining's binary_logloss: 0.162661\n",
      "[3790]\ttraining's binary_logloss: 0.162644\n",
      "[3791]\ttraining's binary_logloss: 0.162632\n",
      "[3792]\ttraining's binary_logloss: 0.162616\n",
      "[3793]\ttraining's binary_logloss: 0.162602\n",
      "[3794]\ttraining's binary_logloss: 0.162586\n",
      "[3795]\ttraining's binary_logloss: 0.162569\n",
      "[3796]\ttraining's binary_logloss: 0.162564\n",
      "[3797]\ttraining's binary_logloss: 0.16255\n",
      "[3798]\ttraining's binary_logloss: 0.16254\n",
      "[3799]\ttraining's binary_logloss: 0.162522\n",
      "[3800]\ttraining's binary_logloss: 0.16252\n",
      "[3801]\ttraining's binary_logloss: 0.162516\n",
      "[3802]\ttraining's binary_logloss: 0.162503\n",
      "[3803]\ttraining's binary_logloss: 0.162493\n",
      "[3804]\ttraining's binary_logloss: 0.162484\n",
      "[3805]\ttraining's binary_logloss: 0.162466\n",
      "[3806]\ttraining's binary_logloss: 0.16245\n",
      "[3807]\ttraining's binary_logloss: 0.162431\n",
      "[3808]\ttraining's binary_logloss: 0.162421\n",
      "[3809]\ttraining's binary_logloss: 0.162405\n",
      "[3810]\ttraining's binary_logloss: 0.162387\n",
      "[3811]\ttraining's binary_logloss: 0.162371\n",
      "[3812]\ttraining's binary_logloss: 0.162356\n",
      "[3813]\ttraining's binary_logloss: 0.162351\n",
      "[3814]\ttraining's binary_logloss: 0.162333\n",
      "[3815]\ttraining's binary_logloss: 0.162316\n",
      "[3816]\ttraining's binary_logloss: 0.162301\n",
      "[3817]\ttraining's binary_logloss: 0.162283\n",
      "[3818]\ttraining's binary_logloss: 0.162265\n",
      "[3819]\ttraining's binary_logloss: 0.16225\n",
      "[3820]\ttraining's binary_logloss: 0.16224\n",
      "[3821]\ttraining's binary_logloss: 0.162225\n",
      "[3822]\ttraining's binary_logloss: 0.162212\n",
      "[3823]\ttraining's binary_logloss: 0.162196\n",
      "[3824]\ttraining's binary_logloss: 0.162181\n",
      "[3825]\ttraining's binary_logloss: 0.162161\n",
      "[3826]\ttraining's binary_logloss: 0.162154\n",
      "[3827]\ttraining's binary_logloss: 0.16215\n",
      "[3828]\ttraining's binary_logloss: 0.162137\n",
      "[3829]\ttraining's binary_logloss: 0.16212\n",
      "[3830]\ttraining's binary_logloss: 0.162104\n",
      "[3831]\ttraining's binary_logloss: 0.162094\n",
      "[3832]\ttraining's binary_logloss: 0.162091\n",
      "[3833]\ttraining's binary_logloss: 0.162074\n",
      "[3834]\ttraining's binary_logloss: 0.162059\n",
      "[3835]\ttraining's binary_logloss: 0.16204\n",
      "[3836]\ttraining's binary_logloss: 0.162025\n",
      "[3837]\ttraining's binary_logloss: 0.162017\n",
      "[3838]\ttraining's binary_logloss: 0.162012\n",
      "[3839]\ttraining's binary_logloss: 0.161995\n",
      "[3840]\ttraining's binary_logloss: 0.161978\n",
      "[3841]\ttraining's binary_logloss: 0.161962\n",
      "[3842]\ttraining's binary_logloss: 0.161944\n",
      "[3843]\ttraining's binary_logloss: 0.161934\n",
      "[3844]\ttraining's binary_logloss: 0.161918\n",
      "[3845]\ttraining's binary_logloss: 0.16191\n",
      "[3846]\ttraining's binary_logloss: 0.161905\n",
      "[3847]\ttraining's binary_logloss: 0.161902\n",
      "[3848]\ttraining's binary_logloss: 0.161887\n",
      "[3849]\ttraining's binary_logloss: 0.161872\n",
      "[3850]\ttraining's binary_logloss: 0.161863\n",
      "[3851]\ttraining's binary_logloss: 0.161857\n",
      "[3852]\ttraining's binary_logloss: 0.161846\n",
      "[3853]\ttraining's binary_logloss: 0.16183\n",
      "[3854]\ttraining's binary_logloss: 0.161814\n",
      "[3855]\ttraining's binary_logloss: 0.161795\n",
      "[3856]\ttraining's binary_logloss: 0.161779\n",
      "[3857]\ttraining's binary_logloss: 0.161759\n",
      "[3858]\ttraining's binary_logloss: 0.161742\n",
      "[3859]\ttraining's binary_logloss: 0.161726\n",
      "[3860]\ttraining's binary_logloss: 0.161711\n",
      "[3861]\ttraining's binary_logloss: 0.161696\n",
      "[3862]\ttraining's binary_logloss: 0.161677\n",
      "[3863]\ttraining's binary_logloss: 0.161663\n",
      "[3864]\ttraining's binary_logloss: 0.161646\n",
      "[3865]\ttraining's binary_logloss: 0.16163\n",
      "[3866]\ttraining's binary_logloss: 0.161618\n",
      "[3867]\ttraining's binary_logloss: 0.161604\n",
      "[3868]\ttraining's binary_logloss: 0.161593\n",
      "[3869]\ttraining's binary_logloss: 0.161574\n",
      "[3870]\ttraining's binary_logloss: 0.161557\n",
      "[3871]\ttraining's binary_logloss: 0.161539\n",
      "[3872]\ttraining's binary_logloss: 0.161524\n",
      "[3873]\ttraining's binary_logloss: 0.161508\n",
      "[3874]\ttraining's binary_logloss: 0.161496\n",
      "[3875]\ttraining's binary_logloss: 0.161482\n",
      "[3876]\ttraining's binary_logloss: 0.161475\n",
      "[3877]\ttraining's binary_logloss: 0.161461\n",
      "[3878]\ttraining's binary_logloss: 0.161445\n",
      "[3879]\ttraining's binary_logloss: 0.161428\n",
      "[3880]\ttraining's binary_logloss: 0.161412\n",
      "[3881]\ttraining's binary_logloss: 0.161396\n",
      "[3882]\ttraining's binary_logloss: 0.161386\n",
      "[3883]\ttraining's binary_logloss: 0.161372\n",
      "[3884]\ttraining's binary_logloss: 0.161356\n",
      "[3885]\ttraining's binary_logloss: 0.161342\n",
      "[3886]\ttraining's binary_logloss: 0.161325\n",
      "[3887]\ttraining's binary_logloss: 0.161309\n",
      "[3888]\ttraining's binary_logloss: 0.161293\n",
      "[3889]\ttraining's binary_logloss: 0.16128\n",
      "[3890]\ttraining's binary_logloss: 0.161264\n",
      "[3891]\ttraining's binary_logloss: 0.161249\n",
      "[3892]\ttraining's binary_logloss: 0.161233\n",
      "[3893]\ttraining's binary_logloss: 0.161222\n",
      "[3894]\ttraining's binary_logloss: 0.161206\n",
      "[3895]\ttraining's binary_logloss: 0.161191\n",
      "[3896]\ttraining's binary_logloss: 0.161176\n",
      "[3897]\ttraining's binary_logloss: 0.161164\n",
      "[3898]\ttraining's binary_logloss: 0.161149\n",
      "[3899]\ttraining's binary_logloss: 0.161134\n",
      "[3900]\ttraining's binary_logloss: 0.161116\n",
      "[3901]\ttraining's binary_logloss: 0.1611\n",
      "[3902]\ttraining's binary_logloss: 0.161082\n",
      "[3903]\ttraining's binary_logloss: 0.161066\n",
      "[3904]\ttraining's binary_logloss: 0.161051\n",
      "[3905]\ttraining's binary_logloss: 0.161038\n",
      "[3906]\ttraining's binary_logloss: 0.161022\n",
      "[3907]\ttraining's binary_logloss: 0.161008\n",
      "[3908]\ttraining's binary_logloss: 0.161005\n",
      "[3909]\ttraining's binary_logloss: 0.160999\n",
      "[3910]\ttraining's binary_logloss: 0.160986\n",
      "[3911]\ttraining's binary_logloss: 0.16098\n",
      "[3912]\ttraining's binary_logloss: 0.160968\n",
      "[3913]\ttraining's binary_logloss: 0.16095\n",
      "[3914]\ttraining's binary_logloss: 0.160935\n",
      "[3915]\ttraining's binary_logloss: 0.160921\n",
      "[3916]\ttraining's binary_logloss: 0.160909\n",
      "[3917]\ttraining's binary_logloss: 0.160897\n",
      "[3918]\ttraining's binary_logloss: 0.160886\n",
      "[3919]\ttraining's binary_logloss: 0.160876\n",
      "[3920]\ttraining's binary_logloss: 0.160859\n",
      "[3921]\ttraining's binary_logloss: 0.160844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3922]\ttraining's binary_logloss: 0.160829\n",
      "[3923]\ttraining's binary_logloss: 0.160813\n",
      "[3924]\ttraining's binary_logloss: 0.160802\n",
      "[3925]\ttraining's binary_logloss: 0.160785\n",
      "[3926]\ttraining's binary_logloss: 0.160769\n",
      "[3927]\ttraining's binary_logloss: 0.160758\n",
      "[3928]\ttraining's binary_logloss: 0.160742\n",
      "[3929]\ttraining's binary_logloss: 0.160727\n",
      "[3930]\ttraining's binary_logloss: 0.160712\n",
      "[3931]\ttraining's binary_logloss: 0.160701\n",
      "[3932]\ttraining's binary_logloss: 0.160685\n",
      "[3933]\ttraining's binary_logloss: 0.160675\n",
      "[3934]\ttraining's binary_logloss: 0.16066\n",
      "[3935]\ttraining's binary_logloss: 0.160654\n",
      "[3936]\ttraining's binary_logloss: 0.160638\n",
      "[3937]\ttraining's binary_logloss: 0.160626\n",
      "[3938]\ttraining's binary_logloss: 0.160619\n",
      "[3939]\ttraining's binary_logloss: 0.160601\n",
      "[3940]\ttraining's binary_logloss: 0.160585\n",
      "[3941]\ttraining's binary_logloss: 0.160572\n",
      "[3942]\ttraining's binary_logloss: 0.160558\n",
      "[3943]\ttraining's binary_logloss: 0.160545\n",
      "[3944]\ttraining's binary_logloss: 0.160528\n",
      "[3945]\ttraining's binary_logloss: 0.160511\n",
      "[3946]\ttraining's binary_logloss: 0.160494\n",
      "[3947]\ttraining's binary_logloss: 0.160478\n",
      "[3948]\ttraining's binary_logloss: 0.160463\n",
      "[3949]\ttraining's binary_logloss: 0.160445\n",
      "[3950]\ttraining's binary_logloss: 0.160429\n",
      "[3951]\ttraining's binary_logloss: 0.160416\n",
      "[3952]\ttraining's binary_logloss: 0.16041\n",
      "[3953]\ttraining's binary_logloss: 0.1604\n",
      "[3954]\ttraining's binary_logloss: 0.160385\n",
      "[3955]\ttraining's binary_logloss: 0.160378\n",
      "[3956]\ttraining's binary_logloss: 0.160359\n",
      "[3957]\ttraining's binary_logloss: 0.160343\n",
      "[3958]\ttraining's binary_logloss: 0.160327\n",
      "[3959]\ttraining's binary_logloss: 0.160311\n",
      "[3960]\ttraining's binary_logloss: 0.160303\n",
      "[3961]\ttraining's binary_logloss: 0.160287\n",
      "[3962]\ttraining's binary_logloss: 0.160281\n",
      "[3963]\ttraining's binary_logloss: 0.160265\n",
      "[3964]\ttraining's binary_logloss: 0.16025\n",
      "[3965]\ttraining's binary_logloss: 0.160235\n",
      "[3966]\ttraining's binary_logloss: 0.160219\n",
      "[3967]\ttraining's binary_logloss: 0.160207\n",
      "[3968]\ttraining's binary_logloss: 0.160194\n",
      "[3969]\ttraining's binary_logloss: 0.160179\n",
      "[3970]\ttraining's binary_logloss: 0.160161\n",
      "[3971]\ttraining's binary_logloss: 0.160146\n",
      "[3972]\ttraining's binary_logloss: 0.160136\n",
      "[3973]\ttraining's binary_logloss: 0.160121\n",
      "[3974]\ttraining's binary_logloss: 0.160105\n",
      "[3975]\ttraining's binary_logloss: 0.160099\n",
      "[3976]\ttraining's binary_logloss: 0.160092\n",
      "[3977]\ttraining's binary_logloss: 0.160075\n",
      "[3978]\ttraining's binary_logloss: 0.160068\n",
      "[3979]\ttraining's binary_logloss: 0.160052\n",
      "[3980]\ttraining's binary_logloss: 0.160046\n",
      "[3981]\ttraining's binary_logloss: 0.160029\n",
      "[3982]\ttraining's binary_logloss: 0.160026\n",
      "[3983]\ttraining's binary_logloss: 0.160009\n",
      "[3984]\ttraining's binary_logloss: 0.160002\n",
      "[3985]\ttraining's binary_logloss: 0.159983\n",
      "[3986]\ttraining's binary_logloss: 0.159968\n",
      "[3987]\ttraining's binary_logloss: 0.159952\n",
      "[3988]\ttraining's binary_logloss: 0.159936\n",
      "[3989]\ttraining's binary_logloss: 0.159922\n",
      "[3990]\ttraining's binary_logloss: 0.159907\n",
      "[3991]\ttraining's binary_logloss: 0.159893\n",
      "[3992]\ttraining's binary_logloss: 0.159875\n",
      "[3993]\ttraining's binary_logloss: 0.159858\n",
      "[3994]\ttraining's binary_logloss: 0.159843\n",
      "[3995]\ttraining's binary_logloss: 0.159835\n",
      "[3996]\ttraining's binary_logloss: 0.159819\n",
      "[3997]\ttraining's binary_logloss: 0.159807\n",
      "[3998]\ttraining's binary_logloss: 0.159791\n",
      "[3999]\ttraining's binary_logloss: 0.159777\n",
      "[4000]\ttraining's binary_logloss: 0.159761\n",
      "[4001]\ttraining's binary_logloss: 0.159745\n",
      "[4002]\ttraining's binary_logloss: 0.159729\n",
      "[4003]\ttraining's binary_logloss: 0.159713\n",
      "[4004]\ttraining's binary_logloss: 0.159698\n",
      "[4005]\ttraining's binary_logloss: 0.159682\n",
      "[4006]\ttraining's binary_logloss: 0.159666\n",
      "[4007]\ttraining's binary_logloss: 0.159654\n",
      "[4008]\ttraining's binary_logloss: 0.159638\n",
      "[4009]\ttraining's binary_logloss: 0.159623\n",
      "[4010]\ttraining's binary_logloss: 0.159607\n",
      "[4011]\ttraining's binary_logloss: 0.159593\n",
      "[4012]\ttraining's binary_logloss: 0.159579\n",
      "[4013]\ttraining's binary_logloss: 0.159566\n",
      "[4014]\ttraining's binary_logloss: 0.159552\n",
      "[4015]\ttraining's binary_logloss: 0.159536\n",
      "[4016]\ttraining's binary_logloss: 0.159521\n",
      "[4017]\ttraining's binary_logloss: 0.159506\n",
      "[4018]\ttraining's binary_logloss: 0.159493\n",
      "[4019]\ttraining's binary_logloss: 0.159479\n",
      "[4020]\ttraining's binary_logloss: 0.159465\n",
      "[4021]\ttraining's binary_logloss: 0.159452\n",
      "[4022]\ttraining's binary_logloss: 0.159446\n",
      "[4023]\ttraining's binary_logloss: 0.159429\n",
      "[4024]\ttraining's binary_logloss: 0.159413\n",
      "[4025]\ttraining's binary_logloss: 0.159398\n",
      "[4026]\ttraining's binary_logloss: 0.159382\n",
      "[4027]\ttraining's binary_logloss: 0.159367\n",
      "[4028]\ttraining's binary_logloss: 0.159355\n",
      "[4029]\ttraining's binary_logloss: 0.15934\n",
      "[4030]\ttraining's binary_logloss: 0.159332\n",
      "[4031]\ttraining's binary_logloss: 0.159314\n",
      "[4032]\ttraining's binary_logloss: 0.159302\n",
      "[4033]\ttraining's binary_logloss: 0.159292\n",
      "[4034]\ttraining's binary_logloss: 0.159277\n",
      "[4035]\ttraining's binary_logloss: 0.159261\n",
      "[4036]\ttraining's binary_logloss: 0.159243\n",
      "[4037]\ttraining's binary_logloss: 0.15923\n",
      "[4038]\ttraining's binary_logloss: 0.159215\n",
      "[4039]\ttraining's binary_logloss: 0.159199\n",
      "[4040]\ttraining's binary_logloss: 0.159186\n",
      "[4041]\ttraining's binary_logloss: 0.159175\n",
      "[4042]\ttraining's binary_logloss: 0.159167\n",
      "[4043]\ttraining's binary_logloss: 0.159154\n",
      "[4044]\ttraining's binary_logloss: 0.159139\n",
      "[4045]\ttraining's binary_logloss: 0.159123\n",
      "[4046]\ttraining's binary_logloss: 0.15911\n",
      "[4047]\ttraining's binary_logloss: 0.159093\n",
      "[4048]\ttraining's binary_logloss: 0.159076\n",
      "[4049]\ttraining's binary_logloss: 0.159065\n",
      "[4050]\ttraining's binary_logloss: 0.159053\n",
      "[4051]\ttraining's binary_logloss: 0.159047\n",
      "[4052]\ttraining's binary_logloss: 0.15903\n",
      "[4053]\ttraining's binary_logloss: 0.159016\n",
      "[4054]\ttraining's binary_logloss: 0.158997\n",
      "[4055]\ttraining's binary_logloss: 0.158989\n",
      "[4056]\ttraining's binary_logloss: 0.158977\n",
      "[4057]\ttraining's binary_logloss: 0.158965\n",
      "[4058]\ttraining's binary_logloss: 0.158949\n",
      "[4059]\ttraining's binary_logloss: 0.158934\n",
      "[4060]\ttraining's binary_logloss: 0.158923\n",
      "[4061]\ttraining's binary_logloss: 0.158919\n",
      "[4062]\ttraining's binary_logloss: 0.158913\n",
      "[4063]\ttraining's binary_logloss: 0.158897\n",
      "[4064]\ttraining's binary_logloss: 0.158882\n",
      "[4065]\ttraining's binary_logloss: 0.15887\n",
      "[4066]\ttraining's binary_logloss: 0.158856\n",
      "[4067]\ttraining's binary_logloss: 0.158839\n",
      "[4068]\ttraining's binary_logloss: 0.158826\n",
      "[4069]\ttraining's binary_logloss: 0.158809\n",
      "[4070]\ttraining's binary_logloss: 0.158794\n",
      "[4071]\ttraining's binary_logloss: 0.158774\n",
      "[4072]\ttraining's binary_logloss: 0.158762\n",
      "[4073]\ttraining's binary_logloss: 0.158754\n",
      "[4074]\ttraining's binary_logloss: 0.158739\n",
      "[4075]\ttraining's binary_logloss: 0.158727\n",
      "[4076]\ttraining's binary_logloss: 0.158711\n",
      "[4077]\ttraining's binary_logloss: 0.158694\n",
      "[4078]\ttraining's binary_logloss: 0.158681\n",
      "[4079]\ttraining's binary_logloss: 0.158665\n",
      "[4080]\ttraining's binary_logloss: 0.158648\n",
      "[4081]\ttraining's binary_logloss: 0.158633\n",
      "[4082]\ttraining's binary_logloss: 0.15862\n",
      "[4083]\ttraining's binary_logloss: 0.158607\n",
      "[4084]\ttraining's binary_logloss: 0.15859\n",
      "[4085]\ttraining's binary_logloss: 0.158574\n",
      "[4086]\ttraining's binary_logloss: 0.158557\n",
      "[4087]\ttraining's binary_logloss: 0.158543\n",
      "[4088]\ttraining's binary_logloss: 0.158539\n",
      "[4089]\ttraining's binary_logloss: 0.158528\n",
      "[4090]\ttraining's binary_logloss: 0.158512\n",
      "[4091]\ttraining's binary_logloss: 0.158496\n",
      "[4092]\ttraining's binary_logloss: 0.158478\n",
      "[4093]\ttraining's binary_logloss: 0.158464\n",
      "[4094]\ttraining's binary_logloss: 0.158446\n",
      "[4095]\ttraining's binary_logloss: 0.158431\n",
      "[4096]\ttraining's binary_logloss: 0.158416\n",
      "[4097]\ttraining's binary_logloss: 0.158412\n",
      "[4098]\ttraining's binary_logloss: 0.158398\n",
      "[4099]\ttraining's binary_logloss: 0.15838\n",
      "[4100]\ttraining's binary_logloss: 0.158362\n",
      "[4101]\ttraining's binary_logloss: 0.158346\n",
      "[4102]\ttraining's binary_logloss: 0.158333\n",
      "[4103]\ttraining's binary_logloss: 0.158319\n",
      "[4104]\ttraining's binary_logloss: 0.158307\n",
      "[4105]\ttraining's binary_logloss: 0.158289\n",
      "[4106]\ttraining's binary_logloss: 0.158273\n",
      "[4107]\ttraining's binary_logloss: 0.158259\n",
      "[4108]\ttraining's binary_logloss: 0.158241\n",
      "[4109]\ttraining's binary_logloss: 0.158227\n",
      "[4110]\ttraining's binary_logloss: 0.158223\n",
      "[4111]\ttraining's binary_logloss: 0.158217\n",
      "[4112]\ttraining's binary_logloss: 0.158205\n",
      "[4113]\ttraining's binary_logloss: 0.158198\n",
      "[4114]\ttraining's binary_logloss: 0.158181\n",
      "[4115]\ttraining's binary_logloss: 0.158165\n",
      "[4116]\ttraining's binary_logloss: 0.158155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4117]\ttraining's binary_logloss: 0.158141\n",
      "[4118]\ttraining's binary_logloss: 0.158128\n",
      "[4119]\ttraining's binary_logloss: 0.158126\n",
      "[4120]\ttraining's binary_logloss: 0.158114\n",
      "[4121]\ttraining's binary_logloss: 0.158098\n",
      "[4122]\ttraining's binary_logloss: 0.158082\n",
      "[4123]\ttraining's binary_logloss: 0.158065\n",
      "[4124]\ttraining's binary_logloss: 0.158052\n",
      "[4125]\ttraining's binary_logloss: 0.158035\n",
      "[4126]\ttraining's binary_logloss: 0.15802\n",
      "[4127]\ttraining's binary_logloss: 0.158004\n",
      "[4128]\ttraining's binary_logloss: 0.157989\n",
      "[4129]\ttraining's binary_logloss: 0.157975\n",
      "[4130]\ttraining's binary_logloss: 0.157961\n",
      "[4131]\ttraining's binary_logloss: 0.15795\n",
      "[4132]\ttraining's binary_logloss: 0.157943\n",
      "[4133]\ttraining's binary_logloss: 0.157937\n",
      "[4134]\ttraining's binary_logloss: 0.157921\n",
      "[4135]\ttraining's binary_logloss: 0.157905\n",
      "[4136]\ttraining's binary_logloss: 0.157889\n",
      "[4137]\ttraining's binary_logloss: 0.157875\n",
      "[4138]\ttraining's binary_logloss: 0.157859\n",
      "[4139]\ttraining's binary_logloss: 0.157843\n",
      "[4140]\ttraining's binary_logloss: 0.157826\n",
      "[4141]\ttraining's binary_logloss: 0.15782\n",
      "[4142]\ttraining's binary_logloss: 0.157812\n",
      "[4143]\ttraining's binary_logloss: 0.1578\n",
      "[4144]\ttraining's binary_logloss: 0.157784\n",
      "[4145]\ttraining's binary_logloss: 0.15777\n",
      "[4146]\ttraining's binary_logloss: 0.15776\n",
      "[4147]\ttraining's binary_logloss: 0.157744\n",
      "[4148]\ttraining's binary_logloss: 0.157731\n",
      "[4149]\ttraining's binary_logloss: 0.157728\n",
      "[4150]\ttraining's binary_logloss: 0.157716\n",
      "[4151]\ttraining's binary_logloss: 0.1577\n",
      "[4152]\ttraining's binary_logloss: 0.157681\n",
      "[4153]\ttraining's binary_logloss: 0.157664\n",
      "[4154]\ttraining's binary_logloss: 0.157646\n",
      "[4155]\ttraining's binary_logloss: 0.15763\n",
      "[4156]\ttraining's binary_logloss: 0.157626\n",
      "[4157]\ttraining's binary_logloss: 0.15761\n",
      "[4158]\ttraining's binary_logloss: 0.157597\n",
      "[4159]\ttraining's binary_logloss: 0.15758\n",
      "[4160]\ttraining's binary_logloss: 0.157562\n",
      "[4161]\ttraining's binary_logloss: 0.157545\n",
      "[4162]\ttraining's binary_logloss: 0.157528\n",
      "[4163]\ttraining's binary_logloss: 0.157511\n",
      "[4164]\ttraining's binary_logloss: 0.157495\n",
      "[4165]\ttraining's binary_logloss: 0.157482\n",
      "[4166]\ttraining's binary_logloss: 0.157467\n",
      "[4167]\ttraining's binary_logloss: 0.157452\n",
      "[4168]\ttraining's binary_logloss: 0.157445\n",
      "[4169]\ttraining's binary_logloss: 0.157436\n",
      "[4170]\ttraining's binary_logloss: 0.157421\n",
      "[4171]\ttraining's binary_logloss: 0.157411\n",
      "[4172]\ttraining's binary_logloss: 0.157394\n",
      "[4173]\ttraining's binary_logloss: 0.157377\n",
      "[4174]\ttraining's binary_logloss: 0.157361\n",
      "[4175]\ttraining's binary_logloss: 0.157345\n",
      "[4176]\ttraining's binary_logloss: 0.157326\n",
      "[4177]\ttraining's binary_logloss: 0.157308\n",
      "[4178]\ttraining's binary_logloss: 0.157296\n",
      "[4179]\ttraining's binary_logloss: 0.157279\n",
      "[4180]\ttraining's binary_logloss: 0.157263\n",
      "[4181]\ttraining's binary_logloss: 0.157251\n",
      "[4182]\ttraining's binary_logloss: 0.157233\n",
      "[4183]\ttraining's binary_logloss: 0.157215\n",
      "[4184]\ttraining's binary_logloss: 0.157198\n",
      "[4185]\ttraining's binary_logloss: 0.157183\n",
      "[4186]\ttraining's binary_logloss: 0.157167\n",
      "[4187]\ttraining's binary_logloss: 0.157155\n",
      "[4188]\ttraining's binary_logloss: 0.157138\n",
      "[4189]\ttraining's binary_logloss: 0.157125\n",
      "[4190]\ttraining's binary_logloss: 0.157112\n",
      "[4191]\ttraining's binary_logloss: 0.157097\n",
      "[4192]\ttraining's binary_logloss: 0.157089\n",
      "[4193]\ttraining's binary_logloss: 0.157076\n",
      "[4194]\ttraining's binary_logloss: 0.157062\n",
      "[4195]\ttraining's binary_logloss: 0.157046\n",
      "[4196]\ttraining's binary_logloss: 0.157029\n",
      "[4197]\ttraining's binary_logloss: 0.157015\n",
      "[4198]\ttraining's binary_logloss: 0.157004\n",
      "[4199]\ttraining's binary_logloss: 0.156995\n",
      "[4200]\ttraining's binary_logloss: 0.15698\n",
      "[4201]\ttraining's binary_logloss: 0.156962\n",
      "[4202]\ttraining's binary_logloss: 0.156945\n",
      "[4203]\ttraining's binary_logloss: 0.156931\n",
      "[4204]\ttraining's binary_logloss: 0.156919\n",
      "[4205]\ttraining's binary_logloss: 0.156901\n",
      "[4206]\ttraining's binary_logloss: 0.156886\n",
      "[4207]\ttraining's binary_logloss: 0.156869\n",
      "[4208]\ttraining's binary_logloss: 0.156853\n",
      "[4209]\ttraining's binary_logloss: 0.156838\n",
      "[4210]\ttraining's binary_logloss: 0.156825\n",
      "[4211]\ttraining's binary_logloss: 0.156809\n",
      "[4212]\ttraining's binary_logloss: 0.156792\n",
      "[4213]\ttraining's binary_logloss: 0.156779\n",
      "[4214]\ttraining's binary_logloss: 0.156765\n",
      "[4215]\ttraining's binary_logloss: 0.156749\n",
      "[4216]\ttraining's binary_logloss: 0.156735\n",
      "[4217]\ttraining's binary_logloss: 0.156719\n",
      "[4218]\ttraining's binary_logloss: 0.156704\n",
      "[4219]\ttraining's binary_logloss: 0.15669\n",
      "[4220]\ttraining's binary_logloss: 0.156674\n",
      "[4221]\ttraining's binary_logloss: 0.156661\n",
      "[4222]\ttraining's binary_logloss: 0.156646\n",
      "[4223]\ttraining's binary_logloss: 0.156639\n",
      "[4224]\ttraining's binary_logloss: 0.156623\n",
      "[4225]\ttraining's binary_logloss: 0.156613\n",
      "[4226]\ttraining's binary_logloss: 0.156597\n",
      "[4227]\ttraining's binary_logloss: 0.156582\n",
      "[4228]\ttraining's binary_logloss: 0.156563\n",
      "[4229]\ttraining's binary_logloss: 0.156546\n",
      "[4230]\ttraining's binary_logloss: 0.15653\n",
      "[4231]\ttraining's binary_logloss: 0.156516\n",
      "[4232]\ttraining's binary_logloss: 0.156499\n",
      "[4233]\ttraining's binary_logloss: 0.156481\n",
      "[4234]\ttraining's binary_logloss: 0.156466\n",
      "[4235]\ttraining's binary_logloss: 0.156451\n",
      "[4236]\ttraining's binary_logloss: 0.156439\n",
      "[4237]\ttraining's binary_logloss: 0.156424\n",
      "[4238]\ttraining's binary_logloss: 0.156409\n",
      "[4239]\ttraining's binary_logloss: 0.156392\n",
      "[4240]\ttraining's binary_logloss: 0.156379\n",
      "[4241]\ttraining's binary_logloss: 0.156364\n",
      "[4242]\ttraining's binary_logloss: 0.156347\n",
      "[4243]\ttraining's binary_logloss: 0.156331\n",
      "[4244]\ttraining's binary_logloss: 0.156316\n",
      "[4245]\ttraining's binary_logloss: 0.156299\n",
      "[4246]\ttraining's binary_logloss: 0.156292\n",
      "[4247]\ttraining's binary_logloss: 0.156278\n",
      "[4248]\ttraining's binary_logloss: 0.156264\n",
      "[4249]\ttraining's binary_logloss: 0.156251\n",
      "[4250]\ttraining's binary_logloss: 0.156235\n",
      "[4251]\ttraining's binary_logloss: 0.156219\n",
      "[4252]\ttraining's binary_logloss: 0.156208\n",
      "[4253]\ttraining's binary_logloss: 0.156193\n",
      "[4254]\ttraining's binary_logloss: 0.156176\n",
      "[4255]\ttraining's binary_logloss: 0.156159\n",
      "[4256]\ttraining's binary_logloss: 0.15614\n",
      "[4257]\ttraining's binary_logloss: 0.156126\n",
      "[4258]\ttraining's binary_logloss: 0.156109\n",
      "[4259]\ttraining's binary_logloss: 0.156092\n",
      "[4260]\ttraining's binary_logloss: 0.156072\n",
      "[4261]\ttraining's binary_logloss: 0.156057\n",
      "[4262]\ttraining's binary_logloss: 0.156038\n",
      "[4263]\ttraining's binary_logloss: 0.156022\n",
      "[4264]\ttraining's binary_logloss: 0.156003\n",
      "[4265]\ttraining's binary_logloss: 0.155989\n",
      "[4266]\ttraining's binary_logloss: 0.155975\n",
      "[4267]\ttraining's binary_logloss: 0.155959\n",
      "[4268]\ttraining's binary_logloss: 0.155942\n",
      "[4269]\ttraining's binary_logloss: 0.155929\n",
      "[4270]\ttraining's binary_logloss: 0.155914\n",
      "[4271]\ttraining's binary_logloss: 0.155903\n",
      "[4272]\ttraining's binary_logloss: 0.155884\n",
      "[4273]\ttraining's binary_logloss: 0.15587\n",
      "[4274]\ttraining's binary_logloss: 0.155855\n",
      "[4275]\ttraining's binary_logloss: 0.15584\n",
      "[4276]\ttraining's binary_logloss: 0.155826\n",
      "[4277]\ttraining's binary_logloss: 0.155811\n",
      "[4278]\ttraining's binary_logloss: 0.155799\n",
      "[4279]\ttraining's binary_logloss: 0.155785\n",
      "[4280]\ttraining's binary_logloss: 0.155774\n",
      "[4281]\ttraining's binary_logloss: 0.155759\n",
      "[4282]\ttraining's binary_logloss: 0.155742\n",
      "[4283]\ttraining's binary_logloss: 0.155725\n",
      "[4284]\ttraining's binary_logloss: 0.155711\n",
      "[4285]\ttraining's binary_logloss: 0.155697\n",
      "[4286]\ttraining's binary_logloss: 0.155681\n",
      "[4287]\ttraining's binary_logloss: 0.155665\n",
      "[4288]\ttraining's binary_logloss: 0.15565\n",
      "[4289]\ttraining's binary_logloss: 0.155635\n",
      "[4290]\ttraining's binary_logloss: 0.155619\n",
      "[4291]\ttraining's binary_logloss: 0.155603\n",
      "[4292]\ttraining's binary_logloss: 0.155587\n",
      "[4293]\ttraining's binary_logloss: 0.155571\n",
      "[4294]\ttraining's binary_logloss: 0.155552\n",
      "[4295]\ttraining's binary_logloss: 0.155536\n",
      "[4296]\ttraining's binary_logloss: 0.15552\n",
      "[4297]\ttraining's binary_logloss: 0.155506\n",
      "[4298]\ttraining's binary_logloss: 0.155487\n",
      "[4299]\ttraining's binary_logloss: 0.155469\n",
      "[4300]\ttraining's binary_logloss: 0.155451\n",
      "[4301]\ttraining's binary_logloss: 0.155435\n",
      "[4302]\ttraining's binary_logloss: 0.15542\n",
      "[4303]\ttraining's binary_logloss: 0.155403\n",
      "[4304]\ttraining's binary_logloss: 0.155387\n",
      "[4305]\ttraining's binary_logloss: 0.155369\n",
      "[4306]\ttraining's binary_logloss: 0.155354\n",
      "[4307]\ttraining's binary_logloss: 0.155338\n",
      "[4308]\ttraining's binary_logloss: 0.155323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4309]\ttraining's binary_logloss: 0.155312\n",
      "[4310]\ttraining's binary_logloss: 0.155305\n",
      "[4311]\ttraining's binary_logloss: 0.15529\n",
      "[4312]\ttraining's binary_logloss: 0.155276\n",
      "[4313]\ttraining's binary_logloss: 0.155262\n",
      "[4314]\ttraining's binary_logloss: 0.155253\n",
      "[4315]\ttraining's binary_logloss: 0.155237\n",
      "[4316]\ttraining's binary_logloss: 0.155226\n",
      "[4317]\ttraining's binary_logloss: 0.155209\n",
      "[4318]\ttraining's binary_logloss: 0.155193\n",
      "[4319]\ttraining's binary_logloss: 0.155179\n",
      "[4320]\ttraining's binary_logloss: 0.155167\n",
      "[4321]\ttraining's binary_logloss: 0.155153\n",
      "[4322]\ttraining's binary_logloss: 0.155139\n",
      "[4323]\ttraining's binary_logloss: 0.155124\n",
      "[4324]\ttraining's binary_logloss: 0.155109\n",
      "[4325]\ttraining's binary_logloss: 0.155094\n",
      "[4326]\ttraining's binary_logloss: 0.155077\n",
      "[4327]\ttraining's binary_logloss: 0.15506\n",
      "[4328]\ttraining's binary_logloss: 0.155046\n",
      "[4329]\ttraining's binary_logloss: 0.155027\n",
      "[4330]\ttraining's binary_logloss: 0.155012\n",
      "[4331]\ttraining's binary_logloss: 0.155007\n",
      "[4332]\ttraining's binary_logloss: 0.155002\n",
      "[4333]\ttraining's binary_logloss: 0.154996\n",
      "[4334]\ttraining's binary_logloss: 0.154979\n",
      "[4335]\ttraining's binary_logloss: 0.154962\n",
      "[4336]\ttraining's binary_logloss: 0.154959\n",
      "[4337]\ttraining's binary_logloss: 0.154952\n",
      "[4338]\ttraining's binary_logloss: 0.15495\n",
      "[4339]\ttraining's binary_logloss: 0.154945\n",
      "[4340]\ttraining's binary_logloss: 0.154933\n",
      "[4341]\ttraining's binary_logloss: 0.154921\n",
      "[4342]\ttraining's binary_logloss: 0.154914\n",
      "[4343]\ttraining's binary_logloss: 0.154898\n",
      "[4344]\ttraining's binary_logloss: 0.154881\n",
      "[4345]\ttraining's binary_logloss: 0.154865\n",
      "[4346]\ttraining's binary_logloss: 0.154855\n",
      "[4347]\ttraining's binary_logloss: 0.154841\n",
      "[4348]\ttraining's binary_logloss: 0.154827\n",
      "[4349]\ttraining's binary_logloss: 0.154813\n",
      "[4350]\ttraining's binary_logloss: 0.154811\n",
      "[4351]\ttraining's binary_logloss: 0.154797\n",
      "[4352]\ttraining's binary_logloss: 0.154791\n",
      "[4353]\ttraining's binary_logloss: 0.154774\n",
      "[4354]\ttraining's binary_logloss: 0.154758\n",
      "[4355]\ttraining's binary_logloss: 0.154747\n",
      "[4356]\ttraining's binary_logloss: 0.154733\n",
      "[4357]\ttraining's binary_logloss: 0.154716\n",
      "[4358]\ttraining's binary_logloss: 0.154703\n",
      "[4359]\ttraining's binary_logloss: 0.154688\n",
      "[4360]\ttraining's binary_logloss: 0.154672\n",
      "[4361]\ttraining's binary_logloss: 0.154653\n",
      "[4362]\ttraining's binary_logloss: 0.154635\n",
      "[4363]\ttraining's binary_logloss: 0.154619\n",
      "[4364]\ttraining's binary_logloss: 0.154606\n",
      "[4365]\ttraining's binary_logloss: 0.154589\n",
      "[4366]\ttraining's binary_logloss: 0.154575\n",
      "[4367]\ttraining's binary_logloss: 0.154567\n",
      "[4368]\ttraining's binary_logloss: 0.154551\n",
      "[4369]\ttraining's binary_logloss: 0.154541\n",
      "[4370]\ttraining's binary_logloss: 0.154524\n",
      "[4371]\ttraining's binary_logloss: 0.154517\n",
      "[4372]\ttraining's binary_logloss: 0.1545\n",
      "[4373]\ttraining's binary_logloss: 0.154493\n",
      "[4374]\ttraining's binary_logloss: 0.154489\n",
      "[4375]\ttraining's binary_logloss: 0.154475\n",
      "[4376]\ttraining's binary_logloss: 0.154461\n",
      "[4377]\ttraining's binary_logloss: 0.154451\n",
      "[4378]\ttraining's binary_logloss: 0.154438\n",
      "[4379]\ttraining's binary_logloss: 0.154424\n",
      "[4380]\ttraining's binary_logloss: 0.15442\n",
      "[4381]\ttraining's binary_logloss: 0.154405\n",
      "[4382]\ttraining's binary_logloss: 0.15439\n",
      "[4383]\ttraining's binary_logloss: 0.154378\n",
      "[4384]\ttraining's binary_logloss: 0.154364\n",
      "[4385]\ttraining's binary_logloss: 0.154351\n",
      "[4386]\ttraining's binary_logloss: 0.154346\n",
      "[4387]\ttraining's binary_logloss: 0.154341\n",
      "[4388]\ttraining's binary_logloss: 0.154325\n",
      "[4389]\ttraining's binary_logloss: 0.154313\n",
      "[4390]\ttraining's binary_logloss: 0.154297\n",
      "[4391]\ttraining's binary_logloss: 0.15428\n",
      "[4392]\ttraining's binary_logloss: 0.154274\n",
      "[4393]\ttraining's binary_logloss: 0.154258\n",
      "[4394]\ttraining's binary_logloss: 0.154243\n",
      "[4395]\ttraining's binary_logloss: 0.154229\n",
      "[4396]\ttraining's binary_logloss: 0.154211\n",
      "[4397]\ttraining's binary_logloss: 0.154196\n",
      "[4398]\ttraining's binary_logloss: 0.154182\n",
      "[4399]\ttraining's binary_logloss: 0.154169\n",
      "[4400]\ttraining's binary_logloss: 0.154151\n",
      "[4401]\ttraining's binary_logloss: 0.154136\n",
      "[4402]\ttraining's binary_logloss: 0.154116\n",
      "[4403]\ttraining's binary_logloss: 0.154106\n",
      "[4404]\ttraining's binary_logloss: 0.154092\n",
      "[4405]\ttraining's binary_logloss: 0.154077\n",
      "[4406]\ttraining's binary_logloss: 0.154063\n",
      "[4407]\ttraining's binary_logloss: 0.154048\n",
      "[4408]\ttraining's binary_logloss: 0.154034\n",
      "[4409]\ttraining's binary_logloss: 0.154029\n",
      "[4410]\ttraining's binary_logloss: 0.154015\n",
      "[4411]\ttraining's binary_logloss: 0.153999\n",
      "[4412]\ttraining's binary_logloss: 0.153985\n",
      "[4413]\ttraining's binary_logloss: 0.153969\n",
      "[4414]\ttraining's binary_logloss: 0.153967\n",
      "[4415]\ttraining's binary_logloss: 0.153951\n",
      "[4416]\ttraining's binary_logloss: 0.153937\n",
      "[4417]\ttraining's binary_logloss: 0.153922\n",
      "[4418]\ttraining's binary_logloss: 0.153907\n",
      "[4419]\ttraining's binary_logloss: 0.153898\n",
      "[4420]\ttraining's binary_logloss: 0.153883\n",
      "[4421]\ttraining's binary_logloss: 0.153875\n",
      "[4422]\ttraining's binary_logloss: 0.153869\n",
      "[4423]\ttraining's binary_logloss: 0.153861\n",
      "[4424]\ttraining's binary_logloss: 0.15385\n",
      "[4425]\ttraining's binary_logloss: 0.153848\n",
      "[4426]\ttraining's binary_logloss: 0.153833\n",
      "[4427]\ttraining's binary_logloss: 0.153817\n",
      "[4428]\ttraining's binary_logloss: 0.153799\n",
      "[4429]\ttraining's binary_logloss: 0.153788\n",
      "[4430]\ttraining's binary_logloss: 0.153778\n",
      "[4431]\ttraining's binary_logloss: 0.153766\n",
      "[4432]\ttraining's binary_logloss: 0.153751\n",
      "[4433]\ttraining's binary_logloss: 0.153734\n",
      "[4434]\ttraining's binary_logloss: 0.15372\n",
      "[4435]\ttraining's binary_logloss: 0.153702\n",
      "[4436]\ttraining's binary_logloss: 0.153687\n",
      "[4437]\ttraining's binary_logloss: 0.153675\n",
      "[4438]\ttraining's binary_logloss: 0.153659\n",
      "[4439]\ttraining's binary_logloss: 0.153644\n",
      "[4440]\ttraining's binary_logloss: 0.153628\n",
      "[4441]\ttraining's binary_logloss: 0.15361\n",
      "[4442]\ttraining's binary_logloss: 0.153597\n",
      "[4443]\ttraining's binary_logloss: 0.15358\n",
      "[4444]\ttraining's binary_logloss: 0.153565\n",
      "[4445]\ttraining's binary_logloss: 0.15355\n",
      "[4446]\ttraining's binary_logloss: 0.153536\n",
      "[4447]\ttraining's binary_logloss: 0.153523\n",
      "[4448]\ttraining's binary_logloss: 0.153507\n",
      "[4449]\ttraining's binary_logloss: 0.153489\n",
      "[4450]\ttraining's binary_logloss: 0.153475\n",
      "[4451]\ttraining's binary_logloss: 0.153461\n",
      "[4452]\ttraining's binary_logloss: 0.153444\n",
      "[4453]\ttraining's binary_logloss: 0.153429\n",
      "[4454]\ttraining's binary_logloss: 0.153425\n",
      "[4455]\ttraining's binary_logloss: 0.15341\n",
      "[4456]\ttraining's binary_logloss: 0.153397\n",
      "[4457]\ttraining's binary_logloss: 0.153383\n",
      "[4458]\ttraining's binary_logloss: 0.153378\n",
      "[4459]\ttraining's binary_logloss: 0.153365\n",
      "[4460]\ttraining's binary_logloss: 0.15335\n",
      "[4461]\ttraining's binary_logloss: 0.153338\n",
      "[4462]\ttraining's binary_logloss: 0.153324\n",
      "[4463]\ttraining's binary_logloss: 0.153309\n",
      "[4464]\ttraining's binary_logloss: 0.153294\n",
      "[4465]\ttraining's binary_logloss: 0.153279\n",
      "[4466]\ttraining's binary_logloss: 0.153271\n",
      "[4467]\ttraining's binary_logloss: 0.153255\n",
      "[4468]\ttraining's binary_logloss: 0.15324\n",
      "[4469]\ttraining's binary_logloss: 0.153229\n",
      "[4470]\ttraining's binary_logloss: 0.153215\n",
      "[4471]\ttraining's binary_logloss: 0.153197\n",
      "[4472]\ttraining's binary_logloss: 0.153184\n",
      "[4473]\ttraining's binary_logloss: 0.15317\n",
      "[4474]\ttraining's binary_logloss: 0.153153\n",
      "[4475]\ttraining's binary_logloss: 0.153142\n",
      "[4476]\ttraining's binary_logloss: 0.153125\n",
      "[4477]\ttraining's binary_logloss: 0.153109\n",
      "[4478]\ttraining's binary_logloss: 0.153095\n",
      "[4479]\ttraining's binary_logloss: 0.15308\n",
      "[4480]\ttraining's binary_logloss: 0.153062\n",
      "[4481]\ttraining's binary_logloss: 0.153048\n",
      "[4482]\ttraining's binary_logloss: 0.153034\n",
      "[4483]\ttraining's binary_logloss: 0.15302\n",
      "[4484]\ttraining's binary_logloss: 0.153006\n",
      "[4485]\ttraining's binary_logloss: 0.152991\n",
      "[4486]\ttraining's binary_logloss: 0.152979\n",
      "[4487]\ttraining's binary_logloss: 0.152963\n",
      "[4488]\ttraining's binary_logloss: 0.152949\n",
      "[4489]\ttraining's binary_logloss: 0.15294\n",
      "[4490]\ttraining's binary_logloss: 0.152928\n",
      "[4491]\ttraining's binary_logloss: 0.152921\n",
      "[4492]\ttraining's binary_logloss: 0.152919\n",
      "[4493]\ttraining's binary_logloss: 0.152899\n",
      "[4494]\ttraining's binary_logloss: 0.152884\n",
      "[4495]\ttraining's binary_logloss: 0.152868\n",
      "[4496]\ttraining's binary_logloss: 0.152852\n",
      "[4497]\ttraining's binary_logloss: 0.152836\n",
      "[4498]\ttraining's binary_logloss: 0.152822\n",
      "[4499]\ttraining's binary_logloss: 0.152808\n",
      "[4500]\ttraining's binary_logloss: 0.152792\n",
      "[4501]\ttraining's binary_logloss: 0.152777\n",
      "[4502]\ttraining's binary_logloss: 0.152762\n",
      "[4503]\ttraining's binary_logloss: 0.152744\n",
      "[4504]\ttraining's binary_logloss: 0.152729\n",
      "[4505]\ttraining's binary_logloss: 0.152715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4506]\ttraining's binary_logloss: 0.152699\n",
      "[4507]\ttraining's binary_logloss: 0.152685\n",
      "[4508]\ttraining's binary_logloss: 0.152682\n",
      "[4509]\ttraining's binary_logloss: 0.152666\n",
      "[4510]\ttraining's binary_logloss: 0.15265\n",
      "[4511]\ttraining's binary_logloss: 0.152637\n",
      "[4512]\ttraining's binary_logloss: 0.152622\n",
      "[4513]\ttraining's binary_logloss: 0.152607\n",
      "[4514]\ttraining's binary_logloss: 0.152593\n",
      "[4515]\ttraining's binary_logloss: 0.152576\n",
      "[4516]\ttraining's binary_logloss: 0.152559\n",
      "[4517]\ttraining's binary_logloss: 0.152543\n",
      "[4518]\ttraining's binary_logloss: 0.152527\n",
      "[4519]\ttraining's binary_logloss: 0.152512\n",
      "[4520]\ttraining's binary_logloss: 0.152496\n",
      "[4521]\ttraining's binary_logloss: 0.152482\n",
      "[4522]\ttraining's binary_logloss: 0.152468\n",
      "[4523]\ttraining's binary_logloss: 0.15245\n",
      "[4524]\ttraining's binary_logloss: 0.152432\n",
      "[4525]\ttraining's binary_logloss: 0.152431\n",
      "[4526]\ttraining's binary_logloss: 0.152418\n",
      "[4527]\ttraining's binary_logloss: 0.152403\n",
      "[4528]\ttraining's binary_logloss: 0.15239\n",
      "[4529]\ttraining's binary_logloss: 0.152373\n",
      "[4530]\ttraining's binary_logloss: 0.152368\n",
      "[4531]\ttraining's binary_logloss: 0.152355\n",
      "[4532]\ttraining's binary_logloss: 0.152347\n",
      "[4533]\ttraining's binary_logloss: 0.152332\n",
      "[4534]\ttraining's binary_logloss: 0.152318\n",
      "[4535]\ttraining's binary_logloss: 0.152301\n",
      "[4536]\ttraining's binary_logloss: 0.152285\n",
      "[4537]\ttraining's binary_logloss: 0.152271\n",
      "[4538]\ttraining's binary_logloss: 0.152258\n",
      "[4539]\ttraining's binary_logloss: 0.152243\n",
      "[4540]\ttraining's binary_logloss: 0.152234\n",
      "[4541]\ttraining's binary_logloss: 0.152221\n",
      "[4542]\ttraining's binary_logloss: 0.152208\n",
      "[4543]\ttraining's binary_logloss: 0.152194\n",
      "[4544]\ttraining's binary_logloss: 0.152178\n",
      "[4545]\ttraining's binary_logloss: 0.152164\n",
      "[4546]\ttraining's binary_logloss: 0.152149\n",
      "[4547]\ttraining's binary_logloss: 0.152135\n",
      "[4548]\ttraining's binary_logloss: 0.152133\n",
      "[4549]\ttraining's binary_logloss: 0.152117\n",
      "[4550]\ttraining's binary_logloss: 0.152104\n",
      "[4551]\ttraining's binary_logloss: 0.152088\n",
      "[4552]\ttraining's binary_logloss: 0.152074\n",
      "[4553]\ttraining's binary_logloss: 0.152062\n",
      "[4554]\ttraining's binary_logloss: 0.152048\n",
      "[4555]\ttraining's binary_logloss: 0.152033\n",
      "[4556]\ttraining's binary_logloss: 0.152016\n",
      "[4557]\ttraining's binary_logloss: 0.152015\n",
      "[4558]\ttraining's binary_logloss: 0.152002\n",
      "[4559]\ttraining's binary_logloss: 0.151989\n",
      "[4560]\ttraining's binary_logloss: 0.151975\n",
      "[4561]\ttraining's binary_logloss: 0.151963\n",
      "[4562]\ttraining's binary_logloss: 0.151947\n",
      "[4563]\ttraining's binary_logloss: 0.151931\n",
      "[4564]\ttraining's binary_logloss: 0.151916\n",
      "[4565]\ttraining's binary_logloss: 0.151902\n",
      "[4566]\ttraining's binary_logloss: 0.151887\n",
      "[4567]\ttraining's binary_logloss: 0.15187\n",
      "[4568]\ttraining's binary_logloss: 0.151855\n",
      "[4569]\ttraining's binary_logloss: 0.15184\n",
      "[4570]\ttraining's binary_logloss: 0.151821\n",
      "[4571]\ttraining's binary_logloss: 0.151806\n",
      "[4572]\ttraining's binary_logloss: 0.15179\n",
      "[4573]\ttraining's binary_logloss: 0.151775\n",
      "[4574]\ttraining's binary_logloss: 0.151763\n",
      "[4575]\ttraining's binary_logloss: 0.151748\n",
      "[4576]\ttraining's binary_logloss: 0.15173\n",
      "[4577]\ttraining's binary_logloss: 0.151712\n",
      "[4578]\ttraining's binary_logloss: 0.151696\n",
      "[4579]\ttraining's binary_logloss: 0.151684\n",
      "[4580]\ttraining's binary_logloss: 0.151669\n",
      "[4581]\ttraining's binary_logloss: 0.151655\n",
      "[4582]\ttraining's binary_logloss: 0.15164\n",
      "[4583]\ttraining's binary_logloss: 0.15163\n",
      "[4584]\ttraining's binary_logloss: 0.151615\n",
      "[4585]\ttraining's binary_logloss: 0.151599\n",
      "[4586]\ttraining's binary_logloss: 0.151586\n",
      "[4587]\ttraining's binary_logloss: 0.151572\n",
      "[4588]\ttraining's binary_logloss: 0.151559\n",
      "[4589]\ttraining's binary_logloss: 0.151547\n",
      "[4590]\ttraining's binary_logloss: 0.151532\n",
      "[4591]\ttraining's binary_logloss: 0.151519\n",
      "[4592]\ttraining's binary_logloss: 0.151506\n",
      "[4593]\ttraining's binary_logloss: 0.151492\n",
      "[4594]\ttraining's binary_logloss: 0.151478\n",
      "[4595]\ttraining's binary_logloss: 0.151464\n",
      "[4596]\ttraining's binary_logloss: 0.151449\n",
      "[4597]\ttraining's binary_logloss: 0.151434\n",
      "[4598]\ttraining's binary_logloss: 0.15142\n",
      "[4599]\ttraining's binary_logloss: 0.151419\n",
      "[4600]\ttraining's binary_logloss: 0.151403\n",
      "[4601]\ttraining's binary_logloss: 0.151389\n",
      "[4602]\ttraining's binary_logloss: 0.151382\n",
      "[4603]\ttraining's binary_logloss: 0.151369\n",
      "[4604]\ttraining's binary_logloss: 0.151355\n",
      "[4605]\ttraining's binary_logloss: 0.151338\n",
      "[4606]\ttraining's binary_logloss: 0.151324\n",
      "[4607]\ttraining's binary_logloss: 0.151315\n",
      "[4608]\ttraining's binary_logloss: 0.151305\n",
      "[4609]\ttraining's binary_logloss: 0.151291\n",
      "[4610]\ttraining's binary_logloss: 0.151274\n",
      "[4611]\ttraining's binary_logloss: 0.151267\n",
      "[4612]\ttraining's binary_logloss: 0.151255\n",
      "[4613]\ttraining's binary_logloss: 0.151247\n",
      "[4614]\ttraining's binary_logloss: 0.151238\n",
      "[4615]\ttraining's binary_logloss: 0.151224\n",
      "[4616]\ttraining's binary_logloss: 0.151208\n",
      "[4617]\ttraining's binary_logloss: 0.151194\n",
      "[4618]\ttraining's binary_logloss: 0.151179\n",
      "[4619]\ttraining's binary_logloss: 0.151164\n",
      "[4620]\ttraining's binary_logloss: 0.151148\n",
      "[4621]\ttraining's binary_logloss: 0.151137\n",
      "[4622]\ttraining's binary_logloss: 0.151128\n",
      "[4623]\ttraining's binary_logloss: 0.151123\n",
      "[4624]\ttraining's binary_logloss: 0.15111\n",
      "[4625]\ttraining's binary_logloss: 0.151098\n",
      "[4626]\ttraining's binary_logloss: 0.151084\n",
      "[4627]\ttraining's binary_logloss: 0.15107\n",
      "[4628]\ttraining's binary_logloss: 0.151056\n",
      "[4629]\ttraining's binary_logloss: 0.151043\n",
      "[4630]\ttraining's binary_logloss: 0.151024\n",
      "[4631]\ttraining's binary_logloss: 0.151008\n",
      "[4632]\ttraining's binary_logloss: 0.150994\n",
      "[4633]\ttraining's binary_logloss: 0.150981\n",
      "[4634]\ttraining's binary_logloss: 0.150967\n",
      "[4635]\ttraining's binary_logloss: 0.150953\n",
      "[4636]\ttraining's binary_logloss: 0.150951\n",
      "[4637]\ttraining's binary_logloss: 0.150936\n",
      "[4638]\ttraining's binary_logloss: 0.150931\n",
      "[4639]\ttraining's binary_logloss: 0.150915\n",
      "[4640]\ttraining's binary_logloss: 0.150897\n",
      "[4641]\ttraining's binary_logloss: 0.150883\n",
      "[4642]\ttraining's binary_logloss: 0.150867\n",
      "[4643]\ttraining's binary_logloss: 0.150852\n",
      "[4644]\ttraining's binary_logloss: 0.150838\n",
      "[4645]\ttraining's binary_logloss: 0.150826\n",
      "[4646]\ttraining's binary_logloss: 0.150812\n",
      "[4647]\ttraining's binary_logloss: 0.150796\n",
      "[4648]\ttraining's binary_logloss: 0.150783\n",
      "[4649]\ttraining's binary_logloss: 0.150769\n",
      "[4650]\ttraining's binary_logloss: 0.150753\n",
      "[4651]\ttraining's binary_logloss: 0.15074\n",
      "[4652]\ttraining's binary_logloss: 0.150726\n",
      "[4653]\ttraining's binary_logloss: 0.150724\n",
      "[4654]\ttraining's binary_logloss: 0.150716\n",
      "[4655]\ttraining's binary_logloss: 0.150705\n",
      "[4656]\ttraining's binary_logloss: 0.150692\n",
      "[4657]\ttraining's binary_logloss: 0.150677\n",
      "[4658]\ttraining's binary_logloss: 0.150664\n",
      "[4659]\ttraining's binary_logloss: 0.15065\n",
      "[4660]\ttraining's binary_logloss: 0.150634\n",
      "[4661]\ttraining's binary_logloss: 0.150618\n",
      "[4662]\ttraining's binary_logloss: 0.150603\n",
      "[4663]\ttraining's binary_logloss: 0.150589\n",
      "[4664]\ttraining's binary_logloss: 0.150574\n",
      "[4665]\ttraining's binary_logloss: 0.150561\n",
      "[4666]\ttraining's binary_logloss: 0.150548\n",
      "[4667]\ttraining's binary_logloss: 0.150535\n",
      "[4668]\ttraining's binary_logloss: 0.15052\n",
      "[4669]\ttraining's binary_logloss: 0.150514\n",
      "[4670]\ttraining's binary_logloss: 0.150498\n",
      "[4671]\ttraining's binary_logloss: 0.150482\n",
      "[4672]\ttraining's binary_logloss: 0.150466\n",
      "[4673]\ttraining's binary_logloss: 0.150462\n",
      "[4674]\ttraining's binary_logloss: 0.150444\n",
      "[4675]\ttraining's binary_logloss: 0.150428\n",
      "[4676]\ttraining's binary_logloss: 0.150416\n",
      "[4677]\ttraining's binary_logloss: 0.150411\n",
      "[4678]\ttraining's binary_logloss: 0.150397\n",
      "[4679]\ttraining's binary_logloss: 0.150383\n",
      "[4680]\ttraining's binary_logloss: 0.150366\n",
      "[4681]\ttraining's binary_logloss: 0.150359\n",
      "[4682]\ttraining's binary_logloss: 0.150347\n",
      "[4683]\ttraining's binary_logloss: 0.150329\n",
      "[4684]\ttraining's binary_logloss: 0.150315\n",
      "[4685]\ttraining's binary_logloss: 0.150299\n",
      "[4686]\ttraining's binary_logloss: 0.150285\n",
      "[4687]\ttraining's binary_logloss: 0.150269\n",
      "[4688]\ttraining's binary_logloss: 0.150255\n",
      "[4689]\ttraining's binary_logloss: 0.150239\n",
      "[4690]\ttraining's binary_logloss: 0.150225\n",
      "[4691]\ttraining's binary_logloss: 0.150209\n",
      "[4692]\ttraining's binary_logloss: 0.150196\n",
      "[4693]\ttraining's binary_logloss: 0.150185\n",
      "[4694]\ttraining's binary_logloss: 0.150173\n",
      "[4695]\ttraining's binary_logloss: 0.150156\n",
      "[4696]\ttraining's binary_logloss: 0.150142\n",
      "[4697]\ttraining's binary_logloss: 0.150128\n",
      "[4698]\ttraining's binary_logloss: 0.150113\n",
      "[4699]\ttraining's binary_logloss: 0.150101\n",
      "[4700]\ttraining's binary_logloss: 0.150087\n",
      "[4701]\ttraining's binary_logloss: 0.150072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4702]\ttraining's binary_logloss: 0.150056\n",
      "[4703]\ttraining's binary_logloss: 0.150041\n",
      "[4704]\ttraining's binary_logloss: 0.150027\n",
      "[4705]\ttraining's binary_logloss: 0.15001\n",
      "[4706]\ttraining's binary_logloss: 0.150005\n",
      "[4707]\ttraining's binary_logloss: 0.149987\n",
      "[4708]\ttraining's binary_logloss: 0.149971\n",
      "[4709]\ttraining's binary_logloss: 0.149963\n",
      "[4710]\ttraining's binary_logloss: 0.149948\n",
      "[4711]\ttraining's binary_logloss: 0.149928\n",
      "[4712]\ttraining's binary_logloss: 0.149912\n",
      "[4713]\ttraining's binary_logloss: 0.149908\n",
      "[4714]\ttraining's binary_logloss: 0.149895\n",
      "[4715]\ttraining's binary_logloss: 0.149877\n",
      "[4716]\ttraining's binary_logloss: 0.149863\n",
      "[4717]\ttraining's binary_logloss: 0.149847\n",
      "[4718]\ttraining's binary_logloss: 0.149837\n",
      "[4719]\ttraining's binary_logloss: 0.149833\n",
      "[4720]\ttraining's binary_logloss: 0.149814\n",
      "[4721]\ttraining's binary_logloss: 0.149797\n",
      "[4722]\ttraining's binary_logloss: 0.149782\n",
      "[4723]\ttraining's binary_logloss: 0.149767\n",
      "[4724]\ttraining's binary_logloss: 0.149752\n",
      "[4725]\ttraining's binary_logloss: 0.149741\n",
      "[4726]\ttraining's binary_logloss: 0.149731\n",
      "[4727]\ttraining's binary_logloss: 0.149717\n",
      "[4728]\ttraining's binary_logloss: 0.149704\n",
      "[4729]\ttraining's binary_logloss: 0.149687\n",
      "[4730]\ttraining's binary_logloss: 0.149673\n",
      "[4731]\ttraining's binary_logloss: 0.14966\n",
      "[4732]\ttraining's binary_logloss: 0.149646\n",
      "[4733]\ttraining's binary_logloss: 0.149632\n",
      "[4734]\ttraining's binary_logloss: 0.149616\n",
      "[4735]\ttraining's binary_logloss: 0.149603\n",
      "[4736]\ttraining's binary_logloss: 0.149588\n",
      "[4737]\ttraining's binary_logloss: 0.149585\n",
      "[4738]\ttraining's binary_logloss: 0.149571\n",
      "[4739]\ttraining's binary_logloss: 0.149553\n",
      "[4740]\ttraining's binary_logloss: 0.149545\n",
      "[4741]\ttraining's binary_logloss: 0.149534\n",
      "[4742]\ttraining's binary_logloss: 0.14952\n",
      "[4743]\ttraining's binary_logloss: 0.149506\n",
      "[4744]\ttraining's binary_logloss: 0.149489\n",
      "[4745]\ttraining's binary_logloss: 0.149471\n",
      "[4746]\ttraining's binary_logloss: 0.149457\n",
      "[4747]\ttraining's binary_logloss: 0.149442\n",
      "[4748]\ttraining's binary_logloss: 0.149429\n",
      "[4749]\ttraining's binary_logloss: 0.149417\n",
      "[4750]\ttraining's binary_logloss: 0.149399\n",
      "[4751]\ttraining's binary_logloss: 0.149389\n",
      "[4752]\ttraining's binary_logloss: 0.149379\n",
      "[4753]\ttraining's binary_logloss: 0.149362\n",
      "[4754]\ttraining's binary_logloss: 0.149353\n",
      "[4755]\ttraining's binary_logloss: 0.149339\n",
      "[4756]\ttraining's binary_logloss: 0.149324\n",
      "[4757]\ttraining's binary_logloss: 0.149309\n",
      "[4758]\ttraining's binary_logloss: 0.149293\n",
      "[4759]\ttraining's binary_logloss: 0.149282\n",
      "[4760]\ttraining's binary_logloss: 0.149269\n",
      "[4761]\ttraining's binary_logloss: 0.149254\n",
      "[4762]\ttraining's binary_logloss: 0.149239\n",
      "[4763]\ttraining's binary_logloss: 0.149223\n",
      "[4764]\ttraining's binary_logloss: 0.149209\n",
      "[4765]\ttraining's binary_logloss: 0.149193\n",
      "[4766]\ttraining's binary_logloss: 0.149187\n",
      "[4767]\ttraining's binary_logloss: 0.149172\n",
      "[4768]\ttraining's binary_logloss: 0.14917\n",
      "[4769]\ttraining's binary_logloss: 0.149156\n",
      "[4770]\ttraining's binary_logloss: 0.149141\n",
      "[4771]\ttraining's binary_logloss: 0.149127\n",
      "[4772]\ttraining's binary_logloss: 0.149113\n",
      "[4773]\ttraining's binary_logloss: 0.149101\n",
      "[4774]\ttraining's binary_logloss: 0.149085\n",
      "[4775]\ttraining's binary_logloss: 0.149073\n",
      "[4776]\ttraining's binary_logloss: 0.149057\n",
      "[4777]\ttraining's binary_logloss: 0.149044\n",
      "[4778]\ttraining's binary_logloss: 0.149041\n",
      "[4779]\ttraining's binary_logloss: 0.149026\n",
      "[4780]\ttraining's binary_logloss: 0.149013\n",
      "[4781]\ttraining's binary_logloss: 0.148998\n",
      "[4782]\ttraining's binary_logloss: 0.148987\n",
      "[4783]\ttraining's binary_logloss: 0.14897\n",
      "[4784]\ttraining's binary_logloss: 0.148958\n",
      "[4785]\ttraining's binary_logloss: 0.148951\n",
      "[4786]\ttraining's binary_logloss: 0.148933\n",
      "[4787]\ttraining's binary_logloss: 0.14892\n",
      "[4788]\ttraining's binary_logloss: 0.148907\n",
      "[4789]\ttraining's binary_logloss: 0.148891\n",
      "[4790]\ttraining's binary_logloss: 0.14888\n",
      "[4791]\ttraining's binary_logloss: 0.148862\n",
      "[4792]\ttraining's binary_logloss: 0.148846\n",
      "[4793]\ttraining's binary_logloss: 0.148831\n",
      "[4794]\ttraining's binary_logloss: 0.148819\n",
      "[4795]\ttraining's binary_logloss: 0.148807\n",
      "[4796]\ttraining's binary_logloss: 0.148799\n",
      "[4797]\ttraining's binary_logloss: 0.148796\n",
      "[4798]\ttraining's binary_logloss: 0.148783\n",
      "[4799]\ttraining's binary_logloss: 0.148771\n",
      "[4800]\ttraining's binary_logloss: 0.148766\n",
      "[4801]\ttraining's binary_logloss: 0.148755\n",
      "[4802]\ttraining's binary_logloss: 0.148738\n",
      "[4803]\ttraining's binary_logloss: 0.148729\n",
      "[4804]\ttraining's binary_logloss: 0.148715\n",
      "[4805]\ttraining's binary_logloss: 0.148699\n",
      "[4806]\ttraining's binary_logloss: 0.148683\n",
      "[4807]\ttraining's binary_logloss: 0.148672\n",
      "[4808]\ttraining's binary_logloss: 0.148657\n",
      "[4809]\ttraining's binary_logloss: 0.148643\n",
      "[4810]\ttraining's binary_logloss: 0.14863\n",
      "[4811]\ttraining's binary_logloss: 0.148625\n",
      "[4812]\ttraining's binary_logloss: 0.148614\n",
      "[4813]\ttraining's binary_logloss: 0.1486\n",
      "[4814]\ttraining's binary_logloss: 0.148585\n",
      "[4815]\ttraining's binary_logloss: 0.148571\n",
      "[4816]\ttraining's binary_logloss: 0.148558\n",
      "[4817]\ttraining's binary_logloss: 0.148549\n",
      "[4818]\ttraining's binary_logloss: 0.148534\n",
      "[4819]\ttraining's binary_logloss: 0.148522\n",
      "[4820]\ttraining's binary_logloss: 0.148507\n",
      "[4821]\ttraining's binary_logloss: 0.148494\n",
      "[4822]\ttraining's binary_logloss: 0.148479\n",
      "[4823]\ttraining's binary_logloss: 0.148462\n",
      "[4824]\ttraining's binary_logloss: 0.148452\n",
      "[4825]\ttraining's binary_logloss: 0.148436\n",
      "[4826]\ttraining's binary_logloss: 0.148421\n",
      "[4827]\ttraining's binary_logloss: 0.148406\n",
      "[4828]\ttraining's binary_logloss: 0.148392\n",
      "[4829]\ttraining's binary_logloss: 0.148379\n",
      "[4830]\ttraining's binary_logloss: 0.148373\n",
      "[4831]\ttraining's binary_logloss: 0.148356\n",
      "[4832]\ttraining's binary_logloss: 0.148352\n",
      "[4833]\ttraining's binary_logloss: 0.148343\n",
      "[4834]\ttraining's binary_logloss: 0.148328\n",
      "[4835]\ttraining's binary_logloss: 0.148313\n",
      "[4836]\ttraining's binary_logloss: 0.148308\n",
      "[4837]\ttraining's binary_logloss: 0.148304\n",
      "[4838]\ttraining's binary_logloss: 0.14829\n",
      "[4839]\ttraining's binary_logloss: 0.148272\n",
      "[4840]\ttraining's binary_logloss: 0.148255\n",
      "[4841]\ttraining's binary_logloss: 0.148243\n",
      "[4842]\ttraining's binary_logloss: 0.148227\n",
      "[4843]\ttraining's binary_logloss: 0.14822\n",
      "[4844]\ttraining's binary_logloss: 0.148204\n",
      "[4845]\ttraining's binary_logloss: 0.148191\n",
      "[4846]\ttraining's binary_logloss: 0.148175\n",
      "[4847]\ttraining's binary_logloss: 0.148159\n",
      "[4848]\ttraining's binary_logloss: 0.148144\n",
      "[4849]\ttraining's binary_logloss: 0.148137\n",
      "[4850]\ttraining's binary_logloss: 0.148122\n",
      "[4851]\ttraining's binary_logloss: 0.148119\n",
      "[4852]\ttraining's binary_logloss: 0.148116\n",
      "[4853]\ttraining's binary_logloss: 0.148102\n",
      "[4854]\ttraining's binary_logloss: 0.148097\n",
      "[4855]\ttraining's binary_logloss: 0.148086\n",
      "[4856]\ttraining's binary_logloss: 0.14807\n",
      "[4857]\ttraining's binary_logloss: 0.148056\n",
      "[4858]\ttraining's binary_logloss: 0.148043\n",
      "[4859]\ttraining's binary_logloss: 0.148038\n",
      "[4860]\ttraining's binary_logloss: 0.148025\n",
      "[4861]\ttraining's binary_logloss: 0.14801\n",
      "[4862]\ttraining's binary_logloss: 0.148008\n",
      "[4863]\ttraining's binary_logloss: 0.148006\n",
      "[4864]\ttraining's binary_logloss: 0.148001\n",
      "[4865]\ttraining's binary_logloss: 0.147988\n",
      "[4866]\ttraining's binary_logloss: 0.147974\n",
      "[4867]\ttraining's binary_logloss: 0.14796\n",
      "[4868]\ttraining's binary_logloss: 0.147952\n",
      "[4869]\ttraining's binary_logloss: 0.147945\n",
      "[4870]\ttraining's binary_logloss: 0.147931\n",
      "[4871]\ttraining's binary_logloss: 0.147913\n",
      "[4872]\ttraining's binary_logloss: 0.147908\n",
      "[4873]\ttraining's binary_logloss: 0.147892\n",
      "[4874]\ttraining's binary_logloss: 0.147878\n",
      "[4875]\ttraining's binary_logloss: 0.147864\n",
      "[4876]\ttraining's binary_logloss: 0.147854\n",
      "[4877]\ttraining's binary_logloss: 0.147843\n",
      "[4878]\ttraining's binary_logloss: 0.147829\n",
      "[4879]\ttraining's binary_logloss: 0.147815\n",
      "[4880]\ttraining's binary_logloss: 0.1478\n",
      "[4881]\ttraining's binary_logloss: 0.147784\n",
      "[4882]\ttraining's binary_logloss: 0.14777\n",
      "[4883]\ttraining's binary_logloss: 0.147756\n",
      "[4884]\ttraining's binary_logloss: 0.147741\n",
      "[4885]\ttraining's binary_logloss: 0.147726\n",
      "[4886]\ttraining's binary_logloss: 0.147721\n",
      "[4887]\ttraining's binary_logloss: 0.147712\n",
      "[4888]\ttraining's binary_logloss: 0.147698\n",
      "[4889]\ttraining's binary_logloss: 0.147684\n",
      "[4890]\ttraining's binary_logloss: 0.147682\n",
      "[4891]\ttraining's binary_logloss: 0.147678\n",
      "[4892]\ttraining's binary_logloss: 0.147668\n",
      "[4893]\ttraining's binary_logloss: 0.147665\n",
      "[4894]\ttraining's binary_logloss: 0.147661\n",
      "[4895]\ttraining's binary_logloss: 0.147645\n",
      "[4896]\ttraining's binary_logloss: 0.147629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4897]\ttraining's binary_logloss: 0.147616\n",
      "[4898]\ttraining's binary_logloss: 0.147601\n",
      "[4899]\ttraining's binary_logloss: 0.147597\n",
      "[4900]\ttraining's binary_logloss: 0.147593\n",
      "[4901]\ttraining's binary_logloss: 0.147576\n",
      "[4902]\ttraining's binary_logloss: 0.147562\n",
      "[4903]\ttraining's binary_logloss: 0.147559\n",
      "[4904]\ttraining's binary_logloss: 0.14755\n",
      "[4905]\ttraining's binary_logloss: 0.147533\n",
      "[4906]\ttraining's binary_logloss: 0.147524\n",
      "[4907]\ttraining's binary_logloss: 0.14751\n",
      "[4908]\ttraining's binary_logloss: 0.147497\n",
      "[4909]\ttraining's binary_logloss: 0.147483\n",
      "[4910]\ttraining's binary_logloss: 0.147468\n",
      "[4911]\ttraining's binary_logloss: 0.147454\n",
      "[4912]\ttraining's binary_logloss: 0.147438\n",
      "[4913]\ttraining's binary_logloss: 0.147424\n",
      "[4914]\ttraining's binary_logloss: 0.147413\n",
      "[4915]\ttraining's binary_logloss: 0.147403\n",
      "[4916]\ttraining's binary_logloss: 0.147389\n",
      "[4917]\ttraining's binary_logloss: 0.147375\n",
      "[4918]\ttraining's binary_logloss: 0.147362\n",
      "[4919]\ttraining's binary_logloss: 0.147354\n",
      "[4920]\ttraining's binary_logloss: 0.14735\n",
      "[4921]\ttraining's binary_logloss: 0.147334\n",
      "[4922]\ttraining's binary_logloss: 0.147325\n",
      "[4923]\ttraining's binary_logloss: 0.147311\n",
      "[4924]\ttraining's binary_logloss: 0.147297\n",
      "[4925]\ttraining's binary_logloss: 0.147284\n",
      "[4926]\ttraining's binary_logloss: 0.147267\n",
      "[4927]\ttraining's binary_logloss: 0.147252\n",
      "[4928]\ttraining's binary_logloss: 0.147238\n",
      "[4929]\ttraining's binary_logloss: 0.147232\n",
      "[4930]\ttraining's binary_logloss: 0.147219\n",
      "[4931]\ttraining's binary_logloss: 0.147204\n",
      "[4932]\ttraining's binary_logloss: 0.147189\n",
      "[4933]\ttraining's binary_logloss: 0.147187\n",
      "[4934]\ttraining's binary_logloss: 0.147181\n",
      "[4935]\ttraining's binary_logloss: 0.147178\n",
      "[4936]\ttraining's binary_logloss: 0.147174\n",
      "[4937]\ttraining's binary_logloss: 0.147168\n",
      "[4938]\ttraining's binary_logloss: 0.147152\n",
      "[4939]\ttraining's binary_logloss: 0.147136\n",
      "[4940]\ttraining's binary_logloss: 0.147124\n",
      "[4941]\ttraining's binary_logloss: 0.147109\n",
      "[4942]\ttraining's binary_logloss: 0.147093\n",
      "[4943]\ttraining's binary_logloss: 0.147091\n",
      "[4944]\ttraining's binary_logloss: 0.147077\n",
      "[4945]\ttraining's binary_logloss: 0.147064\n",
      "[4946]\ttraining's binary_logloss: 0.147051\n",
      "[4947]\ttraining's binary_logloss: 0.147047\n",
      "[4948]\ttraining's binary_logloss: 0.147041\n",
      "[4949]\ttraining's binary_logloss: 0.147028\n",
      "[4950]\ttraining's binary_logloss: 0.147012\n",
      "[4951]\ttraining's binary_logloss: 0.146998\n",
      "[4952]\ttraining's binary_logloss: 0.146985\n",
      "[4953]\ttraining's binary_logloss: 0.146982\n",
      "[4954]\ttraining's binary_logloss: 0.146977\n",
      "[4955]\ttraining's binary_logloss: 0.146964\n",
      "[4956]\ttraining's binary_logloss: 0.146951\n",
      "[4957]\ttraining's binary_logloss: 0.146938\n",
      "[4958]\ttraining's binary_logloss: 0.146923\n",
      "[4959]\ttraining's binary_logloss: 0.146908\n",
      "[4960]\ttraining's binary_logloss: 0.146897\n",
      "[4961]\ttraining's binary_logloss: 0.14688\n",
      "[4962]\ttraining's binary_logloss: 0.146865\n",
      "[4963]\ttraining's binary_logloss: 0.146851\n",
      "[4964]\ttraining's binary_logloss: 0.146834\n",
      "[4965]\ttraining's binary_logloss: 0.146817\n",
      "[4966]\ttraining's binary_logloss: 0.146806\n",
      "[4967]\ttraining's binary_logloss: 0.146789\n",
      "[4968]\ttraining's binary_logloss: 0.146773\n",
      "[4969]\ttraining's binary_logloss: 0.146763\n",
      "[4970]\ttraining's binary_logloss: 0.146749\n",
      "[4971]\ttraining's binary_logloss: 0.146736\n",
      "[4972]\ttraining's binary_logloss: 0.146723\n",
      "[4973]\ttraining's binary_logloss: 0.14671\n",
      "[4974]\ttraining's binary_logloss: 0.146695\n",
      "[4975]\ttraining's binary_logloss: 0.146682\n",
      "[4976]\ttraining's binary_logloss: 0.146666\n",
      "[4977]\ttraining's binary_logloss: 0.146651\n",
      "[4978]\ttraining's binary_logloss: 0.146636\n",
      "[4979]\ttraining's binary_logloss: 0.14662\n",
      "[4980]\ttraining's binary_logloss: 0.146606\n",
      "[4981]\ttraining's binary_logloss: 0.146593\n",
      "[4982]\ttraining's binary_logloss: 0.146578\n",
      "[4983]\ttraining's binary_logloss: 0.146565\n",
      "[4984]\ttraining's binary_logloss: 0.146549\n",
      "[4985]\ttraining's binary_logloss: 0.146534\n",
      "[4986]\ttraining's binary_logloss: 0.14652\n",
      "[4987]\ttraining's binary_logloss: 0.146509\n",
      "[4988]\ttraining's binary_logloss: 0.146501\n",
      "[4989]\ttraining's binary_logloss: 0.146494\n",
      "[4990]\ttraining's binary_logloss: 0.146475\n",
      "[4991]\ttraining's binary_logloss: 0.146463\n",
      "[4992]\ttraining's binary_logloss: 0.14645\n",
      "[4993]\ttraining's binary_logloss: 0.146448\n",
      "[4994]\ttraining's binary_logloss: 0.146436\n",
      "[4995]\ttraining's binary_logloss: 0.146433\n",
      "[4996]\ttraining's binary_logloss: 0.146431\n",
      "[4997]\ttraining's binary_logloss: 0.146416\n",
      "[4998]\ttraining's binary_logloss: 0.146401\n",
      "[4999]\ttraining's binary_logloss: 0.146387\n",
      "[5000]\ttraining's binary_logloss: 0.146372\n",
      "[5001]\ttraining's binary_logloss: 0.146358\n",
      "[5002]\ttraining's binary_logloss: 0.146351\n",
      "[5003]\ttraining's binary_logloss: 0.146336\n",
      "[5004]\ttraining's binary_logloss: 0.146323\n",
      "[5005]\ttraining's binary_logloss: 0.14631\n",
      "[5006]\ttraining's binary_logloss: 0.146299\n",
      "[5007]\ttraining's binary_logloss: 0.146285\n",
      "[5008]\ttraining's binary_logloss: 0.146271\n",
      "[5009]\ttraining's binary_logloss: 0.146256\n",
      "[5010]\ttraining's binary_logloss: 0.146244\n",
      "[5011]\ttraining's binary_logloss: 0.146228\n",
      "[5012]\ttraining's binary_logloss: 0.146213\n",
      "[5013]\ttraining's binary_logloss: 0.14621\n",
      "[5014]\ttraining's binary_logloss: 0.1462\n",
      "[5015]\ttraining's binary_logloss: 0.146197\n",
      "[5016]\ttraining's binary_logloss: 0.146183\n",
      "[5017]\ttraining's binary_logloss: 0.146169\n",
      "[5018]\ttraining's binary_logloss: 0.146159\n",
      "[5019]\ttraining's binary_logloss: 0.146144\n",
      "[5020]\ttraining's binary_logloss: 0.146128\n",
      "[5021]\ttraining's binary_logloss: 0.146116\n",
      "[5022]\ttraining's binary_logloss: 0.146101\n",
      "[5023]\ttraining's binary_logloss: 0.146088\n",
      "[5024]\ttraining's binary_logloss: 0.146085\n",
      "[5025]\ttraining's binary_logloss: 0.146073\n",
      "[5026]\ttraining's binary_logloss: 0.146061\n",
      "[5027]\ttraining's binary_logloss: 0.146049\n",
      "[5028]\ttraining's binary_logloss: 0.146041\n",
      "[5029]\ttraining's binary_logloss: 0.146026\n",
      "[5030]\ttraining's binary_logloss: 0.146015\n",
      "[5031]\ttraining's binary_logloss: 0.146002\n",
      "[5032]\ttraining's binary_logloss: 0.145991\n",
      "[5033]\ttraining's binary_logloss: 0.145975\n",
      "[5034]\ttraining's binary_logloss: 0.145965\n",
      "[5035]\ttraining's binary_logloss: 0.145954\n",
      "[5036]\ttraining's binary_logloss: 0.145939\n",
      "[5037]\ttraining's binary_logloss: 0.145925\n",
      "[5038]\ttraining's binary_logloss: 0.145911\n",
      "[5039]\ttraining's binary_logloss: 0.145897\n",
      "[5040]\ttraining's binary_logloss: 0.145883\n",
      "[5041]\ttraining's binary_logloss: 0.145868\n",
      "[5042]\ttraining's binary_logloss: 0.145853\n",
      "[5043]\ttraining's binary_logloss: 0.145838\n",
      "[5044]\ttraining's binary_logloss: 0.145829\n",
      "[5045]\ttraining's binary_logloss: 0.145826\n",
      "[5046]\ttraining's binary_logloss: 0.14582\n",
      "[5047]\ttraining's binary_logloss: 0.145808\n",
      "[5048]\ttraining's binary_logloss: 0.145795\n",
      "[5049]\ttraining's binary_logloss: 0.145781\n",
      "[5050]\ttraining's binary_logloss: 0.145768\n",
      "[5051]\ttraining's binary_logloss: 0.145753\n",
      "[5052]\ttraining's binary_logloss: 0.145737\n",
      "[5053]\ttraining's binary_logloss: 0.145722\n",
      "[5054]\ttraining's binary_logloss: 0.145714\n",
      "[5055]\ttraining's binary_logloss: 0.14571\n",
      "[5056]\ttraining's binary_logloss: 0.145697\n",
      "[5057]\ttraining's binary_logloss: 0.145683\n",
      "[5058]\ttraining's binary_logloss: 0.145668\n",
      "[5059]\ttraining's binary_logloss: 0.145655\n",
      "[5060]\ttraining's binary_logloss: 0.145642\n",
      "[5061]\ttraining's binary_logloss: 0.14563\n",
      "[5062]\ttraining's binary_logloss: 0.145622\n",
      "[5063]\ttraining's binary_logloss: 0.145617\n",
      "[5064]\ttraining's binary_logloss: 0.145602\n",
      "[5065]\ttraining's binary_logloss: 0.145589\n",
      "[5066]\ttraining's binary_logloss: 0.145581\n",
      "[5067]\ttraining's binary_logloss: 0.145565\n",
      "[5068]\ttraining's binary_logloss: 0.145551\n",
      "[5069]\ttraining's binary_logloss: 0.145539\n",
      "[5070]\ttraining's binary_logloss: 0.145523\n",
      "[5071]\ttraining's binary_logloss: 0.145508\n",
      "[5072]\ttraining's binary_logloss: 0.145493\n",
      "[5073]\ttraining's binary_logloss: 0.14548\n",
      "[5074]\ttraining's binary_logloss: 0.145466\n",
      "[5075]\ttraining's binary_logloss: 0.145452\n",
      "[5076]\ttraining's binary_logloss: 0.145438\n",
      "[5077]\ttraining's binary_logloss: 0.145426\n",
      "[5078]\ttraining's binary_logloss: 0.145412\n",
      "[5079]\ttraining's binary_logloss: 0.145397\n",
      "[5080]\ttraining's binary_logloss: 0.145382\n",
      "[5081]\ttraining's binary_logloss: 0.145379\n",
      "[5082]\ttraining's binary_logloss: 0.145366\n",
      "[5083]\ttraining's binary_logloss: 0.145353\n",
      "[5084]\ttraining's binary_logloss: 0.145338\n",
      "[5085]\ttraining's binary_logloss: 0.145326\n",
      "[5086]\ttraining's binary_logloss: 0.145315\n",
      "[5087]\ttraining's binary_logloss: 0.1453\n",
      "[5088]\ttraining's binary_logloss: 0.145295\n",
      "[5089]\ttraining's binary_logloss: 0.145279\n",
      "[5090]\ttraining's binary_logloss: 0.145271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5091]\ttraining's binary_logloss: 0.145258\n",
      "[5092]\ttraining's binary_logloss: 0.145247\n",
      "[5093]\ttraining's binary_logloss: 0.145239\n",
      "[5094]\ttraining's binary_logloss: 0.145226\n",
      "[5095]\ttraining's binary_logloss: 0.145215\n",
      "[5096]\ttraining's binary_logloss: 0.145201\n",
      "[5097]\ttraining's binary_logloss: 0.145187\n",
      "[5098]\ttraining's binary_logloss: 0.145172\n",
      "[5099]\ttraining's binary_logloss: 0.145158\n",
      "[5100]\ttraining's binary_logloss: 0.145145\n",
      "[5101]\ttraining's binary_logloss: 0.14514\n",
      "[5102]\ttraining's binary_logloss: 0.145122\n",
      "[5103]\ttraining's binary_logloss: 0.14511\n",
      "[5104]\ttraining's binary_logloss: 0.145096\n",
      "[5105]\ttraining's binary_logloss: 0.145081\n",
      "[5106]\ttraining's binary_logloss: 0.145067\n",
      "[5107]\ttraining's binary_logloss: 0.145053\n",
      "[5108]\ttraining's binary_logloss: 0.145039\n",
      "[5109]\ttraining's binary_logloss: 0.145026\n",
      "[5110]\ttraining's binary_logloss: 0.145013\n",
      "[5111]\ttraining's binary_logloss: 0.144997\n",
      "[5112]\ttraining's binary_logloss: 0.144988\n",
      "[5113]\ttraining's binary_logloss: 0.144973\n",
      "[5114]\ttraining's binary_logloss: 0.144967\n",
      "[5115]\ttraining's binary_logloss: 0.144956\n",
      "[5116]\ttraining's binary_logloss: 0.144947\n",
      "[5117]\ttraining's binary_logloss: 0.144935\n",
      "[5118]\ttraining's binary_logloss: 0.144929\n",
      "[5119]\ttraining's binary_logloss: 0.144925\n",
      "[5120]\ttraining's binary_logloss: 0.144911\n",
      "[5121]\ttraining's binary_logloss: 0.144898\n",
      "[5122]\ttraining's binary_logloss: 0.144883\n",
      "[5123]\ttraining's binary_logloss: 0.144868\n",
      "[5124]\ttraining's binary_logloss: 0.144855\n",
      "[5125]\ttraining's binary_logloss: 0.144842\n",
      "[5126]\ttraining's binary_logloss: 0.144827\n",
      "[5127]\ttraining's binary_logloss: 0.144818\n",
      "[5128]\ttraining's binary_logloss: 0.144807\n",
      "[5129]\ttraining's binary_logloss: 0.144792\n",
      "[5130]\ttraining's binary_logloss: 0.144779\n",
      "[5131]\ttraining's binary_logloss: 0.144765\n",
      "[5132]\ttraining's binary_logloss: 0.14475\n",
      "[5133]\ttraining's binary_logloss: 0.144734\n",
      "[5134]\ttraining's binary_logloss: 0.144724\n",
      "[5135]\ttraining's binary_logloss: 0.144714\n",
      "[5136]\ttraining's binary_logloss: 0.144703\n",
      "[5137]\ttraining's binary_logloss: 0.144689\n",
      "[5138]\ttraining's binary_logloss: 0.144673\n",
      "[5139]\ttraining's binary_logloss: 0.144659\n",
      "[5140]\ttraining's binary_logloss: 0.144644\n",
      "[5141]\ttraining's binary_logloss: 0.144632\n",
      "[5142]\ttraining's binary_logloss: 0.144618\n",
      "[5143]\ttraining's binary_logloss: 0.144604\n",
      "[5144]\ttraining's binary_logloss: 0.14459\n",
      "[5145]\ttraining's binary_logloss: 0.144576\n",
      "[5146]\ttraining's binary_logloss: 0.144562\n",
      "[5147]\ttraining's binary_logloss: 0.144549\n",
      "[5148]\ttraining's binary_logloss: 0.144535\n",
      "[5149]\ttraining's binary_logloss: 0.144522\n",
      "[5150]\ttraining's binary_logloss: 0.144508\n",
      "[5151]\ttraining's binary_logloss: 0.144493\n",
      "[5152]\ttraining's binary_logloss: 0.144481\n",
      "[5153]\ttraining's binary_logloss: 0.144465\n",
      "[5154]\ttraining's binary_logloss: 0.144449\n",
      "[5155]\ttraining's binary_logloss: 0.14444\n",
      "[5156]\ttraining's binary_logloss: 0.144427\n",
      "[5157]\ttraining's binary_logloss: 0.144415\n",
      "[5158]\ttraining's binary_logloss: 0.144402\n",
      "[5159]\ttraining's binary_logloss: 0.144391\n",
      "[5160]\ttraining's binary_logloss: 0.144376\n",
      "[5161]\ttraining's binary_logloss: 0.144364\n",
      "[5162]\ttraining's binary_logloss: 0.144352\n",
      "[5163]\ttraining's binary_logloss: 0.144337\n",
      "[5164]\ttraining's binary_logloss: 0.144325\n",
      "[5165]\ttraining's binary_logloss: 0.144313\n",
      "[5166]\ttraining's binary_logloss: 0.144297\n",
      "[5167]\ttraining's binary_logloss: 0.144293\n",
      "[5168]\ttraining's binary_logloss: 0.144275\n",
      "[5169]\ttraining's binary_logloss: 0.144267\n",
      "[5170]\ttraining's binary_logloss: 0.144252\n",
      "[5171]\ttraining's binary_logloss: 0.144237\n",
      "[5172]\ttraining's binary_logloss: 0.144222\n",
      "[5173]\ttraining's binary_logloss: 0.144207\n",
      "[5174]\ttraining's binary_logloss: 0.144195\n",
      "[5175]\ttraining's binary_logloss: 0.144191\n",
      "[5176]\ttraining's binary_logloss: 0.144177\n",
      "[5177]\ttraining's binary_logloss: 0.14417\n",
      "[5178]\ttraining's binary_logloss: 0.144159\n",
      "[5179]\ttraining's binary_logloss: 0.144146\n",
      "[5180]\ttraining's binary_logloss: 0.144133\n",
      "[5181]\ttraining's binary_logloss: 0.14412\n",
      "[5182]\ttraining's binary_logloss: 0.144108\n",
      "[5183]\ttraining's binary_logloss: 0.144095\n",
      "[5184]\ttraining's binary_logloss: 0.144082\n",
      "[5185]\ttraining's binary_logloss: 0.144068\n",
      "[5186]\ttraining's binary_logloss: 0.144054\n",
      "[5187]\ttraining's binary_logloss: 0.144041\n",
      "[5188]\ttraining's binary_logloss: 0.144026\n",
      "[5189]\ttraining's binary_logloss: 0.144017\n",
      "[5190]\ttraining's binary_logloss: 0.144003\n",
      "[5191]\ttraining's binary_logloss: 0.14399\n",
      "[5192]\ttraining's binary_logloss: 0.143987\n",
      "[5193]\ttraining's binary_logloss: 0.143974\n",
      "[5194]\ttraining's binary_logloss: 0.143958\n",
      "[5195]\ttraining's binary_logloss: 0.143947\n",
      "[5196]\ttraining's binary_logloss: 0.143933\n",
      "[5197]\ttraining's binary_logloss: 0.143919\n",
      "[5198]\ttraining's binary_logloss: 0.143909\n",
      "[5199]\ttraining's binary_logloss: 0.143896\n",
      "[5200]\ttraining's binary_logloss: 0.143884\n",
      "[5201]\ttraining's binary_logloss: 0.14387\n",
      "[5202]\ttraining's binary_logloss: 0.143855\n",
      "[5203]\ttraining's binary_logloss: 0.143844\n",
      "[5204]\ttraining's binary_logloss: 0.143829\n",
      "[5205]\ttraining's binary_logloss: 0.143813\n",
      "[5206]\ttraining's binary_logloss: 0.143801\n",
      "[5207]\ttraining's binary_logloss: 0.143785\n",
      "[5208]\ttraining's binary_logloss: 0.143771\n",
      "[5209]\ttraining's binary_logloss: 0.143757\n",
      "[5210]\ttraining's binary_logloss: 0.143743\n",
      "[5211]\ttraining's binary_logloss: 0.143728\n",
      "[5212]\ttraining's binary_logloss: 0.143714\n",
      "[5213]\ttraining's binary_logloss: 0.143705\n",
      "[5214]\ttraining's binary_logloss: 0.143693\n",
      "[5215]\ttraining's binary_logloss: 0.143677\n",
      "[5216]\ttraining's binary_logloss: 0.143663\n",
      "[5217]\ttraining's binary_logloss: 0.143652\n",
      "[5218]\ttraining's binary_logloss: 0.143643\n",
      "[5219]\ttraining's binary_logloss: 0.14363\n",
      "[5220]\ttraining's binary_logloss: 0.143619\n",
      "[5221]\ttraining's binary_logloss: 0.143606\n",
      "[5222]\ttraining's binary_logloss: 0.143592\n",
      "[5223]\ttraining's binary_logloss: 0.14358\n",
      "[5224]\ttraining's binary_logloss: 0.143566\n",
      "[5225]\ttraining's binary_logloss: 0.143552\n",
      "[5226]\ttraining's binary_logloss: 0.143537\n",
      "[5227]\ttraining's binary_logloss: 0.143523\n",
      "[5228]\ttraining's binary_logloss: 0.143507\n",
      "[5229]\ttraining's binary_logloss: 0.143492\n",
      "[5230]\ttraining's binary_logloss: 0.143479\n",
      "[5231]\ttraining's binary_logloss: 0.143464\n",
      "[5232]\ttraining's binary_logloss: 0.143456\n",
      "[5233]\ttraining's binary_logloss: 0.143442\n",
      "[5234]\ttraining's binary_logloss: 0.143432\n",
      "[5235]\ttraining's binary_logloss: 0.14342\n",
      "[5236]\ttraining's binary_logloss: 0.14341\n",
      "[5237]\ttraining's binary_logloss: 0.143397\n",
      "[5238]\ttraining's binary_logloss: 0.143388\n",
      "[5239]\ttraining's binary_logloss: 0.143374\n",
      "[5240]\ttraining's binary_logloss: 0.14336\n",
      "[5241]\ttraining's binary_logloss: 0.143346\n",
      "[5242]\ttraining's binary_logloss: 0.143332\n",
      "[5243]\ttraining's binary_logloss: 0.143319\n",
      "[5244]\ttraining's binary_logloss: 0.143304\n",
      "[5245]\ttraining's binary_logloss: 0.14329\n",
      "[5246]\ttraining's binary_logloss: 0.143276\n",
      "[5247]\ttraining's binary_logloss: 0.143272\n",
      "[5248]\ttraining's binary_logloss: 0.143258\n",
      "[5249]\ttraining's binary_logloss: 0.143244\n",
      "[5250]\ttraining's binary_logloss: 0.143228\n",
      "[5251]\ttraining's binary_logloss: 0.143217\n",
      "[5252]\ttraining's binary_logloss: 0.143214\n",
      "[5253]\ttraining's binary_logloss: 0.1432\n",
      "[5254]\ttraining's binary_logloss: 0.143186\n",
      "[5255]\ttraining's binary_logloss: 0.143172\n",
      "[5256]\ttraining's binary_logloss: 0.143156\n",
      "[5257]\ttraining's binary_logloss: 0.143143\n",
      "[5258]\ttraining's binary_logloss: 0.143138\n",
      "[5259]\ttraining's binary_logloss: 0.14313\n",
      "[5260]\ttraining's binary_logloss: 0.143122\n",
      "[5261]\ttraining's binary_logloss: 0.14311\n",
      "[5262]\ttraining's binary_logloss: 0.143103\n",
      "[5263]\ttraining's binary_logloss: 0.143091\n",
      "[5264]\ttraining's binary_logloss: 0.143081\n",
      "[5265]\ttraining's binary_logloss: 0.143069\n",
      "[5266]\ttraining's binary_logloss: 0.143058\n",
      "[5267]\ttraining's binary_logloss: 0.143049\n",
      "[5268]\ttraining's binary_logloss: 0.143037\n",
      "[5269]\ttraining's binary_logloss: 0.143023\n",
      "[5270]\ttraining's binary_logloss: 0.143009\n",
      "[5271]\ttraining's binary_logloss: 0.143002\n",
      "[5272]\ttraining's binary_logloss: 0.142985\n",
      "[5273]\ttraining's binary_logloss: 0.142971\n",
      "[5274]\ttraining's binary_logloss: 0.142968\n",
      "[5275]\ttraining's binary_logloss: 0.142953\n",
      "[5276]\ttraining's binary_logloss: 0.142936\n",
      "[5277]\ttraining's binary_logloss: 0.142922\n",
      "[5278]\ttraining's binary_logloss: 0.142909\n",
      "[5279]\ttraining's binary_logloss: 0.142895\n",
      "[5280]\ttraining's binary_logloss: 0.142884\n",
      "[5281]\ttraining's binary_logloss: 0.142881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5282]\ttraining's binary_logloss: 0.142867\n",
      "[5283]\ttraining's binary_logloss: 0.142863\n",
      "[5284]\ttraining's binary_logloss: 0.142849\n",
      "[5285]\ttraining's binary_logloss: 0.142837\n",
      "[5286]\ttraining's binary_logloss: 0.142823\n",
      "[5287]\ttraining's binary_logloss: 0.142806\n",
      "[5288]\ttraining's binary_logloss: 0.142803\n",
      "[5289]\ttraining's binary_logloss: 0.142788\n",
      "[5290]\ttraining's binary_logloss: 0.142775\n",
      "[5291]\ttraining's binary_logloss: 0.142763\n",
      "[5292]\ttraining's binary_logloss: 0.14276\n",
      "[5293]\ttraining's binary_logloss: 0.142757\n",
      "[5294]\ttraining's binary_logloss: 0.142748\n",
      "[5295]\ttraining's binary_logloss: 0.142745\n",
      "[5296]\ttraining's binary_logloss: 0.142732\n",
      "[5297]\ttraining's binary_logloss: 0.142719\n",
      "[5298]\ttraining's binary_logloss: 0.142703\n",
      "[5299]\ttraining's binary_logloss: 0.142691\n",
      "[5300]\ttraining's binary_logloss: 0.142677\n",
      "[5301]\ttraining's binary_logloss: 0.142664\n",
      "[5302]\ttraining's binary_logloss: 0.142654\n",
      "[5303]\ttraining's binary_logloss: 0.14265\n",
      "[5304]\ttraining's binary_logloss: 0.142637\n",
      "[5305]\ttraining's binary_logloss: 0.142623\n",
      "[5306]\ttraining's binary_logloss: 0.142608\n",
      "[5307]\ttraining's binary_logloss: 0.142601\n",
      "[5308]\ttraining's binary_logloss: 0.142587\n",
      "[5309]\ttraining's binary_logloss: 0.142573\n",
      "[5310]\ttraining's binary_logloss: 0.142561\n",
      "[5311]\ttraining's binary_logloss: 0.142547\n",
      "[5312]\ttraining's binary_logloss: 0.142532\n",
      "[5313]\ttraining's binary_logloss: 0.142522\n",
      "[5314]\ttraining's binary_logloss: 0.142517\n",
      "[5315]\ttraining's binary_logloss: 0.142498\n",
      "[5316]\ttraining's binary_logloss: 0.142485\n",
      "[5317]\ttraining's binary_logloss: 0.14247\n",
      "[5318]\ttraining's binary_logloss: 0.142457\n",
      "[5319]\ttraining's binary_logloss: 0.142443\n",
      "[5320]\ttraining's binary_logloss: 0.14243\n",
      "[5321]\ttraining's binary_logloss: 0.142427\n",
      "[5322]\ttraining's binary_logloss: 0.142412\n",
      "[5323]\ttraining's binary_logloss: 0.142397\n",
      "[5324]\ttraining's binary_logloss: 0.142386\n",
      "[5325]\ttraining's binary_logloss: 0.142372\n",
      "[5326]\ttraining's binary_logloss: 0.142359\n",
      "[5327]\ttraining's binary_logloss: 0.142346\n",
      "[5328]\ttraining's binary_logloss: 0.142332\n",
      "[5329]\ttraining's binary_logloss: 0.142318\n",
      "[5330]\ttraining's binary_logloss: 0.142303\n",
      "[5331]\ttraining's binary_logloss: 0.142287\n",
      "[5332]\ttraining's binary_logloss: 0.142272\n",
      "[5333]\ttraining's binary_logloss: 0.142259\n",
      "[5334]\ttraining's binary_logloss: 0.142244\n",
      "[5335]\ttraining's binary_logloss: 0.142236\n",
      "[5336]\ttraining's binary_logloss: 0.14223\n",
      "[5337]\ttraining's binary_logloss: 0.142219\n",
      "[5338]\ttraining's binary_logloss: 0.142206\n",
      "[5339]\ttraining's binary_logloss: 0.142193\n",
      "[5340]\ttraining's binary_logloss: 0.142178\n",
      "[5341]\ttraining's binary_logloss: 0.142162\n",
      "[5342]\ttraining's binary_logloss: 0.142147\n",
      "[5343]\ttraining's binary_logloss: 0.142135\n",
      "[5344]\ttraining's binary_logloss: 0.14213\n",
      "[5345]\ttraining's binary_logloss: 0.142118\n",
      "[5346]\ttraining's binary_logloss: 0.142111\n",
      "[5347]\ttraining's binary_logloss: 0.142098\n",
      "[5348]\ttraining's binary_logloss: 0.142084\n",
      "[5349]\ttraining's binary_logloss: 0.142075\n",
      "[5350]\ttraining's binary_logloss: 0.142063\n",
      "[5351]\ttraining's binary_logloss: 0.142048\n",
      "[5352]\ttraining's binary_logloss: 0.142035\n",
      "[5353]\ttraining's binary_logloss: 0.142021\n",
      "[5354]\ttraining's binary_logloss: 0.142017\n",
      "[5355]\ttraining's binary_logloss: 0.142003\n",
      "[5356]\ttraining's binary_logloss: 0.141994\n",
      "[5357]\ttraining's binary_logloss: 0.141981\n",
      "[5358]\ttraining's binary_logloss: 0.14197\n",
      "[5359]\ttraining's binary_logloss: 0.141953\n",
      "[5360]\ttraining's binary_logloss: 0.141942\n",
      "[5361]\ttraining's binary_logloss: 0.141932\n",
      "[5362]\ttraining's binary_logloss: 0.141919\n",
      "[5363]\ttraining's binary_logloss: 0.141904\n",
      "[5364]\ttraining's binary_logloss: 0.1419\n",
      "[5365]\ttraining's binary_logloss: 0.141891\n",
      "[5366]\ttraining's binary_logloss: 0.14188\n",
      "[5367]\ttraining's binary_logloss: 0.141865\n",
      "[5368]\ttraining's binary_logloss: 0.14185\n",
      "[5369]\ttraining's binary_logloss: 0.141837\n",
      "[5370]\ttraining's binary_logloss: 0.141833\n",
      "[5371]\ttraining's binary_logloss: 0.141824\n",
      "[5372]\ttraining's binary_logloss: 0.141812\n",
      "[5373]\ttraining's binary_logloss: 0.141798\n",
      "[5374]\ttraining's binary_logloss: 0.141784\n",
      "[5375]\ttraining's binary_logloss: 0.141771\n",
      "[5376]\ttraining's binary_logloss: 0.141757\n",
      "[5377]\ttraining's binary_logloss: 0.141739\n",
      "[5378]\ttraining's binary_logloss: 0.141736\n",
      "[5379]\ttraining's binary_logloss: 0.141722\n",
      "[5380]\ttraining's binary_logloss: 0.141708\n",
      "[5381]\ttraining's binary_logloss: 0.141701\n",
      "[5382]\ttraining's binary_logloss: 0.141689\n",
      "[5383]\ttraining's binary_logloss: 0.141684\n",
      "[5384]\ttraining's binary_logloss: 0.14167\n",
      "[5385]\ttraining's binary_logloss: 0.141663\n",
      "[5386]\ttraining's binary_logloss: 0.141647\n",
      "[5387]\ttraining's binary_logloss: 0.141635\n",
      "[5388]\ttraining's binary_logloss: 0.141622\n",
      "[5389]\ttraining's binary_logloss: 0.14161\n",
      "[5390]\ttraining's binary_logloss: 0.141596\n",
      "[5391]\ttraining's binary_logloss: 0.141582\n",
      "[5392]\ttraining's binary_logloss: 0.141578\n",
      "[5393]\ttraining's binary_logloss: 0.141573\n",
      "[5394]\ttraining's binary_logloss: 0.141561\n",
      "[5395]\ttraining's binary_logloss: 0.141549\n",
      "[5396]\ttraining's binary_logloss: 0.141545\n",
      "[5397]\ttraining's binary_logloss: 0.14153\n",
      "[5398]\ttraining's binary_logloss: 0.141517\n",
      "[5399]\ttraining's binary_logloss: 0.141504\n",
      "[5400]\ttraining's binary_logloss: 0.1415\n",
      "[5401]\ttraining's binary_logloss: 0.141484\n",
      "[5402]\ttraining's binary_logloss: 0.141469\n",
      "[5403]\ttraining's binary_logloss: 0.141456\n",
      "[5404]\ttraining's binary_logloss: 0.14144\n",
      "[5405]\ttraining's binary_logloss: 0.141429\n",
      "[5406]\ttraining's binary_logloss: 0.141415\n",
      "[5407]\ttraining's binary_logloss: 0.141403\n",
      "[5408]\ttraining's binary_logloss: 0.141394\n",
      "[5409]\ttraining's binary_logloss: 0.14139\n",
      "[5410]\ttraining's binary_logloss: 0.141386\n",
      "[5411]\ttraining's binary_logloss: 0.141369\n",
      "[5412]\ttraining's binary_logloss: 0.141355\n",
      "[5413]\ttraining's binary_logloss: 0.141342\n",
      "[5414]\ttraining's binary_logloss: 0.141339\n",
      "[5415]\ttraining's binary_logloss: 0.141325\n",
      "[5416]\ttraining's binary_logloss: 0.14132\n",
      "[5417]\ttraining's binary_logloss: 0.141307\n",
      "[5418]\ttraining's binary_logloss: 0.141299\n",
      "[5419]\ttraining's binary_logloss: 0.141291\n",
      "[5420]\ttraining's binary_logloss: 0.141278\n",
      "[5421]\ttraining's binary_logloss: 0.141271\n",
      "[5422]\ttraining's binary_logloss: 0.141253\n",
      "[5423]\ttraining's binary_logloss: 0.141251\n",
      "[5424]\ttraining's binary_logloss: 0.141233\n",
      "[5425]\ttraining's binary_logloss: 0.141221\n",
      "[5426]\ttraining's binary_logloss: 0.141207\n",
      "[5427]\ttraining's binary_logloss: 0.141195\n",
      "[5428]\ttraining's binary_logloss: 0.141182\n",
      "[5429]\ttraining's binary_logloss: 0.14117\n",
      "[5430]\ttraining's binary_logloss: 0.141155\n",
      "[5431]\ttraining's binary_logloss: 0.141151\n",
      "[5432]\ttraining's binary_logloss: 0.141137\n",
      "[5433]\ttraining's binary_logloss: 0.141125\n",
      "[5434]\ttraining's binary_logloss: 0.141114\n",
      "[5435]\ttraining's binary_logloss: 0.141102\n",
      "[5436]\ttraining's binary_logloss: 0.141086\n",
      "[5437]\ttraining's binary_logloss: 0.141072\n",
      "[5438]\ttraining's binary_logloss: 0.141058\n",
      "[5439]\ttraining's binary_logloss: 0.141044\n",
      "[5440]\ttraining's binary_logloss: 0.141032\n",
      "[5441]\ttraining's binary_logloss: 0.141018\n",
      "[5442]\ttraining's binary_logloss: 0.141007\n",
      "[5443]\ttraining's binary_logloss: 0.141\n",
      "[5444]\ttraining's binary_logloss: 0.140995\n",
      "[5445]\ttraining's binary_logloss: 0.14098\n",
      "[5446]\ttraining's binary_logloss: 0.140979\n",
      "[5447]\ttraining's binary_logloss: 0.140972\n",
      "[5448]\ttraining's binary_logloss: 0.140969\n",
      "[5449]\ttraining's binary_logloss: 0.140956\n",
      "[5450]\ttraining's binary_logloss: 0.140951\n",
      "[5451]\ttraining's binary_logloss: 0.140937\n",
      "[5452]\ttraining's binary_logloss: 0.140923\n",
      "[5453]\ttraining's binary_logloss: 0.140918\n",
      "[5454]\ttraining's binary_logloss: 0.140905\n",
      "[5455]\ttraining's binary_logloss: 0.140892\n",
      "[5456]\ttraining's binary_logloss: 0.140878\n",
      "[5457]\ttraining's binary_logloss: 0.140865\n",
      "[5458]\ttraining's binary_logloss: 0.140851\n",
      "[5459]\ttraining's binary_logloss: 0.140839\n",
      "[5460]\ttraining's binary_logloss: 0.140825\n",
      "[5461]\ttraining's binary_logloss: 0.140813\n",
      "[5462]\ttraining's binary_logloss: 0.140798\n",
      "[5463]\ttraining's binary_logloss: 0.140786\n",
      "[5464]\ttraining's binary_logloss: 0.140768\n",
      "[5465]\ttraining's binary_logloss: 0.140756\n",
      "[5466]\ttraining's binary_logloss: 0.140741\n",
      "[5467]\ttraining's binary_logloss: 0.140726\n",
      "[5468]\ttraining's binary_logloss: 0.140715\n",
      "[5469]\ttraining's binary_logloss: 0.140704\n",
      "[5470]\ttraining's binary_logloss: 0.140689\n",
      "[5471]\ttraining's binary_logloss: 0.140675\n",
      "[5472]\ttraining's binary_logloss: 0.140665\n",
      "[5473]\ttraining's binary_logloss: 0.140652\n",
      "[5474]\ttraining's binary_logloss: 0.140637\n",
      "[5475]\ttraining's binary_logloss: 0.140633\n",
      "[5476]\ttraining's binary_logloss: 0.140629\n",
      "[5477]\ttraining's binary_logloss: 0.140614\n",
      "[5478]\ttraining's binary_logloss: 0.140599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5479]\ttraining's binary_logloss: 0.140585\n",
      "[5480]\ttraining's binary_logloss: 0.140569\n",
      "[5481]\ttraining's binary_logloss: 0.140555\n",
      "[5482]\ttraining's binary_logloss: 0.140541\n",
      "[5483]\ttraining's binary_logloss: 0.140535\n",
      "[5484]\ttraining's binary_logloss: 0.140532\n",
      "[5485]\ttraining's binary_logloss: 0.140519\n",
      "[5486]\ttraining's binary_logloss: 0.140513\n",
      "[5487]\ttraining's binary_logloss: 0.140499\n",
      "[5488]\ttraining's binary_logloss: 0.140489\n",
      "[5489]\ttraining's binary_logloss: 0.140484\n",
      "[5490]\ttraining's binary_logloss: 0.140468\n",
      "[5491]\ttraining's binary_logloss: 0.140455\n",
      "[5492]\ttraining's binary_logloss: 0.140443\n",
      "[5493]\ttraining's binary_logloss: 0.140428\n",
      "[5494]\ttraining's binary_logloss: 0.140412\n",
      "[5495]\ttraining's binary_logloss: 0.140399\n",
      "[5496]\ttraining's binary_logloss: 0.140384\n",
      "[5497]\ttraining's binary_logloss: 0.140372\n",
      "[5498]\ttraining's binary_logloss: 0.140359\n",
      "[5499]\ttraining's binary_logloss: 0.140343\n",
      "[5500]\ttraining's binary_logloss: 0.140329\n",
      "[5501]\ttraining's binary_logloss: 0.140317\n",
      "[5502]\ttraining's binary_logloss: 0.140303\n",
      "[5503]\ttraining's binary_logloss: 0.14029\n",
      "[5504]\ttraining's binary_logloss: 0.140279\n",
      "[5505]\ttraining's binary_logloss: 0.140275\n",
      "[5506]\ttraining's binary_logloss: 0.140268\n",
      "[5507]\ttraining's binary_logloss: 0.140252\n",
      "[5508]\ttraining's binary_logloss: 0.140237\n",
      "[5509]\ttraining's binary_logloss: 0.140224\n",
      "[5510]\ttraining's binary_logloss: 0.140221\n",
      "[5511]\ttraining's binary_logloss: 0.140209\n",
      "[5512]\ttraining's binary_logloss: 0.140206\n",
      "[5513]\ttraining's binary_logloss: 0.140193\n",
      "[5514]\ttraining's binary_logloss: 0.140187\n",
      "[5515]\ttraining's binary_logloss: 0.140175\n",
      "[5516]\ttraining's binary_logloss: 0.140163\n",
      "[5517]\ttraining's binary_logloss: 0.140156\n",
      "[5518]\ttraining's binary_logloss: 0.140155\n",
      "[5519]\ttraining's binary_logloss: 0.140148\n",
      "[5520]\ttraining's binary_logloss: 0.140136\n",
      "[5521]\ttraining's binary_logloss: 0.140131\n",
      "[5522]\ttraining's binary_logloss: 0.140128\n",
      "[5523]\ttraining's binary_logloss: 0.140113\n",
      "[5524]\ttraining's binary_logloss: 0.140104\n",
      "[5525]\ttraining's binary_logloss: 0.140089\n",
      "[5526]\ttraining's binary_logloss: 0.140078\n",
      "[5527]\ttraining's binary_logloss: 0.140067\n",
      "[5528]\ttraining's binary_logloss: 0.140062\n",
      "[5529]\ttraining's binary_logloss: 0.140049\n",
      "[5530]\ttraining's binary_logloss: 0.140047\n",
      "[5531]\ttraining's binary_logloss: 0.140033\n",
      "[5532]\ttraining's binary_logloss: 0.140027\n",
      "[5533]\ttraining's binary_logloss: 0.140026\n",
      "[5534]\ttraining's binary_logloss: 0.140013\n",
      "[5535]\ttraining's binary_logloss: 0.140001\n",
      "[5536]\ttraining's binary_logloss: 0.139987\n",
      "[5537]\ttraining's binary_logloss: 0.139972\n",
      "[5538]\ttraining's binary_logloss: 0.139958\n",
      "[5539]\ttraining's binary_logloss: 0.13994\n",
      "[5540]\ttraining's binary_logloss: 0.139928\n",
      "[5541]\ttraining's binary_logloss: 0.139926\n",
      "[5542]\ttraining's binary_logloss: 0.139913\n",
      "[5543]\ttraining's binary_logloss: 0.139907\n",
      "[5544]\ttraining's binary_logloss: 0.139892\n",
      "[5545]\ttraining's binary_logloss: 0.139879\n",
      "[5546]\ttraining's binary_logloss: 0.139862\n",
      "[5547]\ttraining's binary_logloss: 0.139849\n",
      "[5548]\ttraining's binary_logloss: 0.139842\n",
      "[5549]\ttraining's binary_logloss: 0.139829\n",
      "[5550]\ttraining's binary_logloss: 0.139815\n",
      "[5551]\ttraining's binary_logloss: 0.13981\n",
      "[5552]\ttraining's binary_logloss: 0.139799\n",
      "[5553]\ttraining's binary_logloss: 0.139786\n",
      "[5554]\ttraining's binary_logloss: 0.139771\n",
      "[5555]\ttraining's binary_logloss: 0.139759\n",
      "[5556]\ttraining's binary_logloss: 0.13975\n",
      "[5557]\ttraining's binary_logloss: 0.139736\n",
      "[5558]\ttraining's binary_logloss: 0.139723\n",
      "[5559]\ttraining's binary_logloss: 0.139708\n",
      "[5560]\ttraining's binary_logloss: 0.139694\n",
      "[5561]\ttraining's binary_logloss: 0.139685\n",
      "[5562]\ttraining's binary_logloss: 0.139677\n",
      "[5563]\ttraining's binary_logloss: 0.139668\n",
      "[5564]\ttraining's binary_logloss: 0.139653\n",
      "[5565]\ttraining's binary_logloss: 0.139648\n",
      "[5566]\ttraining's binary_logloss: 0.139636\n",
      "[5567]\ttraining's binary_logloss: 0.139621\n",
      "[5568]\ttraining's binary_logloss: 0.139616\n",
      "[5569]\ttraining's binary_logloss: 0.1396\n",
      "[5570]\ttraining's binary_logloss: 0.139585\n",
      "[5571]\ttraining's binary_logloss: 0.139572\n",
      "[5572]\ttraining's binary_logloss: 0.139557\n",
      "[5573]\ttraining's binary_logloss: 0.139545\n",
      "[5574]\ttraining's binary_logloss: 0.139532\n",
      "[5575]\ttraining's binary_logloss: 0.139518\n",
      "[5576]\ttraining's binary_logloss: 0.139506\n",
      "[5577]\ttraining's binary_logloss: 0.139491\n",
      "[5578]\ttraining's binary_logloss: 0.139487\n",
      "[5579]\ttraining's binary_logloss: 0.139474\n",
      "[5580]\ttraining's binary_logloss: 0.139459\n",
      "[5581]\ttraining's binary_logloss: 0.139445\n",
      "[5582]\ttraining's binary_logloss: 0.13943\n",
      "[5583]\ttraining's binary_logloss: 0.139417\n",
      "[5584]\ttraining's binary_logloss: 0.139402\n",
      "[5585]\ttraining's binary_logloss: 0.139387\n",
      "[5586]\ttraining's binary_logloss: 0.139379\n",
      "[5587]\ttraining's binary_logloss: 0.139375\n",
      "[5588]\ttraining's binary_logloss: 0.139362\n",
      "[5589]\ttraining's binary_logloss: 0.139352\n",
      "[5590]\ttraining's binary_logloss: 0.139337\n",
      "[5591]\ttraining's binary_logloss: 0.139325\n",
      "[5592]\ttraining's binary_logloss: 0.139312\n",
      "[5593]\ttraining's binary_logloss: 0.139297\n",
      "[5594]\ttraining's binary_logloss: 0.139284\n",
      "[5595]\ttraining's binary_logloss: 0.139268\n",
      "[5596]\ttraining's binary_logloss: 0.139261\n",
      "[5597]\ttraining's binary_logloss: 0.13925\n",
      "[5598]\ttraining's binary_logloss: 0.139237\n",
      "[5599]\ttraining's binary_logloss: 0.139223\n",
      "[5600]\ttraining's binary_logloss: 0.139211\n",
      "[5601]\ttraining's binary_logloss: 0.139197\n",
      "[5602]\ttraining's binary_logloss: 0.139191\n",
      "[5603]\ttraining's binary_logloss: 0.139179\n",
      "[5604]\ttraining's binary_logloss: 0.139166\n",
      "[5605]\ttraining's binary_logloss: 0.139153\n",
      "[5606]\ttraining's binary_logloss: 0.139139\n",
      "[5607]\ttraining's binary_logloss: 0.139128\n",
      "[5608]\ttraining's binary_logloss: 0.139115\n",
      "[5609]\ttraining's binary_logloss: 0.139099\n",
      "[5610]\ttraining's binary_logloss: 0.139085\n",
      "[5611]\ttraining's binary_logloss: 0.139082\n",
      "[5612]\ttraining's binary_logloss: 0.139079\n",
      "[5613]\ttraining's binary_logloss: 0.139073\n",
      "[5614]\ttraining's binary_logloss: 0.139066\n",
      "[5615]\ttraining's binary_logloss: 0.139061\n",
      "[5616]\ttraining's binary_logloss: 0.139049\n",
      "[5617]\ttraining's binary_logloss: 0.139044\n",
      "[5618]\ttraining's binary_logloss: 0.139031\n",
      "[5619]\ttraining's binary_logloss: 0.139014\n",
      "[5620]\ttraining's binary_logloss: 0.139004\n",
      "[5621]\ttraining's binary_logloss: 0.138993\n",
      "[5622]\ttraining's binary_logloss: 0.13898\n",
      "[5623]\ttraining's binary_logloss: 0.138969\n",
      "[5624]\ttraining's binary_logloss: 0.138962\n",
      "[5625]\ttraining's binary_logloss: 0.138952\n",
      "[5626]\ttraining's binary_logloss: 0.138946\n",
      "[5627]\ttraining's binary_logloss: 0.138933\n",
      "[5628]\ttraining's binary_logloss: 0.138921\n",
      "[5629]\ttraining's binary_logloss: 0.138906\n",
      "[5630]\ttraining's binary_logloss: 0.138894\n",
      "[5631]\ttraining's binary_logloss: 0.138879\n",
      "[5632]\ttraining's binary_logloss: 0.138865\n",
      "[5633]\ttraining's binary_logloss: 0.138852\n",
      "[5634]\ttraining's binary_logloss: 0.138849\n",
      "[5635]\ttraining's binary_logloss: 0.138835\n",
      "[5636]\ttraining's binary_logloss: 0.138821\n",
      "[5637]\ttraining's binary_logloss: 0.138807\n",
      "[5638]\ttraining's binary_logloss: 0.138793\n",
      "[5639]\ttraining's binary_logloss: 0.13878\n",
      "[5640]\ttraining's binary_logloss: 0.138766\n",
      "[5641]\ttraining's binary_logloss: 0.138754\n",
      "[5642]\ttraining's binary_logloss: 0.138744\n",
      "[5643]\ttraining's binary_logloss: 0.138729\n",
      "[5644]\ttraining's binary_logloss: 0.138714\n",
      "[5645]\ttraining's binary_logloss: 0.1387\n",
      "[5646]\ttraining's binary_logloss: 0.138698\n",
      "[5647]\ttraining's binary_logloss: 0.138695\n",
      "[5648]\ttraining's binary_logloss: 0.138682\n",
      "[5649]\ttraining's binary_logloss: 0.138669\n",
      "[5650]\ttraining's binary_logloss: 0.138667\n",
      "[5651]\ttraining's binary_logloss: 0.138652\n",
      "[5652]\ttraining's binary_logloss: 0.138634\n",
      "[5653]\ttraining's binary_logloss: 0.138632\n",
      "[5654]\ttraining's binary_logloss: 0.138629\n",
      "[5655]\ttraining's binary_logloss: 0.138616\n",
      "[5656]\ttraining's binary_logloss: 0.138601\n",
      "[5657]\ttraining's binary_logloss: 0.138589\n",
      "[5658]\ttraining's binary_logloss: 0.138578\n",
      "[5659]\ttraining's binary_logloss: 0.138565\n",
      "[5660]\ttraining's binary_logloss: 0.13855\n",
      "[5661]\ttraining's binary_logloss: 0.138536\n",
      "[5662]\ttraining's binary_logloss: 0.138522\n",
      "[5663]\ttraining's binary_logloss: 0.138513\n",
      "[5664]\ttraining's binary_logloss: 0.138496\n",
      "[5665]\ttraining's binary_logloss: 0.13849\n",
      "[5666]\ttraining's binary_logloss: 0.138476\n",
      "[5667]\ttraining's binary_logloss: 0.138465\n",
      "[5668]\ttraining's binary_logloss: 0.138452\n",
      "[5669]\ttraining's binary_logloss: 0.13844\n",
      "[5670]\ttraining's binary_logloss: 0.138426\n",
      "[5671]\ttraining's binary_logloss: 0.138418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5672]\ttraining's binary_logloss: 0.138412\n",
      "[5673]\ttraining's binary_logloss: 0.138397\n",
      "[5674]\ttraining's binary_logloss: 0.138385\n",
      "[5675]\ttraining's binary_logloss: 0.138373\n",
      "[5676]\ttraining's binary_logloss: 0.13836\n",
      "[5677]\ttraining's binary_logloss: 0.138351\n",
      "[5678]\ttraining's binary_logloss: 0.138339\n",
      "[5679]\ttraining's binary_logloss: 0.13833\n",
      "[5680]\ttraining's binary_logloss: 0.138317\n",
      "[5681]\ttraining's binary_logloss: 0.138307\n",
      "[5682]\ttraining's binary_logloss: 0.138295\n",
      "[5683]\ttraining's binary_logloss: 0.13828\n",
      "[5684]\ttraining's binary_logloss: 0.138269\n",
      "[5685]\ttraining's binary_logloss: 0.138259\n",
      "[5686]\ttraining's binary_logloss: 0.138245\n",
      "[5687]\ttraining's binary_logloss: 0.138229\n",
      "[5688]\ttraining's binary_logloss: 0.138217\n",
      "[5689]\ttraining's binary_logloss: 0.138203\n",
      "[5690]\ttraining's binary_logloss: 0.13819\n",
      "[5691]\ttraining's binary_logloss: 0.138181\n",
      "[5692]\ttraining's binary_logloss: 0.138168\n",
      "[5693]\ttraining's binary_logloss: 0.138162\n",
      "[5694]\ttraining's binary_logloss: 0.138147\n",
      "[5695]\ttraining's binary_logloss: 0.138134\n",
      "[5696]\ttraining's binary_logloss: 0.13812\n",
      "[5697]\ttraining's binary_logloss: 0.138106\n",
      "[5698]\ttraining's binary_logloss: 0.138093\n",
      "[5699]\ttraining's binary_logloss: 0.138077\n",
      "[5700]\ttraining's binary_logloss: 0.138062\n",
      "[5701]\ttraining's binary_logloss: 0.138048\n",
      "[5702]\ttraining's binary_logloss: 0.138032\n",
      "[5703]\ttraining's binary_logloss: 0.13802\n",
      "[5704]\ttraining's binary_logloss: 0.138006\n",
      "[5705]\ttraining's binary_logloss: 0.137991\n",
      "[5706]\ttraining's binary_logloss: 0.137976\n",
      "[5707]\ttraining's binary_logloss: 0.137963\n",
      "[5708]\ttraining's binary_logloss: 0.137949\n",
      "[5709]\ttraining's binary_logloss: 0.137935\n",
      "[5710]\ttraining's binary_logloss: 0.137922\n",
      "[5711]\ttraining's binary_logloss: 0.137914\n",
      "[5712]\ttraining's binary_logloss: 0.137902\n",
      "[5713]\ttraining's binary_logloss: 0.13789\n",
      "[5714]\ttraining's binary_logloss: 0.137877\n",
      "[5715]\ttraining's binary_logloss: 0.137865\n",
      "[5716]\ttraining's binary_logloss: 0.13785\n",
      "[5717]\ttraining's binary_logloss: 0.137842\n",
      "[5718]\ttraining's binary_logloss: 0.137827\n",
      "[5719]\ttraining's binary_logloss: 0.137814\n",
      "[5720]\ttraining's binary_logloss: 0.1378\n",
      "[5721]\ttraining's binary_logloss: 0.137793\n",
      "[5722]\ttraining's binary_logloss: 0.137778\n",
      "[5723]\ttraining's binary_logloss: 0.137764\n",
      "[5724]\ttraining's binary_logloss: 0.137753\n",
      "[5725]\ttraining's binary_logloss: 0.137738\n",
      "[5726]\ttraining's binary_logloss: 0.137725\n",
      "[5727]\ttraining's binary_logloss: 0.13771\n",
      "[5728]\ttraining's binary_logloss: 0.137695\n",
      "[5729]\ttraining's binary_logloss: 0.137681\n",
      "[5730]\ttraining's binary_logloss: 0.137668\n",
      "[5731]\ttraining's binary_logloss: 0.137655\n",
      "[5732]\ttraining's binary_logloss: 0.137647\n",
      "[5733]\ttraining's binary_logloss: 0.137642\n",
      "[5734]\ttraining's binary_logloss: 0.137627\n",
      "[5735]\ttraining's binary_logloss: 0.137616\n",
      "[5736]\ttraining's binary_logloss: 0.137604\n",
      "[5737]\ttraining's binary_logloss: 0.137591\n",
      "[5738]\ttraining's binary_logloss: 0.137573\n",
      "[5739]\ttraining's binary_logloss: 0.137569\n",
      "[5740]\ttraining's binary_logloss: 0.137558\n",
      "[5741]\ttraining's binary_logloss: 0.137547\n",
      "[5742]\ttraining's binary_logloss: 0.137534\n",
      "[5743]\ttraining's binary_logloss: 0.137519\n",
      "[5744]\ttraining's binary_logloss: 0.137513\n",
      "[5745]\ttraining's binary_logloss: 0.137502\n",
      "[5746]\ttraining's binary_logloss: 0.137487\n",
      "[5747]\ttraining's binary_logloss: 0.137474\n",
      "[5748]\ttraining's binary_logloss: 0.137462\n",
      "[5749]\ttraining's binary_logloss: 0.137448\n",
      "[5750]\ttraining's binary_logloss: 0.137436\n",
      "[5751]\ttraining's binary_logloss: 0.137424\n",
      "[5752]\ttraining's binary_logloss: 0.137412\n",
      "[5753]\ttraining's binary_logloss: 0.137401\n",
      "[5754]\ttraining's binary_logloss: 0.137397\n",
      "[5755]\ttraining's binary_logloss: 0.137387\n",
      "[5756]\ttraining's binary_logloss: 0.137374\n",
      "[5757]\ttraining's binary_logloss: 0.13736\n",
      "[5758]\ttraining's binary_logloss: 0.137352\n",
      "[5759]\ttraining's binary_logloss: 0.137338\n",
      "[5760]\ttraining's binary_logloss: 0.137325\n",
      "[5761]\ttraining's binary_logloss: 0.137311\n",
      "[5762]\ttraining's binary_logloss: 0.137296\n",
      "[5763]\ttraining's binary_logloss: 0.137284\n",
      "[5764]\ttraining's binary_logloss: 0.137271\n",
      "[5765]\ttraining's binary_logloss: 0.137259\n",
      "[5766]\ttraining's binary_logloss: 0.137245\n",
      "[5767]\ttraining's binary_logloss: 0.137228\n",
      "[5768]\ttraining's binary_logloss: 0.137218\n",
      "[5769]\ttraining's binary_logloss: 0.137204\n",
      "[5770]\ttraining's binary_logloss: 0.137191\n",
      "[5771]\ttraining's binary_logloss: 0.137178\n",
      "[5772]\ttraining's binary_logloss: 0.137164\n",
      "[5773]\ttraining's binary_logloss: 0.13715\n",
      "[5774]\ttraining's binary_logloss: 0.137136\n",
      "[5775]\ttraining's binary_logloss: 0.137123\n",
      "[5776]\ttraining's binary_logloss: 0.137112\n",
      "[5777]\ttraining's binary_logloss: 0.137099\n",
      "[5778]\ttraining's binary_logloss: 0.137086\n",
      "[5779]\ttraining's binary_logloss: 0.13707\n",
      "[5780]\ttraining's binary_logloss: 0.137058\n",
      "[5781]\ttraining's binary_logloss: 0.13705\n",
      "[5782]\ttraining's binary_logloss: 0.137035\n",
      "[5783]\ttraining's binary_logloss: 0.137026\n",
      "[5784]\ttraining's binary_logloss: 0.137011\n",
      "[5785]\ttraining's binary_logloss: 0.137001\n",
      "[5786]\ttraining's binary_logloss: 0.136984\n",
      "[5787]\ttraining's binary_logloss: 0.136969\n",
      "[5788]\ttraining's binary_logloss: 0.136956\n",
      "[5789]\ttraining's binary_logloss: 0.136943\n",
      "[5790]\ttraining's binary_logloss: 0.136928\n",
      "[5791]\ttraining's binary_logloss: 0.136916\n",
      "[5792]\ttraining's binary_logloss: 0.136906\n",
      "[5793]\ttraining's binary_logloss: 0.136892\n",
      "[5794]\ttraining's binary_logloss: 0.136889\n",
      "[5795]\ttraining's binary_logloss: 0.136873\n",
      "[5796]\ttraining's binary_logloss: 0.136859\n",
      "[5797]\ttraining's binary_logloss: 0.136846\n",
      "[5798]\ttraining's binary_logloss: 0.136837\n",
      "[5799]\ttraining's binary_logloss: 0.136824\n",
      "[5800]\ttraining's binary_logloss: 0.13681\n",
      "[5801]\ttraining's binary_logloss: 0.136797\n",
      "[5802]\ttraining's binary_logloss: 0.136783\n",
      "[5803]\ttraining's binary_logloss: 0.136771\n",
      "[5804]\ttraining's binary_logloss: 0.136758\n",
      "[5805]\ttraining's binary_logloss: 0.136744\n",
      "[5806]\ttraining's binary_logloss: 0.13673\n",
      "[5807]\ttraining's binary_logloss: 0.136717\n",
      "[5808]\ttraining's binary_logloss: 0.136705\n",
      "[5809]\ttraining's binary_logloss: 0.136691\n",
      "[5810]\ttraining's binary_logloss: 0.136679\n",
      "[5811]\ttraining's binary_logloss: 0.136666\n",
      "[5812]\ttraining's binary_logloss: 0.136653\n",
      "[5813]\ttraining's binary_logloss: 0.136641\n",
      "[5814]\ttraining's binary_logloss: 0.136632\n",
      "[5815]\ttraining's binary_logloss: 0.136618\n",
      "[5816]\ttraining's binary_logloss: 0.136603\n",
      "[5817]\ttraining's binary_logloss: 0.13659\n",
      "[5818]\ttraining's binary_logloss: 0.136578\n",
      "[5819]\ttraining's binary_logloss: 0.136565\n",
      "[5820]\ttraining's binary_logloss: 0.136555\n",
      "[5821]\ttraining's binary_logloss: 0.136546\n",
      "[5822]\ttraining's binary_logloss: 0.136534\n",
      "[5823]\ttraining's binary_logloss: 0.136522\n",
      "[5824]\ttraining's binary_logloss: 0.136509\n",
      "[5825]\ttraining's binary_logloss: 0.136503\n",
      "[5826]\ttraining's binary_logloss: 0.136491\n",
      "[5827]\ttraining's binary_logloss: 0.136478\n",
      "[5828]\ttraining's binary_logloss: 0.136469\n",
      "[5829]\ttraining's binary_logloss: 0.136456\n",
      "[5830]\ttraining's binary_logloss: 0.136443\n",
      "[5831]\ttraining's binary_logloss: 0.136429\n",
      "[5832]\ttraining's binary_logloss: 0.136414\n",
      "[5833]\ttraining's binary_logloss: 0.136407\n",
      "[5834]\ttraining's binary_logloss: 0.136395\n",
      "[5835]\ttraining's binary_logloss: 0.136383\n",
      "[5836]\ttraining's binary_logloss: 0.136368\n",
      "[5837]\ttraining's binary_logloss: 0.136356\n",
      "[5838]\ttraining's binary_logloss: 0.136343\n",
      "[5839]\ttraining's binary_logloss: 0.136333\n",
      "[5840]\ttraining's binary_logloss: 0.136332\n",
      "[5841]\ttraining's binary_logloss: 0.136321\n",
      "[5842]\ttraining's binary_logloss: 0.136307\n",
      "[5843]\ttraining's binary_logloss: 0.136292\n",
      "[5844]\ttraining's binary_logloss: 0.136276\n",
      "[5845]\ttraining's binary_logloss: 0.136264\n",
      "[5846]\ttraining's binary_logloss: 0.136249\n",
      "[5847]\ttraining's binary_logloss: 0.136233\n",
      "[5848]\ttraining's binary_logloss: 0.136221\n",
      "[5849]\ttraining's binary_logloss: 0.136208\n",
      "[5850]\ttraining's binary_logloss: 0.136193\n",
      "[5851]\ttraining's binary_logloss: 0.136179\n",
      "[5852]\ttraining's binary_logloss: 0.136161\n",
      "[5853]\ttraining's binary_logloss: 0.136148\n",
      "[5854]\ttraining's binary_logloss: 0.136135\n",
      "[5855]\ttraining's binary_logloss: 0.136122\n",
      "[5856]\ttraining's binary_logloss: 0.136108\n",
      "[5857]\ttraining's binary_logloss: 0.136097\n",
      "[5858]\ttraining's binary_logloss: 0.136084\n",
      "[5859]\ttraining's binary_logloss: 0.13608\n",
      "[5860]\ttraining's binary_logloss: 0.136068\n",
      "[5861]\ttraining's binary_logloss: 0.136055\n",
      "[5862]\ttraining's binary_logloss: 0.136042\n",
      "[5863]\ttraining's binary_logloss: 0.136041\n",
      "[5864]\ttraining's binary_logloss: 0.136029\n",
      "[5865]\ttraining's binary_logloss: 0.13602\n",
      "[5866]\ttraining's binary_logloss: 0.136011\n",
      "[5867]\ttraining's binary_logloss: 0.136\n",
      "[5868]\ttraining's binary_logloss: 0.135988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5869]\ttraining's binary_logloss: 0.135974\n",
      "[5870]\ttraining's binary_logloss: 0.135962\n",
      "[5871]\ttraining's binary_logloss: 0.135958\n",
      "[5872]\ttraining's binary_logloss: 0.135947\n",
      "[5873]\ttraining's binary_logloss: 0.135935\n",
      "[5874]\ttraining's binary_logloss: 0.135926\n",
      "[5875]\ttraining's binary_logloss: 0.135914\n",
      "[5876]\ttraining's binary_logloss: 0.1359\n",
      "[5877]\ttraining's binary_logloss: 0.135893\n",
      "[5878]\ttraining's binary_logloss: 0.135882\n",
      "[5879]\ttraining's binary_logloss: 0.13587\n",
      "[5880]\ttraining's binary_logloss: 0.135858\n",
      "[5881]\ttraining's binary_logloss: 0.135847\n",
      "[5882]\ttraining's binary_logloss: 0.135834\n",
      "[5883]\ttraining's binary_logloss: 0.135824\n",
      "[5884]\ttraining's binary_logloss: 0.135812\n",
      "[5885]\ttraining's binary_logloss: 0.135796\n",
      "[5886]\ttraining's binary_logloss: 0.135784\n",
      "[5887]\ttraining's binary_logloss: 0.135769\n",
      "[5888]\ttraining's binary_logloss: 0.135756\n",
      "[5889]\ttraining's binary_logloss: 0.135752\n",
      "[5890]\ttraining's binary_logloss: 0.135747\n",
      "[5891]\ttraining's binary_logloss: 0.135735\n",
      "[5892]\ttraining's binary_logloss: 0.135724\n",
      "[5893]\ttraining's binary_logloss: 0.135722\n",
      "[5894]\ttraining's binary_logloss: 0.135715\n",
      "[5895]\ttraining's binary_logloss: 0.135704\n",
      "[5896]\ttraining's binary_logloss: 0.135691\n",
      "[5897]\ttraining's binary_logloss: 0.135688\n",
      "[5898]\ttraining's binary_logloss: 0.135681\n",
      "[5899]\ttraining's binary_logloss: 0.135667\n",
      "[5900]\ttraining's binary_logloss: 0.135653\n",
      "[5901]\ttraining's binary_logloss: 0.135643\n",
      "[5902]\ttraining's binary_logloss: 0.135632\n",
      "[5903]\ttraining's binary_logloss: 0.135622\n",
      "[5904]\ttraining's binary_logloss: 0.135618\n",
      "[5905]\ttraining's binary_logloss: 0.135605\n",
      "[5906]\ttraining's binary_logloss: 0.1356\n",
      "[5907]\ttraining's binary_logloss: 0.135586\n",
      "[5908]\ttraining's binary_logloss: 0.135583\n",
      "[5909]\ttraining's binary_logloss: 0.135568\n",
      "[5910]\ttraining's binary_logloss: 0.135556\n",
      "[5911]\ttraining's binary_logloss: 0.135545\n",
      "[5912]\ttraining's binary_logloss: 0.135535\n",
      "[5913]\ttraining's binary_logloss: 0.135526\n",
      "[5914]\ttraining's binary_logloss: 0.135513\n",
      "[5915]\ttraining's binary_logloss: 0.135499\n",
      "[5916]\ttraining's binary_logloss: 0.135486\n",
      "[5917]\ttraining's binary_logloss: 0.135473\n",
      "[5918]\ttraining's binary_logloss: 0.13546\n",
      "[5919]\ttraining's binary_logloss: 0.135448\n",
      "[5920]\ttraining's binary_logloss: 0.135435\n",
      "[5921]\ttraining's binary_logloss: 0.135423\n",
      "[5922]\ttraining's binary_logloss: 0.135409\n",
      "[5923]\ttraining's binary_logloss: 0.135404\n",
      "[5924]\ttraining's binary_logloss: 0.135395\n",
      "[5925]\ttraining's binary_logloss: 0.135382\n",
      "[5926]\ttraining's binary_logloss: 0.135369\n",
      "[5927]\ttraining's binary_logloss: 0.135356\n",
      "[5928]\ttraining's binary_logloss: 0.135342\n",
      "[5929]\ttraining's binary_logloss: 0.135331\n",
      "[5930]\ttraining's binary_logloss: 0.135319\n",
      "[5931]\ttraining's binary_logloss: 0.135307\n",
      "[5932]\ttraining's binary_logloss: 0.135303\n",
      "[5933]\ttraining's binary_logloss: 0.135292\n",
      "[5934]\ttraining's binary_logloss: 0.135291\n",
      "[5935]\ttraining's binary_logloss: 0.135278\n",
      "[5936]\ttraining's binary_logloss: 0.135265\n",
      "[5937]\ttraining's binary_logloss: 0.135252\n",
      "[5938]\ttraining's binary_logloss: 0.135239\n",
      "[5939]\ttraining's binary_logloss: 0.135226\n",
      "[5940]\ttraining's binary_logloss: 0.135215\n",
      "[5941]\ttraining's binary_logloss: 0.135201\n",
      "[5942]\ttraining's binary_logloss: 0.135188\n",
      "[5943]\ttraining's binary_logloss: 0.135177\n",
      "[5944]\ttraining's binary_logloss: 0.135167\n",
      "[5945]\ttraining's binary_logloss: 0.135157\n",
      "[5946]\ttraining's binary_logloss: 0.13515\n",
      "[5947]\ttraining's binary_logloss: 0.135143\n",
      "[5948]\ttraining's binary_logloss: 0.135139\n",
      "[5949]\ttraining's binary_logloss: 0.135136\n",
      "[5950]\ttraining's binary_logloss: 0.135132\n",
      "[5951]\ttraining's binary_logloss: 0.13512\n",
      "[5952]\ttraining's binary_logloss: 0.135107\n",
      "[5953]\ttraining's binary_logloss: 0.135097\n",
      "[5954]\ttraining's binary_logloss: 0.135083\n",
      "[5955]\ttraining's binary_logloss: 0.135068\n",
      "[5956]\ttraining's binary_logloss: 0.135059\n",
      "[5957]\ttraining's binary_logloss: 0.135046\n",
      "[5958]\ttraining's binary_logloss: 0.135033\n",
      "[5959]\ttraining's binary_logloss: 0.135028\n",
      "[5960]\ttraining's binary_logloss: 0.135014\n",
      "[5961]\ttraining's binary_logloss: 0.135002\n",
      "[5962]\ttraining's binary_logloss: 0.13499\n",
      "[5963]\ttraining's binary_logloss: 0.134976\n",
      "[5964]\ttraining's binary_logloss: 0.134963\n",
      "[5965]\ttraining's binary_logloss: 0.134949\n",
      "[5966]\ttraining's binary_logloss: 0.134935\n",
      "[5967]\ttraining's binary_logloss: 0.13492\n",
      "[5968]\ttraining's binary_logloss: 0.134907\n",
      "[5969]\ttraining's binary_logloss: 0.134893\n",
      "[5970]\ttraining's binary_logloss: 0.13488\n",
      "[5971]\ttraining's binary_logloss: 0.134865\n",
      "[5972]\ttraining's binary_logloss: 0.134851\n",
      "[5973]\ttraining's binary_logloss: 0.134836\n",
      "[5974]\ttraining's binary_logloss: 0.134823\n",
      "[5975]\ttraining's binary_logloss: 0.134811\n",
      "[5976]\ttraining's binary_logloss: 0.134797\n",
      "[5977]\ttraining's binary_logloss: 0.134785\n",
      "[5978]\ttraining's binary_logloss: 0.134782\n",
      "[5979]\ttraining's binary_logloss: 0.134771\n",
      "[5980]\ttraining's binary_logloss: 0.134758\n",
      "[5981]\ttraining's binary_logloss: 0.134755\n",
      "[5982]\ttraining's binary_logloss: 0.134743\n",
      "[5983]\ttraining's binary_logloss: 0.134729\n",
      "[5984]\ttraining's binary_logloss: 0.134715\n",
      "[5985]\ttraining's binary_logloss: 0.134707\n",
      "[5986]\ttraining's binary_logloss: 0.134706\n",
      "[5987]\ttraining's binary_logloss: 0.134691\n",
      "[5988]\ttraining's binary_logloss: 0.134677\n",
      "[5989]\ttraining's binary_logloss: 0.134664\n",
      "[5990]\ttraining's binary_logloss: 0.134651\n",
      "[5991]\ttraining's binary_logloss: 0.134637\n",
      "[5992]\ttraining's binary_logloss: 0.134626\n",
      "[5993]\ttraining's binary_logloss: 0.134611\n",
      "[5994]\ttraining's binary_logloss: 0.1346\n",
      "[5995]\ttraining's binary_logloss: 0.134585\n",
      "[5996]\ttraining's binary_logloss: 0.134579\n",
      "[5997]\ttraining's binary_logloss: 0.134567\n",
      "[5998]\ttraining's binary_logloss: 0.134555\n",
      "[5999]\ttraining's binary_logloss: 0.13454\n",
      "[6000]\ttraining's binary_logloss: 0.134528\n",
      "[6001]\ttraining's binary_logloss: 0.134515\n",
      "[6002]\ttraining's binary_logloss: 0.134501\n",
      "[6003]\ttraining's binary_logloss: 0.134486\n",
      "[6004]\ttraining's binary_logloss: 0.134471\n",
      "[6005]\ttraining's binary_logloss: 0.134459\n",
      "[6006]\ttraining's binary_logloss: 0.134445\n",
      "[6007]\ttraining's binary_logloss: 0.134432\n",
      "[6008]\ttraining's binary_logloss: 0.134418\n",
      "[6009]\ttraining's binary_logloss: 0.134406\n",
      "[6010]\ttraining's binary_logloss: 0.134392\n",
      "[6011]\ttraining's binary_logloss: 0.134379\n",
      "[6012]\ttraining's binary_logloss: 0.134372\n",
      "[6013]\ttraining's binary_logloss: 0.134365\n",
      "[6014]\ttraining's binary_logloss: 0.134355\n",
      "[6015]\ttraining's binary_logloss: 0.13434\n",
      "[6016]\ttraining's binary_logloss: 0.134327\n",
      "[6017]\ttraining's binary_logloss: 0.134311\n",
      "[6018]\ttraining's binary_logloss: 0.134301\n",
      "[6019]\ttraining's binary_logloss: 0.134299\n",
      "[6020]\ttraining's binary_logloss: 0.134287\n",
      "[6021]\ttraining's binary_logloss: 0.134275\n",
      "[6022]\ttraining's binary_logloss: 0.134261\n",
      "[6023]\ttraining's binary_logloss: 0.134251\n",
      "[6024]\ttraining's binary_logloss: 0.134242\n",
      "[6025]\ttraining's binary_logloss: 0.134229\n",
      "[6026]\ttraining's binary_logloss: 0.134212\n",
      "[6027]\ttraining's binary_logloss: 0.1342\n",
      "[6028]\ttraining's binary_logloss: 0.134187\n",
      "[6029]\ttraining's binary_logloss: 0.134185\n",
      "[6030]\ttraining's binary_logloss: 0.134172\n",
      "[6031]\ttraining's binary_logloss: 0.134158\n",
      "[6032]\ttraining's binary_logloss: 0.134146\n",
      "[6033]\ttraining's binary_logloss: 0.134133\n",
      "[6034]\ttraining's binary_logloss: 0.134118\n",
      "[6035]\ttraining's binary_logloss: 0.134104\n",
      "[6036]\ttraining's binary_logloss: 0.134093\n",
      "[6037]\ttraining's binary_logloss: 0.134081\n",
      "[6038]\ttraining's binary_logloss: 0.134068\n",
      "[6039]\ttraining's binary_logloss: 0.134057\n",
      "[6040]\ttraining's binary_logloss: 0.134044\n",
      "[6041]\ttraining's binary_logloss: 0.134029\n",
      "[6042]\ttraining's binary_logloss: 0.134019\n",
      "[6043]\ttraining's binary_logloss: 0.134007\n",
      "[6044]\ttraining's binary_logloss: 0.133995\n",
      "[6045]\ttraining's binary_logloss: 0.133983\n",
      "[6046]\ttraining's binary_logloss: 0.133969\n",
      "[6047]\ttraining's binary_logloss: 0.133956\n",
      "[6048]\ttraining's binary_logloss: 0.13394\n",
      "[6049]\ttraining's binary_logloss: 0.133938\n",
      "[6050]\ttraining's binary_logloss: 0.133925\n",
      "[6051]\ttraining's binary_logloss: 0.133912\n",
      "[6052]\ttraining's binary_logloss: 0.133898\n",
      "[6053]\ttraining's binary_logloss: 0.133886\n",
      "[6054]\ttraining's binary_logloss: 0.13387\n",
      "[6055]\ttraining's binary_logloss: 0.133859\n",
      "[6056]\ttraining's binary_logloss: 0.133847\n",
      "[6057]\ttraining's binary_logloss: 0.133834\n",
      "[6058]\ttraining's binary_logloss: 0.133818\n",
      "[6059]\ttraining's binary_logloss: 0.133805\n",
      "[6060]\ttraining's binary_logloss: 0.133793\n",
      "[6061]\ttraining's binary_logloss: 0.133782\n",
      "[6062]\ttraining's binary_logloss: 0.133768\n",
      "[6063]\ttraining's binary_logloss: 0.133757\n",
      "[6064]\ttraining's binary_logloss: 0.133744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6065]\ttraining's binary_logloss: 0.133731\n",
      "[6066]\ttraining's binary_logloss: 0.133718\n",
      "[6067]\ttraining's binary_logloss: 0.133705\n",
      "[6068]\ttraining's binary_logloss: 0.133692\n",
      "[6069]\ttraining's binary_logloss: 0.133679\n",
      "[6070]\ttraining's binary_logloss: 0.133667\n",
      "[6071]\ttraining's binary_logloss: 0.133654\n",
      "[6072]\ttraining's binary_logloss: 0.133639\n",
      "[6073]\ttraining's binary_logloss: 0.133627\n",
      "[6074]\ttraining's binary_logloss: 0.133613\n",
      "[6075]\ttraining's binary_logloss: 0.133605\n",
      "[6076]\ttraining's binary_logloss: 0.133596\n",
      "[6077]\ttraining's binary_logloss: 0.133585\n",
      "[6078]\ttraining's binary_logloss: 0.133571\n",
      "[6079]\ttraining's binary_logloss: 0.133557\n",
      "[6080]\ttraining's binary_logloss: 0.133549\n",
      "[6081]\ttraining's binary_logloss: 0.133534\n",
      "[6082]\ttraining's binary_logloss: 0.133523\n",
      "[6083]\ttraining's binary_logloss: 0.13351\n",
      "[6084]\ttraining's binary_logloss: 0.133496\n",
      "[6085]\ttraining's binary_logloss: 0.133484\n",
      "[6086]\ttraining's binary_logloss: 0.13347\n",
      "[6087]\ttraining's binary_logloss: 0.133466\n",
      "[6088]\ttraining's binary_logloss: 0.133453\n",
      "[6089]\ttraining's binary_logloss: 0.13344\n",
      "[6090]\ttraining's binary_logloss: 0.133429\n",
      "[6091]\ttraining's binary_logloss: 0.133418\n",
      "[6092]\ttraining's binary_logloss: 0.133403\n",
      "[6093]\ttraining's binary_logloss: 0.13339\n",
      "[6094]\ttraining's binary_logloss: 0.133387\n",
      "[6095]\ttraining's binary_logloss: 0.133376\n",
      "[6096]\ttraining's binary_logloss: 0.133364\n",
      "[6097]\ttraining's binary_logloss: 0.133355\n",
      "[6098]\ttraining's binary_logloss: 0.133343\n",
      "[6099]\ttraining's binary_logloss: 0.133329\n",
      "[6100]\ttraining's binary_logloss: 0.133317\n",
      "[6101]\ttraining's binary_logloss: 0.133302\n",
      "[6102]\ttraining's binary_logloss: 0.13329\n",
      "[6103]\ttraining's binary_logloss: 0.133277\n",
      "[6104]\ttraining's binary_logloss: 0.133265\n",
      "[6105]\ttraining's binary_logloss: 0.13325\n",
      "[6106]\ttraining's binary_logloss: 0.133235\n",
      "[6107]\ttraining's binary_logloss: 0.133226\n",
      "[6108]\ttraining's binary_logloss: 0.133213\n",
      "[6109]\ttraining's binary_logloss: 0.133198\n",
      "[6110]\ttraining's binary_logloss: 0.133186\n",
      "[6111]\ttraining's binary_logloss: 0.133174\n",
      "[6112]\ttraining's binary_logloss: 0.133161\n",
      "[6113]\ttraining's binary_logloss: 0.133147\n",
      "[6114]\ttraining's binary_logloss: 0.133135\n",
      "[6115]\ttraining's binary_logloss: 0.13312\n",
      "[6116]\ttraining's binary_logloss: 0.133109\n",
      "[6117]\ttraining's binary_logloss: 0.133096\n",
      "[6118]\ttraining's binary_logloss: 0.133081\n",
      "[6119]\ttraining's binary_logloss: 0.133068\n",
      "[6120]\ttraining's binary_logloss: 0.133054\n",
      "[6121]\ttraining's binary_logloss: 0.133039\n",
      "[6122]\ttraining's binary_logloss: 0.133027\n",
      "[6123]\ttraining's binary_logloss: 0.133013\n",
      "[6124]\ttraining's binary_logloss: 0.133\n",
      "[6125]\ttraining's binary_logloss: 0.132987\n",
      "[6126]\ttraining's binary_logloss: 0.13298\n",
      "[6127]\ttraining's binary_logloss: 0.132968\n",
      "[6128]\ttraining's binary_logloss: 0.132954\n",
      "[6129]\ttraining's binary_logloss: 0.13294\n",
      "[6130]\ttraining's binary_logloss: 0.132927\n",
      "[6131]\ttraining's binary_logloss: 0.132914\n",
      "[6132]\ttraining's binary_logloss: 0.13291\n",
      "[6133]\ttraining's binary_logloss: 0.132906\n",
      "[6134]\ttraining's binary_logloss: 0.132892\n",
      "[6135]\ttraining's binary_logloss: 0.132875\n",
      "[6136]\ttraining's binary_logloss: 0.132864\n",
      "[6137]\ttraining's binary_logloss: 0.13285\n",
      "[6138]\ttraining's binary_logloss: 0.132839\n",
      "[6139]\ttraining's binary_logloss: 0.132825\n",
      "[6140]\ttraining's binary_logloss: 0.132812\n",
      "[6141]\ttraining's binary_logloss: 0.132798\n",
      "[6142]\ttraining's binary_logloss: 0.132785\n",
      "[6143]\ttraining's binary_logloss: 0.132773\n",
      "[6144]\ttraining's binary_logloss: 0.132762\n",
      "[6145]\ttraining's binary_logloss: 0.132757\n",
      "[6146]\ttraining's binary_logloss: 0.132755\n",
      "[6147]\ttraining's binary_logloss: 0.132741\n",
      "[6148]\ttraining's binary_logloss: 0.132736\n",
      "[6149]\ttraining's binary_logloss: 0.132733\n",
      "[6150]\ttraining's binary_logloss: 0.132729\n",
      "[6151]\ttraining's binary_logloss: 0.132716\n",
      "[6152]\ttraining's binary_logloss: 0.132705\n",
      "[6153]\ttraining's binary_logloss: 0.132695\n",
      "[6154]\ttraining's binary_logloss: 0.132687\n",
      "[6155]\ttraining's binary_logloss: 0.13268\n",
      "[6156]\ttraining's binary_logloss: 0.132669\n",
      "[6157]\ttraining's binary_logloss: 0.132657\n",
      "[6158]\ttraining's binary_logloss: 0.132646\n",
      "[6159]\ttraining's binary_logloss: 0.132634\n",
      "[6160]\ttraining's binary_logloss: 0.132618\n",
      "[6161]\ttraining's binary_logloss: 0.132606\n",
      "[6162]\ttraining's binary_logloss: 0.132594\n",
      "[6163]\ttraining's binary_logloss: 0.132582\n",
      "[6164]\ttraining's binary_logloss: 0.132569\n",
      "[6165]\ttraining's binary_logloss: 0.132558\n",
      "[6166]\ttraining's binary_logloss: 0.132544\n",
      "[6167]\ttraining's binary_logloss: 0.132532\n",
      "[6168]\ttraining's binary_logloss: 0.132521\n",
      "[6169]\ttraining's binary_logloss: 0.132506\n",
      "[6170]\ttraining's binary_logloss: 0.132492\n",
      "[6171]\ttraining's binary_logloss: 0.132491\n",
      "[6172]\ttraining's binary_logloss: 0.132486\n",
      "[6173]\ttraining's binary_logloss: 0.132474\n",
      "[6174]\ttraining's binary_logloss: 0.132464\n",
      "[6175]\ttraining's binary_logloss: 0.132451\n",
      "[6176]\ttraining's binary_logloss: 0.132449\n",
      "[6177]\ttraining's binary_logloss: 0.132443\n",
      "[6178]\ttraining's binary_logloss: 0.132433\n",
      "[6179]\ttraining's binary_logloss: 0.13242\n",
      "[6180]\ttraining's binary_logloss: 0.132408\n",
      "[6181]\ttraining's binary_logloss: 0.132407\n",
      "[6182]\ttraining's binary_logloss: 0.132395\n",
      "[6183]\ttraining's binary_logloss: 0.132383\n",
      "[6184]\ttraining's binary_logloss: 0.13237\n",
      "[6185]\ttraining's binary_logloss: 0.132355\n",
      "[6186]\ttraining's binary_logloss: 0.13234\n",
      "[6187]\ttraining's binary_logloss: 0.132328\n",
      "[6188]\ttraining's binary_logloss: 0.132313\n",
      "[6189]\ttraining's binary_logloss: 0.132302\n",
      "[6190]\ttraining's binary_logloss: 0.13229\n",
      "[6191]\ttraining's binary_logloss: 0.132285\n",
      "[6192]\ttraining's binary_logloss: 0.132273\n",
      "[6193]\ttraining's binary_logloss: 0.132261\n",
      "[6194]\ttraining's binary_logloss: 0.132248\n",
      "[6195]\ttraining's binary_logloss: 0.132238\n",
      "[6196]\ttraining's binary_logloss: 0.132225\n",
      "[6197]\ttraining's binary_logloss: 0.132211\n",
      "[6198]\ttraining's binary_logloss: 0.132199\n",
      "[6199]\ttraining's binary_logloss: 0.132187\n",
      "[6200]\ttraining's binary_logloss: 0.132184\n",
      "[6201]\ttraining's binary_logloss: 0.132173\n",
      "[6202]\ttraining's binary_logloss: 0.13216\n",
      "[6203]\ttraining's binary_logloss: 0.132152\n",
      "[6204]\ttraining's binary_logloss: 0.132138\n",
      "[6205]\ttraining's binary_logloss: 0.132123\n",
      "[6206]\ttraining's binary_logloss: 0.132118\n",
      "[6207]\ttraining's binary_logloss: 0.13211\n",
      "[6208]\ttraining's binary_logloss: 0.132102\n",
      "[6209]\ttraining's binary_logloss: 0.13209\n",
      "[6210]\ttraining's binary_logloss: 0.132077\n",
      "[6211]\ttraining's binary_logloss: 0.132063\n",
      "[6212]\ttraining's binary_logloss: 0.132051\n",
      "[6213]\ttraining's binary_logloss: 0.132038\n",
      "[6214]\ttraining's binary_logloss: 0.132036\n",
      "[6215]\ttraining's binary_logloss: 0.132025\n",
      "[6216]\ttraining's binary_logloss: 0.13202\n",
      "[6217]\ttraining's binary_logloss: 0.132007\n",
      "[6218]\ttraining's binary_logloss: 0.132003\n",
      "[6219]\ttraining's binary_logloss: 0.131992\n",
      "[6220]\ttraining's binary_logloss: 0.131978\n",
      "[6221]\ttraining's binary_logloss: 0.131968\n",
      "[6222]\ttraining's binary_logloss: 0.131956\n",
      "[6223]\ttraining's binary_logloss: 0.131942\n",
      "[6224]\ttraining's binary_logloss: 0.131927\n",
      "[6225]\ttraining's binary_logloss: 0.131917\n",
      "[6226]\ttraining's binary_logloss: 0.131904\n",
      "[6227]\ttraining's binary_logloss: 0.131891\n",
      "[6228]\ttraining's binary_logloss: 0.131877\n",
      "[6229]\ttraining's binary_logloss: 0.131863\n",
      "[6230]\ttraining's binary_logloss: 0.13185\n",
      "[6231]\ttraining's binary_logloss: 0.13184\n",
      "[6232]\ttraining's binary_logloss: 0.131831\n",
      "[6233]\ttraining's binary_logloss: 0.131823\n",
      "[6234]\ttraining's binary_logloss: 0.131811\n",
      "[6235]\ttraining's binary_logloss: 0.1318\n",
      "[6236]\ttraining's binary_logloss: 0.131788\n",
      "[6237]\ttraining's binary_logloss: 0.131774\n",
      "[6238]\ttraining's binary_logloss: 0.131763\n",
      "[6239]\ttraining's binary_logloss: 0.131749\n",
      "[6240]\ttraining's binary_logloss: 0.131739\n",
      "[6241]\ttraining's binary_logloss: 0.131724\n",
      "[6242]\ttraining's binary_logloss: 0.131715\n",
      "[6243]\ttraining's binary_logloss: 0.1317\n",
      "[6244]\ttraining's binary_logloss: 0.131692\n",
      "[6245]\ttraining's binary_logloss: 0.131678\n",
      "[6246]\ttraining's binary_logloss: 0.131665\n",
      "[6247]\ttraining's binary_logloss: 0.131653\n",
      "[6248]\ttraining's binary_logloss: 0.131641\n",
      "[6249]\ttraining's binary_logloss: 0.131627\n",
      "[6250]\ttraining's binary_logloss: 0.131613\n",
      "[6251]\ttraining's binary_logloss: 0.131598\n",
      "[6252]\ttraining's binary_logloss: 0.13159\n",
      "[6253]\ttraining's binary_logloss: 0.131579\n",
      "[6254]\ttraining's binary_logloss: 0.131567\n",
      "[6255]\ttraining's binary_logloss: 0.131554\n",
      "[6256]\ttraining's binary_logloss: 0.131543\n",
      "[6257]\ttraining's binary_logloss: 0.13153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6258]\ttraining's binary_logloss: 0.131518\n",
      "[6259]\ttraining's binary_logloss: 0.131503\n",
      "[6260]\ttraining's binary_logloss: 0.131492\n",
      "[6261]\ttraining's binary_logloss: 0.13148\n",
      "[6262]\ttraining's binary_logloss: 0.131468\n",
      "[6263]\ttraining's binary_logloss: 0.131461\n",
      "[6264]\ttraining's binary_logloss: 0.131459\n",
      "[6265]\ttraining's binary_logloss: 0.131445\n",
      "[6266]\ttraining's binary_logloss: 0.13143\n",
      "[6267]\ttraining's binary_logloss: 0.131418\n",
      "[6268]\ttraining's binary_logloss: 0.131407\n",
      "[6269]\ttraining's binary_logloss: 0.131394\n",
      "[6270]\ttraining's binary_logloss: 0.131382\n",
      "[6271]\ttraining's binary_logloss: 0.13137\n",
      "[6272]\ttraining's binary_logloss: 0.131359\n",
      "[6273]\ttraining's binary_logloss: 0.131347\n",
      "[6274]\ttraining's binary_logloss: 0.131336\n",
      "[6275]\ttraining's binary_logloss: 0.131327\n",
      "[6276]\ttraining's binary_logloss: 0.131323\n",
      "[6277]\ttraining's binary_logloss: 0.131311\n",
      "[6278]\ttraining's binary_logloss: 0.131304\n",
      "[6279]\ttraining's binary_logloss: 0.131293\n",
      "[6280]\ttraining's binary_logloss: 0.13128\n",
      "[6281]\ttraining's binary_logloss: 0.131269\n",
      "[6282]\ttraining's binary_logloss: 0.131265\n",
      "[6283]\ttraining's binary_logloss: 0.131254\n",
      "[6284]\ttraining's binary_logloss: 0.131253\n",
      "[6285]\ttraining's binary_logloss: 0.13125\n",
      "[6286]\ttraining's binary_logloss: 0.131238\n",
      "[6287]\ttraining's binary_logloss: 0.131236\n",
      "[6288]\ttraining's binary_logloss: 0.131223\n",
      "[6289]\ttraining's binary_logloss: 0.131211\n",
      "[6290]\ttraining's binary_logloss: 0.131198\n",
      "[6291]\ttraining's binary_logloss: 0.131191\n",
      "[6292]\ttraining's binary_logloss: 0.131178\n",
      "[6293]\ttraining's binary_logloss: 0.131166\n",
      "[6294]\ttraining's binary_logloss: 0.131162\n",
      "[6295]\ttraining's binary_logloss: 0.131157\n",
      "[6296]\ttraining's binary_logloss: 0.131143\n",
      "[6297]\ttraining's binary_logloss: 0.13113\n",
      "[6298]\ttraining's binary_logloss: 0.131117\n",
      "[6299]\ttraining's binary_logloss: 0.131102\n",
      "[6300]\ttraining's binary_logloss: 0.131093\n",
      "[6301]\ttraining's binary_logloss: 0.131082\n",
      "[6302]\ttraining's binary_logloss: 0.131072\n",
      "[6303]\ttraining's binary_logloss: 0.131058\n",
      "[6304]\ttraining's binary_logloss: 0.131046\n",
      "[6305]\ttraining's binary_logloss: 0.131034\n",
      "[6306]\ttraining's binary_logloss: 0.13102\n",
      "[6307]\ttraining's binary_logloss: 0.131009\n",
      "[6308]\ttraining's binary_logloss: 0.130996\n",
      "[6309]\ttraining's binary_logloss: 0.130983\n",
      "[6310]\ttraining's binary_logloss: 0.130971\n",
      "[6311]\ttraining's binary_logloss: 0.130961\n",
      "[6312]\ttraining's binary_logloss: 0.130952\n",
      "[6313]\ttraining's binary_logloss: 0.13094\n",
      "[6314]\ttraining's binary_logloss: 0.130928\n",
      "[6315]\ttraining's binary_logloss: 0.130918\n",
      "[6316]\ttraining's binary_logloss: 0.130907\n",
      "[6317]\ttraining's binary_logloss: 0.1309\n",
      "[6318]\ttraining's binary_logloss: 0.130887\n",
      "[6319]\ttraining's binary_logloss: 0.130873\n",
      "[6320]\ttraining's binary_logloss: 0.130861\n",
      "[6321]\ttraining's binary_logloss: 0.130854\n",
      "[6322]\ttraining's binary_logloss: 0.130842\n",
      "[6323]\ttraining's binary_logloss: 0.130829\n",
      "[6324]\ttraining's binary_logloss: 0.130818\n",
      "[6325]\ttraining's binary_logloss: 0.130806\n",
      "[6326]\ttraining's binary_logloss: 0.130795\n",
      "[6327]\ttraining's binary_logloss: 0.130786\n",
      "[6328]\ttraining's binary_logloss: 0.130771\n",
      "[6329]\ttraining's binary_logloss: 0.130762\n",
      "[6330]\ttraining's binary_logloss: 0.130749\n",
      "[6331]\ttraining's binary_logloss: 0.13074\n",
      "[6332]\ttraining's binary_logloss: 0.130729\n",
      "[6333]\ttraining's binary_logloss: 0.130717\n",
      "[6334]\ttraining's binary_logloss: 0.13071\n",
      "[6335]\ttraining's binary_logloss: 0.130698\n",
      "[6336]\ttraining's binary_logloss: 0.130686\n",
      "[6337]\ttraining's binary_logloss: 0.130674\n",
      "[6338]\ttraining's binary_logloss: 0.13066\n",
      "[6339]\ttraining's binary_logloss: 0.13065\n",
      "[6340]\ttraining's binary_logloss: 0.130638\n",
      "[6341]\ttraining's binary_logloss: 0.130627\n",
      "[6342]\ttraining's binary_logloss: 0.130614\n",
      "[6343]\ttraining's binary_logloss: 0.130604\n",
      "[6344]\ttraining's binary_logloss: 0.130592\n",
      "[6345]\ttraining's binary_logloss: 0.130578\n",
      "[6346]\ttraining's binary_logloss: 0.130565\n",
      "[6347]\ttraining's binary_logloss: 0.130553\n",
      "[6348]\ttraining's binary_logloss: 0.130538\n",
      "[6349]\ttraining's binary_logloss: 0.130524\n",
      "[6350]\ttraining's binary_logloss: 0.130515\n",
      "[6351]\ttraining's binary_logloss: 0.130502\n",
      "[6352]\ttraining's binary_logloss: 0.130489\n",
      "[6353]\ttraining's binary_logloss: 0.130483\n",
      "[6354]\ttraining's binary_logloss: 0.130472\n",
      "[6355]\ttraining's binary_logloss: 0.13046\n",
      "[6356]\ttraining's binary_logloss: 0.130457\n",
      "[6357]\ttraining's binary_logloss: 0.130452\n",
      "[6358]\ttraining's binary_logloss: 0.130448\n",
      "[6359]\ttraining's binary_logloss: 0.130447\n",
      "[6360]\ttraining's binary_logloss: 0.130435\n",
      "[6361]\ttraining's binary_logloss: 0.130423\n",
      "[6362]\ttraining's binary_logloss: 0.130408\n",
      "[6363]\ttraining's binary_logloss: 0.130401\n",
      "[6364]\ttraining's binary_logloss: 0.130389\n",
      "[6365]\ttraining's binary_logloss: 0.130378\n",
      "[6366]\ttraining's binary_logloss: 0.13037\n",
      "[6367]\ttraining's binary_logloss: 0.130357\n",
      "[6368]\ttraining's binary_logloss: 0.130343\n",
      "[6369]\ttraining's binary_logloss: 0.130332\n",
      "[6370]\ttraining's binary_logloss: 0.130321\n",
      "[6371]\ttraining's binary_logloss: 0.130308\n",
      "[6372]\ttraining's binary_logloss: 0.130297\n",
      "[6373]\ttraining's binary_logloss: 0.130285\n",
      "[6374]\ttraining's binary_logloss: 0.13027\n",
      "[6375]\ttraining's binary_logloss: 0.130267\n",
      "[6376]\ttraining's binary_logloss: 0.130255\n",
      "[6377]\ttraining's binary_logloss: 0.130243\n",
      "[6378]\ttraining's binary_logloss: 0.130232\n",
      "[6379]\ttraining's binary_logloss: 0.130219\n",
      "[6380]\ttraining's binary_logloss: 0.130206\n",
      "[6381]\ttraining's binary_logloss: 0.130204\n",
      "[6382]\ttraining's binary_logloss: 0.130193\n",
      "[6383]\ttraining's binary_logloss: 0.130181\n",
      "[6384]\ttraining's binary_logloss: 0.130175\n",
      "[6385]\ttraining's binary_logloss: 0.130163\n",
      "[6386]\ttraining's binary_logloss: 0.130151\n",
      "[6387]\ttraining's binary_logloss: 0.13014\n",
      "[6388]\ttraining's binary_logloss: 0.130127\n",
      "[6389]\ttraining's binary_logloss: 0.130115\n",
      "[6390]\ttraining's binary_logloss: 0.130104\n",
      "[6391]\ttraining's binary_logloss: 0.130092\n",
      "[6392]\ttraining's binary_logloss: 0.13008\n",
      "[6393]\ttraining's binary_logloss: 0.130069\n",
      "[6394]\ttraining's binary_logloss: 0.130067\n",
      "[6395]\ttraining's binary_logloss: 0.130055\n",
      "[6396]\ttraining's binary_logloss: 0.130042\n",
      "[6397]\ttraining's binary_logloss: 0.130026\n",
      "[6398]\ttraining's binary_logloss: 0.130015\n",
      "[6399]\ttraining's binary_logloss: 0.130004\n",
      "[6400]\ttraining's binary_logloss: 0.129991\n",
      "[6401]\ttraining's binary_logloss: 0.129979\n",
      "[6402]\ttraining's binary_logloss: 0.129967\n",
      "[6403]\ttraining's binary_logloss: 0.129962\n",
      "[6404]\ttraining's binary_logloss: 0.12995\n",
      "[6405]\ttraining's binary_logloss: 0.129936\n",
      "[6406]\ttraining's binary_logloss: 0.129925\n",
      "[6407]\ttraining's binary_logloss: 0.129914\n",
      "[6408]\ttraining's binary_logloss: 0.129908\n",
      "[6409]\ttraining's binary_logloss: 0.129894\n",
      "[6410]\ttraining's binary_logloss: 0.129883\n",
      "[6411]\ttraining's binary_logloss: 0.129872\n",
      "[6412]\ttraining's binary_logloss: 0.129859\n",
      "[6413]\ttraining's binary_logloss: 0.129847\n",
      "[6414]\ttraining's binary_logloss: 0.12984\n",
      "[6415]\ttraining's binary_logloss: 0.12983\n",
      "[6416]\ttraining's binary_logloss: 0.129816\n",
      "[6417]\ttraining's binary_logloss: 0.129805\n",
      "[6418]\ttraining's binary_logloss: 0.129795\n",
      "[6419]\ttraining's binary_logloss: 0.12979\n",
      "[6420]\ttraining's binary_logloss: 0.129777\n",
      "[6421]\ttraining's binary_logloss: 0.129767\n",
      "[6422]\ttraining's binary_logloss: 0.129757\n",
      "[6423]\ttraining's binary_logloss: 0.129744\n",
      "[6424]\ttraining's binary_logloss: 0.129731\n",
      "[6425]\ttraining's binary_logloss: 0.129727\n",
      "[6426]\ttraining's binary_logloss: 0.129714\n",
      "[6427]\ttraining's binary_logloss: 0.129702\n",
      "[6428]\ttraining's binary_logloss: 0.129698\n",
      "[6429]\ttraining's binary_logloss: 0.129696\n",
      "[6430]\ttraining's binary_logloss: 0.129683\n",
      "[6431]\ttraining's binary_logloss: 0.129675\n",
      "[6432]\ttraining's binary_logloss: 0.129662\n",
      "[6433]\ttraining's binary_logloss: 0.129649\n",
      "[6434]\ttraining's binary_logloss: 0.129646\n",
      "[6435]\ttraining's binary_logloss: 0.129633\n",
      "[6436]\ttraining's binary_logloss: 0.129619\n",
      "[6437]\ttraining's binary_logloss: 0.129606\n",
      "[6438]\ttraining's binary_logloss: 0.129593\n",
      "[6439]\ttraining's binary_logloss: 0.129581\n",
      "[6440]\ttraining's binary_logloss: 0.12957\n",
      "[6441]\ttraining's binary_logloss: 0.129559\n",
      "[6442]\ttraining's binary_logloss: 0.129546\n",
      "[6443]\ttraining's binary_logloss: 0.129533\n",
      "[6444]\ttraining's binary_logloss: 0.129522\n",
      "[6445]\ttraining's binary_logloss: 0.129511\n",
      "[6446]\ttraining's binary_logloss: 0.129506\n",
      "[6447]\ttraining's binary_logloss: 0.129494\n",
      "[6448]\ttraining's binary_logloss: 0.129488\n",
      "[6449]\ttraining's binary_logloss: 0.129474\n",
      "[6450]\ttraining's binary_logloss: 0.12946\n",
      "[6451]\ttraining's binary_logloss: 0.129455\n",
      "[6452]\ttraining's binary_logloss: 0.129443\n",
      "[6453]\ttraining's binary_logloss: 0.129438\n",
      "[6454]\ttraining's binary_logloss: 0.129428\n",
      "[6455]\ttraining's binary_logloss: 0.129418\n",
      "[6456]\ttraining's binary_logloss: 0.129406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6457]\ttraining's binary_logloss: 0.129394\n",
      "[6458]\ttraining's binary_logloss: 0.129392\n",
      "[6459]\ttraining's binary_logloss: 0.12938\n",
      "[6460]\ttraining's binary_logloss: 0.129373\n",
      "[6461]\ttraining's binary_logloss: 0.129371\n",
      "[6462]\ttraining's binary_logloss: 0.129361\n",
      "[6463]\ttraining's binary_logloss: 0.129348\n",
      "[6464]\ttraining's binary_logloss: 0.129336\n",
      "[6465]\ttraining's binary_logloss: 0.129325\n",
      "[6466]\ttraining's binary_logloss: 0.129323\n",
      "[6467]\ttraining's binary_logloss: 0.12931\n",
      "[6468]\ttraining's binary_logloss: 0.129298\n",
      "[6469]\ttraining's binary_logloss: 0.129285\n",
      "[6470]\ttraining's binary_logloss: 0.129273\n",
      "[6471]\ttraining's binary_logloss: 0.129266\n",
      "[6472]\ttraining's binary_logloss: 0.129256\n",
      "[6473]\ttraining's binary_logloss: 0.129242\n",
      "[6474]\ttraining's binary_logloss: 0.12923\n",
      "[6475]\ttraining's binary_logloss: 0.129216\n",
      "[6476]\ttraining's binary_logloss: 0.129213\n",
      "[6477]\ttraining's binary_logloss: 0.1292\n",
      "[6478]\ttraining's binary_logloss: 0.129188\n",
      "[6479]\ttraining's binary_logloss: 0.129176\n",
      "[6480]\ttraining's binary_logloss: 0.129171\n",
      "[6481]\ttraining's binary_logloss: 0.129159\n",
      "[6482]\ttraining's binary_logloss: 0.129146\n",
      "[6483]\ttraining's binary_logloss: 0.129133\n",
      "[6484]\ttraining's binary_logloss: 0.129127\n",
      "[6485]\ttraining's binary_logloss: 0.129116\n",
      "[6486]\ttraining's binary_logloss: 0.129106\n",
      "[6487]\ttraining's binary_logloss: 0.129095\n",
      "[6488]\ttraining's binary_logloss: 0.129084\n",
      "[6489]\ttraining's binary_logloss: 0.129075\n",
      "[6490]\ttraining's binary_logloss: 0.129062\n",
      "[6491]\ttraining's binary_logloss: 0.129048\n",
      "[6492]\ttraining's binary_logloss: 0.129037\n",
      "[6493]\ttraining's binary_logloss: 0.129027\n",
      "[6494]\ttraining's binary_logloss: 0.12902\n",
      "[6495]\ttraining's binary_logloss: 0.129007\n",
      "[6496]\ttraining's binary_logloss: 0.128997\n",
      "[6497]\ttraining's binary_logloss: 0.128986\n",
      "[6498]\ttraining's binary_logloss: 0.128973\n",
      "[6499]\ttraining's binary_logloss: 0.128961\n",
      "[6500]\ttraining's binary_logloss: 0.128951\n",
      "[6501]\ttraining's binary_logloss: 0.128939\n",
      "[6502]\ttraining's binary_logloss: 0.128929\n",
      "[6503]\ttraining's binary_logloss: 0.128916\n",
      "[6504]\ttraining's binary_logloss: 0.128904\n",
      "[6505]\ttraining's binary_logloss: 0.12889\n",
      "[6506]\ttraining's binary_logloss: 0.128879\n",
      "[6507]\ttraining's binary_logloss: 0.128876\n",
      "[6508]\ttraining's binary_logloss: 0.128862\n",
      "[6509]\ttraining's binary_logloss: 0.12885\n",
      "[6510]\ttraining's binary_logloss: 0.128837\n",
      "[6511]\ttraining's binary_logloss: 0.128825\n",
      "[6512]\ttraining's binary_logloss: 0.128812\n",
      "[6513]\ttraining's binary_logloss: 0.128806\n",
      "[6514]\ttraining's binary_logloss: 0.128795\n",
      "[6515]\ttraining's binary_logloss: 0.128782\n",
      "[6516]\ttraining's binary_logloss: 0.128767\n",
      "[6517]\ttraining's binary_logloss: 0.128756\n",
      "[6518]\ttraining's binary_logloss: 0.128745\n",
      "[6519]\ttraining's binary_logloss: 0.128736\n",
      "[6520]\ttraining's binary_logloss: 0.128723\n",
      "[6521]\ttraining's binary_logloss: 0.128712\n",
      "[6522]\ttraining's binary_logloss: 0.128701\n",
      "[6523]\ttraining's binary_logloss: 0.128688\n",
      "[6524]\ttraining's binary_logloss: 0.128675\n",
      "[6525]\ttraining's binary_logloss: 0.128665\n",
      "[6526]\ttraining's binary_logloss: 0.128653\n",
      "[6527]\ttraining's binary_logloss: 0.128639\n",
      "[6528]\ttraining's binary_logloss: 0.128629\n",
      "[6529]\ttraining's binary_logloss: 0.128617\n",
      "[6530]\ttraining's binary_logloss: 0.128604\n",
      "[6531]\ttraining's binary_logloss: 0.128593\n",
      "[6532]\ttraining's binary_logloss: 0.12859\n",
      "[6533]\ttraining's binary_logloss: 0.128577\n",
      "[6534]\ttraining's binary_logloss: 0.128572\n",
      "[6535]\ttraining's binary_logloss: 0.12856\n",
      "[6536]\ttraining's binary_logloss: 0.128548\n",
      "[6537]\ttraining's binary_logloss: 0.128537\n",
      "[6538]\ttraining's binary_logloss: 0.128524\n",
      "[6539]\ttraining's binary_logloss: 0.128513\n",
      "[6540]\ttraining's binary_logloss: 0.128502\n",
      "[6541]\ttraining's binary_logloss: 0.12849\n",
      "[6542]\ttraining's binary_logloss: 0.128479\n",
      "[6543]\ttraining's binary_logloss: 0.128476\n",
      "[6544]\ttraining's binary_logloss: 0.128468\n",
      "[6545]\ttraining's binary_logloss: 0.128458\n",
      "[6546]\ttraining's binary_logloss: 0.128447\n",
      "[6547]\ttraining's binary_logloss: 0.128445\n",
      "[6548]\ttraining's binary_logloss: 0.128432\n",
      "[6549]\ttraining's binary_logloss: 0.128423\n",
      "[6550]\ttraining's binary_logloss: 0.12841\n",
      "[6551]\ttraining's binary_logloss: 0.128398\n",
      "[6552]\ttraining's binary_logloss: 0.128386\n",
      "[6553]\ttraining's binary_logloss: 0.128373\n",
      "[6554]\ttraining's binary_logloss: 0.12836\n",
      "[6555]\ttraining's binary_logloss: 0.128348\n",
      "[6556]\ttraining's binary_logloss: 0.128338\n",
      "[6557]\ttraining's binary_logloss: 0.128325\n",
      "[6558]\ttraining's binary_logloss: 0.128322\n",
      "[6559]\ttraining's binary_logloss: 0.128314\n",
      "[6560]\ttraining's binary_logloss: 0.128303\n",
      "[6561]\ttraining's binary_logloss: 0.128292\n",
      "[6562]\ttraining's binary_logloss: 0.128285\n",
      "[6563]\ttraining's binary_logloss: 0.128284\n",
      "[6564]\ttraining's binary_logloss: 0.128272\n",
      "[6565]\ttraining's binary_logloss: 0.128259\n",
      "[6566]\ttraining's binary_logloss: 0.128252\n",
      "[6567]\ttraining's binary_logloss: 0.128238\n",
      "[6568]\ttraining's binary_logloss: 0.128225\n",
      "[6569]\ttraining's binary_logloss: 0.128213\n",
      "[6570]\ttraining's binary_logloss: 0.128201\n",
      "[6571]\ttraining's binary_logloss: 0.128188\n",
      "[6572]\ttraining's binary_logloss: 0.128176\n",
      "[6573]\ttraining's binary_logloss: 0.128168\n",
      "[6574]\ttraining's binary_logloss: 0.128155\n",
      "[6575]\ttraining's binary_logloss: 0.128142\n",
      "[6576]\ttraining's binary_logloss: 0.128131\n",
      "[6577]\ttraining's binary_logloss: 0.128116\n",
      "[6578]\ttraining's binary_logloss: 0.128103\n",
      "[6579]\ttraining's binary_logloss: 0.128091\n",
      "[6580]\ttraining's binary_logloss: 0.12808\n",
      "[6581]\ttraining's binary_logloss: 0.128077\n",
      "[6582]\ttraining's binary_logloss: 0.128065\n",
      "[6583]\ttraining's binary_logloss: 0.128054\n",
      "[6584]\ttraining's binary_logloss: 0.128044\n",
      "[6585]\ttraining's binary_logloss: 0.128031\n",
      "[6586]\ttraining's binary_logloss: 0.128021\n",
      "[6587]\ttraining's binary_logloss: 0.12801\n",
      "[6588]\ttraining's binary_logloss: 0.128008\n",
      "[6589]\ttraining's binary_logloss: 0.127997\n",
      "[6590]\ttraining's binary_logloss: 0.127984\n",
      "[6591]\ttraining's binary_logloss: 0.127977\n",
      "[6592]\ttraining's binary_logloss: 0.127966\n",
      "[6593]\ttraining's binary_logloss: 0.127954\n",
      "[6594]\ttraining's binary_logloss: 0.127943\n",
      "[6595]\ttraining's binary_logloss: 0.12793\n",
      "[6596]\ttraining's binary_logloss: 0.127921\n",
      "[6597]\ttraining's binary_logloss: 0.127909\n",
      "[6598]\ttraining's binary_logloss: 0.127902\n",
      "[6599]\ttraining's binary_logloss: 0.127892\n",
      "[6600]\ttraining's binary_logloss: 0.127885\n",
      "[6601]\ttraining's binary_logloss: 0.127872\n",
      "[6602]\ttraining's binary_logloss: 0.127861\n",
      "[6603]\ttraining's binary_logloss: 0.127849\n",
      "[6604]\ttraining's binary_logloss: 0.127835\n",
      "[6605]\ttraining's binary_logloss: 0.127823\n",
      "[6606]\ttraining's binary_logloss: 0.127814\n",
      "[6607]\ttraining's binary_logloss: 0.127803\n",
      "[6608]\ttraining's binary_logloss: 0.127792\n",
      "[6609]\ttraining's binary_logloss: 0.127779\n",
      "[6610]\ttraining's binary_logloss: 0.127772\n",
      "[6611]\ttraining's binary_logloss: 0.12776\n",
      "[6612]\ttraining's binary_logloss: 0.127755\n",
      "[6613]\ttraining's binary_logloss: 0.127742\n",
      "[6614]\ttraining's binary_logloss: 0.127728\n",
      "[6615]\ttraining's binary_logloss: 0.127716\n",
      "[6616]\ttraining's binary_logloss: 0.127707\n",
      "[6617]\ttraining's binary_logloss: 0.127698\n",
      "[6618]\ttraining's binary_logloss: 0.12769\n",
      "[6619]\ttraining's binary_logloss: 0.127677\n",
      "[6620]\ttraining's binary_logloss: 0.127673\n",
      "[6621]\ttraining's binary_logloss: 0.127663\n",
      "[6622]\ttraining's binary_logloss: 0.127652\n",
      "[6623]\ttraining's binary_logloss: 0.127639\n",
      "[6624]\ttraining's binary_logloss: 0.127628\n",
      "[6625]\ttraining's binary_logloss: 0.127614\n",
      "[6626]\ttraining's binary_logloss: 0.127601\n",
      "[6627]\ttraining's binary_logloss: 0.127589\n",
      "[6628]\ttraining's binary_logloss: 0.127577\n",
      "[6629]\ttraining's binary_logloss: 0.127567\n",
      "[6630]\ttraining's binary_logloss: 0.127556\n",
      "[6631]\ttraining's binary_logloss: 0.127549\n",
      "[6632]\ttraining's binary_logloss: 0.127537\n",
      "[6633]\ttraining's binary_logloss: 0.127529\n",
      "[6634]\ttraining's binary_logloss: 0.127517\n",
      "[6635]\ttraining's binary_logloss: 0.127503\n",
      "[6636]\ttraining's binary_logloss: 0.12749\n",
      "[6637]\ttraining's binary_logloss: 0.127483\n",
      "[6638]\ttraining's binary_logloss: 0.12747\n",
      "[6639]\ttraining's binary_logloss: 0.127458\n",
      "[6640]\ttraining's binary_logloss: 0.127446\n",
      "[6641]\ttraining's binary_logloss: 0.127433\n",
      "[6642]\ttraining's binary_logloss: 0.127424\n",
      "[6643]\ttraining's binary_logloss: 0.127411\n",
      "[6644]\ttraining's binary_logloss: 0.127399\n",
      "[6645]\ttraining's binary_logloss: 0.127397\n",
      "[6646]\ttraining's binary_logloss: 0.127388\n",
      "[6647]\ttraining's binary_logloss: 0.127375\n",
      "[6648]\ttraining's binary_logloss: 0.127365\n",
      "[6649]\ttraining's binary_logloss: 0.127353\n",
      "[6650]\ttraining's binary_logloss: 0.127339\n",
      "[6651]\ttraining's binary_logloss: 0.127327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6652]\ttraining's binary_logloss: 0.127316\n",
      "[6653]\ttraining's binary_logloss: 0.127303\n",
      "[6654]\ttraining's binary_logloss: 0.127293\n",
      "[6655]\ttraining's binary_logloss: 0.127281\n",
      "[6656]\ttraining's binary_logloss: 0.127266\n",
      "[6657]\ttraining's binary_logloss: 0.127256\n",
      "[6658]\ttraining's binary_logloss: 0.127244\n",
      "[6659]\ttraining's binary_logloss: 0.127234\n",
      "[6660]\ttraining's binary_logloss: 0.127222\n",
      "[6661]\ttraining's binary_logloss: 0.127209\n",
      "[6662]\ttraining's binary_logloss: 0.127197\n",
      "[6663]\ttraining's binary_logloss: 0.127183\n",
      "[6664]\ttraining's binary_logloss: 0.127172\n",
      "[6665]\ttraining's binary_logloss: 0.127165\n",
      "[6666]\ttraining's binary_logloss: 0.127152\n",
      "[6667]\ttraining's binary_logloss: 0.12714\n",
      "[6668]\ttraining's binary_logloss: 0.127129\n",
      "[6669]\ttraining's binary_logloss: 0.127117\n",
      "[6670]\ttraining's binary_logloss: 0.127106\n",
      "[6671]\ttraining's binary_logloss: 0.127094\n",
      "[6672]\ttraining's binary_logloss: 0.127083\n",
      "[6673]\ttraining's binary_logloss: 0.12707\n",
      "[6674]\ttraining's binary_logloss: 0.127058\n",
      "[6675]\ttraining's binary_logloss: 0.127046\n",
      "[6676]\ttraining's binary_logloss: 0.127035\n",
      "[6677]\ttraining's binary_logloss: 0.127024\n",
      "[6678]\ttraining's binary_logloss: 0.12701\n",
      "[6679]\ttraining's binary_logloss: 0.126996\n",
      "[6680]\ttraining's binary_logloss: 0.126985\n",
      "[6681]\ttraining's binary_logloss: 0.126974\n",
      "[6682]\ttraining's binary_logloss: 0.126962\n",
      "[6683]\ttraining's binary_logloss: 0.126958\n",
      "[6684]\ttraining's binary_logloss: 0.126951\n",
      "[6685]\ttraining's binary_logloss: 0.126939\n",
      "[6686]\ttraining's binary_logloss: 0.126931\n",
      "[6687]\ttraining's binary_logloss: 0.126925\n",
      "[6688]\ttraining's binary_logloss: 0.126914\n",
      "[6689]\ttraining's binary_logloss: 0.126905\n",
      "[6690]\ttraining's binary_logloss: 0.126895\n",
      "[6691]\ttraining's binary_logloss: 0.126886\n",
      "[6692]\ttraining's binary_logloss: 0.126874\n",
      "[6693]\ttraining's binary_logloss: 0.12687\n",
      "[6694]\ttraining's binary_logloss: 0.126859\n",
      "[6695]\ttraining's binary_logloss: 0.126852\n",
      "[6696]\ttraining's binary_logloss: 0.126841\n",
      "[6697]\ttraining's binary_logloss: 0.12684\n",
      "[6698]\ttraining's binary_logloss: 0.126828\n",
      "[6699]\ttraining's binary_logloss: 0.126814\n",
      "[6700]\ttraining's binary_logloss: 0.1268\n",
      "[6701]\ttraining's binary_logloss: 0.126793\n",
      "[6702]\ttraining's binary_logloss: 0.126784\n",
      "[6703]\ttraining's binary_logloss: 0.126771\n",
      "[6704]\ttraining's binary_logloss: 0.126759\n",
      "[6705]\ttraining's binary_logloss: 0.126747\n",
      "[6706]\ttraining's binary_logloss: 0.126736\n",
      "[6707]\ttraining's binary_logloss: 0.126727\n",
      "[6708]\ttraining's binary_logloss: 0.126715\n",
      "[6709]\ttraining's binary_logloss: 0.126702\n",
      "[6710]\ttraining's binary_logloss: 0.126698\n",
      "[6711]\ttraining's binary_logloss: 0.126687\n",
      "[6712]\ttraining's binary_logloss: 0.126675\n",
      "[6713]\ttraining's binary_logloss: 0.126664\n",
      "[6714]\ttraining's binary_logloss: 0.126651\n",
      "[6715]\ttraining's binary_logloss: 0.126639\n",
      "[6716]\ttraining's binary_logloss: 0.126627\n",
      "[6717]\ttraining's binary_logloss: 0.126619\n",
      "[6718]\ttraining's binary_logloss: 0.126608\n",
      "[6719]\ttraining's binary_logloss: 0.126595\n",
      "[6720]\ttraining's binary_logloss: 0.12659\n",
      "[6721]\ttraining's binary_logloss: 0.126579\n",
      "[6722]\ttraining's binary_logloss: 0.126566\n",
      "[6723]\ttraining's binary_logloss: 0.126555\n",
      "[6724]\ttraining's binary_logloss: 0.126544\n",
      "[6725]\ttraining's binary_logloss: 0.126532\n",
      "[6726]\ttraining's binary_logloss: 0.126522\n",
      "[6727]\ttraining's binary_logloss: 0.126512\n",
      "[6728]\ttraining's binary_logloss: 0.126499\n",
      "[6729]\ttraining's binary_logloss: 0.126485\n",
      "[6730]\ttraining's binary_logloss: 0.126472\n",
      "[6731]\ttraining's binary_logloss: 0.126463\n",
      "[6732]\ttraining's binary_logloss: 0.12646\n",
      "[6733]\ttraining's binary_logloss: 0.126444\n",
      "[6734]\ttraining's binary_logloss: 0.126435\n",
      "[6735]\ttraining's binary_logloss: 0.126429\n",
      "[6736]\ttraining's binary_logloss: 0.126424\n",
      "[6737]\ttraining's binary_logloss: 0.126411\n",
      "[6738]\ttraining's binary_logloss: 0.126401\n",
      "[6739]\ttraining's binary_logloss: 0.126389\n",
      "[6740]\ttraining's binary_logloss: 0.126378\n",
      "[6741]\ttraining's binary_logloss: 0.126373\n",
      "[6742]\ttraining's binary_logloss: 0.12637\n",
      "[6743]\ttraining's binary_logloss: 0.126356\n",
      "[6744]\ttraining's binary_logloss: 0.126343\n",
      "[6745]\ttraining's binary_logloss: 0.126333\n",
      "[6746]\ttraining's binary_logloss: 0.126322\n",
      "[6747]\ttraining's binary_logloss: 0.126312\n",
      "[6748]\ttraining's binary_logloss: 0.126299\n",
      "[6749]\ttraining's binary_logloss: 0.126287\n",
      "[6750]\ttraining's binary_logloss: 0.126275\n",
      "[6751]\ttraining's binary_logloss: 0.126264\n",
      "[6752]\ttraining's binary_logloss: 0.126261\n",
      "[6753]\ttraining's binary_logloss: 0.12625\n",
      "[6754]\ttraining's binary_logloss: 0.126236\n",
      "[6755]\ttraining's binary_logloss: 0.126225\n",
      "[6756]\ttraining's binary_logloss: 0.126214\n",
      "[6757]\ttraining's binary_logloss: 0.126201\n",
      "[6758]\ttraining's binary_logloss: 0.126189\n",
      "[6759]\ttraining's binary_logloss: 0.126186\n",
      "[6760]\ttraining's binary_logloss: 0.126175\n",
      "[6761]\ttraining's binary_logloss: 0.126166\n",
      "[6762]\ttraining's binary_logloss: 0.126159\n",
      "[6763]\ttraining's binary_logloss: 0.126157\n",
      "[6764]\ttraining's binary_logloss: 0.126147\n",
      "[6765]\ttraining's binary_logloss: 0.126146\n",
      "[6766]\ttraining's binary_logloss: 0.126143\n",
      "[6767]\ttraining's binary_logloss: 0.12613\n",
      "[6768]\ttraining's binary_logloss: 0.126119\n",
      "[6769]\ttraining's binary_logloss: 0.126111\n",
      "[6770]\ttraining's binary_logloss: 0.126102\n",
      "[6771]\ttraining's binary_logloss: 0.126094\n",
      "[6772]\ttraining's binary_logloss: 0.126083\n",
      "[6773]\ttraining's binary_logloss: 0.126071\n",
      "[6774]\ttraining's binary_logloss: 0.12606\n",
      "[6775]\ttraining's binary_logloss: 0.126048\n",
      "[6776]\ttraining's binary_logloss: 0.126038\n",
      "[6777]\ttraining's binary_logloss: 0.126027\n",
      "[6778]\ttraining's binary_logloss: 0.126016\n",
      "[6779]\ttraining's binary_logloss: 0.126005\n",
      "[6780]\ttraining's binary_logloss: 0.126002\n",
      "[6781]\ttraining's binary_logloss: 0.125986\n",
      "[6782]\ttraining's binary_logloss: 0.125971\n",
      "[6783]\ttraining's binary_logloss: 0.12596\n",
      "[6784]\ttraining's binary_logloss: 0.125949\n",
      "[6785]\ttraining's binary_logloss: 0.125937\n",
      "[6786]\ttraining's binary_logloss: 0.125925\n",
      "[6787]\ttraining's binary_logloss: 0.125912\n",
      "[6788]\ttraining's binary_logloss: 0.125901\n",
      "[6789]\ttraining's binary_logloss: 0.125888\n",
      "[6790]\ttraining's binary_logloss: 0.125885\n",
      "[6791]\ttraining's binary_logloss: 0.125876\n",
      "[6792]\ttraining's binary_logloss: 0.125865\n",
      "[6793]\ttraining's binary_logloss: 0.125854\n",
      "[6794]\ttraining's binary_logloss: 0.125845\n",
      "[6795]\ttraining's binary_logloss: 0.125843\n",
      "[6796]\ttraining's binary_logloss: 0.125832\n",
      "[6797]\ttraining's binary_logloss: 0.125819\n",
      "[6798]\ttraining's binary_logloss: 0.125808\n",
      "[6799]\ttraining's binary_logloss: 0.125796\n",
      "[6800]\ttraining's binary_logloss: 0.125784\n",
      "[6801]\ttraining's binary_logloss: 0.125777\n",
      "[6802]\ttraining's binary_logloss: 0.125764\n",
      "[6803]\ttraining's binary_logloss: 0.125757\n",
      "[6804]\ttraining's binary_logloss: 0.125748\n",
      "[6805]\ttraining's binary_logloss: 0.125736\n",
      "[6806]\ttraining's binary_logloss: 0.125725\n",
      "[6807]\ttraining's binary_logloss: 0.125723\n",
      "[6808]\ttraining's binary_logloss: 0.125709\n",
      "[6809]\ttraining's binary_logloss: 0.125698\n",
      "[6810]\ttraining's binary_logloss: 0.125694\n",
      "[6811]\ttraining's binary_logloss: 0.125682\n",
      "[6812]\ttraining's binary_logloss: 0.125678\n",
      "[6813]\ttraining's binary_logloss: 0.125666\n",
      "[6814]\ttraining's binary_logloss: 0.125656\n",
      "[6815]\ttraining's binary_logloss: 0.125645\n",
      "[6816]\ttraining's binary_logloss: 0.125634\n",
      "[6817]\ttraining's binary_logloss: 0.125627\n",
      "[6818]\ttraining's binary_logloss: 0.125617\n",
      "[6819]\ttraining's binary_logloss: 0.125606\n",
      "[6820]\ttraining's binary_logloss: 0.125594\n",
      "[6821]\ttraining's binary_logloss: 0.125582\n",
      "[6822]\ttraining's binary_logloss: 0.12557\n",
      "[6823]\ttraining's binary_logloss: 0.125558\n",
      "[6824]\ttraining's binary_logloss: 0.125548\n",
      "[6825]\ttraining's binary_logloss: 0.125536\n",
      "[6826]\ttraining's binary_logloss: 0.125526\n",
      "[6827]\ttraining's binary_logloss: 0.125516\n",
      "[6828]\ttraining's binary_logloss: 0.125505\n",
      "[6829]\ttraining's binary_logloss: 0.125491\n",
      "[6830]\ttraining's binary_logloss: 0.125481\n",
      "[6831]\ttraining's binary_logloss: 0.12547\n",
      "[6832]\ttraining's binary_logloss: 0.125459\n",
      "[6833]\ttraining's binary_logloss: 0.125453\n",
      "[6834]\ttraining's binary_logloss: 0.125451\n",
      "[6835]\ttraining's binary_logloss: 0.12544\n",
      "[6836]\ttraining's binary_logloss: 0.125427\n",
      "[6837]\ttraining's binary_logloss: 0.125416\n",
      "[6838]\ttraining's binary_logloss: 0.125405\n",
      "[6839]\ttraining's binary_logloss: 0.125398\n",
      "[6840]\ttraining's binary_logloss: 0.125394\n",
      "[6841]\ttraining's binary_logloss: 0.125384\n",
      "[6842]\ttraining's binary_logloss: 0.125371\n",
      "[6843]\ttraining's binary_logloss: 0.125359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6844]\ttraining's binary_logloss: 0.125347\n",
      "[6845]\ttraining's binary_logloss: 0.125336\n",
      "[6846]\ttraining's binary_logloss: 0.125325\n",
      "[6847]\ttraining's binary_logloss: 0.125313\n",
      "[6848]\ttraining's binary_logloss: 0.125309\n",
      "[6849]\ttraining's binary_logloss: 0.125301\n",
      "[6850]\ttraining's binary_logloss: 0.125289\n",
      "[6851]\ttraining's binary_logloss: 0.125278\n",
      "[6852]\ttraining's binary_logloss: 0.125267\n",
      "[6853]\ttraining's binary_logloss: 0.125257\n",
      "[6854]\ttraining's binary_logloss: 0.125246\n",
      "[6855]\ttraining's binary_logloss: 0.125235\n",
      "[6856]\ttraining's binary_logloss: 0.125225\n",
      "[6857]\ttraining's binary_logloss: 0.125224\n",
      "[6858]\ttraining's binary_logloss: 0.125212\n",
      "[6859]\ttraining's binary_logloss: 0.125202\n",
      "[6860]\ttraining's binary_logloss: 0.125195\n",
      "[6861]\ttraining's binary_logloss: 0.125194\n",
      "[6862]\ttraining's binary_logloss: 0.125182\n",
      "[6863]\ttraining's binary_logloss: 0.125171\n",
      "[6864]\ttraining's binary_logloss: 0.125159\n",
      "[6865]\ttraining's binary_logloss: 0.125148\n",
      "[6866]\ttraining's binary_logloss: 0.125142\n",
      "[6867]\ttraining's binary_logloss: 0.125138\n",
      "[6868]\ttraining's binary_logloss: 0.125126\n",
      "[6869]\ttraining's binary_logloss: 0.125115\n",
      "[6870]\ttraining's binary_logloss: 0.125109\n",
      "[6871]\ttraining's binary_logloss: 0.125098\n",
      "[6872]\ttraining's binary_logloss: 0.125087\n",
      "[6873]\ttraining's binary_logloss: 0.125076\n",
      "[6874]\ttraining's binary_logloss: 0.125062\n",
      "[6875]\ttraining's binary_logloss: 0.125049\n",
      "[6876]\ttraining's binary_logloss: 0.125038\n",
      "[6877]\ttraining's binary_logloss: 0.125028\n",
      "[6878]\ttraining's binary_logloss: 0.125016\n",
      "[6879]\ttraining's binary_logloss: 0.125006\n",
      "[6880]\ttraining's binary_logloss: 0.124996\n",
      "[6881]\ttraining's binary_logloss: 0.124985\n",
      "[6882]\ttraining's binary_logloss: 0.124972\n",
      "[6883]\ttraining's binary_logloss: 0.12496\n",
      "[6884]\ttraining's binary_logloss: 0.124946\n",
      "[6885]\ttraining's binary_logloss: 0.124936\n",
      "[6886]\ttraining's binary_logloss: 0.124928\n",
      "[6887]\ttraining's binary_logloss: 0.124917\n",
      "[6888]\ttraining's binary_logloss: 0.124904\n",
      "[6889]\ttraining's binary_logloss: 0.124902\n",
      "[6890]\ttraining's binary_logloss: 0.124892\n",
      "[6891]\ttraining's binary_logloss: 0.124889\n",
      "[6892]\ttraining's binary_logloss: 0.124879\n",
      "[6893]\ttraining's binary_logloss: 0.124874\n",
      "[6894]\ttraining's binary_logloss: 0.124871\n",
      "[6895]\ttraining's binary_logloss: 0.124859\n",
      "[6896]\ttraining's binary_logloss: 0.124847\n",
      "[6897]\ttraining's binary_logloss: 0.124836\n",
      "[6898]\ttraining's binary_logloss: 0.124822\n",
      "[6899]\ttraining's binary_logloss: 0.124809\n",
      "[6900]\ttraining's binary_logloss: 0.124807\n",
      "[6901]\ttraining's binary_logloss: 0.124799\n",
      "[6902]\ttraining's binary_logloss: 0.12479\n",
      "[6903]\ttraining's binary_logloss: 0.124787\n",
      "[6904]\ttraining's binary_logloss: 0.124776\n",
      "[6905]\ttraining's binary_logloss: 0.124764\n",
      "[6906]\ttraining's binary_logloss: 0.124752\n",
      "[6907]\ttraining's binary_logloss: 0.124743\n",
      "[6908]\ttraining's binary_logloss: 0.124731\n",
      "[6909]\ttraining's binary_logloss: 0.12472\n",
      "[6910]\ttraining's binary_logloss: 0.124708\n",
      "[6911]\ttraining's binary_logloss: 0.124694\n",
      "[6912]\ttraining's binary_logloss: 0.124682\n",
      "[6913]\ttraining's binary_logloss: 0.12467\n",
      "[6914]\ttraining's binary_logloss: 0.124658\n",
      "[6915]\ttraining's binary_logloss: 0.124648\n",
      "[6916]\ttraining's binary_logloss: 0.124636\n",
      "[6917]\ttraining's binary_logloss: 0.124622\n",
      "[6918]\ttraining's binary_logloss: 0.124611\n",
      "[6919]\ttraining's binary_logloss: 0.124602\n",
      "[6920]\ttraining's binary_logloss: 0.124593\n",
      "[6921]\ttraining's binary_logloss: 0.124578\n",
      "[6922]\ttraining's binary_logloss: 0.124567\n",
      "[6923]\ttraining's binary_logloss: 0.124554\n",
      "[6924]\ttraining's binary_logloss: 0.124541\n",
      "[6925]\ttraining's binary_logloss: 0.12453\n",
      "[6926]\ttraining's binary_logloss: 0.124519\n",
      "[6927]\ttraining's binary_logloss: 0.124516\n",
      "[6928]\ttraining's binary_logloss: 0.124514\n",
      "[6929]\ttraining's binary_logloss: 0.124501\n",
      "[6930]\ttraining's binary_logloss: 0.124489\n",
      "[6931]\ttraining's binary_logloss: 0.124475\n",
      "[6932]\ttraining's binary_logloss: 0.124464\n",
      "[6933]\ttraining's binary_logloss: 0.124454\n",
      "[6934]\ttraining's binary_logloss: 0.124444\n",
      "[6935]\ttraining's binary_logloss: 0.124441\n",
      "[6936]\ttraining's binary_logloss: 0.124435\n",
      "[6937]\ttraining's binary_logloss: 0.124432\n",
      "[6938]\ttraining's binary_logloss: 0.124419\n",
      "[6939]\ttraining's binary_logloss: 0.124418\n",
      "[6940]\ttraining's binary_logloss: 0.124409\n",
      "[6941]\ttraining's binary_logloss: 0.124402\n",
      "[6942]\ttraining's binary_logloss: 0.12439\n",
      "[6943]\ttraining's binary_logloss: 0.124379\n",
      "[6944]\ttraining's binary_logloss: 0.124377\n",
      "[6945]\ttraining's binary_logloss: 0.124365\n",
      "[6946]\ttraining's binary_logloss: 0.124353\n",
      "[6947]\ttraining's binary_logloss: 0.124351\n",
      "[6948]\ttraining's binary_logloss: 0.124339\n",
      "[6949]\ttraining's binary_logloss: 0.124327\n",
      "[6950]\ttraining's binary_logloss: 0.124315\n",
      "[6951]\ttraining's binary_logloss: 0.124309\n",
      "[6952]\ttraining's binary_logloss: 0.124303\n",
      "[6953]\ttraining's binary_logloss: 0.124293\n",
      "[6954]\ttraining's binary_logloss: 0.124281\n",
      "[6955]\ttraining's binary_logloss: 0.124272\n",
      "[6956]\ttraining's binary_logloss: 0.124262\n",
      "[6957]\ttraining's binary_logloss: 0.124249\n",
      "[6958]\ttraining's binary_logloss: 0.124237\n",
      "[6959]\ttraining's binary_logloss: 0.124225\n",
      "[6960]\ttraining's binary_logloss: 0.124214\n",
      "[6961]\ttraining's binary_logloss: 0.124201\n",
      "[6962]\ttraining's binary_logloss: 0.124187\n",
      "[6963]\ttraining's binary_logloss: 0.124175\n",
      "[6964]\ttraining's binary_logloss: 0.124162\n",
      "[6965]\ttraining's binary_logloss: 0.124161\n",
      "[6966]\ttraining's binary_logloss: 0.124149\n",
      "[6967]\ttraining's binary_logloss: 0.124137\n",
      "[6968]\ttraining's binary_logloss: 0.124126\n",
      "[6969]\ttraining's binary_logloss: 0.124112\n",
      "[6970]\ttraining's binary_logloss: 0.124105\n",
      "[6971]\ttraining's binary_logloss: 0.124094\n",
      "[6972]\ttraining's binary_logloss: 0.124082\n",
      "[6973]\ttraining's binary_logloss: 0.124071\n",
      "[6974]\ttraining's binary_logloss: 0.124061\n",
      "[6975]\ttraining's binary_logloss: 0.124052\n",
      "[6976]\ttraining's binary_logloss: 0.124047\n",
      "[6977]\ttraining's binary_logloss: 0.124045\n",
      "[6978]\ttraining's binary_logloss: 0.124034\n",
      "[6979]\ttraining's binary_logloss: 0.124023\n",
      "[6980]\ttraining's binary_logloss: 0.12401\n",
      "[6981]\ttraining's binary_logloss: 0.123999\n",
      "[6982]\ttraining's binary_logloss: 0.123988\n",
      "[6983]\ttraining's binary_logloss: 0.123982\n",
      "[6984]\ttraining's binary_logloss: 0.123973\n",
      "[6985]\ttraining's binary_logloss: 0.123962\n",
      "[6986]\ttraining's binary_logloss: 0.123953\n",
      "[6987]\ttraining's binary_logloss: 0.12394\n",
      "[6988]\ttraining's binary_logloss: 0.123938\n",
      "[6989]\ttraining's binary_logloss: 0.123926\n",
      "[6990]\ttraining's binary_logloss: 0.123915\n",
      "[6991]\ttraining's binary_logloss: 0.123905\n",
      "[6992]\ttraining's binary_logloss: 0.123893\n",
      "[6993]\ttraining's binary_logloss: 0.123882\n",
      "[6994]\ttraining's binary_logloss: 0.123871\n",
      "[6995]\ttraining's binary_logloss: 0.123861\n",
      "[6996]\ttraining's binary_logloss: 0.123855\n",
      "[6997]\ttraining's binary_logloss: 0.123846\n",
      "[6998]\ttraining's binary_logloss: 0.123837\n",
      "[6999]\ttraining's binary_logloss: 0.123825\n",
      "[7000]\ttraining's binary_logloss: 0.123814\n",
      "[7001]\ttraining's binary_logloss: 0.123802\n",
      "[7002]\ttraining's binary_logloss: 0.12379\n",
      "[7003]\ttraining's binary_logloss: 0.123778\n",
      "[7004]\ttraining's binary_logloss: 0.123765\n",
      "[7005]\ttraining's binary_logloss: 0.123752\n",
      "[7006]\ttraining's binary_logloss: 0.123739\n",
      "[7007]\ttraining's binary_logloss: 0.123731\n",
      "[7008]\ttraining's binary_logloss: 0.12372\n",
      "[7009]\ttraining's binary_logloss: 0.123707\n",
      "[7010]\ttraining's binary_logloss: 0.123694\n",
      "[7011]\ttraining's binary_logloss: 0.123684\n",
      "[7012]\ttraining's binary_logloss: 0.123672\n",
      "[7013]\ttraining's binary_logloss: 0.123662\n",
      "[7014]\ttraining's binary_logloss: 0.123659\n",
      "[7015]\ttraining's binary_logloss: 0.123648\n",
      "[7016]\ttraining's binary_logloss: 0.123639\n",
      "[7017]\ttraining's binary_logloss: 0.123631\n",
      "[7018]\ttraining's binary_logloss: 0.123621\n",
      "[7019]\ttraining's binary_logloss: 0.12361\n",
      "[7020]\ttraining's binary_logloss: 0.123601\n",
      "[7021]\ttraining's binary_logloss: 0.123591\n",
      "[7022]\ttraining's binary_logloss: 0.12358\n",
      "[7023]\ttraining's binary_logloss: 0.12357\n",
      "[7024]\ttraining's binary_logloss: 0.123558\n",
      "[7025]\ttraining's binary_logloss: 0.123544\n",
      "[7026]\ttraining's binary_logloss: 0.123534\n",
      "[7027]\ttraining's binary_logloss: 0.123522\n",
      "[7028]\ttraining's binary_logloss: 0.123512\n",
      "[7029]\ttraining's binary_logloss: 0.123501\n",
      "[7030]\ttraining's binary_logloss: 0.123489\n",
      "[7031]\ttraining's binary_logloss: 0.123484\n",
      "[7032]\ttraining's binary_logloss: 0.123472\n",
      "[7033]\ttraining's binary_logloss: 0.123467\n",
      "[7034]\ttraining's binary_logloss: 0.123466\n",
      "[7035]\ttraining's binary_logloss: 0.123453\n",
      "[7036]\ttraining's binary_logloss: 0.12344\n",
      "[7037]\ttraining's binary_logloss: 0.123428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7038]\ttraining's binary_logloss: 0.123416\n",
      "[7039]\ttraining's binary_logloss: 0.123406\n",
      "[7040]\ttraining's binary_logloss: 0.123396\n",
      "[7041]\ttraining's binary_logloss: 0.123394\n",
      "[7042]\ttraining's binary_logloss: 0.123381\n",
      "[7043]\ttraining's binary_logloss: 0.123368\n",
      "[7044]\ttraining's binary_logloss: 0.123359\n",
      "[7045]\ttraining's binary_logloss: 0.123348\n",
      "[7046]\ttraining's binary_logloss: 0.123337\n",
      "[7047]\ttraining's binary_logloss: 0.123327\n",
      "[7048]\ttraining's binary_logloss: 0.123314\n",
      "[7049]\ttraining's binary_logloss: 0.123302\n",
      "[7050]\ttraining's binary_logloss: 0.1233\n",
      "[7051]\ttraining's binary_logloss: 0.123288\n",
      "[7052]\ttraining's binary_logloss: 0.123276\n",
      "[7053]\ttraining's binary_logloss: 0.123264\n",
      "[7054]\ttraining's binary_logloss: 0.123254\n",
      "[7055]\ttraining's binary_logloss: 0.12324\n",
      "[7056]\ttraining's binary_logloss: 0.123229\n",
      "[7057]\ttraining's binary_logloss: 0.123215\n",
      "[7058]\ttraining's binary_logloss: 0.123205\n",
      "[7059]\ttraining's binary_logloss: 0.123193\n",
      "[7060]\ttraining's binary_logloss: 0.12318\n",
      "[7061]\ttraining's binary_logloss: 0.12317\n",
      "[7062]\ttraining's binary_logloss: 0.123168\n",
      "[7063]\ttraining's binary_logloss: 0.123157\n",
      "[7064]\ttraining's binary_logloss: 0.123146\n",
      "[7065]\ttraining's binary_logloss: 0.123134\n",
      "[7066]\ttraining's binary_logloss: 0.123122\n",
      "[7067]\ttraining's binary_logloss: 0.123113\n",
      "[7068]\ttraining's binary_logloss: 0.123101\n",
      "[7069]\ttraining's binary_logloss: 0.123088\n",
      "[7070]\ttraining's binary_logloss: 0.123073\n",
      "[7071]\ttraining's binary_logloss: 0.123062\n",
      "[7072]\ttraining's binary_logloss: 0.123058\n",
      "[7073]\ttraining's binary_logloss: 0.123048\n",
      "[7074]\ttraining's binary_logloss: 0.123034\n",
      "[7075]\ttraining's binary_logloss: 0.123024\n",
      "[7076]\ttraining's binary_logloss: 0.123011\n",
      "[7077]\ttraining's binary_logloss: 0.123002\n",
      "[7078]\ttraining's binary_logloss: 0.122993\n",
      "[7079]\ttraining's binary_logloss: 0.122982\n",
      "[7080]\ttraining's binary_logloss: 0.12298\n",
      "[7081]\ttraining's binary_logloss: 0.122969\n",
      "[7082]\ttraining's binary_logloss: 0.122961\n",
      "[7083]\ttraining's binary_logloss: 0.122947\n",
      "[7084]\ttraining's binary_logloss: 0.122936\n",
      "[7085]\ttraining's binary_logloss: 0.122925\n",
      "[7086]\ttraining's binary_logloss: 0.122915\n",
      "[7087]\ttraining's binary_logloss: 0.122903\n",
      "[7088]\ttraining's binary_logloss: 0.122892\n",
      "[7089]\ttraining's binary_logloss: 0.12288\n",
      "[7090]\ttraining's binary_logloss: 0.122871\n",
      "[7091]\ttraining's binary_logloss: 0.122858\n",
      "[7092]\ttraining's binary_logloss: 0.122856\n",
      "[7093]\ttraining's binary_logloss: 0.122848\n",
      "[7094]\ttraining's binary_logloss: 0.122843\n",
      "[7095]\ttraining's binary_logloss: 0.12284\n",
      "[7096]\ttraining's binary_logloss: 0.122829\n",
      "[7097]\ttraining's binary_logloss: 0.122827\n",
      "[7098]\ttraining's binary_logloss: 0.122817\n",
      "[7099]\ttraining's binary_logloss: 0.122807\n",
      "[7100]\ttraining's binary_logloss: 0.122797\n",
      "[7101]\ttraining's binary_logloss: 0.122783\n",
      "[7102]\ttraining's binary_logloss: 0.122775\n",
      "[7103]\ttraining's binary_logloss: 0.122764\n",
      "[7104]\ttraining's binary_logloss: 0.12275\n",
      "[7105]\ttraining's binary_logloss: 0.12274\n",
      "[7106]\ttraining's binary_logloss: 0.122728\n",
      "[7107]\ttraining's binary_logloss: 0.122719\n",
      "[7108]\ttraining's binary_logloss: 0.12271\n",
      "[7109]\ttraining's binary_logloss: 0.122698\n",
      "[7110]\ttraining's binary_logloss: 0.122695\n",
      "[7111]\ttraining's binary_logloss: 0.122683\n",
      "[7112]\ttraining's binary_logloss: 0.12268\n",
      "[7113]\ttraining's binary_logloss: 0.12267\n",
      "[7114]\ttraining's binary_logloss: 0.122668\n",
      "[7115]\ttraining's binary_logloss: 0.122656\n",
      "[7116]\ttraining's binary_logloss: 0.122647\n",
      "[7117]\ttraining's binary_logloss: 0.122636\n",
      "[7118]\ttraining's binary_logloss: 0.122625\n",
      "[7119]\ttraining's binary_logloss: 0.122614\n",
      "[7120]\ttraining's binary_logloss: 0.122606\n",
      "[7121]\ttraining's binary_logloss: 0.122594\n",
      "[7122]\ttraining's binary_logloss: 0.122582\n",
      "[7123]\ttraining's binary_logloss: 0.122572\n",
      "[7124]\ttraining's binary_logloss: 0.122564\n",
      "[7125]\ttraining's binary_logloss: 0.122554\n",
      "[7126]\ttraining's binary_logloss: 0.122543\n",
      "[7127]\ttraining's binary_logloss: 0.122532\n",
      "[7128]\ttraining's binary_logloss: 0.122521\n",
      "[7129]\ttraining's binary_logloss: 0.122509\n",
      "[7130]\ttraining's binary_logloss: 0.122497\n",
      "[7131]\ttraining's binary_logloss: 0.122493\n",
      "[7132]\ttraining's binary_logloss: 0.122482\n",
      "[7133]\ttraining's binary_logloss: 0.122469\n",
      "[7134]\ttraining's binary_logloss: 0.122457\n",
      "[7135]\ttraining's binary_logloss: 0.122444\n",
      "[7136]\ttraining's binary_logloss: 0.122431\n",
      "[7137]\ttraining's binary_logloss: 0.122418\n",
      "[7138]\ttraining's binary_logloss: 0.122408\n",
      "[7139]\ttraining's binary_logloss: 0.122396\n",
      "[7140]\ttraining's binary_logloss: 0.122384\n",
      "[7141]\ttraining's binary_logloss: 0.122371\n",
      "[7142]\ttraining's binary_logloss: 0.122359\n",
      "[7143]\ttraining's binary_logloss: 0.122348\n",
      "[7144]\ttraining's binary_logloss: 0.122335\n",
      "[7145]\ttraining's binary_logloss: 0.122325\n",
      "[7146]\ttraining's binary_logloss: 0.122316\n",
      "[7147]\ttraining's binary_logloss: 0.122304\n",
      "[7148]\ttraining's binary_logloss: 0.122292\n",
      "[7149]\ttraining's binary_logloss: 0.122282\n",
      "[7150]\ttraining's binary_logloss: 0.122271\n",
      "[7151]\ttraining's binary_logloss: 0.12226\n",
      "[7152]\ttraining's binary_logloss: 0.122258\n",
      "[7153]\ttraining's binary_logloss: 0.122248\n",
      "[7154]\ttraining's binary_logloss: 0.122237\n",
      "[7155]\ttraining's binary_logloss: 0.122224\n",
      "[7156]\ttraining's binary_logloss: 0.122211\n",
      "[7157]\ttraining's binary_logloss: 0.1222\n",
      "[7158]\ttraining's binary_logloss: 0.122186\n",
      "[7159]\ttraining's binary_logloss: 0.122176\n",
      "[7160]\ttraining's binary_logloss: 0.122165\n",
      "[7161]\ttraining's binary_logloss: 0.122154\n",
      "[7162]\ttraining's binary_logloss: 0.122142\n",
      "[7163]\ttraining's binary_logloss: 0.122131\n",
      "[7164]\ttraining's binary_logloss: 0.122122\n",
      "[7165]\ttraining's binary_logloss: 0.122107\n",
      "[7166]\ttraining's binary_logloss: 0.122095\n",
      "[7167]\ttraining's binary_logloss: 0.122083\n",
      "[7168]\ttraining's binary_logloss: 0.12207\n",
      "[7169]\ttraining's binary_logloss: 0.122068\n",
      "[7170]\ttraining's binary_logloss: 0.122056\n",
      "[7171]\ttraining's binary_logloss: 0.122045\n",
      "[7172]\ttraining's binary_logloss: 0.122034\n",
      "[7173]\ttraining's binary_logloss: 0.122024\n",
      "[7174]\ttraining's binary_logloss: 0.122013\n",
      "[7175]\ttraining's binary_logloss: 0.122004\n",
      "[7176]\ttraining's binary_logloss: 0.121993\n",
      "[7177]\ttraining's binary_logloss: 0.12198\n",
      "[7178]\ttraining's binary_logloss: 0.121974\n",
      "[7179]\ttraining's binary_logloss: 0.121963\n",
      "[7180]\ttraining's binary_logloss: 0.121951\n",
      "[7181]\ttraining's binary_logloss: 0.12194\n",
      "[7182]\ttraining's binary_logloss: 0.121927\n",
      "[7183]\ttraining's binary_logloss: 0.121915\n",
      "[7184]\ttraining's binary_logloss: 0.121903\n",
      "[7185]\ttraining's binary_logloss: 0.12189\n",
      "[7186]\ttraining's binary_logloss: 0.121876\n",
      "[7187]\ttraining's binary_logloss: 0.121868\n",
      "[7188]\ttraining's binary_logloss: 0.121864\n",
      "[7189]\ttraining's binary_logloss: 0.121853\n",
      "[7190]\ttraining's binary_logloss: 0.121841\n",
      "[7191]\ttraining's binary_logloss: 0.121838\n",
      "[7192]\ttraining's binary_logloss: 0.121826\n",
      "[7193]\ttraining's binary_logloss: 0.121817\n",
      "[7194]\ttraining's binary_logloss: 0.121804\n",
      "[7195]\ttraining's binary_logloss: 0.121791\n",
      "[7196]\ttraining's binary_logloss: 0.12178\n",
      "[7197]\ttraining's binary_logloss: 0.121768\n",
      "[7198]\ttraining's binary_logloss: 0.121754\n",
      "[7199]\ttraining's binary_logloss: 0.121744\n",
      "[7200]\ttraining's binary_logloss: 0.121739\n",
      "[7201]\ttraining's binary_logloss: 0.121728\n",
      "[7202]\ttraining's binary_logloss: 0.121717\n",
      "[7203]\ttraining's binary_logloss: 0.121704\n",
      "[7204]\ttraining's binary_logloss: 0.121692\n",
      "[7205]\ttraining's binary_logloss: 0.121681\n",
      "[7206]\ttraining's binary_logloss: 0.12167\n",
      "[7207]\ttraining's binary_logloss: 0.121657\n",
      "[7208]\ttraining's binary_logloss: 0.121646\n",
      "[7209]\ttraining's binary_logloss: 0.121643\n",
      "[7210]\ttraining's binary_logloss: 0.121633\n",
      "[7211]\ttraining's binary_logloss: 0.12162\n",
      "[7212]\ttraining's binary_logloss: 0.121609\n",
      "[7213]\ttraining's binary_logloss: 0.121598\n",
      "[7214]\ttraining's binary_logloss: 0.121588\n",
      "[7215]\ttraining's binary_logloss: 0.121577\n",
      "[7216]\ttraining's binary_logloss: 0.121575\n",
      "[7217]\ttraining's binary_logloss: 0.121565\n",
      "[7218]\ttraining's binary_logloss: 0.121553\n",
      "[7219]\ttraining's binary_logloss: 0.12154\n",
      "[7220]\ttraining's binary_logloss: 0.121527\n",
      "[7221]\ttraining's binary_logloss: 0.121515\n",
      "[7222]\ttraining's binary_logloss: 0.121512\n",
      "[7223]\ttraining's binary_logloss: 0.121499\n",
      "[7224]\ttraining's binary_logloss: 0.121487\n",
      "[7225]\ttraining's binary_logloss: 0.121475\n",
      "[7226]\ttraining's binary_logloss: 0.121472\n",
      "[7227]\ttraining's binary_logloss: 0.12146\n",
      "[7228]\ttraining's binary_logloss: 0.121446\n",
      "[7229]\ttraining's binary_logloss: 0.121436\n",
      "[7230]\ttraining's binary_logloss: 0.12143\n",
      "[7231]\ttraining's binary_logloss: 0.121418\n",
      "[7232]\ttraining's binary_logloss: 0.121408\n",
      "[7233]\ttraining's binary_logloss: 0.121397\n",
      "[7234]\ttraining's binary_logloss: 0.121386\n",
      "[7235]\ttraining's binary_logloss: 0.121374\n",
      "[7236]\ttraining's binary_logloss: 0.12137\n",
      "[7237]\ttraining's binary_logloss: 0.12136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7238]\ttraining's binary_logloss: 0.121347\n",
      "[7239]\ttraining's binary_logloss: 0.121337\n",
      "[7240]\ttraining's binary_logloss: 0.121327\n",
      "[7241]\ttraining's binary_logloss: 0.121315\n",
      "[7242]\ttraining's binary_logloss: 0.121303\n",
      "[7243]\ttraining's binary_logloss: 0.121295\n",
      "[7244]\ttraining's binary_logloss: 0.121286\n",
      "[7245]\ttraining's binary_logloss: 0.121274\n",
      "[7246]\ttraining's binary_logloss: 0.121272\n",
      "[7247]\ttraining's binary_logloss: 0.121265\n",
      "[7248]\ttraining's binary_logloss: 0.121253\n",
      "[7249]\ttraining's binary_logloss: 0.121251\n",
      "[7250]\ttraining's binary_logloss: 0.121245\n",
      "[7251]\ttraining's binary_logloss: 0.121233\n",
      "[7252]\ttraining's binary_logloss: 0.12122\n",
      "[7253]\ttraining's binary_logloss: 0.121209\n",
      "[7254]\ttraining's binary_logloss: 0.121198\n",
      "[7255]\ttraining's binary_logloss: 0.121187\n",
      "[7256]\ttraining's binary_logloss: 0.121177\n",
      "[7257]\ttraining's binary_logloss: 0.121165\n",
      "[7258]\ttraining's binary_logloss: 0.121155\n",
      "[7259]\ttraining's binary_logloss: 0.121144\n",
      "[7260]\ttraining's binary_logloss: 0.121133\n",
      "[7261]\ttraining's binary_logloss: 0.121122\n",
      "[7262]\ttraining's binary_logloss: 0.121108\n",
      "[7263]\ttraining's binary_logloss: 0.121101\n",
      "[7264]\ttraining's binary_logloss: 0.121094\n",
      "[7265]\ttraining's binary_logloss: 0.121082\n",
      "[7266]\ttraining's binary_logloss: 0.121069\n",
      "[7267]\ttraining's binary_logloss: 0.121056\n",
      "[7268]\ttraining's binary_logloss: 0.121044\n",
      "[7269]\ttraining's binary_logloss: 0.121032\n",
      "[7270]\ttraining's binary_logloss: 0.12102\n",
      "[7271]\ttraining's binary_logloss: 0.121008\n",
      "[7272]\ttraining's binary_logloss: 0.120997\n",
      "[7273]\ttraining's binary_logloss: 0.120985\n",
      "[7274]\ttraining's binary_logloss: 0.120974\n",
      "[7275]\ttraining's binary_logloss: 0.120968\n",
      "[7276]\ttraining's binary_logloss: 0.120954\n",
      "[7277]\ttraining's binary_logloss: 0.120941\n",
      "[7278]\ttraining's binary_logloss: 0.120933\n",
      "[7279]\ttraining's binary_logloss: 0.120922\n",
      "[7280]\ttraining's binary_logloss: 0.120911\n",
      "[7281]\ttraining's binary_logloss: 0.120898\n",
      "[7282]\ttraining's binary_logloss: 0.120888\n",
      "[7283]\ttraining's binary_logloss: 0.120881\n",
      "[7284]\ttraining's binary_logloss: 0.120878\n",
      "[7285]\ttraining's binary_logloss: 0.120867\n",
      "[7286]\ttraining's binary_logloss: 0.120856\n",
      "[7287]\ttraining's binary_logloss: 0.120845\n",
      "[7288]\ttraining's binary_logloss: 0.120835\n",
      "[7289]\ttraining's binary_logloss: 0.120824\n",
      "[7290]\ttraining's binary_logloss: 0.120813\n",
      "[7291]\ttraining's binary_logloss: 0.120803\n",
      "[7292]\ttraining's binary_logloss: 0.120792\n",
      "[7293]\ttraining's binary_logloss: 0.12078\n",
      "[7294]\ttraining's binary_logloss: 0.120768\n",
      "[7295]\ttraining's binary_logloss: 0.120764\n",
      "[7296]\ttraining's binary_logloss: 0.120752\n",
      "[7297]\ttraining's binary_logloss: 0.120741\n",
      "[7298]\ttraining's binary_logloss: 0.120728\n",
      "[7299]\ttraining's binary_logloss: 0.120717\n",
      "[7300]\ttraining's binary_logloss: 0.120705\n",
      "[7301]\ttraining's binary_logloss: 0.120697\n",
      "[7302]\ttraining's binary_logloss: 0.12069\n",
      "[7303]\ttraining's binary_logloss: 0.120678\n",
      "[7304]\ttraining's binary_logloss: 0.120667\n",
      "[7305]\ttraining's binary_logloss: 0.120659\n",
      "[7306]\ttraining's binary_logloss: 0.120648\n",
      "[7307]\ttraining's binary_logloss: 0.120642\n",
      "[7308]\ttraining's binary_logloss: 0.120632\n",
      "[7309]\ttraining's binary_logloss: 0.120621\n",
      "[7310]\ttraining's binary_logloss: 0.120611\n",
      "[7311]\ttraining's binary_logloss: 0.120604\n",
      "[7312]\ttraining's binary_logloss: 0.120592\n",
      "[7313]\ttraining's binary_logloss: 0.120581\n",
      "[7314]\ttraining's binary_logloss: 0.120568\n",
      "[7315]\ttraining's binary_logloss: 0.120565\n",
      "[7316]\ttraining's binary_logloss: 0.120555\n",
      "[7317]\ttraining's binary_logloss: 0.120552\n",
      "[7318]\ttraining's binary_logloss: 0.120545\n",
      "[7319]\ttraining's binary_logloss: 0.120535\n",
      "[7320]\ttraining's binary_logloss: 0.120523\n",
      "[7321]\ttraining's binary_logloss: 0.120511\n",
      "[7322]\ttraining's binary_logloss: 0.120506\n",
      "[7323]\ttraining's binary_logloss: 0.120495\n",
      "[7324]\ttraining's binary_logloss: 0.120485\n",
      "[7325]\ttraining's binary_logloss: 0.120473\n",
      "[7326]\ttraining's binary_logloss: 0.120468\n",
      "[7327]\ttraining's binary_logloss: 0.120462\n",
      "[7328]\ttraining's binary_logloss: 0.120452\n",
      "[7329]\ttraining's binary_logloss: 0.120447\n",
      "[7330]\ttraining's binary_logloss: 0.120437\n",
      "[7331]\ttraining's binary_logloss: 0.120427\n",
      "[7332]\ttraining's binary_logloss: 0.120416\n",
      "[7333]\ttraining's binary_logloss: 0.120405\n",
      "[7334]\ttraining's binary_logloss: 0.120395\n",
      "[7335]\ttraining's binary_logloss: 0.120383\n",
      "[7336]\ttraining's binary_logloss: 0.120373\n",
      "[7337]\ttraining's binary_logloss: 0.120362\n",
      "[7338]\ttraining's binary_logloss: 0.120351\n",
      "[7339]\ttraining's binary_logloss: 0.120341\n",
      "[7340]\ttraining's binary_logloss: 0.120331\n",
      "[7341]\ttraining's binary_logloss: 0.120327\n",
      "[7342]\ttraining's binary_logloss: 0.120316\n",
      "[7343]\ttraining's binary_logloss: 0.120309\n",
      "[7344]\ttraining's binary_logloss: 0.120297\n",
      "[7345]\ttraining's binary_logloss: 0.120284\n",
      "[7346]\ttraining's binary_logloss: 0.120283\n",
      "[7347]\ttraining's binary_logloss: 0.120271\n",
      "[7348]\ttraining's binary_logloss: 0.120268\n",
      "[7349]\ttraining's binary_logloss: 0.120256\n",
      "[7350]\ttraining's binary_logloss: 0.120245\n",
      "[7351]\ttraining's binary_logloss: 0.120235\n",
      "[7352]\ttraining's binary_logloss: 0.120224\n",
      "[7353]\ttraining's binary_logloss: 0.120213\n",
      "[7354]\ttraining's binary_logloss: 0.120209\n",
      "[7355]\ttraining's binary_logloss: 0.120207\n",
      "[7356]\ttraining's binary_logloss: 0.120204\n",
      "[7357]\ttraining's binary_logloss: 0.120198\n",
      "[7358]\ttraining's binary_logloss: 0.120187\n",
      "[7359]\ttraining's binary_logloss: 0.120183\n",
      "[7360]\ttraining's binary_logloss: 0.120172\n",
      "[7361]\ttraining's binary_logloss: 0.120161\n",
      "[7362]\ttraining's binary_logloss: 0.120149\n",
      "[7363]\ttraining's binary_logloss: 0.12014\n",
      "[7364]\ttraining's binary_logloss: 0.120131\n",
      "[7365]\ttraining's binary_logloss: 0.120121\n",
      "[7366]\ttraining's binary_logloss: 0.12011\n",
      "[7367]\ttraining's binary_logloss: 0.1201\n",
      "[7368]\ttraining's binary_logloss: 0.120092\n",
      "[7369]\ttraining's binary_logloss: 0.120081\n",
      "[7370]\ttraining's binary_logloss: 0.120076\n",
      "[7371]\ttraining's binary_logloss: 0.120072\n",
      "[7372]\ttraining's binary_logloss: 0.120061\n",
      "[7373]\ttraining's binary_logloss: 0.120053\n",
      "[7374]\ttraining's binary_logloss: 0.120041\n",
      "[7375]\ttraining's binary_logloss: 0.120033\n",
      "[7376]\ttraining's binary_logloss: 0.12002\n",
      "[7377]\ttraining's binary_logloss: 0.120014\n",
      "[7378]\ttraining's binary_logloss: 0.120002\n",
      "[7379]\ttraining's binary_logloss: 0.119996\n",
      "[7380]\ttraining's binary_logloss: 0.119995\n",
      "[7381]\ttraining's binary_logloss: 0.119986\n",
      "[7382]\ttraining's binary_logloss: 0.119975\n",
      "[7383]\ttraining's binary_logloss: 0.119969\n",
      "[7384]\ttraining's binary_logloss: 0.119961\n",
      "[7385]\ttraining's binary_logloss: 0.119949\n",
      "[7386]\ttraining's binary_logloss: 0.119937\n",
      "[7387]\ttraining's binary_logloss: 0.119927\n",
      "[7388]\ttraining's binary_logloss: 0.119915\n",
      "[7389]\ttraining's binary_logloss: 0.119905\n",
      "[7390]\ttraining's binary_logloss: 0.119894\n",
      "[7391]\ttraining's binary_logloss: 0.119884\n",
      "[7392]\ttraining's binary_logloss: 0.11988\n",
      "[7393]\ttraining's binary_logloss: 0.119877\n",
      "[7394]\ttraining's binary_logloss: 0.119867\n",
      "[7395]\ttraining's binary_logloss: 0.119857\n",
      "[7396]\ttraining's binary_logloss: 0.119845\n",
      "[7397]\ttraining's binary_logloss: 0.11984\n",
      "[7398]\ttraining's binary_logloss: 0.119839\n",
      "[7399]\ttraining's binary_logloss: 0.119829\n",
      "[7400]\ttraining's binary_logloss: 0.119817\n",
      "[7401]\ttraining's binary_logloss: 0.119815\n",
      "[7402]\ttraining's binary_logloss: 0.119804\n",
      "[7403]\ttraining's binary_logloss: 0.119799\n",
      "[7404]\ttraining's binary_logloss: 0.119788\n",
      "[7405]\ttraining's binary_logloss: 0.119786\n",
      "[7406]\ttraining's binary_logloss: 0.119774\n",
      "[7407]\ttraining's binary_logloss: 0.119767\n",
      "[7408]\ttraining's binary_logloss: 0.119756\n",
      "[7409]\ttraining's binary_logloss: 0.119744\n",
      "[7410]\ttraining's binary_logloss: 0.119738\n",
      "[7411]\ttraining's binary_logloss: 0.119733\n",
      "[7412]\ttraining's binary_logloss: 0.119724\n",
      "[7413]\ttraining's binary_logloss: 0.11972\n",
      "[7414]\ttraining's binary_logloss: 0.119709\n",
      "[7415]\ttraining's binary_logloss: 0.119699\n",
      "[7416]\ttraining's binary_logloss: 0.119689\n",
      "[7417]\ttraining's binary_logloss: 0.119678\n",
      "[7418]\ttraining's binary_logloss: 0.119669\n",
      "[7419]\ttraining's binary_logloss: 0.119657\n",
      "[7420]\ttraining's binary_logloss: 0.119647\n",
      "[7421]\ttraining's binary_logloss: 0.119637\n",
      "[7422]\ttraining's binary_logloss: 0.119629\n",
      "[7423]\ttraining's binary_logloss: 0.119617\n",
      "[7424]\ttraining's binary_logloss: 0.119607\n",
      "[7425]\ttraining's binary_logloss: 0.119596\n",
      "[7426]\ttraining's binary_logloss: 0.119584\n",
      "[7427]\ttraining's binary_logloss: 0.119571\n",
      "[7428]\ttraining's binary_logloss: 0.119564\n",
      "[7429]\ttraining's binary_logloss: 0.119555\n",
      "[7430]\ttraining's binary_logloss: 0.119544\n",
      "[7431]\ttraining's binary_logloss: 0.119532\n",
      "[7432]\ttraining's binary_logloss: 0.11952\n",
      "[7433]\ttraining's binary_logloss: 0.119512\n",
      "[7434]\ttraining's binary_logloss: 0.119501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7435]\ttraining's binary_logloss: 0.119495\n",
      "[7436]\ttraining's binary_logloss: 0.119484\n",
      "[7437]\ttraining's binary_logloss: 0.119472\n",
      "[7438]\ttraining's binary_logloss: 0.119461\n",
      "[7439]\ttraining's binary_logloss: 0.11945\n",
      "[7440]\ttraining's binary_logloss: 0.119443\n",
      "[7441]\ttraining's binary_logloss: 0.119433\n",
      "[7442]\ttraining's binary_logloss: 0.119422\n",
      "[7443]\ttraining's binary_logloss: 0.119412\n",
      "[7444]\ttraining's binary_logloss: 0.119401\n",
      "[7445]\ttraining's binary_logloss: 0.119395\n",
      "[7446]\ttraining's binary_logloss: 0.119385\n",
      "[7447]\ttraining's binary_logloss: 0.119379\n",
      "[7448]\ttraining's binary_logloss: 0.119374\n",
      "[7449]\ttraining's binary_logloss: 0.119358\n",
      "[7450]\ttraining's binary_logloss: 0.119353\n",
      "[7451]\ttraining's binary_logloss: 0.119339\n",
      "[7452]\ttraining's binary_logloss: 0.119337\n",
      "[7453]\ttraining's binary_logloss: 0.119325\n",
      "[7454]\ttraining's binary_logloss: 0.119319\n",
      "[7455]\ttraining's binary_logloss: 0.119317\n",
      "[7456]\ttraining's binary_logloss: 0.119306\n",
      "[7457]\ttraining's binary_logloss: 0.119297\n",
      "[7458]\ttraining's binary_logloss: 0.119286\n",
      "[7459]\ttraining's binary_logloss: 0.119273\n",
      "[7460]\ttraining's binary_logloss: 0.119262\n",
      "[7461]\ttraining's binary_logloss: 0.119251\n",
      "[7462]\ttraining's binary_logloss: 0.119239\n",
      "[7463]\ttraining's binary_logloss: 0.119236\n",
      "[7464]\ttraining's binary_logloss: 0.119227\n",
      "[7465]\ttraining's binary_logloss: 0.119219\n",
      "[7466]\ttraining's binary_logloss: 0.119206\n",
      "[7467]\ttraining's binary_logloss: 0.119192\n",
      "[7468]\ttraining's binary_logloss: 0.119181\n",
      "[7469]\ttraining's binary_logloss: 0.119172\n",
      "[7470]\ttraining's binary_logloss: 0.119161\n",
      "[7471]\ttraining's binary_logloss: 0.119149\n",
      "[7472]\ttraining's binary_logloss: 0.119139\n",
      "[7473]\ttraining's binary_logloss: 0.119127\n",
      "[7474]\ttraining's binary_logloss: 0.119116\n",
      "[7475]\ttraining's binary_logloss: 0.119105\n",
      "[7476]\ttraining's binary_logloss: 0.119093\n",
      "[7477]\ttraining's binary_logloss: 0.119081\n",
      "[7478]\ttraining's binary_logloss: 0.119072\n",
      "[7479]\ttraining's binary_logloss: 0.119061\n",
      "[7480]\ttraining's binary_logloss: 0.11905\n",
      "[7481]\ttraining's binary_logloss: 0.119041\n",
      "[7482]\ttraining's binary_logloss: 0.11903\n",
      "[7483]\ttraining's binary_logloss: 0.119019\n",
      "[7484]\ttraining's binary_logloss: 0.11901\n",
      "[7485]\ttraining's binary_logloss: 0.119001\n",
      "[7486]\ttraining's binary_logloss: 0.118988\n",
      "[7487]\ttraining's binary_logloss: 0.118982\n",
      "[7488]\ttraining's binary_logloss: 0.11897\n",
      "[7489]\ttraining's binary_logloss: 0.11896\n",
      "[7490]\ttraining's binary_logloss: 0.118948\n",
      "[7491]\ttraining's binary_logloss: 0.118935\n",
      "[7492]\ttraining's binary_logloss: 0.118922\n",
      "[7493]\ttraining's binary_logloss: 0.118913\n",
      "[7494]\ttraining's binary_logloss: 0.1189\n",
      "[7495]\ttraining's binary_logloss: 0.118889\n",
      "[7496]\ttraining's binary_logloss: 0.118876\n",
      "[7497]\ttraining's binary_logloss: 0.118868\n",
      "[7498]\ttraining's binary_logloss: 0.118858\n",
      "[7499]\ttraining's binary_logloss: 0.118851\n",
      "[7500]\ttraining's binary_logloss: 0.118837\n",
      "[7501]\ttraining's binary_logloss: 0.118823\n",
      "[7502]\ttraining's binary_logloss: 0.118813\n",
      "[7503]\ttraining's binary_logloss: 0.118802\n",
      "[7504]\ttraining's binary_logloss: 0.118789\n",
      "[7505]\ttraining's binary_logloss: 0.118781\n",
      "[7506]\ttraining's binary_logloss: 0.11878\n",
      "[7507]\ttraining's binary_logloss: 0.118768\n",
      "[7508]\ttraining's binary_logloss: 0.118758\n",
      "[7509]\ttraining's binary_logloss: 0.118746\n",
      "[7510]\ttraining's binary_logloss: 0.118736\n",
      "[7511]\ttraining's binary_logloss: 0.118726\n",
      "[7512]\ttraining's binary_logloss: 0.118713\n",
      "[7513]\ttraining's binary_logloss: 0.118706\n",
      "[7514]\ttraining's binary_logloss: 0.118695\n",
      "[7515]\ttraining's binary_logloss: 0.118685\n",
      "[7516]\ttraining's binary_logloss: 0.118675\n",
      "[7517]\ttraining's binary_logloss: 0.118667\n",
      "[7518]\ttraining's binary_logloss: 0.118656\n",
      "[7519]\ttraining's binary_logloss: 0.118646\n",
      "[7520]\ttraining's binary_logloss: 0.118635\n",
      "[7521]\ttraining's binary_logloss: 0.11863\n",
      "[7522]\ttraining's binary_logloss: 0.118618\n",
      "[7523]\ttraining's binary_logloss: 0.118612\n",
      "[7524]\ttraining's binary_logloss: 0.11861\n",
      "[7525]\ttraining's binary_logloss: 0.118608\n",
      "[7526]\ttraining's binary_logloss: 0.118599\n",
      "[7527]\ttraining's binary_logloss: 0.118587\n",
      "[7528]\ttraining's binary_logloss: 0.118577\n",
      "[7529]\ttraining's binary_logloss: 0.118565\n",
      "[7530]\ttraining's binary_logloss: 0.118557\n",
      "[7531]\ttraining's binary_logloss: 0.118546\n",
      "[7532]\ttraining's binary_logloss: 0.118537\n",
      "[7533]\ttraining's binary_logloss: 0.118525\n",
      "[7534]\ttraining's binary_logloss: 0.118512\n",
      "[7535]\ttraining's binary_logloss: 0.118504\n",
      "[7536]\ttraining's binary_logloss: 0.118493\n",
      "[7537]\ttraining's binary_logloss: 0.118483\n",
      "[7538]\ttraining's binary_logloss: 0.118472\n",
      "[7539]\ttraining's binary_logloss: 0.118461\n",
      "[7540]\ttraining's binary_logloss: 0.118457\n",
      "[7541]\ttraining's binary_logloss: 0.118448\n",
      "[7542]\ttraining's binary_logloss: 0.118437\n",
      "[7543]\ttraining's binary_logloss: 0.11843\n",
      "[7544]\ttraining's binary_logloss: 0.11842\n",
      "[7545]\ttraining's binary_logloss: 0.118414\n",
      "[7546]\ttraining's binary_logloss: 0.118406\n",
      "[7547]\ttraining's binary_logloss: 0.118397\n",
      "[7548]\ttraining's binary_logloss: 0.118386\n",
      "[7549]\ttraining's binary_logloss: 0.118384\n",
      "[7550]\ttraining's binary_logloss: 0.118376\n",
      "[7551]\ttraining's binary_logloss: 0.118374\n",
      "[7552]\ttraining's binary_logloss: 0.118364\n",
      "[7553]\ttraining's binary_logloss: 0.11835\n",
      "[7554]\ttraining's binary_logloss: 0.118345\n",
      "[7555]\ttraining's binary_logloss: 0.118336\n",
      "[7556]\ttraining's binary_logloss: 0.118326\n",
      "[7557]\ttraining's binary_logloss: 0.118324\n",
      "[7558]\ttraining's binary_logloss: 0.118314\n",
      "[7559]\ttraining's binary_logloss: 0.118303\n",
      "[7560]\ttraining's binary_logloss: 0.118294\n",
      "[7561]\ttraining's binary_logloss: 0.118288\n",
      "[7562]\ttraining's binary_logloss: 0.118282\n",
      "[7563]\ttraining's binary_logloss: 0.118272\n",
      "[7564]\ttraining's binary_logloss: 0.11826\n",
      "[7565]\ttraining's binary_logloss: 0.118253\n",
      "[7566]\ttraining's binary_logloss: 0.11824\n",
      "[7567]\ttraining's binary_logloss: 0.118235\n",
      "[7568]\ttraining's binary_logloss: 0.118225\n",
      "[7569]\ttraining's binary_logloss: 0.118212\n",
      "[7570]\ttraining's binary_logloss: 0.118201\n",
      "[7571]\ttraining's binary_logloss: 0.118199\n",
      "[7572]\ttraining's binary_logloss: 0.118187\n",
      "[7573]\ttraining's binary_logloss: 0.118176\n",
      "[7574]\ttraining's binary_logloss: 0.118166\n",
      "[7575]\ttraining's binary_logloss: 0.118154\n",
      "[7576]\ttraining's binary_logloss: 0.118144\n",
      "[7577]\ttraining's binary_logloss: 0.118134\n",
      "[7578]\ttraining's binary_logloss: 0.118118\n",
      "[7579]\ttraining's binary_logloss: 0.118111\n",
      "[7580]\ttraining's binary_logloss: 0.118108\n",
      "[7581]\ttraining's binary_logloss: 0.118096\n",
      "[7582]\ttraining's binary_logloss: 0.118089\n",
      "[7583]\ttraining's binary_logloss: 0.118086\n",
      "[7584]\ttraining's binary_logloss: 0.118077\n",
      "[7585]\ttraining's binary_logloss: 0.11807\n",
      "[7586]\ttraining's binary_logloss: 0.118064\n",
      "[7587]\ttraining's binary_logloss: 0.118053\n",
      "[7588]\ttraining's binary_logloss: 0.11805\n",
      "[7589]\ttraining's binary_logloss: 0.118038\n",
      "[7590]\ttraining's binary_logloss: 0.118036\n",
      "[7591]\ttraining's binary_logloss: 0.118026\n",
      "[7592]\ttraining's binary_logloss: 0.118023\n",
      "[7593]\ttraining's binary_logloss: 0.118009\n",
      "[7594]\ttraining's binary_logloss: 0.118003\n",
      "[7595]\ttraining's binary_logloss: 0.118002\n",
      "[7596]\ttraining's binary_logloss: 0.11799\n",
      "[7597]\ttraining's binary_logloss: 0.117979\n",
      "[7598]\ttraining's binary_logloss: 0.117968\n",
      "[7599]\ttraining's binary_logloss: 0.117956\n",
      "[7600]\ttraining's binary_logloss: 0.117947\n",
      "[7601]\ttraining's binary_logloss: 0.117931\n",
      "[7602]\ttraining's binary_logloss: 0.117921\n",
      "[7603]\ttraining's binary_logloss: 0.117908\n",
      "[7604]\ttraining's binary_logloss: 0.117897\n",
      "[7605]\ttraining's binary_logloss: 0.117888\n",
      "[7606]\ttraining's binary_logloss: 0.117876\n",
      "[7607]\ttraining's binary_logloss: 0.117866\n",
      "[7608]\ttraining's binary_logloss: 0.117863\n",
      "[7609]\ttraining's binary_logloss: 0.117851\n",
      "[7610]\ttraining's binary_logloss: 0.117839\n",
      "[7611]\ttraining's binary_logloss: 0.117829\n",
      "[7612]\ttraining's binary_logloss: 0.117821\n",
      "[7613]\ttraining's binary_logloss: 0.117813\n",
      "[7614]\ttraining's binary_logloss: 0.117801\n",
      "[7615]\ttraining's binary_logloss: 0.117798\n",
      "[7616]\ttraining's binary_logloss: 0.117786\n",
      "[7617]\ttraining's binary_logloss: 0.117774\n",
      "[7618]\ttraining's binary_logloss: 0.117765\n",
      "[7619]\ttraining's binary_logloss: 0.117757\n",
      "[7620]\ttraining's binary_logloss: 0.11775\n",
      "[7621]\ttraining's binary_logloss: 0.117747\n",
      "[7622]\ttraining's binary_logloss: 0.117741\n",
      "[7623]\ttraining's binary_logloss: 0.117733\n",
      "[7624]\ttraining's binary_logloss: 0.117725\n",
      "[7625]\ttraining's binary_logloss: 0.117713\n",
      "[7626]\ttraining's binary_logloss: 0.117704\n",
      "[7627]\ttraining's binary_logloss: 0.117695\n",
      "[7628]\ttraining's binary_logloss: 0.117685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7629]\ttraining's binary_logloss: 0.117677\n",
      "[7630]\ttraining's binary_logloss: 0.117668\n",
      "[7631]\ttraining's binary_logloss: 0.117659\n",
      "[7632]\ttraining's binary_logloss: 0.117651\n",
      "[7633]\ttraining's binary_logloss: 0.11765\n",
      "[7634]\ttraining's binary_logloss: 0.117638\n",
      "[7635]\ttraining's binary_logloss: 0.117627\n",
      "[7636]\ttraining's binary_logloss: 0.117618\n",
      "[7637]\ttraining's binary_logloss: 0.117607\n",
      "[7638]\ttraining's binary_logloss: 0.117596\n",
      "[7639]\ttraining's binary_logloss: 0.117585\n",
      "[7640]\ttraining's binary_logloss: 0.117575\n",
      "[7641]\ttraining's binary_logloss: 0.117565\n",
      "[7642]\ttraining's binary_logloss: 0.117562\n",
      "[7643]\ttraining's binary_logloss: 0.117551\n",
      "[7644]\ttraining's binary_logloss: 0.11754\n",
      "[7645]\ttraining's binary_logloss: 0.117527\n",
      "[7646]\ttraining's binary_logloss: 0.117517\n",
      "[7647]\ttraining's binary_logloss: 0.117514\n",
      "[7648]\ttraining's binary_logloss: 0.117503\n",
      "[7649]\ttraining's binary_logloss: 0.117494\n",
      "[7650]\ttraining's binary_logloss: 0.117484\n",
      "[7651]\ttraining's binary_logloss: 0.117478\n",
      "[7652]\ttraining's binary_logloss: 0.117467\n",
      "[7653]\ttraining's binary_logloss: 0.117459\n",
      "[7654]\ttraining's binary_logloss: 0.11745\n",
      "[7655]\ttraining's binary_logloss: 0.117439\n",
      "[7656]\ttraining's binary_logloss: 0.11743\n",
      "[7657]\ttraining's binary_logloss: 0.117418\n",
      "[7658]\ttraining's binary_logloss: 0.117407\n",
      "[7659]\ttraining's binary_logloss: 0.117399\n",
      "[7660]\ttraining's binary_logloss: 0.117392\n",
      "[7661]\ttraining's binary_logloss: 0.117386\n",
      "[7662]\ttraining's binary_logloss: 0.117376\n",
      "[7663]\ttraining's binary_logloss: 0.117365\n",
      "[7664]\ttraining's binary_logloss: 0.117353\n",
      "[7665]\ttraining's binary_logloss: 0.11734\n",
      "[7666]\ttraining's binary_logloss: 0.11733\n",
      "[7667]\ttraining's binary_logloss: 0.117328\n",
      "[7668]\ttraining's binary_logloss: 0.117326\n",
      "[7669]\ttraining's binary_logloss: 0.117318\n",
      "[7670]\ttraining's binary_logloss: 0.117308\n",
      "[7671]\ttraining's binary_logloss: 0.117305\n",
      "[7672]\ttraining's binary_logloss: 0.1173\n",
      "[7673]\ttraining's binary_logloss: 0.117289\n",
      "[7674]\ttraining's binary_logloss: 0.117282\n",
      "[7675]\ttraining's binary_logloss: 0.117279\n",
      "[7676]\ttraining's binary_logloss: 0.117278\n",
      "[7677]\ttraining's binary_logloss: 0.117267\n",
      "[7678]\ttraining's binary_logloss: 0.117258\n",
      "[7679]\ttraining's binary_logloss: 0.117256\n",
      "[7680]\ttraining's binary_logloss: 0.117247\n",
      "[7681]\ttraining's binary_logloss: 0.117237\n",
      "[7682]\ttraining's binary_logloss: 0.117225\n",
      "[7683]\ttraining's binary_logloss: 0.117222\n",
      "[7684]\ttraining's binary_logloss: 0.117213\n",
      "[7685]\ttraining's binary_logloss: 0.117202\n",
      "[7686]\ttraining's binary_logloss: 0.117191\n",
      "[7687]\ttraining's binary_logloss: 0.117181\n",
      "[7688]\ttraining's binary_logloss: 0.117174\n",
      "[7689]\ttraining's binary_logloss: 0.117163\n",
      "[7690]\ttraining's binary_logloss: 0.117155\n",
      "[7691]\ttraining's binary_logloss: 0.117145\n",
      "[7692]\ttraining's binary_logloss: 0.117134\n",
      "[7693]\ttraining's binary_logloss: 0.117127\n",
      "[7694]\ttraining's binary_logloss: 0.117119\n",
      "[7695]\ttraining's binary_logloss: 0.117114\n",
      "[7696]\ttraining's binary_logloss: 0.117104\n",
      "[7697]\ttraining's binary_logloss: 0.117093\n",
      "[7698]\ttraining's binary_logloss: 0.11709\n",
      "[7699]\ttraining's binary_logloss: 0.117088\n",
      "[7700]\ttraining's binary_logloss: 0.117077\n",
      "[7701]\ttraining's binary_logloss: 0.117067\n",
      "[7702]\ttraining's binary_logloss: 0.117056\n",
      "[7703]\ttraining's binary_logloss: 0.117054\n",
      "[7704]\ttraining's binary_logloss: 0.117042\n",
      "[7705]\ttraining's binary_logloss: 0.117037\n",
      "[7706]\ttraining's binary_logloss: 0.117027\n",
      "[7707]\ttraining's binary_logloss: 0.117025\n",
      "[7708]\ttraining's binary_logloss: 0.117023\n",
      "[7709]\ttraining's binary_logloss: 0.117013\n",
      "[7710]\ttraining's binary_logloss: 0.117002\n",
      "[7711]\ttraining's binary_logloss: 0.116999\n",
      "[7712]\ttraining's binary_logloss: 0.11699\n",
      "[7713]\ttraining's binary_logloss: 0.11698\n",
      "[7714]\ttraining's binary_logloss: 0.116972\n",
      "[7715]\ttraining's binary_logloss: 0.116961\n",
      "[7716]\ttraining's binary_logloss: 0.116949\n",
      "[7717]\ttraining's binary_logloss: 0.11694\n",
      "[7718]\ttraining's binary_logloss: 0.116929\n",
      "[7719]\ttraining's binary_logloss: 0.116921\n",
      "[7720]\ttraining's binary_logloss: 0.116909\n",
      "[7721]\ttraining's binary_logloss: 0.116899\n",
      "[7722]\ttraining's binary_logloss: 0.116887\n",
      "[7723]\ttraining's binary_logloss: 0.116877\n",
      "[7724]\ttraining's binary_logloss: 0.116866\n",
      "[7725]\ttraining's binary_logloss: 0.116856\n",
      "[7726]\ttraining's binary_logloss: 0.116846\n",
      "[7727]\ttraining's binary_logloss: 0.116837\n",
      "[7728]\ttraining's binary_logloss: 0.11683\n",
      "[7729]\ttraining's binary_logloss: 0.116827\n",
      "[7730]\ttraining's binary_logloss: 0.116817\n",
      "[7731]\ttraining's binary_logloss: 0.116814\n",
      "[7732]\ttraining's binary_logloss: 0.116804\n",
      "[7733]\ttraining's binary_logloss: 0.116794\n",
      "[7734]\ttraining's binary_logloss: 0.116785\n",
      "[7735]\ttraining's binary_logloss: 0.116775\n",
      "[7736]\ttraining's binary_logloss: 0.116765\n",
      "[7737]\ttraining's binary_logloss: 0.116755\n",
      "[7738]\ttraining's binary_logloss: 0.116742\n",
      "[7739]\ttraining's binary_logloss: 0.116733\n",
      "[7740]\ttraining's binary_logloss: 0.116723\n",
      "[7741]\ttraining's binary_logloss: 0.116714\n",
      "[7742]\ttraining's binary_logloss: 0.116711\n",
      "[7743]\ttraining's binary_logloss: 0.116702\n",
      "[7744]\ttraining's binary_logloss: 0.116691\n",
      "[7745]\ttraining's binary_logloss: 0.116681\n",
      "[7746]\ttraining's binary_logloss: 0.11667\n",
      "[7747]\ttraining's binary_logloss: 0.116659\n",
      "[7748]\ttraining's binary_logloss: 0.116648\n",
      "[7749]\ttraining's binary_logloss: 0.116646\n",
      "[7750]\ttraining's binary_logloss: 0.116643\n",
      "[7751]\ttraining's binary_logloss: 0.116639\n",
      "[7752]\ttraining's binary_logloss: 0.116628\n",
      "[7753]\ttraining's binary_logloss: 0.116626\n",
      "[7754]\ttraining's binary_logloss: 0.116614\n",
      "[7755]\ttraining's binary_logloss: 0.116606\n",
      "[7756]\ttraining's binary_logloss: 0.116597\n",
      "[7757]\ttraining's binary_logloss: 0.11659\n",
      "[7758]\ttraining's binary_logloss: 0.116578\n",
      "[7759]\ttraining's binary_logloss: 0.116568\n",
      "[7760]\ttraining's binary_logloss: 0.116554\n",
      "[7761]\ttraining's binary_logloss: 0.116542\n",
      "[7762]\ttraining's binary_logloss: 0.116531\n",
      "[7763]\ttraining's binary_logloss: 0.116521\n",
      "[7764]\ttraining's binary_logloss: 0.11651\n",
      "[7765]\ttraining's binary_logloss: 0.116498\n",
      "[7766]\ttraining's binary_logloss: 0.116492\n",
      "[7767]\ttraining's binary_logloss: 0.116481\n",
      "[7768]\ttraining's binary_logloss: 0.116469\n",
      "[7769]\ttraining's binary_logloss: 0.116459\n",
      "[7770]\ttraining's binary_logloss: 0.116447\n",
      "[7771]\ttraining's binary_logloss: 0.116437\n",
      "[7772]\ttraining's binary_logloss: 0.116429\n",
      "[7773]\ttraining's binary_logloss: 0.116421\n",
      "[7774]\ttraining's binary_logloss: 0.11641\n",
      "[7775]\ttraining's binary_logloss: 0.1164\n",
      "[7776]\ttraining's binary_logloss: 0.116389\n",
      "[7777]\ttraining's binary_logloss: 0.11638\n",
      "[7778]\ttraining's binary_logloss: 0.116376\n",
      "[7779]\ttraining's binary_logloss: 0.116366\n",
      "[7780]\ttraining's binary_logloss: 0.116355\n",
      "[7781]\ttraining's binary_logloss: 0.116344\n",
      "[7782]\ttraining's binary_logloss: 0.116334\n",
      "[7783]\ttraining's binary_logloss: 0.116324\n",
      "[7784]\ttraining's binary_logloss: 0.116314\n",
      "[7785]\ttraining's binary_logloss: 0.116311\n",
      "[7786]\ttraining's binary_logloss: 0.116301\n",
      "[7787]\ttraining's binary_logloss: 0.116291\n",
      "[7788]\ttraining's binary_logloss: 0.116279\n",
      "[7789]\ttraining's binary_logloss: 0.116268\n",
      "[7790]\ttraining's binary_logloss: 0.116257\n",
      "[7791]\ttraining's binary_logloss: 0.116246\n",
      "[7792]\ttraining's binary_logloss: 0.116235\n",
      "[7793]\ttraining's binary_logloss: 0.116224\n",
      "[7794]\ttraining's binary_logloss: 0.116222\n",
      "[7795]\ttraining's binary_logloss: 0.116216\n",
      "[7796]\ttraining's binary_logloss: 0.116206\n",
      "[7797]\ttraining's binary_logloss: 0.116197\n",
      "[7798]\ttraining's binary_logloss: 0.116186\n",
      "[7799]\ttraining's binary_logloss: 0.116175\n",
      "[7800]\ttraining's binary_logloss: 0.116165\n",
      "[7801]\ttraining's binary_logloss: 0.116159\n",
      "[7802]\ttraining's binary_logloss: 0.116149\n",
      "[7803]\ttraining's binary_logloss: 0.116138\n",
      "[7804]\ttraining's binary_logloss: 0.116128\n",
      "[7805]\ttraining's binary_logloss: 0.116119\n",
      "[7806]\ttraining's binary_logloss: 0.116108\n",
      "[7807]\ttraining's binary_logloss: 0.116097\n",
      "[7808]\ttraining's binary_logloss: 0.116089\n",
      "[7809]\ttraining's binary_logloss: 0.11608\n",
      "[7810]\ttraining's binary_logloss: 0.11607\n",
      "[7811]\ttraining's binary_logloss: 0.116064\n",
      "[7812]\ttraining's binary_logloss: 0.116055\n",
      "[7813]\ttraining's binary_logloss: 0.116045\n",
      "[7814]\ttraining's binary_logloss: 0.116034\n",
      "[7815]\ttraining's binary_logloss: 0.11602\n",
      "[7816]\ttraining's binary_logloss: 0.116008\n",
      "[7817]\ttraining's binary_logloss: 0.115997\n",
      "[7818]\ttraining's binary_logloss: 0.115986\n",
      "[7819]\ttraining's binary_logloss: 0.115974\n",
      "[7820]\ttraining's binary_logloss: 0.115963\n",
      "[7821]\ttraining's binary_logloss: 0.115954\n",
      "[7822]\ttraining's binary_logloss: 0.115945\n",
      "[7823]\ttraining's binary_logloss: 0.115934\n",
      "[7824]\ttraining's binary_logloss: 0.115927\n",
      "[7825]\ttraining's binary_logloss: 0.115923\n",
      "[7826]\ttraining's binary_logloss: 0.115911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7827]\ttraining's binary_logloss: 0.115901\n",
      "[7828]\ttraining's binary_logloss: 0.115894\n",
      "[7829]\ttraining's binary_logloss: 0.115882\n",
      "[7830]\ttraining's binary_logloss: 0.115879\n",
      "[7831]\ttraining's binary_logloss: 0.115869\n",
      "[7832]\ttraining's binary_logloss: 0.115856\n",
      "[7833]\ttraining's binary_logloss: 0.115845\n",
      "[7834]\ttraining's binary_logloss: 0.115832\n",
      "[7835]\ttraining's binary_logloss: 0.115825\n",
      "[7836]\ttraining's binary_logloss: 0.115814\n",
      "[7837]\ttraining's binary_logloss: 0.115809\n",
      "[7838]\ttraining's binary_logloss: 0.115795\n",
      "[7839]\ttraining's binary_logloss: 0.115785\n",
      "[7840]\ttraining's binary_logloss: 0.115777\n",
      "[7841]\ttraining's binary_logloss: 0.115765\n",
      "[7842]\ttraining's binary_logloss: 0.115752\n",
      "[7843]\ttraining's binary_logloss: 0.115747\n",
      "[7844]\ttraining's binary_logloss: 0.115735\n",
      "[7845]\ttraining's binary_logloss: 0.115732\n",
      "[7846]\ttraining's binary_logloss: 0.115727\n",
      "[7847]\ttraining's binary_logloss: 0.115716\n",
      "[7848]\ttraining's binary_logloss: 0.115707\n",
      "[7849]\ttraining's binary_logloss: 0.1157\n",
      "[7850]\ttraining's binary_logloss: 0.115688\n",
      "[7851]\ttraining's binary_logloss: 0.115684\n",
      "[7852]\ttraining's binary_logloss: 0.115679\n",
      "[7853]\ttraining's binary_logloss: 0.115672\n",
      "[7854]\ttraining's binary_logloss: 0.115661\n",
      "[7855]\ttraining's binary_logloss: 0.115657\n",
      "[7856]\ttraining's binary_logloss: 0.115654\n",
      "[7857]\ttraining's binary_logloss: 0.115643\n",
      "[7858]\ttraining's binary_logloss: 0.115633\n",
      "[7859]\ttraining's binary_logloss: 0.115624\n",
      "[7860]\ttraining's binary_logloss: 0.115617\n",
      "[7861]\ttraining's binary_logloss: 0.115607\n",
      "[7862]\ttraining's binary_logloss: 0.115595\n",
      "[7863]\ttraining's binary_logloss: 0.115584\n",
      "[7864]\ttraining's binary_logloss: 0.115575\n",
      "[7865]\ttraining's binary_logloss: 0.115568\n",
      "[7866]\ttraining's binary_logloss: 0.115558\n",
      "[7867]\ttraining's binary_logloss: 0.115547\n",
      "[7868]\ttraining's binary_logloss: 0.115536\n",
      "[7869]\ttraining's binary_logloss: 0.115527\n",
      "[7870]\ttraining's binary_logloss: 0.115518\n",
      "[7871]\ttraining's binary_logloss: 0.115507\n",
      "[7872]\ttraining's binary_logloss: 0.115496\n",
      "[7873]\ttraining's binary_logloss: 0.115492\n",
      "[7874]\ttraining's binary_logloss: 0.115482\n",
      "[7875]\ttraining's binary_logloss: 0.115473\n",
      "[7876]\ttraining's binary_logloss: 0.115462\n",
      "[7877]\ttraining's binary_logloss: 0.115452\n",
      "[7878]\ttraining's binary_logloss: 0.11544\n",
      "[7879]\ttraining's binary_logloss: 0.115429\n",
      "[7880]\ttraining's binary_logloss: 0.115417\n",
      "[7881]\ttraining's binary_logloss: 0.115407\n",
      "[7882]\ttraining's binary_logloss: 0.115396\n",
      "[7883]\ttraining's binary_logloss: 0.115387\n",
      "[7884]\ttraining's binary_logloss: 0.115379\n",
      "[7885]\ttraining's binary_logloss: 0.115371\n",
      "[7886]\ttraining's binary_logloss: 0.115362\n",
      "[7887]\ttraining's binary_logloss: 0.115352\n",
      "[7888]\ttraining's binary_logloss: 0.115343\n",
      "[7889]\ttraining's binary_logloss: 0.115332\n",
      "[7890]\ttraining's binary_logloss: 0.115321\n",
      "[7891]\ttraining's binary_logloss: 0.11531\n",
      "[7892]\ttraining's binary_logloss: 0.115301\n",
      "[7893]\ttraining's binary_logloss: 0.115293\n",
      "[7894]\ttraining's binary_logloss: 0.115283\n",
      "[7895]\ttraining's binary_logloss: 0.115274\n",
      "[7896]\ttraining's binary_logloss: 0.115269\n",
      "[7897]\ttraining's binary_logloss: 0.115258\n",
      "[7898]\ttraining's binary_logloss: 0.115247\n",
      "[7899]\ttraining's binary_logloss: 0.115238\n",
      "[7900]\ttraining's binary_logloss: 0.115227\n",
      "[7901]\ttraining's binary_logloss: 0.115222\n",
      "[7902]\ttraining's binary_logloss: 0.115211\n",
      "[7903]\ttraining's binary_logloss: 0.115203\n",
      "[7904]\ttraining's binary_logloss: 0.115193\n",
      "[7905]\ttraining's binary_logloss: 0.115187\n",
      "[7906]\ttraining's binary_logloss: 0.115176\n",
      "[7907]\ttraining's binary_logloss: 0.115165\n",
      "[7908]\ttraining's binary_logloss: 0.115155\n",
      "[7909]\ttraining's binary_logloss: 0.115143\n",
      "[7910]\ttraining's binary_logloss: 0.115136\n",
      "[7911]\ttraining's binary_logloss: 0.115125\n",
      "[7912]\ttraining's binary_logloss: 0.115112\n",
      "[7913]\ttraining's binary_logloss: 0.115105\n",
      "[7914]\ttraining's binary_logloss: 0.115096\n",
      "[7915]\ttraining's binary_logloss: 0.115087\n",
      "[7916]\ttraining's binary_logloss: 0.115077\n",
      "[7917]\ttraining's binary_logloss: 0.115067\n",
      "[7918]\ttraining's binary_logloss: 0.115058\n",
      "[7919]\ttraining's binary_logloss: 0.115047\n",
      "[7920]\ttraining's binary_logloss: 0.11504\n",
      "[7921]\ttraining's binary_logloss: 0.11503\n",
      "[7922]\ttraining's binary_logloss: 0.115022\n",
      "[7923]\ttraining's binary_logloss: 0.115011\n",
      "[7924]\ttraining's binary_logloss: 0.115002\n",
      "[7925]\ttraining's binary_logloss: 0.11499\n",
      "[7926]\ttraining's binary_logloss: 0.114981\n",
      "[7927]\ttraining's binary_logloss: 0.114969\n",
      "[7928]\ttraining's binary_logloss: 0.114967\n",
      "[7929]\ttraining's binary_logloss: 0.114964\n",
      "[7930]\ttraining's binary_logloss: 0.114955\n",
      "[7931]\ttraining's binary_logloss: 0.114949\n",
      "[7932]\ttraining's binary_logloss: 0.114948\n",
      "[7933]\ttraining's binary_logloss: 0.114937\n",
      "[7934]\ttraining's binary_logloss: 0.114935\n",
      "[7935]\ttraining's binary_logloss: 0.114922\n",
      "[7936]\ttraining's binary_logloss: 0.114913\n",
      "[7937]\ttraining's binary_logloss: 0.114908\n",
      "[7938]\ttraining's binary_logloss: 0.114907\n",
      "[7939]\ttraining's binary_logloss: 0.114897\n",
      "[7940]\ttraining's binary_logloss: 0.114894\n",
      "[7941]\ttraining's binary_logloss: 0.114884\n",
      "[7942]\ttraining's binary_logloss: 0.114874\n",
      "[7943]\ttraining's binary_logloss: 0.114864\n",
      "[7944]\ttraining's binary_logloss: 0.114856\n",
      "[7945]\ttraining's binary_logloss: 0.114845\n",
      "[7946]\ttraining's binary_logloss: 0.114835\n",
      "[7947]\ttraining's binary_logloss: 0.114825\n",
      "[7948]\ttraining's binary_logloss: 0.114815\n",
      "[7949]\ttraining's binary_logloss: 0.114804\n",
      "[7950]\ttraining's binary_logloss: 0.114792\n",
      "[7951]\ttraining's binary_logloss: 0.11478\n",
      "[7952]\ttraining's binary_logloss: 0.114771\n",
      "[7953]\ttraining's binary_logloss: 0.114761\n",
      "[7954]\ttraining's binary_logloss: 0.114754\n",
      "[7955]\ttraining's binary_logloss: 0.114743\n",
      "[7956]\ttraining's binary_logloss: 0.114733\n",
      "[7957]\ttraining's binary_logloss: 0.114723\n",
      "[7958]\ttraining's binary_logloss: 0.114712\n",
      "[7959]\ttraining's binary_logloss: 0.114703\n",
      "[7960]\ttraining's binary_logloss: 0.114692\n",
      "[7961]\ttraining's binary_logloss: 0.114686\n",
      "[7962]\ttraining's binary_logloss: 0.114682\n",
      "[7963]\ttraining's binary_logloss: 0.114674\n",
      "[7964]\ttraining's binary_logloss: 0.114673\n",
      "[7965]\ttraining's binary_logloss: 0.114663\n",
      "[7966]\ttraining's binary_logloss: 0.114652\n",
      "[7967]\ttraining's binary_logloss: 0.114643\n",
      "[7968]\ttraining's binary_logloss: 0.114632\n",
      "[7969]\ttraining's binary_logloss: 0.114622\n",
      "[7970]\ttraining's binary_logloss: 0.114615\n",
      "[7971]\ttraining's binary_logloss: 0.114607\n",
      "[7972]\ttraining's binary_logloss: 0.114598\n",
      "[7973]\ttraining's binary_logloss: 0.114588\n",
      "[7974]\ttraining's binary_logloss: 0.114585\n",
      "[7975]\ttraining's binary_logloss: 0.114576\n",
      "[7976]\ttraining's binary_logloss: 0.114567\n",
      "[7977]\ttraining's binary_logloss: 0.114557\n",
      "[7978]\ttraining's binary_logloss: 0.114546\n",
      "[7979]\ttraining's binary_logloss: 0.114543\n",
      "[7980]\ttraining's binary_logloss: 0.114534\n",
      "[7981]\ttraining's binary_logloss: 0.114525\n",
      "[7982]\ttraining's binary_logloss: 0.114518\n",
      "[7983]\ttraining's binary_logloss: 0.114509\n",
      "[7984]\ttraining's binary_logloss: 0.114508\n",
      "[7985]\ttraining's binary_logloss: 0.114507\n",
      "[7986]\ttraining's binary_logloss: 0.114496\n",
      "[7987]\ttraining's binary_logloss: 0.114488\n",
      "[7988]\ttraining's binary_logloss: 0.114477\n",
      "[7989]\ttraining's binary_logloss: 0.114466\n",
      "[7990]\ttraining's binary_logloss: 0.114457\n",
      "[7991]\ttraining's binary_logloss: 0.114447\n",
      "[7992]\ttraining's binary_logloss: 0.114436\n",
      "[7993]\ttraining's binary_logloss: 0.114427\n",
      "[7994]\ttraining's binary_logloss: 0.114419\n",
      "[7995]\ttraining's binary_logloss: 0.11441\n",
      "[7996]\ttraining's binary_logloss: 0.114401\n",
      "[7997]\ttraining's binary_logloss: 0.11439\n",
      "[7998]\ttraining's binary_logloss: 0.114383\n",
      "[7999]\ttraining's binary_logloss: 0.114373\n",
      "[8000]\ttraining's binary_logloss: 0.114368\n",
      "[8001]\ttraining's binary_logloss: 0.114367\n",
      "[8002]\ttraining's binary_logloss: 0.114358\n",
      "[8003]\ttraining's binary_logloss: 0.114348\n",
      "[8004]\ttraining's binary_logloss: 0.114336\n",
      "[8005]\ttraining's binary_logloss: 0.114326\n",
      "[8006]\ttraining's binary_logloss: 0.114324\n",
      "[8007]\ttraining's binary_logloss: 0.114315\n",
      "[8008]\ttraining's binary_logloss: 0.114304\n",
      "[8009]\ttraining's binary_logloss: 0.114296\n",
      "[8010]\ttraining's binary_logloss: 0.114287\n",
      "[8011]\ttraining's binary_logloss: 0.114275\n",
      "[8012]\ttraining's binary_logloss: 0.114266\n",
      "[8013]\ttraining's binary_logloss: 0.114255\n",
      "[8014]\ttraining's binary_logloss: 0.114245\n",
      "[8015]\ttraining's binary_logloss: 0.114235\n",
      "[8016]\ttraining's binary_logloss: 0.114224\n",
      "[8017]\ttraining's binary_logloss: 0.114214\n",
      "[8018]\ttraining's binary_logloss: 0.114201\n",
      "[8019]\ttraining's binary_logloss: 0.114193\n",
      "[8020]\ttraining's binary_logloss: 0.11419\n",
      "[8021]\ttraining's binary_logloss: 0.114183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8022]\ttraining's binary_logloss: 0.114172\n",
      "[8023]\ttraining's binary_logloss: 0.114161\n",
      "[8024]\ttraining's binary_logloss: 0.114153\n",
      "[8025]\ttraining's binary_logloss: 0.114142\n",
      "[8026]\ttraining's binary_logloss: 0.114132\n",
      "[8027]\ttraining's binary_logloss: 0.114122\n",
      "[8028]\ttraining's binary_logloss: 0.114113\n",
      "[8029]\ttraining's binary_logloss: 0.114102\n",
      "[8030]\ttraining's binary_logloss: 0.114091\n",
      "[8031]\ttraining's binary_logloss: 0.11408\n",
      "[8032]\ttraining's binary_logloss: 0.114075\n",
      "[8033]\ttraining's binary_logloss: 0.114065\n",
      "[8034]\ttraining's binary_logloss: 0.114058\n",
      "[8035]\ttraining's binary_logloss: 0.114046\n",
      "[8036]\ttraining's binary_logloss: 0.114034\n",
      "[8037]\ttraining's binary_logloss: 0.114029\n",
      "[8038]\ttraining's binary_logloss: 0.114024\n",
      "[8039]\ttraining's binary_logloss: 0.114013\n",
      "[8040]\ttraining's binary_logloss: 0.114003\n",
      "[8041]\ttraining's binary_logloss: 0.113997\n",
      "[8042]\ttraining's binary_logloss: 0.113987\n",
      "[8043]\ttraining's binary_logloss: 0.113976\n",
      "[8044]\ttraining's binary_logloss: 0.113966\n",
      "[8045]\ttraining's binary_logloss: 0.113954\n",
      "[8046]\ttraining's binary_logloss: 0.113945\n",
      "[8047]\ttraining's binary_logloss: 0.113936\n",
      "[8048]\ttraining's binary_logloss: 0.113927\n",
      "[8049]\ttraining's binary_logloss: 0.113918\n",
      "[8050]\ttraining's binary_logloss: 0.113909\n",
      "[8051]\ttraining's binary_logloss: 0.1139\n",
      "[8052]\ttraining's binary_logloss: 0.113892\n",
      "[8053]\ttraining's binary_logloss: 0.113885\n",
      "[8054]\ttraining's binary_logloss: 0.113878\n",
      "[8055]\ttraining's binary_logloss: 0.113867\n",
      "[8056]\ttraining's binary_logloss: 0.113856\n",
      "[8057]\ttraining's binary_logloss: 0.113847\n",
      "[8058]\ttraining's binary_logloss: 0.113838\n",
      "[8059]\ttraining's binary_logloss: 0.113829\n",
      "[8060]\ttraining's binary_logloss: 0.113823\n",
      "[8061]\ttraining's binary_logloss: 0.113811\n",
      "[8062]\ttraining's binary_logloss: 0.113805\n",
      "[8063]\ttraining's binary_logloss: 0.113796\n",
      "[8064]\ttraining's binary_logloss: 0.113787\n",
      "[8065]\ttraining's binary_logloss: 0.113784\n",
      "[8066]\ttraining's binary_logloss: 0.113773\n",
      "[8067]\ttraining's binary_logloss: 0.113766\n",
      "[8068]\ttraining's binary_logloss: 0.113754\n",
      "[8069]\ttraining's binary_logloss: 0.113744\n",
      "[8070]\ttraining's binary_logloss: 0.113732\n",
      "[8071]\ttraining's binary_logloss: 0.113722\n",
      "[8072]\ttraining's binary_logloss: 0.113718\n",
      "[8073]\ttraining's binary_logloss: 0.113707\n",
      "[8074]\ttraining's binary_logloss: 0.113696\n",
      "[8075]\ttraining's binary_logloss: 0.113685\n",
      "[8076]\ttraining's binary_logloss: 0.113674\n",
      "[8077]\ttraining's binary_logloss: 0.113663\n",
      "[8078]\ttraining's binary_logloss: 0.113652\n",
      "[8079]\ttraining's binary_logloss: 0.113641\n",
      "[8080]\ttraining's binary_logloss: 0.113631\n",
      "[8081]\ttraining's binary_logloss: 0.113623\n",
      "[8082]\ttraining's binary_logloss: 0.113613\n",
      "[8083]\ttraining's binary_logloss: 0.113601\n",
      "[8084]\ttraining's binary_logloss: 0.113594\n",
      "[8085]\ttraining's binary_logloss: 0.113584\n",
      "[8086]\ttraining's binary_logloss: 0.113574\n",
      "[8087]\ttraining's binary_logloss: 0.113563\n",
      "[8088]\ttraining's binary_logloss: 0.113554\n",
      "[8089]\ttraining's binary_logloss: 0.113545\n",
      "[8090]\ttraining's binary_logloss: 0.113536\n",
      "[8091]\ttraining's binary_logloss: 0.113526\n",
      "[8092]\ttraining's binary_logloss: 0.113525\n",
      "[8093]\ttraining's binary_logloss: 0.113514\n",
      "[8094]\ttraining's binary_logloss: 0.113504\n",
      "[8095]\ttraining's binary_logloss: 0.113493\n",
      "[8096]\ttraining's binary_logloss: 0.113483\n",
      "[8097]\ttraining's binary_logloss: 0.113473\n",
      "[8098]\ttraining's binary_logloss: 0.113466\n",
      "[8099]\ttraining's binary_logloss: 0.113463\n",
      "[8100]\ttraining's binary_logloss: 0.113457\n",
      "[8101]\ttraining's binary_logloss: 0.113444\n",
      "[8102]\ttraining's binary_logloss: 0.113434\n",
      "[8103]\ttraining's binary_logloss: 0.113423\n",
      "[8104]\ttraining's binary_logloss: 0.113412\n",
      "[8105]\ttraining's binary_logloss: 0.113409\n",
      "[8106]\ttraining's binary_logloss: 0.113399\n",
      "[8107]\ttraining's binary_logloss: 0.113389\n",
      "[8108]\ttraining's binary_logloss: 0.113378\n",
      "[8109]\ttraining's binary_logloss: 0.113372\n",
      "[8110]\ttraining's binary_logloss: 0.113359\n",
      "[8111]\ttraining's binary_logloss: 0.113349\n",
      "[8112]\ttraining's binary_logloss: 0.113339\n",
      "[8113]\ttraining's binary_logloss: 0.113328\n",
      "[8114]\ttraining's binary_logloss: 0.113319\n",
      "[8115]\ttraining's binary_logloss: 0.113309\n",
      "[8116]\ttraining's binary_logloss: 0.1133\n",
      "[8117]\ttraining's binary_logloss: 0.113293\n",
      "[8118]\ttraining's binary_logloss: 0.113286\n",
      "[8119]\ttraining's binary_logloss: 0.113281\n",
      "[8120]\ttraining's binary_logloss: 0.113277\n",
      "[8121]\ttraining's binary_logloss: 0.113268\n",
      "[8122]\ttraining's binary_logloss: 0.113256\n",
      "[8123]\ttraining's binary_logloss: 0.113246\n",
      "[8124]\ttraining's binary_logloss: 0.113236\n",
      "[8125]\ttraining's binary_logloss: 0.113226\n",
      "[8126]\ttraining's binary_logloss: 0.113215\n",
      "[8127]\ttraining's binary_logloss: 0.113204\n",
      "[8128]\ttraining's binary_logloss: 0.113197\n",
      "[8129]\ttraining's binary_logloss: 0.113186\n",
      "[8130]\ttraining's binary_logloss: 0.113176\n",
      "[8131]\ttraining's binary_logloss: 0.113169\n",
      "[8132]\ttraining's binary_logloss: 0.11316\n",
      "[8133]\ttraining's binary_logloss: 0.113149\n",
      "[8134]\ttraining's binary_logloss: 0.113138\n",
      "[8135]\ttraining's binary_logloss: 0.11313\n",
      "[8136]\ttraining's binary_logloss: 0.113119\n",
      "[8137]\ttraining's binary_logloss: 0.113109\n",
      "[8138]\ttraining's binary_logloss: 0.113108\n",
      "[8139]\ttraining's binary_logloss: 0.113106\n",
      "[8140]\ttraining's binary_logloss: 0.113099\n",
      "[8141]\ttraining's binary_logloss: 0.113087\n",
      "[8142]\ttraining's binary_logloss: 0.113083\n",
      "[8143]\ttraining's binary_logloss: 0.113074\n",
      "[8144]\ttraining's binary_logloss: 0.113071\n",
      "[8145]\ttraining's binary_logloss: 0.11306\n",
      "[8146]\ttraining's binary_logloss: 0.113054\n",
      "[8147]\ttraining's binary_logloss: 0.113043\n",
      "[8148]\ttraining's binary_logloss: 0.113032\n",
      "[8149]\ttraining's binary_logloss: 0.11303\n",
      "[8150]\ttraining's binary_logloss: 0.113021\n",
      "[8151]\ttraining's binary_logloss: 0.113013\n",
      "[8152]\ttraining's binary_logloss: 0.113006\n",
      "[8153]\ttraining's binary_logloss: 0.112996\n",
      "[8154]\ttraining's binary_logloss: 0.112988\n",
      "[8155]\ttraining's binary_logloss: 0.112984\n",
      "[8156]\ttraining's binary_logloss: 0.112979\n",
      "[8157]\ttraining's binary_logloss: 0.112976\n",
      "[8158]\ttraining's binary_logloss: 0.112974\n",
      "[8159]\ttraining's binary_logloss: 0.112972\n",
      "[8160]\ttraining's binary_logloss: 0.112968\n",
      "[8161]\ttraining's binary_logloss: 0.112958\n",
      "[8162]\ttraining's binary_logloss: 0.112947\n",
      "[8163]\ttraining's binary_logloss: 0.112934\n",
      "[8164]\ttraining's binary_logloss: 0.112922\n",
      "[8165]\ttraining's binary_logloss: 0.112913\n",
      "[8166]\ttraining's binary_logloss: 0.112902\n",
      "[8167]\ttraining's binary_logloss: 0.11289\n",
      "[8168]\ttraining's binary_logloss: 0.112881\n",
      "[8169]\ttraining's binary_logloss: 0.112873\n",
      "[8170]\ttraining's binary_logloss: 0.112864\n",
      "[8171]\ttraining's binary_logloss: 0.112853\n",
      "[8172]\ttraining's binary_logloss: 0.112841\n",
      "[8173]\ttraining's binary_logloss: 0.11283\n",
      "[8174]\ttraining's binary_logloss: 0.11282\n",
      "[8175]\ttraining's binary_logloss: 0.112818\n",
      "[8176]\ttraining's binary_logloss: 0.112816\n",
      "[8177]\ttraining's binary_logloss: 0.112804\n",
      "[8178]\ttraining's binary_logloss: 0.11279\n",
      "[8179]\ttraining's binary_logloss: 0.112778\n",
      "[8180]\ttraining's binary_logloss: 0.112767\n",
      "[8181]\ttraining's binary_logloss: 0.112756\n",
      "[8182]\ttraining's binary_logloss: 0.112748\n",
      "[8183]\ttraining's binary_logloss: 0.112736\n",
      "[8184]\ttraining's binary_logloss: 0.112727\n",
      "[8185]\ttraining's binary_logloss: 0.112713\n",
      "[8186]\ttraining's binary_logloss: 0.112702\n",
      "[8187]\ttraining's binary_logloss: 0.112692\n",
      "[8188]\ttraining's binary_logloss: 0.112687\n",
      "[8189]\ttraining's binary_logloss: 0.112678\n",
      "[8190]\ttraining's binary_logloss: 0.112668\n",
      "[8191]\ttraining's binary_logloss: 0.112662\n",
      "[8192]\ttraining's binary_logloss: 0.112653\n",
      "[8193]\ttraining's binary_logloss: 0.112644\n",
      "[8194]\ttraining's binary_logloss: 0.112639\n",
      "[8195]\ttraining's binary_logloss: 0.112634\n",
      "[8196]\ttraining's binary_logloss: 0.112633\n",
      "[8197]\ttraining's binary_logloss: 0.112622\n",
      "[8198]\ttraining's binary_logloss: 0.112614\n",
      "[8199]\ttraining's binary_logloss: 0.112607\n",
      "[8200]\ttraining's binary_logloss: 0.112597\n",
      "[8201]\ttraining's binary_logloss: 0.112588\n",
      "[8202]\ttraining's binary_logloss: 0.112579\n",
      "[8203]\ttraining's binary_logloss: 0.11257\n",
      "[8204]\ttraining's binary_logloss: 0.112561\n",
      "[8205]\ttraining's binary_logloss: 0.11255\n",
      "[8206]\ttraining's binary_logloss: 0.112543\n",
      "[8207]\ttraining's binary_logloss: 0.112538\n",
      "[8208]\ttraining's binary_logloss: 0.112531\n",
      "[8209]\ttraining's binary_logloss: 0.112528\n",
      "[8210]\ttraining's binary_logloss: 0.112525\n",
      "[8211]\ttraining's binary_logloss: 0.112522\n",
      "[8212]\ttraining's binary_logloss: 0.112519\n",
      "[8213]\ttraining's binary_logloss: 0.112509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8214]\ttraining's binary_logloss: 0.112501\n",
      "[8215]\ttraining's binary_logloss: 0.112494\n",
      "[8216]\ttraining's binary_logloss: 0.112489\n",
      "[8217]\ttraining's binary_logloss: 0.112478\n",
      "[8218]\ttraining's binary_logloss: 0.112466\n",
      "[8219]\ttraining's binary_logloss: 0.112461\n",
      "[8220]\ttraining's binary_logloss: 0.112454\n",
      "[8221]\ttraining's binary_logloss: 0.112443\n",
      "[8222]\ttraining's binary_logloss: 0.112431\n",
      "[8223]\ttraining's binary_logloss: 0.112418\n",
      "[8224]\ttraining's binary_logloss: 0.112412\n",
      "[8225]\ttraining's binary_logloss: 0.112402\n",
      "[8226]\ttraining's binary_logloss: 0.11239\n",
      "[8227]\ttraining's binary_logloss: 0.112385\n",
      "[8228]\ttraining's binary_logloss: 0.112374\n",
      "[8229]\ttraining's binary_logloss: 0.112363\n",
      "[8230]\ttraining's binary_logloss: 0.112353\n",
      "[8231]\ttraining's binary_logloss: 0.112341\n",
      "[8232]\ttraining's binary_logloss: 0.112332\n",
      "[8233]\ttraining's binary_logloss: 0.112322\n",
      "[8234]\ttraining's binary_logloss: 0.11231\n",
      "[8235]\ttraining's binary_logloss: 0.1123\n",
      "[8236]\ttraining's binary_logloss: 0.11229\n",
      "[8237]\ttraining's binary_logloss: 0.112282\n",
      "[8238]\ttraining's binary_logloss: 0.112272\n",
      "[8239]\ttraining's binary_logloss: 0.11226\n",
      "[8240]\ttraining's binary_logloss: 0.112249\n",
      "[8241]\ttraining's binary_logloss: 0.112244\n",
      "[8242]\ttraining's binary_logloss: 0.112233\n",
      "[8243]\ttraining's binary_logloss: 0.112223\n",
      "[8244]\ttraining's binary_logloss: 0.11222\n",
      "[8245]\ttraining's binary_logloss: 0.112214\n",
      "[8246]\ttraining's binary_logloss: 0.112204\n",
      "[8247]\ttraining's binary_logloss: 0.112197\n",
      "[8248]\ttraining's binary_logloss: 0.112188\n",
      "[8249]\ttraining's binary_logloss: 0.112185\n",
      "[8250]\ttraining's binary_logloss: 0.112183\n",
      "[8251]\ttraining's binary_logloss: 0.112174\n",
      "[8252]\ttraining's binary_logloss: 0.112167\n",
      "[8253]\ttraining's binary_logloss: 0.112156\n",
      "[8254]\ttraining's binary_logloss: 0.112148\n",
      "[8255]\ttraining's binary_logloss: 0.112136\n",
      "[8256]\ttraining's binary_logloss: 0.112134\n",
      "[8257]\ttraining's binary_logloss: 0.112123\n",
      "[8258]\ttraining's binary_logloss: 0.112114\n",
      "[8259]\ttraining's binary_logloss: 0.112102\n",
      "[8260]\ttraining's binary_logloss: 0.112091\n",
      "[8261]\ttraining's binary_logloss: 0.11208\n",
      "[8262]\ttraining's binary_logloss: 0.112069\n",
      "[8263]\ttraining's binary_logloss: 0.112061\n",
      "[8264]\ttraining's binary_logloss: 0.112049\n",
      "[8265]\ttraining's binary_logloss: 0.112039\n",
      "[8266]\ttraining's binary_logloss: 0.112029\n",
      "[8267]\ttraining's binary_logloss: 0.112022\n",
      "[8268]\ttraining's binary_logloss: 0.11201\n",
      "[8269]\ttraining's binary_logloss: 0.112002\n",
      "[8270]\ttraining's binary_logloss: 0.111992\n",
      "[8271]\ttraining's binary_logloss: 0.111986\n",
      "[8272]\ttraining's binary_logloss: 0.111977\n",
      "[8273]\ttraining's binary_logloss: 0.111972\n",
      "[8274]\ttraining's binary_logloss: 0.111961\n",
      "[8275]\ttraining's binary_logloss: 0.111951\n",
      "[8276]\ttraining's binary_logloss: 0.11194\n",
      "[8277]\ttraining's binary_logloss: 0.111933\n",
      "[8278]\ttraining's binary_logloss: 0.111925\n",
      "[8279]\ttraining's binary_logloss: 0.111915\n",
      "[8280]\ttraining's binary_logloss: 0.111906\n",
      "[8281]\ttraining's binary_logloss: 0.111897\n",
      "[8282]\ttraining's binary_logloss: 0.111894\n",
      "[8283]\ttraining's binary_logloss: 0.111885\n",
      "[8284]\ttraining's binary_logloss: 0.11188\n",
      "[8285]\ttraining's binary_logloss: 0.11187\n",
      "[8286]\ttraining's binary_logloss: 0.111861\n",
      "[8287]\ttraining's binary_logloss: 0.111854\n",
      "[8288]\ttraining's binary_logloss: 0.111849\n",
      "[8289]\ttraining's binary_logloss: 0.111844\n",
      "[8290]\ttraining's binary_logloss: 0.111833\n",
      "[8291]\ttraining's binary_logloss: 0.11182\n",
      "[8292]\ttraining's binary_logloss: 0.111809\n",
      "[8293]\ttraining's binary_logloss: 0.111799\n",
      "[8294]\ttraining's binary_logloss: 0.111786\n",
      "[8295]\ttraining's binary_logloss: 0.111775\n",
      "[8296]\ttraining's binary_logloss: 0.111763\n",
      "[8297]\ttraining's binary_logloss: 0.111753\n",
      "[8298]\ttraining's binary_logloss: 0.111742\n",
      "[8299]\ttraining's binary_logloss: 0.111735\n",
      "[8300]\ttraining's binary_logloss: 0.111725\n",
      "[8301]\ttraining's binary_logloss: 0.111717\n",
      "[8302]\ttraining's binary_logloss: 0.111708\n",
      "[8303]\ttraining's binary_logloss: 0.111698\n",
      "[8304]\ttraining's binary_logloss: 0.111692\n",
      "[8305]\ttraining's binary_logloss: 0.111682\n",
      "[8306]\ttraining's binary_logloss: 0.111675\n",
      "[8307]\ttraining's binary_logloss: 0.111663\n",
      "[8308]\ttraining's binary_logloss: 0.111653\n",
      "[8309]\ttraining's binary_logloss: 0.111645\n",
      "[8310]\ttraining's binary_logloss: 0.111636\n",
      "[8311]\ttraining's binary_logloss: 0.111634\n",
      "[8312]\ttraining's binary_logloss: 0.111633\n",
      "[8313]\ttraining's binary_logloss: 0.111622\n",
      "[8314]\ttraining's binary_logloss: 0.111609\n",
      "[8315]\ttraining's binary_logloss: 0.111604\n",
      "[8316]\ttraining's binary_logloss: 0.1116\n",
      "[8317]\ttraining's binary_logloss: 0.111595\n",
      "[8318]\ttraining's binary_logloss: 0.111585\n",
      "[8319]\ttraining's binary_logloss: 0.111572\n",
      "[8320]\ttraining's binary_logloss: 0.111563\n",
      "[8321]\ttraining's binary_logloss: 0.111562\n",
      "[8322]\ttraining's binary_logloss: 0.111552\n",
      "[8323]\ttraining's binary_logloss: 0.111539\n",
      "[8324]\ttraining's binary_logloss: 0.111528\n",
      "[8325]\ttraining's binary_logloss: 0.111521\n",
      "[8326]\ttraining's binary_logloss: 0.11152\n",
      "[8327]\ttraining's binary_logloss: 0.111518\n",
      "[8328]\ttraining's binary_logloss: 0.11151\n",
      "[8329]\ttraining's binary_logloss: 0.111499\n",
      "[8330]\ttraining's binary_logloss: 0.111489\n",
      "[8331]\ttraining's binary_logloss: 0.111487\n",
      "[8332]\ttraining's binary_logloss: 0.111484\n",
      "[8333]\ttraining's binary_logloss: 0.111481\n",
      "[8334]\ttraining's binary_logloss: 0.111471\n",
      "[8335]\ttraining's binary_logloss: 0.11146\n",
      "[8336]\ttraining's binary_logloss: 0.111459\n",
      "[8337]\ttraining's binary_logloss: 0.111451\n",
      "[8338]\ttraining's binary_logloss: 0.111439\n",
      "[8339]\ttraining's binary_logloss: 0.111428\n",
      "[8340]\ttraining's binary_logloss: 0.111417\n",
      "[8341]\ttraining's binary_logloss: 0.111408\n",
      "[8342]\ttraining's binary_logloss: 0.111396\n",
      "[8343]\ttraining's binary_logloss: 0.111394\n",
      "[8344]\ttraining's binary_logloss: 0.111391\n",
      "[8345]\ttraining's binary_logloss: 0.111382\n",
      "[8346]\ttraining's binary_logloss: 0.11138\n",
      "[8347]\ttraining's binary_logloss: 0.111376\n",
      "[8348]\ttraining's binary_logloss: 0.111374\n",
      "[8349]\ttraining's binary_logloss: 0.111373\n",
      "[8350]\ttraining's binary_logloss: 0.111361\n",
      "[8351]\ttraining's binary_logloss: 0.11135\n",
      "[8352]\ttraining's binary_logloss: 0.11134\n",
      "[8353]\ttraining's binary_logloss: 0.11133\n",
      "[8354]\ttraining's binary_logloss: 0.11132\n",
      "[8355]\ttraining's binary_logloss: 0.11131\n",
      "[8356]\ttraining's binary_logloss: 0.111299\n",
      "[8357]\ttraining's binary_logloss: 0.111289\n",
      "[8358]\ttraining's binary_logloss: 0.111278\n",
      "[8359]\ttraining's binary_logloss: 0.111269\n",
      "[8360]\ttraining's binary_logloss: 0.111256\n",
      "[8361]\ttraining's binary_logloss: 0.111246\n",
      "[8362]\ttraining's binary_logloss: 0.111235\n",
      "[8363]\ttraining's binary_logloss: 0.111225\n",
      "[8364]\ttraining's binary_logloss: 0.111213\n",
      "[8365]\ttraining's binary_logloss: 0.111203\n",
      "[8366]\ttraining's binary_logloss: 0.111192\n",
      "[8367]\ttraining's binary_logloss: 0.111182\n",
      "[8368]\ttraining's binary_logloss: 0.111169\n",
      "[8369]\ttraining's binary_logloss: 0.111159\n",
      "[8370]\ttraining's binary_logloss: 0.111154\n",
      "[8371]\ttraining's binary_logloss: 0.111148\n",
      "[8372]\ttraining's binary_logloss: 0.111137\n",
      "[8373]\ttraining's binary_logloss: 0.111127\n",
      "[8374]\ttraining's binary_logloss: 0.111116\n",
      "[8375]\ttraining's binary_logloss: 0.111105\n",
      "[8376]\ttraining's binary_logloss: 0.111094\n",
      "[8377]\ttraining's binary_logloss: 0.111084\n",
      "[8378]\ttraining's binary_logloss: 0.111074\n",
      "[8379]\ttraining's binary_logloss: 0.111063\n",
      "[8380]\ttraining's binary_logloss: 0.111055\n",
      "[8381]\ttraining's binary_logloss: 0.111046\n",
      "[8382]\ttraining's binary_logloss: 0.111035\n",
      "[8383]\ttraining's binary_logloss: 0.111024\n",
      "[8384]\ttraining's binary_logloss: 0.111013\n",
      "[8385]\ttraining's binary_logloss: 0.111004\n",
      "[8386]\ttraining's binary_logloss: 0.110991\n",
      "[8387]\ttraining's binary_logloss: 0.110984\n",
      "[8388]\ttraining's binary_logloss: 0.110977\n",
      "[8389]\ttraining's binary_logloss: 0.110974\n",
      "[8390]\ttraining's binary_logloss: 0.110965\n",
      "[8391]\ttraining's binary_logloss: 0.110958\n",
      "[8392]\ttraining's binary_logloss: 0.110946\n",
      "[8393]\ttraining's binary_logloss: 0.110935\n",
      "[8394]\ttraining's binary_logloss: 0.110926\n",
      "[8395]\ttraining's binary_logloss: 0.110917\n",
      "[8396]\ttraining's binary_logloss: 0.110907\n",
      "[8397]\ttraining's binary_logloss: 0.110895\n",
      "[8398]\ttraining's binary_logloss: 0.110884\n",
      "[8399]\ttraining's binary_logloss: 0.110874\n",
      "[8400]\ttraining's binary_logloss: 0.110864\n",
      "[8401]\ttraining's binary_logloss: 0.110853\n",
      "[8402]\ttraining's binary_logloss: 0.110841\n",
      "[8403]\ttraining's binary_logloss: 0.11083\n",
      "[8404]\ttraining's binary_logloss: 0.110819\n",
      "[8405]\ttraining's binary_logloss: 0.110809\n",
      "[8406]\ttraining's binary_logloss: 0.110798\n",
      "[8407]\ttraining's binary_logloss: 0.110788\n",
      "[8408]\ttraining's binary_logloss: 0.110777\n",
      "[8409]\ttraining's binary_logloss: 0.110769\n",
      "[8410]\ttraining's binary_logloss: 0.110758\n",
      "[8411]\ttraining's binary_logloss: 0.110748\n",
      "[8412]\ttraining's binary_logloss: 0.110736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8413]\ttraining's binary_logloss: 0.110727\n",
      "[8414]\ttraining's binary_logloss: 0.110717\n",
      "[8415]\ttraining's binary_logloss: 0.110706\n",
      "[8416]\ttraining's binary_logloss: 0.1107\n",
      "[8417]\ttraining's binary_logloss: 0.110693\n",
      "[8418]\ttraining's binary_logloss: 0.110688\n",
      "[8419]\ttraining's binary_logloss: 0.110678\n",
      "[8420]\ttraining's binary_logloss: 0.110668\n",
      "[8421]\ttraining's binary_logloss: 0.110659\n",
      "[8422]\ttraining's binary_logloss: 0.110649\n",
      "[8423]\ttraining's binary_logloss: 0.110638\n",
      "[8424]\ttraining's binary_logloss: 0.110629\n",
      "[8425]\ttraining's binary_logloss: 0.110619\n",
      "[8426]\ttraining's binary_logloss: 0.110609\n",
      "[8427]\ttraining's binary_logloss: 0.110602\n",
      "[8428]\ttraining's binary_logloss: 0.110592\n",
      "[8429]\ttraining's binary_logloss: 0.110582\n",
      "[8430]\ttraining's binary_logloss: 0.110574\n",
      "[8431]\ttraining's binary_logloss: 0.110567\n",
      "[8432]\ttraining's binary_logloss: 0.110559\n",
      "[8433]\ttraining's binary_logloss: 0.110549\n",
      "[8434]\ttraining's binary_logloss: 0.110539\n",
      "[8435]\ttraining's binary_logloss: 0.110531\n",
      "[8436]\ttraining's binary_logloss: 0.11052\n",
      "[8437]\ttraining's binary_logloss: 0.11051\n",
      "[8438]\ttraining's binary_logloss: 0.110501\n",
      "[8439]\ttraining's binary_logloss: 0.11049\n",
      "[8440]\ttraining's binary_logloss: 0.110482\n",
      "[8441]\ttraining's binary_logloss: 0.110478\n",
      "[8442]\ttraining's binary_logloss: 0.110467\n",
      "[8443]\ttraining's binary_logloss: 0.110458\n",
      "[8444]\ttraining's binary_logloss: 0.110446\n",
      "[8445]\ttraining's binary_logloss: 0.11044\n",
      "[8446]\ttraining's binary_logloss: 0.110436\n",
      "[8447]\ttraining's binary_logloss: 0.110425\n",
      "[8448]\ttraining's binary_logloss: 0.110414\n",
      "[8449]\ttraining's binary_logloss: 0.110403\n",
      "[8450]\ttraining's binary_logloss: 0.110395\n",
      "[8451]\ttraining's binary_logloss: 0.110385\n",
      "[8452]\ttraining's binary_logloss: 0.110375\n",
      "[8453]\ttraining's binary_logloss: 0.110365\n",
      "[8454]\ttraining's binary_logloss: 0.110356\n",
      "[8455]\ttraining's binary_logloss: 0.110345\n",
      "[8456]\ttraining's binary_logloss: 0.110335\n",
      "[8457]\ttraining's binary_logloss: 0.110325\n",
      "[8458]\ttraining's binary_logloss: 0.110316\n",
      "[8459]\ttraining's binary_logloss: 0.110308\n",
      "[8460]\ttraining's binary_logloss: 0.110299\n",
      "[8461]\ttraining's binary_logloss: 0.110296\n",
      "[8462]\ttraining's binary_logloss: 0.110292\n",
      "[8463]\ttraining's binary_logloss: 0.110289\n",
      "[8464]\ttraining's binary_logloss: 0.110279\n",
      "[8465]\ttraining's binary_logloss: 0.110268\n",
      "[8466]\ttraining's binary_logloss: 0.11026\n",
      "[8467]\ttraining's binary_logloss: 0.110253\n",
      "[8468]\ttraining's binary_logloss: 0.110242\n",
      "[8469]\ttraining's binary_logloss: 0.11024\n",
      "[8470]\ttraining's binary_logloss: 0.110231\n",
      "[8471]\ttraining's binary_logloss: 0.110221\n",
      "[8472]\ttraining's binary_logloss: 0.110212\n",
      "[8473]\ttraining's binary_logloss: 0.110209\n",
      "[8474]\ttraining's binary_logloss: 0.110202\n",
      "[8475]\ttraining's binary_logloss: 0.110193\n",
      "[8476]\ttraining's binary_logloss: 0.110183\n",
      "[8477]\ttraining's binary_logloss: 0.110173\n",
      "[8478]\ttraining's binary_logloss: 0.110166\n",
      "[8479]\ttraining's binary_logloss: 0.110159\n",
      "[8480]\ttraining's binary_logloss: 0.110148\n",
      "[8481]\ttraining's binary_logloss: 0.110138\n",
      "[8482]\ttraining's binary_logloss: 0.110128\n",
      "[8483]\ttraining's binary_logloss: 0.110117\n",
      "[8484]\ttraining's binary_logloss: 0.110107\n",
      "[8485]\ttraining's binary_logloss: 0.110097\n",
      "[8486]\ttraining's binary_logloss: 0.110085\n",
      "[8487]\ttraining's binary_logloss: 0.110074\n",
      "[8488]\ttraining's binary_logloss: 0.110064\n",
      "[8489]\ttraining's binary_logloss: 0.110055\n",
      "[8490]\ttraining's binary_logloss: 0.110044\n",
      "[8491]\ttraining's binary_logloss: 0.110032\n",
      "[8492]\ttraining's binary_logloss: 0.110022\n",
      "[8493]\ttraining's binary_logloss: 0.110019\n",
      "[8494]\ttraining's binary_logloss: 0.110017\n",
      "[8495]\ttraining's binary_logloss: 0.110009\n",
      "[8496]\ttraining's binary_logloss: 0.110001\n",
      "[8497]\ttraining's binary_logloss: 0.10999\n",
      "[8498]\ttraining's binary_logloss: 0.109988\n",
      "[8499]\ttraining's binary_logloss: 0.109979\n",
      "[8500]\ttraining's binary_logloss: 0.109969\n",
      "[8501]\ttraining's binary_logloss: 0.10996\n",
      "[8502]\ttraining's binary_logloss: 0.109956\n",
      "[8503]\ttraining's binary_logloss: 0.109947\n",
      "[8504]\ttraining's binary_logloss: 0.109945\n",
      "[8505]\ttraining's binary_logloss: 0.109933\n",
      "[8506]\ttraining's binary_logloss: 0.109928\n",
      "[8507]\ttraining's binary_logloss: 0.109925\n",
      "[8508]\ttraining's binary_logloss: 0.109923\n",
      "[8509]\ttraining's binary_logloss: 0.109913\n",
      "[8510]\ttraining's binary_logloss: 0.109902\n",
      "[8511]\ttraining's binary_logloss: 0.109898\n",
      "[8512]\ttraining's binary_logloss: 0.109889\n",
      "[8513]\ttraining's binary_logloss: 0.109879\n",
      "[8514]\ttraining's binary_logloss: 0.10987\n",
      "[8515]\ttraining's binary_logloss: 0.10986\n",
      "[8516]\ttraining's binary_logloss: 0.109851\n",
      "[8517]\ttraining's binary_logloss: 0.10985\n",
      "[8518]\ttraining's binary_logloss: 0.109837\n",
      "[8519]\ttraining's binary_logloss: 0.109828\n",
      "[8520]\ttraining's binary_logloss: 0.109817\n",
      "[8521]\ttraining's binary_logloss: 0.109808\n",
      "[8522]\ttraining's binary_logloss: 0.109799\n",
      "[8523]\ttraining's binary_logloss: 0.109789\n",
      "[8524]\ttraining's binary_logloss: 0.109779\n",
      "[8525]\ttraining's binary_logloss: 0.109768\n",
      "[8526]\ttraining's binary_logloss: 0.109758\n",
      "[8527]\ttraining's binary_logloss: 0.109748\n",
      "[8528]\ttraining's binary_logloss: 0.109738\n",
      "[8529]\ttraining's binary_logloss: 0.109726\n",
      "[8530]\ttraining's binary_logloss: 0.109714\n",
      "[8531]\ttraining's binary_logloss: 0.109704\n",
      "[8532]\ttraining's binary_logloss: 0.109694\n",
      "[8533]\ttraining's binary_logloss: 0.109692\n",
      "[8534]\ttraining's binary_logloss: 0.109681\n",
      "[8535]\ttraining's binary_logloss: 0.109674\n",
      "[8536]\ttraining's binary_logloss: 0.109664\n",
      "[8537]\ttraining's binary_logloss: 0.109652\n",
      "[8538]\ttraining's binary_logloss: 0.109643\n",
      "[8539]\ttraining's binary_logloss: 0.109638\n",
      "[8540]\ttraining's binary_logloss: 0.109628\n",
      "[8541]\ttraining's binary_logloss: 0.109618\n",
      "[8542]\ttraining's binary_logloss: 0.109609\n",
      "[8543]\ttraining's binary_logloss: 0.109599\n",
      "[8544]\ttraining's binary_logloss: 0.109586\n",
      "[8545]\ttraining's binary_logloss: 0.109576\n",
      "[8546]\ttraining's binary_logloss: 0.109572\n",
      "[8547]\ttraining's binary_logloss: 0.10956\n",
      "[8548]\ttraining's binary_logloss: 0.109557\n",
      "[8549]\ttraining's binary_logloss: 0.109555\n",
      "[8550]\ttraining's binary_logloss: 0.109542\n",
      "[8551]\ttraining's binary_logloss: 0.109533\n",
      "[8552]\ttraining's binary_logloss: 0.109531\n",
      "[8553]\ttraining's binary_logloss: 0.10952\n",
      "[8554]\ttraining's binary_logloss: 0.109512\n",
      "[8555]\ttraining's binary_logloss: 0.109503\n",
      "[8556]\ttraining's binary_logloss: 0.109493\n",
      "[8557]\ttraining's binary_logloss: 0.109488\n",
      "[8558]\ttraining's binary_logloss: 0.109478\n",
      "[8559]\ttraining's binary_logloss: 0.109467\n",
      "[8560]\ttraining's binary_logloss: 0.109457\n",
      "[8561]\ttraining's binary_logloss: 0.109447\n",
      "[8562]\ttraining's binary_logloss: 0.10944\n",
      "[8563]\ttraining's binary_logloss: 0.109432\n",
      "[8564]\ttraining's binary_logloss: 0.109421\n",
      "[8565]\ttraining's binary_logloss: 0.109411\n",
      "[8566]\ttraining's binary_logloss: 0.109402\n",
      "[8567]\ttraining's binary_logloss: 0.109395\n",
      "[8568]\ttraining's binary_logloss: 0.109384\n",
      "[8569]\ttraining's binary_logloss: 0.109375\n",
      "[8570]\ttraining's binary_logloss: 0.109364\n",
      "[8571]\ttraining's binary_logloss: 0.109355\n",
      "[8572]\ttraining's binary_logloss: 0.109345\n",
      "[8573]\ttraining's binary_logloss: 0.109333\n",
      "[8574]\ttraining's binary_logloss: 0.109324\n",
      "[8575]\ttraining's binary_logloss: 0.109315\n",
      "[8576]\ttraining's binary_logloss: 0.109305\n",
      "[8577]\ttraining's binary_logloss: 0.109294\n",
      "[8578]\ttraining's binary_logloss: 0.109287\n",
      "[8579]\ttraining's binary_logloss: 0.109275\n",
      "[8580]\ttraining's binary_logloss: 0.109266\n",
      "[8581]\ttraining's binary_logloss: 0.109254\n",
      "[8582]\ttraining's binary_logloss: 0.109243\n",
      "[8583]\ttraining's binary_logloss: 0.109233\n",
      "[8584]\ttraining's binary_logloss: 0.109223\n",
      "[8585]\ttraining's binary_logloss: 0.109213\n",
      "[8586]\ttraining's binary_logloss: 0.109203\n",
      "[8587]\ttraining's binary_logloss: 0.109194\n",
      "[8588]\ttraining's binary_logloss: 0.109185\n",
      "[8589]\ttraining's binary_logloss: 0.109182\n",
      "[8590]\ttraining's binary_logloss: 0.109172\n",
      "[8591]\ttraining's binary_logloss: 0.109161\n",
      "[8592]\ttraining's binary_logloss: 0.109151\n",
      "[8593]\ttraining's binary_logloss: 0.10914\n",
      "[8594]\ttraining's binary_logloss: 0.109131\n",
      "[8595]\ttraining's binary_logloss: 0.109129\n",
      "[8596]\ttraining's binary_logloss: 0.109118\n",
      "[8597]\ttraining's binary_logloss: 0.109108\n",
      "[8598]\ttraining's binary_logloss: 0.109099\n",
      "[8599]\ttraining's binary_logloss: 0.109088\n",
      "[8600]\ttraining's binary_logloss: 0.109078\n",
      "[8601]\ttraining's binary_logloss: 0.109068\n",
      "[8602]\ttraining's binary_logloss: 0.109057\n",
      "[8603]\ttraining's binary_logloss: 0.109053\n",
      "[8604]\ttraining's binary_logloss: 0.109049\n",
      "[8605]\ttraining's binary_logloss: 0.109045\n",
      "[8606]\ttraining's binary_logloss: 0.109035\n",
      "[8607]\ttraining's binary_logloss: 0.109028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8608]\ttraining's binary_logloss: 0.109017\n",
      "[8609]\ttraining's binary_logloss: 0.109007\n",
      "[8610]\ttraining's binary_logloss: 0.108995\n",
      "[8611]\ttraining's binary_logloss: 0.108985\n",
      "[8612]\ttraining's binary_logloss: 0.108972\n",
      "[8613]\ttraining's binary_logloss: 0.108969\n",
      "[8614]\ttraining's binary_logloss: 0.108957\n",
      "[8615]\ttraining's binary_logloss: 0.108947\n",
      "[8616]\ttraining's binary_logloss: 0.108937\n",
      "[8617]\ttraining's binary_logloss: 0.108926\n",
      "[8618]\ttraining's binary_logloss: 0.108915\n",
      "[8619]\ttraining's binary_logloss: 0.108905\n",
      "[8620]\ttraining's binary_logloss: 0.108895\n",
      "[8621]\ttraining's binary_logloss: 0.108885\n",
      "[8622]\ttraining's binary_logloss: 0.108874\n",
      "[8623]\ttraining's binary_logloss: 0.108866\n",
      "[8624]\ttraining's binary_logloss: 0.108854\n",
      "[8625]\ttraining's binary_logloss: 0.108846\n",
      "[8626]\ttraining's binary_logloss: 0.108834\n",
      "[8627]\ttraining's binary_logloss: 0.108829\n",
      "[8628]\ttraining's binary_logloss: 0.108823\n",
      "[8629]\ttraining's binary_logloss: 0.108813\n",
      "[8630]\ttraining's binary_logloss: 0.10881\n",
      "[8631]\ttraining's binary_logloss: 0.108801\n",
      "[8632]\ttraining's binary_logloss: 0.10879\n",
      "[8633]\ttraining's binary_logloss: 0.108783\n",
      "[8634]\ttraining's binary_logloss: 0.108773\n",
      "[8635]\ttraining's binary_logloss: 0.108762\n",
      "[8636]\ttraining's binary_logloss: 0.108754\n",
      "[8637]\ttraining's binary_logloss: 0.108744\n",
      "[8638]\ttraining's binary_logloss: 0.108732\n",
      "[8639]\ttraining's binary_logloss: 0.108721\n",
      "[8640]\ttraining's binary_logloss: 0.108711\n",
      "[8641]\ttraining's binary_logloss: 0.108701\n",
      "[8642]\ttraining's binary_logloss: 0.108688\n",
      "[8643]\ttraining's binary_logloss: 0.10868\n",
      "[8644]\ttraining's binary_logloss: 0.108675\n",
      "[8645]\ttraining's binary_logloss: 0.108665\n",
      "[8646]\ttraining's binary_logloss: 0.108655\n",
      "[8647]\ttraining's binary_logloss: 0.108645\n",
      "[8648]\ttraining's binary_logloss: 0.108633\n",
      "[8649]\ttraining's binary_logloss: 0.108623\n",
      "[8650]\ttraining's binary_logloss: 0.108612\n",
      "[8651]\ttraining's binary_logloss: 0.108602\n",
      "[8652]\ttraining's binary_logloss: 0.108591\n",
      "[8653]\ttraining's binary_logloss: 0.108582\n",
      "[8654]\ttraining's binary_logloss: 0.108572\n",
      "[8655]\ttraining's binary_logloss: 0.108561\n",
      "[8656]\ttraining's binary_logloss: 0.10855\n",
      "[8657]\ttraining's binary_logloss: 0.108541\n",
      "[8658]\ttraining's binary_logloss: 0.10853\n",
      "[8659]\ttraining's binary_logloss: 0.108523\n",
      "[8660]\ttraining's binary_logloss: 0.108515\n",
      "[8661]\ttraining's binary_logloss: 0.108507\n",
      "[8662]\ttraining's binary_logloss: 0.108497\n",
      "[8663]\ttraining's binary_logloss: 0.108494\n",
      "[8664]\ttraining's binary_logloss: 0.108485\n",
      "[8665]\ttraining's binary_logloss: 0.108474\n",
      "[8666]\ttraining's binary_logloss: 0.108465\n",
      "[8667]\ttraining's binary_logloss: 0.108455\n",
      "[8668]\ttraining's binary_logloss: 0.108442\n",
      "[8669]\ttraining's binary_logloss: 0.108432\n",
      "[8670]\ttraining's binary_logloss: 0.108423\n",
      "[8671]\ttraining's binary_logloss: 0.108415\n",
      "[8672]\ttraining's binary_logloss: 0.108405\n",
      "[8673]\ttraining's binary_logloss: 0.108394\n",
      "[8674]\ttraining's binary_logloss: 0.108383\n",
      "[8675]\ttraining's binary_logloss: 0.108373\n",
      "[8676]\ttraining's binary_logloss: 0.108364\n",
      "[8677]\ttraining's binary_logloss: 0.108357\n",
      "[8678]\ttraining's binary_logloss: 0.108347\n",
      "[8679]\ttraining's binary_logloss: 0.108337\n",
      "[8680]\ttraining's binary_logloss: 0.108326\n",
      "[8681]\ttraining's binary_logloss: 0.10832\n",
      "[8682]\ttraining's binary_logloss: 0.10831\n",
      "[8683]\ttraining's binary_logloss: 0.108302\n",
      "[8684]\ttraining's binary_logloss: 0.108294\n",
      "[8685]\ttraining's binary_logloss: 0.108285\n",
      "[8686]\ttraining's binary_logloss: 0.108276\n",
      "[8687]\ttraining's binary_logloss: 0.108267\n",
      "[8688]\ttraining's binary_logloss: 0.108256\n",
      "[8689]\ttraining's binary_logloss: 0.108246\n",
      "[8690]\ttraining's binary_logloss: 0.108236\n",
      "[8691]\ttraining's binary_logloss: 0.108226\n",
      "[8692]\ttraining's binary_logloss: 0.108216\n",
      "[8693]\ttraining's binary_logloss: 0.108209\n",
      "[8694]\ttraining's binary_logloss: 0.108199\n",
      "[8695]\ttraining's binary_logloss: 0.108193\n",
      "[8696]\ttraining's binary_logloss: 0.108182\n",
      "[8697]\ttraining's binary_logloss: 0.108174\n",
      "[8698]\ttraining's binary_logloss: 0.108166\n",
      "[8699]\ttraining's binary_logloss: 0.108156\n",
      "[8700]\ttraining's binary_logloss: 0.108147\n",
      "[8701]\ttraining's binary_logloss: 0.108137\n",
      "[8702]\ttraining's binary_logloss: 0.108127\n",
      "[8703]\ttraining's binary_logloss: 0.108119\n",
      "[8704]\ttraining's binary_logloss: 0.10811\n",
      "[8705]\ttraining's binary_logloss: 0.1081\n",
      "[8706]\ttraining's binary_logloss: 0.108091\n",
      "[8707]\ttraining's binary_logloss: 0.108082\n",
      "[8708]\ttraining's binary_logloss: 0.108071\n",
      "[8709]\ttraining's binary_logloss: 0.108062\n",
      "[8710]\ttraining's binary_logloss: 0.108053\n",
      "[8711]\ttraining's binary_logloss: 0.108045\n",
      "[8712]\ttraining's binary_logloss: 0.108037\n",
      "[8713]\ttraining's binary_logloss: 0.108027\n",
      "[8714]\ttraining's binary_logloss: 0.108017\n",
      "[8715]\ttraining's binary_logloss: 0.108007\n",
      "[8716]\ttraining's binary_logloss: 0.107998\n",
      "[8717]\ttraining's binary_logloss: 0.107988\n",
      "[8718]\ttraining's binary_logloss: 0.107977\n",
      "[8719]\ttraining's binary_logloss: 0.107968\n",
      "[8720]\ttraining's binary_logloss: 0.107958\n",
      "[8721]\ttraining's binary_logloss: 0.107948\n",
      "[8722]\ttraining's binary_logloss: 0.107937\n",
      "[8723]\ttraining's binary_logloss: 0.107925\n",
      "[8724]\ttraining's binary_logloss: 0.107917\n",
      "[8725]\ttraining's binary_logloss: 0.107904\n",
      "[8726]\ttraining's binary_logloss: 0.107895\n",
      "[8727]\ttraining's binary_logloss: 0.107888\n",
      "[8728]\ttraining's binary_logloss: 0.107878\n",
      "[8729]\ttraining's binary_logloss: 0.107868\n",
      "[8730]\ttraining's binary_logloss: 0.107859\n",
      "[8731]\ttraining's binary_logloss: 0.107852\n",
      "[8732]\ttraining's binary_logloss: 0.107842\n",
      "[8733]\ttraining's binary_logloss: 0.107831\n",
      "[8734]\ttraining's binary_logloss: 0.107822\n",
      "[8735]\ttraining's binary_logloss: 0.107812\n",
      "[8736]\ttraining's binary_logloss: 0.107801\n",
      "[8737]\ttraining's binary_logloss: 0.10779\n",
      "[8738]\ttraining's binary_logloss: 0.107781\n",
      "[8739]\ttraining's binary_logloss: 0.107771\n",
      "[8740]\ttraining's binary_logloss: 0.10776\n",
      "[8741]\ttraining's binary_logloss: 0.10775\n",
      "[8742]\ttraining's binary_logloss: 0.107741\n",
      "[8743]\ttraining's binary_logloss: 0.10773\n",
      "[8744]\ttraining's binary_logloss: 0.107719\n",
      "[8745]\ttraining's binary_logloss: 0.107712\n",
      "[8746]\ttraining's binary_logloss: 0.107702\n",
      "[8747]\ttraining's binary_logloss: 0.107693\n",
      "[8748]\ttraining's binary_logloss: 0.107682\n",
      "[8749]\ttraining's binary_logloss: 0.107675\n",
      "[8750]\ttraining's binary_logloss: 0.107666\n",
      "[8751]\ttraining's binary_logloss: 0.107656\n",
      "[8752]\ttraining's binary_logloss: 0.107646\n",
      "[8753]\ttraining's binary_logloss: 0.107639\n",
      "[8754]\ttraining's binary_logloss: 0.107629\n",
      "[8755]\ttraining's binary_logloss: 0.10762\n",
      "[8756]\ttraining's binary_logloss: 0.107611\n",
      "[8757]\ttraining's binary_logloss: 0.107602\n",
      "[8758]\ttraining's binary_logloss: 0.107592\n",
      "[8759]\ttraining's binary_logloss: 0.107583\n",
      "[8760]\ttraining's binary_logloss: 0.107578\n",
      "[8761]\ttraining's binary_logloss: 0.107568\n",
      "[8762]\ttraining's binary_logloss: 0.10756\n",
      "[8763]\ttraining's binary_logloss: 0.107553\n",
      "[8764]\ttraining's binary_logloss: 0.107543\n",
      "[8765]\ttraining's binary_logloss: 0.107534\n",
      "[8766]\ttraining's binary_logloss: 0.107533\n",
      "[8767]\ttraining's binary_logloss: 0.107523\n",
      "[8768]\ttraining's binary_logloss: 0.107514\n",
      "[8769]\ttraining's binary_logloss: 0.107503\n",
      "[8770]\ttraining's binary_logloss: 0.107493\n",
      "[8771]\ttraining's binary_logloss: 0.107483\n",
      "[8772]\ttraining's binary_logloss: 0.107474\n",
      "[8773]\ttraining's binary_logloss: 0.107464\n",
      "[8774]\ttraining's binary_logloss: 0.107457\n",
      "[8775]\ttraining's binary_logloss: 0.107446\n",
      "[8776]\ttraining's binary_logloss: 0.107436\n",
      "[8777]\ttraining's binary_logloss: 0.107426\n",
      "[8778]\ttraining's binary_logloss: 0.107417\n",
      "[8779]\ttraining's binary_logloss: 0.107408\n",
      "[8780]\ttraining's binary_logloss: 0.107399\n",
      "[8781]\ttraining's binary_logloss: 0.10739\n",
      "[8782]\ttraining's binary_logloss: 0.10738\n",
      "[8783]\ttraining's binary_logloss: 0.107372\n",
      "[8784]\ttraining's binary_logloss: 0.107362\n",
      "[8785]\ttraining's binary_logloss: 0.10735\n",
      "[8786]\ttraining's binary_logloss: 0.107341\n",
      "[8787]\ttraining's binary_logloss: 0.107332\n",
      "[8788]\ttraining's binary_logloss: 0.107323\n",
      "[8789]\ttraining's binary_logloss: 0.107319\n",
      "[8790]\ttraining's binary_logloss: 0.107308\n",
      "[8791]\ttraining's binary_logloss: 0.107304\n",
      "[8792]\ttraining's binary_logloss: 0.107302\n",
      "[8793]\ttraining's binary_logloss: 0.107292\n",
      "[8794]\ttraining's binary_logloss: 0.107281\n",
      "[8795]\ttraining's binary_logloss: 0.107272\n",
      "[8796]\ttraining's binary_logloss: 0.107262\n",
      "[8797]\ttraining's binary_logloss: 0.107251\n",
      "[8798]\ttraining's binary_logloss: 0.10724\n",
      "[8799]\ttraining's binary_logloss: 0.107231\n",
      "[8800]\ttraining's binary_logloss: 0.107221\n",
      "[8801]\ttraining's binary_logloss: 0.107208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8802]\ttraining's binary_logloss: 0.107202\n",
      "[8803]\ttraining's binary_logloss: 0.107193\n",
      "[8804]\ttraining's binary_logloss: 0.107183\n",
      "[8805]\ttraining's binary_logloss: 0.107173\n",
      "[8806]\ttraining's binary_logloss: 0.107163\n",
      "[8807]\ttraining's binary_logloss: 0.107151\n",
      "[8808]\ttraining's binary_logloss: 0.107143\n",
      "[8809]\ttraining's binary_logloss: 0.107135\n",
      "[8810]\ttraining's binary_logloss: 0.107128\n",
      "[8811]\ttraining's binary_logloss: 0.107123\n",
      "[8812]\ttraining's binary_logloss: 0.10712\n",
      "[8813]\ttraining's binary_logloss: 0.10711\n",
      "[8814]\ttraining's binary_logloss: 0.1071\n",
      "[8815]\ttraining's binary_logloss: 0.10709\n",
      "[8816]\ttraining's binary_logloss: 0.107082\n",
      "[8817]\ttraining's binary_logloss: 0.107073\n",
      "[8818]\ttraining's binary_logloss: 0.107064\n",
      "[8819]\ttraining's binary_logloss: 0.107054\n",
      "[8820]\ttraining's binary_logloss: 0.107044\n",
      "[8821]\ttraining's binary_logloss: 0.107034\n",
      "[8822]\ttraining's binary_logloss: 0.107026\n",
      "[8823]\ttraining's binary_logloss: 0.107017\n",
      "[8824]\ttraining's binary_logloss: 0.107008\n",
      "[8825]\ttraining's binary_logloss: 0.106996\n",
      "[8826]\ttraining's binary_logloss: 0.106986\n",
      "[8827]\ttraining's binary_logloss: 0.106976\n",
      "[8828]\ttraining's binary_logloss: 0.106965\n",
      "[8829]\ttraining's binary_logloss: 0.106955\n",
      "[8830]\ttraining's binary_logloss: 0.106946\n",
      "[8831]\ttraining's binary_logloss: 0.106936\n",
      "[8832]\ttraining's binary_logloss: 0.106927\n",
      "[8833]\ttraining's binary_logloss: 0.106918\n",
      "[8834]\ttraining's binary_logloss: 0.106908\n",
      "[8835]\ttraining's binary_logloss: 0.106896\n",
      "[8836]\ttraining's binary_logloss: 0.106889\n",
      "[8837]\ttraining's binary_logloss: 0.106879\n",
      "[8838]\ttraining's binary_logloss: 0.106871\n",
      "[8839]\ttraining's binary_logloss: 0.106861\n",
      "[8840]\ttraining's binary_logloss: 0.106851\n",
      "[8841]\ttraining's binary_logloss: 0.106842\n",
      "[8842]\ttraining's binary_logloss: 0.106833\n",
      "[8843]\ttraining's binary_logloss: 0.106822\n",
      "[8844]\ttraining's binary_logloss: 0.106814\n",
      "[8845]\ttraining's binary_logloss: 0.106808\n",
      "[8846]\ttraining's binary_logloss: 0.106799\n",
      "[8847]\ttraining's binary_logloss: 0.106797\n",
      "[8848]\ttraining's binary_logloss: 0.10679\n",
      "[8849]\ttraining's binary_logloss: 0.10678\n",
      "[8850]\ttraining's binary_logloss: 0.106769\n",
      "[8851]\ttraining's binary_logloss: 0.10676\n",
      "[8852]\ttraining's binary_logloss: 0.106754\n",
      "[8853]\ttraining's binary_logloss: 0.106747\n",
      "[8854]\ttraining's binary_logloss: 0.106746\n",
      "[8855]\ttraining's binary_logloss: 0.106744\n",
      "[8856]\ttraining's binary_logloss: 0.106733\n",
      "[8857]\ttraining's binary_logloss: 0.106729\n",
      "[8858]\ttraining's binary_logloss: 0.106724\n",
      "[8859]\ttraining's binary_logloss: 0.106716\n",
      "[8860]\ttraining's binary_logloss: 0.106705\n",
      "[8861]\ttraining's binary_logloss: 0.106696\n",
      "[8862]\ttraining's binary_logloss: 0.106686\n",
      "[8863]\ttraining's binary_logloss: 0.106677\n",
      "[8864]\ttraining's binary_logloss: 0.106667\n",
      "[8865]\ttraining's binary_logloss: 0.106658\n",
      "[8866]\ttraining's binary_logloss: 0.106648\n",
      "[8867]\ttraining's binary_logloss: 0.106638\n",
      "[8868]\ttraining's binary_logloss: 0.106628\n",
      "[8869]\ttraining's binary_logloss: 0.106618\n",
      "[8870]\ttraining's binary_logloss: 0.106606\n",
      "[8871]\ttraining's binary_logloss: 0.106597\n",
      "[8872]\ttraining's binary_logloss: 0.106586\n",
      "[8873]\ttraining's binary_logloss: 0.106583\n",
      "[8874]\ttraining's binary_logloss: 0.106573\n",
      "[8875]\ttraining's binary_logloss: 0.106572\n",
      "[8876]\ttraining's binary_logloss: 0.106565\n",
      "[8877]\ttraining's binary_logloss: 0.106556\n",
      "[8878]\ttraining's binary_logloss: 0.106546\n",
      "[8879]\ttraining's binary_logloss: 0.106538\n",
      "[8880]\ttraining's binary_logloss: 0.106527\n",
      "[8881]\ttraining's binary_logloss: 0.106526\n",
      "[8882]\ttraining's binary_logloss: 0.106518\n",
      "[8883]\ttraining's binary_logloss: 0.106514\n",
      "[8884]\ttraining's binary_logloss: 0.10651\n",
      "[8885]\ttraining's binary_logloss: 0.106507\n",
      "[8886]\ttraining's binary_logloss: 0.106497\n",
      "[8887]\ttraining's binary_logloss: 0.106488\n",
      "[8888]\ttraining's binary_logloss: 0.106476\n",
      "[8889]\ttraining's binary_logloss: 0.106467\n",
      "[8890]\ttraining's binary_logloss: 0.106457\n",
      "[8891]\ttraining's binary_logloss: 0.10645\n",
      "[8892]\ttraining's binary_logloss: 0.10644\n",
      "[8893]\ttraining's binary_logloss: 0.106436\n",
      "[8894]\ttraining's binary_logloss: 0.106425\n",
      "[8895]\ttraining's binary_logloss: 0.106414\n",
      "[8896]\ttraining's binary_logloss: 0.106404\n",
      "[8897]\ttraining's binary_logloss: 0.106393\n",
      "[8898]\ttraining's binary_logloss: 0.106384\n",
      "[8899]\ttraining's binary_logloss: 0.106378\n",
      "[8900]\ttraining's binary_logloss: 0.106368\n",
      "[8901]\ttraining's binary_logloss: 0.106355\n",
      "[8902]\ttraining's binary_logloss: 0.106346\n",
      "[8903]\ttraining's binary_logloss: 0.106337\n",
      "[8904]\ttraining's binary_logloss: 0.106329\n",
      "[8905]\ttraining's binary_logloss: 0.106327\n",
      "[8906]\ttraining's binary_logloss: 0.106321\n",
      "[8907]\ttraining's binary_logloss: 0.106312\n",
      "[8908]\ttraining's binary_logloss: 0.106302\n",
      "[8909]\ttraining's binary_logloss: 0.106294\n",
      "[8910]\ttraining's binary_logloss: 0.106285\n",
      "[8911]\ttraining's binary_logloss: 0.106277\n",
      "[8912]\ttraining's binary_logloss: 0.106267\n",
      "[8913]\ttraining's binary_logloss: 0.106257\n",
      "[8914]\ttraining's binary_logloss: 0.106248\n",
      "[8915]\ttraining's binary_logloss: 0.106238\n",
      "[8916]\ttraining's binary_logloss: 0.106228\n",
      "[8917]\ttraining's binary_logloss: 0.10622\n",
      "[8918]\ttraining's binary_logloss: 0.106211\n",
      "[8919]\ttraining's binary_logloss: 0.106203\n",
      "[8920]\ttraining's binary_logloss: 0.106196\n",
      "[8921]\ttraining's binary_logloss: 0.106188\n",
      "[8922]\ttraining's binary_logloss: 0.10618\n",
      "[8923]\ttraining's binary_logloss: 0.106172\n",
      "[8924]\ttraining's binary_logloss: 0.106162\n",
      "[8925]\ttraining's binary_logloss: 0.106154\n",
      "[8926]\ttraining's binary_logloss: 0.106144\n",
      "[8927]\ttraining's binary_logloss: 0.106133\n",
      "[8928]\ttraining's binary_logloss: 0.106124\n",
      "[8929]\ttraining's binary_logloss: 0.106115\n",
      "[8930]\ttraining's binary_logloss: 0.106106\n",
      "[8931]\ttraining's binary_logloss: 0.106102\n",
      "[8932]\ttraining's binary_logloss: 0.106095\n",
      "[8933]\ttraining's binary_logloss: 0.106086\n",
      "[8934]\ttraining's binary_logloss: 0.106079\n",
      "[8935]\ttraining's binary_logloss: 0.106069\n",
      "[8936]\ttraining's binary_logloss: 0.106067\n",
      "[8937]\ttraining's binary_logloss: 0.106059\n",
      "[8938]\ttraining's binary_logloss: 0.106056\n",
      "[8939]\ttraining's binary_logloss: 0.106045\n",
      "[8940]\ttraining's binary_logloss: 0.106036\n",
      "[8941]\ttraining's binary_logloss: 0.106026\n",
      "[8942]\ttraining's binary_logloss: 0.106016\n",
      "[8943]\ttraining's binary_logloss: 0.106006\n",
      "[8944]\ttraining's binary_logloss: 0.105997\n",
      "[8945]\ttraining's binary_logloss: 0.105989\n",
      "[8946]\ttraining's binary_logloss: 0.105987\n",
      "[8947]\ttraining's binary_logloss: 0.105978\n",
      "[8948]\ttraining's binary_logloss: 0.105968\n",
      "[8949]\ttraining's binary_logloss: 0.105958\n",
      "[8950]\ttraining's binary_logloss: 0.105951\n",
      "[8951]\ttraining's binary_logloss: 0.105942\n",
      "[8952]\ttraining's binary_logloss: 0.105932\n",
      "[8953]\ttraining's binary_logloss: 0.105926\n",
      "[8954]\ttraining's binary_logloss: 0.105917\n",
      "[8955]\ttraining's binary_logloss: 0.105909\n",
      "[8956]\ttraining's binary_logloss: 0.105903\n",
      "[8957]\ttraining's binary_logloss: 0.105894\n",
      "[8958]\ttraining's binary_logloss: 0.105883\n",
      "[8959]\ttraining's binary_logloss: 0.105874\n",
      "[8960]\ttraining's binary_logloss: 0.105864\n",
      "[8961]\ttraining's binary_logloss: 0.105853\n",
      "[8962]\ttraining's binary_logloss: 0.105844\n",
      "[8963]\ttraining's binary_logloss: 0.105838\n",
      "[8964]\ttraining's binary_logloss: 0.105831\n",
      "[8965]\ttraining's binary_logloss: 0.105822\n",
      "[8966]\ttraining's binary_logloss: 0.105815\n",
      "[8967]\ttraining's binary_logloss: 0.105806\n",
      "[8968]\ttraining's binary_logloss: 0.105796\n",
      "[8969]\ttraining's binary_logloss: 0.105789\n",
      "[8970]\ttraining's binary_logloss: 0.105775\n",
      "[8971]\ttraining's binary_logloss: 0.105764\n",
      "[8972]\ttraining's binary_logloss: 0.105754\n",
      "[8973]\ttraining's binary_logloss: 0.105745\n",
      "[8974]\ttraining's binary_logloss: 0.105739\n",
      "[8975]\ttraining's binary_logloss: 0.105728\n",
      "[8976]\ttraining's binary_logloss: 0.105717\n",
      "[8977]\ttraining's binary_logloss: 0.105707\n",
      "[8978]\ttraining's binary_logloss: 0.105696\n",
      "[8979]\ttraining's binary_logloss: 0.105686\n",
      "[8980]\ttraining's binary_logloss: 0.105676\n",
      "[8981]\ttraining's binary_logloss: 0.105667\n",
      "[8982]\ttraining's binary_logloss: 0.105659\n",
      "[8983]\ttraining's binary_logloss: 0.105649\n",
      "[8984]\ttraining's binary_logloss: 0.10564\n",
      "[8985]\ttraining's binary_logloss: 0.105631\n",
      "[8986]\ttraining's binary_logloss: 0.105624\n",
      "[8987]\ttraining's binary_logloss: 0.10562\n",
      "[8988]\ttraining's binary_logloss: 0.105607\n",
      "[8989]\ttraining's binary_logloss: 0.105598\n",
      "[8990]\ttraining's binary_logloss: 0.105588\n",
      "[8991]\ttraining's binary_logloss: 0.105579\n",
      "[8992]\ttraining's binary_logloss: 0.105569\n",
      "[8993]\ttraining's binary_logloss: 0.105558\n",
      "[8994]\ttraining's binary_logloss: 0.105549\n",
      "[8995]\ttraining's binary_logloss: 0.105547\n",
      "[8996]\ttraining's binary_logloss: 0.105538\n",
      "[8997]\ttraining's binary_logloss: 0.105536\n",
      "[8998]\ttraining's binary_logloss: 0.105527\n",
      "[8999]\ttraining's binary_logloss: 0.105518\n",
      "[9000]\ttraining's binary_logloss: 0.105511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9001]\ttraining's binary_logloss: 0.105503\n",
      "[9002]\ttraining's binary_logloss: 0.105498\n",
      "[9003]\ttraining's binary_logloss: 0.10549\n",
      "[9004]\ttraining's binary_logloss: 0.10548\n",
      "[9005]\ttraining's binary_logloss: 0.105473\n",
      "[9006]\ttraining's binary_logloss: 0.105472\n",
      "[9007]\ttraining's binary_logloss: 0.105462\n",
      "[9008]\ttraining's binary_logloss: 0.105452\n",
      "[9009]\ttraining's binary_logloss: 0.105445\n",
      "[9010]\ttraining's binary_logloss: 0.105435\n",
      "[9011]\ttraining's binary_logloss: 0.105433\n",
      "[9012]\ttraining's binary_logloss: 0.105424\n",
      "[9013]\ttraining's binary_logloss: 0.105419\n",
      "[9014]\ttraining's binary_logloss: 0.105412\n",
      "[9015]\ttraining's binary_logloss: 0.105403\n",
      "[9016]\ttraining's binary_logloss: 0.1054\n",
      "[9017]\ttraining's binary_logloss: 0.105391\n",
      "[9018]\ttraining's binary_logloss: 0.105384\n",
      "[9019]\ttraining's binary_logloss: 0.105379\n",
      "[9020]\ttraining's binary_logloss: 0.105368\n",
      "[9021]\ttraining's binary_logloss: 0.105358\n",
      "[9022]\ttraining's binary_logloss: 0.105353\n",
      "[9023]\ttraining's binary_logloss: 0.105345\n",
      "[9024]\ttraining's binary_logloss: 0.105339\n",
      "[9025]\ttraining's binary_logloss: 0.105329\n",
      "[9026]\ttraining's binary_logloss: 0.105327\n",
      "[9027]\ttraining's binary_logloss: 0.105316\n",
      "[9028]\ttraining's binary_logloss: 0.105306\n",
      "[9029]\ttraining's binary_logloss: 0.105297\n",
      "[9030]\ttraining's binary_logloss: 0.105295\n",
      "[9031]\ttraining's binary_logloss: 0.105292\n",
      "[9032]\ttraining's binary_logloss: 0.105283\n",
      "[9033]\ttraining's binary_logloss: 0.105274\n",
      "[9034]\ttraining's binary_logloss: 0.105265\n",
      "[9035]\ttraining's binary_logloss: 0.105259\n",
      "[9036]\ttraining's binary_logloss: 0.105256\n",
      "[9037]\ttraining's binary_logloss: 0.105251\n",
      "[9038]\ttraining's binary_logloss: 0.105242\n",
      "[9039]\ttraining's binary_logloss: 0.105233\n",
      "[9040]\ttraining's binary_logloss: 0.105231\n",
      "[9041]\ttraining's binary_logloss: 0.105222\n",
      "[9042]\ttraining's binary_logloss: 0.105213\n",
      "[9043]\ttraining's binary_logloss: 0.105202\n",
      "[9044]\ttraining's binary_logloss: 0.105191\n",
      "[9045]\ttraining's binary_logloss: 0.105182\n",
      "[9046]\ttraining's binary_logloss: 0.105172\n",
      "[9047]\ttraining's binary_logloss: 0.105165\n",
      "[9048]\ttraining's binary_logloss: 0.105154\n",
      "[9049]\ttraining's binary_logloss: 0.10515\n",
      "[9050]\ttraining's binary_logloss: 0.10514\n",
      "[9051]\ttraining's binary_logloss: 0.105131\n",
      "[9052]\ttraining's binary_logloss: 0.105125\n",
      "[9053]\ttraining's binary_logloss: 0.105123\n",
      "[9054]\ttraining's binary_logloss: 0.105114\n",
      "[9055]\ttraining's binary_logloss: 0.105105\n",
      "[9056]\ttraining's binary_logloss: 0.105098\n",
      "[9057]\ttraining's binary_logloss: 0.105088\n",
      "[9058]\ttraining's binary_logloss: 0.105087\n",
      "[9059]\ttraining's binary_logloss: 0.105078\n",
      "[9060]\ttraining's binary_logloss: 0.105071\n",
      "[9061]\ttraining's binary_logloss: 0.105068\n",
      "[9062]\ttraining's binary_logloss: 0.105058\n",
      "[9063]\ttraining's binary_logloss: 0.10505\n",
      "[9064]\ttraining's binary_logloss: 0.10504\n",
      "[9065]\ttraining's binary_logloss: 0.105033\n",
      "[9066]\ttraining's binary_logloss: 0.105028\n",
      "[9067]\ttraining's binary_logloss: 0.105026\n",
      "[9068]\ttraining's binary_logloss: 0.105016\n",
      "[9069]\ttraining's binary_logloss: 0.105007\n",
      "[9070]\ttraining's binary_logloss: 0.105\n",
      "[9071]\ttraining's binary_logloss: 0.10499\n",
      "[9072]\ttraining's binary_logloss: 0.10498\n",
      "[9073]\ttraining's binary_logloss: 0.104973\n",
      "[9074]\ttraining's binary_logloss: 0.104964\n",
      "[9075]\ttraining's binary_logloss: 0.104953\n",
      "[9076]\ttraining's binary_logloss: 0.104943\n",
      "[9077]\ttraining's binary_logloss: 0.104932\n",
      "[9078]\ttraining's binary_logloss: 0.104924\n",
      "[9079]\ttraining's binary_logloss: 0.104914\n",
      "[9080]\ttraining's binary_logloss: 0.104906\n",
      "[9081]\ttraining's binary_logloss: 0.104897\n",
      "[9082]\ttraining's binary_logloss: 0.104896\n",
      "[9083]\ttraining's binary_logloss: 0.104895\n",
      "[9084]\ttraining's binary_logloss: 0.104886\n",
      "[9085]\ttraining's binary_logloss: 0.104878\n",
      "[9086]\ttraining's binary_logloss: 0.104872\n",
      "[9087]\ttraining's binary_logloss: 0.104862\n",
      "[9088]\ttraining's binary_logloss: 0.104854\n",
      "[9089]\ttraining's binary_logloss: 0.104849\n",
      "[9090]\ttraining's binary_logloss: 0.104844\n",
      "[9091]\ttraining's binary_logloss: 0.104834\n",
      "[9092]\ttraining's binary_logloss: 0.104827\n",
      "[9093]\ttraining's binary_logloss: 0.104819\n",
      "[9094]\ttraining's binary_logloss: 0.10481\n",
      "[9095]\ttraining's binary_logloss: 0.104797\n",
      "[9096]\ttraining's binary_logloss: 0.10479\n",
      "[9097]\ttraining's binary_logloss: 0.10478\n",
      "[9098]\ttraining's binary_logloss: 0.104779\n",
      "[9099]\ttraining's binary_logloss: 0.104774\n",
      "[9100]\ttraining's binary_logloss: 0.104771\n",
      "[9101]\ttraining's binary_logloss: 0.104767\n",
      "[9102]\ttraining's binary_logloss: 0.104757\n",
      "[9103]\ttraining's binary_logloss: 0.104753\n",
      "[9104]\ttraining's binary_logloss: 0.104746\n",
      "[9105]\ttraining's binary_logloss: 0.104735\n",
      "[9106]\ttraining's binary_logloss: 0.104725\n",
      "[9107]\ttraining's binary_logloss: 0.104716\n",
      "[9108]\ttraining's binary_logloss: 0.104706\n",
      "[9109]\ttraining's binary_logloss: 0.104697\n",
      "[9110]\ttraining's binary_logloss: 0.104687\n",
      "[9111]\ttraining's binary_logloss: 0.104676\n",
      "[9112]\ttraining's binary_logloss: 0.104667\n",
      "[9113]\ttraining's binary_logloss: 0.104657\n",
      "[9114]\ttraining's binary_logloss: 0.104647\n",
      "[9115]\ttraining's binary_logloss: 0.104641\n",
      "[9116]\ttraining's binary_logloss: 0.104631\n",
      "[9117]\ttraining's binary_logloss: 0.104621\n",
      "[9118]\ttraining's binary_logloss: 0.104613\n",
      "[9119]\ttraining's binary_logloss: 0.10461\n",
      "[9120]\ttraining's binary_logloss: 0.104605\n",
      "[9121]\ttraining's binary_logloss: 0.104599\n",
      "[9122]\ttraining's binary_logloss: 0.104593\n",
      "[9123]\ttraining's binary_logloss: 0.104589\n",
      "[9124]\ttraining's binary_logloss: 0.104581\n",
      "[9125]\ttraining's binary_logloss: 0.104571\n",
      "[9126]\ttraining's binary_logloss: 0.104565\n",
      "[9127]\ttraining's binary_logloss: 0.104555\n",
      "[9128]\ttraining's binary_logloss: 0.104546\n",
      "[9129]\ttraining's binary_logloss: 0.104537\n",
      "[9130]\ttraining's binary_logloss: 0.104526\n",
      "[9131]\ttraining's binary_logloss: 0.104519\n",
      "[9132]\ttraining's binary_logloss: 0.104509\n",
      "[9133]\ttraining's binary_logloss: 0.104498\n",
      "[9134]\ttraining's binary_logloss: 0.10449\n",
      "[9135]\ttraining's binary_logloss: 0.104479\n",
      "[9136]\ttraining's binary_logloss: 0.104471\n",
      "[9137]\ttraining's binary_logloss: 0.104461\n",
      "[9138]\ttraining's binary_logloss: 0.104451\n",
      "[9139]\ttraining's binary_logloss: 0.104442\n",
      "[9140]\ttraining's binary_logloss: 0.104433\n",
      "[9141]\ttraining's binary_logloss: 0.104424\n",
      "[9142]\ttraining's binary_logloss: 0.104416\n",
      "[9143]\ttraining's binary_logloss: 0.10441\n",
      "[9144]\ttraining's binary_logloss: 0.104401\n",
      "[9145]\ttraining's binary_logloss: 0.104392\n",
      "[9146]\ttraining's binary_logloss: 0.104383\n",
      "[9147]\ttraining's binary_logloss: 0.104377\n",
      "[9148]\ttraining's binary_logloss: 0.104369\n",
      "[9149]\ttraining's binary_logloss: 0.104359\n",
      "[9150]\ttraining's binary_logloss: 0.104352\n",
      "[9151]\ttraining's binary_logloss: 0.104342\n",
      "[9152]\ttraining's binary_logloss: 0.104333\n",
      "[9153]\ttraining's binary_logloss: 0.104322\n",
      "[9154]\ttraining's binary_logloss: 0.104313\n",
      "[9155]\ttraining's binary_logloss: 0.104302\n",
      "[9156]\ttraining's binary_logloss: 0.1043\n",
      "[9157]\ttraining's binary_logloss: 0.104298\n",
      "[9158]\ttraining's binary_logloss: 0.104288\n",
      "[9159]\ttraining's binary_logloss: 0.104285\n",
      "[9160]\ttraining's binary_logloss: 0.104276\n",
      "[9161]\ttraining's binary_logloss: 0.104267\n",
      "[9162]\ttraining's binary_logloss: 0.104264\n",
      "[9163]\ttraining's binary_logloss: 0.104262\n",
      "[9164]\ttraining's binary_logloss: 0.104251\n",
      "[9165]\ttraining's binary_logloss: 0.104241\n",
      "[9166]\ttraining's binary_logloss: 0.104235\n",
      "[9167]\ttraining's binary_logloss: 0.104224\n",
      "[9168]\ttraining's binary_logloss: 0.104214\n",
      "[9169]\ttraining's binary_logloss: 0.104213\n",
      "[9170]\ttraining's binary_logloss: 0.104201\n",
      "[9171]\ttraining's binary_logloss: 0.104195\n",
      "[9172]\ttraining's binary_logloss: 0.104185\n",
      "[9173]\ttraining's binary_logloss: 0.104175\n",
      "[9174]\ttraining's binary_logloss: 0.104172\n",
      "[9175]\ttraining's binary_logloss: 0.104171\n",
      "[9176]\ttraining's binary_logloss: 0.104165\n",
      "[9177]\ttraining's binary_logloss: 0.104159\n",
      "[9178]\ttraining's binary_logloss: 0.104149\n",
      "[9179]\ttraining's binary_logloss: 0.104146\n",
      "[9180]\ttraining's binary_logloss: 0.104134\n",
      "[9181]\ttraining's binary_logloss: 0.104123\n",
      "[9182]\ttraining's binary_logloss: 0.104116\n",
      "[9183]\ttraining's binary_logloss: 0.104108\n",
      "[9184]\ttraining's binary_logloss: 0.104099\n",
      "[9185]\ttraining's binary_logloss: 0.104097\n",
      "[9186]\ttraining's binary_logloss: 0.104089\n",
      "[9187]\ttraining's binary_logloss: 0.104076\n",
      "[9188]\ttraining's binary_logloss: 0.104068\n",
      "[9189]\ttraining's binary_logloss: 0.104059\n",
      "[9190]\ttraining's binary_logloss: 0.104051\n",
      "[9191]\ttraining's binary_logloss: 0.104048\n",
      "[9192]\ttraining's binary_logloss: 0.104039\n",
      "[9193]\ttraining's binary_logloss: 0.10403\n",
      "[9194]\ttraining's binary_logloss: 0.10402\n",
      "[9195]\ttraining's binary_logloss: 0.104016\n",
      "[9196]\ttraining's binary_logloss: 0.104006\n",
      "[9197]\ttraining's binary_logloss: 0.103993\n",
      "[9198]\ttraining's binary_logloss: 0.103986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9199]\ttraining's binary_logloss: 0.103974\n",
      "[9200]\ttraining's binary_logloss: 0.103965\n",
      "[9201]\ttraining's binary_logloss: 0.103956\n",
      "[9202]\ttraining's binary_logloss: 0.103946\n",
      "[9203]\ttraining's binary_logloss: 0.10394\n",
      "[9204]\ttraining's binary_logloss: 0.10393\n",
      "[9205]\ttraining's binary_logloss: 0.103922\n",
      "[9206]\ttraining's binary_logloss: 0.10391\n",
      "[9207]\ttraining's binary_logloss: 0.103898\n",
      "[9208]\ttraining's binary_logloss: 0.103887\n",
      "[9209]\ttraining's binary_logloss: 0.103878\n",
      "[9210]\ttraining's binary_logloss: 0.103868\n",
      "[9211]\ttraining's binary_logloss: 0.10386\n",
      "[9212]\ttraining's binary_logloss: 0.103853\n",
      "[9213]\ttraining's binary_logloss: 0.103843\n",
      "[9214]\ttraining's binary_logloss: 0.103832\n",
      "[9215]\ttraining's binary_logloss: 0.103822\n",
      "[9216]\ttraining's binary_logloss: 0.103811\n",
      "[9217]\ttraining's binary_logloss: 0.103803\n",
      "[9218]\ttraining's binary_logloss: 0.10379\n",
      "[9219]\ttraining's binary_logloss: 0.10378\n",
      "[9220]\ttraining's binary_logloss: 0.103771\n",
      "[9221]\ttraining's binary_logloss: 0.10376\n",
      "[9222]\ttraining's binary_logloss: 0.103752\n",
      "[9223]\ttraining's binary_logloss: 0.103742\n",
      "[9224]\ttraining's binary_logloss: 0.103731\n",
      "[9225]\ttraining's binary_logloss: 0.103721\n",
      "[9226]\ttraining's binary_logloss: 0.10371\n",
      "[9227]\ttraining's binary_logloss: 0.103702\n",
      "[9228]\ttraining's binary_logloss: 0.103694\n",
      "[9229]\ttraining's binary_logloss: 0.103685\n",
      "[9230]\ttraining's binary_logloss: 0.103673\n",
      "[9231]\ttraining's binary_logloss: 0.103665\n",
      "[9232]\ttraining's binary_logloss: 0.103661\n",
      "[9233]\ttraining's binary_logloss: 0.103652\n",
      "[9234]\ttraining's binary_logloss: 0.103641\n",
      "[9235]\ttraining's binary_logloss: 0.103635\n",
      "[9236]\ttraining's binary_logloss: 0.103634\n",
      "[9237]\ttraining's binary_logloss: 0.103623\n",
      "[9238]\ttraining's binary_logloss: 0.103613\n",
      "[9239]\ttraining's binary_logloss: 0.103602\n",
      "[9240]\ttraining's binary_logloss: 0.103593\n",
      "[9241]\ttraining's binary_logloss: 0.103583\n",
      "[9242]\ttraining's binary_logloss: 0.103571\n",
      "[9243]\ttraining's binary_logloss: 0.10356\n",
      "[9244]\ttraining's binary_logloss: 0.103558\n",
      "[9245]\ttraining's binary_logloss: 0.103545\n",
      "[9246]\ttraining's binary_logloss: 0.103537\n",
      "[9247]\ttraining's binary_logloss: 0.10353\n",
      "[9248]\ttraining's binary_logloss: 0.103524\n",
      "[9249]\ttraining's binary_logloss: 0.103512\n",
      "[9250]\ttraining's binary_logloss: 0.103507\n",
      "[9251]\ttraining's binary_logloss: 0.103495\n",
      "[9252]\ttraining's binary_logloss: 0.103491\n",
      "[9253]\ttraining's binary_logloss: 0.103481\n",
      "[9254]\ttraining's binary_logloss: 0.103471\n",
      "[9255]\ttraining's binary_logloss: 0.103467\n",
      "[9256]\ttraining's binary_logloss: 0.103464\n",
      "[9257]\ttraining's binary_logloss: 0.103456\n",
      "[9258]\ttraining's binary_logloss: 0.103444\n",
      "[9259]\ttraining's binary_logloss: 0.103434\n",
      "[9260]\ttraining's binary_logloss: 0.103422\n",
      "[9261]\ttraining's binary_logloss: 0.103411\n",
      "[9262]\ttraining's binary_logloss: 0.103403\n",
      "[9263]\ttraining's binary_logloss: 0.103398\n",
      "[9264]\ttraining's binary_logloss: 0.103389\n",
      "[9265]\ttraining's binary_logloss: 0.103378\n",
      "[9266]\ttraining's binary_logloss: 0.103368\n",
      "[9267]\ttraining's binary_logloss: 0.103358\n",
      "[9268]\ttraining's binary_logloss: 0.10335\n",
      "[9269]\ttraining's binary_logloss: 0.103341\n",
      "[9270]\ttraining's binary_logloss: 0.103332\n",
      "[9271]\ttraining's binary_logloss: 0.103323\n",
      "[9272]\ttraining's binary_logloss: 0.103314\n",
      "[9273]\ttraining's binary_logloss: 0.103311\n",
      "[9274]\ttraining's binary_logloss: 0.103302\n",
      "[9275]\ttraining's binary_logloss: 0.103295\n",
      "[9276]\ttraining's binary_logloss: 0.103292\n",
      "[9277]\ttraining's binary_logloss: 0.103283\n",
      "[9278]\ttraining's binary_logloss: 0.103275\n",
      "[9279]\ttraining's binary_logloss: 0.103265\n",
      "[9280]\ttraining's binary_logloss: 0.103262\n",
      "[9281]\ttraining's binary_logloss: 0.103252\n",
      "[9282]\ttraining's binary_logloss: 0.103243\n",
      "[9283]\ttraining's binary_logloss: 0.103235\n",
      "[9284]\ttraining's binary_logloss: 0.103233\n",
      "[9285]\ttraining's binary_logloss: 0.103221\n",
      "[9286]\ttraining's binary_logloss: 0.103211\n",
      "[9287]\ttraining's binary_logloss: 0.103202\n",
      "[9288]\ttraining's binary_logloss: 0.103199\n",
      "[9289]\ttraining's binary_logloss: 0.103195\n",
      "[9290]\ttraining's binary_logloss: 0.103186\n",
      "[9291]\ttraining's binary_logloss: 0.103177\n",
      "[9292]\ttraining's binary_logloss: 0.103174\n",
      "[9293]\ttraining's binary_logloss: 0.103173\n",
      "[9294]\ttraining's binary_logloss: 0.103167\n",
      "[9295]\ttraining's binary_logloss: 0.103159\n",
      "[9296]\ttraining's binary_logloss: 0.103149\n",
      "[9297]\ttraining's binary_logloss: 0.103142\n",
      "[9298]\ttraining's binary_logloss: 0.103131\n",
      "[9299]\ttraining's binary_logloss: 0.103119\n",
      "[9300]\ttraining's binary_logloss: 0.103117\n",
      "[9301]\ttraining's binary_logloss: 0.103106\n",
      "[9302]\ttraining's binary_logloss: 0.103096\n",
      "[9303]\ttraining's binary_logloss: 0.103087\n",
      "[9304]\ttraining's binary_logloss: 0.103079\n",
      "[9305]\ttraining's binary_logloss: 0.103074\n",
      "[9306]\ttraining's binary_logloss: 0.103064\n",
      "[9307]\ttraining's binary_logloss: 0.103053\n",
      "[9308]\ttraining's binary_logloss: 0.103043\n",
      "[9309]\ttraining's binary_logloss: 0.103034\n",
      "[9310]\ttraining's binary_logloss: 0.103033\n",
      "[9311]\ttraining's binary_logloss: 0.103022\n",
      "[9312]\ttraining's binary_logloss: 0.103013\n",
      "[9313]\ttraining's binary_logloss: 0.103004\n",
      "[9314]\ttraining's binary_logloss: 0.102994\n",
      "[9315]\ttraining's binary_logloss: 0.102983\n",
      "[9316]\ttraining's binary_logloss: 0.102975\n",
      "[9317]\ttraining's binary_logloss: 0.102966\n",
      "[9318]\ttraining's binary_logloss: 0.102957\n",
      "[9319]\ttraining's binary_logloss: 0.102952\n",
      "[9320]\ttraining's binary_logloss: 0.102943\n",
      "[9321]\ttraining's binary_logloss: 0.102934\n",
      "[9322]\ttraining's binary_logloss: 0.102923\n",
      "[9323]\ttraining's binary_logloss: 0.102914\n",
      "[9324]\ttraining's binary_logloss: 0.102904\n",
      "[9325]\ttraining's binary_logloss: 0.102895\n",
      "[9326]\ttraining's binary_logloss: 0.102885\n",
      "[9327]\ttraining's binary_logloss: 0.102875\n",
      "[9328]\ttraining's binary_logloss: 0.102866\n",
      "[9329]\ttraining's binary_logloss: 0.102861\n",
      "[9330]\ttraining's binary_logloss: 0.102852\n",
      "[9331]\ttraining's binary_logloss: 0.102841\n",
      "[9332]\ttraining's binary_logloss: 0.102832\n",
      "[9333]\ttraining's binary_logloss: 0.102822\n",
      "[9334]\ttraining's binary_logloss: 0.102815\n",
      "[9335]\ttraining's binary_logloss: 0.102807\n",
      "[9336]\ttraining's binary_logloss: 0.102797\n",
      "[9337]\ttraining's binary_logloss: 0.102789\n",
      "[9338]\ttraining's binary_logloss: 0.102779\n",
      "[9339]\ttraining's binary_logloss: 0.102769\n",
      "[9340]\ttraining's binary_logloss: 0.102758\n",
      "[9341]\ttraining's binary_logloss: 0.102751\n",
      "[9342]\ttraining's binary_logloss: 0.102743\n",
      "[9343]\ttraining's binary_logloss: 0.102734\n",
      "[9344]\ttraining's binary_logloss: 0.102724\n",
      "[9345]\ttraining's binary_logloss: 0.102714\n",
      "[9346]\ttraining's binary_logloss: 0.102704\n",
      "[9347]\ttraining's binary_logloss: 0.102695\n",
      "[9348]\ttraining's binary_logloss: 0.102685\n",
      "[9349]\ttraining's binary_logloss: 0.102684\n",
      "[9350]\ttraining's binary_logloss: 0.102682\n",
      "[9351]\ttraining's binary_logloss: 0.102678\n",
      "[9352]\ttraining's binary_logloss: 0.102673\n",
      "[9353]\ttraining's binary_logloss: 0.102672\n",
      "[9354]\ttraining's binary_logloss: 0.102668\n",
      "[9355]\ttraining's binary_logloss: 0.102663\n",
      "[9356]\ttraining's binary_logloss: 0.102654\n",
      "[9357]\ttraining's binary_logloss: 0.10265\n",
      "[9358]\ttraining's binary_logloss: 0.102641\n",
      "[9359]\ttraining's binary_logloss: 0.102633\n",
      "[9360]\ttraining's binary_logloss: 0.102623\n",
      "[9361]\ttraining's binary_logloss: 0.102615\n",
      "[9362]\ttraining's binary_logloss: 0.102614\n",
      "[9363]\ttraining's binary_logloss: 0.102609\n",
      "[9364]\ttraining's binary_logloss: 0.102602\n",
      "[9365]\ttraining's binary_logloss: 0.102594\n",
      "[9366]\ttraining's binary_logloss: 0.102584\n",
      "[9367]\ttraining's binary_logloss: 0.10258\n",
      "[9368]\ttraining's binary_logloss: 0.102571\n",
      "[9369]\ttraining's binary_logloss: 0.102564\n",
      "[9370]\ttraining's binary_logloss: 0.102563\n",
      "[9371]\ttraining's binary_logloss: 0.102558\n",
      "[9372]\ttraining's binary_logloss: 0.102549\n",
      "[9373]\ttraining's binary_logloss: 0.102539\n",
      "[9374]\ttraining's binary_logloss: 0.102537\n",
      "[9375]\ttraining's binary_logloss: 0.102527\n",
      "[9376]\ttraining's binary_logloss: 0.102517\n",
      "[9377]\ttraining's binary_logloss: 0.102507\n",
      "[9378]\ttraining's binary_logloss: 0.102498\n",
      "[9379]\ttraining's binary_logloss: 0.102491\n",
      "[9380]\ttraining's binary_logloss: 0.102482\n",
      "[9381]\ttraining's binary_logloss: 0.10248\n",
      "[9382]\ttraining's binary_logloss: 0.102469\n",
      "[9383]\ttraining's binary_logloss: 0.102462\n",
      "[9384]\ttraining's binary_logloss: 0.102453\n",
      "[9385]\ttraining's binary_logloss: 0.102444\n",
      "[9386]\ttraining's binary_logloss: 0.102435\n",
      "[9387]\ttraining's binary_logloss: 0.102425\n",
      "[9388]\ttraining's binary_logloss: 0.102416\n",
      "[9389]\ttraining's binary_logloss: 0.102408\n",
      "[9390]\ttraining's binary_logloss: 0.102399\n",
      "[9391]\ttraining's binary_logloss: 0.102395\n",
      "[9392]\ttraining's binary_logloss: 0.102384\n",
      "[9393]\ttraining's binary_logloss: 0.10238\n",
      "[9394]\ttraining's binary_logloss: 0.102374\n",
      "[9395]\ttraining's binary_logloss: 0.102366\n",
      "[9396]\ttraining's binary_logloss: 0.102357\n",
      "[9397]\ttraining's binary_logloss: 0.102349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9398]\ttraining's binary_logloss: 0.102338\n",
      "[9399]\ttraining's binary_logloss: 0.102328\n",
      "[9400]\ttraining's binary_logloss: 0.10232\n",
      "[9401]\ttraining's binary_logloss: 0.102312\n",
      "[9402]\ttraining's binary_logloss: 0.102304\n",
      "[9403]\ttraining's binary_logloss: 0.102295\n",
      "[9404]\ttraining's binary_logloss: 0.102285\n",
      "[9405]\ttraining's binary_logloss: 0.102276\n",
      "[9406]\ttraining's binary_logloss: 0.102267\n",
      "[9407]\ttraining's binary_logloss: 0.102262\n",
      "[9408]\ttraining's binary_logloss: 0.10226\n",
      "[9409]\ttraining's binary_logloss: 0.102252\n",
      "[9410]\ttraining's binary_logloss: 0.102247\n",
      "[9411]\ttraining's binary_logloss: 0.102245\n",
      "[9412]\ttraining's binary_logloss: 0.102235\n",
      "[9413]\ttraining's binary_logloss: 0.102226\n",
      "[9414]\ttraining's binary_logloss: 0.102215\n",
      "[9415]\ttraining's binary_logloss: 0.102205\n",
      "[9416]\ttraining's binary_logloss: 0.102196\n",
      "[9417]\ttraining's binary_logloss: 0.102188\n",
      "[9418]\ttraining's binary_logloss: 0.102181\n",
      "[9419]\ttraining's binary_logloss: 0.102175\n",
      "[9420]\ttraining's binary_logloss: 0.102167\n",
      "[9421]\ttraining's binary_logloss: 0.102161\n",
      "[9422]\ttraining's binary_logloss: 0.102153\n",
      "[9423]\ttraining's binary_logloss: 0.102143\n",
      "[9424]\ttraining's binary_logloss: 0.102133\n",
      "[9425]\ttraining's binary_logloss: 0.102123\n",
      "[9426]\ttraining's binary_logloss: 0.102114\n",
      "[9427]\ttraining's binary_logloss: 0.102104\n",
      "[9428]\ttraining's binary_logloss: 0.102095\n",
      "[9429]\ttraining's binary_logloss: 0.102089\n",
      "[9430]\ttraining's binary_logloss: 0.102082\n",
      "[9431]\ttraining's binary_logloss: 0.102072\n",
      "[9432]\ttraining's binary_logloss: 0.102063\n",
      "[9433]\ttraining's binary_logloss: 0.102058\n",
      "[9434]\ttraining's binary_logloss: 0.10205\n",
      "[9435]\ttraining's binary_logloss: 0.102042\n",
      "[9436]\ttraining's binary_logloss: 0.10204\n",
      "[9437]\ttraining's binary_logloss: 0.102039\n",
      "[9438]\ttraining's binary_logloss: 0.102026\n",
      "[9439]\ttraining's binary_logloss: 0.102023\n",
      "[9440]\ttraining's binary_logloss: 0.102014\n",
      "[9441]\ttraining's binary_logloss: 0.102004\n",
      "[9442]\ttraining's binary_logloss: 0.102003\n",
      "[9443]\ttraining's binary_logloss: 0.10199\n",
      "[9444]\ttraining's binary_logloss: 0.101985\n",
      "[9445]\ttraining's binary_logloss: 0.101976\n",
      "[9446]\ttraining's binary_logloss: 0.101968\n",
      "[9447]\ttraining's binary_logloss: 0.101958\n",
      "[9448]\ttraining's binary_logloss: 0.101949\n",
      "[9449]\ttraining's binary_logloss: 0.101942\n",
      "[9450]\ttraining's binary_logloss: 0.10194\n",
      "[9451]\ttraining's binary_logloss: 0.101931\n",
      "[9452]\ttraining's binary_logloss: 0.101921\n",
      "[9453]\ttraining's binary_logloss: 0.101912\n",
      "[9454]\ttraining's binary_logloss: 0.101902\n",
      "[9455]\ttraining's binary_logloss: 0.101893\n",
      "[9456]\ttraining's binary_logloss: 0.101891\n",
      "[9457]\ttraining's binary_logloss: 0.101889\n",
      "[9458]\ttraining's binary_logloss: 0.101882\n",
      "[9459]\ttraining's binary_logloss: 0.101873\n",
      "[9460]\ttraining's binary_logloss: 0.101864\n",
      "[9461]\ttraining's binary_logloss: 0.101855\n",
      "[9462]\ttraining's binary_logloss: 0.101849\n",
      "[9463]\ttraining's binary_logloss: 0.101842\n",
      "[9464]\ttraining's binary_logloss: 0.101838\n",
      "[9465]\ttraining's binary_logloss: 0.10183\n",
      "[9466]\ttraining's binary_logloss: 0.101826\n",
      "[9467]\ttraining's binary_logloss: 0.101825\n",
      "[9468]\ttraining's binary_logloss: 0.101815\n",
      "[9469]\ttraining's binary_logloss: 0.101806\n",
      "[9470]\ttraining's binary_logloss: 0.101798\n",
      "[9471]\ttraining's binary_logloss: 0.101788\n",
      "[9472]\ttraining's binary_logloss: 0.101778\n",
      "[9473]\ttraining's binary_logloss: 0.101772\n",
      "[9474]\ttraining's binary_logloss: 0.101763\n",
      "[9475]\ttraining's binary_logloss: 0.101756\n",
      "[9476]\ttraining's binary_logloss: 0.10175\n",
      "[9477]\ttraining's binary_logloss: 0.101742\n",
      "[9478]\ttraining's binary_logloss: 0.101732\n",
      "[9479]\ttraining's binary_logloss: 0.101722\n",
      "[9480]\ttraining's binary_logloss: 0.101718\n",
      "[9481]\ttraining's binary_logloss: 0.101709\n",
      "[9482]\ttraining's binary_logloss: 0.101699\n",
      "[9483]\ttraining's binary_logloss: 0.101691\n",
      "[9484]\ttraining's binary_logloss: 0.101683\n",
      "[9485]\ttraining's binary_logloss: 0.101678\n",
      "[9486]\ttraining's binary_logloss: 0.101671\n",
      "[9487]\ttraining's binary_logloss: 0.101662\n",
      "[9488]\ttraining's binary_logloss: 0.101653\n",
      "[9489]\ttraining's binary_logloss: 0.101644\n",
      "[9490]\ttraining's binary_logloss: 0.101634\n",
      "[9491]\ttraining's binary_logloss: 0.101624\n",
      "[9492]\ttraining's binary_logloss: 0.101621\n",
      "[9493]\ttraining's binary_logloss: 0.101614\n",
      "[9494]\ttraining's binary_logloss: 0.10161\n",
      "[9495]\ttraining's binary_logloss: 0.101609\n",
      "[9496]\ttraining's binary_logloss: 0.1016\n",
      "[9497]\ttraining's binary_logloss: 0.10159\n",
      "[9498]\ttraining's binary_logloss: 0.10158\n",
      "[9499]\ttraining's binary_logloss: 0.101572\n",
      "[9500]\ttraining's binary_logloss: 0.101564\n",
      "[9501]\ttraining's binary_logloss: 0.101554\n",
      "[9502]\ttraining's binary_logloss: 0.101546\n",
      "[9503]\ttraining's binary_logloss: 0.101537\n",
      "[9504]\ttraining's binary_logloss: 0.101528\n",
      "[9505]\ttraining's binary_logloss: 0.101519\n",
      "[9506]\ttraining's binary_logloss: 0.101515\n",
      "[9507]\ttraining's binary_logloss: 0.101506\n",
      "[9508]\ttraining's binary_logloss: 0.101494\n",
      "[9509]\ttraining's binary_logloss: 0.101485\n",
      "[9510]\ttraining's binary_logloss: 0.101476\n",
      "[9511]\ttraining's binary_logloss: 0.101466\n",
      "[9512]\ttraining's binary_logloss: 0.101456\n",
      "[9513]\ttraining's binary_logloss: 0.101444\n",
      "[9514]\ttraining's binary_logloss: 0.101437\n",
      "[9515]\ttraining's binary_logloss: 0.101427\n",
      "[9516]\ttraining's binary_logloss: 0.101418\n",
      "[9517]\ttraining's binary_logloss: 0.101408\n",
      "[9518]\ttraining's binary_logloss: 0.101397\n",
      "[9519]\ttraining's binary_logloss: 0.101387\n",
      "[9520]\ttraining's binary_logloss: 0.101379\n",
      "[9521]\ttraining's binary_logloss: 0.10137\n",
      "[9522]\ttraining's binary_logloss: 0.101361\n",
      "[9523]\ttraining's binary_logloss: 0.101352\n",
      "[9524]\ttraining's binary_logloss: 0.101343\n",
      "[9525]\ttraining's binary_logloss: 0.101333\n",
      "[9526]\ttraining's binary_logloss: 0.101324\n",
      "[9527]\ttraining's binary_logloss: 0.101319\n",
      "[9528]\ttraining's binary_logloss: 0.101313\n",
      "[9529]\ttraining's binary_logloss: 0.101303\n",
      "[9530]\ttraining's binary_logloss: 0.101301\n",
      "[9531]\ttraining's binary_logloss: 0.101291\n",
      "[9532]\ttraining's binary_logloss: 0.101288\n",
      "[9533]\ttraining's binary_logloss: 0.101281\n",
      "[9534]\ttraining's binary_logloss: 0.101269\n",
      "[9535]\ttraining's binary_logloss: 0.101259\n",
      "[9536]\ttraining's binary_logloss: 0.101247\n",
      "[9537]\ttraining's binary_logloss: 0.101237\n",
      "[9538]\ttraining's binary_logloss: 0.101227\n",
      "[9539]\ttraining's binary_logloss: 0.101218\n",
      "[9540]\ttraining's binary_logloss: 0.101208\n",
      "[9541]\ttraining's binary_logloss: 0.101198\n",
      "[9542]\ttraining's binary_logloss: 0.101186\n",
      "[9543]\ttraining's binary_logloss: 0.101178\n",
      "[9544]\ttraining's binary_logloss: 0.101167\n",
      "[9545]\ttraining's binary_logloss: 0.101157\n",
      "[9546]\ttraining's binary_logloss: 0.101149\n",
      "[9547]\ttraining's binary_logloss: 0.101139\n",
      "[9548]\ttraining's binary_logloss: 0.101129\n",
      "[9549]\ttraining's binary_logloss: 0.101127\n",
      "[9550]\ttraining's binary_logloss: 0.101121\n",
      "[9551]\ttraining's binary_logloss: 0.101114\n",
      "[9552]\ttraining's binary_logloss: 0.101104\n",
      "[9553]\ttraining's binary_logloss: 0.101095\n",
      "[9554]\ttraining's binary_logloss: 0.101086\n",
      "[9555]\ttraining's binary_logloss: 0.101076\n",
      "[9556]\ttraining's binary_logloss: 0.101071\n",
      "[9557]\ttraining's binary_logloss: 0.101063\n",
      "[9558]\ttraining's binary_logloss: 0.101054\n",
      "[9559]\ttraining's binary_logloss: 0.101045\n",
      "[9560]\ttraining's binary_logloss: 0.101037\n",
      "[9561]\ttraining's binary_logloss: 0.101029\n",
      "[9562]\ttraining's binary_logloss: 0.101019\n",
      "[9563]\ttraining's binary_logloss: 0.101013\n",
      "[9564]\ttraining's binary_logloss: 0.101005\n",
      "[9565]\ttraining's binary_logloss: 0.100996\n",
      "[9566]\ttraining's binary_logloss: 0.100987\n",
      "[9567]\ttraining's binary_logloss: 0.100976\n",
      "[9568]\ttraining's binary_logloss: 0.100965\n",
      "[9569]\ttraining's binary_logloss: 0.100956\n",
      "[9570]\ttraining's binary_logloss: 0.100947\n",
      "[9571]\ttraining's binary_logloss: 0.100938\n",
      "[9572]\ttraining's binary_logloss: 0.100936\n",
      "[9573]\ttraining's binary_logloss: 0.100929\n",
      "[9574]\ttraining's binary_logloss: 0.100921\n",
      "[9575]\ttraining's binary_logloss: 0.100916\n",
      "[9576]\ttraining's binary_logloss: 0.100909\n",
      "[9577]\ttraining's binary_logloss: 0.100901\n",
      "[9578]\ttraining's binary_logloss: 0.100892\n",
      "[9579]\ttraining's binary_logloss: 0.100883\n",
      "[9580]\ttraining's binary_logloss: 0.100874\n",
      "[9581]\ttraining's binary_logloss: 0.100865\n",
      "[9582]\ttraining's binary_logloss: 0.100859\n",
      "[9583]\ttraining's binary_logloss: 0.100852\n",
      "[9584]\ttraining's binary_logloss: 0.100842\n",
      "[9585]\ttraining's binary_logloss: 0.100832\n",
      "[9586]\ttraining's binary_logloss: 0.100823\n",
      "[9587]\ttraining's binary_logloss: 0.100816\n",
      "[9588]\ttraining's binary_logloss: 0.100807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9589]\ttraining's binary_logloss: 0.100796\n",
      "[9590]\ttraining's binary_logloss: 0.100788\n",
      "[9591]\ttraining's binary_logloss: 0.100779\n",
      "[9592]\ttraining's binary_logloss: 0.10077\n",
      "[9593]\ttraining's binary_logloss: 0.100761\n",
      "[9594]\ttraining's binary_logloss: 0.100752\n",
      "[9595]\ttraining's binary_logloss: 0.100748\n",
      "[9596]\ttraining's binary_logloss: 0.100737\n",
      "[9597]\ttraining's binary_logloss: 0.100731\n",
      "[9598]\ttraining's binary_logloss: 0.100722\n",
      "[9599]\ttraining's binary_logloss: 0.100713\n",
      "[9600]\ttraining's binary_logloss: 0.100703\n",
      "[9601]\ttraining's binary_logloss: 0.100698\n",
      "[9602]\ttraining's binary_logloss: 0.100694\n",
      "[9603]\ttraining's binary_logloss: 0.100685\n",
      "[9604]\ttraining's binary_logloss: 0.100674\n",
      "[9605]\ttraining's binary_logloss: 0.100666\n",
      "[9606]\ttraining's binary_logloss: 0.100657\n",
      "[9607]\ttraining's binary_logloss: 0.10065\n",
      "[9608]\ttraining's binary_logloss: 0.100642\n",
      "[9609]\ttraining's binary_logloss: 0.100636\n",
      "[9610]\ttraining's binary_logloss: 0.100625\n",
      "[9611]\ttraining's binary_logloss: 0.100615\n",
      "[9612]\ttraining's binary_logloss: 0.100604\n",
      "[9613]\ttraining's binary_logloss: 0.100595\n",
      "[9614]\ttraining's binary_logloss: 0.100585\n",
      "[9615]\ttraining's binary_logloss: 0.100576\n",
      "[9616]\ttraining's binary_logloss: 0.100566\n",
      "[9617]\ttraining's binary_logloss: 0.100566\n",
      "[9618]\ttraining's binary_logloss: 0.100556\n",
      "[9619]\ttraining's binary_logloss: 0.100548\n",
      "[9620]\ttraining's binary_logloss: 0.100538\n",
      "[9621]\ttraining's binary_logloss: 0.100528\n",
      "[9622]\ttraining's binary_logloss: 0.100519\n",
      "[9623]\ttraining's binary_logloss: 0.100511\n",
      "[9624]\ttraining's binary_logloss: 0.100502\n",
      "[9625]\ttraining's binary_logloss: 0.100493\n",
      "[9626]\ttraining's binary_logloss: 0.100485\n",
      "[9627]\ttraining's binary_logloss: 0.100476\n",
      "[9628]\ttraining's binary_logloss: 0.100465\n",
      "[9629]\ttraining's binary_logloss: 0.100457\n",
      "[9630]\ttraining's binary_logloss: 0.100451\n",
      "[9631]\ttraining's binary_logloss: 0.100442\n",
      "[9632]\ttraining's binary_logloss: 0.100432\n",
      "[9633]\ttraining's binary_logloss: 0.100422\n",
      "[9634]\ttraining's binary_logloss: 0.100412\n",
      "[9635]\ttraining's binary_logloss: 0.100402\n",
      "[9636]\ttraining's binary_logloss: 0.100394\n",
      "[9637]\ttraining's binary_logloss: 0.100389\n",
      "[9638]\ttraining's binary_logloss: 0.100378\n",
      "[9639]\ttraining's binary_logloss: 0.10037\n",
      "[9640]\ttraining's binary_logloss: 0.100368\n",
      "[9641]\ttraining's binary_logloss: 0.10036\n",
      "[9642]\ttraining's binary_logloss: 0.100352\n",
      "[9643]\ttraining's binary_logloss: 0.100344\n",
      "[9644]\ttraining's binary_logloss: 0.100334\n",
      "[9645]\ttraining's binary_logloss: 0.100324\n",
      "[9646]\ttraining's binary_logloss: 0.100319\n",
      "[9647]\ttraining's binary_logloss: 0.100318\n",
      "[9648]\ttraining's binary_logloss: 0.100308\n",
      "[9649]\ttraining's binary_logloss: 0.100299\n",
      "[9650]\ttraining's binary_logloss: 0.100292\n",
      "[9651]\ttraining's binary_logloss: 0.100291\n",
      "[9652]\ttraining's binary_logloss: 0.100286\n",
      "[9653]\ttraining's binary_logloss: 0.100276\n",
      "[9654]\ttraining's binary_logloss: 0.100268\n",
      "[9655]\ttraining's binary_logloss: 0.100258\n",
      "[9656]\ttraining's binary_logloss: 0.10025\n",
      "[9657]\ttraining's binary_logloss: 0.100241\n",
      "[9658]\ttraining's binary_logloss: 0.100234\n",
      "[9659]\ttraining's binary_logloss: 0.100223\n",
      "[9660]\ttraining's binary_logloss: 0.100214\n",
      "[9661]\ttraining's binary_logloss: 0.100204\n",
      "[9662]\ttraining's binary_logloss: 0.100198\n",
      "[9663]\ttraining's binary_logloss: 0.100189\n",
      "[9664]\ttraining's binary_logloss: 0.100182\n",
      "[9665]\ttraining's binary_logloss: 0.100172\n",
      "[9666]\ttraining's binary_logloss: 0.100163\n",
      "[9667]\ttraining's binary_logloss: 0.100154\n",
      "[9668]\ttraining's binary_logloss: 0.100145\n",
      "[9669]\ttraining's binary_logloss: 0.100137\n",
      "[9670]\ttraining's binary_logloss: 0.100128\n",
      "[9671]\ttraining's binary_logloss: 0.100118\n",
      "[9672]\ttraining's binary_logloss: 0.100107\n",
      "[9673]\ttraining's binary_logloss: 0.100099\n",
      "[9674]\ttraining's binary_logloss: 0.100097\n",
      "[9675]\ttraining's binary_logloss: 0.10009\n",
      "[9676]\ttraining's binary_logloss: 0.100081\n",
      "[9677]\ttraining's binary_logloss: 0.100071\n",
      "[9678]\ttraining's binary_logloss: 0.100066\n",
      "[9679]\ttraining's binary_logloss: 0.100056\n",
      "[9680]\ttraining's binary_logloss: 0.100047\n",
      "[9681]\ttraining's binary_logloss: 0.10004\n",
      "[9682]\ttraining's binary_logloss: 0.100031\n",
      "[9683]\ttraining's binary_logloss: 0.100024\n",
      "[9684]\ttraining's binary_logloss: 0.100014\n",
      "[9685]\ttraining's binary_logloss: 0.100004\n",
      "[9686]\ttraining's binary_logloss: 0.0999917\n",
      "[9687]\ttraining's binary_logloss: 0.0999818\n",
      "[9688]\ttraining's binary_logloss: 0.0999726\n",
      "[9689]\ttraining's binary_logloss: 0.0999639\n",
      "[9690]\ttraining's binary_logloss: 0.0999554\n",
      "[9691]\ttraining's binary_logloss: 0.0999463\n",
      "[9692]\ttraining's binary_logloss: 0.0999402\n",
      "[9693]\ttraining's binary_logloss: 0.0999305\n",
      "[9694]\ttraining's binary_logloss: 0.0999218\n",
      "[9695]\ttraining's binary_logloss: 0.0999131\n",
      "[9696]\ttraining's binary_logloss: 0.0999091\n",
      "[9697]\ttraining's binary_logloss: 0.0999028\n",
      "[9698]\ttraining's binary_logloss: 0.0998964\n",
      "[9699]\ttraining's binary_logloss: 0.0998875\n",
      "[9700]\ttraining's binary_logloss: 0.0998787\n",
      "[9701]\ttraining's binary_logloss: 0.0998673\n",
      "[9702]\ttraining's binary_logloss: 0.0998599\n",
      "[9703]\ttraining's binary_logloss: 0.0998515\n",
      "[9704]\ttraining's binary_logloss: 0.0998412\n",
      "[9705]\ttraining's binary_logloss: 0.0998341\n",
      "[9706]\ttraining's binary_logloss: 0.0998246\n",
      "[9707]\ttraining's binary_logloss: 0.0998164\n",
      "[9708]\ttraining's binary_logloss: 0.0998112\n",
      "[9709]\ttraining's binary_logloss: 0.0998022\n",
      "[9710]\ttraining's binary_logloss: 0.099793\n",
      "[9711]\ttraining's binary_logloss: 0.0997841\n",
      "[9712]\ttraining's binary_logloss: 0.0997782\n",
      "[9713]\ttraining's binary_logloss: 0.0997688\n",
      "[9714]\ttraining's binary_logloss: 0.0997613\n",
      "[9715]\ttraining's binary_logloss: 0.0997526\n",
      "[9716]\ttraining's binary_logloss: 0.0997442\n",
      "[9717]\ttraining's binary_logloss: 0.0997349\n",
      "[9718]\ttraining's binary_logloss: 0.0997299\n",
      "[9719]\ttraining's binary_logloss: 0.0997201\n",
      "[9720]\ttraining's binary_logloss: 0.0997127\n",
      "[9721]\ttraining's binary_logloss: 0.0997011\n",
      "[9722]\ttraining's binary_logloss: 0.0996918\n",
      "[9723]\ttraining's binary_logloss: 0.0996814\n",
      "[9724]\ttraining's binary_logloss: 0.0996742\n",
      "[9725]\ttraining's binary_logloss: 0.0996633\n",
      "[9726]\ttraining's binary_logloss: 0.0996547\n",
      "[9727]\ttraining's binary_logloss: 0.0996456\n",
      "[9728]\ttraining's binary_logloss: 0.0996361\n",
      "[9729]\ttraining's binary_logloss: 0.0996261\n",
      "[9730]\ttraining's binary_logloss: 0.0996153\n",
      "[9731]\ttraining's binary_logloss: 0.0996048\n",
      "[9732]\ttraining's binary_logloss: 0.0995955\n",
      "[9733]\ttraining's binary_logloss: 0.0995862\n",
      "[9734]\ttraining's binary_logloss: 0.0995761\n",
      "[9735]\ttraining's binary_logloss: 0.0995747\n",
      "[9736]\ttraining's binary_logloss: 0.099567\n",
      "[9737]\ttraining's binary_logloss: 0.099558\n",
      "[9738]\ttraining's binary_logloss: 0.0995491\n",
      "[9739]\ttraining's binary_logloss: 0.0995376\n",
      "[9740]\ttraining's binary_logloss: 0.0995288\n",
      "[9741]\ttraining's binary_logloss: 0.0995205\n",
      "[9742]\ttraining's binary_logloss: 0.0995118\n",
      "[9743]\ttraining's binary_logloss: 0.0995028\n",
      "[9744]\ttraining's binary_logloss: 0.0994974\n",
      "[9745]\ttraining's binary_logloss: 0.0994879\n",
      "[9746]\ttraining's binary_logloss: 0.0994796\n",
      "[9747]\ttraining's binary_logloss: 0.0994705\n",
      "[9748]\ttraining's binary_logloss: 0.0994608\n",
      "[9749]\ttraining's binary_logloss: 0.0994593\n",
      "[9750]\ttraining's binary_logloss: 0.0994496\n",
      "[9751]\ttraining's binary_logloss: 0.0994418\n",
      "[9752]\ttraining's binary_logloss: 0.0994398\n",
      "[9753]\ttraining's binary_logloss: 0.0994313\n",
      "[9754]\ttraining's binary_logloss: 0.0994235\n",
      "[9755]\ttraining's binary_logloss: 0.0994151\n",
      "[9756]\ttraining's binary_logloss: 0.099405\n",
      "[9757]\ttraining's binary_logloss: 0.0993956\n",
      "[9758]\ttraining's binary_logloss: 0.0993853\n",
      "[9759]\ttraining's binary_logloss: 0.0993798\n",
      "[9760]\ttraining's binary_logloss: 0.0993719\n",
      "[9761]\ttraining's binary_logloss: 0.0993617\n",
      "[9762]\ttraining's binary_logloss: 0.0993543\n",
      "[9763]\ttraining's binary_logloss: 0.0993449\n",
      "[9764]\ttraining's binary_logloss: 0.0993442\n",
      "[9765]\ttraining's binary_logloss: 0.0993363\n",
      "[9766]\ttraining's binary_logloss: 0.0993273\n",
      "[9767]\ttraining's binary_logloss: 0.0993186\n",
      "[9768]\ttraining's binary_logloss: 0.0993096\n",
      "[9769]\ttraining's binary_logloss: 0.0993016\n",
      "[9770]\ttraining's binary_logloss: 0.0992968\n",
      "[9771]\ttraining's binary_logloss: 0.0992878\n",
      "[9772]\ttraining's binary_logloss: 0.0992776\n",
      "[9773]\ttraining's binary_logloss: 0.0992681\n",
      "[9774]\ttraining's binary_logloss: 0.0992618\n",
      "[9775]\ttraining's binary_logloss: 0.0992556\n",
      "[9776]\ttraining's binary_logloss: 0.099244\n",
      "[9777]\ttraining's binary_logloss: 0.0992353\n",
      "[9778]\ttraining's binary_logloss: 0.0992244\n",
      "[9779]\ttraining's binary_logloss: 0.0992134\n",
      "[9780]\ttraining's binary_logloss: 0.0992056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9781]\ttraining's binary_logloss: 0.099195\n",
      "[9782]\ttraining's binary_logloss: 0.0991886\n",
      "[9783]\ttraining's binary_logloss: 0.0991876\n",
      "[9784]\ttraining's binary_logloss: 0.0991785\n",
      "[9785]\ttraining's binary_logloss: 0.0991687\n",
      "[9786]\ttraining's binary_logloss: 0.0991602\n",
      "[9787]\ttraining's binary_logloss: 0.0991533\n",
      "[9788]\ttraining's binary_logloss: 0.0991436\n",
      "[9789]\ttraining's binary_logloss: 0.0991392\n",
      "[9790]\ttraining's binary_logloss: 0.0991345\n",
      "[9791]\ttraining's binary_logloss: 0.0991242\n",
      "[9792]\ttraining's binary_logloss: 0.0991186\n",
      "[9793]\ttraining's binary_logloss: 0.0991078\n",
      "[9794]\ttraining's binary_logloss: 0.0991003\n",
      "[9795]\ttraining's binary_logloss: 0.0990994\n",
      "[9796]\ttraining's binary_logloss: 0.0990908\n",
      "[9797]\ttraining's binary_logloss: 0.0990877\n",
      "[9798]\ttraining's binary_logloss: 0.0990785\n",
      "[9799]\ttraining's binary_logloss: 0.0990715\n",
      "[9800]\ttraining's binary_logloss: 0.0990609\n",
      "[9801]\ttraining's binary_logloss: 0.099051\n",
      "[9802]\ttraining's binary_logloss: 0.0990419\n",
      "[9803]\ttraining's binary_logloss: 0.0990327\n",
      "[9804]\ttraining's binary_logloss: 0.0990228\n",
      "[9805]\ttraining's binary_logloss: 0.0990141\n",
      "[9806]\ttraining's binary_logloss: 0.0990063\n",
      "[9807]\ttraining's binary_logloss: 0.098995\n",
      "[9808]\ttraining's binary_logloss: 0.0989889\n",
      "[9809]\ttraining's binary_logloss: 0.0989795\n",
      "[9810]\ttraining's binary_logloss: 0.0989702\n",
      "[9811]\ttraining's binary_logloss: 0.0989627\n",
      "[9812]\ttraining's binary_logloss: 0.0989528\n",
      "[9813]\ttraining's binary_logloss: 0.0989423\n",
      "[9814]\ttraining's binary_logloss: 0.098936\n",
      "[9815]\ttraining's binary_logloss: 0.0989269\n",
      "[9816]\ttraining's binary_logloss: 0.0989178\n",
      "[9817]\ttraining's binary_logloss: 0.0989102\n",
      "[9818]\ttraining's binary_logloss: 0.0989023\n",
      "[9819]\ttraining's binary_logloss: 0.0988934\n",
      "[9820]\ttraining's binary_logloss: 0.0988908\n",
      "[9821]\ttraining's binary_logloss: 0.0988882\n",
      "[9822]\ttraining's binary_logloss: 0.0988801\n",
      "[9823]\ttraining's binary_logloss: 0.0988709\n",
      "[9824]\ttraining's binary_logloss: 0.0988621\n",
      "[9825]\ttraining's binary_logloss: 0.0988508\n",
      "[9826]\ttraining's binary_logloss: 0.098843\n",
      "[9827]\ttraining's binary_logloss: 0.0988372\n",
      "[9828]\ttraining's binary_logloss: 0.0988315\n",
      "[9829]\ttraining's binary_logloss: 0.0988221\n",
      "[9830]\ttraining's binary_logloss: 0.0988131\n",
      "[9831]\ttraining's binary_logloss: 0.0988051\n",
      "[9832]\ttraining's binary_logloss: 0.0987989\n",
      "[9833]\ttraining's binary_logloss: 0.0987907\n",
      "[9834]\ttraining's binary_logloss: 0.0987823\n",
      "[9835]\ttraining's binary_logloss: 0.0987764\n",
      "[9836]\ttraining's binary_logloss: 0.0987678\n",
      "[9837]\ttraining's binary_logloss: 0.0987606\n",
      "[9838]\ttraining's binary_logloss: 0.0987589\n",
      "[9839]\ttraining's binary_logloss: 0.0987575\n",
      "[9840]\ttraining's binary_logloss: 0.0987479\n",
      "[9841]\ttraining's binary_logloss: 0.0987387\n",
      "[9842]\ttraining's binary_logloss: 0.0987324\n",
      "[9843]\ttraining's binary_logloss: 0.0987243\n",
      "[9844]\ttraining's binary_logloss: 0.0987172\n",
      "[9845]\ttraining's binary_logloss: 0.0987085\n",
      "[9846]\ttraining's binary_logloss: 0.0987013\n",
      "[9847]\ttraining's binary_logloss: 0.0986931\n",
      "[9848]\ttraining's binary_logloss: 0.0986849\n",
      "[9849]\ttraining's binary_logloss: 0.0986765\n",
      "[9850]\ttraining's binary_logloss: 0.0986679\n",
      "[9851]\ttraining's binary_logloss: 0.0986592\n",
      "[9852]\ttraining's binary_logloss: 0.0986547\n",
      "[9853]\ttraining's binary_logloss: 0.0986491\n",
      "[9854]\ttraining's binary_logloss: 0.0986472\n",
      "[9855]\ttraining's binary_logloss: 0.0986457\n",
      "[9856]\ttraining's binary_logloss: 0.0986406\n",
      "[9857]\ttraining's binary_logloss: 0.0986295\n",
      "[9858]\ttraining's binary_logloss: 0.0986216\n",
      "[9859]\ttraining's binary_logloss: 0.0986128\n",
      "[9860]\ttraining's binary_logloss: 0.0986121\n",
      "[9861]\ttraining's binary_logloss: 0.0986072\n",
      "[9862]\ttraining's binary_logloss: 0.0986003\n",
      "[9863]\ttraining's binary_logloss: 0.0985897\n",
      "[9864]\ttraining's binary_logloss: 0.0985812\n",
      "[9865]\ttraining's binary_logloss: 0.0985719\n",
      "[9866]\ttraining's binary_logloss: 0.098571\n",
      "[9867]\ttraining's binary_logloss: 0.0985668\n",
      "[9868]\ttraining's binary_logloss: 0.0985602\n",
      "[9869]\ttraining's binary_logloss: 0.098557\n",
      "[9870]\ttraining's binary_logloss: 0.098555\n",
      "[9871]\ttraining's binary_logloss: 0.0985461\n",
      "[9872]\ttraining's binary_logloss: 0.0985363\n",
      "[9873]\ttraining's binary_logloss: 0.098533\n",
      "[9874]\ttraining's binary_logloss: 0.0985268\n",
      "[9875]\ttraining's binary_logloss: 0.0985188\n",
      "[9876]\ttraining's binary_logloss: 0.0985118\n",
      "[9877]\ttraining's binary_logloss: 0.0985109\n",
      "[9878]\ttraining's binary_logloss: 0.0985097\n",
      "[9879]\ttraining's binary_logloss: 0.0985076\n",
      "[9880]\ttraining's binary_logloss: 0.0984984\n",
      "[9881]\ttraining's binary_logloss: 0.0984896\n",
      "[9882]\ttraining's binary_logloss: 0.0984803\n",
      "[9883]\ttraining's binary_logloss: 0.0984738\n",
      "[9884]\ttraining's binary_logloss: 0.0984653\n",
      "[9885]\ttraining's binary_logloss: 0.0984606\n",
      "[9886]\ttraining's binary_logloss: 0.098451\n",
      "[9887]\ttraining's binary_logloss: 0.0984419\n",
      "[9888]\ttraining's binary_logloss: 0.0984374\n",
      "[9889]\ttraining's binary_logloss: 0.0984298\n",
      "[9890]\ttraining's binary_logloss: 0.0984209\n",
      "[9891]\ttraining's binary_logloss: 0.0984173\n",
      "[9892]\ttraining's binary_logloss: 0.0984088\n",
      "[9893]\ttraining's binary_logloss: 0.0984032\n",
      "[9894]\ttraining's binary_logloss: 0.0983964\n",
      "[9895]\ttraining's binary_logloss: 0.0983878\n",
      "[9896]\ttraining's binary_logloss: 0.0983781\n",
      "[9897]\ttraining's binary_logloss: 0.0983704\n",
      "[9898]\ttraining's binary_logloss: 0.0983637\n",
      "[9899]\ttraining's binary_logloss: 0.0983542\n",
      "[9900]\ttraining's binary_logloss: 0.0983456\n",
      "[9901]\ttraining's binary_logloss: 0.0983388\n",
      "[9902]\ttraining's binary_logloss: 0.0983308\n",
      "[9903]\ttraining's binary_logloss: 0.0983276\n",
      "[9904]\ttraining's binary_logloss: 0.0983182\n",
      "[9905]\ttraining's binary_logloss: 0.0983145\n",
      "[9906]\ttraining's binary_logloss: 0.0983061\n",
      "[9907]\ttraining's binary_logloss: 0.0982999\n",
      "[9908]\ttraining's binary_logloss: 0.0982934\n",
      "[9909]\ttraining's binary_logloss: 0.0982922\n",
      "[9910]\ttraining's binary_logloss: 0.0982847\n",
      "[9911]\ttraining's binary_logloss: 0.0982749\n",
      "[9912]\ttraining's binary_logloss: 0.0982727\n",
      "[9913]\ttraining's binary_logloss: 0.0982648\n",
      "[9914]\ttraining's binary_logloss: 0.0982588\n",
      "[9915]\ttraining's binary_logloss: 0.0982568\n",
      "[9916]\ttraining's binary_logloss: 0.0982516\n",
      "[9917]\ttraining's binary_logloss: 0.0982428\n",
      "[9918]\ttraining's binary_logloss: 0.0982342\n",
      "[9919]\ttraining's binary_logloss: 0.0982257\n",
      "[9920]\ttraining's binary_logloss: 0.0982149\n",
      "[9921]\ttraining's binary_logloss: 0.0982054\n",
      "[9922]\ttraining's binary_logloss: 0.0981957\n",
      "[9923]\ttraining's binary_logloss: 0.0981873\n",
      "[9924]\ttraining's binary_logloss: 0.0981782\n",
      "[9925]\ttraining's binary_logloss: 0.098167\n",
      "[9926]\ttraining's binary_logloss: 0.0981586\n",
      "[9927]\ttraining's binary_logloss: 0.0981511\n",
      "[9928]\ttraining's binary_logloss: 0.0981428\n",
      "[9929]\ttraining's binary_logloss: 0.0981343\n",
      "[9930]\ttraining's binary_logloss: 0.0981317\n",
      "[9931]\ttraining's binary_logloss: 0.0981271\n",
      "[9932]\ttraining's binary_logloss: 0.0981256\n",
      "[9933]\ttraining's binary_logloss: 0.0981148\n",
      "[9934]\ttraining's binary_logloss: 0.0981125\n",
      "[9935]\ttraining's binary_logloss: 0.0981031\n",
      "[9936]\ttraining's binary_logloss: 0.0980955\n",
      "[9937]\ttraining's binary_logloss: 0.0980852\n",
      "[9938]\ttraining's binary_logloss: 0.0980795\n",
      "[9939]\ttraining's binary_logloss: 0.0980707\n",
      "[9940]\ttraining's binary_logloss: 0.0980681\n",
      "[9941]\ttraining's binary_logloss: 0.0980583\n",
      "[9942]\ttraining's binary_logloss: 0.0980492\n",
      "[9943]\ttraining's binary_logloss: 0.0980415\n",
      "[9944]\ttraining's binary_logloss: 0.0980341\n",
      "[9945]\ttraining's binary_logloss: 0.0980248\n",
      "[9946]\ttraining's binary_logloss: 0.0980176\n",
      "[9947]\ttraining's binary_logloss: 0.0980088\n",
      "[9948]\ttraining's binary_logloss: 0.0980017\n",
      "[9949]\ttraining's binary_logloss: 0.0979936\n",
      "[9950]\ttraining's binary_logloss: 0.0979852\n",
      "[9951]\ttraining's binary_logloss: 0.0979768\n",
      "[9952]\ttraining's binary_logloss: 0.0979713\n",
      "[9953]\ttraining's binary_logloss: 0.0979611\n",
      "[9954]\ttraining's binary_logloss: 0.0979563\n",
      "[9955]\ttraining's binary_logloss: 0.0979517\n",
      "[9956]\ttraining's binary_logloss: 0.0979434\n",
      "[9957]\ttraining's binary_logloss: 0.0979325\n",
      "[9958]\ttraining's binary_logloss: 0.0979232\n",
      "[9959]\ttraining's binary_logloss: 0.0979169\n",
      "[9960]\ttraining's binary_logloss: 0.0979098\n",
      "[9961]\ttraining's binary_logloss: 0.0979011\n",
      "[9962]\ttraining's binary_logloss: 0.0978918\n",
      "[9963]\ttraining's binary_logloss: 0.0978841\n",
      "[9964]\ttraining's binary_logloss: 0.0978767\n",
      "[9965]\ttraining's binary_logloss: 0.0978682\n",
      "[9966]\ttraining's binary_logloss: 0.0978674\n",
      "[9967]\ttraining's binary_logloss: 0.0978588\n",
      "[9968]\ttraining's binary_logloss: 0.0978486\n",
      "[9969]\ttraining's binary_logloss: 0.097843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9970]\ttraining's binary_logloss: 0.0978387\n",
      "[9971]\ttraining's binary_logloss: 0.0978297\n",
      "[9972]\ttraining's binary_logloss: 0.097822\n",
      "[9973]\ttraining's binary_logloss: 0.0978182\n",
      "[9974]\ttraining's binary_logloss: 0.0978138\n",
      "[9975]\ttraining's binary_logloss: 0.0978047\n",
      "[9976]\ttraining's binary_logloss: 0.0977945\n",
      "[9977]\ttraining's binary_logloss: 0.0977917\n",
      "[9978]\ttraining's binary_logloss: 0.0977836\n",
      "[9979]\ttraining's binary_logloss: 0.0977789\n",
      "[9980]\ttraining's binary_logloss: 0.0977694\n",
      "[9981]\ttraining's binary_logloss: 0.0977602\n",
      "[9982]\ttraining's binary_logloss: 0.0977509\n",
      "[9983]\ttraining's binary_logloss: 0.0977449\n",
      "[9984]\ttraining's binary_logloss: 0.097742\n",
      "[9985]\ttraining's binary_logloss: 0.0977377\n",
      "[9986]\ttraining's binary_logloss: 0.0977337\n",
      "[9987]\ttraining's binary_logloss: 0.0977252\n",
      "[9988]\ttraining's binary_logloss: 0.0977164\n",
      "[9989]\ttraining's binary_logloss: 0.0977084\n",
      "[9990]\ttraining's binary_logloss: 0.0977026\n",
      "[9991]\ttraining's binary_logloss: 0.0976985\n",
      "[9992]\ttraining's binary_logloss: 0.0976902\n",
      "[9993]\ttraining's binary_logloss: 0.0976891\n",
      "[9994]\ttraining's binary_logloss: 0.0976876\n",
      "[9995]\ttraining's binary_logloss: 0.0976803\n",
      "[9996]\ttraining's binary_logloss: 0.0976713\n",
      "[9997]\ttraining's binary_logloss: 0.0976696\n",
      "[9998]\ttraining's binary_logloss: 0.0976654\n",
      "[9999]\ttraining's binary_logloss: 0.0976587\n",
      "[10000]\ttraining's binary_logloss: 0.0976499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    nthread=4,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=34,\n",
    "    colsample_bytree=0.9497036,\n",
    "    subsample=0.8715623,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.041545473,\n",
    "    reg_lambda=0.0735294,\n",
    "    min_split_gain=0.0222415,\n",
    "    min_child_weight=39.3259775,\n",
    "    silent=-1,)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric='f1')\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3f706fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test: 0.11359315589353611\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"Score F1 sur l'ensemble de test: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf4e9bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[42158   245]\n",
      " [ 3485   239]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c77e977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "probas_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Initialiser les listes pour stocker les résultats\n",
    "threshold_array = np.linspace(0, 1, 100)\n",
    "f1_list = []\n",
    "\n",
    "# Calculer le F1 pour différents seuils\n",
    "for threshold in threshold_array:\n",
    "    # Labels prédits pour un seuil donné\n",
    "    label_pred_threshold = (probas_pred > threshold).astype(int)\n",
    "    # Calcul du f1 pour un seuil donné\n",
    "    f1_threshold = f1_score(\n",
    "        y_true=y_test, y_pred=label_pred_threshold\n",
    "    )\n",
    "\n",
    "    f1_list.append(f1_threshold)\n",
    "\n",
    "# Trouver l'indice du maximum de la liste des scores F1\n",
    "best_threshold_index = np.argmax(f1_list)\n",
    "\n",
    "# Récupérer le seuil correspondant\n",
    "best_threshold = threshold_array[best_threshold_index]\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.plot(threshold_array, f1_list)\n",
    "plt.xlabel('Seuil')\n",
    "plt.ylabel('Score F1')\n",
    "plt.title('Score F1 en fonction du seuil')\n",
    "plt.scatter(best_threshold, f1_list[best_threshold_index], color='red', label=f'Max F1 at threshold {best_threshold:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Utiliser le seuil optimal pour les prédictions\n",
    "optimal_predictions = (probas_pred > best_threshold).astype(int)\n",
    "print(optimal_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c768e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché avec le seuil optimal: 0.3183861418704089\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_with_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1] > best_threshold).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_with_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché avec le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e00aeea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[38457  3945]\n",
      " [ 2272  1452]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_hide_test, predictions_with_optimal_threshold)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e888db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prédire sur l'ensemble de test sans le seuil optimal\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions_without_optimal_threshold \u001b[38;5;241m=\u001b[39m (\u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_hide_test)[:, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculer le score F1 avec le seuil optimal\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fbeta_optimal \u001b[38;5;241m=\u001b[39m custom_fbeta_score(y_hide_test, predictions_without_optimal_threshold)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_without_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1]).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_without_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché sans le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d192f",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2119df31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 197877, 1: 17377})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a9d91d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur les données\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "640af6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 197877, 1: 197877})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_resampled)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7809c79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n",
      "[1]\ttraining's binary_logloss: 0.68764\n",
      "[2]\ttraining's binary_logloss: 0.682327\n",
      "[3]\ttraining's binary_logloss: 0.677262\n",
      "[4]\ttraining's binary_logloss: 0.672366\n",
      "[5]\ttraining's binary_logloss: 0.667499\n",
      "[6]\ttraining's binary_logloss: 0.662897\n",
      "[7]\ttraining's binary_logloss: 0.658438\n",
      "[8]\ttraining's binary_logloss: 0.654014\n",
      "[9]\ttraining's binary_logloss: 0.64971\n",
      "[10]\ttraining's binary_logloss: 0.645707\n",
      "[11]\ttraining's binary_logloss: 0.641771\n",
      "[12]\ttraining's binary_logloss: 0.637959\n",
      "[13]\ttraining's binary_logloss: 0.634223\n",
      "[14]\ttraining's binary_logloss: 0.630599\n",
      "[15]\ttraining's binary_logloss: 0.627033\n",
      "[16]\ttraining's binary_logloss: 0.623576\n",
      "[17]\ttraining's binary_logloss: 0.620239\n",
      "[18]\ttraining's binary_logloss: 0.616847\n",
      "[19]\ttraining's binary_logloss: 0.613558\n",
      "[20]\ttraining's binary_logloss: 0.610498\n",
      "[21]\ttraining's binary_logloss: 0.60732\n",
      "[22]\ttraining's binary_logloss: 0.604399\n",
      "[23]\ttraining's binary_logloss: 0.601436\n",
      "[24]\ttraining's binary_logloss: 0.598514\n",
      "[25]\ttraining's binary_logloss: 0.595815\n",
      "[26]\ttraining's binary_logloss: 0.593061\n",
      "[27]\ttraining's binary_logloss: 0.590354\n",
      "[28]\ttraining's binary_logloss: 0.587743\n",
      "[29]\ttraining's binary_logloss: 0.585195\n",
      "[30]\ttraining's binary_logloss: 0.582749\n",
      "[31]\ttraining's binary_logloss: 0.580421\n",
      "[32]\ttraining's binary_logloss: 0.578\n",
      "[33]\ttraining's binary_logloss: 0.575632\n",
      "[34]\ttraining's binary_logloss: 0.573207\n",
      "[35]\ttraining's binary_logloss: 0.570999\n",
      "[36]\ttraining's binary_logloss: 0.568656\n",
      "[37]\ttraining's binary_logloss: 0.566299\n",
      "[38]\ttraining's binary_logloss: 0.564049\n",
      "[39]\ttraining's binary_logloss: 0.561847\n",
      "[40]\ttraining's binary_logloss: 0.559694\n",
      "[41]\ttraining's binary_logloss: 0.55747\n",
      "[42]\ttraining's binary_logloss: 0.555421\n",
      "[43]\ttraining's binary_logloss: 0.553148\n",
      "[44]\ttraining's binary_logloss: 0.550944\n",
      "[45]\ttraining's binary_logloss: 0.54897\n",
      "[46]\ttraining's binary_logloss: 0.547036\n",
      "[47]\ttraining's binary_logloss: 0.544984\n",
      "[48]\ttraining's binary_logloss: 0.54297\n",
      "[49]\ttraining's binary_logloss: 0.540942\n",
      "[50]\ttraining's binary_logloss: 0.538864\n",
      "[51]\ttraining's binary_logloss: 0.536953\n",
      "[52]\ttraining's binary_logloss: 0.534935\n",
      "[53]\ttraining's binary_logloss: 0.532984\n",
      "[54]\ttraining's binary_logloss: 0.531129\n",
      "[55]\ttraining's binary_logloss: 0.52951\n",
      "[56]\ttraining's binary_logloss: 0.527758\n",
      "[57]\ttraining's binary_logloss: 0.52557\n",
      "[58]\ttraining's binary_logloss: 0.523618\n",
      "[59]\ttraining's binary_logloss: 0.521025\n",
      "[60]\ttraining's binary_logloss: 0.51952\n",
      "[61]\ttraining's binary_logloss: 0.517673\n",
      "[62]\ttraining's binary_logloss: 0.516258\n",
      "[63]\ttraining's binary_logloss: 0.514389\n",
      "[64]\ttraining's binary_logloss: 0.512774\n",
      "[65]\ttraining's binary_logloss: 0.510238\n",
      "[66]\ttraining's binary_logloss: 0.508504\n",
      "[67]\ttraining's binary_logloss: 0.506915\n",
      "[68]\ttraining's binary_logloss: 0.505468\n",
      "[69]\ttraining's binary_logloss: 0.503888\n",
      "[70]\ttraining's binary_logloss: 0.502151\n",
      "[71]\ttraining's binary_logloss: 0.499734\n",
      "[72]\ttraining's binary_logloss: 0.498121\n",
      "[73]\ttraining's binary_logloss: 0.496395\n",
      "[74]\ttraining's binary_logloss: 0.494103\n",
      "[75]\ttraining's binary_logloss: 0.491733\n",
      "[76]\ttraining's binary_logloss: 0.490234\n",
      "[77]\ttraining's binary_logloss: 0.488676\n",
      "[78]\ttraining's binary_logloss: 0.486595\n",
      "[79]\ttraining's binary_logloss: 0.484966\n",
      "[80]\ttraining's binary_logloss: 0.483562\n",
      "[81]\ttraining's binary_logloss: 0.480903\n",
      "[82]\ttraining's binary_logloss: 0.478725\n",
      "[83]\ttraining's binary_logloss: 0.477015\n",
      "[84]\ttraining's binary_logloss: 0.474877\n",
      "[85]\ttraining's binary_logloss: 0.473403\n",
      "[86]\ttraining's binary_logloss: 0.471923\n",
      "[87]\ttraining's binary_logloss: 0.47053\n",
      "[88]\ttraining's binary_logloss: 0.468536\n",
      "[89]\ttraining's binary_logloss: 0.467224\n",
      "[90]\ttraining's binary_logloss: 0.466107\n",
      "[91]\ttraining's binary_logloss: 0.464335\n",
      "[92]\ttraining's binary_logloss: 0.462953\n",
      "[93]\ttraining's binary_logloss: 0.460586\n",
      "[94]\ttraining's binary_logloss: 0.45862\n",
      "[95]\ttraining's binary_logloss: 0.457409\n",
      "[96]\ttraining's binary_logloss: 0.455549\n",
      "[97]\ttraining's binary_logloss: 0.454233\n",
      "[98]\ttraining's binary_logloss: 0.451341\n",
      "[99]\ttraining's binary_logloss: 0.449325\n",
      "[100]\ttraining's binary_logloss: 0.448\n",
      "[101]\ttraining's binary_logloss: 0.446077\n",
      "[102]\ttraining's binary_logloss: 0.44475\n",
      "[103]\ttraining's binary_logloss: 0.442026\n",
      "[104]\ttraining's binary_logloss: 0.440337\n",
      "[105]\ttraining's binary_logloss: 0.439184\n",
      "[106]\ttraining's binary_logloss: 0.438087\n",
      "[107]\ttraining's binary_logloss: 0.436309\n",
      "[108]\ttraining's binary_logloss: 0.435214\n",
      "[109]\ttraining's binary_logloss: 0.433437\n",
      "[110]\ttraining's binary_logloss: 0.432339\n",
      "[111]\ttraining's binary_logloss: 0.429796\n",
      "[112]\ttraining's binary_logloss: 0.428367\n",
      "[113]\ttraining's binary_logloss: 0.427032\n",
      "[114]\ttraining's binary_logloss: 0.424592\n",
      "[115]\ttraining's binary_logloss: 0.423323\n",
      "[116]\ttraining's binary_logloss: 0.422341\n",
      "[117]\ttraining's binary_logloss: 0.420707\n",
      "[118]\ttraining's binary_logloss: 0.418379\n",
      "[119]\ttraining's binary_logloss: 0.41705\n",
      "[120]\ttraining's binary_logloss: 0.415657\n",
      "[121]\ttraining's binary_logloss: 0.414492\n",
      "[122]\ttraining's binary_logloss: 0.41267\n",
      "[123]\ttraining's binary_logloss: 0.411124\n",
      "[124]\ttraining's binary_logloss: 0.40955\n",
      "[125]\ttraining's binary_logloss: 0.408669\n",
      "[126]\ttraining's binary_logloss: 0.407816\n",
      "[127]\ttraining's binary_logloss: 0.40635\n",
      "[128]\ttraining's binary_logloss: 0.405158\n",
      "[129]\ttraining's binary_logloss: 0.403735\n",
      "[130]\ttraining's binary_logloss: 0.402859\n",
      "[131]\ttraining's binary_logloss: 0.401408\n",
      "[132]\ttraining's binary_logloss: 0.400392\n",
      "[133]\ttraining's binary_logloss: 0.399201\n",
      "[134]\ttraining's binary_logloss: 0.397781\n",
      "[135]\ttraining's binary_logloss: 0.396401\n",
      "[136]\ttraining's binary_logloss: 0.395437\n",
      "[137]\ttraining's binary_logloss: 0.394436\n",
      "[138]\ttraining's binary_logloss: 0.393298\n",
      "[139]\ttraining's binary_logloss: 0.392331\n",
      "[140]\ttraining's binary_logloss: 0.391422\n",
      "[141]\ttraining's binary_logloss: 0.389878\n",
      "[142]\ttraining's binary_logloss: 0.388313\n",
      "[143]\ttraining's binary_logloss: 0.387405\n",
      "[144]\ttraining's binary_logloss: 0.386661\n",
      "[145]\ttraining's binary_logloss: 0.385854\n",
      "[146]\ttraining's binary_logloss: 0.384574\n",
      "[147]\ttraining's binary_logloss: 0.382702\n",
      "[148]\ttraining's binary_logloss: 0.381852\n",
      "[149]\ttraining's binary_logloss: 0.380395\n",
      "[150]\ttraining's binary_logloss: 0.377471\n",
      "[151]\ttraining's binary_logloss: 0.375597\n",
      "[152]\ttraining's binary_logloss: 0.374591\n",
      "[153]\ttraining's binary_logloss: 0.373755\n",
      "[154]\ttraining's binary_logloss: 0.371949\n",
      "[155]\ttraining's binary_logloss: 0.371259\n",
      "[156]\ttraining's binary_logloss: 0.370283\n",
      "[157]\ttraining's binary_logloss: 0.368956\n",
      "[158]\ttraining's binary_logloss: 0.367826\n",
      "[159]\ttraining's binary_logloss: 0.367031\n",
      "[160]\ttraining's binary_logloss: 0.365648\n",
      "[161]\ttraining's binary_logloss: 0.362945\n",
      "[162]\ttraining's binary_logloss: 0.361258\n",
      "[163]\ttraining's binary_logloss: 0.360083\n",
      "[164]\ttraining's binary_logloss: 0.358806\n",
      "[165]\ttraining's binary_logloss: 0.358138\n",
      "[166]\ttraining's binary_logloss: 0.356526\n",
      "[167]\ttraining's binary_logloss: 0.355618\n",
      "[168]\ttraining's binary_logloss: 0.354453\n",
      "[169]\ttraining's binary_logloss: 0.352212\n",
      "[170]\ttraining's binary_logloss: 0.350994\n",
      "[171]\ttraining's binary_logloss: 0.350117\n",
      "[172]\ttraining's binary_logloss: 0.349498\n",
      "[173]\ttraining's binary_logloss: 0.348481\n",
      "[174]\ttraining's binary_logloss: 0.347861\n",
      "[175]\ttraining's binary_logloss: 0.346643\n",
      "[176]\ttraining's binary_logloss: 0.346001\n",
      "[177]\ttraining's binary_logloss: 0.345228\n",
      "[178]\ttraining's binary_logloss: 0.344065\n",
      "[179]\ttraining's binary_logloss: 0.342921\n",
      "[180]\ttraining's binary_logloss: 0.342339\n",
      "[181]\ttraining's binary_logloss: 0.339978\n",
      "[182]\ttraining's binary_logloss: 0.338545\n",
      "[183]\ttraining's binary_logloss: 0.335801\n",
      "[184]\ttraining's binary_logloss: 0.33503\n",
      "[185]\ttraining's binary_logloss: 0.333658\n",
      "[186]\ttraining's binary_logloss: 0.332976\n",
      "[187]\ttraining's binary_logloss: 0.332424\n",
      "[188]\ttraining's binary_logloss: 0.329802\n",
      "[189]\ttraining's binary_logloss: 0.32849\n",
      "[190]\ttraining's binary_logloss: 0.32636\n",
      "[191]\ttraining's binary_logloss: 0.325486\n",
      "[192]\ttraining's binary_logloss: 0.324225\n",
      "[193]\ttraining's binary_logloss: 0.323689\n",
      "[194]\ttraining's binary_logloss: 0.322784\n",
      "[195]\ttraining's binary_logloss: 0.320178\n",
      "[196]\ttraining's binary_logloss: 0.31919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197]\ttraining's binary_logloss: 0.318362\n",
      "[198]\ttraining's binary_logloss: 0.317805\n",
      "[199]\ttraining's binary_logloss: 0.316741\n",
      "[200]\ttraining's binary_logloss: 0.314264\n",
      "[201]\ttraining's binary_logloss: 0.313461\n",
      "[202]\ttraining's binary_logloss: 0.313035\n",
      "[203]\ttraining's binary_logloss: 0.310649\n",
      "[204]\ttraining's binary_logloss: 0.308328\n",
      "[205]\ttraining's binary_logloss: 0.307466\n",
      "[206]\ttraining's binary_logloss: 0.307065\n",
      "[207]\ttraining's binary_logloss: 0.306452\n",
      "[208]\ttraining's binary_logloss: 0.304224\n",
      "[209]\ttraining's binary_logloss: 0.303256\n",
      "[210]\ttraining's binary_logloss: 0.302576\n",
      "[211]\ttraining's binary_logloss: 0.300434\n",
      "[212]\ttraining's binary_logloss: 0.300041\n",
      "[213]\ttraining's binary_logloss: 0.299277\n",
      "[214]\ttraining's binary_logloss: 0.298628\n",
      "[215]\ttraining's binary_logloss: 0.296565\n",
      "[216]\ttraining's binary_logloss: 0.29597\n",
      "[217]\ttraining's binary_logloss: 0.293969\n",
      "[218]\ttraining's binary_logloss: 0.293494\n",
      "[219]\ttraining's binary_logloss: 0.291558\n",
      "[220]\ttraining's binary_logloss: 0.291043\n",
      "[221]\ttraining's binary_logloss: 0.290007\n",
      "[222]\ttraining's binary_logloss: 0.289558\n",
      "[223]\ttraining's binary_logloss: 0.287701\n",
      "[224]\ttraining's binary_logloss: 0.287029\n",
      "[225]\ttraining's binary_logloss: 0.286032\n",
      "[226]\ttraining's binary_logloss: 0.285645\n",
      "[227]\ttraining's binary_logloss: 0.283864\n",
      "[228]\ttraining's binary_logloss: 0.283157\n",
      "[229]\ttraining's binary_logloss: 0.282797\n",
      "[230]\ttraining's binary_logloss: 0.282413\n",
      "[231]\ttraining's binary_logloss: 0.281998\n",
      "[232]\ttraining's binary_logloss: 0.281056\n",
      "[233]\ttraining's binary_logloss: 0.279722\n",
      "[234]\ttraining's binary_logloss: 0.279415\n",
      "[235]\ttraining's binary_logloss: 0.278503\n",
      "[236]\ttraining's binary_logloss: 0.278155\n",
      "[237]\ttraining's binary_logloss: 0.277229\n",
      "[238]\ttraining's binary_logloss: 0.275592\n",
      "[239]\ttraining's binary_logloss: 0.275098\n",
      "[240]\ttraining's binary_logloss: 0.274528\n",
      "[241]\ttraining's binary_logloss: 0.274075\n",
      "[242]\ttraining's binary_logloss: 0.273461\n",
      "[243]\ttraining's binary_logloss: 0.271888\n",
      "[244]\ttraining's binary_logloss: 0.27158\n",
      "[245]\ttraining's binary_logloss: 0.270391\n",
      "[246]\ttraining's binary_logloss: 0.270042\n",
      "[247]\ttraining's binary_logloss: 0.269365\n",
      "[248]\ttraining's binary_logloss: 0.268536\n",
      "[249]\ttraining's binary_logloss: 0.268056\n",
      "[250]\ttraining's binary_logloss: 0.267567\n",
      "[251]\ttraining's binary_logloss: 0.266764\n",
      "[252]\ttraining's binary_logloss: 0.266484\n",
      "[253]\ttraining's binary_logloss: 0.265034\n",
      "[254]\ttraining's binary_logloss: 0.264676\n",
      "[255]\ttraining's binary_logloss: 0.264374\n",
      "[256]\ttraining's binary_logloss: 0.263915\n",
      "[257]\ttraining's binary_logloss: 0.263268\n",
      "[258]\ttraining's binary_logloss: 0.261875\n",
      "[259]\ttraining's binary_logloss: 0.261451\n",
      "[260]\ttraining's binary_logloss: 0.260685\n",
      "[261]\ttraining's binary_logloss: 0.259946\n",
      "[262]\ttraining's binary_logloss: 0.259521\n",
      "[263]\ttraining's binary_logloss: 0.259258\n",
      "[264]\ttraining's binary_logloss: 0.258709\n",
      "[265]\ttraining's binary_logloss: 0.25739\n",
      "[266]\ttraining's binary_logloss: 0.257118\n",
      "[267]\ttraining's binary_logloss: 0.256019\n",
      "[268]\ttraining's binary_logloss: 0.255726\n",
      "[269]\ttraining's binary_logloss: 0.255006\n",
      "[270]\ttraining's binary_logloss: 0.254443\n",
      "[271]\ttraining's binary_logloss: 0.253944\n",
      "[272]\ttraining's binary_logloss: 0.253476\n",
      "[273]\ttraining's binary_logloss: 0.252927\n",
      "[274]\ttraining's binary_logloss: 0.251711\n",
      "[275]\ttraining's binary_logloss: 0.251335\n",
      "[276]\ttraining's binary_logloss: 0.251121\n",
      "[277]\ttraining's binary_logloss: 0.250115\n",
      "[278]\ttraining's binary_logloss: 0.249569\n",
      "[279]\ttraining's binary_logloss: 0.249138\n",
      "[280]\ttraining's binary_logloss: 0.248453\n",
      "[281]\ttraining's binary_logloss: 0.247312\n",
      "[282]\ttraining's binary_logloss: 0.247052\n",
      "[283]\ttraining's binary_logloss: 0.246547\n",
      "[284]\ttraining's binary_logloss: 0.245447\n",
      "[285]\ttraining's binary_logloss: 0.24495\n",
      "[286]\ttraining's binary_logloss: 0.244702\n",
      "[287]\ttraining's binary_logloss: 0.244512\n",
      "[288]\ttraining's binary_logloss: 0.243449\n",
      "[289]\ttraining's binary_logloss: 0.242988\n",
      "[290]\ttraining's binary_logloss: 0.242716\n",
      "[291]\ttraining's binary_logloss: 0.242141\n",
      "[292]\ttraining's binary_logloss: 0.241697\n",
      "[293]\ttraining's binary_logloss: 0.240685\n",
      "[294]\ttraining's binary_logloss: 0.240219\n",
      "[295]\ttraining's binary_logloss: 0.239638\n",
      "[296]\ttraining's binary_logloss: 0.238665\n",
      "[297]\ttraining's binary_logloss: 0.238174\n",
      "[298]\ttraining's binary_logloss: 0.237729\n",
      "[299]\ttraining's binary_logloss: 0.236791\n",
      "[300]\ttraining's binary_logloss: 0.236411\n",
      "[301]\ttraining's binary_logloss: 0.236233\n",
      "[302]\ttraining's binary_logloss: 0.235821\n",
      "[303]\ttraining's binary_logloss: 0.235562\n",
      "[304]\ttraining's binary_logloss: 0.234659\n",
      "[305]\ttraining's binary_logloss: 0.234327\n",
      "[306]\ttraining's binary_logloss: 0.233816\n",
      "[307]\ttraining's binary_logloss: 0.233351\n",
      "[308]\ttraining's binary_logloss: 0.23319\n",
      "[309]\ttraining's binary_logloss: 0.232964\n",
      "[310]\ttraining's binary_logloss: 0.232617\n",
      "[311]\ttraining's binary_logloss: 0.232413\n",
      "[312]\ttraining's binary_logloss: 0.231676\n",
      "[313]\ttraining's binary_logloss: 0.230973\n",
      "[314]\ttraining's binary_logloss: 0.230473\n",
      "[315]\ttraining's binary_logloss: 0.230029\n",
      "[316]\ttraining's binary_logloss: 0.229725\n",
      "[317]\ttraining's binary_logloss: 0.229326\n",
      "[318]\ttraining's binary_logloss: 0.228928\n",
      "[319]\ttraining's binary_logloss: 0.228143\n",
      "[320]\ttraining's binary_logloss: 0.227853\n",
      "[321]\ttraining's binary_logloss: 0.227631\n",
      "[322]\ttraining's binary_logloss: 0.22742\n",
      "[323]\ttraining's binary_logloss: 0.227084\n",
      "[324]\ttraining's binary_logloss: 0.22629\n",
      "[325]\ttraining's binary_logloss: 0.225976\n",
      "[326]\ttraining's binary_logloss: 0.225323\n",
      "[327]\ttraining's binary_logloss: 0.224904\n",
      "[328]\ttraining's binary_logloss: 0.224497\n",
      "[329]\ttraining's binary_logloss: 0.22415\n",
      "[330]\ttraining's binary_logloss: 0.223886\n",
      "[331]\ttraining's binary_logloss: 0.223739\n",
      "[332]\ttraining's binary_logloss: 0.223431\n",
      "[333]\ttraining's binary_logloss: 0.222692\n",
      "[334]\ttraining's binary_logloss: 0.22231\n",
      "[335]\ttraining's binary_logloss: 0.221979\n",
      "[336]\ttraining's binary_logloss: 0.22169\n",
      "[337]\ttraining's binary_logloss: 0.221463\n",
      "[338]\ttraining's binary_logloss: 0.220859\n",
      "[339]\ttraining's binary_logloss: 0.220466\n",
      "[340]\ttraining's binary_logloss: 0.219762\n",
      "[341]\ttraining's binary_logloss: 0.219598\n",
      "[342]\ttraining's binary_logloss: 0.219018\n",
      "[343]\ttraining's binary_logloss: 0.218798\n",
      "[344]\ttraining's binary_logloss: 0.218221\n",
      "[345]\ttraining's binary_logloss: 0.217841\n",
      "[346]\ttraining's binary_logloss: 0.21761\n",
      "[347]\ttraining's binary_logloss: 0.217358\n",
      "[348]\ttraining's binary_logloss: 0.217227\n",
      "[349]\ttraining's binary_logloss: 0.217029\n",
      "[350]\ttraining's binary_logloss: 0.216781\n",
      "[351]\ttraining's binary_logloss: 0.216508\n",
      "[352]\ttraining's binary_logloss: 0.216144\n",
      "[353]\ttraining's binary_logloss: 0.215805\n",
      "[354]\ttraining's binary_logloss: 0.215491\n",
      "[355]\ttraining's binary_logloss: 0.215359\n",
      "[356]\ttraining's binary_logloss: 0.214826\n",
      "[357]\ttraining's binary_logloss: 0.214465\n",
      "[358]\ttraining's binary_logloss: 0.214181\n",
      "[359]\ttraining's binary_logloss: 0.214033\n",
      "[360]\ttraining's binary_logloss: 0.213801\n",
      "[361]\ttraining's binary_logloss: 0.213255\n",
      "[362]\ttraining's binary_logloss: 0.213039\n",
      "[363]\ttraining's binary_logloss: 0.212793\n",
      "[364]\ttraining's binary_logloss: 0.212449\n",
      "[365]\ttraining's binary_logloss: 0.212065\n",
      "[366]\ttraining's binary_logloss: 0.211915\n",
      "[367]\ttraining's binary_logloss: 0.211728\n",
      "[368]\ttraining's binary_logloss: 0.21115\n",
      "[369]\ttraining's binary_logloss: 0.210998\n",
      "[370]\ttraining's binary_logloss: 0.210734\n",
      "[371]\ttraining's binary_logloss: 0.210569\n",
      "[372]\ttraining's binary_logloss: 0.210064\n",
      "[373]\ttraining's binary_logloss: 0.209878\n",
      "[374]\ttraining's binary_logloss: 0.209322\n",
      "[375]\ttraining's binary_logloss: 0.209036\n",
      "[376]\ttraining's binary_logloss: 0.208769\n",
      "[377]\ttraining's binary_logloss: 0.208316\n",
      "[378]\ttraining's binary_logloss: 0.207839\n",
      "[379]\ttraining's binary_logloss: 0.207612\n",
      "[380]\ttraining's binary_logloss: 0.207383\n",
      "[381]\ttraining's binary_logloss: 0.207225\n",
      "[382]\ttraining's binary_logloss: 0.206925\n",
      "[383]\ttraining's binary_logloss: 0.206611\n",
      "[384]\ttraining's binary_logloss: 0.206459\n",
      "[385]\ttraining's binary_logloss: 0.206219\n",
      "[386]\ttraining's binary_logloss: 0.205804\n",
      "[387]\ttraining's binary_logloss: 0.20555\n",
      "[388]\ttraining's binary_logloss: 0.205282\n",
      "[389]\ttraining's binary_logloss: 0.204833\n",
      "[390]\ttraining's binary_logloss: 0.204573\n",
      "[391]\ttraining's binary_logloss: 0.204419\n",
      "[392]\ttraining's binary_logloss: 0.204119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[393]\ttraining's binary_logloss: 0.203991\n",
      "[394]\ttraining's binary_logloss: 0.203788\n",
      "[395]\ttraining's binary_logloss: 0.203492\n",
      "[396]\ttraining's binary_logloss: 0.203257\n",
      "[397]\ttraining's binary_logloss: 0.202828\n",
      "[398]\ttraining's binary_logloss: 0.202646\n",
      "[399]\ttraining's binary_logloss: 0.202341\n",
      "[400]\ttraining's binary_logloss: 0.202166\n",
      "[401]\ttraining's binary_logloss: 0.20188\n",
      "[402]\ttraining's binary_logloss: 0.201734\n",
      "[403]\ttraining's binary_logloss: 0.201436\n",
      "[404]\ttraining's binary_logloss: 0.201303\n",
      "[405]\ttraining's binary_logloss: 0.200894\n",
      "[406]\ttraining's binary_logloss: 0.200761\n",
      "[407]\ttraining's binary_logloss: 0.2006\n",
      "[408]\ttraining's binary_logloss: 0.200386\n",
      "[409]\ttraining's binary_logloss: 0.200184\n",
      "[410]\ttraining's binary_logloss: 0.19991\n",
      "[411]\ttraining's binary_logloss: 0.199776\n",
      "[412]\ttraining's binary_logloss: 0.199645\n",
      "[413]\ttraining's binary_logloss: 0.199195\n",
      "[414]\ttraining's binary_logloss: 0.198918\n",
      "[415]\ttraining's binary_logloss: 0.198814\n",
      "[416]\ttraining's binary_logloss: 0.19851\n",
      "[417]\ttraining's binary_logloss: 0.19837\n",
      "[418]\ttraining's binary_logloss: 0.198137\n",
      "[419]\ttraining's binary_logloss: 0.198007\n",
      "[420]\ttraining's binary_logloss: 0.197883\n",
      "[421]\ttraining's binary_logloss: 0.197771\n",
      "[422]\ttraining's binary_logloss: 0.197421\n",
      "[423]\ttraining's binary_logloss: 0.197249\n",
      "[424]\ttraining's binary_logloss: 0.196989\n",
      "[425]\ttraining's binary_logloss: 0.196848\n",
      "[426]\ttraining's binary_logloss: 0.196699\n",
      "[427]\ttraining's binary_logloss: 0.196365\n",
      "[428]\ttraining's binary_logloss: 0.196239\n",
      "[429]\ttraining's binary_logloss: 0.196099\n",
      "[430]\ttraining's binary_logloss: 0.195987\n",
      "[431]\ttraining's binary_logloss: 0.195882\n",
      "[432]\ttraining's binary_logloss: 0.195621\n",
      "[433]\ttraining's binary_logloss: 0.195479\n",
      "[434]\ttraining's binary_logloss: 0.195153\n",
      "[435]\ttraining's binary_logloss: 0.194934\n",
      "[436]\ttraining's binary_logloss: 0.194814\n",
      "[437]\ttraining's binary_logloss: 0.194567\n",
      "[438]\ttraining's binary_logloss: 0.194315\n",
      "[439]\ttraining's binary_logloss: 0.194225\n",
      "[440]\ttraining's binary_logloss: 0.194089\n",
      "[441]\ttraining's binary_logloss: 0.193958\n",
      "[442]\ttraining's binary_logloss: 0.1936\n",
      "[443]\ttraining's binary_logloss: 0.193455\n",
      "[444]\ttraining's binary_logloss: 0.1933\n",
      "[445]\ttraining's binary_logloss: 0.193205\n",
      "[446]\ttraining's binary_logloss: 0.192968\n",
      "[447]\ttraining's binary_logloss: 0.192666\n",
      "[448]\ttraining's binary_logloss: 0.192407\n",
      "[449]\ttraining's binary_logloss: 0.192271\n",
      "[450]\ttraining's binary_logloss: 0.192143\n",
      "[451]\ttraining's binary_logloss: 0.191984\n",
      "[452]\ttraining's binary_logloss: 0.191624\n",
      "[453]\ttraining's binary_logloss: 0.191495\n",
      "[454]\ttraining's binary_logloss: 0.191282\n",
      "[455]\ttraining's binary_logloss: 0.191056\n",
      "[456]\ttraining's binary_logloss: 0.190934\n",
      "[457]\ttraining's binary_logloss: 0.190841\n",
      "[458]\ttraining's binary_logloss: 0.190692\n",
      "[459]\ttraining's binary_logloss: 0.190395\n",
      "[460]\ttraining's binary_logloss: 0.190297\n",
      "[461]\ttraining's binary_logloss: 0.190073\n",
      "[462]\ttraining's binary_logloss: 0.189854\n",
      "[463]\ttraining's binary_logloss: 0.189683\n",
      "[464]\ttraining's binary_logloss: 0.189597\n",
      "[465]\ttraining's binary_logloss: 0.189491\n",
      "[466]\ttraining's binary_logloss: 0.189109\n",
      "[467]\ttraining's binary_logloss: 0.188945\n",
      "[468]\ttraining's binary_logloss: 0.188664\n",
      "[469]\ttraining's binary_logloss: 0.188569\n",
      "[470]\ttraining's binary_logloss: 0.188215\n",
      "[471]\ttraining's binary_logloss: 0.188092\n",
      "[472]\ttraining's binary_logloss: 0.187943\n",
      "[473]\ttraining's binary_logloss: 0.187735\n",
      "[474]\ttraining's binary_logloss: 0.187531\n",
      "[475]\ttraining's binary_logloss: 0.18742\n",
      "[476]\ttraining's binary_logloss: 0.18722\n",
      "[477]\ttraining's binary_logloss: 0.187113\n",
      "[478]\ttraining's binary_logloss: 0.186851\n",
      "[479]\ttraining's binary_logloss: 0.186571\n",
      "[480]\ttraining's binary_logloss: 0.186492\n",
      "[481]\ttraining's binary_logloss: 0.186356\n",
      "[482]\ttraining's binary_logloss: 0.186238\n",
      "[483]\ttraining's binary_logloss: 0.186046\n",
      "[484]\ttraining's binary_logloss: 0.185959\n",
      "[485]\ttraining's binary_logloss: 0.185763\n",
      "[486]\ttraining's binary_logloss: 0.185617\n",
      "[487]\ttraining's binary_logloss: 0.185351\n",
      "[488]\ttraining's binary_logloss: 0.18514\n",
      "[489]\ttraining's binary_logloss: 0.185055\n",
      "[490]\ttraining's binary_logloss: 0.184859\n",
      "[491]\ttraining's binary_logloss: 0.184499\n",
      "[492]\ttraining's binary_logloss: 0.18429\n",
      "[493]\ttraining's binary_logloss: 0.184209\n",
      "[494]\ttraining's binary_logloss: 0.184121\n",
      "[495]\ttraining's binary_logloss: 0.184014\n",
      "[496]\ttraining's binary_logloss: 0.18376\n",
      "[497]\ttraining's binary_logloss: 0.183621\n",
      "[498]\ttraining's binary_logloss: 0.183355\n",
      "[499]\ttraining's binary_logloss: 0.183268\n",
      "[500]\ttraining's binary_logloss: 0.183137\n",
      "[501]\ttraining's binary_logloss: 0.183041\n",
      "[502]\ttraining's binary_logloss: 0.182854\n",
      "[503]\ttraining's binary_logloss: 0.182653\n",
      "[504]\ttraining's binary_logloss: 0.182576\n",
      "[505]\ttraining's binary_logloss: 0.182271\n",
      "[506]\ttraining's binary_logloss: 0.182196\n",
      "[507]\ttraining's binary_logloss: 0.182046\n",
      "[508]\ttraining's binary_logloss: 0.181851\n",
      "[509]\ttraining's binary_logloss: 0.181788\n",
      "[510]\ttraining's binary_logloss: 0.181454\n",
      "[511]\ttraining's binary_logloss: 0.181385\n",
      "[512]\ttraining's binary_logloss: 0.181208\n",
      "[513]\ttraining's binary_logloss: 0.181012\n",
      "[514]\ttraining's binary_logloss: 0.180898\n",
      "[515]\ttraining's binary_logloss: 0.180722\n",
      "[516]\ttraining's binary_logloss: 0.180506\n",
      "[517]\ttraining's binary_logloss: 0.180417\n",
      "[518]\ttraining's binary_logloss: 0.180284\n",
      "[519]\ttraining's binary_logloss: 0.180116\n",
      "[520]\ttraining's binary_logloss: 0.180048\n",
      "[521]\ttraining's binary_logloss: 0.179952\n",
      "[522]\ttraining's binary_logloss: 0.179874\n",
      "[523]\ttraining's binary_logloss: 0.179703\n",
      "[524]\ttraining's binary_logloss: 0.179589\n",
      "[525]\ttraining's binary_logloss: 0.179423\n",
      "[526]\ttraining's binary_logloss: 0.179116\n",
      "[527]\ttraining's binary_logloss: 0.17901\n",
      "[528]\ttraining's binary_logloss: 0.178917\n",
      "[529]\ttraining's binary_logloss: 0.178686\n",
      "[530]\ttraining's binary_logloss: 0.178563\n",
      "[531]\ttraining's binary_logloss: 0.178409\n",
      "[532]\ttraining's binary_logloss: 0.178326\n",
      "[533]\ttraining's binary_logloss: 0.178129\n",
      "[534]\ttraining's binary_logloss: 0.178054\n",
      "[535]\ttraining's binary_logloss: 0.17796\n",
      "[536]\ttraining's binary_logloss: 0.177886\n",
      "[537]\ttraining's binary_logloss: 0.177665\n",
      "[538]\ttraining's binary_logloss: 0.177504\n",
      "[539]\ttraining's binary_logloss: 0.177427\n",
      "[540]\ttraining's binary_logloss: 0.177337\n",
      "[541]\ttraining's binary_logloss: 0.177231\n",
      "[542]\ttraining's binary_logloss: 0.177097\n",
      "[543]\ttraining's binary_logloss: 0.176985\n",
      "[544]\ttraining's binary_logloss: 0.176902\n",
      "[545]\ttraining's binary_logloss: 0.176833\n",
      "[546]\ttraining's binary_logloss: 0.176769\n",
      "[547]\ttraining's binary_logloss: 0.176701\n",
      "[548]\ttraining's binary_logloss: 0.176501\n",
      "[549]\ttraining's binary_logloss: 0.176416\n",
      "[550]\ttraining's binary_logloss: 0.176295\n",
      "[551]\ttraining's binary_logloss: 0.176215\n",
      "[552]\ttraining's binary_logloss: 0.176029\n",
      "[553]\ttraining's binary_logloss: 0.175819\n",
      "[554]\ttraining's binary_logloss: 0.175762\n",
      "[555]\ttraining's binary_logloss: 0.175707\n",
      "[556]\ttraining's binary_logloss: 0.175554\n",
      "[557]\ttraining's binary_logloss: 0.175464\n",
      "[558]\ttraining's binary_logloss: 0.175278\n",
      "[559]\ttraining's binary_logloss: 0.175058\n",
      "[560]\ttraining's binary_logloss: 0.174937\n",
      "[561]\ttraining's binary_logloss: 0.174865\n",
      "[562]\ttraining's binary_logloss: 0.174786\n",
      "[563]\ttraining's binary_logloss: 0.174712\n",
      "[564]\ttraining's binary_logloss: 0.174484\n",
      "[565]\ttraining's binary_logloss: 0.174418\n",
      "[566]\ttraining's binary_logloss: 0.174347\n",
      "[567]\ttraining's binary_logloss: 0.174151\n",
      "[568]\ttraining's binary_logloss: 0.174039\n",
      "[569]\ttraining's binary_logloss: 0.173892\n",
      "[570]\ttraining's binary_logloss: 0.173844\n",
      "[571]\ttraining's binary_logloss: 0.173675\n",
      "[572]\ttraining's binary_logloss: 0.173556\n",
      "[573]\ttraining's binary_logloss: 0.17347\n",
      "[574]\ttraining's binary_logloss: 0.173424\n",
      "[575]\ttraining's binary_logloss: 0.173254\n",
      "[576]\ttraining's binary_logloss: 0.173163\n",
      "[577]\ttraining's binary_logloss: 0.173033\n",
      "[578]\ttraining's binary_logloss: 0.172929\n",
      "[579]\ttraining's binary_logloss: 0.172851\n",
      "[580]\ttraining's binary_logloss: 0.172699\n",
      "[581]\ttraining's binary_logloss: 0.172639\n",
      "[582]\ttraining's binary_logloss: 0.172527\n",
      "[583]\ttraining's binary_logloss: 0.172345\n",
      "[584]\ttraining's binary_logloss: 0.172253\n",
      "[585]\ttraining's binary_logloss: 0.172185\n",
      "[586]\ttraining's binary_logloss: 0.172123\n",
      "[587]\ttraining's binary_logloss: 0.172036\n",
      "[588]\ttraining's binary_logloss: 0.171838\n",
      "[589]\ttraining's binary_logloss: 0.171782\n",
      "[590]\ttraining's binary_logloss: 0.171711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[591]\ttraining's binary_logloss: 0.171605\n",
      "[592]\ttraining's binary_logloss: 0.171525\n",
      "[593]\ttraining's binary_logloss: 0.171438\n",
      "[594]\ttraining's binary_logloss: 0.171358\n",
      "[595]\ttraining's binary_logloss: 0.17131\n",
      "[596]\ttraining's binary_logloss: 0.171135\n",
      "[597]\ttraining's binary_logloss: 0.170993\n",
      "[598]\ttraining's binary_logloss: 0.170945\n",
      "[599]\ttraining's binary_logloss: 0.170854\n",
      "[600]\ttraining's binary_logloss: 0.170742\n",
      "[601]\ttraining's binary_logloss: 0.170692\n",
      "[602]\ttraining's binary_logloss: 0.170538\n",
      "[603]\ttraining's binary_logloss: 0.170484\n",
      "[604]\ttraining's binary_logloss: 0.170336\n",
      "[605]\ttraining's binary_logloss: 0.170186\n",
      "[606]\ttraining's binary_logloss: 0.1701\n",
      "[607]\ttraining's binary_logloss: 0.170018\n",
      "[608]\ttraining's binary_logloss: 0.169959\n",
      "[609]\ttraining's binary_logloss: 0.169896\n",
      "[610]\ttraining's binary_logloss: 0.169744\n",
      "[611]\ttraining's binary_logloss: 0.169674\n",
      "[612]\ttraining's binary_logloss: 0.169592\n",
      "[613]\ttraining's binary_logloss: 0.169476\n",
      "[614]\ttraining's binary_logloss: 0.169389\n",
      "[615]\ttraining's binary_logloss: 0.169316\n",
      "[616]\ttraining's binary_logloss: 0.169224\n",
      "[617]\ttraining's binary_logloss: 0.16912\n",
      "[618]\ttraining's binary_logloss: 0.16905\n",
      "[619]\ttraining's binary_logloss: 0.168947\n",
      "[620]\ttraining's binary_logloss: 0.168869\n",
      "[621]\ttraining's binary_logloss: 0.168814\n",
      "[622]\ttraining's binary_logloss: 0.168702\n",
      "[623]\ttraining's binary_logloss: 0.168555\n",
      "[624]\ttraining's binary_logloss: 0.168489\n",
      "[625]\ttraining's binary_logloss: 0.168303\n",
      "[626]\ttraining's binary_logloss: 0.168248\n",
      "[627]\ttraining's binary_logloss: 0.168187\n",
      "[628]\ttraining's binary_logloss: 0.168109\n",
      "[629]\ttraining's binary_logloss: 0.168064\n",
      "[630]\ttraining's binary_logloss: 0.167988\n",
      "[631]\ttraining's binary_logloss: 0.167926\n",
      "[632]\ttraining's binary_logloss: 0.167771\n",
      "[633]\ttraining's binary_logloss: 0.167701\n",
      "[634]\ttraining's binary_logloss: 0.167591\n",
      "[635]\ttraining's binary_logloss: 0.167435\n",
      "[636]\ttraining's binary_logloss: 0.16739\n",
      "[637]\ttraining's binary_logloss: 0.167331\n",
      "[638]\ttraining's binary_logloss: 0.167288\n",
      "[639]\ttraining's binary_logloss: 0.167226\n",
      "[640]\ttraining's binary_logloss: 0.167018\n",
      "[641]\ttraining's binary_logloss: 0.166967\n",
      "[642]\ttraining's binary_logloss: 0.166923\n",
      "[643]\ttraining's binary_logloss: 0.166753\n",
      "[644]\ttraining's binary_logloss: 0.166636\n",
      "[645]\ttraining's binary_logloss: 0.166569\n",
      "[646]\ttraining's binary_logloss: 0.166448\n",
      "[647]\ttraining's binary_logloss: 0.166406\n",
      "[648]\ttraining's binary_logloss: 0.166333\n",
      "[649]\ttraining's binary_logloss: 0.166182\n",
      "[650]\ttraining's binary_logloss: 0.166133\n",
      "[651]\ttraining's binary_logloss: 0.16603\n",
      "[652]\ttraining's binary_logloss: 0.165946\n",
      "[653]\ttraining's binary_logloss: 0.165904\n",
      "[654]\ttraining's binary_logloss: 0.16586\n",
      "[655]\ttraining's binary_logloss: 0.165815\n",
      "[656]\ttraining's binary_logloss: 0.165631\n",
      "[657]\ttraining's binary_logloss: 0.165575\n",
      "[658]\ttraining's binary_logloss: 0.165462\n",
      "[659]\ttraining's binary_logloss: 0.165392\n",
      "[660]\ttraining's binary_logloss: 0.165275\n",
      "[661]\ttraining's binary_logloss: 0.165164\n",
      "[662]\ttraining's binary_logloss: 0.165114\n",
      "[663]\ttraining's binary_logloss: 0.165034\n",
      "[664]\ttraining's binary_logloss: 0.164994\n",
      "[665]\ttraining's binary_logloss: 0.164904\n",
      "[666]\ttraining's binary_logloss: 0.164833\n",
      "[667]\ttraining's binary_logloss: 0.164758\n",
      "[668]\ttraining's binary_logloss: 0.164641\n",
      "[669]\ttraining's binary_logloss: 0.164566\n",
      "[670]\ttraining's binary_logloss: 0.164503\n",
      "[671]\ttraining's binary_logloss: 0.164425\n",
      "[672]\ttraining's binary_logloss: 0.164317\n",
      "[673]\ttraining's binary_logloss: 0.164278\n",
      "[674]\ttraining's binary_logloss: 0.164186\n",
      "[675]\ttraining's binary_logloss: 0.164134\n",
      "[676]\ttraining's binary_logloss: 0.164067\n",
      "[677]\ttraining's binary_logloss: 0.164027\n",
      "[678]\ttraining's binary_logloss: 0.163921\n",
      "[679]\ttraining's binary_logloss: 0.16381\n",
      "[680]\ttraining's binary_logloss: 0.163724\n",
      "[681]\ttraining's binary_logloss: 0.163652\n",
      "[682]\ttraining's binary_logloss: 0.163549\n",
      "[683]\ttraining's binary_logloss: 0.16346\n",
      "[684]\ttraining's binary_logloss: 0.163372\n",
      "[685]\ttraining's binary_logloss: 0.163278\n",
      "[686]\ttraining's binary_logloss: 0.163221\n",
      "[687]\ttraining's binary_logloss: 0.163174\n",
      "[688]\ttraining's binary_logloss: 0.163039\n",
      "[689]\ttraining's binary_logloss: 0.162987\n",
      "[690]\ttraining's binary_logloss: 0.162887\n",
      "[691]\ttraining's binary_logloss: 0.16282\n",
      "[692]\ttraining's binary_logloss: 0.162763\n",
      "[693]\ttraining's binary_logloss: 0.162609\n",
      "[694]\ttraining's binary_logloss: 0.162567\n",
      "[695]\ttraining's binary_logloss: 0.162523\n",
      "[696]\ttraining's binary_logloss: 0.162439\n",
      "[697]\ttraining's binary_logloss: 0.162379\n",
      "[698]\ttraining's binary_logloss: 0.162287\n",
      "[699]\ttraining's binary_logloss: 0.162183\n",
      "[700]\ttraining's binary_logloss: 0.162138\n",
      "[701]\ttraining's binary_logloss: 0.161979\n",
      "[702]\ttraining's binary_logloss: 0.161915\n",
      "[703]\ttraining's binary_logloss: 0.161844\n",
      "[704]\ttraining's binary_logloss: 0.161769\n",
      "[705]\ttraining's binary_logloss: 0.161724\n",
      "[706]\ttraining's binary_logloss: 0.161659\n",
      "[707]\ttraining's binary_logloss: 0.161605\n",
      "[708]\ttraining's binary_logloss: 0.161524\n",
      "[709]\ttraining's binary_logloss: 0.16147\n",
      "[710]\ttraining's binary_logloss: 0.161319\n",
      "[711]\ttraining's binary_logloss: 0.161198\n",
      "[712]\ttraining's binary_logloss: 0.161132\n",
      "[713]\ttraining's binary_logloss: 0.161089\n",
      "[714]\ttraining's binary_logloss: 0.161024\n",
      "[715]\ttraining's binary_logloss: 0.160989\n",
      "[716]\ttraining's binary_logloss: 0.160886\n",
      "[717]\ttraining's binary_logloss: 0.160841\n",
      "[718]\ttraining's binary_logloss: 0.160789\n",
      "[719]\ttraining's binary_logloss: 0.160645\n",
      "[720]\ttraining's binary_logloss: 0.160581\n",
      "[721]\ttraining's binary_logloss: 0.160482\n",
      "[722]\ttraining's binary_logloss: 0.16043\n",
      "[723]\ttraining's binary_logloss: 0.160401\n",
      "[724]\ttraining's binary_logloss: 0.160252\n",
      "[725]\ttraining's binary_logloss: 0.160213\n",
      "[726]\ttraining's binary_logloss: 0.160153\n",
      "[727]\ttraining's binary_logloss: 0.160102\n",
      "[728]\ttraining's binary_logloss: 0.16003\n",
      "[729]\ttraining's binary_logloss: 0.159995\n",
      "[730]\ttraining's binary_logloss: 0.159946\n",
      "[731]\ttraining's binary_logloss: 0.159858\n",
      "[732]\ttraining's binary_logloss: 0.159809\n",
      "[733]\ttraining's binary_logloss: 0.15972\n",
      "[734]\ttraining's binary_logloss: 0.159675\n",
      "[735]\ttraining's binary_logloss: 0.159533\n",
      "[736]\ttraining's binary_logloss: 0.159477\n",
      "[737]\ttraining's binary_logloss: 0.159429\n",
      "[738]\ttraining's binary_logloss: 0.159305\n",
      "[739]\ttraining's binary_logloss: 0.159155\n",
      "[740]\ttraining's binary_logloss: 0.159095\n",
      "[741]\ttraining's binary_logloss: 0.159058\n",
      "[742]\ttraining's binary_logloss: 0.159014\n",
      "[743]\ttraining's binary_logloss: 0.158935\n",
      "[744]\ttraining's binary_logloss: 0.158899\n",
      "[745]\ttraining's binary_logloss: 0.158843\n",
      "[746]\ttraining's binary_logloss: 0.158725\n",
      "[747]\ttraining's binary_logloss: 0.158596\n",
      "[748]\ttraining's binary_logloss: 0.15855\n",
      "[749]\ttraining's binary_logloss: 0.158483\n",
      "[750]\ttraining's binary_logloss: 0.158427\n",
      "[751]\ttraining's binary_logloss: 0.158357\n",
      "[752]\ttraining's binary_logloss: 0.158288\n",
      "[753]\ttraining's binary_logloss: 0.15824\n",
      "[754]\ttraining's binary_logloss: 0.158172\n",
      "[755]\ttraining's binary_logloss: 0.158118\n",
      "[756]\ttraining's binary_logloss: 0.157979\n",
      "[757]\ttraining's binary_logloss: 0.157929\n",
      "[758]\ttraining's binary_logloss: 0.157886\n",
      "[759]\ttraining's binary_logloss: 0.157804\n",
      "[760]\ttraining's binary_logloss: 0.157723\n",
      "[761]\ttraining's binary_logloss: 0.157669\n",
      "[762]\ttraining's binary_logloss: 0.157633\n",
      "[763]\ttraining's binary_logloss: 0.157594\n",
      "[764]\ttraining's binary_logloss: 0.157529\n",
      "[765]\ttraining's binary_logloss: 0.157448\n",
      "[766]\ttraining's binary_logloss: 0.157398\n",
      "[767]\ttraining's binary_logloss: 0.157277\n",
      "[768]\ttraining's binary_logloss: 0.157231\n",
      "[769]\ttraining's binary_logloss: 0.157191\n",
      "[770]\ttraining's binary_logloss: 0.157142\n",
      "[771]\ttraining's binary_logloss: 0.157101\n",
      "[772]\ttraining's binary_logloss: 0.157067\n",
      "[773]\ttraining's binary_logloss: 0.156967\n",
      "[774]\ttraining's binary_logloss: 0.156905\n",
      "[775]\ttraining's binary_logloss: 0.156863\n",
      "[776]\ttraining's binary_logloss: 0.156811\n",
      "[777]\ttraining's binary_logloss: 0.156735\n",
      "[778]\ttraining's binary_logloss: 0.156685\n",
      "[779]\ttraining's binary_logloss: 0.15664\n",
      "[780]\ttraining's binary_logloss: 0.156512\n",
      "[781]\ttraining's binary_logloss: 0.156481\n",
      "[782]\ttraining's binary_logloss: 0.156444\n",
      "[783]\ttraining's binary_logloss: 0.156356\n",
      "[784]\ttraining's binary_logloss: 0.156313\n",
      "[785]\ttraining's binary_logloss: 0.15628\n",
      "[786]\ttraining's binary_logloss: 0.156213\n",
      "[787]\ttraining's binary_logloss: 0.156157\n",
      "[788]\ttraining's binary_logloss: 0.156073\n",
      "[789]\ttraining's binary_logloss: 0.156042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[790]\ttraining's binary_logloss: 0.155946\n",
      "[791]\ttraining's binary_logloss: 0.155898\n",
      "[792]\ttraining's binary_logloss: 0.15585\n",
      "[793]\ttraining's binary_logloss: 0.15579\n",
      "[794]\ttraining's binary_logloss: 0.155751\n",
      "[795]\ttraining's binary_logloss: 0.155699\n",
      "[796]\ttraining's binary_logloss: 0.155658\n",
      "[797]\ttraining's binary_logloss: 0.155615\n",
      "[798]\ttraining's binary_logloss: 0.155476\n",
      "[799]\ttraining's binary_logloss: 0.155332\n",
      "[800]\ttraining's binary_logloss: 0.155266\n",
      "[801]\ttraining's binary_logloss: 0.155224\n",
      "[802]\ttraining's binary_logloss: 0.155155\n",
      "[803]\ttraining's binary_logloss: 0.155124\n",
      "[804]\ttraining's binary_logloss: 0.155088\n",
      "[805]\ttraining's binary_logloss: 0.155057\n",
      "[806]\ttraining's binary_logloss: 0.155008\n",
      "[807]\ttraining's binary_logloss: 0.15497\n",
      "[808]\ttraining's binary_logloss: 0.154888\n",
      "[809]\ttraining's binary_logloss: 0.154844\n",
      "[810]\ttraining's binary_logloss: 0.154738\n",
      "[811]\ttraining's binary_logloss: 0.15468\n",
      "[812]\ttraining's binary_logloss: 0.154533\n",
      "[813]\ttraining's binary_logloss: 0.154492\n",
      "[814]\ttraining's binary_logloss: 0.15445\n",
      "[815]\ttraining's binary_logloss: 0.154381\n",
      "[816]\ttraining's binary_logloss: 0.154308\n",
      "[817]\ttraining's binary_logloss: 0.154258\n",
      "[818]\ttraining's binary_logloss: 0.154222\n",
      "[819]\ttraining's binary_logloss: 0.15417\n",
      "[820]\ttraining's binary_logloss: 0.154134\n",
      "[821]\ttraining's binary_logloss: 0.154028\n",
      "[822]\ttraining's binary_logloss: 0.153981\n",
      "[823]\ttraining's binary_logloss: 0.153839\n",
      "[824]\ttraining's binary_logloss: 0.153792\n",
      "[825]\ttraining's binary_logloss: 0.153708\n",
      "[826]\ttraining's binary_logloss: 0.153663\n",
      "[827]\ttraining's binary_logloss: 0.153559\n",
      "[828]\ttraining's binary_logloss: 0.15352\n",
      "[829]\ttraining's binary_logloss: 0.153459\n",
      "[830]\ttraining's binary_logloss: 0.153427\n",
      "[831]\ttraining's binary_logloss: 0.153359\n",
      "[832]\ttraining's binary_logloss: 0.153311\n",
      "[833]\ttraining's binary_logloss: 0.153237\n",
      "[834]\ttraining's binary_logloss: 0.153178\n",
      "[835]\ttraining's binary_logloss: 0.153125\n",
      "[836]\ttraining's binary_logloss: 0.153084\n",
      "[837]\ttraining's binary_logloss: 0.153041\n",
      "[838]\ttraining's binary_logloss: 0.153009\n",
      "[839]\ttraining's binary_logloss: 0.152907\n",
      "[840]\ttraining's binary_logloss: 0.152869\n",
      "[841]\ttraining's binary_logloss: 0.152825\n",
      "[842]\ttraining's binary_logloss: 0.15276\n",
      "[843]\ttraining's binary_logloss: 0.15273\n",
      "[844]\ttraining's binary_logloss: 0.15269\n",
      "[845]\ttraining's binary_logloss: 0.152663\n",
      "[846]\ttraining's binary_logloss: 0.15263\n",
      "[847]\ttraining's binary_logloss: 0.152532\n",
      "[848]\ttraining's binary_logloss: 0.15249\n",
      "[849]\ttraining's binary_logloss: 0.152436\n",
      "[850]\ttraining's binary_logloss: 0.1524\n",
      "[851]\ttraining's binary_logloss: 0.152338\n",
      "[852]\ttraining's binary_logloss: 0.1523\n",
      "[853]\ttraining's binary_logloss: 0.152264\n",
      "[854]\ttraining's binary_logloss: 0.152225\n",
      "[855]\ttraining's binary_logloss: 0.152182\n",
      "[856]\ttraining's binary_logloss: 0.152147\n",
      "[857]\ttraining's binary_logloss: 0.152089\n",
      "[858]\ttraining's binary_logloss: 0.152015\n",
      "[859]\ttraining's binary_logloss: 0.151896\n",
      "[860]\ttraining's binary_logloss: 0.15186\n",
      "[861]\ttraining's binary_logloss: 0.151819\n",
      "[862]\ttraining's binary_logloss: 0.151762\n",
      "[863]\ttraining's binary_logloss: 0.151723\n",
      "[864]\ttraining's binary_logloss: 0.151625\n",
      "[865]\ttraining's binary_logloss: 0.15158\n",
      "[866]\ttraining's binary_logloss: 0.151545\n",
      "[867]\ttraining's binary_logloss: 0.151473\n",
      "[868]\ttraining's binary_logloss: 0.151434\n",
      "[869]\ttraining's binary_logloss: 0.151388\n",
      "[870]\ttraining's binary_logloss: 0.151281\n",
      "[871]\ttraining's binary_logloss: 0.151243\n",
      "[872]\ttraining's binary_logloss: 0.151206\n",
      "[873]\ttraining's binary_logloss: 0.15117\n",
      "[874]\ttraining's binary_logloss: 0.151132\n",
      "[875]\ttraining's binary_logloss: 0.151061\n",
      "[876]\ttraining's binary_logloss: 0.151034\n",
      "[877]\ttraining's binary_logloss: 0.150998\n",
      "[878]\ttraining's binary_logloss: 0.150959\n",
      "[879]\ttraining's binary_logloss: 0.150921\n",
      "[880]\ttraining's binary_logloss: 0.15086\n",
      "[881]\ttraining's binary_logloss: 0.150811\n",
      "[882]\ttraining's binary_logloss: 0.150776\n",
      "[883]\ttraining's binary_logloss: 0.150737\n",
      "[884]\ttraining's binary_logloss: 0.150674\n",
      "[885]\ttraining's binary_logloss: 0.150633\n",
      "[886]\ttraining's binary_logloss: 0.150579\n",
      "[887]\ttraining's binary_logloss: 0.150504\n",
      "[888]\ttraining's binary_logloss: 0.150437\n",
      "[889]\ttraining's binary_logloss: 0.150364\n",
      "[890]\ttraining's binary_logloss: 0.150273\n",
      "[891]\ttraining's binary_logloss: 0.150242\n",
      "[892]\ttraining's binary_logloss: 0.150202\n",
      "[893]\ttraining's binary_logloss: 0.150136\n",
      "[894]\ttraining's binary_logloss: 0.150053\n",
      "[895]\ttraining's binary_logloss: 0.15002\n",
      "[896]\ttraining's binary_logloss: 0.149985\n",
      "[897]\ttraining's binary_logloss: 0.149937\n",
      "[898]\ttraining's binary_logloss: 0.1499\n",
      "[899]\ttraining's binary_logloss: 0.149872\n",
      "[900]\ttraining's binary_logloss: 0.149833\n",
      "[901]\ttraining's binary_logloss: 0.149802\n",
      "[902]\ttraining's binary_logloss: 0.149743\n",
      "[903]\ttraining's binary_logloss: 0.149685\n",
      "[904]\ttraining's binary_logloss: 0.149653\n",
      "[905]\ttraining's binary_logloss: 0.149619\n",
      "[906]\ttraining's binary_logloss: 0.149558\n",
      "[907]\ttraining's binary_logloss: 0.149519\n",
      "[908]\ttraining's binary_logloss: 0.149455\n",
      "[909]\ttraining's binary_logloss: 0.14942\n",
      "[910]\ttraining's binary_logloss: 0.149387\n",
      "[911]\ttraining's binary_logloss: 0.14934\n",
      "[912]\ttraining's binary_logloss: 0.149295\n",
      "[913]\ttraining's binary_logloss: 0.149229\n",
      "[914]\ttraining's binary_logloss: 0.149196\n",
      "[915]\ttraining's binary_logloss: 0.149166\n",
      "[916]\ttraining's binary_logloss: 0.149142\n",
      "[917]\ttraining's binary_logloss: 0.149109\n",
      "[918]\ttraining's binary_logloss: 0.14908\n",
      "[919]\ttraining's binary_logloss: 0.149031\n",
      "[920]\ttraining's binary_logloss: 0.148996\n",
      "[921]\ttraining's binary_logloss: 0.148965\n",
      "[922]\ttraining's binary_logloss: 0.148903\n",
      "[923]\ttraining's binary_logloss: 0.148852\n",
      "[924]\ttraining's binary_logloss: 0.148787\n",
      "[925]\ttraining's binary_logloss: 0.148722\n",
      "[926]\ttraining's binary_logloss: 0.148678\n",
      "[927]\ttraining's binary_logloss: 0.148647\n",
      "[928]\ttraining's binary_logloss: 0.148579\n",
      "[929]\ttraining's binary_logloss: 0.148536\n",
      "[930]\ttraining's binary_logloss: 0.148501\n",
      "[931]\ttraining's binary_logloss: 0.148461\n",
      "[932]\ttraining's binary_logloss: 0.148433\n",
      "[933]\ttraining's binary_logloss: 0.148404\n",
      "[934]\ttraining's binary_logloss: 0.148368\n",
      "[935]\ttraining's binary_logloss: 0.148336\n",
      "[936]\ttraining's binary_logloss: 0.148302\n",
      "[937]\ttraining's binary_logloss: 0.14827\n",
      "[938]\ttraining's binary_logloss: 0.148224\n",
      "[939]\ttraining's binary_logloss: 0.148179\n",
      "[940]\ttraining's binary_logloss: 0.148125\n",
      "[941]\ttraining's binary_logloss: 0.148064\n",
      "[942]\ttraining's binary_logloss: 0.148003\n",
      "[943]\ttraining's binary_logloss: 0.147946\n",
      "[944]\ttraining's binary_logloss: 0.147924\n",
      "[945]\ttraining's binary_logloss: 0.147892\n",
      "[946]\ttraining's binary_logloss: 0.14786\n",
      "[947]\ttraining's binary_logloss: 0.147817\n",
      "[948]\ttraining's binary_logloss: 0.147773\n",
      "[949]\ttraining's binary_logloss: 0.147741\n",
      "[950]\ttraining's binary_logloss: 0.147709\n",
      "[951]\ttraining's binary_logloss: 0.147665\n",
      "[952]\ttraining's binary_logloss: 0.147629\n",
      "[953]\ttraining's binary_logloss: 0.147605\n",
      "[954]\ttraining's binary_logloss: 0.147561\n",
      "[955]\ttraining's binary_logloss: 0.147526\n",
      "[956]\ttraining's binary_logloss: 0.14749\n",
      "[957]\ttraining's binary_logloss: 0.147433\n",
      "[958]\ttraining's binary_logloss: 0.147404\n",
      "[959]\ttraining's binary_logloss: 0.147363\n",
      "[960]\ttraining's binary_logloss: 0.147331\n",
      "[961]\ttraining's binary_logloss: 0.147297\n",
      "[962]\ttraining's binary_logloss: 0.147264\n",
      "[963]\ttraining's binary_logloss: 0.14722\n",
      "[964]\ttraining's binary_logloss: 0.147179\n",
      "[965]\ttraining's binary_logloss: 0.147146\n",
      "[966]\ttraining's binary_logloss: 0.1471\n",
      "[967]\ttraining's binary_logloss: 0.147066\n",
      "[968]\ttraining's binary_logloss: 0.147037\n",
      "[969]\ttraining's binary_logloss: 0.14698\n",
      "[970]\ttraining's binary_logloss: 0.146946\n",
      "[971]\ttraining's binary_logloss: 0.146919\n",
      "[972]\ttraining's binary_logloss: 0.146869\n",
      "[973]\ttraining's binary_logloss: 0.146827\n",
      "[974]\ttraining's binary_logloss: 0.146792\n",
      "[975]\ttraining's binary_logloss: 0.146763\n",
      "[976]\ttraining's binary_logloss: 0.146728\n",
      "[977]\ttraining's binary_logloss: 0.146692\n",
      "[978]\ttraining's binary_logloss: 0.146628\n",
      "[979]\ttraining's binary_logloss: 0.146594\n",
      "[980]\ttraining's binary_logloss: 0.146564\n",
      "[981]\ttraining's binary_logloss: 0.146528\n",
      "[982]\ttraining's binary_logloss: 0.146497\n",
      "[983]\ttraining's binary_logloss: 0.146471\n",
      "[984]\ttraining's binary_logloss: 0.14644\n",
      "[985]\ttraining's binary_logloss: 0.146405\n",
      "[986]\ttraining's binary_logloss: 0.146344\n",
      "[987]\ttraining's binary_logloss: 0.146301\n",
      "[988]\ttraining's binary_logloss: 0.146234\n",
      "[989]\ttraining's binary_logloss: 0.146204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[990]\ttraining's binary_logloss: 0.146175\n",
      "[991]\ttraining's binary_logloss: 0.146148\n",
      "[992]\ttraining's binary_logloss: 0.146088\n",
      "[993]\ttraining's binary_logloss: 0.146053\n",
      "[994]\ttraining's binary_logloss: 0.14602\n",
      "[995]\ttraining's binary_logloss: 0.145968\n",
      "[996]\ttraining's binary_logloss: 0.145931\n",
      "[997]\ttraining's binary_logloss: 0.145898\n",
      "[998]\ttraining's binary_logloss: 0.14586\n",
      "[999]\ttraining's binary_logloss: 0.145823\n",
      "[1000]\ttraining's binary_logloss: 0.145787\n",
      "[1001]\ttraining's binary_logloss: 0.145754\n",
      "[1002]\ttraining's binary_logloss: 0.145697\n",
      "[1003]\ttraining's binary_logloss: 0.145669\n",
      "[1004]\ttraining's binary_logloss: 0.145637\n",
      "[1005]\ttraining's binary_logloss: 0.145604\n",
      "[1006]\ttraining's binary_logloss: 0.145578\n",
      "[1007]\ttraining's binary_logloss: 0.145514\n",
      "[1008]\ttraining's binary_logloss: 0.145478\n",
      "[1009]\ttraining's binary_logloss: 0.145446\n",
      "[1010]\ttraining's binary_logloss: 0.145416\n",
      "[1011]\ttraining's binary_logloss: 0.14535\n",
      "[1012]\ttraining's binary_logloss: 0.1453\n",
      "[1013]\ttraining's binary_logloss: 0.145266\n",
      "[1014]\ttraining's binary_logloss: 0.145229\n",
      "[1015]\ttraining's binary_logloss: 0.145199\n",
      "[1016]\ttraining's binary_logloss: 0.14517\n",
      "[1017]\ttraining's binary_logloss: 0.145141\n",
      "[1018]\ttraining's binary_logloss: 0.145097\n",
      "[1019]\ttraining's binary_logloss: 0.14507\n",
      "[1020]\ttraining's binary_logloss: 0.145042\n",
      "[1021]\ttraining's binary_logloss: 0.145012\n",
      "[1022]\ttraining's binary_logloss: 0.144977\n",
      "[1023]\ttraining's binary_logloss: 0.14495\n",
      "[1024]\ttraining's binary_logloss: 0.144913\n",
      "[1025]\ttraining's binary_logloss: 0.144865\n",
      "[1026]\ttraining's binary_logloss: 0.144839\n",
      "[1027]\ttraining's binary_logloss: 0.144805\n",
      "[1028]\ttraining's binary_logloss: 0.144773\n",
      "[1029]\ttraining's binary_logloss: 0.144722\n",
      "[1030]\ttraining's binary_logloss: 0.144696\n",
      "[1031]\ttraining's binary_logloss: 0.14464\n",
      "[1032]\ttraining's binary_logloss: 0.14461\n",
      "[1033]\ttraining's binary_logloss: 0.144565\n",
      "[1034]\ttraining's binary_logloss: 0.144476\n",
      "[1035]\ttraining's binary_logloss: 0.144437\n",
      "[1036]\ttraining's binary_logloss: 0.144404\n",
      "[1037]\ttraining's binary_logloss: 0.144366\n",
      "[1038]\ttraining's binary_logloss: 0.144335\n",
      "[1039]\ttraining's binary_logloss: 0.144284\n",
      "[1040]\ttraining's binary_logloss: 0.144253\n",
      "[1041]\ttraining's binary_logloss: 0.144219\n",
      "[1042]\ttraining's binary_logloss: 0.144172\n",
      "[1043]\ttraining's binary_logloss: 0.144126\n",
      "[1044]\ttraining's binary_logloss: 0.144095\n",
      "[1045]\ttraining's binary_logloss: 0.144021\n",
      "[1046]\ttraining's binary_logloss: 0.143994\n",
      "[1047]\ttraining's binary_logloss: 0.143964\n",
      "[1048]\ttraining's binary_logloss: 0.143926\n",
      "[1049]\ttraining's binary_logloss: 0.143893\n",
      "[1050]\ttraining's binary_logloss: 0.14387\n",
      "[1051]\ttraining's binary_logloss: 0.143825\n",
      "[1052]\ttraining's binary_logloss: 0.143794\n",
      "[1053]\ttraining's binary_logloss: 0.143764\n",
      "[1054]\ttraining's binary_logloss: 0.14373\n",
      "[1055]\ttraining's binary_logloss: 0.143701\n",
      "[1056]\ttraining's binary_logloss: 0.143674\n",
      "[1057]\ttraining's binary_logloss: 0.143651\n",
      "[1058]\ttraining's binary_logloss: 0.143622\n",
      "[1059]\ttraining's binary_logloss: 0.143585\n",
      "[1060]\ttraining's binary_logloss: 0.143559\n",
      "[1061]\ttraining's binary_logloss: 0.143531\n",
      "[1062]\ttraining's binary_logloss: 0.143503\n",
      "[1063]\ttraining's binary_logloss: 0.143478\n",
      "[1064]\ttraining's binary_logloss: 0.143449\n",
      "[1065]\ttraining's binary_logloss: 0.143411\n",
      "[1066]\ttraining's binary_logloss: 0.143379\n",
      "[1067]\ttraining's binary_logloss: 0.143348\n",
      "[1068]\ttraining's binary_logloss: 0.143324\n",
      "[1069]\ttraining's binary_logloss: 0.143294\n",
      "[1070]\ttraining's binary_logloss: 0.143253\n",
      "[1071]\ttraining's binary_logloss: 0.143224\n",
      "[1072]\ttraining's binary_logloss: 0.143202\n",
      "[1073]\ttraining's binary_logloss: 0.143155\n",
      "[1074]\ttraining's binary_logloss: 0.143126\n",
      "[1075]\ttraining's binary_logloss: 0.143098\n",
      "[1076]\ttraining's binary_logloss: 0.143045\n",
      "[1077]\ttraining's binary_logloss: 0.143024\n",
      "[1078]\ttraining's binary_logloss: 0.142996\n",
      "[1079]\ttraining's binary_logloss: 0.142965\n",
      "[1080]\ttraining's binary_logloss: 0.142919\n",
      "[1081]\ttraining's binary_logloss: 0.142893\n",
      "[1082]\ttraining's binary_logloss: 0.142863\n",
      "[1083]\ttraining's binary_logloss: 0.142804\n",
      "[1084]\ttraining's binary_logloss: 0.142717\n",
      "[1085]\ttraining's binary_logloss: 0.142691\n",
      "[1086]\ttraining's binary_logloss: 0.142635\n",
      "[1087]\ttraining's binary_logloss: 0.142606\n",
      "[1088]\ttraining's binary_logloss: 0.142577\n",
      "[1089]\ttraining's binary_logloss: 0.142553\n",
      "[1090]\ttraining's binary_logloss: 0.142521\n",
      "[1091]\ttraining's binary_logloss: 0.142497\n",
      "[1092]\ttraining's binary_logloss: 0.142469\n",
      "[1093]\ttraining's binary_logloss: 0.142427\n",
      "[1094]\ttraining's binary_logloss: 0.14234\n",
      "[1095]\ttraining's binary_logloss: 0.142311\n",
      "[1096]\ttraining's binary_logloss: 0.142279\n",
      "[1097]\ttraining's binary_logloss: 0.142251\n",
      "[1098]\ttraining's binary_logloss: 0.142237\n",
      "[1099]\ttraining's binary_logloss: 0.142194\n",
      "[1100]\ttraining's binary_logloss: 0.142166\n",
      "[1101]\ttraining's binary_logloss: 0.142099\n",
      "[1102]\ttraining's binary_logloss: 0.14207\n",
      "[1103]\ttraining's binary_logloss: 0.142049\n",
      "[1104]\ttraining's binary_logloss: 0.142024\n",
      "[1105]\ttraining's binary_logloss: 0.141993\n",
      "[1106]\ttraining's binary_logloss: 0.141958\n",
      "[1107]\ttraining's binary_logloss: 0.141932\n",
      "[1108]\ttraining's binary_logloss: 0.141904\n",
      "[1109]\ttraining's binary_logloss: 0.141876\n",
      "[1110]\ttraining's binary_logloss: 0.141844\n",
      "[1111]\ttraining's binary_logloss: 0.141817\n",
      "[1112]\ttraining's binary_logloss: 0.141763\n",
      "[1113]\ttraining's binary_logloss: 0.141731\n",
      "[1114]\ttraining's binary_logloss: 0.141676\n",
      "[1115]\ttraining's binary_logloss: 0.141632\n",
      "[1116]\ttraining's binary_logloss: 0.141597\n",
      "[1117]\ttraining's binary_logloss: 0.141571\n",
      "[1118]\ttraining's binary_logloss: 0.141542\n",
      "[1119]\ttraining's binary_logloss: 0.141513\n",
      "[1120]\ttraining's binary_logloss: 0.141485\n",
      "[1121]\ttraining's binary_logloss: 0.141445\n",
      "[1122]\ttraining's binary_logloss: 0.141423\n",
      "[1123]\ttraining's binary_logloss: 0.141397\n",
      "[1124]\ttraining's binary_logloss: 0.141361\n",
      "[1125]\ttraining's binary_logloss: 0.14128\n",
      "[1126]\ttraining's binary_logloss: 0.141244\n",
      "[1127]\ttraining's binary_logloss: 0.141218\n",
      "[1128]\ttraining's binary_logloss: 0.141188\n",
      "[1129]\ttraining's binary_logloss: 0.141157\n",
      "[1130]\ttraining's binary_logloss: 0.141132\n",
      "[1131]\ttraining's binary_logloss: 0.141101\n",
      "[1132]\ttraining's binary_logloss: 0.141073\n",
      "[1133]\ttraining's binary_logloss: 0.141051\n",
      "[1134]\ttraining's binary_logloss: 0.141026\n",
      "[1135]\ttraining's binary_logloss: 0.140997\n",
      "[1136]\ttraining's binary_logloss: 0.140976\n",
      "[1137]\ttraining's binary_logloss: 0.14093\n",
      "[1138]\ttraining's binary_logloss: 0.140905\n",
      "[1139]\ttraining's binary_logloss: 0.140878\n",
      "[1140]\ttraining's binary_logloss: 0.140852\n",
      "[1141]\ttraining's binary_logloss: 0.140831\n",
      "[1142]\ttraining's binary_logloss: 0.140804\n",
      "[1143]\ttraining's binary_logloss: 0.140766\n",
      "[1144]\ttraining's binary_logloss: 0.140739\n",
      "[1145]\ttraining's binary_logloss: 0.140711\n",
      "[1146]\ttraining's binary_logloss: 0.140684\n",
      "[1147]\ttraining's binary_logloss: 0.140658\n",
      "[1148]\ttraining's binary_logloss: 0.140633\n",
      "[1149]\ttraining's binary_logloss: 0.140607\n",
      "[1150]\ttraining's binary_logloss: 0.140568\n",
      "[1151]\ttraining's binary_logloss: 0.140522\n",
      "[1152]\ttraining's binary_logloss: 0.140498\n",
      "[1153]\ttraining's binary_logloss: 0.140474\n",
      "[1154]\ttraining's binary_logloss: 0.140402\n",
      "[1155]\ttraining's binary_logloss: 0.140377\n",
      "[1156]\ttraining's binary_logloss: 0.140339\n",
      "[1157]\ttraining's binary_logloss: 0.140314\n",
      "[1158]\ttraining's binary_logloss: 0.140287\n",
      "[1159]\ttraining's binary_logloss: 0.140262\n",
      "[1160]\ttraining's binary_logloss: 0.140238\n",
      "[1161]\ttraining's binary_logloss: 0.14021\n",
      "[1162]\ttraining's binary_logloss: 0.140161\n",
      "[1163]\ttraining's binary_logloss: 0.140136\n",
      "[1164]\ttraining's binary_logloss: 0.140101\n",
      "[1165]\ttraining's binary_logloss: 0.140079\n",
      "[1166]\ttraining's binary_logloss: 0.140021\n",
      "[1167]\ttraining's binary_logloss: 0.139996\n",
      "[1168]\ttraining's binary_logloss: 0.139966\n",
      "[1169]\ttraining's binary_logloss: 0.13994\n",
      "[1170]\ttraining's binary_logloss: 0.139887\n",
      "[1171]\ttraining's binary_logloss: 0.139864\n",
      "[1172]\ttraining's binary_logloss: 0.13984\n",
      "[1173]\ttraining's binary_logloss: 0.139815\n",
      "[1174]\ttraining's binary_logloss: 0.139789\n",
      "[1175]\ttraining's binary_logloss: 0.139764\n",
      "[1176]\ttraining's binary_logloss: 0.139744\n",
      "[1177]\ttraining's binary_logloss: 0.139698\n",
      "[1178]\ttraining's binary_logloss: 0.139674\n",
      "[1179]\ttraining's binary_logloss: 0.139646\n",
      "[1180]\ttraining's binary_logloss: 0.139621\n",
      "[1181]\ttraining's binary_logloss: 0.139599\n",
      "[1182]\ttraining's binary_logloss: 0.139568\n",
      "[1183]\ttraining's binary_logloss: 0.139546\n",
      "[1184]\ttraining's binary_logloss: 0.139522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1185]\ttraining's binary_logloss: 0.139472\n",
      "[1186]\ttraining's binary_logloss: 0.139415\n",
      "[1187]\ttraining's binary_logloss: 0.139389\n",
      "[1188]\ttraining's binary_logloss: 0.139366\n",
      "[1189]\ttraining's binary_logloss: 0.139342\n",
      "[1190]\ttraining's binary_logloss: 0.139315\n",
      "[1191]\ttraining's binary_logloss: 0.13929\n",
      "[1192]\ttraining's binary_logloss: 0.139266\n",
      "[1193]\ttraining's binary_logloss: 0.139243\n",
      "[1194]\ttraining's binary_logloss: 0.139212\n",
      "[1195]\ttraining's binary_logloss: 0.139182\n",
      "[1196]\ttraining's binary_logloss: 0.139166\n",
      "[1197]\ttraining's binary_logloss: 0.139138\n",
      "[1198]\ttraining's binary_logloss: 0.139112\n",
      "[1199]\ttraining's binary_logloss: 0.139085\n",
      "[1200]\ttraining's binary_logloss: 0.13906\n",
      "[1201]\ttraining's binary_logloss: 0.139037\n",
      "[1202]\ttraining's binary_logloss: 0.139005\n",
      "[1203]\ttraining's binary_logloss: 0.138981\n",
      "[1204]\ttraining's binary_logloss: 0.138959\n",
      "[1205]\ttraining's binary_logloss: 0.138938\n",
      "[1206]\ttraining's binary_logloss: 0.138914\n",
      "[1207]\ttraining's binary_logloss: 0.13889\n",
      "[1208]\ttraining's binary_logloss: 0.138861\n",
      "[1209]\ttraining's binary_logloss: 0.138838\n",
      "[1210]\ttraining's binary_logloss: 0.138814\n",
      "[1211]\ttraining's binary_logloss: 0.13879\n",
      "[1212]\ttraining's binary_logloss: 0.138766\n",
      "[1213]\ttraining's binary_logloss: 0.138741\n",
      "[1214]\ttraining's binary_logloss: 0.138717\n",
      "[1215]\ttraining's binary_logloss: 0.138694\n",
      "[1216]\ttraining's binary_logloss: 0.138672\n",
      "[1217]\ttraining's binary_logloss: 0.13865\n",
      "[1218]\ttraining's binary_logloss: 0.138617\n",
      "[1219]\ttraining's binary_logloss: 0.13859\n",
      "[1220]\ttraining's binary_logloss: 0.138562\n",
      "[1221]\ttraining's binary_logloss: 0.138516\n",
      "[1222]\ttraining's binary_logloss: 0.138497\n",
      "[1223]\ttraining's binary_logloss: 0.138469\n",
      "[1224]\ttraining's binary_logloss: 0.138436\n",
      "[1225]\ttraining's binary_logloss: 0.138415\n",
      "[1226]\ttraining's binary_logloss: 0.138393\n",
      "[1227]\ttraining's binary_logloss: 0.138359\n",
      "[1228]\ttraining's binary_logloss: 0.138327\n",
      "[1229]\ttraining's binary_logloss: 0.138273\n",
      "[1230]\ttraining's binary_logloss: 0.138252\n",
      "[1231]\ttraining's binary_logloss: 0.138228\n",
      "[1232]\ttraining's binary_logloss: 0.138206\n",
      "[1233]\ttraining's binary_logloss: 0.138182\n",
      "[1234]\ttraining's binary_logloss: 0.138157\n",
      "[1235]\ttraining's binary_logloss: 0.138133\n",
      "[1236]\ttraining's binary_logloss: 0.138107\n",
      "[1237]\ttraining's binary_logloss: 0.138084\n",
      "[1238]\ttraining's binary_logloss: 0.138062\n",
      "[1239]\ttraining's binary_logloss: 0.138039\n",
      "[1240]\ttraining's binary_logloss: 0.138011\n",
      "[1241]\ttraining's binary_logloss: 0.137985\n",
      "[1242]\ttraining's binary_logloss: 0.137961\n",
      "[1243]\ttraining's binary_logloss: 0.137927\n",
      "[1244]\ttraining's binary_logloss: 0.137903\n",
      "[1245]\ttraining's binary_logloss: 0.137852\n",
      "[1246]\ttraining's binary_logloss: 0.137831\n",
      "[1247]\ttraining's binary_logloss: 0.137807\n",
      "[1248]\ttraining's binary_logloss: 0.137781\n",
      "[1249]\ttraining's binary_logloss: 0.13776\n",
      "[1250]\ttraining's binary_logloss: 0.137735\n",
      "[1251]\ttraining's binary_logloss: 0.13769\n",
      "[1252]\ttraining's binary_logloss: 0.137668\n",
      "[1253]\ttraining's binary_logloss: 0.137646\n",
      "[1254]\ttraining's binary_logloss: 0.137621\n",
      "[1255]\ttraining's binary_logloss: 0.137598\n",
      "[1256]\ttraining's binary_logloss: 0.137568\n",
      "[1257]\ttraining's binary_logloss: 0.137544\n",
      "[1258]\ttraining's binary_logloss: 0.137523\n",
      "[1259]\ttraining's binary_logloss: 0.137503\n",
      "[1260]\ttraining's binary_logloss: 0.137482\n",
      "[1261]\ttraining's binary_logloss: 0.137453\n",
      "[1262]\ttraining's binary_logloss: 0.137439\n",
      "[1263]\ttraining's binary_logloss: 0.137418\n",
      "[1264]\ttraining's binary_logloss: 0.137405\n",
      "[1265]\ttraining's binary_logloss: 0.137377\n",
      "[1266]\ttraining's binary_logloss: 0.137356\n",
      "[1267]\ttraining's binary_logloss: 0.137309\n",
      "[1268]\ttraining's binary_logloss: 0.137279\n",
      "[1269]\ttraining's binary_logloss: 0.137259\n",
      "[1270]\ttraining's binary_logloss: 0.137238\n",
      "[1271]\ttraining's binary_logloss: 0.137208\n",
      "[1272]\ttraining's binary_logloss: 0.137168\n",
      "[1273]\ttraining's binary_logloss: 0.137148\n",
      "[1274]\ttraining's binary_logloss: 0.137125\n",
      "[1275]\ttraining's binary_logloss: 0.137104\n",
      "[1276]\ttraining's binary_logloss: 0.137082\n",
      "[1277]\ttraining's binary_logloss: 0.137057\n",
      "[1278]\ttraining's binary_logloss: 0.137035\n",
      "[1279]\ttraining's binary_logloss: 0.137011\n",
      "[1280]\ttraining's binary_logloss: 0.136989\n",
      "[1281]\ttraining's binary_logloss: 0.136967\n",
      "[1282]\ttraining's binary_logloss: 0.136946\n",
      "[1283]\ttraining's binary_logloss: 0.136927\n",
      "[1284]\ttraining's binary_logloss: 0.136906\n",
      "[1285]\ttraining's binary_logloss: 0.136889\n",
      "[1286]\ttraining's binary_logloss: 0.136864\n",
      "[1287]\ttraining's binary_logloss: 0.136839\n",
      "[1288]\ttraining's binary_logloss: 0.136785\n",
      "[1289]\ttraining's binary_logloss: 0.136757\n",
      "[1290]\ttraining's binary_logloss: 0.136736\n",
      "[1291]\ttraining's binary_logloss: 0.136713\n",
      "[1292]\ttraining's binary_logloss: 0.136687\n",
      "[1293]\ttraining's binary_logloss: 0.136668\n",
      "[1294]\ttraining's binary_logloss: 0.136636\n",
      "[1295]\ttraining's binary_logloss: 0.136614\n",
      "[1296]\ttraining's binary_logloss: 0.136587\n",
      "[1297]\ttraining's binary_logloss: 0.136564\n",
      "[1298]\ttraining's binary_logloss: 0.136528\n",
      "[1299]\ttraining's binary_logloss: 0.136509\n",
      "[1300]\ttraining's binary_logloss: 0.13649\n",
      "[1301]\ttraining's binary_logloss: 0.13647\n",
      "[1302]\ttraining's binary_logloss: 0.136449\n",
      "[1303]\ttraining's binary_logloss: 0.136388\n",
      "[1304]\ttraining's binary_logloss: 0.136356\n",
      "[1305]\ttraining's binary_logloss: 0.136335\n",
      "[1306]\ttraining's binary_logloss: 0.136313\n",
      "[1307]\ttraining's binary_logloss: 0.13628\n",
      "[1308]\ttraining's binary_logloss: 0.136259\n",
      "[1309]\ttraining's binary_logloss: 0.136237\n",
      "[1310]\ttraining's binary_logloss: 0.136212\n",
      "[1311]\ttraining's binary_logloss: 0.13619\n",
      "[1312]\ttraining's binary_logloss: 0.136178\n",
      "[1313]\ttraining's binary_logloss: 0.136158\n",
      "[1314]\ttraining's binary_logloss: 0.136137\n",
      "[1315]\ttraining's binary_logloss: 0.136107\n",
      "[1316]\ttraining's binary_logloss: 0.136081\n",
      "[1317]\ttraining's binary_logloss: 0.13606\n",
      "[1318]\ttraining's binary_logloss: 0.136035\n",
      "[1319]\ttraining's binary_logloss: 0.136013\n",
      "[1320]\ttraining's binary_logloss: 0.135957\n",
      "[1321]\ttraining's binary_logloss: 0.135936\n",
      "[1322]\ttraining's binary_logloss: 0.135907\n",
      "[1323]\ttraining's binary_logloss: 0.135883\n",
      "[1324]\ttraining's binary_logloss: 0.135861\n",
      "[1325]\ttraining's binary_logloss: 0.135835\n",
      "[1326]\ttraining's binary_logloss: 0.135813\n",
      "[1327]\ttraining's binary_logloss: 0.135789\n",
      "[1328]\ttraining's binary_logloss: 0.13576\n",
      "[1329]\ttraining's binary_logloss: 0.135731\n",
      "[1330]\ttraining's binary_logloss: 0.135702\n",
      "[1331]\ttraining's binary_logloss: 0.135681\n",
      "[1332]\ttraining's binary_logloss: 0.135662\n",
      "[1333]\ttraining's binary_logloss: 0.135639\n",
      "[1334]\ttraining's binary_logloss: 0.13562\n",
      "[1335]\ttraining's binary_logloss: 0.135597\n",
      "[1336]\ttraining's binary_logloss: 0.135569\n",
      "[1337]\ttraining's binary_logloss: 0.135547\n",
      "[1338]\ttraining's binary_logloss: 0.135527\n",
      "[1339]\ttraining's binary_logloss: 0.135489\n",
      "[1340]\ttraining's binary_logloss: 0.135468\n",
      "[1341]\ttraining's binary_logloss: 0.135447\n",
      "[1342]\ttraining's binary_logloss: 0.135426\n",
      "[1343]\ttraining's binary_logloss: 0.135408\n",
      "[1344]\ttraining's binary_logloss: 0.135378\n",
      "[1345]\ttraining's binary_logloss: 0.135358\n",
      "[1346]\ttraining's binary_logloss: 0.135337\n",
      "[1347]\ttraining's binary_logloss: 0.135313\n",
      "[1348]\ttraining's binary_logloss: 0.135291\n",
      "[1349]\ttraining's binary_logloss: 0.135278\n",
      "[1350]\ttraining's binary_logloss: 0.135256\n",
      "[1351]\ttraining's binary_logloss: 0.135237\n",
      "[1352]\ttraining's binary_logloss: 0.13521\n",
      "[1353]\ttraining's binary_logloss: 0.135189\n",
      "[1354]\ttraining's binary_logloss: 0.135168\n",
      "[1355]\ttraining's binary_logloss: 0.135148\n",
      "[1356]\ttraining's binary_logloss: 0.135097\n",
      "[1357]\ttraining's binary_logloss: 0.135073\n",
      "[1358]\ttraining's binary_logloss: 0.135036\n",
      "[1359]\ttraining's binary_logloss: 0.13501\n",
      "[1360]\ttraining's binary_logloss: 0.134991\n",
      "[1361]\ttraining's binary_logloss: 0.13496\n",
      "[1362]\ttraining's binary_logloss: 0.134941\n",
      "[1363]\ttraining's binary_logloss: 0.134919\n",
      "[1364]\ttraining's binary_logloss: 0.134892\n",
      "[1365]\ttraining's binary_logloss: 0.134879\n",
      "[1366]\ttraining's binary_logloss: 0.134858\n",
      "[1367]\ttraining's binary_logloss: 0.134838\n",
      "[1368]\ttraining's binary_logloss: 0.134817\n",
      "[1369]\ttraining's binary_logloss: 0.134804\n",
      "[1370]\ttraining's binary_logloss: 0.134782\n",
      "[1371]\ttraining's binary_logloss: 0.134762\n",
      "[1372]\ttraining's binary_logloss: 0.134741\n",
      "[1373]\ttraining's binary_logloss: 0.134718\n",
      "[1374]\ttraining's binary_logloss: 0.134698\n",
      "[1375]\ttraining's binary_logloss: 0.134677\n",
      "[1376]\ttraining's binary_logloss: 0.134657\n",
      "[1377]\ttraining's binary_logloss: 0.134614\n",
      "[1378]\ttraining's binary_logloss: 0.134593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1379]\ttraining's binary_logloss: 0.134577\n",
      "[1380]\ttraining's binary_logloss: 0.134557\n",
      "[1381]\ttraining's binary_logloss: 0.134539\n",
      "[1382]\ttraining's binary_logloss: 0.134527\n",
      "[1383]\ttraining's binary_logloss: 0.134501\n",
      "[1384]\ttraining's binary_logloss: 0.134471\n",
      "[1385]\ttraining's binary_logloss: 0.134447\n",
      "[1386]\ttraining's binary_logloss: 0.134426\n",
      "[1387]\ttraining's binary_logloss: 0.134406\n",
      "[1388]\ttraining's binary_logloss: 0.13438\n",
      "[1389]\ttraining's binary_logloss: 0.134356\n",
      "[1390]\ttraining's binary_logloss: 0.134335\n",
      "[1391]\ttraining's binary_logloss: 0.134306\n",
      "[1392]\ttraining's binary_logloss: 0.134285\n",
      "[1393]\ttraining's binary_logloss: 0.13426\n",
      "[1394]\ttraining's binary_logloss: 0.134242\n",
      "[1395]\ttraining's binary_logloss: 0.13422\n",
      "[1396]\ttraining's binary_logloss: 0.134192\n",
      "[1397]\ttraining's binary_logloss: 0.134172\n",
      "[1398]\ttraining's binary_logloss: 0.134158\n",
      "[1399]\ttraining's binary_logloss: 0.134139\n",
      "[1400]\ttraining's binary_logloss: 0.13412\n",
      "[1401]\ttraining's binary_logloss: 0.13408\n",
      "[1402]\ttraining's binary_logloss: 0.134059\n",
      "[1403]\ttraining's binary_logloss: 0.134032\n",
      "[1404]\ttraining's binary_logloss: 0.134003\n",
      "[1405]\ttraining's binary_logloss: 0.133981\n",
      "[1406]\ttraining's binary_logloss: 0.13397\n",
      "[1407]\ttraining's binary_logloss: 0.133956\n",
      "[1408]\ttraining's binary_logloss: 0.133934\n",
      "[1409]\ttraining's binary_logloss: 0.133916\n",
      "[1410]\ttraining's binary_logloss: 0.133892\n",
      "[1411]\ttraining's binary_logloss: 0.133872\n",
      "[1412]\ttraining's binary_logloss: 0.133848\n",
      "[1413]\ttraining's binary_logloss: 0.13383\n",
      "[1414]\ttraining's binary_logloss: 0.133779\n",
      "[1415]\ttraining's binary_logloss: 0.133752\n",
      "[1416]\ttraining's binary_logloss: 0.133727\n",
      "[1417]\ttraining's binary_logloss: 0.133709\n",
      "[1418]\ttraining's binary_logloss: 0.133683\n",
      "[1419]\ttraining's binary_logloss: 0.133664\n",
      "[1420]\ttraining's binary_logloss: 0.133644\n",
      "[1421]\ttraining's binary_logloss: 0.133609\n",
      "[1422]\ttraining's binary_logloss: 0.13359\n",
      "[1423]\ttraining's binary_logloss: 0.133571\n",
      "[1424]\ttraining's binary_logloss: 0.133552\n",
      "[1425]\ttraining's binary_logloss: 0.133525\n",
      "[1426]\ttraining's binary_logloss: 0.133508\n",
      "[1427]\ttraining's binary_logloss: 0.133485\n",
      "[1428]\ttraining's binary_logloss: 0.133449\n",
      "[1429]\ttraining's binary_logloss: 0.133426\n",
      "[1430]\ttraining's binary_logloss: 0.133406\n",
      "[1431]\ttraining's binary_logloss: 0.133386\n",
      "[1432]\ttraining's binary_logloss: 0.133364\n",
      "[1433]\ttraining's binary_logloss: 0.133346\n",
      "[1434]\ttraining's binary_logloss: 0.133319\n",
      "[1435]\ttraining's binary_logloss: 0.133306\n",
      "[1436]\ttraining's binary_logloss: 0.133286\n",
      "[1437]\ttraining's binary_logloss: 0.133267\n",
      "[1438]\ttraining's binary_logloss: 0.133245\n",
      "[1439]\ttraining's binary_logloss: 0.133202\n",
      "[1440]\ttraining's binary_logloss: 0.133184\n",
      "[1441]\ttraining's binary_logloss: 0.133165\n",
      "[1442]\ttraining's binary_logloss: 0.133147\n",
      "[1443]\ttraining's binary_logloss: 0.133127\n",
      "[1444]\ttraining's binary_logloss: 0.133108\n",
      "[1445]\ttraining's binary_logloss: 0.133079\n",
      "[1446]\ttraining's binary_logloss: 0.13306\n",
      "[1447]\ttraining's binary_logloss: 0.133043\n",
      "[1448]\ttraining's binary_logloss: 0.133021\n",
      "[1449]\ttraining's binary_logloss: 0.132999\n",
      "[1450]\ttraining's binary_logloss: 0.132975\n",
      "[1451]\ttraining's binary_logloss: 0.132956\n",
      "[1452]\ttraining's binary_logloss: 0.132926\n",
      "[1453]\ttraining's binary_logloss: 0.132906\n",
      "[1454]\ttraining's binary_logloss: 0.132881\n",
      "[1455]\ttraining's binary_logloss: 0.132863\n",
      "[1456]\ttraining's binary_logloss: 0.132845\n",
      "[1457]\ttraining's binary_logloss: 0.132828\n",
      "[1458]\ttraining's binary_logloss: 0.132805\n",
      "[1459]\ttraining's binary_logloss: 0.132794\n",
      "[1460]\ttraining's binary_logloss: 0.132775\n",
      "[1461]\ttraining's binary_logloss: 0.132755\n",
      "[1462]\ttraining's binary_logloss: 0.132735\n",
      "[1463]\ttraining's binary_logloss: 0.132712\n",
      "[1464]\ttraining's binary_logloss: 0.132696\n",
      "[1465]\ttraining's binary_logloss: 0.132678\n",
      "[1466]\ttraining's binary_logloss: 0.132648\n",
      "[1467]\ttraining's binary_logloss: 0.132625\n",
      "[1468]\ttraining's binary_logloss: 0.132602\n",
      "[1469]\ttraining's binary_logloss: 0.132549\n",
      "[1470]\ttraining's binary_logloss: 0.13252\n",
      "[1471]\ttraining's binary_logloss: 0.132502\n",
      "[1472]\ttraining's binary_logloss: 0.132481\n",
      "[1473]\ttraining's binary_logloss: 0.132463\n",
      "[1474]\ttraining's binary_logloss: 0.132432\n",
      "[1475]\ttraining's binary_logloss: 0.13241\n",
      "[1476]\ttraining's binary_logloss: 0.132386\n",
      "[1477]\ttraining's binary_logloss: 0.132337\n",
      "[1478]\ttraining's binary_logloss: 0.132306\n",
      "[1479]\ttraining's binary_logloss: 0.132286\n",
      "[1480]\ttraining's binary_logloss: 0.132262\n",
      "[1481]\ttraining's binary_logloss: 0.132243\n",
      "[1482]\ttraining's binary_logloss: 0.132225\n",
      "[1483]\ttraining's binary_logloss: 0.132201\n",
      "[1484]\ttraining's binary_logloss: 0.132179\n",
      "[1485]\ttraining's binary_logloss: 0.132157\n",
      "[1486]\ttraining's binary_logloss: 0.132136\n",
      "[1487]\ttraining's binary_logloss: 0.132112\n",
      "[1488]\ttraining's binary_logloss: 0.132091\n",
      "[1489]\ttraining's binary_logloss: 0.132053\n",
      "[1490]\ttraining's binary_logloss: 0.132032\n",
      "[1491]\ttraining's binary_logloss: 0.132012\n",
      "[1492]\ttraining's binary_logloss: 0.131977\n",
      "[1493]\ttraining's binary_logloss: 0.131958\n",
      "[1494]\ttraining's binary_logloss: 0.131938\n",
      "[1495]\ttraining's binary_logloss: 0.131909\n",
      "[1496]\ttraining's binary_logloss: 0.131889\n",
      "[1497]\ttraining's binary_logloss: 0.131871\n",
      "[1498]\ttraining's binary_logloss: 0.131853\n",
      "[1499]\ttraining's binary_logloss: 0.131824\n",
      "[1500]\ttraining's binary_logloss: 0.131807\n",
      "[1501]\ttraining's binary_logloss: 0.131785\n",
      "[1502]\ttraining's binary_logloss: 0.131761\n",
      "[1503]\ttraining's binary_logloss: 0.131744\n",
      "[1504]\ttraining's binary_logloss: 0.131722\n",
      "[1505]\ttraining's binary_logloss: 0.131694\n",
      "[1506]\ttraining's binary_logloss: 0.131678\n",
      "[1507]\ttraining's binary_logloss: 0.131659\n",
      "[1508]\ttraining's binary_logloss: 0.131641\n",
      "[1509]\ttraining's binary_logloss: 0.131621\n",
      "[1510]\ttraining's binary_logloss: 0.1316\n",
      "[1511]\ttraining's binary_logloss: 0.13158\n",
      "[1512]\ttraining's binary_logloss: 0.131561\n",
      "[1513]\ttraining's binary_logloss: 0.131544\n",
      "[1514]\ttraining's binary_logloss: 0.131526\n",
      "[1515]\ttraining's binary_logloss: 0.131504\n",
      "[1516]\ttraining's binary_logloss: 0.131481\n",
      "[1517]\ttraining's binary_logloss: 0.131467\n",
      "[1518]\ttraining's binary_logloss: 0.131446\n",
      "[1519]\ttraining's binary_logloss: 0.131428\n",
      "[1520]\ttraining's binary_logloss: 0.131407\n",
      "[1521]\ttraining's binary_logloss: 0.131376\n",
      "[1522]\ttraining's binary_logloss: 0.131361\n",
      "[1523]\ttraining's binary_logloss: 0.131343\n",
      "[1524]\ttraining's binary_logloss: 0.131322\n",
      "[1525]\ttraining's binary_logloss: 0.131298\n",
      "[1526]\ttraining's binary_logloss: 0.131282\n",
      "[1527]\ttraining's binary_logloss: 0.131262\n",
      "[1528]\ttraining's binary_logloss: 0.13124\n",
      "[1529]\ttraining's binary_logloss: 0.131214\n",
      "[1530]\ttraining's binary_logloss: 0.131195\n",
      "[1531]\ttraining's binary_logloss: 0.131177\n",
      "[1532]\ttraining's binary_logloss: 0.131158\n",
      "[1533]\ttraining's binary_logloss: 0.131137\n",
      "[1534]\ttraining's binary_logloss: 0.131119\n",
      "[1535]\ttraining's binary_logloss: 0.131102\n",
      "[1536]\ttraining's binary_logloss: 0.131078\n",
      "[1537]\ttraining's binary_logloss: 0.131057\n",
      "[1538]\ttraining's binary_logloss: 0.131038\n",
      "[1539]\ttraining's binary_logloss: 0.131016\n",
      "[1540]\ttraining's binary_logloss: 0.130997\n",
      "[1541]\ttraining's binary_logloss: 0.130951\n",
      "[1542]\ttraining's binary_logloss: 0.130919\n",
      "[1543]\ttraining's binary_logloss: 0.1309\n",
      "[1544]\ttraining's binary_logloss: 0.130873\n",
      "[1545]\ttraining's binary_logloss: 0.130851\n",
      "[1546]\ttraining's binary_logloss: 0.130837\n",
      "[1547]\ttraining's binary_logloss: 0.130814\n",
      "[1548]\ttraining's binary_logloss: 0.130795\n",
      "[1549]\ttraining's binary_logloss: 0.130779\n",
      "[1550]\ttraining's binary_logloss: 0.130759\n",
      "[1551]\ttraining's binary_logloss: 0.130741\n",
      "[1552]\ttraining's binary_logloss: 0.130727\n",
      "[1553]\ttraining's binary_logloss: 0.130707\n",
      "[1554]\ttraining's binary_logloss: 0.130688\n",
      "[1555]\ttraining's binary_logloss: 0.13067\n",
      "[1556]\ttraining's binary_logloss: 0.130645\n",
      "[1557]\ttraining's binary_logloss: 0.130628\n",
      "[1558]\ttraining's binary_logloss: 0.130606\n",
      "[1559]\ttraining's binary_logloss: 0.130585\n",
      "[1560]\ttraining's binary_logloss: 0.130563\n",
      "[1561]\ttraining's binary_logloss: 0.13055\n",
      "[1562]\ttraining's binary_logloss: 0.130531\n",
      "[1563]\ttraining's binary_logloss: 0.130512\n",
      "[1564]\ttraining's binary_logloss: 0.130501\n",
      "[1565]\ttraining's binary_logloss: 0.130477\n",
      "[1566]\ttraining's binary_logloss: 0.130456\n",
      "[1567]\ttraining's binary_logloss: 0.130441\n",
      "[1568]\ttraining's binary_logloss: 0.130415\n",
      "[1569]\ttraining's binary_logloss: 0.130397\n",
      "[1570]\ttraining's binary_logloss: 0.130382\n",
      "[1571]\ttraining's binary_logloss: 0.130365\n",
      "[1572]\ttraining's binary_logloss: 0.130348\n",
      "[1573]\ttraining's binary_logloss: 0.13033\n",
      "[1574]\ttraining's binary_logloss: 0.130313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1575]\ttraining's binary_logloss: 0.130291\n",
      "[1576]\ttraining's binary_logloss: 0.130269\n",
      "[1577]\ttraining's binary_logloss: 0.130247\n",
      "[1578]\ttraining's binary_logloss: 0.130201\n",
      "[1579]\ttraining's binary_logloss: 0.130182\n",
      "[1580]\ttraining's binary_logloss: 0.130165\n",
      "[1581]\ttraining's binary_logloss: 0.130149\n",
      "[1582]\ttraining's binary_logloss: 0.130131\n",
      "[1583]\ttraining's binary_logloss: 0.130106\n",
      "[1584]\ttraining's binary_logloss: 0.130087\n",
      "[1585]\ttraining's binary_logloss: 0.130068\n",
      "[1586]\ttraining's binary_logloss: 0.130049\n",
      "[1587]\ttraining's binary_logloss: 0.130027\n",
      "[1588]\ttraining's binary_logloss: 0.130005\n",
      "[1589]\ttraining's binary_logloss: 0.129983\n",
      "[1590]\ttraining's binary_logloss: 0.129961\n",
      "[1591]\ttraining's binary_logloss: 0.129945\n",
      "[1592]\ttraining's binary_logloss: 0.129921\n",
      "[1593]\ttraining's binary_logloss: 0.129905\n",
      "[1594]\ttraining's binary_logloss: 0.129886\n",
      "[1595]\ttraining's binary_logloss: 0.129864\n",
      "[1596]\ttraining's binary_logloss: 0.129836\n",
      "[1597]\ttraining's binary_logloss: 0.129815\n",
      "[1598]\ttraining's binary_logloss: 0.129793\n",
      "[1599]\ttraining's binary_logloss: 0.129764\n",
      "[1600]\ttraining's binary_logloss: 0.129747\n",
      "[1601]\ttraining's binary_logloss: 0.129727\n",
      "[1602]\ttraining's binary_logloss: 0.129712\n",
      "[1603]\ttraining's binary_logloss: 0.129697\n",
      "[1604]\ttraining's binary_logloss: 0.129679\n",
      "[1605]\ttraining's binary_logloss: 0.129661\n",
      "[1606]\ttraining's binary_logloss: 0.129641\n",
      "[1607]\ttraining's binary_logloss: 0.129619\n",
      "[1608]\ttraining's binary_logloss: 0.129572\n",
      "[1609]\ttraining's binary_logloss: 0.129551\n",
      "[1610]\ttraining's binary_logloss: 0.129525\n",
      "[1611]\ttraining's binary_logloss: 0.129507\n",
      "[1612]\ttraining's binary_logloss: 0.129491\n",
      "[1613]\ttraining's binary_logloss: 0.129463\n",
      "[1614]\ttraining's binary_logloss: 0.129445\n",
      "[1615]\ttraining's binary_logloss: 0.129424\n",
      "[1616]\ttraining's binary_logloss: 0.129401\n",
      "[1617]\ttraining's binary_logloss: 0.129384\n",
      "[1618]\ttraining's binary_logloss: 0.129364\n",
      "[1619]\ttraining's binary_logloss: 0.129346\n",
      "[1620]\ttraining's binary_logloss: 0.129324\n",
      "[1621]\ttraining's binary_logloss: 0.129304\n",
      "[1622]\ttraining's binary_logloss: 0.129281\n",
      "[1623]\ttraining's binary_logloss: 0.129265\n",
      "[1624]\ttraining's binary_logloss: 0.129242\n",
      "[1625]\ttraining's binary_logloss: 0.129221\n",
      "[1626]\ttraining's binary_logloss: 0.129201\n",
      "[1627]\ttraining's binary_logloss: 0.129184\n",
      "[1628]\ttraining's binary_logloss: 0.129165\n",
      "[1629]\ttraining's binary_logloss: 0.129144\n",
      "[1630]\ttraining's binary_logloss: 0.129126\n",
      "[1631]\ttraining's binary_logloss: 0.129109\n",
      "[1632]\ttraining's binary_logloss: 0.129084\n",
      "[1633]\ttraining's binary_logloss: 0.129067\n",
      "[1634]\ttraining's binary_logloss: 0.129051\n",
      "[1635]\ttraining's binary_logloss: 0.129033\n",
      "[1636]\ttraining's binary_logloss: 0.129023\n",
      "[1637]\ttraining's binary_logloss: 0.129001\n",
      "[1638]\ttraining's binary_logloss: 0.128979\n",
      "[1639]\ttraining's binary_logloss: 0.128958\n",
      "[1640]\ttraining's binary_logloss: 0.128938\n",
      "[1641]\ttraining's binary_logloss: 0.128916\n",
      "[1642]\ttraining's binary_logloss: 0.128895\n",
      "[1643]\ttraining's binary_logloss: 0.128877\n",
      "[1644]\ttraining's binary_logloss: 0.128859\n",
      "[1645]\ttraining's binary_logloss: 0.128837\n",
      "[1646]\ttraining's binary_logloss: 0.128811\n",
      "[1647]\ttraining's binary_logloss: 0.128795\n",
      "[1648]\ttraining's binary_logloss: 0.128773\n",
      "[1649]\ttraining's binary_logloss: 0.128754\n",
      "[1650]\ttraining's binary_logloss: 0.128724\n",
      "[1651]\ttraining's binary_logloss: 0.128703\n",
      "[1652]\ttraining's binary_logloss: 0.128684\n",
      "[1653]\ttraining's binary_logloss: 0.128664\n",
      "[1654]\ttraining's binary_logloss: 0.128643\n",
      "[1655]\ttraining's binary_logloss: 0.128624\n",
      "[1656]\ttraining's binary_logloss: 0.128609\n",
      "[1657]\ttraining's binary_logloss: 0.128591\n",
      "[1658]\ttraining's binary_logloss: 0.128571\n",
      "[1659]\ttraining's binary_logloss: 0.128549\n",
      "[1660]\ttraining's binary_logloss: 0.128532\n",
      "[1661]\ttraining's binary_logloss: 0.128516\n",
      "[1662]\ttraining's binary_logloss: 0.128498\n",
      "[1663]\ttraining's binary_logloss: 0.12848\n",
      "[1664]\ttraining's binary_logloss: 0.128457\n",
      "[1665]\ttraining's binary_logloss: 0.128438\n",
      "[1666]\ttraining's binary_logloss: 0.128421\n",
      "[1667]\ttraining's binary_logloss: 0.128407\n",
      "[1668]\ttraining's binary_logloss: 0.128389\n",
      "[1669]\ttraining's binary_logloss: 0.128381\n",
      "[1670]\ttraining's binary_logloss: 0.128368\n",
      "[1671]\ttraining's binary_logloss: 0.12835\n",
      "[1672]\ttraining's binary_logloss: 0.128335\n",
      "[1673]\ttraining's binary_logloss: 0.128315\n",
      "[1674]\ttraining's binary_logloss: 0.128295\n",
      "[1675]\ttraining's binary_logloss: 0.128275\n",
      "[1676]\ttraining's binary_logloss: 0.128248\n",
      "[1677]\ttraining's binary_logloss: 0.12823\n",
      "[1678]\ttraining's binary_logloss: 0.128212\n",
      "[1679]\ttraining's binary_logloss: 0.128199\n",
      "[1680]\ttraining's binary_logloss: 0.128177\n",
      "[1681]\ttraining's binary_logloss: 0.12816\n",
      "[1682]\ttraining's binary_logloss: 0.12815\n",
      "[1683]\ttraining's binary_logloss: 0.128131\n",
      "[1684]\ttraining's binary_logloss: 0.12811\n",
      "[1685]\ttraining's binary_logloss: 0.128079\n",
      "[1686]\ttraining's binary_logloss: 0.128065\n",
      "[1687]\ttraining's binary_logloss: 0.128047\n",
      "[1688]\ttraining's binary_logloss: 0.128026\n",
      "[1689]\ttraining's binary_logloss: 0.128009\n",
      "[1690]\ttraining's binary_logloss: 0.127996\n",
      "[1691]\ttraining's binary_logloss: 0.127972\n",
      "[1692]\ttraining's binary_logloss: 0.127957\n",
      "[1693]\ttraining's binary_logloss: 0.127939\n",
      "[1694]\ttraining's binary_logloss: 0.127896\n",
      "[1695]\ttraining's binary_logloss: 0.127875\n",
      "[1696]\ttraining's binary_logloss: 0.127857\n",
      "[1697]\ttraining's binary_logloss: 0.127845\n",
      "[1698]\ttraining's binary_logloss: 0.127811\n",
      "[1699]\ttraining's binary_logloss: 0.127795\n",
      "[1700]\ttraining's binary_logloss: 0.127776\n",
      "[1701]\ttraining's binary_logloss: 0.127758\n",
      "[1702]\ttraining's binary_logloss: 0.127737\n",
      "[1703]\ttraining's binary_logloss: 0.12772\n",
      "[1704]\ttraining's binary_logloss: 0.12771\n",
      "[1705]\ttraining's binary_logloss: 0.127693\n",
      "[1706]\ttraining's binary_logloss: 0.127676\n",
      "[1707]\ttraining's binary_logloss: 0.127653\n",
      "[1708]\ttraining's binary_logloss: 0.127635\n",
      "[1709]\ttraining's binary_logloss: 0.127619\n",
      "[1710]\ttraining's binary_logloss: 0.1276\n",
      "[1711]\ttraining's binary_logloss: 0.127583\n",
      "[1712]\ttraining's binary_logloss: 0.127538\n",
      "[1713]\ttraining's binary_logloss: 0.127521\n",
      "[1714]\ttraining's binary_logloss: 0.127498\n",
      "[1715]\ttraining's binary_logloss: 0.12748\n",
      "[1716]\ttraining's binary_logloss: 0.127459\n",
      "[1717]\ttraining's binary_logloss: 0.127427\n",
      "[1718]\ttraining's binary_logloss: 0.127412\n",
      "[1719]\ttraining's binary_logloss: 0.127393\n",
      "[1720]\ttraining's binary_logloss: 0.127374\n",
      "[1721]\ttraining's binary_logloss: 0.127356\n",
      "[1722]\ttraining's binary_logloss: 0.127341\n",
      "[1723]\ttraining's binary_logloss: 0.127321\n",
      "[1724]\ttraining's binary_logloss: 0.127303\n",
      "[1725]\ttraining's binary_logloss: 0.127284\n",
      "[1726]\ttraining's binary_logloss: 0.127262\n",
      "[1727]\ttraining's binary_logloss: 0.127222\n",
      "[1728]\ttraining's binary_logloss: 0.127206\n",
      "[1729]\ttraining's binary_logloss: 0.127187\n",
      "[1730]\ttraining's binary_logloss: 0.127169\n",
      "[1731]\ttraining's binary_logloss: 0.12715\n",
      "[1732]\ttraining's binary_logloss: 0.127133\n",
      "[1733]\ttraining's binary_logloss: 0.127113\n",
      "[1734]\ttraining's binary_logloss: 0.127091\n",
      "[1735]\ttraining's binary_logloss: 0.12707\n",
      "[1736]\ttraining's binary_logloss: 0.12705\n",
      "[1737]\ttraining's binary_logloss: 0.127033\n",
      "[1738]\ttraining's binary_logloss: 0.127013\n",
      "[1739]\ttraining's binary_logloss: 0.126995\n",
      "[1740]\ttraining's binary_logloss: 0.126976\n",
      "[1741]\ttraining's binary_logloss: 0.126957\n",
      "[1742]\ttraining's binary_logloss: 0.12692\n",
      "[1743]\ttraining's binary_logloss: 0.126912\n",
      "[1744]\ttraining's binary_logloss: 0.126896\n",
      "[1745]\ttraining's binary_logloss: 0.126877\n",
      "[1746]\ttraining's binary_logloss: 0.126838\n",
      "[1747]\ttraining's binary_logloss: 0.126821\n",
      "[1748]\ttraining's binary_logloss: 0.126802\n",
      "[1749]\ttraining's binary_logloss: 0.126787\n",
      "[1750]\ttraining's binary_logloss: 0.126772\n",
      "[1751]\ttraining's binary_logloss: 0.126762\n",
      "[1752]\ttraining's binary_logloss: 0.126739\n",
      "[1753]\ttraining's binary_logloss: 0.126723\n",
      "[1754]\ttraining's binary_logloss: 0.126706\n",
      "[1755]\ttraining's binary_logloss: 0.126672\n",
      "[1756]\ttraining's binary_logloss: 0.126654\n",
      "[1757]\ttraining's binary_logloss: 0.126636\n",
      "[1758]\ttraining's binary_logloss: 0.126626\n",
      "[1759]\ttraining's binary_logloss: 0.126606\n",
      "[1760]\ttraining's binary_logloss: 0.12659\n",
      "[1761]\ttraining's binary_logloss: 0.126572\n",
      "[1762]\ttraining's binary_logloss: 0.126555\n",
      "[1763]\ttraining's binary_logloss: 0.126539\n",
      "[1764]\ttraining's binary_logloss: 0.126522\n",
      "[1765]\ttraining's binary_logloss: 0.126504\n",
      "[1766]\ttraining's binary_logloss: 0.126486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1767]\ttraining's binary_logloss: 0.126458\n",
      "[1768]\ttraining's binary_logloss: 0.126443\n",
      "[1769]\ttraining's binary_logloss: 0.126426\n",
      "[1770]\ttraining's binary_logloss: 0.126407\n",
      "[1771]\ttraining's binary_logloss: 0.126387\n",
      "[1772]\ttraining's binary_logloss: 0.126369\n",
      "[1773]\ttraining's binary_logloss: 0.126353\n",
      "[1774]\ttraining's binary_logloss: 0.126338\n",
      "[1775]\ttraining's binary_logloss: 0.126297\n",
      "[1776]\ttraining's binary_logloss: 0.126282\n",
      "[1777]\ttraining's binary_logloss: 0.126263\n",
      "[1778]\ttraining's binary_logloss: 0.126246\n",
      "[1779]\ttraining's binary_logloss: 0.126229\n",
      "[1780]\ttraining's binary_logloss: 0.126212\n",
      "[1781]\ttraining's binary_logloss: 0.126192\n",
      "[1782]\ttraining's binary_logloss: 0.126145\n",
      "[1783]\ttraining's binary_logloss: 0.126129\n",
      "[1784]\ttraining's binary_logloss: 0.126113\n",
      "[1785]\ttraining's binary_logloss: 0.126096\n",
      "[1786]\ttraining's binary_logloss: 0.126078\n",
      "[1787]\ttraining's binary_logloss: 0.12606\n",
      "[1788]\ttraining's binary_logloss: 0.126049\n",
      "[1789]\ttraining's binary_logloss: 0.126031\n",
      "[1790]\ttraining's binary_logloss: 0.126019\n",
      "[1791]\ttraining's binary_logloss: 0.126001\n",
      "[1792]\ttraining's binary_logloss: 0.125972\n",
      "[1793]\ttraining's binary_logloss: 0.125957\n",
      "[1794]\ttraining's binary_logloss: 0.125939\n",
      "[1795]\ttraining's binary_logloss: 0.125922\n",
      "[1796]\ttraining's binary_logloss: 0.125902\n",
      "[1797]\ttraining's binary_logloss: 0.12588\n",
      "[1798]\ttraining's binary_logloss: 0.125865\n",
      "[1799]\ttraining's binary_logloss: 0.125849\n",
      "[1800]\ttraining's binary_logloss: 0.12583\n",
      "[1801]\ttraining's binary_logloss: 0.125809\n",
      "[1802]\ttraining's binary_logloss: 0.125793\n",
      "[1803]\ttraining's binary_logloss: 0.125772\n",
      "[1804]\ttraining's binary_logloss: 0.125753\n",
      "[1805]\ttraining's binary_logloss: 0.125737\n",
      "[1806]\ttraining's binary_logloss: 0.125721\n",
      "[1807]\ttraining's binary_logloss: 0.1257\n",
      "[1808]\ttraining's binary_logloss: 0.125681\n",
      "[1809]\ttraining's binary_logloss: 0.125663\n",
      "[1810]\ttraining's binary_logloss: 0.125643\n",
      "[1811]\ttraining's binary_logloss: 0.125625\n",
      "[1812]\ttraining's binary_logloss: 0.125609\n",
      "[1813]\ttraining's binary_logloss: 0.125592\n",
      "[1814]\ttraining's binary_logloss: 0.125578\n",
      "[1815]\ttraining's binary_logloss: 0.125561\n",
      "[1816]\ttraining's binary_logloss: 0.125543\n",
      "[1817]\ttraining's binary_logloss: 0.125527\n",
      "[1818]\ttraining's binary_logloss: 0.125511\n",
      "[1819]\ttraining's binary_logloss: 0.125492\n",
      "[1820]\ttraining's binary_logloss: 0.125457\n",
      "[1821]\ttraining's binary_logloss: 0.125441\n",
      "[1822]\ttraining's binary_logloss: 0.125394\n",
      "[1823]\ttraining's binary_logloss: 0.125377\n",
      "[1824]\ttraining's binary_logloss: 0.125362\n",
      "[1825]\ttraining's binary_logloss: 0.125345\n",
      "[1826]\ttraining's binary_logloss: 0.125328\n",
      "[1827]\ttraining's binary_logloss: 0.12531\n",
      "[1828]\ttraining's binary_logloss: 0.125294\n",
      "[1829]\ttraining's binary_logloss: 0.125276\n",
      "[1830]\ttraining's binary_logloss: 0.125259\n",
      "[1831]\ttraining's binary_logloss: 0.125242\n",
      "[1832]\ttraining's binary_logloss: 0.125226\n",
      "[1833]\ttraining's binary_logloss: 0.12521\n",
      "[1834]\ttraining's binary_logloss: 0.125193\n",
      "[1835]\ttraining's binary_logloss: 0.125174\n",
      "[1836]\ttraining's binary_logloss: 0.125158\n",
      "[1837]\ttraining's binary_logloss: 0.125137\n",
      "[1838]\ttraining's binary_logloss: 0.125114\n",
      "[1839]\ttraining's binary_logloss: 0.125096\n",
      "[1840]\ttraining's binary_logloss: 0.12508\n",
      "[1841]\ttraining's binary_logloss: 0.125062\n",
      "[1842]\ttraining's binary_logloss: 0.125044\n",
      "[1843]\ttraining's binary_logloss: 0.12501\n",
      "[1844]\ttraining's binary_logloss: 0.124993\n",
      "[1845]\ttraining's binary_logloss: 0.124976\n",
      "[1846]\ttraining's binary_logloss: 0.124961\n",
      "[1847]\ttraining's binary_logloss: 0.124933\n",
      "[1848]\ttraining's binary_logloss: 0.124918\n",
      "[1849]\ttraining's binary_logloss: 0.124902\n",
      "[1850]\ttraining's binary_logloss: 0.124884\n",
      "[1851]\ttraining's binary_logloss: 0.124869\n",
      "[1852]\ttraining's binary_logloss: 0.124851\n",
      "[1853]\ttraining's binary_logloss: 0.124822\n",
      "[1854]\ttraining's binary_logloss: 0.124804\n",
      "[1855]\ttraining's binary_logloss: 0.124787\n",
      "[1856]\ttraining's binary_logloss: 0.124769\n",
      "[1857]\ttraining's binary_logloss: 0.124754\n",
      "[1858]\ttraining's binary_logloss: 0.124734\n",
      "[1859]\ttraining's binary_logloss: 0.124721\n",
      "[1860]\ttraining's binary_logloss: 0.1247\n",
      "[1861]\ttraining's binary_logloss: 0.124683\n",
      "[1862]\ttraining's binary_logloss: 0.12464\n",
      "[1863]\ttraining's binary_logloss: 0.124624\n",
      "[1864]\ttraining's binary_logloss: 0.124604\n",
      "[1865]\ttraining's binary_logloss: 0.124577\n",
      "[1866]\ttraining's binary_logloss: 0.124563\n",
      "[1867]\ttraining's binary_logloss: 0.124546\n",
      "[1868]\ttraining's binary_logloss: 0.12453\n",
      "[1869]\ttraining's binary_logloss: 0.124514\n",
      "[1870]\ttraining's binary_logloss: 0.124496\n",
      "[1871]\ttraining's binary_logloss: 0.124478\n",
      "[1872]\ttraining's binary_logloss: 0.124462\n",
      "[1873]\ttraining's binary_logloss: 0.124449\n",
      "[1874]\ttraining's binary_logloss: 0.124434\n",
      "[1875]\ttraining's binary_logloss: 0.124418\n",
      "[1876]\ttraining's binary_logloss: 0.124396\n",
      "[1877]\ttraining's binary_logloss: 0.124376\n",
      "[1878]\ttraining's binary_logloss: 0.124362\n",
      "[1879]\ttraining's binary_logloss: 0.124356\n",
      "[1880]\ttraining's binary_logloss: 0.124338\n",
      "[1881]\ttraining's binary_logloss: 0.124318\n",
      "[1882]\ttraining's binary_logloss: 0.124308\n",
      "[1883]\ttraining's binary_logloss: 0.124287\n",
      "[1884]\ttraining's binary_logloss: 0.124271\n",
      "[1885]\ttraining's binary_logloss: 0.124255\n",
      "[1886]\ttraining's binary_logloss: 0.124235\n",
      "[1887]\ttraining's binary_logloss: 0.124219\n",
      "[1888]\ttraining's binary_logloss: 0.124202\n",
      "[1889]\ttraining's binary_logloss: 0.124185\n",
      "[1890]\ttraining's binary_logloss: 0.124168\n",
      "[1891]\ttraining's binary_logloss: 0.124151\n",
      "[1892]\ttraining's binary_logloss: 0.124133\n",
      "[1893]\ttraining's binary_logloss: 0.124111\n",
      "[1894]\ttraining's binary_logloss: 0.124095\n",
      "[1895]\ttraining's binary_logloss: 0.124077\n",
      "[1896]\ttraining's binary_logloss: 0.124063\n",
      "[1897]\ttraining's binary_logloss: 0.124043\n",
      "[1898]\ttraining's binary_logloss: 0.124026\n",
      "[1899]\ttraining's binary_logloss: 0.124009\n",
      "[1900]\ttraining's binary_logloss: 0.12399\n",
      "[1901]\ttraining's binary_logloss: 0.123974\n",
      "[1902]\ttraining's binary_logloss: 0.123957\n",
      "[1903]\ttraining's binary_logloss: 0.123938\n",
      "[1904]\ttraining's binary_logloss: 0.123921\n",
      "[1905]\ttraining's binary_logloss: 0.123902\n",
      "[1906]\ttraining's binary_logloss: 0.123886\n",
      "[1907]\ttraining's binary_logloss: 0.123868\n",
      "[1908]\ttraining's binary_logloss: 0.123847\n",
      "[1909]\ttraining's binary_logloss: 0.123828\n",
      "[1910]\ttraining's binary_logloss: 0.123804\n",
      "[1911]\ttraining's binary_logloss: 0.123796\n",
      "[1912]\ttraining's binary_logloss: 0.123765\n",
      "[1913]\ttraining's binary_logloss: 0.12375\n",
      "[1914]\ttraining's binary_logloss: 0.123735\n",
      "[1915]\ttraining's binary_logloss: 0.123718\n",
      "[1916]\ttraining's binary_logloss: 0.123703\n",
      "[1917]\ttraining's binary_logloss: 0.123687\n",
      "[1918]\ttraining's binary_logloss: 0.123669\n",
      "[1919]\ttraining's binary_logloss: 0.123652\n",
      "[1920]\ttraining's binary_logloss: 0.123632\n",
      "[1921]\ttraining's binary_logloss: 0.123612\n",
      "[1922]\ttraining's binary_logloss: 0.123596\n",
      "[1923]\ttraining's binary_logloss: 0.12358\n",
      "[1924]\ttraining's binary_logloss: 0.123561\n",
      "[1925]\ttraining's binary_logloss: 0.123545\n",
      "[1926]\ttraining's binary_logloss: 0.123527\n",
      "[1927]\ttraining's binary_logloss: 0.12351\n",
      "[1928]\ttraining's binary_logloss: 0.123494\n",
      "[1929]\ttraining's binary_logloss: 0.123476\n",
      "[1930]\ttraining's binary_logloss: 0.123457\n",
      "[1931]\ttraining's binary_logloss: 0.123438\n",
      "[1932]\ttraining's binary_logloss: 0.123421\n",
      "[1933]\ttraining's binary_logloss: 0.123405\n",
      "[1934]\ttraining's binary_logloss: 0.123378\n",
      "[1935]\ttraining's binary_logloss: 0.123362\n",
      "[1936]\ttraining's binary_logloss: 0.123345\n",
      "[1937]\ttraining's binary_logloss: 0.123328\n",
      "[1938]\ttraining's binary_logloss: 0.123309\n",
      "[1939]\ttraining's binary_logloss: 0.123292\n",
      "[1940]\ttraining's binary_logloss: 0.123275\n",
      "[1941]\ttraining's binary_logloss: 0.123248\n",
      "[1942]\ttraining's binary_logloss: 0.123228\n",
      "[1943]\ttraining's binary_logloss: 0.123212\n",
      "[1944]\ttraining's binary_logloss: 0.123197\n",
      "[1945]\ttraining's binary_logloss: 0.123177\n",
      "[1946]\ttraining's binary_logloss: 0.123162\n",
      "[1947]\ttraining's binary_logloss: 0.123142\n",
      "[1948]\ttraining's binary_logloss: 0.123127\n",
      "[1949]\ttraining's binary_logloss: 0.12311\n",
      "[1950]\ttraining's binary_logloss: 0.123095\n",
      "[1951]\ttraining's binary_logloss: 0.123079\n",
      "[1952]\ttraining's binary_logloss: 0.123067\n",
      "[1953]\ttraining's binary_logloss: 0.123052\n",
      "[1954]\ttraining's binary_logloss: 0.123032\n",
      "[1955]\ttraining's binary_logloss: 0.123006\n",
      "[1956]\ttraining's binary_logloss: 0.122994\n",
      "[1957]\ttraining's binary_logloss: 0.122976\n",
      "[1958]\ttraining's binary_logloss: 0.122958\n",
      "[1959]\ttraining's binary_logloss: 0.122938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1960]\ttraining's binary_logloss: 0.122921\n",
      "[1961]\ttraining's binary_logloss: 0.122904\n",
      "[1962]\ttraining's binary_logloss: 0.122886\n",
      "[1963]\ttraining's binary_logloss: 0.122869\n",
      "[1964]\ttraining's binary_logloss: 0.122849\n",
      "[1965]\ttraining's binary_logloss: 0.122832\n",
      "[1966]\ttraining's binary_logloss: 0.122816\n",
      "[1967]\ttraining's binary_logloss: 0.122799\n",
      "[1968]\ttraining's binary_logloss: 0.122783\n",
      "[1969]\ttraining's binary_logloss: 0.122764\n",
      "[1970]\ttraining's binary_logloss: 0.122746\n",
      "[1971]\ttraining's binary_logloss: 0.122729\n",
      "[1972]\ttraining's binary_logloss: 0.12271\n",
      "[1973]\ttraining's binary_logloss: 0.122692\n",
      "[1974]\ttraining's binary_logloss: 0.122674\n",
      "[1975]\ttraining's binary_logloss: 0.122657\n",
      "[1976]\ttraining's binary_logloss: 0.12264\n",
      "[1977]\ttraining's binary_logloss: 0.122621\n",
      "[1978]\ttraining's binary_logloss: 0.122607\n",
      "[1979]\ttraining's binary_logloss: 0.122589\n",
      "[1980]\ttraining's binary_logloss: 0.122571\n",
      "[1981]\ttraining's binary_logloss: 0.122552\n",
      "[1982]\ttraining's binary_logloss: 0.122536\n",
      "[1983]\ttraining's binary_logloss: 0.122529\n",
      "[1984]\ttraining's binary_logloss: 0.122512\n",
      "[1985]\ttraining's binary_logloss: 0.122495\n",
      "[1986]\ttraining's binary_logloss: 0.122478\n",
      "[1987]\ttraining's binary_logloss: 0.12246\n",
      "[1988]\ttraining's binary_logloss: 0.122444\n",
      "[1989]\ttraining's binary_logloss: 0.12243\n",
      "[1990]\ttraining's binary_logloss: 0.122411\n",
      "[1991]\ttraining's binary_logloss: 0.122396\n",
      "[1992]\ttraining's binary_logloss: 0.122379\n",
      "[1993]\ttraining's binary_logloss: 0.122362\n",
      "[1994]\ttraining's binary_logloss: 0.122346\n",
      "[1995]\ttraining's binary_logloss: 0.122328\n",
      "[1996]\ttraining's binary_logloss: 0.122315\n",
      "[1997]\ttraining's binary_logloss: 0.1223\n",
      "[1998]\ttraining's binary_logloss: 0.122283\n",
      "[1999]\ttraining's binary_logloss: 0.122267\n",
      "[2000]\ttraining's binary_logloss: 0.12225\n",
      "[2001]\ttraining's binary_logloss: 0.122233\n",
      "[2002]\ttraining's binary_logloss: 0.122218\n",
      "[2003]\ttraining's binary_logloss: 0.122199\n",
      "[2004]\ttraining's binary_logloss: 0.122182\n",
      "[2005]\ttraining's binary_logloss: 0.122166\n",
      "[2006]\ttraining's binary_logloss: 0.122142\n",
      "[2007]\ttraining's binary_logloss: 0.122125\n",
      "[2008]\ttraining's binary_logloss: 0.122108\n",
      "[2009]\ttraining's binary_logloss: 0.122082\n",
      "[2010]\ttraining's binary_logloss: 0.122067\n",
      "[2011]\ttraining's binary_logloss: 0.122048\n",
      "[2012]\ttraining's binary_logloss: 0.122038\n",
      "[2013]\ttraining's binary_logloss: 0.122022\n",
      "[2014]\ttraining's binary_logloss: 0.122006\n",
      "[2015]\ttraining's binary_logloss: 0.121987\n",
      "[2016]\ttraining's binary_logloss: 0.12197\n",
      "[2017]\ttraining's binary_logloss: 0.121955\n",
      "[2018]\ttraining's binary_logloss: 0.121938\n",
      "[2019]\ttraining's binary_logloss: 0.121922\n",
      "[2020]\ttraining's binary_logloss: 0.121906\n",
      "[2021]\ttraining's binary_logloss: 0.121887\n",
      "[2022]\ttraining's binary_logloss: 0.121863\n",
      "[2023]\ttraining's binary_logloss: 0.121848\n",
      "[2024]\ttraining's binary_logloss: 0.121831\n",
      "[2025]\ttraining's binary_logloss: 0.121822\n",
      "[2026]\ttraining's binary_logloss: 0.121807\n",
      "[2027]\ttraining's binary_logloss: 0.121792\n",
      "[2028]\ttraining's binary_logloss: 0.121774\n",
      "[2029]\ttraining's binary_logloss: 0.121758\n",
      "[2030]\ttraining's binary_logloss: 0.121741\n",
      "[2031]\ttraining's binary_logloss: 0.12172\n",
      "[2032]\ttraining's binary_logloss: 0.121705\n",
      "[2033]\ttraining's binary_logloss: 0.121687\n",
      "[2034]\ttraining's binary_logloss: 0.121673\n",
      "[2035]\ttraining's binary_logloss: 0.121653\n",
      "[2036]\ttraining's binary_logloss: 0.121638\n",
      "[2037]\ttraining's binary_logloss: 0.121622\n",
      "[2038]\ttraining's binary_logloss: 0.121596\n",
      "[2039]\ttraining's binary_logloss: 0.121578\n",
      "[2040]\ttraining's binary_logloss: 0.121562\n",
      "[2041]\ttraining's binary_logloss: 0.121548\n",
      "[2042]\ttraining's binary_logloss: 0.121531\n",
      "[2043]\ttraining's binary_logloss: 0.121515\n",
      "[2044]\ttraining's binary_logloss: 0.121505\n",
      "[2045]\ttraining's binary_logloss: 0.121482\n",
      "[2046]\ttraining's binary_logloss: 0.121466\n",
      "[2047]\ttraining's binary_logloss: 0.121451\n",
      "[2048]\ttraining's binary_logloss: 0.121434\n",
      "[2049]\ttraining's binary_logloss: 0.121417\n",
      "[2050]\ttraining's binary_logloss: 0.1214\n",
      "[2051]\ttraining's binary_logloss: 0.121384\n",
      "[2052]\ttraining's binary_logloss: 0.121368\n",
      "[2053]\ttraining's binary_logloss: 0.121352\n",
      "[2054]\ttraining's binary_logloss: 0.121338\n",
      "[2055]\ttraining's binary_logloss: 0.121323\n",
      "[2056]\ttraining's binary_logloss: 0.121308\n",
      "[2057]\ttraining's binary_logloss: 0.121296\n",
      "[2058]\ttraining's binary_logloss: 0.121288\n",
      "[2059]\ttraining's binary_logloss: 0.12127\n",
      "[2060]\ttraining's binary_logloss: 0.121255\n",
      "[2061]\ttraining's binary_logloss: 0.121239\n",
      "[2062]\ttraining's binary_logloss: 0.12123\n",
      "[2063]\ttraining's binary_logloss: 0.121205\n",
      "[2064]\ttraining's binary_logloss: 0.121188\n",
      "[2065]\ttraining's binary_logloss: 0.121173\n",
      "[2066]\ttraining's binary_logloss: 0.121157\n",
      "[2067]\ttraining's binary_logloss: 0.121136\n",
      "[2068]\ttraining's binary_logloss: 0.121108\n",
      "[2069]\ttraining's binary_logloss: 0.121094\n",
      "[2070]\ttraining's binary_logloss: 0.121076\n",
      "[2071]\ttraining's binary_logloss: 0.12106\n",
      "[2072]\ttraining's binary_logloss: 0.121041\n",
      "[2073]\ttraining's binary_logloss: 0.121022\n",
      "[2074]\ttraining's binary_logloss: 0.121006\n",
      "[2075]\ttraining's binary_logloss: 0.120989\n",
      "[2076]\ttraining's binary_logloss: 0.120973\n",
      "[2077]\ttraining's binary_logloss: 0.120958\n",
      "[2078]\ttraining's binary_logloss: 0.120944\n",
      "[2079]\ttraining's binary_logloss: 0.120927\n",
      "[2080]\ttraining's binary_logloss: 0.120911\n",
      "[2081]\ttraining's binary_logloss: 0.120897\n",
      "[2082]\ttraining's binary_logloss: 0.120882\n",
      "[2083]\ttraining's binary_logloss: 0.120867\n",
      "[2084]\ttraining's binary_logloss: 0.120847\n",
      "[2085]\ttraining's binary_logloss: 0.120831\n",
      "[2086]\ttraining's binary_logloss: 0.120817\n",
      "[2087]\ttraining's binary_logloss: 0.1208\n",
      "[2088]\ttraining's binary_logloss: 0.120776\n",
      "[2089]\ttraining's binary_logloss: 0.120763\n",
      "[2090]\ttraining's binary_logloss: 0.120745\n",
      "[2091]\ttraining's binary_logloss: 0.120731\n",
      "[2092]\ttraining's binary_logloss: 0.120716\n",
      "[2093]\ttraining's binary_logloss: 0.120699\n",
      "[2094]\ttraining's binary_logloss: 0.120682\n",
      "[2095]\ttraining's binary_logloss: 0.12067\n",
      "[2096]\ttraining's binary_logloss: 0.120648\n",
      "[2097]\ttraining's binary_logloss: 0.120637\n",
      "[2098]\ttraining's binary_logloss: 0.120622\n",
      "[2099]\ttraining's binary_logloss: 0.12061\n",
      "[2100]\ttraining's binary_logloss: 0.12057\n",
      "[2101]\ttraining's binary_logloss: 0.120551\n",
      "[2102]\ttraining's binary_logloss: 0.120536\n",
      "[2103]\ttraining's binary_logloss: 0.120514\n",
      "[2104]\ttraining's binary_logloss: 0.120497\n",
      "[2105]\ttraining's binary_logloss: 0.120481\n",
      "[2106]\ttraining's binary_logloss: 0.120466\n",
      "[2107]\ttraining's binary_logloss: 0.120455\n",
      "[2108]\ttraining's binary_logloss: 0.120439\n",
      "[2109]\ttraining's binary_logloss: 0.120421\n",
      "[2110]\ttraining's binary_logloss: 0.120407\n",
      "[2111]\ttraining's binary_logloss: 0.120401\n",
      "[2112]\ttraining's binary_logloss: 0.120383\n",
      "[2113]\ttraining's binary_logloss: 0.120365\n",
      "[2114]\ttraining's binary_logloss: 0.12035\n",
      "[2115]\ttraining's binary_logloss: 0.120334\n",
      "[2116]\ttraining's binary_logloss: 0.120317\n",
      "[2117]\ttraining's binary_logloss: 0.1203\n",
      "[2118]\ttraining's binary_logloss: 0.120286\n",
      "[2119]\ttraining's binary_logloss: 0.120269\n",
      "[2120]\ttraining's binary_logloss: 0.120254\n",
      "[2121]\ttraining's binary_logloss: 0.120238\n",
      "[2122]\ttraining's binary_logloss: 0.120215\n",
      "[2123]\ttraining's binary_logloss: 0.1202\n",
      "[2124]\ttraining's binary_logloss: 0.120185\n",
      "[2125]\ttraining's binary_logloss: 0.120171\n",
      "[2126]\ttraining's binary_logloss: 0.120155\n",
      "[2127]\ttraining's binary_logloss: 0.12014\n",
      "[2128]\ttraining's binary_logloss: 0.120117\n",
      "[2129]\ttraining's binary_logloss: 0.120102\n",
      "[2130]\ttraining's binary_logloss: 0.120087\n",
      "[2131]\ttraining's binary_logloss: 0.120071\n",
      "[2132]\ttraining's binary_logloss: 0.120057\n",
      "[2133]\ttraining's binary_logloss: 0.120042\n",
      "[2134]\ttraining's binary_logloss: 0.120025\n",
      "[2135]\ttraining's binary_logloss: 0.12001\n",
      "[2136]\ttraining's binary_logloss: 0.119995\n",
      "[2137]\ttraining's binary_logloss: 0.119975\n",
      "[2138]\ttraining's binary_logloss: 0.11996\n",
      "[2139]\ttraining's binary_logloss: 0.119947\n",
      "[2140]\ttraining's binary_logloss: 0.119932\n",
      "[2141]\ttraining's binary_logloss: 0.119917\n",
      "[2142]\ttraining's binary_logloss: 0.119902\n",
      "[2143]\ttraining's binary_logloss: 0.119893\n",
      "[2144]\ttraining's binary_logloss: 0.119879\n",
      "[2145]\ttraining's binary_logloss: 0.119861\n",
      "[2146]\ttraining's binary_logloss: 0.119845\n",
      "[2147]\ttraining's binary_logloss: 0.119821\n",
      "[2148]\ttraining's binary_logloss: 0.119806\n",
      "[2149]\ttraining's binary_logloss: 0.119791\n",
      "[2150]\ttraining's binary_logloss: 0.119774\n",
      "[2151]\ttraining's binary_logloss: 0.119766\n",
      "[2152]\ttraining's binary_logloss: 0.119752\n",
      "[2153]\ttraining's binary_logloss: 0.119738\n",
      "[2154]\ttraining's binary_logloss: 0.119723\n",
      "[2155]\ttraining's binary_logloss: 0.119708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2156]\ttraining's binary_logloss: 0.119691\n",
      "[2157]\ttraining's binary_logloss: 0.119676\n",
      "[2158]\ttraining's binary_logloss: 0.119649\n",
      "[2159]\ttraining's binary_logloss: 0.119633\n",
      "[2160]\ttraining's binary_logloss: 0.119617\n",
      "[2161]\ttraining's binary_logloss: 0.119601\n",
      "[2162]\ttraining's binary_logloss: 0.119591\n",
      "[2163]\ttraining's binary_logloss: 0.119573\n",
      "[2164]\ttraining's binary_logloss: 0.119558\n",
      "[2165]\ttraining's binary_logloss: 0.119544\n",
      "[2166]\ttraining's binary_logloss: 0.119527\n",
      "[2167]\ttraining's binary_logloss: 0.119501\n",
      "[2168]\ttraining's binary_logloss: 0.119491\n",
      "[2169]\ttraining's binary_logloss: 0.119474\n",
      "[2170]\ttraining's binary_logloss: 0.119459\n",
      "[2171]\ttraining's binary_logloss: 0.119446\n",
      "[2172]\ttraining's binary_logloss: 0.119431\n",
      "[2173]\ttraining's binary_logloss: 0.119414\n",
      "[2174]\ttraining's binary_logloss: 0.119398\n",
      "[2175]\ttraining's binary_logloss: 0.119383\n",
      "[2176]\ttraining's binary_logloss: 0.119368\n",
      "[2177]\ttraining's binary_logloss: 0.119354\n",
      "[2178]\ttraining's binary_logloss: 0.119336\n",
      "[2179]\ttraining's binary_logloss: 0.119313\n",
      "[2180]\ttraining's binary_logloss: 0.119296\n",
      "[2181]\ttraining's binary_logloss: 0.119281\n",
      "[2182]\ttraining's binary_logloss: 0.119263\n",
      "[2183]\ttraining's binary_logloss: 0.119248\n",
      "[2184]\ttraining's binary_logloss: 0.119232\n",
      "[2185]\ttraining's binary_logloss: 0.119212\n",
      "[2186]\ttraining's binary_logloss: 0.119196\n",
      "[2187]\ttraining's binary_logloss: 0.119182\n",
      "[2188]\ttraining's binary_logloss: 0.119167\n",
      "[2189]\ttraining's binary_logloss: 0.11915\n",
      "[2190]\ttraining's binary_logloss: 0.119134\n",
      "[2191]\ttraining's binary_logloss: 0.119118\n",
      "[2192]\ttraining's binary_logloss: 0.119106\n",
      "[2193]\ttraining's binary_logloss: 0.119089\n",
      "[2194]\ttraining's binary_logloss: 0.119075\n",
      "[2195]\ttraining's binary_logloss: 0.119057\n",
      "[2196]\ttraining's binary_logloss: 0.119041\n",
      "[2197]\ttraining's binary_logloss: 0.119028\n",
      "[2198]\ttraining's binary_logloss: 0.119013\n",
      "[2199]\ttraining's binary_logloss: 0.118996\n",
      "[2200]\ttraining's binary_logloss: 0.11898\n",
      "[2201]\ttraining's binary_logloss: 0.118961\n",
      "[2202]\ttraining's binary_logloss: 0.118947\n",
      "[2203]\ttraining's binary_logloss: 0.11893\n",
      "[2204]\ttraining's binary_logloss: 0.118908\n",
      "[2205]\ttraining's binary_logloss: 0.118893\n",
      "[2206]\ttraining's binary_logloss: 0.118878\n",
      "[2207]\ttraining's binary_logloss: 0.118862\n",
      "[2208]\ttraining's binary_logloss: 0.118845\n",
      "[2209]\ttraining's binary_logloss: 0.118826\n",
      "[2210]\ttraining's binary_logloss: 0.118814\n",
      "[2211]\ttraining's binary_logloss: 0.118795\n",
      "[2212]\ttraining's binary_logloss: 0.118779\n",
      "[2213]\ttraining's binary_logloss: 0.118763\n",
      "[2214]\ttraining's binary_logloss: 0.118747\n",
      "[2215]\ttraining's binary_logloss: 0.118729\n",
      "[2216]\ttraining's binary_logloss: 0.118723\n",
      "[2217]\ttraining's binary_logloss: 0.118707\n",
      "[2218]\ttraining's binary_logloss: 0.118691\n",
      "[2219]\ttraining's binary_logloss: 0.118676\n",
      "[2220]\ttraining's binary_logloss: 0.118661\n",
      "[2221]\ttraining's binary_logloss: 0.118644\n",
      "[2222]\ttraining's binary_logloss: 0.118629\n",
      "[2223]\ttraining's binary_logloss: 0.118613\n",
      "[2224]\ttraining's binary_logloss: 0.118596\n",
      "[2225]\ttraining's binary_logloss: 0.11858\n",
      "[2226]\ttraining's binary_logloss: 0.118566\n",
      "[2227]\ttraining's binary_logloss: 0.118528\n",
      "[2228]\ttraining's binary_logloss: 0.118511\n",
      "[2229]\ttraining's binary_logloss: 0.118496\n",
      "[2230]\ttraining's binary_logloss: 0.118479\n",
      "[2231]\ttraining's binary_logloss: 0.118464\n",
      "[2232]\ttraining's binary_logloss: 0.11845\n",
      "[2233]\ttraining's binary_logloss: 0.118434\n",
      "[2234]\ttraining's binary_logloss: 0.11842\n",
      "[2235]\ttraining's binary_logloss: 0.118407\n",
      "[2236]\ttraining's binary_logloss: 0.118392\n",
      "[2237]\ttraining's binary_logloss: 0.118375\n",
      "[2238]\ttraining's binary_logloss: 0.118359\n",
      "[2239]\ttraining's binary_logloss: 0.118321\n",
      "[2240]\ttraining's binary_logloss: 0.118306\n",
      "[2241]\ttraining's binary_logloss: 0.118298\n",
      "[2242]\ttraining's binary_logloss: 0.118284\n",
      "[2243]\ttraining's binary_logloss: 0.118268\n",
      "[2244]\ttraining's binary_logloss: 0.118254\n",
      "[2245]\ttraining's binary_logloss: 0.118237\n",
      "[2246]\ttraining's binary_logloss: 0.118222\n",
      "[2247]\ttraining's binary_logloss: 0.118208\n",
      "[2248]\ttraining's binary_logloss: 0.118191\n",
      "[2249]\ttraining's binary_logloss: 0.118174\n",
      "[2250]\ttraining's binary_logloss: 0.118158\n",
      "[2251]\ttraining's binary_logloss: 0.118138\n",
      "[2252]\ttraining's binary_logloss: 0.118131\n",
      "[2253]\ttraining's binary_logloss: 0.118115\n",
      "[2254]\ttraining's binary_logloss: 0.1181\n",
      "[2255]\ttraining's binary_logloss: 0.118084\n",
      "[2256]\ttraining's binary_logloss: 0.118068\n",
      "[2257]\ttraining's binary_logloss: 0.118051\n",
      "[2258]\ttraining's binary_logloss: 0.118037\n",
      "[2259]\ttraining's binary_logloss: 0.118023\n",
      "[2260]\ttraining's binary_logloss: 0.118007\n",
      "[2261]\ttraining's binary_logloss: 0.117992\n",
      "[2262]\ttraining's binary_logloss: 0.117979\n",
      "[2263]\ttraining's binary_logloss: 0.117963\n",
      "[2264]\ttraining's binary_logloss: 0.117943\n",
      "[2265]\ttraining's binary_logloss: 0.117936\n",
      "[2266]\ttraining's binary_logloss: 0.117922\n",
      "[2267]\ttraining's binary_logloss: 0.117908\n",
      "[2268]\ttraining's binary_logloss: 0.117893\n",
      "[2269]\ttraining's binary_logloss: 0.117877\n",
      "[2270]\ttraining's binary_logloss: 0.11787\n",
      "[2271]\ttraining's binary_logloss: 0.117855\n",
      "[2272]\ttraining's binary_logloss: 0.11784\n",
      "[2273]\ttraining's binary_logloss: 0.117825\n",
      "[2274]\ttraining's binary_logloss: 0.117809\n",
      "[2275]\ttraining's binary_logloss: 0.117794\n",
      "[2276]\ttraining's binary_logloss: 0.117779\n",
      "[2277]\ttraining's binary_logloss: 0.117764\n",
      "[2278]\ttraining's binary_logloss: 0.11775\n",
      "[2279]\ttraining's binary_logloss: 0.117734\n",
      "[2280]\ttraining's binary_logloss: 0.117719\n",
      "[2281]\ttraining's binary_logloss: 0.117706\n",
      "[2282]\ttraining's binary_logloss: 0.117687\n",
      "[2283]\ttraining's binary_logloss: 0.117672\n",
      "[2284]\ttraining's binary_logloss: 0.117656\n",
      "[2285]\ttraining's binary_logloss: 0.117639\n",
      "[2286]\ttraining's binary_logloss: 0.11762\n",
      "[2287]\ttraining's binary_logloss: 0.117605\n",
      "[2288]\ttraining's binary_logloss: 0.117588\n",
      "[2289]\ttraining's binary_logloss: 0.117582\n",
      "[2290]\ttraining's binary_logloss: 0.117566\n",
      "[2291]\ttraining's binary_logloss: 0.117551\n",
      "[2292]\ttraining's binary_logloss: 0.117528\n",
      "[2293]\ttraining's binary_logloss: 0.117515\n",
      "[2294]\ttraining's binary_logloss: 0.117502\n",
      "[2295]\ttraining's binary_logloss: 0.117488\n",
      "[2296]\ttraining's binary_logloss: 0.117473\n",
      "[2297]\ttraining's binary_logloss: 0.117458\n",
      "[2298]\ttraining's binary_logloss: 0.117443\n",
      "[2299]\ttraining's binary_logloss: 0.117428\n",
      "[2300]\ttraining's binary_logloss: 0.117392\n",
      "[2301]\ttraining's binary_logloss: 0.117377\n",
      "[2302]\ttraining's binary_logloss: 0.117363\n",
      "[2303]\ttraining's binary_logloss: 0.117358\n",
      "[2304]\ttraining's binary_logloss: 0.117342\n",
      "[2305]\ttraining's binary_logloss: 0.117323\n",
      "[2306]\ttraining's binary_logloss: 0.117309\n",
      "[2307]\ttraining's binary_logloss: 0.117294\n",
      "[2308]\ttraining's binary_logloss: 0.117279\n",
      "[2309]\ttraining's binary_logloss: 0.117265\n",
      "[2310]\ttraining's binary_logloss: 0.11725\n",
      "[2311]\ttraining's binary_logloss: 0.117236\n",
      "[2312]\ttraining's binary_logloss: 0.117233\n",
      "[2313]\ttraining's binary_logloss: 0.117219\n",
      "[2314]\ttraining's binary_logloss: 0.117198\n",
      "[2315]\ttraining's binary_logloss: 0.117181\n",
      "[2316]\ttraining's binary_logloss: 0.117168\n",
      "[2317]\ttraining's binary_logloss: 0.117153\n",
      "[2318]\ttraining's binary_logloss: 0.117138\n",
      "[2319]\ttraining's binary_logloss: 0.11711\n",
      "[2320]\ttraining's binary_logloss: 0.117095\n",
      "[2321]\ttraining's binary_logloss: 0.11708\n",
      "[2322]\ttraining's binary_logloss: 0.117065\n",
      "[2323]\ttraining's binary_logloss: 0.117055\n",
      "[2324]\ttraining's binary_logloss: 0.117037\n",
      "[2325]\ttraining's binary_logloss: 0.117023\n",
      "[2326]\ttraining's binary_logloss: 0.11701\n",
      "[2327]\ttraining's binary_logloss: 0.116996\n",
      "[2328]\ttraining's binary_logloss: 0.116969\n",
      "[2329]\ttraining's binary_logloss: 0.116955\n",
      "[2330]\ttraining's binary_logloss: 0.116938\n",
      "[2331]\ttraining's binary_logloss: 0.116924\n",
      "[2332]\ttraining's binary_logloss: 0.116909\n",
      "[2333]\ttraining's binary_logloss: 0.116893\n",
      "[2334]\ttraining's binary_logloss: 0.116877\n",
      "[2335]\ttraining's binary_logloss: 0.116862\n",
      "[2336]\ttraining's binary_logloss: 0.116849\n",
      "[2337]\ttraining's binary_logloss: 0.116834\n",
      "[2338]\ttraining's binary_logloss: 0.116818\n",
      "[2339]\ttraining's binary_logloss: 0.116804\n",
      "[2340]\ttraining's binary_logloss: 0.116789\n",
      "[2341]\ttraining's binary_logloss: 0.116771\n",
      "[2342]\ttraining's binary_logloss: 0.116757\n",
      "[2343]\ttraining's binary_logloss: 0.11674\n",
      "[2344]\ttraining's binary_logloss: 0.116727\n",
      "[2345]\ttraining's binary_logloss: 0.11671\n",
      "[2346]\ttraining's binary_logloss: 0.116695\n",
      "[2347]\ttraining's binary_logloss: 0.116677\n",
      "[2348]\ttraining's binary_logloss: 0.116663\n",
      "[2349]\ttraining's binary_logloss: 0.116652\n",
      "[2350]\ttraining's binary_logloss: 0.116638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2351]\ttraining's binary_logloss: 0.116623\n",
      "[2352]\ttraining's binary_logloss: 0.11661\n",
      "[2353]\ttraining's binary_logloss: 0.116598\n",
      "[2354]\ttraining's binary_logloss: 0.116583\n",
      "[2355]\ttraining's binary_logloss: 0.116569\n",
      "[2356]\ttraining's binary_logloss: 0.116555\n",
      "[2357]\ttraining's binary_logloss: 0.11654\n",
      "[2358]\ttraining's binary_logloss: 0.116525\n",
      "[2359]\ttraining's binary_logloss: 0.11651\n",
      "[2360]\ttraining's binary_logloss: 0.116492\n",
      "[2361]\ttraining's binary_logloss: 0.116476\n",
      "[2362]\ttraining's binary_logloss: 0.11646\n",
      "[2363]\ttraining's binary_logloss: 0.116449\n",
      "[2364]\ttraining's binary_logloss: 0.116447\n",
      "[2365]\ttraining's binary_logloss: 0.116426\n",
      "[2366]\ttraining's binary_logloss: 0.116412\n",
      "[2367]\ttraining's binary_logloss: 0.116397\n",
      "[2368]\ttraining's binary_logloss: 0.116383\n",
      "[2369]\ttraining's binary_logloss: 0.116368\n",
      "[2370]\ttraining's binary_logloss: 0.116354\n",
      "[2371]\ttraining's binary_logloss: 0.116329\n",
      "[2372]\ttraining's binary_logloss: 0.116315\n",
      "[2373]\ttraining's binary_logloss: 0.1163\n",
      "[2374]\ttraining's binary_logloss: 0.116284\n",
      "[2375]\ttraining's binary_logloss: 0.116279\n",
      "[2376]\ttraining's binary_logloss: 0.116263\n",
      "[2377]\ttraining's binary_logloss: 0.11625\n",
      "[2378]\ttraining's binary_logloss: 0.116235\n",
      "[2379]\ttraining's binary_logloss: 0.116221\n",
      "[2380]\ttraining's binary_logloss: 0.116206\n",
      "[2381]\ttraining's binary_logloss: 0.11619\n",
      "[2382]\ttraining's binary_logloss: 0.116175\n",
      "[2383]\ttraining's binary_logloss: 0.116157\n",
      "[2384]\ttraining's binary_logloss: 0.116137\n",
      "[2385]\ttraining's binary_logloss: 0.116121\n",
      "[2386]\ttraining's binary_logloss: 0.1161\n",
      "[2387]\ttraining's binary_logloss: 0.116085\n",
      "[2388]\ttraining's binary_logloss: 0.11607\n",
      "[2389]\ttraining's binary_logloss: 0.116054\n",
      "[2390]\ttraining's binary_logloss: 0.116039\n",
      "[2391]\ttraining's binary_logloss: 0.116026\n",
      "[2392]\ttraining's binary_logloss: 0.116012\n",
      "[2393]\ttraining's binary_logloss: 0.115999\n",
      "[2394]\ttraining's binary_logloss: 0.115986\n",
      "[2395]\ttraining's binary_logloss: 0.115969\n",
      "[2396]\ttraining's binary_logloss: 0.115956\n",
      "[2397]\ttraining's binary_logloss: 0.11594\n",
      "[2398]\ttraining's binary_logloss: 0.115927\n",
      "[2399]\ttraining's binary_logloss: 0.115909\n",
      "[2400]\ttraining's binary_logloss: 0.115896\n",
      "[2401]\ttraining's binary_logloss: 0.115883\n",
      "[2402]\ttraining's binary_logloss: 0.115867\n",
      "[2403]\ttraining's binary_logloss: 0.115851\n",
      "[2404]\ttraining's binary_logloss: 0.115838\n",
      "[2405]\ttraining's binary_logloss: 0.115821\n",
      "[2406]\ttraining's binary_logloss: 0.115806\n",
      "[2407]\ttraining's binary_logloss: 0.115788\n",
      "[2408]\ttraining's binary_logloss: 0.115774\n",
      "[2409]\ttraining's binary_logloss: 0.115765\n",
      "[2410]\ttraining's binary_logloss: 0.115751\n",
      "[2411]\ttraining's binary_logloss: 0.115736\n",
      "[2412]\ttraining's binary_logloss: 0.115721\n",
      "[2413]\ttraining's binary_logloss: 0.115703\n",
      "[2414]\ttraining's binary_logloss: 0.115687\n",
      "[2415]\ttraining's binary_logloss: 0.115674\n",
      "[2416]\ttraining's binary_logloss: 0.115659\n",
      "[2417]\ttraining's binary_logloss: 0.115647\n",
      "[2418]\ttraining's binary_logloss: 0.115628\n",
      "[2419]\ttraining's binary_logloss: 0.115609\n",
      "[2420]\ttraining's binary_logloss: 0.115589\n",
      "[2421]\ttraining's binary_logloss: 0.115575\n",
      "[2422]\ttraining's binary_logloss: 0.115559\n",
      "[2423]\ttraining's binary_logloss: 0.115547\n",
      "[2424]\ttraining's binary_logloss: 0.115535\n",
      "[2425]\ttraining's binary_logloss: 0.11552\n",
      "[2426]\ttraining's binary_logloss: 0.115508\n",
      "[2427]\ttraining's binary_logloss: 0.115491\n",
      "[2428]\ttraining's binary_logloss: 0.11548\n",
      "[2429]\ttraining's binary_logloss: 0.115466\n",
      "[2430]\ttraining's binary_logloss: 0.115452\n",
      "[2431]\ttraining's binary_logloss: 0.115436\n",
      "[2432]\ttraining's binary_logloss: 0.115406\n",
      "[2433]\ttraining's binary_logloss: 0.115392\n",
      "[2434]\ttraining's binary_logloss: 0.115369\n",
      "[2435]\ttraining's binary_logloss: 0.115355\n",
      "[2436]\ttraining's binary_logloss: 0.115337\n",
      "[2437]\ttraining's binary_logloss: 0.115322\n",
      "[2438]\ttraining's binary_logloss: 0.11531\n",
      "[2439]\ttraining's binary_logloss: 0.115299\n",
      "[2440]\ttraining's binary_logloss: 0.115284\n",
      "[2441]\ttraining's binary_logloss: 0.115271\n",
      "[2442]\ttraining's binary_logloss: 0.115257\n",
      "[2443]\ttraining's binary_logloss: 0.115244\n",
      "[2444]\ttraining's binary_logloss: 0.115229\n",
      "[2445]\ttraining's binary_logloss: 0.115215\n",
      "[2446]\ttraining's binary_logloss: 0.115207\n",
      "[2447]\ttraining's binary_logloss: 0.115193\n",
      "[2448]\ttraining's binary_logloss: 0.115178\n",
      "[2449]\ttraining's binary_logloss: 0.115163\n",
      "[2450]\ttraining's binary_logloss: 0.115148\n",
      "[2451]\ttraining's binary_logloss: 0.115131\n",
      "[2452]\ttraining's binary_logloss: 0.115116\n",
      "[2453]\ttraining's binary_logloss: 0.115102\n",
      "[2454]\ttraining's binary_logloss: 0.115088\n",
      "[2455]\ttraining's binary_logloss: 0.115075\n",
      "[2456]\ttraining's binary_logloss: 0.11506\n",
      "[2457]\ttraining's binary_logloss: 0.115045\n",
      "[2458]\ttraining's binary_logloss: 0.115031\n",
      "[2459]\ttraining's binary_logloss: 0.115015\n",
      "[2460]\ttraining's binary_logloss: 0.115001\n",
      "[2461]\ttraining's binary_logloss: 0.114986\n",
      "[2462]\ttraining's binary_logloss: 0.114972\n",
      "[2463]\ttraining's binary_logloss: 0.114958\n",
      "[2464]\ttraining's binary_logloss: 0.11494\n",
      "[2465]\ttraining's binary_logloss: 0.114925\n",
      "[2466]\ttraining's binary_logloss: 0.114909\n",
      "[2467]\ttraining's binary_logloss: 0.114894\n",
      "[2468]\ttraining's binary_logloss: 0.11486\n",
      "[2469]\ttraining's binary_logloss: 0.114848\n",
      "[2470]\ttraining's binary_logloss: 0.114834\n",
      "[2471]\ttraining's binary_logloss: 0.114821\n",
      "[2472]\ttraining's binary_logloss: 0.114806\n",
      "[2473]\ttraining's binary_logloss: 0.11479\n",
      "[2474]\ttraining's binary_logloss: 0.114776\n",
      "[2475]\ttraining's binary_logloss: 0.11476\n",
      "[2476]\ttraining's binary_logloss: 0.114745\n",
      "[2477]\ttraining's binary_logloss: 0.114731\n",
      "[2478]\ttraining's binary_logloss: 0.114718\n",
      "[2479]\ttraining's binary_logloss: 0.114704\n",
      "[2480]\ttraining's binary_logloss: 0.114691\n",
      "[2481]\ttraining's binary_logloss: 0.114674\n",
      "[2482]\ttraining's binary_logloss: 0.11466\n",
      "[2483]\ttraining's binary_logloss: 0.114643\n",
      "[2484]\ttraining's binary_logloss: 0.11463\n",
      "[2485]\ttraining's binary_logloss: 0.114616\n",
      "[2486]\ttraining's binary_logloss: 0.114601\n",
      "[2487]\ttraining's binary_logloss: 0.114588\n",
      "[2488]\ttraining's binary_logloss: 0.11457\n",
      "[2489]\ttraining's binary_logloss: 0.114558\n",
      "[2490]\ttraining's binary_logloss: 0.114546\n",
      "[2491]\ttraining's binary_logloss: 0.114529\n",
      "[2492]\ttraining's binary_logloss: 0.114507\n",
      "[2493]\ttraining's binary_logloss: 0.114491\n",
      "[2494]\ttraining's binary_logloss: 0.114476\n",
      "[2495]\ttraining's binary_logloss: 0.114463\n",
      "[2496]\ttraining's binary_logloss: 0.114448\n",
      "[2497]\ttraining's binary_logloss: 0.114431\n",
      "[2498]\ttraining's binary_logloss: 0.114416\n",
      "[2499]\ttraining's binary_logloss: 0.114413\n",
      "[2500]\ttraining's binary_logloss: 0.114399\n",
      "[2501]\ttraining's binary_logloss: 0.114385\n",
      "[2502]\ttraining's binary_logloss: 0.114368\n",
      "[2503]\ttraining's binary_logloss: 0.114354\n",
      "[2504]\ttraining's binary_logloss: 0.114337\n",
      "[2505]\ttraining's binary_logloss: 0.114323\n",
      "[2506]\ttraining's binary_logloss: 0.11431\n",
      "[2507]\ttraining's binary_logloss: 0.114296\n",
      "[2508]\ttraining's binary_logloss: 0.11428\n",
      "[2509]\ttraining's binary_logloss: 0.114267\n",
      "[2510]\ttraining's binary_logloss: 0.114246\n",
      "[2511]\ttraining's binary_logloss: 0.114231\n",
      "[2512]\ttraining's binary_logloss: 0.114218\n",
      "[2513]\ttraining's binary_logloss: 0.114202\n",
      "[2514]\ttraining's binary_logloss: 0.114188\n",
      "[2515]\ttraining's binary_logloss: 0.114172\n",
      "[2516]\ttraining's binary_logloss: 0.114152\n",
      "[2517]\ttraining's binary_logloss: 0.114139\n",
      "[2518]\ttraining's binary_logloss: 0.114126\n",
      "[2519]\ttraining's binary_logloss: 0.114109\n",
      "[2520]\ttraining's binary_logloss: 0.11409\n",
      "[2521]\ttraining's binary_logloss: 0.114074\n",
      "[2522]\ttraining's binary_logloss: 0.114061\n",
      "[2523]\ttraining's binary_logloss: 0.114046\n",
      "[2524]\ttraining's binary_logloss: 0.114033\n",
      "[2525]\ttraining's binary_logloss: 0.11403\n",
      "[2526]\ttraining's binary_logloss: 0.114013\n",
      "[2527]\ttraining's binary_logloss: 0.114\n",
      "[2528]\ttraining's binary_logloss: 0.113987\n",
      "[2529]\ttraining's binary_logloss: 0.113973\n",
      "[2530]\ttraining's binary_logloss: 0.113958\n",
      "[2531]\ttraining's binary_logloss: 0.113934\n",
      "[2532]\ttraining's binary_logloss: 0.113921\n",
      "[2533]\ttraining's binary_logloss: 0.113907\n",
      "[2534]\ttraining's binary_logloss: 0.113891\n",
      "[2535]\ttraining's binary_logloss: 0.113879\n",
      "[2536]\ttraining's binary_logloss: 0.113862\n",
      "[2537]\ttraining's binary_logloss: 0.113848\n",
      "[2538]\ttraining's binary_logloss: 0.113835\n",
      "[2539]\ttraining's binary_logloss: 0.113821\n",
      "[2540]\ttraining's binary_logloss: 0.113809\n",
      "[2541]\ttraining's binary_logloss: 0.113796\n",
      "[2542]\ttraining's binary_logloss: 0.113782\n",
      "[2543]\ttraining's binary_logloss: 0.113768\n",
      "[2544]\ttraining's binary_logloss: 0.113753\n",
      "[2545]\ttraining's binary_logloss: 0.113738\n",
      "[2546]\ttraining's binary_logloss: 0.113722\n",
      "[2547]\ttraining's binary_logloss: 0.113709\n",
      "[2548]\ttraining's binary_logloss: 0.113696\n",
      "[2549]\ttraining's binary_logloss: 0.113685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2550]\ttraining's binary_logloss: 0.113672\n",
      "[2551]\ttraining's binary_logloss: 0.113658\n",
      "[2552]\ttraining's binary_logloss: 0.113642\n",
      "[2553]\ttraining's binary_logloss: 0.113627\n",
      "[2554]\ttraining's binary_logloss: 0.113613\n",
      "[2555]\ttraining's binary_logloss: 0.113598\n",
      "[2556]\ttraining's binary_logloss: 0.113584\n",
      "[2557]\ttraining's binary_logloss: 0.113576\n",
      "[2558]\ttraining's binary_logloss: 0.113562\n",
      "[2559]\ttraining's binary_logloss: 0.113546\n",
      "[2560]\ttraining's binary_logloss: 0.11353\n",
      "[2561]\ttraining's binary_logloss: 0.113517\n",
      "[2562]\ttraining's binary_logloss: 0.113505\n",
      "[2563]\ttraining's binary_logloss: 0.11349\n",
      "[2564]\ttraining's binary_logloss: 0.113475\n",
      "[2565]\ttraining's binary_logloss: 0.113462\n",
      "[2566]\ttraining's binary_logloss: 0.113448\n",
      "[2567]\ttraining's binary_logloss: 0.113433\n",
      "[2568]\ttraining's binary_logloss: 0.113426\n",
      "[2569]\ttraining's binary_logloss: 0.113413\n",
      "[2570]\ttraining's binary_logloss: 0.113399\n",
      "[2571]\ttraining's binary_logloss: 0.113383\n",
      "[2572]\ttraining's binary_logloss: 0.11337\n",
      "[2573]\ttraining's binary_logloss: 0.113352\n",
      "[2574]\ttraining's binary_logloss: 0.11334\n",
      "[2575]\ttraining's binary_logloss: 0.113323\n",
      "[2576]\ttraining's binary_logloss: 0.11331\n",
      "[2577]\ttraining's binary_logloss: 0.113296\n",
      "[2578]\ttraining's binary_logloss: 0.11328\n",
      "[2579]\ttraining's binary_logloss: 0.113267\n",
      "[2580]\ttraining's binary_logloss: 0.113251\n",
      "[2581]\ttraining's binary_logloss: 0.113237\n",
      "[2582]\ttraining's binary_logloss: 0.113223\n",
      "[2583]\ttraining's binary_logloss: 0.113208\n",
      "[2584]\ttraining's binary_logloss: 0.113192\n",
      "[2585]\ttraining's binary_logloss: 0.113177\n",
      "[2586]\ttraining's binary_logloss: 0.113162\n",
      "[2587]\ttraining's binary_logloss: 0.113146\n",
      "[2588]\ttraining's binary_logloss: 0.11313\n",
      "[2589]\ttraining's binary_logloss: 0.113116\n",
      "[2590]\ttraining's binary_logloss: 0.113102\n",
      "[2591]\ttraining's binary_logloss: 0.113081\n",
      "[2592]\ttraining's binary_logloss: 0.113067\n",
      "[2593]\ttraining's binary_logloss: 0.113056\n",
      "[2594]\ttraining's binary_logloss: 0.113041\n",
      "[2595]\ttraining's binary_logloss: 0.113027\n",
      "[2596]\ttraining's binary_logloss: 0.113019\n",
      "[2597]\ttraining's binary_logloss: 0.113006\n",
      "[2598]\ttraining's binary_logloss: 0.112991\n",
      "[2599]\ttraining's binary_logloss: 0.112977\n",
      "[2600]\ttraining's binary_logloss: 0.112961\n",
      "[2601]\ttraining's binary_logloss: 0.112948\n",
      "[2602]\ttraining's binary_logloss: 0.112934\n",
      "[2603]\ttraining's binary_logloss: 0.112921\n",
      "[2604]\ttraining's binary_logloss: 0.112909\n",
      "[2605]\ttraining's binary_logloss: 0.112892\n",
      "[2606]\ttraining's binary_logloss: 0.112877\n",
      "[2607]\ttraining's binary_logloss: 0.112853\n",
      "[2608]\ttraining's binary_logloss: 0.112848\n",
      "[2609]\ttraining's binary_logloss: 0.112833\n",
      "[2610]\ttraining's binary_logloss: 0.11282\n",
      "[2611]\ttraining's binary_logloss: 0.112808\n",
      "[2612]\ttraining's binary_logloss: 0.112794\n",
      "[2613]\ttraining's binary_logloss: 0.112781\n",
      "[2614]\ttraining's binary_logloss: 0.112767\n",
      "[2615]\ttraining's binary_logloss: 0.112754\n",
      "[2616]\ttraining's binary_logloss: 0.112741\n",
      "[2617]\ttraining's binary_logloss: 0.112725\n",
      "[2618]\ttraining's binary_logloss: 0.112712\n",
      "[2619]\ttraining's binary_logloss: 0.112706\n",
      "[2620]\ttraining's binary_logloss: 0.11269\n",
      "[2621]\ttraining's binary_logloss: 0.112675\n",
      "[2622]\ttraining's binary_logloss: 0.11266\n",
      "[2623]\ttraining's binary_logloss: 0.112647\n",
      "[2624]\ttraining's binary_logloss: 0.112634\n",
      "[2625]\ttraining's binary_logloss: 0.112626\n",
      "[2626]\ttraining's binary_logloss: 0.112611\n",
      "[2627]\ttraining's binary_logloss: 0.112599\n",
      "[2628]\ttraining's binary_logloss: 0.112586\n",
      "[2629]\ttraining's binary_logloss: 0.112574\n",
      "[2630]\ttraining's binary_logloss: 0.11256\n",
      "[2631]\ttraining's binary_logloss: 0.112546\n",
      "[2632]\ttraining's binary_logloss: 0.112532\n",
      "[2633]\ttraining's binary_logloss: 0.112506\n",
      "[2634]\ttraining's binary_logloss: 0.112493\n",
      "[2635]\ttraining's binary_logloss: 0.11248\n",
      "[2636]\ttraining's binary_logloss: 0.112466\n",
      "[2637]\ttraining's binary_logloss: 0.112451\n",
      "[2638]\ttraining's binary_logloss: 0.112437\n",
      "[2639]\ttraining's binary_logloss: 0.112423\n",
      "[2640]\ttraining's binary_logloss: 0.112412\n",
      "[2641]\ttraining's binary_logloss: 0.112397\n",
      "[2642]\ttraining's binary_logloss: 0.112382\n",
      "[2643]\ttraining's binary_logloss: 0.112368\n",
      "[2644]\ttraining's binary_logloss: 0.112357\n",
      "[2645]\ttraining's binary_logloss: 0.112331\n",
      "[2646]\ttraining's binary_logloss: 0.112316\n",
      "[2647]\ttraining's binary_logloss: 0.112302\n",
      "[2648]\ttraining's binary_logloss: 0.112279\n",
      "[2649]\ttraining's binary_logloss: 0.112265\n",
      "[2650]\ttraining's binary_logloss: 0.11225\n",
      "[2651]\ttraining's binary_logloss: 0.112236\n",
      "[2652]\ttraining's binary_logloss: 0.112222\n",
      "[2653]\ttraining's binary_logloss: 0.112209\n",
      "[2654]\ttraining's binary_logloss: 0.112196\n",
      "[2655]\ttraining's binary_logloss: 0.112184\n",
      "[2656]\ttraining's binary_logloss: 0.112171\n",
      "[2657]\ttraining's binary_logloss: 0.112158\n",
      "[2658]\ttraining's binary_logloss: 0.112146\n",
      "[2659]\ttraining's binary_logloss: 0.112131\n",
      "[2660]\ttraining's binary_logloss: 0.112122\n",
      "[2661]\ttraining's binary_logloss: 0.112112\n",
      "[2662]\ttraining's binary_logloss: 0.112096\n",
      "[2663]\ttraining's binary_logloss: 0.112083\n",
      "[2664]\ttraining's binary_logloss: 0.112067\n",
      "[2665]\ttraining's binary_logloss: 0.112053\n",
      "[2666]\ttraining's binary_logloss: 0.112038\n",
      "[2667]\ttraining's binary_logloss: 0.112019\n",
      "[2668]\ttraining's binary_logloss: 0.112007\n",
      "[2669]\ttraining's binary_logloss: 0.111993\n",
      "[2670]\ttraining's binary_logloss: 0.111982\n",
      "[2671]\ttraining's binary_logloss: 0.111972\n",
      "[2672]\ttraining's binary_logloss: 0.11196\n",
      "[2673]\ttraining's binary_logloss: 0.111946\n",
      "[2674]\ttraining's binary_logloss: 0.111933\n",
      "[2675]\ttraining's binary_logloss: 0.11192\n",
      "[2676]\ttraining's binary_logloss: 0.111906\n",
      "[2677]\ttraining's binary_logloss: 0.111892\n",
      "[2678]\ttraining's binary_logloss: 0.111878\n",
      "[2679]\ttraining's binary_logloss: 0.111863\n",
      "[2680]\ttraining's binary_logloss: 0.11185\n",
      "[2681]\ttraining's binary_logloss: 0.111838\n",
      "[2682]\ttraining's binary_logloss: 0.111822\n",
      "[2683]\ttraining's binary_logloss: 0.111808\n",
      "[2684]\ttraining's binary_logloss: 0.111794\n",
      "[2685]\ttraining's binary_logloss: 0.111781\n",
      "[2686]\ttraining's binary_logloss: 0.111767\n",
      "[2687]\ttraining's binary_logloss: 0.111754\n",
      "[2688]\ttraining's binary_logloss: 0.11174\n",
      "[2689]\ttraining's binary_logloss: 0.111726\n",
      "[2690]\ttraining's binary_logloss: 0.111713\n",
      "[2691]\ttraining's binary_logloss: 0.111699\n",
      "[2692]\ttraining's binary_logloss: 0.111689\n",
      "[2693]\ttraining's binary_logloss: 0.111676\n",
      "[2694]\ttraining's binary_logloss: 0.111664\n",
      "[2695]\ttraining's binary_logloss: 0.111648\n",
      "[2696]\ttraining's binary_logloss: 0.111634\n",
      "[2697]\ttraining's binary_logloss: 0.111622\n",
      "[2698]\ttraining's binary_logloss: 0.111608\n",
      "[2699]\ttraining's binary_logloss: 0.111595\n",
      "[2700]\ttraining's binary_logloss: 0.111582\n",
      "[2701]\ttraining's binary_logloss: 0.111568\n",
      "[2702]\ttraining's binary_logloss: 0.111554\n",
      "[2703]\ttraining's binary_logloss: 0.11154\n",
      "[2704]\ttraining's binary_logloss: 0.111523\n",
      "[2705]\ttraining's binary_logloss: 0.111509\n",
      "[2706]\ttraining's binary_logloss: 0.111498\n",
      "[2707]\ttraining's binary_logloss: 0.111484\n",
      "[2708]\ttraining's binary_logloss: 0.11147\n",
      "[2709]\ttraining's binary_logloss: 0.111455\n",
      "[2710]\ttraining's binary_logloss: 0.111441\n",
      "[2711]\ttraining's binary_logloss: 0.111426\n",
      "[2712]\ttraining's binary_logloss: 0.111408\n",
      "[2713]\ttraining's binary_logloss: 0.111393\n",
      "[2714]\ttraining's binary_logloss: 0.11138\n",
      "[2715]\ttraining's binary_logloss: 0.111366\n",
      "[2716]\ttraining's binary_logloss: 0.111352\n",
      "[2717]\ttraining's binary_logloss: 0.111338\n",
      "[2718]\ttraining's binary_logloss: 0.111324\n",
      "[2719]\ttraining's binary_logloss: 0.111311\n",
      "[2720]\ttraining's binary_logloss: 0.111298\n",
      "[2721]\ttraining's binary_logloss: 0.111283\n",
      "[2722]\ttraining's binary_logloss: 0.111269\n",
      "[2723]\ttraining's binary_logloss: 0.111256\n",
      "[2724]\ttraining's binary_logloss: 0.111242\n",
      "[2725]\ttraining's binary_logloss: 0.111231\n",
      "[2726]\ttraining's binary_logloss: 0.111223\n",
      "[2727]\ttraining's binary_logloss: 0.111207\n",
      "[2728]\ttraining's binary_logloss: 0.111193\n",
      "[2729]\ttraining's binary_logloss: 0.111179\n",
      "[2730]\ttraining's binary_logloss: 0.111162\n",
      "[2731]\ttraining's binary_logloss: 0.111146\n",
      "[2732]\ttraining's binary_logloss: 0.111134\n",
      "[2733]\ttraining's binary_logloss: 0.111119\n",
      "[2734]\ttraining's binary_logloss: 0.111105\n",
      "[2735]\ttraining's binary_logloss: 0.11109\n",
      "[2736]\ttraining's binary_logloss: 0.111076\n",
      "[2737]\ttraining's binary_logloss: 0.111063\n",
      "[2738]\ttraining's binary_logloss: 0.111056\n",
      "[2739]\ttraining's binary_logloss: 0.111044\n",
      "[2740]\ttraining's binary_logloss: 0.111028\n",
      "[2741]\ttraining's binary_logloss: 0.111021\n",
      "[2742]\ttraining's binary_logloss: 0.111007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2743]\ttraining's binary_logloss: 0.110992\n",
      "[2744]\ttraining's binary_logloss: 0.110978\n",
      "[2745]\ttraining's binary_logloss: 0.110964\n",
      "[2746]\ttraining's binary_logloss: 0.110959\n",
      "[2747]\ttraining's binary_logloss: 0.110946\n",
      "[2748]\ttraining's binary_logloss: 0.110934\n",
      "[2749]\ttraining's binary_logloss: 0.110924\n",
      "[2750]\ttraining's binary_logloss: 0.11091\n",
      "[2751]\ttraining's binary_logloss: 0.110896\n",
      "[2752]\ttraining's binary_logloss: 0.11088\n",
      "[2753]\ttraining's binary_logloss: 0.110867\n",
      "[2754]\ttraining's binary_logloss: 0.110851\n",
      "[2755]\ttraining's binary_logloss: 0.110836\n",
      "[2756]\ttraining's binary_logloss: 0.110832\n",
      "[2757]\ttraining's binary_logloss: 0.110817\n",
      "[2758]\ttraining's binary_logloss: 0.110802\n",
      "[2759]\ttraining's binary_logloss: 0.110789\n",
      "[2760]\ttraining's binary_logloss: 0.110775\n",
      "[2761]\ttraining's binary_logloss: 0.110767\n",
      "[2762]\ttraining's binary_logloss: 0.110753\n",
      "[2763]\ttraining's binary_logloss: 0.110737\n",
      "[2764]\ttraining's binary_logloss: 0.110726\n",
      "[2765]\ttraining's binary_logloss: 0.110711\n",
      "[2766]\ttraining's binary_logloss: 0.110697\n",
      "[2767]\ttraining's binary_logloss: 0.11069\n",
      "[2768]\ttraining's binary_logloss: 0.110677\n",
      "[2769]\ttraining's binary_logloss: 0.110658\n",
      "[2770]\ttraining's binary_logloss: 0.110644\n",
      "[2771]\ttraining's binary_logloss: 0.110631\n",
      "[2772]\ttraining's binary_logloss: 0.110616\n",
      "[2773]\ttraining's binary_logloss: 0.110603\n",
      "[2774]\ttraining's binary_logloss: 0.110591\n",
      "[2775]\ttraining's binary_logloss: 0.110575\n",
      "[2776]\ttraining's binary_logloss: 0.110561\n",
      "[2777]\ttraining's binary_logloss: 0.110547\n",
      "[2778]\ttraining's binary_logloss: 0.110545\n",
      "[2779]\ttraining's binary_logloss: 0.11054\n",
      "[2780]\ttraining's binary_logloss: 0.110526\n",
      "[2781]\ttraining's binary_logloss: 0.110517\n",
      "[2782]\ttraining's binary_logloss: 0.110507\n",
      "[2783]\ttraining's binary_logloss: 0.110492\n",
      "[2784]\ttraining's binary_logloss: 0.110477\n",
      "[2785]\ttraining's binary_logloss: 0.110462\n",
      "[2786]\ttraining's binary_logloss: 0.110448\n",
      "[2787]\ttraining's binary_logloss: 0.110431\n",
      "[2788]\ttraining's binary_logloss: 0.110417\n",
      "[2789]\ttraining's binary_logloss: 0.110402\n",
      "[2790]\ttraining's binary_logloss: 0.11039\n",
      "[2791]\ttraining's binary_logloss: 0.110377\n",
      "[2792]\ttraining's binary_logloss: 0.110364\n",
      "[2793]\ttraining's binary_logloss: 0.110349\n",
      "[2794]\ttraining's binary_logloss: 0.110333\n",
      "[2795]\ttraining's binary_logloss: 0.11032\n",
      "[2796]\ttraining's binary_logloss: 0.110307\n",
      "[2797]\ttraining's binary_logloss: 0.110294\n",
      "[2798]\ttraining's binary_logloss: 0.110279\n",
      "[2799]\ttraining's binary_logloss: 0.110268\n",
      "[2800]\ttraining's binary_logloss: 0.110253\n",
      "[2801]\ttraining's binary_logloss: 0.110239\n",
      "[2802]\ttraining's binary_logloss: 0.110234\n",
      "[2803]\ttraining's binary_logloss: 0.11022\n",
      "[2804]\ttraining's binary_logloss: 0.110208\n",
      "[2805]\ttraining's binary_logloss: 0.110196\n",
      "[2806]\ttraining's binary_logloss: 0.110183\n",
      "[2807]\ttraining's binary_logloss: 0.110171\n",
      "[2808]\ttraining's binary_logloss: 0.110159\n",
      "[2809]\ttraining's binary_logloss: 0.110145\n",
      "[2810]\ttraining's binary_logloss: 0.11013\n",
      "[2811]\ttraining's binary_logloss: 0.110117\n",
      "[2812]\ttraining's binary_logloss: 0.110103\n",
      "[2813]\ttraining's binary_logloss: 0.11009\n",
      "[2814]\ttraining's binary_logloss: 0.110077\n",
      "[2815]\ttraining's binary_logloss: 0.110064\n",
      "[2816]\ttraining's binary_logloss: 0.110051\n",
      "[2817]\ttraining's binary_logloss: 0.110035\n",
      "[2818]\ttraining's binary_logloss: 0.110017\n",
      "[2819]\ttraining's binary_logloss: 0.110002\n",
      "[2820]\ttraining's binary_logloss: 0.109991\n",
      "[2821]\ttraining's binary_logloss: 0.109976\n",
      "[2822]\ttraining's binary_logloss: 0.109961\n",
      "[2823]\ttraining's binary_logloss: 0.109946\n",
      "[2824]\ttraining's binary_logloss: 0.109942\n",
      "[2825]\ttraining's binary_logloss: 0.109928\n",
      "[2826]\ttraining's binary_logloss: 0.109917\n",
      "[2827]\ttraining's binary_logloss: 0.109902\n",
      "[2828]\ttraining's binary_logloss: 0.10989\n",
      "[2829]\ttraining's binary_logloss: 0.109876\n",
      "[2830]\ttraining's binary_logloss: 0.109864\n",
      "[2831]\ttraining's binary_logloss: 0.10985\n",
      "[2832]\ttraining's binary_logloss: 0.109837\n",
      "[2833]\ttraining's binary_logloss: 0.109824\n",
      "[2834]\ttraining's binary_logloss: 0.109814\n",
      "[2835]\ttraining's binary_logloss: 0.109802\n",
      "[2836]\ttraining's binary_logloss: 0.109788\n",
      "[2837]\ttraining's binary_logloss: 0.109776\n",
      "[2838]\ttraining's binary_logloss: 0.109763\n",
      "[2839]\ttraining's binary_logloss: 0.10975\n",
      "[2840]\ttraining's binary_logloss: 0.109736\n",
      "[2841]\ttraining's binary_logloss: 0.109729\n",
      "[2842]\ttraining's binary_logloss: 0.109715\n",
      "[2843]\ttraining's binary_logloss: 0.109702\n",
      "[2844]\ttraining's binary_logloss: 0.109689\n",
      "[2845]\ttraining's binary_logloss: 0.109675\n",
      "[2846]\ttraining's binary_logloss: 0.109663\n",
      "[2847]\ttraining's binary_logloss: 0.109649\n",
      "[2848]\ttraining's binary_logloss: 0.10963\n",
      "[2849]\ttraining's binary_logloss: 0.109615\n",
      "[2850]\ttraining's binary_logloss: 0.109601\n",
      "[2851]\ttraining's binary_logloss: 0.109587\n",
      "[2852]\ttraining's binary_logloss: 0.109573\n",
      "[2853]\ttraining's binary_logloss: 0.109559\n",
      "[2854]\ttraining's binary_logloss: 0.109546\n",
      "[2855]\ttraining's binary_logloss: 0.109532\n",
      "[2856]\ttraining's binary_logloss: 0.109519\n",
      "[2857]\ttraining's binary_logloss: 0.109505\n",
      "[2858]\ttraining's binary_logloss: 0.109491\n",
      "[2859]\ttraining's binary_logloss: 0.109485\n",
      "[2860]\ttraining's binary_logloss: 0.109469\n",
      "[2861]\ttraining's binary_logloss: 0.109448\n",
      "[2862]\ttraining's binary_logloss: 0.109435\n",
      "[2863]\ttraining's binary_logloss: 0.109423\n",
      "[2864]\ttraining's binary_logloss: 0.109409\n",
      "[2865]\ttraining's binary_logloss: 0.109394\n",
      "[2866]\ttraining's binary_logloss: 0.10938\n",
      "[2867]\ttraining's binary_logloss: 0.109368\n",
      "[2868]\ttraining's binary_logloss: 0.109352\n",
      "[2869]\ttraining's binary_logloss: 0.109339\n",
      "[2870]\ttraining's binary_logloss: 0.109327\n",
      "[2871]\ttraining's binary_logloss: 0.109313\n",
      "[2872]\ttraining's binary_logloss: 0.109295\n",
      "[2873]\ttraining's binary_logloss: 0.109288\n",
      "[2874]\ttraining's binary_logloss: 0.109271\n",
      "[2875]\ttraining's binary_logloss: 0.109258\n",
      "[2876]\ttraining's binary_logloss: 0.109245\n",
      "[2877]\ttraining's binary_logloss: 0.109233\n",
      "[2878]\ttraining's binary_logloss: 0.109217\n",
      "[2879]\ttraining's binary_logloss: 0.109207\n",
      "[2880]\ttraining's binary_logloss: 0.109193\n",
      "[2881]\ttraining's binary_logloss: 0.109179\n",
      "[2882]\ttraining's binary_logloss: 0.109168\n",
      "[2883]\ttraining's binary_logloss: 0.109156\n",
      "[2884]\ttraining's binary_logloss: 0.109142\n",
      "[2885]\ttraining's binary_logloss: 0.109127\n",
      "[2886]\ttraining's binary_logloss: 0.109111\n",
      "[2887]\ttraining's binary_logloss: 0.109098\n",
      "[2888]\ttraining's binary_logloss: 0.109093\n",
      "[2889]\ttraining's binary_logloss: 0.109079\n",
      "[2890]\ttraining's binary_logloss: 0.109064\n",
      "[2891]\ttraining's binary_logloss: 0.109044\n",
      "[2892]\ttraining's binary_logloss: 0.109031\n",
      "[2893]\ttraining's binary_logloss: 0.109017\n",
      "[2894]\ttraining's binary_logloss: 0.109003\n",
      "[2895]\ttraining's binary_logloss: 0.108989\n",
      "[2896]\ttraining's binary_logloss: 0.108976\n",
      "[2897]\ttraining's binary_logloss: 0.108965\n",
      "[2898]\ttraining's binary_logloss: 0.10895\n",
      "[2899]\ttraining's binary_logloss: 0.108938\n",
      "[2900]\ttraining's binary_logloss: 0.108935\n",
      "[2901]\ttraining's binary_logloss: 0.10892\n",
      "[2902]\ttraining's binary_logloss: 0.108908\n",
      "[2903]\ttraining's binary_logloss: 0.108892\n",
      "[2904]\ttraining's binary_logloss: 0.108876\n",
      "[2905]\ttraining's binary_logloss: 0.10886\n",
      "[2906]\ttraining's binary_logloss: 0.108846\n",
      "[2907]\ttraining's binary_logloss: 0.108832\n",
      "[2908]\ttraining's binary_logloss: 0.108815\n",
      "[2909]\ttraining's binary_logloss: 0.108811\n",
      "[2910]\ttraining's binary_logloss: 0.108796\n",
      "[2911]\ttraining's binary_logloss: 0.108783\n",
      "[2912]\ttraining's binary_logloss: 0.108767\n",
      "[2913]\ttraining's binary_logloss: 0.108755\n",
      "[2914]\ttraining's binary_logloss: 0.108744\n",
      "[2915]\ttraining's binary_logloss: 0.108731\n",
      "[2916]\ttraining's binary_logloss: 0.108718\n",
      "[2917]\ttraining's binary_logloss: 0.108705\n",
      "[2918]\ttraining's binary_logloss: 0.108689\n",
      "[2919]\ttraining's binary_logloss: 0.108673\n",
      "[2920]\ttraining's binary_logloss: 0.108661\n",
      "[2921]\ttraining's binary_logloss: 0.108649\n",
      "[2922]\ttraining's binary_logloss: 0.108634\n",
      "[2923]\ttraining's binary_logloss: 0.108628\n",
      "[2924]\ttraining's binary_logloss: 0.108614\n",
      "[2925]\ttraining's binary_logloss: 0.108602\n",
      "[2926]\ttraining's binary_logloss: 0.10859\n",
      "[2927]\ttraining's binary_logloss: 0.108573\n",
      "[2928]\ttraining's binary_logloss: 0.10856\n",
      "[2929]\ttraining's binary_logloss: 0.108546\n",
      "[2930]\ttraining's binary_logloss: 0.108533\n",
      "[2931]\ttraining's binary_logloss: 0.108518\n",
      "[2932]\ttraining's binary_logloss: 0.108503\n",
      "[2933]\ttraining's binary_logloss: 0.10849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2934]\ttraining's binary_logloss: 0.108476\n",
      "[2935]\ttraining's binary_logloss: 0.108466\n",
      "[2936]\ttraining's binary_logloss: 0.108452\n",
      "[2937]\ttraining's binary_logloss: 0.108436\n",
      "[2938]\ttraining's binary_logloss: 0.108421\n",
      "[2939]\ttraining's binary_logloss: 0.108409\n",
      "[2940]\ttraining's binary_logloss: 0.108396\n",
      "[2941]\ttraining's binary_logloss: 0.108385\n",
      "[2942]\ttraining's binary_logloss: 0.108373\n",
      "[2943]\ttraining's binary_logloss: 0.108364\n",
      "[2944]\ttraining's binary_logloss: 0.108352\n",
      "[2945]\ttraining's binary_logloss: 0.108347\n",
      "[2946]\ttraining's binary_logloss: 0.108334\n",
      "[2947]\ttraining's binary_logloss: 0.108321\n",
      "[2948]\ttraining's binary_logloss: 0.108306\n",
      "[2949]\ttraining's binary_logloss: 0.108296\n",
      "[2950]\ttraining's binary_logloss: 0.108284\n",
      "[2951]\ttraining's binary_logloss: 0.108271\n",
      "[2952]\ttraining's binary_logloss: 0.108254\n",
      "[2953]\ttraining's binary_logloss: 0.108245\n",
      "[2954]\ttraining's binary_logloss: 0.108234\n",
      "[2955]\ttraining's binary_logloss: 0.108225\n",
      "[2956]\ttraining's binary_logloss: 0.108211\n",
      "[2957]\ttraining's binary_logloss: 0.1082\n",
      "[2958]\ttraining's binary_logloss: 0.108186\n",
      "[2959]\ttraining's binary_logloss: 0.108173\n",
      "[2960]\ttraining's binary_logloss: 0.108164\n",
      "[2961]\ttraining's binary_logloss: 0.108151\n",
      "[2962]\ttraining's binary_logloss: 0.108138\n",
      "[2963]\ttraining's binary_logloss: 0.108128\n",
      "[2964]\ttraining's binary_logloss: 0.108114\n",
      "[2965]\ttraining's binary_logloss: 0.108101\n",
      "[2966]\ttraining's binary_logloss: 0.108088\n",
      "[2967]\ttraining's binary_logloss: 0.108074\n",
      "[2968]\ttraining's binary_logloss: 0.108061\n",
      "[2969]\ttraining's binary_logloss: 0.108049\n",
      "[2970]\ttraining's binary_logloss: 0.108035\n",
      "[2971]\ttraining's binary_logloss: 0.108023\n",
      "[2972]\ttraining's binary_logloss: 0.108009\n",
      "[2973]\ttraining's binary_logloss: 0.107995\n",
      "[2974]\ttraining's binary_logloss: 0.107979\n",
      "[2975]\ttraining's binary_logloss: 0.107963\n",
      "[2976]\ttraining's binary_logloss: 0.107956\n",
      "[2977]\ttraining's binary_logloss: 0.107944\n",
      "[2978]\ttraining's binary_logloss: 0.10793\n",
      "[2979]\ttraining's binary_logloss: 0.10792\n",
      "[2980]\ttraining's binary_logloss: 0.107905\n",
      "[2981]\ttraining's binary_logloss: 0.107893\n",
      "[2982]\ttraining's binary_logloss: 0.107883\n",
      "[2983]\ttraining's binary_logloss: 0.107869\n",
      "[2984]\ttraining's binary_logloss: 0.107851\n",
      "[2985]\ttraining's binary_logloss: 0.107838\n",
      "[2986]\ttraining's binary_logloss: 0.107826\n",
      "[2987]\ttraining's binary_logloss: 0.107814\n",
      "[2988]\ttraining's binary_logloss: 0.107801\n",
      "[2989]\ttraining's binary_logloss: 0.107788\n",
      "[2990]\ttraining's binary_logloss: 0.107775\n",
      "[2991]\ttraining's binary_logloss: 0.107762\n",
      "[2992]\ttraining's binary_logloss: 0.10775\n",
      "[2993]\ttraining's binary_logloss: 0.107733\n",
      "[2994]\ttraining's binary_logloss: 0.10772\n",
      "[2995]\ttraining's binary_logloss: 0.107707\n",
      "[2996]\ttraining's binary_logloss: 0.107691\n",
      "[2997]\ttraining's binary_logloss: 0.107677\n",
      "[2998]\ttraining's binary_logloss: 0.107664\n",
      "[2999]\ttraining's binary_logloss: 0.10765\n",
      "[3000]\ttraining's binary_logloss: 0.107636\n",
      "[3001]\ttraining's binary_logloss: 0.107623\n",
      "[3002]\ttraining's binary_logloss: 0.107609\n",
      "[3003]\ttraining's binary_logloss: 0.107597\n",
      "[3004]\ttraining's binary_logloss: 0.107589\n",
      "[3005]\ttraining's binary_logloss: 0.107575\n",
      "[3006]\ttraining's binary_logloss: 0.107563\n",
      "[3007]\ttraining's binary_logloss: 0.107552\n",
      "[3008]\ttraining's binary_logloss: 0.107537\n",
      "[3009]\ttraining's binary_logloss: 0.107523\n",
      "[3010]\ttraining's binary_logloss: 0.107511\n",
      "[3011]\ttraining's binary_logloss: 0.107497\n",
      "[3012]\ttraining's binary_logloss: 0.107485\n",
      "[3013]\ttraining's binary_logloss: 0.107474\n",
      "[3014]\ttraining's binary_logloss: 0.107461\n",
      "[3015]\ttraining's binary_logloss: 0.107454\n",
      "[3016]\ttraining's binary_logloss: 0.10744\n",
      "[3017]\ttraining's binary_logloss: 0.107427\n",
      "[3018]\ttraining's binary_logloss: 0.107415\n",
      "[3019]\ttraining's binary_logloss: 0.107402\n",
      "[3020]\ttraining's binary_logloss: 0.107387\n",
      "[3021]\ttraining's binary_logloss: 0.107376\n",
      "[3022]\ttraining's binary_logloss: 0.107363\n",
      "[3023]\ttraining's binary_logloss: 0.107348\n",
      "[3024]\ttraining's binary_logloss: 0.107335\n",
      "[3025]\ttraining's binary_logloss: 0.107323\n",
      "[3026]\ttraining's binary_logloss: 0.107308\n",
      "[3027]\ttraining's binary_logloss: 0.107299\n",
      "[3028]\ttraining's binary_logloss: 0.107286\n",
      "[3029]\ttraining's binary_logloss: 0.107272\n",
      "[3030]\ttraining's binary_logloss: 0.10726\n",
      "[3031]\ttraining's binary_logloss: 0.107248\n",
      "[3032]\ttraining's binary_logloss: 0.107235\n",
      "[3033]\ttraining's binary_logloss: 0.107221\n",
      "[3034]\ttraining's binary_logloss: 0.107208\n",
      "[3035]\ttraining's binary_logloss: 0.107199\n",
      "[3036]\ttraining's binary_logloss: 0.107186\n",
      "[3037]\ttraining's binary_logloss: 0.107173\n",
      "[3038]\ttraining's binary_logloss: 0.107161\n",
      "[3039]\ttraining's binary_logloss: 0.107148\n",
      "[3040]\ttraining's binary_logloss: 0.107134\n",
      "[3041]\ttraining's binary_logloss: 0.107127\n",
      "[3042]\ttraining's binary_logloss: 0.107113\n",
      "[3043]\ttraining's binary_logloss: 0.1071\n",
      "[3044]\ttraining's binary_logloss: 0.107088\n",
      "[3045]\ttraining's binary_logloss: 0.107075\n",
      "[3046]\ttraining's binary_logloss: 0.107066\n",
      "[3047]\ttraining's binary_logloss: 0.10705\n",
      "[3048]\ttraining's binary_logloss: 0.107037\n",
      "[3049]\ttraining's binary_logloss: 0.107025\n",
      "[3050]\ttraining's binary_logloss: 0.107012\n",
      "[3051]\ttraining's binary_logloss: 0.106999\n",
      "[3052]\ttraining's binary_logloss: 0.106987\n",
      "[3053]\ttraining's binary_logloss: 0.106975\n",
      "[3054]\ttraining's binary_logloss: 0.106966\n",
      "[3055]\ttraining's binary_logloss: 0.106955\n",
      "[3056]\ttraining's binary_logloss: 0.106942\n",
      "[3057]\ttraining's binary_logloss: 0.106928\n",
      "[3058]\ttraining's binary_logloss: 0.106914\n",
      "[3059]\ttraining's binary_logloss: 0.106903\n",
      "[3060]\ttraining's binary_logloss: 0.10689\n",
      "[3061]\ttraining's binary_logloss: 0.106878\n",
      "[3062]\ttraining's binary_logloss: 0.106871\n",
      "[3063]\ttraining's binary_logloss: 0.10686\n",
      "[3064]\ttraining's binary_logloss: 0.106846\n",
      "[3065]\ttraining's binary_logloss: 0.106837\n",
      "[3066]\ttraining's binary_logloss: 0.106824\n",
      "[3067]\ttraining's binary_logloss: 0.106816\n",
      "[3068]\ttraining's binary_logloss: 0.106811\n",
      "[3069]\ttraining's binary_logloss: 0.106799\n",
      "[3070]\ttraining's binary_logloss: 0.106787\n",
      "[3071]\ttraining's binary_logloss: 0.106775\n",
      "[3072]\ttraining's binary_logloss: 0.106762\n",
      "[3073]\ttraining's binary_logloss: 0.10675\n",
      "[3074]\ttraining's binary_logloss: 0.106738\n",
      "[3075]\ttraining's binary_logloss: 0.106725\n",
      "[3076]\ttraining's binary_logloss: 0.106712\n",
      "[3077]\ttraining's binary_logloss: 0.106698\n",
      "[3078]\ttraining's binary_logloss: 0.106691\n",
      "[3079]\ttraining's binary_logloss: 0.106678\n",
      "[3080]\ttraining's binary_logloss: 0.106671\n",
      "[3081]\ttraining's binary_logloss: 0.106657\n",
      "[3082]\ttraining's binary_logloss: 0.106651\n",
      "[3083]\ttraining's binary_logloss: 0.106638\n",
      "[3084]\ttraining's binary_logloss: 0.106626\n",
      "[3085]\ttraining's binary_logloss: 0.106611\n",
      "[3086]\ttraining's binary_logloss: 0.106598\n",
      "[3087]\ttraining's binary_logloss: 0.106583\n",
      "[3088]\ttraining's binary_logloss: 0.106571\n",
      "[3089]\ttraining's binary_logloss: 0.106558\n",
      "[3090]\ttraining's binary_logloss: 0.106544\n",
      "[3091]\ttraining's binary_logloss: 0.106533\n",
      "[3092]\ttraining's binary_logloss: 0.10652\n",
      "[3093]\ttraining's binary_logloss: 0.106505\n",
      "[3094]\ttraining's binary_logloss: 0.106494\n",
      "[3095]\ttraining's binary_logloss: 0.106478\n",
      "[3096]\ttraining's binary_logloss: 0.106458\n",
      "[3097]\ttraining's binary_logloss: 0.106445\n",
      "[3098]\ttraining's binary_logloss: 0.106433\n",
      "[3099]\ttraining's binary_logloss: 0.10642\n",
      "[3100]\ttraining's binary_logloss: 0.106416\n",
      "[3101]\ttraining's binary_logloss: 0.106402\n",
      "[3102]\ttraining's binary_logloss: 0.106386\n",
      "[3103]\ttraining's binary_logloss: 0.106373\n",
      "[3104]\ttraining's binary_logloss: 0.106361\n",
      "[3105]\ttraining's binary_logloss: 0.106352\n",
      "[3106]\ttraining's binary_logloss: 0.106341\n",
      "[3107]\ttraining's binary_logloss: 0.106335\n",
      "[3108]\ttraining's binary_logloss: 0.106323\n",
      "[3109]\ttraining's binary_logloss: 0.106311\n",
      "[3110]\ttraining's binary_logloss: 0.106298\n",
      "[3111]\ttraining's binary_logloss: 0.106285\n",
      "[3112]\ttraining's binary_logloss: 0.106281\n",
      "[3113]\ttraining's binary_logloss: 0.106274\n",
      "[3114]\ttraining's binary_logloss: 0.106265\n",
      "[3115]\ttraining's binary_logloss: 0.106253\n",
      "[3116]\ttraining's binary_logloss: 0.106236\n",
      "[3117]\ttraining's binary_logloss: 0.106224\n",
      "[3118]\ttraining's binary_logloss: 0.10621\n",
      "[3119]\ttraining's binary_logloss: 0.106196\n",
      "[3120]\ttraining's binary_logloss: 0.106182\n",
      "[3121]\ttraining's binary_logloss: 0.106169\n",
      "[3122]\ttraining's binary_logloss: 0.106157\n",
      "[3123]\ttraining's binary_logloss: 0.10615\n",
      "[3124]\ttraining's binary_logloss: 0.106135\n",
      "[3125]\ttraining's binary_logloss: 0.106122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3126]\ttraining's binary_logloss: 0.106105\n",
      "[3127]\ttraining's binary_logloss: 0.106093\n",
      "[3128]\ttraining's binary_logloss: 0.106081\n",
      "[3129]\ttraining's binary_logloss: 0.106069\n",
      "[3130]\ttraining's binary_logloss: 0.106057\n",
      "[3131]\ttraining's binary_logloss: 0.106044\n",
      "[3132]\ttraining's binary_logloss: 0.106031\n",
      "[3133]\ttraining's binary_logloss: 0.106018\n",
      "[3134]\ttraining's binary_logloss: 0.106005\n",
      "[3135]\ttraining's binary_logloss: 0.105993\n",
      "[3136]\ttraining's binary_logloss: 0.105981\n",
      "[3137]\ttraining's binary_logloss: 0.105972\n",
      "[3138]\ttraining's binary_logloss: 0.10596\n",
      "[3139]\ttraining's binary_logloss: 0.105946\n",
      "[3140]\ttraining's binary_logloss: 0.105932\n",
      "[3141]\ttraining's binary_logloss: 0.105916\n",
      "[3142]\ttraining's binary_logloss: 0.105908\n",
      "[3143]\ttraining's binary_logloss: 0.105897\n",
      "[3144]\ttraining's binary_logloss: 0.105886\n",
      "[3145]\ttraining's binary_logloss: 0.105875\n",
      "[3146]\ttraining's binary_logloss: 0.105867\n",
      "[3147]\ttraining's binary_logloss: 0.105859\n",
      "[3148]\ttraining's binary_logloss: 0.105847\n",
      "[3149]\ttraining's binary_logloss: 0.105831\n",
      "[3150]\ttraining's binary_logloss: 0.105819\n",
      "[3151]\ttraining's binary_logloss: 0.105806\n",
      "[3152]\ttraining's binary_logloss: 0.105792\n",
      "[3153]\ttraining's binary_logloss: 0.105768\n",
      "[3154]\ttraining's binary_logloss: 0.105756\n",
      "[3155]\ttraining's binary_logloss: 0.105743\n",
      "[3156]\ttraining's binary_logloss: 0.105729\n",
      "[3157]\ttraining's binary_logloss: 0.105712\n",
      "[3158]\ttraining's binary_logloss: 0.105705\n",
      "[3159]\ttraining's binary_logloss: 0.10569\n",
      "[3160]\ttraining's binary_logloss: 0.105678\n",
      "[3161]\ttraining's binary_logloss: 0.105665\n",
      "[3162]\ttraining's binary_logloss: 0.105649\n",
      "[3163]\ttraining's binary_logloss: 0.10564\n",
      "[3164]\ttraining's binary_logloss: 0.105628\n",
      "[3165]\ttraining's binary_logloss: 0.105615\n",
      "[3166]\ttraining's binary_logloss: 0.105601\n",
      "[3167]\ttraining's binary_logloss: 0.105589\n",
      "[3168]\ttraining's binary_logloss: 0.105581\n",
      "[3169]\ttraining's binary_logloss: 0.105569\n",
      "[3170]\ttraining's binary_logloss: 0.105556\n",
      "[3171]\ttraining's binary_logloss: 0.105545\n",
      "[3172]\ttraining's binary_logloss: 0.105529\n",
      "[3173]\ttraining's binary_logloss: 0.105515\n",
      "[3174]\ttraining's binary_logloss: 0.105503\n",
      "[3175]\ttraining's binary_logloss: 0.105494\n",
      "[3176]\ttraining's binary_logloss: 0.105483\n",
      "[3177]\ttraining's binary_logloss: 0.105471\n",
      "[3178]\ttraining's binary_logloss: 0.105467\n",
      "[3179]\ttraining's binary_logloss: 0.105455\n",
      "[3180]\ttraining's binary_logloss: 0.105441\n",
      "[3181]\ttraining's binary_logloss: 0.10543\n",
      "[3182]\ttraining's binary_logloss: 0.105414\n",
      "[3183]\ttraining's binary_logloss: 0.105402\n",
      "[3184]\ttraining's binary_logloss: 0.105387\n",
      "[3185]\ttraining's binary_logloss: 0.105373\n",
      "[3186]\ttraining's binary_logloss: 0.105361\n",
      "[3187]\ttraining's binary_logloss: 0.105346\n",
      "[3188]\ttraining's binary_logloss: 0.105333\n",
      "[3189]\ttraining's binary_logloss: 0.105319\n",
      "[3190]\ttraining's binary_logloss: 0.105306\n",
      "[3191]\ttraining's binary_logloss: 0.105292\n",
      "[3192]\ttraining's binary_logloss: 0.105279\n",
      "[3193]\ttraining's binary_logloss: 0.105266\n",
      "[3194]\ttraining's binary_logloss: 0.105257\n",
      "[3195]\ttraining's binary_logloss: 0.105245\n",
      "[3196]\ttraining's binary_logloss: 0.105241\n",
      "[3197]\ttraining's binary_logloss: 0.105238\n",
      "[3198]\ttraining's binary_logloss: 0.105226\n",
      "[3199]\ttraining's binary_logloss: 0.105217\n",
      "[3200]\ttraining's binary_logloss: 0.105204\n",
      "[3201]\ttraining's binary_logloss: 0.105196\n",
      "[3202]\ttraining's binary_logloss: 0.105184\n",
      "[3203]\ttraining's binary_logloss: 0.105174\n",
      "[3204]\ttraining's binary_logloss: 0.105163\n",
      "[3205]\ttraining's binary_logloss: 0.105151\n",
      "[3206]\ttraining's binary_logloss: 0.105138\n",
      "[3207]\ttraining's binary_logloss: 0.105127\n",
      "[3208]\ttraining's binary_logloss: 0.105118\n",
      "[3209]\ttraining's binary_logloss: 0.105113\n",
      "[3210]\ttraining's binary_logloss: 0.1051\n",
      "[3211]\ttraining's binary_logloss: 0.105084\n",
      "[3212]\ttraining's binary_logloss: 0.105072\n",
      "[3213]\ttraining's binary_logloss: 0.10506\n",
      "[3214]\ttraining's binary_logloss: 0.105044\n",
      "[3215]\ttraining's binary_logloss: 0.105032\n",
      "[3216]\ttraining's binary_logloss: 0.10502\n",
      "[3217]\ttraining's binary_logloss: 0.10501\n",
      "[3218]\ttraining's binary_logloss: 0.104998\n",
      "[3219]\ttraining's binary_logloss: 0.104983\n",
      "[3220]\ttraining's binary_logloss: 0.10497\n",
      "[3221]\ttraining's binary_logloss: 0.104956\n",
      "[3222]\ttraining's binary_logloss: 0.104944\n",
      "[3223]\ttraining's binary_logloss: 0.104932\n",
      "[3224]\ttraining's binary_logloss: 0.104917\n",
      "[3225]\ttraining's binary_logloss: 0.104904\n",
      "[3226]\ttraining's binary_logloss: 0.104892\n",
      "[3227]\ttraining's binary_logloss: 0.10488\n",
      "[3228]\ttraining's binary_logloss: 0.104867\n",
      "[3229]\ttraining's binary_logloss: 0.104855\n",
      "[3230]\ttraining's binary_logloss: 0.104842\n",
      "[3231]\ttraining's binary_logloss: 0.104827\n",
      "[3232]\ttraining's binary_logloss: 0.104814\n",
      "[3233]\ttraining's binary_logloss: 0.104801\n",
      "[3234]\ttraining's binary_logloss: 0.104789\n",
      "[3235]\ttraining's binary_logloss: 0.104777\n",
      "[3236]\ttraining's binary_logloss: 0.104763\n",
      "[3237]\ttraining's binary_logloss: 0.104751\n",
      "[3238]\ttraining's binary_logloss: 0.104738\n",
      "[3239]\ttraining's binary_logloss: 0.104713\n",
      "[3240]\ttraining's binary_logloss: 0.104701\n",
      "[3241]\ttraining's binary_logloss: 0.104677\n",
      "[3242]\ttraining's binary_logloss: 0.104665\n",
      "[3243]\ttraining's binary_logloss: 0.104653\n",
      "[3244]\ttraining's binary_logloss: 0.10464\n",
      "[3245]\ttraining's binary_logloss: 0.104624\n",
      "[3246]\ttraining's binary_logloss: 0.104611\n",
      "[3247]\ttraining's binary_logloss: 0.1046\n",
      "[3248]\ttraining's binary_logloss: 0.104586\n",
      "[3249]\ttraining's binary_logloss: 0.10457\n",
      "[3250]\ttraining's binary_logloss: 0.104558\n",
      "[3251]\ttraining's binary_logloss: 0.104546\n",
      "[3252]\ttraining's binary_logloss: 0.104535\n",
      "[3253]\ttraining's binary_logloss: 0.104521\n",
      "[3254]\ttraining's binary_logloss: 0.104508\n",
      "[3255]\ttraining's binary_logloss: 0.104494\n",
      "[3256]\ttraining's binary_logloss: 0.10448\n",
      "[3257]\ttraining's binary_logloss: 0.104466\n",
      "[3258]\ttraining's binary_logloss: 0.104454\n",
      "[3259]\ttraining's binary_logloss: 0.10444\n",
      "[3260]\ttraining's binary_logloss: 0.104426\n",
      "[3261]\ttraining's binary_logloss: 0.104414\n",
      "[3262]\ttraining's binary_logloss: 0.104403\n",
      "[3263]\ttraining's binary_logloss: 0.104392\n",
      "[3264]\ttraining's binary_logloss: 0.104379\n",
      "[3265]\ttraining's binary_logloss: 0.104366\n",
      "[3266]\ttraining's binary_logloss: 0.104357\n",
      "[3267]\ttraining's binary_logloss: 0.104345\n",
      "[3268]\ttraining's binary_logloss: 0.104331\n",
      "[3269]\ttraining's binary_logloss: 0.104318\n",
      "[3270]\ttraining's binary_logloss: 0.104306\n",
      "[3271]\ttraining's binary_logloss: 0.104298\n",
      "[3272]\ttraining's binary_logloss: 0.104285\n",
      "[3273]\ttraining's binary_logloss: 0.104271\n",
      "[3274]\ttraining's binary_logloss: 0.104258\n",
      "[3275]\ttraining's binary_logloss: 0.104244\n",
      "[3276]\ttraining's binary_logloss: 0.104233\n",
      "[3277]\ttraining's binary_logloss: 0.104223\n",
      "[3278]\ttraining's binary_logloss: 0.104217\n",
      "[3279]\ttraining's binary_logloss: 0.104214\n",
      "[3280]\ttraining's binary_logloss: 0.104201\n",
      "[3281]\ttraining's binary_logloss: 0.104186\n",
      "[3282]\ttraining's binary_logloss: 0.104172\n",
      "[3283]\ttraining's binary_logloss: 0.104158\n",
      "[3284]\ttraining's binary_logloss: 0.104147\n",
      "[3285]\ttraining's binary_logloss: 0.104134\n",
      "[3286]\ttraining's binary_logloss: 0.104121\n",
      "[3287]\ttraining's binary_logloss: 0.104107\n",
      "[3288]\ttraining's binary_logloss: 0.104095\n",
      "[3289]\ttraining's binary_logloss: 0.104085\n",
      "[3290]\ttraining's binary_logloss: 0.104072\n",
      "[3291]\ttraining's binary_logloss: 0.104061\n",
      "[3292]\ttraining's binary_logloss: 0.104049\n",
      "[3293]\ttraining's binary_logloss: 0.104037\n",
      "[3294]\ttraining's binary_logloss: 0.104026\n",
      "[3295]\ttraining's binary_logloss: 0.104014\n",
      "[3296]\ttraining's binary_logloss: 0.104003\n",
      "[3297]\ttraining's binary_logloss: 0.103994\n",
      "[3298]\ttraining's binary_logloss: 0.103981\n",
      "[3299]\ttraining's binary_logloss: 0.103965\n",
      "[3300]\ttraining's binary_logloss: 0.103951\n",
      "[3301]\ttraining's binary_logloss: 0.103939\n",
      "[3302]\ttraining's binary_logloss: 0.103927\n",
      "[3303]\ttraining's binary_logloss: 0.103914\n",
      "[3304]\ttraining's binary_logloss: 0.103901\n",
      "[3305]\ttraining's binary_logloss: 0.103893\n",
      "[3306]\ttraining's binary_logloss: 0.103879\n",
      "[3307]\ttraining's binary_logloss: 0.103869\n",
      "[3308]\ttraining's binary_logloss: 0.103861\n",
      "[3309]\ttraining's binary_logloss: 0.103849\n",
      "[3310]\ttraining's binary_logloss: 0.103836\n",
      "[3311]\ttraining's binary_logloss: 0.103823\n",
      "[3312]\ttraining's binary_logloss: 0.103812\n",
      "[3313]\ttraining's binary_logloss: 0.103801\n",
      "[3314]\ttraining's binary_logloss: 0.103787\n",
      "[3315]\ttraining's binary_logloss: 0.103773\n",
      "[3316]\ttraining's binary_logloss: 0.103761\n",
      "[3317]\ttraining's binary_logloss: 0.103749\n",
      "[3318]\ttraining's binary_logloss: 0.103735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3319]\ttraining's binary_logloss: 0.103724\n",
      "[3320]\ttraining's binary_logloss: 0.103711\n",
      "[3321]\ttraining's binary_logloss: 0.103699\n",
      "[3322]\ttraining's binary_logloss: 0.103684\n",
      "[3323]\ttraining's binary_logloss: 0.103672\n",
      "[3324]\ttraining's binary_logloss: 0.103661\n",
      "[3325]\ttraining's binary_logloss: 0.103648\n",
      "[3326]\ttraining's binary_logloss: 0.103634\n",
      "[3327]\ttraining's binary_logloss: 0.103621\n",
      "[3328]\ttraining's binary_logloss: 0.10361\n",
      "[3329]\ttraining's binary_logloss: 0.103597\n",
      "[3330]\ttraining's binary_logloss: 0.103586\n",
      "[3331]\ttraining's binary_logloss: 0.103576\n",
      "[3332]\ttraining's binary_logloss: 0.103564\n",
      "[3333]\ttraining's binary_logloss: 0.103552\n",
      "[3334]\ttraining's binary_logloss: 0.103541\n",
      "[3335]\ttraining's binary_logloss: 0.103527\n",
      "[3336]\ttraining's binary_logloss: 0.103513\n",
      "[3337]\ttraining's binary_logloss: 0.103499\n",
      "[3338]\ttraining's binary_logloss: 0.103486\n",
      "[3339]\ttraining's binary_logloss: 0.103475\n",
      "[3340]\ttraining's binary_logloss: 0.103463\n",
      "[3341]\ttraining's binary_logloss: 0.103452\n",
      "[3342]\ttraining's binary_logloss: 0.103439\n",
      "[3343]\ttraining's binary_logloss: 0.103426\n",
      "[3344]\ttraining's binary_logloss: 0.103417\n",
      "[3345]\ttraining's binary_logloss: 0.103403\n",
      "[3346]\ttraining's binary_logloss: 0.103391\n",
      "[3347]\ttraining's binary_logloss: 0.103375\n",
      "[3348]\ttraining's binary_logloss: 0.103363\n",
      "[3349]\ttraining's binary_logloss: 0.103352\n",
      "[3350]\ttraining's binary_logloss: 0.103339\n",
      "[3351]\ttraining's binary_logloss: 0.103326\n",
      "[3352]\ttraining's binary_logloss: 0.103318\n",
      "[3353]\ttraining's binary_logloss: 0.103306\n",
      "[3354]\ttraining's binary_logloss: 0.103295\n",
      "[3355]\ttraining's binary_logloss: 0.103282\n",
      "[3356]\ttraining's binary_logloss: 0.103271\n",
      "[3357]\ttraining's binary_logloss: 0.103259\n",
      "[3358]\ttraining's binary_logloss: 0.103247\n",
      "[3359]\ttraining's binary_logloss: 0.103235\n",
      "[3360]\ttraining's binary_logloss: 0.10322\n",
      "[3361]\ttraining's binary_logloss: 0.103208\n",
      "[3362]\ttraining's binary_logloss: 0.103197\n",
      "[3363]\ttraining's binary_logloss: 0.103185\n",
      "[3364]\ttraining's binary_logloss: 0.103174\n",
      "[3365]\ttraining's binary_logloss: 0.103163\n",
      "[3366]\ttraining's binary_logloss: 0.103151\n",
      "[3367]\ttraining's binary_logloss: 0.10314\n",
      "[3368]\ttraining's binary_logloss: 0.103126\n",
      "[3369]\ttraining's binary_logloss: 0.103114\n",
      "[3370]\ttraining's binary_logloss: 0.103102\n",
      "[3371]\ttraining's binary_logloss: 0.103091\n",
      "[3372]\ttraining's binary_logloss: 0.103079\n",
      "[3373]\ttraining's binary_logloss: 0.103065\n",
      "[3374]\ttraining's binary_logloss: 0.103054\n",
      "[3375]\ttraining's binary_logloss: 0.103042\n",
      "[3376]\ttraining's binary_logloss: 0.103029\n",
      "[3377]\ttraining's binary_logloss: 0.103017\n",
      "[3378]\ttraining's binary_logloss: 0.102994\n",
      "[3379]\ttraining's binary_logloss: 0.102983\n",
      "[3380]\ttraining's binary_logloss: 0.10297\n",
      "[3381]\ttraining's binary_logloss: 0.102957\n",
      "[3382]\ttraining's binary_logloss: 0.102945\n",
      "[3383]\ttraining's binary_logloss: 0.102933\n",
      "[3384]\ttraining's binary_logloss: 0.102912\n",
      "[3385]\ttraining's binary_logloss: 0.1029\n",
      "[3386]\ttraining's binary_logloss: 0.102887\n",
      "[3387]\ttraining's binary_logloss: 0.102874\n",
      "[3388]\ttraining's binary_logloss: 0.102864\n",
      "[3389]\ttraining's binary_logloss: 0.102852\n",
      "[3390]\ttraining's binary_logloss: 0.102839\n",
      "[3391]\ttraining's binary_logloss: 0.102828\n",
      "[3392]\ttraining's binary_logloss: 0.102816\n",
      "[3393]\ttraining's binary_logloss: 0.102803\n",
      "[3394]\ttraining's binary_logloss: 0.102792\n",
      "[3395]\ttraining's binary_logloss: 0.10278\n",
      "[3396]\ttraining's binary_logloss: 0.102768\n",
      "[3397]\ttraining's binary_logloss: 0.102758\n",
      "[3398]\ttraining's binary_logloss: 0.102746\n",
      "[3399]\ttraining's binary_logloss: 0.102734\n",
      "[3400]\ttraining's binary_logloss: 0.102721\n",
      "[3401]\ttraining's binary_logloss: 0.102708\n",
      "[3402]\ttraining's binary_logloss: 0.102694\n",
      "[3403]\ttraining's binary_logloss: 0.102681\n",
      "[3404]\ttraining's binary_logloss: 0.102667\n",
      "[3405]\ttraining's binary_logloss: 0.102654\n",
      "[3406]\ttraining's binary_logloss: 0.102643\n",
      "[3407]\ttraining's binary_logloss: 0.102633\n",
      "[3408]\ttraining's binary_logloss: 0.102622\n",
      "[3409]\ttraining's binary_logloss: 0.10261\n",
      "[3410]\ttraining's binary_logloss: 0.102595\n",
      "[3411]\ttraining's binary_logloss: 0.102582\n",
      "[3412]\ttraining's binary_logloss: 0.10257\n",
      "[3413]\ttraining's binary_logloss: 0.102547\n",
      "[3414]\ttraining's binary_logloss: 0.10254\n",
      "[3415]\ttraining's binary_logloss: 0.10253\n",
      "[3416]\ttraining's binary_logloss: 0.102519\n",
      "[3417]\ttraining's binary_logloss: 0.102507\n",
      "[3418]\ttraining's binary_logloss: 0.102495\n",
      "[3419]\ttraining's binary_logloss: 0.102464\n",
      "[3420]\ttraining's binary_logloss: 0.102452\n",
      "[3421]\ttraining's binary_logloss: 0.102438\n",
      "[3422]\ttraining's binary_logloss: 0.102427\n",
      "[3423]\ttraining's binary_logloss: 0.102416\n",
      "[3424]\ttraining's binary_logloss: 0.102403\n",
      "[3425]\ttraining's binary_logloss: 0.102395\n",
      "[3426]\ttraining's binary_logloss: 0.102383\n",
      "[3427]\ttraining's binary_logloss: 0.102371\n",
      "[3428]\ttraining's binary_logloss: 0.102359\n",
      "[3429]\ttraining's binary_logloss: 0.102349\n",
      "[3430]\ttraining's binary_logloss: 0.102337\n",
      "[3431]\ttraining's binary_logloss: 0.102325\n",
      "[3432]\ttraining's binary_logloss: 0.102314\n",
      "[3433]\ttraining's binary_logloss: 0.102308\n",
      "[3434]\ttraining's binary_logloss: 0.102286\n",
      "[3435]\ttraining's binary_logloss: 0.102272\n",
      "[3436]\ttraining's binary_logloss: 0.102259\n",
      "[3437]\ttraining's binary_logloss: 0.102238\n",
      "[3438]\ttraining's binary_logloss: 0.102228\n",
      "[3439]\ttraining's binary_logloss: 0.102217\n",
      "[3440]\ttraining's binary_logloss: 0.102203\n",
      "[3441]\ttraining's binary_logloss: 0.102192\n",
      "[3442]\ttraining's binary_logloss: 0.102171\n",
      "[3443]\ttraining's binary_logloss: 0.10216\n",
      "[3444]\ttraining's binary_logloss: 0.102147\n",
      "[3445]\ttraining's binary_logloss: 0.102136\n",
      "[3446]\ttraining's binary_logloss: 0.102123\n",
      "[3447]\ttraining's binary_logloss: 0.102111\n",
      "[3448]\ttraining's binary_logloss: 0.102099\n",
      "[3449]\ttraining's binary_logloss: 0.102086\n",
      "[3450]\ttraining's binary_logloss: 0.102073\n",
      "[3451]\ttraining's binary_logloss: 0.102063\n",
      "[3452]\ttraining's binary_logloss: 0.102051\n",
      "[3453]\ttraining's binary_logloss: 0.102038\n",
      "[3454]\ttraining's binary_logloss: 0.102026\n",
      "[3455]\ttraining's binary_logloss: 0.102011\n",
      "[3456]\ttraining's binary_logloss: 0.102\n",
      "[3457]\ttraining's binary_logloss: 0.101987\n",
      "[3458]\ttraining's binary_logloss: 0.101974\n",
      "[3459]\ttraining's binary_logloss: 0.101961\n",
      "[3460]\ttraining's binary_logloss: 0.10195\n",
      "[3461]\ttraining's binary_logloss: 0.10194\n",
      "[3462]\ttraining's binary_logloss: 0.101928\n",
      "[3463]\ttraining's binary_logloss: 0.101916\n",
      "[3464]\ttraining's binary_logloss: 0.101905\n",
      "[3465]\ttraining's binary_logloss: 0.101894\n",
      "[3466]\ttraining's binary_logloss: 0.101882\n",
      "[3467]\ttraining's binary_logloss: 0.101872\n",
      "[3468]\ttraining's binary_logloss: 0.101861\n",
      "[3469]\ttraining's binary_logloss: 0.101849\n",
      "[3470]\ttraining's binary_logloss: 0.101836\n",
      "[3471]\ttraining's binary_logloss: 0.10183\n",
      "[3472]\ttraining's binary_logloss: 0.101819\n",
      "[3473]\ttraining's binary_logloss: 0.101807\n",
      "[3474]\ttraining's binary_logloss: 0.101796\n",
      "[3475]\ttraining's binary_logloss: 0.101785\n",
      "[3476]\ttraining's binary_logloss: 0.101774\n",
      "[3477]\ttraining's binary_logloss: 0.101764\n",
      "[3478]\ttraining's binary_logloss: 0.101753\n",
      "[3479]\ttraining's binary_logloss: 0.101739\n",
      "[3480]\ttraining's binary_logloss: 0.101726\n",
      "[3481]\ttraining's binary_logloss: 0.101713\n",
      "[3482]\ttraining's binary_logloss: 0.101704\n",
      "[3483]\ttraining's binary_logloss: 0.101692\n",
      "[3484]\ttraining's binary_logloss: 0.101679\n",
      "[3485]\ttraining's binary_logloss: 0.101666\n",
      "[3486]\ttraining's binary_logloss: 0.101655\n",
      "[3487]\ttraining's binary_logloss: 0.101643\n",
      "[3488]\ttraining's binary_logloss: 0.101627\n",
      "[3489]\ttraining's binary_logloss: 0.101614\n",
      "[3490]\ttraining's binary_logloss: 0.101609\n",
      "[3491]\ttraining's binary_logloss: 0.101598\n",
      "[3492]\ttraining's binary_logloss: 0.101588\n",
      "[3493]\ttraining's binary_logloss: 0.101576\n",
      "[3494]\ttraining's binary_logloss: 0.101565\n",
      "[3495]\ttraining's binary_logloss: 0.101553\n",
      "[3496]\ttraining's binary_logloss: 0.101545\n",
      "[3497]\ttraining's binary_logloss: 0.101541\n",
      "[3498]\ttraining's binary_logloss: 0.101529\n",
      "[3499]\ttraining's binary_logloss: 0.101515\n",
      "[3500]\ttraining's binary_logloss: 0.101503\n",
      "[3501]\ttraining's binary_logloss: 0.101492\n",
      "[3502]\ttraining's binary_logloss: 0.101478\n",
      "[3503]\ttraining's binary_logloss: 0.101467\n",
      "[3504]\ttraining's binary_logloss: 0.101456\n",
      "[3505]\ttraining's binary_logloss: 0.101445\n",
      "[3506]\ttraining's binary_logloss: 0.101431\n",
      "[3507]\ttraining's binary_logloss: 0.101417\n",
      "[3508]\ttraining's binary_logloss: 0.101406\n",
      "[3509]\ttraining's binary_logloss: 0.101395\n",
      "[3510]\ttraining's binary_logloss: 0.101384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3511]\ttraining's binary_logloss: 0.101369\n",
      "[3512]\ttraining's binary_logloss: 0.101358\n",
      "[3513]\ttraining's binary_logloss: 0.101345\n",
      "[3514]\ttraining's binary_logloss: 0.101333\n",
      "[3515]\ttraining's binary_logloss: 0.101325\n",
      "[3516]\ttraining's binary_logloss: 0.101311\n",
      "[3517]\ttraining's binary_logloss: 0.101301\n",
      "[3518]\ttraining's binary_logloss: 0.101289\n",
      "[3519]\ttraining's binary_logloss: 0.101277\n",
      "[3520]\ttraining's binary_logloss: 0.101266\n",
      "[3521]\ttraining's binary_logloss: 0.101256\n",
      "[3522]\ttraining's binary_logloss: 0.101244\n",
      "[3523]\ttraining's binary_logloss: 0.101232\n",
      "[3524]\ttraining's binary_logloss: 0.10122\n",
      "[3525]\ttraining's binary_logloss: 0.101208\n",
      "[3526]\ttraining's binary_logloss: 0.101195\n",
      "[3527]\ttraining's binary_logloss: 0.101184\n",
      "[3528]\ttraining's binary_logloss: 0.101175\n",
      "[3529]\ttraining's binary_logloss: 0.10117\n",
      "[3530]\ttraining's binary_logloss: 0.101158\n",
      "[3531]\ttraining's binary_logloss: 0.101149\n",
      "[3532]\ttraining's binary_logloss: 0.101139\n",
      "[3533]\ttraining's binary_logloss: 0.101127\n",
      "[3534]\ttraining's binary_logloss: 0.101115\n",
      "[3535]\ttraining's binary_logloss: 0.101102\n",
      "[3536]\ttraining's binary_logloss: 0.10109\n",
      "[3537]\ttraining's binary_logloss: 0.101078\n",
      "[3538]\ttraining's binary_logloss: 0.101064\n",
      "[3539]\ttraining's binary_logloss: 0.101051\n",
      "[3540]\ttraining's binary_logloss: 0.10104\n",
      "[3541]\ttraining's binary_logloss: 0.10103\n",
      "[3542]\ttraining's binary_logloss: 0.101023\n",
      "[3543]\ttraining's binary_logloss: 0.101019\n",
      "[3544]\ttraining's binary_logloss: 0.101016\n",
      "[3545]\ttraining's binary_logloss: 0.101004\n",
      "[3546]\ttraining's binary_logloss: 0.100992\n",
      "[3547]\ttraining's binary_logloss: 0.100978\n",
      "[3548]\ttraining's binary_logloss: 0.100966\n",
      "[3549]\ttraining's binary_logloss: 0.100954\n",
      "[3550]\ttraining's binary_logloss: 0.100942\n",
      "[3551]\ttraining's binary_logloss: 0.100936\n",
      "[3552]\ttraining's binary_logloss: 0.100923\n",
      "[3553]\ttraining's binary_logloss: 0.100913\n",
      "[3554]\ttraining's binary_logloss: 0.100902\n",
      "[3555]\ttraining's binary_logloss: 0.10089\n",
      "[3556]\ttraining's binary_logloss: 0.100878\n",
      "[3557]\ttraining's binary_logloss: 0.100867\n",
      "[3558]\ttraining's binary_logloss: 0.100856\n",
      "[3559]\ttraining's binary_logloss: 0.100845\n",
      "[3560]\ttraining's binary_logloss: 0.100835\n",
      "[3561]\ttraining's binary_logloss: 0.100826\n",
      "[3562]\ttraining's binary_logloss: 0.100814\n",
      "[3563]\ttraining's binary_logloss: 0.100801\n",
      "[3564]\ttraining's binary_logloss: 0.100789\n",
      "[3565]\ttraining's binary_logloss: 0.100777\n",
      "[3566]\ttraining's binary_logloss: 0.100765\n",
      "[3567]\ttraining's binary_logloss: 0.100752\n",
      "[3568]\ttraining's binary_logloss: 0.100743\n",
      "[3569]\ttraining's binary_logloss: 0.100732\n",
      "[3570]\ttraining's binary_logloss: 0.100719\n",
      "[3571]\ttraining's binary_logloss: 0.100712\n",
      "[3572]\ttraining's binary_logloss: 0.100703\n",
      "[3573]\ttraining's binary_logloss: 0.100691\n",
      "[3574]\ttraining's binary_logloss: 0.100681\n",
      "[3575]\ttraining's binary_logloss: 0.100672\n",
      "[3576]\ttraining's binary_logloss: 0.10066\n",
      "[3577]\ttraining's binary_logloss: 0.100648\n",
      "[3578]\ttraining's binary_logloss: 0.100634\n",
      "[3579]\ttraining's binary_logloss: 0.100622\n",
      "[3580]\ttraining's binary_logloss: 0.100609\n",
      "[3581]\ttraining's binary_logloss: 0.100598\n",
      "[3582]\ttraining's binary_logloss: 0.100584\n",
      "[3583]\ttraining's binary_logloss: 0.100574\n",
      "[3584]\ttraining's binary_logloss: 0.100563\n",
      "[3585]\ttraining's binary_logloss: 0.100551\n",
      "[3586]\ttraining's binary_logloss: 0.100539\n",
      "[3587]\ttraining's binary_logloss: 0.100525\n",
      "[3588]\ttraining's binary_logloss: 0.100514\n",
      "[3589]\ttraining's binary_logloss: 0.100507\n",
      "[3590]\ttraining's binary_logloss: 0.100485\n",
      "[3591]\ttraining's binary_logloss: 0.100474\n",
      "[3592]\ttraining's binary_logloss: 0.100462\n",
      "[3593]\ttraining's binary_logloss: 0.100451\n",
      "[3594]\ttraining's binary_logloss: 0.10044\n",
      "[3595]\ttraining's binary_logloss: 0.100429\n",
      "[3596]\ttraining's binary_logloss: 0.100419\n",
      "[3597]\ttraining's binary_logloss: 0.100414\n",
      "[3598]\ttraining's binary_logloss: 0.100403\n",
      "[3599]\ttraining's binary_logloss: 0.10039\n",
      "[3600]\ttraining's binary_logloss: 0.10038\n",
      "[3601]\ttraining's binary_logloss: 0.100369\n",
      "[3602]\ttraining's binary_logloss: 0.100357\n",
      "[3603]\ttraining's binary_logloss: 0.100345\n",
      "[3604]\ttraining's binary_logloss: 0.100333\n",
      "[3605]\ttraining's binary_logloss: 0.100322\n",
      "[3606]\ttraining's binary_logloss: 0.10031\n",
      "[3607]\ttraining's binary_logloss: 0.100298\n",
      "[3608]\ttraining's binary_logloss: 0.100286\n",
      "[3609]\ttraining's binary_logloss: 0.100276\n",
      "[3610]\ttraining's binary_logloss: 0.100265\n",
      "[3611]\ttraining's binary_logloss: 0.100253\n",
      "[3612]\ttraining's binary_logloss: 0.100241\n",
      "[3613]\ttraining's binary_logloss: 0.100229\n",
      "[3614]\ttraining's binary_logloss: 0.100217\n",
      "[3615]\ttraining's binary_logloss: 0.100214\n",
      "[3616]\ttraining's binary_logloss: 0.100202\n",
      "[3617]\ttraining's binary_logloss: 0.100191\n",
      "[3618]\ttraining's binary_logloss: 0.100178\n",
      "[3619]\ttraining's binary_logloss: 0.100166\n",
      "[3620]\ttraining's binary_logloss: 0.100153\n",
      "[3621]\ttraining's binary_logloss: 0.100142\n",
      "[3622]\ttraining's binary_logloss: 0.100131\n",
      "[3623]\ttraining's binary_logloss: 0.10011\n",
      "[3624]\ttraining's binary_logloss: 0.100098\n",
      "[3625]\ttraining's binary_logloss: 0.100085\n",
      "[3626]\ttraining's binary_logloss: 0.100073\n",
      "[3627]\ttraining's binary_logloss: 0.100062\n",
      "[3628]\ttraining's binary_logloss: 0.100049\n",
      "[3629]\ttraining's binary_logloss: 0.100043\n",
      "[3630]\ttraining's binary_logloss: 0.100031\n",
      "[3631]\ttraining's binary_logloss: 0.10002\n",
      "[3632]\ttraining's binary_logloss: 0.100006\n",
      "[3633]\ttraining's binary_logloss: 0.0999937\n",
      "[3634]\ttraining's binary_logloss: 0.0999829\n",
      "[3635]\ttraining's binary_logloss: 0.0999727\n",
      "[3636]\ttraining's binary_logloss: 0.0999612\n",
      "[3637]\ttraining's binary_logloss: 0.0999494\n",
      "[3638]\ttraining's binary_logloss: 0.0999371\n",
      "[3639]\ttraining's binary_logloss: 0.0999268\n",
      "[3640]\ttraining's binary_logloss: 0.0999152\n",
      "[3641]\ttraining's binary_logloss: 0.0999019\n",
      "[3642]\ttraining's binary_logloss: 0.0998919\n",
      "[3643]\ttraining's binary_logloss: 0.0998803\n",
      "[3644]\ttraining's binary_logloss: 0.0998661\n",
      "[3645]\ttraining's binary_logloss: 0.0998538\n",
      "[3646]\ttraining's binary_logloss: 0.0998405\n",
      "[3647]\ttraining's binary_logloss: 0.0998272\n",
      "[3648]\ttraining's binary_logloss: 0.0998126\n",
      "[3649]\ttraining's binary_logloss: 0.0998018\n",
      "[3650]\ttraining's binary_logloss: 0.0997903\n",
      "[3651]\ttraining's binary_logloss: 0.099779\n",
      "[3652]\ttraining's binary_logloss: 0.0997672\n",
      "[3653]\ttraining's binary_logloss: 0.0997533\n",
      "[3654]\ttraining's binary_logloss: 0.0997409\n",
      "[3655]\ttraining's binary_logloss: 0.099728\n",
      "[3656]\ttraining's binary_logloss: 0.099716\n",
      "[3657]\ttraining's binary_logloss: 0.0997041\n",
      "[3658]\ttraining's binary_logloss: 0.0996925\n",
      "[3659]\ttraining's binary_logloss: 0.0996812\n",
      "[3660]\ttraining's binary_logloss: 0.0996674\n",
      "[3661]\ttraining's binary_logloss: 0.0996551\n",
      "[3662]\ttraining's binary_logloss: 0.099644\n",
      "[3663]\ttraining's binary_logloss: 0.0996316\n",
      "[3664]\ttraining's binary_logloss: 0.0996203\n",
      "[3665]\ttraining's binary_logloss: 0.0996127\n",
      "[3666]\ttraining's binary_logloss: 0.0996014\n",
      "[3667]\ttraining's binary_logloss: 0.099589\n",
      "[3668]\ttraining's binary_logloss: 0.0995758\n",
      "[3669]\ttraining's binary_logloss: 0.0995635\n",
      "[3670]\ttraining's binary_logloss: 0.0995521\n",
      "[3671]\ttraining's binary_logloss: 0.0995402\n",
      "[3672]\ttraining's binary_logloss: 0.0995336\n",
      "[3673]\ttraining's binary_logloss: 0.0995232\n",
      "[3674]\ttraining's binary_logloss: 0.099512\n",
      "[3675]\ttraining's binary_logloss: 0.0994991\n",
      "[3676]\ttraining's binary_logloss: 0.0994893\n",
      "[3677]\ttraining's binary_logloss: 0.0994781\n",
      "[3678]\ttraining's binary_logloss: 0.0994675\n",
      "[3679]\ttraining's binary_logloss: 0.099457\n",
      "[3680]\ttraining's binary_logloss: 0.0994454\n",
      "[3681]\ttraining's binary_logloss: 0.0994338\n",
      "[3682]\ttraining's binary_logloss: 0.0994222\n",
      "[3683]\ttraining's binary_logloss: 0.0994094\n",
      "[3684]\ttraining's binary_logloss: 0.0993974\n",
      "[3685]\ttraining's binary_logloss: 0.0993862\n",
      "[3686]\ttraining's binary_logloss: 0.0993744\n",
      "[3687]\ttraining's binary_logloss: 0.0993624\n",
      "[3688]\ttraining's binary_logloss: 0.0993491\n",
      "[3689]\ttraining's binary_logloss: 0.0993368\n",
      "[3690]\ttraining's binary_logloss: 0.0993324\n",
      "[3691]\ttraining's binary_logloss: 0.0993209\n",
      "[3692]\ttraining's binary_logloss: 0.0993077\n",
      "[3693]\ttraining's binary_logloss: 0.0992952\n",
      "[3694]\ttraining's binary_logloss: 0.099282\n",
      "[3695]\ttraining's binary_logloss: 0.0992708\n",
      "[3696]\ttraining's binary_logloss: 0.0992593\n",
      "[3697]\ttraining's binary_logloss: 0.0992522\n",
      "[3698]\ttraining's binary_logloss: 0.099246\n",
      "[3699]\ttraining's binary_logloss: 0.0992336\n",
      "[3700]\ttraining's binary_logloss: 0.0992273\n",
      "[3701]\ttraining's binary_logloss: 0.0992159\n",
      "[3702]\ttraining's binary_logloss: 0.0992051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3703]\ttraining's binary_logloss: 0.0991926\n",
      "[3704]\ttraining's binary_logloss: 0.099181\n",
      "[3705]\ttraining's binary_logloss: 0.0991694\n",
      "[3706]\ttraining's binary_logloss: 0.0991563\n",
      "[3707]\ttraining's binary_logloss: 0.099144\n",
      "[3708]\ttraining's binary_logloss: 0.0991308\n",
      "[3709]\ttraining's binary_logloss: 0.0991195\n",
      "[3710]\ttraining's binary_logloss: 0.0991085\n",
      "[3711]\ttraining's binary_logloss: 0.0990984\n",
      "[3712]\ttraining's binary_logloss: 0.0990899\n",
      "[3713]\ttraining's binary_logloss: 0.0990772\n",
      "[3714]\ttraining's binary_logloss: 0.0990715\n",
      "[3715]\ttraining's binary_logloss: 0.0990593\n",
      "[3716]\ttraining's binary_logloss: 0.0990483\n",
      "[3717]\ttraining's binary_logloss: 0.0990372\n",
      "[3718]\ttraining's binary_logloss: 0.0990258\n",
      "[3719]\ttraining's binary_logloss: 0.0990147\n",
      "[3720]\ttraining's binary_logloss: 0.0990025\n",
      "[3721]\ttraining's binary_logloss: 0.0989899\n",
      "[3722]\ttraining's binary_logloss: 0.0989785\n",
      "[3723]\ttraining's binary_logloss: 0.0989671\n",
      "[3724]\ttraining's binary_logloss: 0.0989564\n",
      "[3725]\ttraining's binary_logloss: 0.0989443\n",
      "[3726]\ttraining's binary_logloss: 0.0989348\n",
      "[3727]\ttraining's binary_logloss: 0.0989236\n",
      "[3728]\ttraining's binary_logloss: 0.0989109\n",
      "[3729]\ttraining's binary_logloss: 0.0988996\n",
      "[3730]\ttraining's binary_logloss: 0.0988878\n",
      "[3731]\ttraining's binary_logloss: 0.0988768\n",
      "[3732]\ttraining's binary_logloss: 0.0988705\n",
      "[3733]\ttraining's binary_logloss: 0.0988577\n",
      "[3734]\ttraining's binary_logloss: 0.098845\n",
      "[3735]\ttraining's binary_logloss: 0.0988333\n",
      "[3736]\ttraining's binary_logloss: 0.0988187\n",
      "[3737]\ttraining's binary_logloss: 0.098807\n",
      "[3738]\ttraining's binary_logloss: 0.0987962\n",
      "[3739]\ttraining's binary_logloss: 0.0987832\n",
      "[3740]\ttraining's binary_logloss: 0.0987633\n",
      "[3741]\ttraining's binary_logloss: 0.0987525\n",
      "[3742]\ttraining's binary_logloss: 0.0987404\n",
      "[3743]\ttraining's binary_logloss: 0.0987324\n",
      "[3744]\ttraining's binary_logloss: 0.0987215\n",
      "[3745]\ttraining's binary_logloss: 0.0987106\n",
      "[3746]\ttraining's binary_logloss: 0.098704\n",
      "[3747]\ttraining's binary_logloss: 0.0986939\n",
      "[3748]\ttraining's binary_logloss: 0.0986816\n",
      "[3749]\ttraining's binary_logloss: 0.098669\n",
      "[3750]\ttraining's binary_logloss: 0.0986579\n",
      "[3751]\ttraining's binary_logloss: 0.0986531\n",
      "[3752]\ttraining's binary_logloss: 0.0986399\n",
      "[3753]\ttraining's binary_logloss: 0.0986275\n",
      "[3754]\ttraining's binary_logloss: 0.0986169\n",
      "[3755]\ttraining's binary_logloss: 0.0986071\n",
      "[3756]\ttraining's binary_logloss: 0.0986022\n",
      "[3757]\ttraining's binary_logloss: 0.0985887\n",
      "[3758]\ttraining's binary_logloss: 0.098578\n",
      "[3759]\ttraining's binary_logloss: 0.0985653\n",
      "[3760]\ttraining's binary_logloss: 0.09856\n",
      "[3761]\ttraining's binary_logloss: 0.098553\n",
      "[3762]\ttraining's binary_logloss: 0.0985414\n",
      "[3763]\ttraining's binary_logloss: 0.0985301\n",
      "[3764]\ttraining's binary_logloss: 0.0985191\n",
      "[3765]\ttraining's binary_logloss: 0.0985089\n",
      "[3766]\ttraining's binary_logloss: 0.098498\n",
      "[3767]\ttraining's binary_logloss: 0.0984927\n",
      "[3768]\ttraining's binary_logloss: 0.0984817\n",
      "[3769]\ttraining's binary_logloss: 0.0984707\n",
      "[3770]\ttraining's binary_logloss: 0.098458\n",
      "[3771]\ttraining's binary_logloss: 0.0984533\n",
      "[3772]\ttraining's binary_logloss: 0.0984402\n",
      "[3773]\ttraining's binary_logloss: 0.0984288\n",
      "[3774]\ttraining's binary_logloss: 0.0984172\n",
      "[3775]\ttraining's binary_logloss: 0.0984059\n",
      "[3776]\ttraining's binary_logloss: 0.0983947\n",
      "[3777]\ttraining's binary_logloss: 0.098383\n",
      "[3778]\ttraining's binary_logloss: 0.0983748\n",
      "[3779]\ttraining's binary_logloss: 0.0983687\n",
      "[3780]\ttraining's binary_logloss: 0.0983581\n",
      "[3781]\ttraining's binary_logloss: 0.0983475\n",
      "[3782]\ttraining's binary_logloss: 0.0983352\n",
      "[3783]\ttraining's binary_logloss: 0.0983293\n",
      "[3784]\ttraining's binary_logloss: 0.0983177\n",
      "[3785]\ttraining's binary_logloss: 0.0983076\n",
      "[3786]\ttraining's binary_logloss: 0.0983025\n",
      "[3787]\ttraining's binary_logloss: 0.0982916\n",
      "[3788]\ttraining's binary_logloss: 0.0982808\n",
      "[3789]\ttraining's binary_logloss: 0.0982696\n",
      "[3790]\ttraining's binary_logloss: 0.0982596\n",
      "[3791]\ttraining's binary_logloss: 0.0982471\n",
      "[3792]\ttraining's binary_logloss: 0.0982351\n",
      "[3793]\ttraining's binary_logloss: 0.0982239\n",
      "[3794]\ttraining's binary_logloss: 0.0982157\n",
      "[3795]\ttraining's binary_logloss: 0.0982047\n",
      "[3796]\ttraining's binary_logloss: 0.0981947\n",
      "[3797]\ttraining's binary_logloss: 0.0981839\n",
      "[3798]\ttraining's binary_logloss: 0.0981726\n",
      "[3799]\ttraining's binary_logloss: 0.0981648\n",
      "[3800]\ttraining's binary_logloss: 0.0981527\n",
      "[3801]\ttraining's binary_logloss: 0.0981415\n",
      "[3802]\ttraining's binary_logloss: 0.0981296\n",
      "[3803]\ttraining's binary_logloss: 0.0981098\n",
      "[3804]\ttraining's binary_logloss: 0.0980973\n",
      "[3805]\ttraining's binary_logloss: 0.0980866\n",
      "[3806]\ttraining's binary_logloss: 0.0980738\n",
      "[3807]\ttraining's binary_logloss: 0.0980625\n",
      "[3808]\ttraining's binary_logloss: 0.0980512\n",
      "[3809]\ttraining's binary_logloss: 0.0980393\n",
      "[3810]\ttraining's binary_logloss: 0.0980291\n",
      "[3811]\ttraining's binary_logloss: 0.0980103\n",
      "[3812]\ttraining's binary_logloss: 0.0980008\n",
      "[3813]\ttraining's binary_logloss: 0.0979887\n",
      "[3814]\ttraining's binary_logloss: 0.0979754\n",
      "[3815]\ttraining's binary_logloss: 0.0979652\n",
      "[3816]\ttraining's binary_logloss: 0.0979528\n",
      "[3817]\ttraining's binary_logloss: 0.0979418\n",
      "[3818]\ttraining's binary_logloss: 0.0979322\n",
      "[3819]\ttraining's binary_logloss: 0.0979232\n",
      "[3820]\ttraining's binary_logloss: 0.0979101\n",
      "[3821]\ttraining's binary_logloss: 0.0979002\n",
      "[3822]\ttraining's binary_logloss: 0.0978893\n",
      "[3823]\ttraining's binary_logloss: 0.0978861\n",
      "[3824]\ttraining's binary_logloss: 0.0978741\n",
      "[3825]\ttraining's binary_logloss: 0.0978625\n",
      "[3826]\ttraining's binary_logloss: 0.0978507\n",
      "[3827]\ttraining's binary_logloss: 0.0978386\n",
      "[3828]\ttraining's binary_logloss: 0.097827\n",
      "[3829]\ttraining's binary_logloss: 0.0978159\n",
      "[3830]\ttraining's binary_logloss: 0.0978052\n",
      "[3831]\ttraining's binary_logloss: 0.0977936\n",
      "[3832]\ttraining's binary_logloss: 0.0977821\n",
      "[3833]\ttraining's binary_logloss: 0.0977702\n",
      "[3834]\ttraining's binary_logloss: 0.0977604\n",
      "[3835]\ttraining's binary_logloss: 0.0977496\n",
      "[3836]\ttraining's binary_logloss: 0.0977367\n",
      "[3837]\ttraining's binary_logloss: 0.097725\n",
      "[3838]\ttraining's binary_logloss: 0.0977157\n",
      "[3839]\ttraining's binary_logloss: 0.0977039\n",
      "[3840]\ttraining's binary_logloss: 0.0976926\n",
      "[3841]\ttraining's binary_logloss: 0.0976815\n",
      "[3842]\ttraining's binary_logloss: 0.0976712\n",
      "[3843]\ttraining's binary_logloss: 0.097659\n",
      "[3844]\ttraining's binary_logloss: 0.0976511\n",
      "[3845]\ttraining's binary_logloss: 0.0976454\n",
      "[3846]\ttraining's binary_logloss: 0.0976348\n",
      "[3847]\ttraining's binary_logloss: 0.097622\n",
      "[3848]\ttraining's binary_logloss: 0.0976106\n",
      "[3849]\ttraining's binary_logloss: 0.0975997\n",
      "[3850]\ttraining's binary_logloss: 0.0975875\n",
      "[3851]\ttraining's binary_logloss: 0.0975748\n",
      "[3852]\ttraining's binary_logloss: 0.0975633\n",
      "[3853]\ttraining's binary_logloss: 0.0975517\n",
      "[3854]\ttraining's binary_logloss: 0.0975418\n",
      "[3855]\ttraining's binary_logloss: 0.0975369\n",
      "[3856]\ttraining's binary_logloss: 0.0975265\n",
      "[3857]\ttraining's binary_logloss: 0.0975138\n",
      "[3858]\ttraining's binary_logloss: 0.0975013\n",
      "[3859]\ttraining's binary_logloss: 0.0974906\n",
      "[3860]\ttraining's binary_logloss: 0.0974808\n",
      "[3861]\ttraining's binary_logloss: 0.0974756\n",
      "[3862]\ttraining's binary_logloss: 0.097464\n",
      "[3863]\ttraining's binary_logloss: 0.0974521\n",
      "[3864]\ttraining's binary_logloss: 0.0974471\n",
      "[3865]\ttraining's binary_logloss: 0.0974362\n",
      "[3866]\ttraining's binary_logloss: 0.0974261\n",
      "[3867]\ttraining's binary_logloss: 0.0974139\n",
      "[3868]\ttraining's binary_logloss: 0.0974021\n",
      "[3869]\ttraining's binary_logloss: 0.0973899\n",
      "[3870]\ttraining's binary_logloss: 0.0973771\n",
      "[3871]\ttraining's binary_logloss: 0.0973656\n",
      "[3872]\ttraining's binary_logloss: 0.0973573\n",
      "[3873]\ttraining's binary_logloss: 0.097346\n",
      "[3874]\ttraining's binary_logloss: 0.0973346\n",
      "[3875]\ttraining's binary_logloss: 0.0973288\n",
      "[3876]\ttraining's binary_logloss: 0.0973168\n",
      "[3877]\ttraining's binary_logloss: 0.0973087\n",
      "[3878]\ttraining's binary_logloss: 0.0972963\n",
      "[3879]\ttraining's binary_logloss: 0.0972836\n",
      "[3880]\ttraining's binary_logloss: 0.0972727\n",
      "[3881]\ttraining's binary_logloss: 0.0972582\n",
      "[3882]\ttraining's binary_logloss: 0.0972481\n",
      "[3883]\ttraining's binary_logloss: 0.0972369\n",
      "[3884]\ttraining's binary_logloss: 0.0972295\n",
      "[3885]\ttraining's binary_logloss: 0.0972175\n",
      "[3886]\ttraining's binary_logloss: 0.0972065\n",
      "[3887]\ttraining's binary_logloss: 0.0971944\n",
      "[3888]\ttraining's binary_logloss: 0.0971827\n",
      "[3889]\ttraining's binary_logloss: 0.0971715\n",
      "[3890]\ttraining's binary_logloss: 0.0971593\n",
      "[3891]\ttraining's binary_logloss: 0.0971484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3892]\ttraining's binary_logloss: 0.0971375\n",
      "[3893]\ttraining's binary_logloss: 0.0971267\n",
      "[3894]\ttraining's binary_logloss: 0.0971139\n",
      "[3895]\ttraining's binary_logloss: 0.0971033\n",
      "[3896]\ttraining's binary_logloss: 0.097094\n",
      "[3897]\ttraining's binary_logloss: 0.0970841\n",
      "[3898]\ttraining's binary_logloss: 0.097073\n",
      "[3899]\ttraining's binary_logloss: 0.0970666\n",
      "[3900]\ttraining's binary_logloss: 0.0970562\n",
      "[3901]\ttraining's binary_logloss: 0.0970421\n",
      "[3902]\ttraining's binary_logloss: 0.0970305\n",
      "[3903]\ttraining's binary_logloss: 0.0970169\n",
      "[3904]\ttraining's binary_logloss: 0.0970046\n",
      "[3905]\ttraining's binary_logloss: 0.0969941\n",
      "[3906]\ttraining's binary_logloss: 0.0969822\n",
      "[3907]\ttraining's binary_logloss: 0.0969672\n",
      "[3908]\ttraining's binary_logloss: 0.0969576\n",
      "[3909]\ttraining's binary_logloss: 0.0969475\n",
      "[3910]\ttraining's binary_logloss: 0.0969353\n",
      "[3911]\ttraining's binary_logloss: 0.0969259\n",
      "[3912]\ttraining's binary_logloss: 0.0969149\n",
      "[3913]\ttraining's binary_logloss: 0.0969044\n",
      "[3914]\ttraining's binary_logloss: 0.0968921\n",
      "[3915]\ttraining's binary_logloss: 0.0968803\n",
      "[3916]\ttraining's binary_logloss: 0.0968694\n",
      "[3917]\ttraining's binary_logloss: 0.0968625\n",
      "[3918]\ttraining's binary_logloss: 0.0968498\n",
      "[3919]\ttraining's binary_logloss: 0.0968399\n",
      "[3920]\ttraining's binary_logloss: 0.0968338\n",
      "[3921]\ttraining's binary_logloss: 0.0968235\n",
      "[3922]\ttraining's binary_logloss: 0.0968162\n",
      "[3923]\ttraining's binary_logloss: 0.0968036\n",
      "[3924]\ttraining's binary_logloss: 0.0967931\n",
      "[3925]\ttraining's binary_logloss: 0.0967824\n",
      "[3926]\ttraining's binary_logloss: 0.0967702\n",
      "[3927]\ttraining's binary_logloss: 0.0967638\n",
      "[3928]\ttraining's binary_logloss: 0.0967531\n",
      "[3929]\ttraining's binary_logloss: 0.0967421\n",
      "[3930]\ttraining's binary_logloss: 0.0967299\n",
      "[3931]\ttraining's binary_logloss: 0.0967187\n",
      "[3932]\ttraining's binary_logloss: 0.0967089\n",
      "[3933]\ttraining's binary_logloss: 0.0966954\n",
      "[3934]\ttraining's binary_logloss: 0.0966875\n",
      "[3935]\ttraining's binary_logloss: 0.0966751\n",
      "[3936]\ttraining's binary_logloss: 0.0966639\n",
      "[3937]\ttraining's binary_logloss: 0.0966512\n",
      "[3938]\ttraining's binary_logloss: 0.0966403\n",
      "[3939]\ttraining's binary_logloss: 0.0966366\n",
      "[3940]\ttraining's binary_logloss: 0.0966263\n",
      "[3941]\ttraining's binary_logloss: 0.0966147\n",
      "[3942]\ttraining's binary_logloss: 0.0966038\n",
      "[3943]\ttraining's binary_logloss: 0.0965918\n",
      "[3944]\ttraining's binary_logloss: 0.0965802\n",
      "[3945]\ttraining's binary_logloss: 0.0965704\n",
      "[3946]\ttraining's binary_logloss: 0.0965554\n",
      "[3947]\ttraining's binary_logloss: 0.096545\n",
      "[3948]\ttraining's binary_logloss: 0.0965334\n",
      "[3949]\ttraining's binary_logloss: 0.0965207\n",
      "[3950]\ttraining's binary_logloss: 0.0965119\n",
      "[3951]\ttraining's binary_logloss: 0.0964942\n",
      "[3952]\ttraining's binary_logloss: 0.096482\n",
      "[3953]\ttraining's binary_logloss: 0.0964708\n",
      "[3954]\ttraining's binary_logloss: 0.0964567\n",
      "[3955]\ttraining's binary_logloss: 0.0964464\n",
      "[3956]\ttraining's binary_logloss: 0.0964345\n",
      "[3957]\ttraining's binary_logloss: 0.0964236\n",
      "[3958]\ttraining's binary_logloss: 0.0964123\n",
      "[3959]\ttraining's binary_logloss: 0.0964007\n",
      "[3960]\ttraining's binary_logloss: 0.0963901\n",
      "[3961]\ttraining's binary_logloss: 0.0963803\n",
      "[3962]\ttraining's binary_logloss: 0.0963697\n",
      "[3963]\ttraining's binary_logloss: 0.0963589\n",
      "[3964]\ttraining's binary_logloss: 0.096349\n",
      "[3965]\ttraining's binary_logloss: 0.0963378\n",
      "[3966]\ttraining's binary_logloss: 0.0963302\n",
      "[3967]\ttraining's binary_logloss: 0.0963171\n",
      "[3968]\ttraining's binary_logloss: 0.0963029\n",
      "[3969]\ttraining's binary_logloss: 0.0962921\n",
      "[3970]\ttraining's binary_logloss: 0.0962797\n",
      "[3971]\ttraining's binary_logloss: 0.0962678\n",
      "[3972]\ttraining's binary_logloss: 0.0962618\n",
      "[3973]\ttraining's binary_logloss: 0.0962499\n",
      "[3974]\ttraining's binary_logloss: 0.0962439\n",
      "[3975]\ttraining's binary_logloss: 0.096234\n",
      "[3976]\ttraining's binary_logloss: 0.0962236\n",
      "[3977]\ttraining's binary_logloss: 0.0962102\n",
      "[3978]\ttraining's binary_logloss: 0.0961999\n",
      "[3979]\ttraining's binary_logloss: 0.0961877\n",
      "[3980]\ttraining's binary_logloss: 0.0961751\n",
      "[3981]\ttraining's binary_logloss: 0.096163\n",
      "[3982]\ttraining's binary_logloss: 0.0961505\n",
      "[3983]\ttraining's binary_logloss: 0.0961399\n",
      "[3984]\ttraining's binary_logloss: 0.0961278\n",
      "[3985]\ttraining's binary_logloss: 0.0961215\n",
      "[3986]\ttraining's binary_logloss: 0.0961079\n",
      "[3987]\ttraining's binary_logloss: 0.0960993\n",
      "[3988]\ttraining's binary_logloss: 0.0960883\n",
      "[3989]\ttraining's binary_logloss: 0.0960791\n",
      "[3990]\ttraining's binary_logloss: 0.0960688\n",
      "[3991]\ttraining's binary_logloss: 0.0960573\n",
      "[3992]\ttraining's binary_logloss: 0.0960451\n",
      "[3993]\ttraining's binary_logloss: 0.0960328\n",
      "[3994]\ttraining's binary_logloss: 0.0960198\n",
      "[3995]\ttraining's binary_logloss: 0.0960107\n",
      "[3996]\ttraining's binary_logloss: 0.0959994\n",
      "[3997]\ttraining's binary_logloss: 0.0959887\n",
      "[3998]\ttraining's binary_logloss: 0.0959756\n",
      "[3999]\ttraining's binary_logloss: 0.0959647\n",
      "[4000]\ttraining's binary_logloss: 0.0959535\n",
      "[4001]\ttraining's binary_logloss: 0.0959495\n",
      "[4002]\ttraining's binary_logloss: 0.0959369\n",
      "[4003]\ttraining's binary_logloss: 0.095924\n",
      "[4004]\ttraining's binary_logloss: 0.0959134\n",
      "[4005]\ttraining's binary_logloss: 0.0959015\n",
      "[4006]\ttraining's binary_logloss: 0.0958853\n",
      "[4007]\ttraining's binary_logloss: 0.0958754\n",
      "[4008]\ttraining's binary_logloss: 0.0958727\n",
      "[4009]\ttraining's binary_logloss: 0.0958601\n",
      "[4010]\ttraining's binary_logloss: 0.0958479\n",
      "[4011]\ttraining's binary_logloss: 0.0958454\n",
      "[4012]\ttraining's binary_logloss: 0.0958317\n",
      "[4013]\ttraining's binary_logloss: 0.0958211\n",
      "[4014]\ttraining's binary_logloss: 0.0958114\n",
      "[4015]\ttraining's binary_logloss: 0.0958054\n",
      "[4016]\ttraining's binary_logloss: 0.0957956\n",
      "[4017]\ttraining's binary_logloss: 0.0957843\n",
      "[4018]\ttraining's binary_logloss: 0.0957736\n",
      "[4019]\ttraining's binary_logloss: 0.0957638\n",
      "[4020]\ttraining's binary_logloss: 0.0957521\n",
      "[4021]\ttraining's binary_logloss: 0.0957412\n",
      "[4022]\ttraining's binary_logloss: 0.0957284\n",
      "[4023]\ttraining's binary_logloss: 0.0957172\n",
      "[4024]\ttraining's binary_logloss: 0.0957077\n",
      "[4025]\ttraining's binary_logloss: 0.0956945\n",
      "[4026]\ttraining's binary_logloss: 0.0956843\n",
      "[4027]\ttraining's binary_logloss: 0.0956695\n",
      "[4028]\ttraining's binary_logloss: 0.0956593\n",
      "[4029]\ttraining's binary_logloss: 0.0956491\n",
      "[4030]\ttraining's binary_logloss: 0.0956406\n",
      "[4031]\ttraining's binary_logloss: 0.0956285\n",
      "[4032]\ttraining's binary_logloss: 0.0956178\n",
      "[4033]\ttraining's binary_logloss: 0.0956073\n",
      "[4034]\ttraining's binary_logloss: 0.0955973\n",
      "[4035]\ttraining's binary_logloss: 0.0955855\n",
      "[4036]\ttraining's binary_logloss: 0.0955742\n",
      "[4037]\ttraining's binary_logloss: 0.0955632\n",
      "[4038]\ttraining's binary_logloss: 0.0955514\n",
      "[4039]\ttraining's binary_logloss: 0.0955436\n",
      "[4040]\ttraining's binary_logloss: 0.0955321\n",
      "[4041]\ttraining's binary_logloss: 0.0955237\n",
      "[4042]\ttraining's binary_logloss: 0.0955157\n",
      "[4043]\ttraining's binary_logloss: 0.0955052\n",
      "[4044]\ttraining's binary_logloss: 0.0954939\n",
      "[4045]\ttraining's binary_logloss: 0.0954842\n",
      "[4046]\ttraining's binary_logloss: 0.0954729\n",
      "[4047]\ttraining's binary_logloss: 0.0954602\n",
      "[4048]\ttraining's binary_logloss: 0.0954491\n",
      "[4049]\ttraining's binary_logloss: 0.0954362\n",
      "[4050]\ttraining's binary_logloss: 0.0954255\n",
      "[4051]\ttraining's binary_logloss: 0.0954206\n",
      "[4052]\ttraining's binary_logloss: 0.0954105\n",
      "[4053]\ttraining's binary_logloss: 0.0954001\n",
      "[4054]\ttraining's binary_logloss: 0.0953884\n",
      "[4055]\ttraining's binary_logloss: 0.0953784\n",
      "[4056]\ttraining's binary_logloss: 0.0953676\n",
      "[4057]\ttraining's binary_logloss: 0.0953553\n",
      "[4058]\ttraining's binary_logloss: 0.0953466\n",
      "[4059]\ttraining's binary_logloss: 0.0953369\n",
      "[4060]\ttraining's binary_logloss: 0.0953238\n",
      "[4061]\ttraining's binary_logloss: 0.0953122\n",
      "[4062]\ttraining's binary_logloss: 0.0953004\n",
      "[4063]\ttraining's binary_logloss: 0.095287\n",
      "[4064]\ttraining's binary_logloss: 0.0952772\n",
      "[4065]\ttraining's binary_logloss: 0.0952633\n",
      "[4066]\ttraining's binary_logloss: 0.0952519\n",
      "[4067]\ttraining's binary_logloss: 0.0952407\n",
      "[4068]\ttraining's binary_logloss: 0.0952312\n",
      "[4069]\ttraining's binary_logloss: 0.0952184\n",
      "[4070]\ttraining's binary_logloss: 0.0952102\n",
      "[4071]\ttraining's binary_logloss: 0.0952005\n",
      "[4072]\ttraining's binary_logloss: 0.0951898\n",
      "[4073]\ttraining's binary_logloss: 0.0951787\n",
      "[4074]\ttraining's binary_logloss: 0.0951678\n",
      "[4075]\ttraining's binary_logloss: 0.0951573\n",
      "[4076]\ttraining's binary_logloss: 0.0951455\n",
      "[4077]\ttraining's binary_logloss: 0.0951401\n",
      "[4078]\ttraining's binary_logloss: 0.0951282\n",
      "[4079]\ttraining's binary_logloss: 0.0951193\n",
      "[4080]\ttraining's binary_logloss: 0.0951076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4081]\ttraining's binary_logloss: 0.0950968\n",
      "[4082]\ttraining's binary_logloss: 0.0950857\n",
      "[4083]\ttraining's binary_logloss: 0.0950748\n",
      "[4084]\ttraining's binary_logloss: 0.0950708\n",
      "[4085]\ttraining's binary_logloss: 0.0950599\n",
      "[4086]\ttraining's binary_logloss: 0.0950489\n",
      "[4087]\ttraining's binary_logloss: 0.0950388\n",
      "[4088]\ttraining's binary_logloss: 0.095029\n",
      "[4089]\ttraining's binary_logloss: 0.0950185\n",
      "[4090]\ttraining's binary_logloss: 0.095006\n",
      "[4091]\ttraining's binary_logloss: 0.0949949\n",
      "[4092]\ttraining's binary_logloss: 0.0949834\n",
      "[4093]\ttraining's binary_logloss: 0.0949729\n",
      "[4094]\ttraining's binary_logloss: 0.094962\n",
      "[4095]\ttraining's binary_logloss: 0.0949523\n",
      "[4096]\ttraining's binary_logloss: 0.0949423\n",
      "[4097]\ttraining's binary_logloss: 0.0949317\n",
      "[4098]\ttraining's binary_logloss: 0.0949196\n",
      "[4099]\ttraining's binary_logloss: 0.0949078\n",
      "[4100]\ttraining's binary_logloss: 0.0948976\n",
      "[4101]\ttraining's binary_logloss: 0.0948861\n",
      "[4102]\ttraining's binary_logloss: 0.0948686\n",
      "[4103]\ttraining's binary_logloss: 0.094859\n",
      "[4104]\ttraining's binary_logloss: 0.0948487\n",
      "[4105]\ttraining's binary_logloss: 0.0948468\n",
      "[4106]\ttraining's binary_logloss: 0.0948346\n",
      "[4107]\ttraining's binary_logloss: 0.0948234\n",
      "[4108]\ttraining's binary_logloss: 0.0948115\n",
      "[4109]\ttraining's binary_logloss: 0.0948044\n",
      "[4110]\ttraining's binary_logloss: 0.0947939\n",
      "[4111]\ttraining's binary_logloss: 0.0947826\n",
      "[4112]\ttraining's binary_logloss: 0.094771\n",
      "[4113]\ttraining's binary_logloss: 0.0947596\n",
      "[4114]\ttraining's binary_logloss: 0.0947491\n",
      "[4115]\ttraining's binary_logloss: 0.0947427\n",
      "[4116]\ttraining's binary_logloss: 0.0947324\n",
      "[4117]\ttraining's binary_logloss: 0.0947211\n",
      "[4118]\ttraining's binary_logloss: 0.0947106\n",
      "[4119]\ttraining's binary_logloss: 0.0946992\n",
      "[4120]\ttraining's binary_logloss: 0.0946874\n",
      "[4121]\ttraining's binary_logloss: 0.0946813\n",
      "[4122]\ttraining's binary_logloss: 0.0946696\n",
      "[4123]\ttraining's binary_logloss: 0.0946582\n",
      "[4124]\ttraining's binary_logloss: 0.094649\n",
      "[4125]\ttraining's binary_logloss: 0.0946382\n",
      "[4126]\ttraining's binary_logloss: 0.0946265\n",
      "[4127]\ttraining's binary_logloss: 0.0946141\n",
      "[4128]\ttraining's binary_logloss: 0.0946068\n",
      "[4129]\ttraining's binary_logloss: 0.0945954\n",
      "[4130]\ttraining's binary_logloss: 0.0945849\n",
      "[4131]\ttraining's binary_logloss: 0.0945743\n",
      "[4132]\ttraining's binary_logloss: 0.0945629\n",
      "[4133]\ttraining's binary_logloss: 0.0945524\n",
      "[4134]\ttraining's binary_logloss: 0.0945409\n",
      "[4135]\ttraining's binary_logloss: 0.094529\n",
      "[4136]\ttraining's binary_logloss: 0.0945171\n",
      "[4137]\ttraining's binary_logloss: 0.0945064\n",
      "[4138]\ttraining's binary_logloss: 0.0944951\n",
      "[4139]\ttraining's binary_logloss: 0.0944853\n",
      "[4140]\ttraining's binary_logloss: 0.094475\n",
      "[4141]\ttraining's binary_logloss: 0.094463\n",
      "[4142]\ttraining's binary_logloss: 0.0944508\n",
      "[4143]\ttraining's binary_logloss: 0.0944424\n",
      "[4144]\ttraining's binary_logloss: 0.0944326\n",
      "[4145]\ttraining's binary_logloss: 0.0944194\n",
      "[4146]\ttraining's binary_logloss: 0.0944127\n",
      "[4147]\ttraining's binary_logloss: 0.0944071\n",
      "[4148]\ttraining's binary_logloss: 0.0943969\n",
      "[4149]\ttraining's binary_logloss: 0.0943845\n",
      "[4150]\ttraining's binary_logloss: 0.0943765\n",
      "[4151]\ttraining's binary_logloss: 0.0943661\n",
      "[4152]\ttraining's binary_logloss: 0.0943568\n",
      "[4153]\ttraining's binary_logloss: 0.0943465\n",
      "[4154]\ttraining's binary_logloss: 0.0943352\n",
      "[4155]\ttraining's binary_logloss: 0.094325\n",
      "[4156]\ttraining's binary_logloss: 0.0943144\n",
      "[4157]\ttraining's binary_logloss: 0.0943081\n",
      "[4158]\ttraining's binary_logloss: 0.0942968\n",
      "[4159]\ttraining's binary_logloss: 0.0942865\n",
      "[4160]\ttraining's binary_logloss: 0.0942758\n",
      "[4161]\ttraining's binary_logloss: 0.0942638\n",
      "[4162]\ttraining's binary_logloss: 0.0942547\n",
      "[4163]\ttraining's binary_logloss: 0.0942424\n",
      "[4164]\ttraining's binary_logloss: 0.094233\n",
      "[4165]\ttraining's binary_logloss: 0.0942222\n",
      "[4166]\ttraining's binary_logloss: 0.094212\n",
      "[4167]\ttraining's binary_logloss: 0.0942018\n",
      "[4168]\ttraining's binary_logloss: 0.0941918\n",
      "[4169]\ttraining's binary_logloss: 0.0941808\n",
      "[4170]\ttraining's binary_logloss: 0.09417\n",
      "[4171]\ttraining's binary_logloss: 0.0941587\n",
      "[4172]\ttraining's binary_logloss: 0.0941539\n",
      "[4173]\ttraining's binary_logloss: 0.0941441\n",
      "[4174]\ttraining's binary_logloss: 0.094133\n",
      "[4175]\ttraining's binary_logloss: 0.0941211\n",
      "[4176]\ttraining's binary_logloss: 0.0941113\n",
      "[4177]\ttraining's binary_logloss: 0.0941018\n",
      "[4178]\ttraining's binary_logloss: 0.0940919\n",
      "[4179]\ttraining's binary_logloss: 0.0940802\n",
      "[4180]\ttraining's binary_logloss: 0.0940693\n",
      "[4181]\ttraining's binary_logloss: 0.0940576\n",
      "[4182]\ttraining's binary_logloss: 0.0940461\n",
      "[4183]\ttraining's binary_logloss: 0.0940364\n",
      "[4184]\ttraining's binary_logloss: 0.0940281\n",
      "[4185]\ttraining's binary_logloss: 0.0940178\n",
      "[4186]\ttraining's binary_logloss: 0.0940109\n",
      "[4187]\ttraining's binary_logloss: 0.093999\n",
      "[4188]\ttraining's binary_logloss: 0.0939881\n",
      "[4189]\ttraining's binary_logloss: 0.0939788\n",
      "[4190]\ttraining's binary_logloss: 0.0939684\n",
      "[4191]\ttraining's binary_logloss: 0.0939546\n",
      "[4192]\ttraining's binary_logloss: 0.0939443\n",
      "[4193]\ttraining's binary_logloss: 0.0939396\n",
      "[4194]\ttraining's binary_logloss: 0.0939358\n",
      "[4195]\ttraining's binary_logloss: 0.0939244\n",
      "[4196]\ttraining's binary_logloss: 0.0939141\n",
      "[4197]\ttraining's binary_logloss: 0.0939018\n",
      "[4198]\ttraining's binary_logloss: 0.093891\n",
      "[4199]\ttraining's binary_logloss: 0.0938791\n",
      "[4200]\ttraining's binary_logloss: 0.0938686\n",
      "[4201]\ttraining's binary_logloss: 0.0938588\n",
      "[4202]\ttraining's binary_logloss: 0.0938485\n",
      "[4203]\ttraining's binary_logloss: 0.0938436\n",
      "[4204]\ttraining's binary_logloss: 0.0938317\n",
      "[4205]\ttraining's binary_logloss: 0.0938209\n",
      "[4206]\ttraining's binary_logloss: 0.0938101\n",
      "[4207]\ttraining's binary_logloss: 0.0937978\n",
      "[4208]\ttraining's binary_logloss: 0.0937953\n",
      "[4209]\ttraining's binary_logloss: 0.0937826\n",
      "[4210]\ttraining's binary_logloss: 0.0937705\n",
      "[4211]\ttraining's binary_logloss: 0.0937596\n",
      "[4212]\ttraining's binary_logloss: 0.0937486\n",
      "[4213]\ttraining's binary_logloss: 0.0937381\n",
      "[4214]\ttraining's binary_logloss: 0.0937258\n",
      "[4215]\ttraining's binary_logloss: 0.0937145\n",
      "[4216]\ttraining's binary_logloss: 0.0937104\n",
      "[4217]\ttraining's binary_logloss: 0.0936989\n",
      "[4218]\ttraining's binary_logloss: 0.0936895\n",
      "[4219]\ttraining's binary_logloss: 0.0936789\n",
      "[4220]\ttraining's binary_logloss: 0.0936671\n",
      "[4221]\ttraining's binary_logloss: 0.093656\n",
      "[4222]\ttraining's binary_logloss: 0.0936411\n",
      "[4223]\ttraining's binary_logloss: 0.0936276\n",
      "[4224]\ttraining's binary_logloss: 0.0936167\n",
      "[4225]\ttraining's binary_logloss: 0.0936075\n",
      "[4226]\ttraining's binary_logloss: 0.0935969\n",
      "[4227]\ttraining's binary_logloss: 0.0935873\n",
      "[4228]\ttraining's binary_logloss: 0.0935745\n",
      "[4229]\ttraining's binary_logloss: 0.0935625\n",
      "[4230]\ttraining's binary_logloss: 0.0935513\n",
      "[4231]\ttraining's binary_logloss: 0.0935422\n",
      "[4232]\ttraining's binary_logloss: 0.0935315\n",
      "[4233]\ttraining's binary_logloss: 0.0935196\n",
      "[4234]\ttraining's binary_logloss: 0.0935081\n",
      "[4235]\ttraining's binary_logloss: 0.0934965\n",
      "[4236]\ttraining's binary_logloss: 0.0934925\n",
      "[4237]\ttraining's binary_logloss: 0.0934792\n",
      "[4238]\ttraining's binary_logloss: 0.093468\n",
      "[4239]\ttraining's binary_logloss: 0.0934568\n",
      "[4240]\ttraining's binary_logloss: 0.093447\n",
      "[4241]\ttraining's binary_logloss: 0.0934359\n",
      "[4242]\ttraining's binary_logloss: 0.0934217\n",
      "[4243]\ttraining's binary_logloss: 0.0934105\n",
      "[4244]\ttraining's binary_logloss: 0.0933995\n",
      "[4245]\ttraining's binary_logloss: 0.093387\n",
      "[4246]\ttraining's binary_logloss: 0.0933756\n",
      "[4247]\ttraining's binary_logloss: 0.0933643\n",
      "[4248]\ttraining's binary_logloss: 0.093355\n",
      "[4249]\ttraining's binary_logloss: 0.0933452\n",
      "[4250]\ttraining's binary_logloss: 0.0933391\n",
      "[4251]\ttraining's binary_logloss: 0.093332\n",
      "[4252]\ttraining's binary_logloss: 0.0933229\n",
      "[4253]\ttraining's binary_logloss: 0.0933118\n",
      "[4254]\ttraining's binary_logloss: 0.0933018\n",
      "[4255]\ttraining's binary_logloss: 0.0932901\n",
      "[4256]\ttraining's binary_logloss: 0.0932792\n",
      "[4257]\ttraining's binary_logloss: 0.093266\n",
      "[4258]\ttraining's binary_logloss: 0.0932566\n",
      "[4259]\ttraining's binary_logloss: 0.0932465\n",
      "[4260]\ttraining's binary_logloss: 0.0932349\n",
      "[4261]\ttraining's binary_logloss: 0.0932244\n",
      "[4262]\ttraining's binary_logloss: 0.0932137\n",
      "[4263]\ttraining's binary_logloss: 0.0932033\n",
      "[4264]\ttraining's binary_logloss: 0.0931935\n",
      "[4265]\ttraining's binary_logloss: 0.0931867\n",
      "[4266]\ttraining's binary_logloss: 0.0931764\n",
      "[4267]\ttraining's binary_logloss: 0.093162\n",
      "[4268]\ttraining's binary_logloss: 0.0931506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4269]\ttraining's binary_logloss: 0.0931403\n",
      "[4270]\ttraining's binary_logloss: 0.0931302\n",
      "[4271]\ttraining's binary_logloss: 0.0931267\n",
      "[4272]\ttraining's binary_logloss: 0.0931175\n",
      "[4273]\ttraining's binary_logloss: 0.093107\n",
      "[4274]\ttraining's binary_logloss: 0.0930965\n",
      "[4275]\ttraining's binary_logloss: 0.0930875\n",
      "[4276]\ttraining's binary_logloss: 0.0930778\n",
      "[4277]\ttraining's binary_logloss: 0.0930667\n",
      "[4278]\ttraining's binary_logloss: 0.0930559\n",
      "[4279]\ttraining's binary_logloss: 0.0930465\n",
      "[4280]\ttraining's binary_logloss: 0.0930345\n",
      "[4281]\ttraining's binary_logloss: 0.0930248\n",
      "[4282]\ttraining's binary_logloss: 0.0930129\n",
      "[4283]\ttraining's binary_logloss: 0.0930054\n",
      "[4284]\ttraining's binary_logloss: 0.0929945\n",
      "[4285]\ttraining's binary_logloss: 0.0929824\n",
      "[4286]\ttraining's binary_logloss: 0.0929731\n",
      "[4287]\ttraining's binary_logloss: 0.0929708\n",
      "[4288]\ttraining's binary_logloss: 0.09296\n",
      "[4289]\ttraining's binary_logloss: 0.0929495\n",
      "[4290]\ttraining's binary_logloss: 0.09294\n",
      "[4291]\ttraining's binary_logloss: 0.0929296\n",
      "[4292]\ttraining's binary_logloss: 0.0929186\n",
      "[4293]\ttraining's binary_logloss: 0.09291\n",
      "[4294]\ttraining's binary_logloss: 0.092899\n",
      "[4295]\ttraining's binary_logloss: 0.0928877\n",
      "[4296]\ttraining's binary_logloss: 0.0928763\n",
      "[4297]\ttraining's binary_logloss: 0.0928662\n",
      "[4298]\ttraining's binary_logloss: 0.0928561\n",
      "[4299]\ttraining's binary_logloss: 0.0928443\n",
      "[4300]\ttraining's binary_logloss: 0.0928344\n",
      "[4301]\ttraining's binary_logloss: 0.0928282\n",
      "[4302]\ttraining's binary_logloss: 0.0928179\n",
      "[4303]\ttraining's binary_logloss: 0.092807\n",
      "[4304]\ttraining's binary_logloss: 0.0927967\n",
      "[4305]\ttraining's binary_logloss: 0.0927866\n",
      "[4306]\ttraining's binary_logloss: 0.0927812\n",
      "[4307]\ttraining's binary_logloss: 0.0927694\n",
      "[4308]\ttraining's binary_logloss: 0.0927597\n",
      "[4309]\ttraining's binary_logloss: 0.0927486\n",
      "[4310]\ttraining's binary_logloss: 0.0927342\n",
      "[4311]\ttraining's binary_logloss: 0.0927237\n",
      "[4312]\ttraining's binary_logloss: 0.0927144\n",
      "[4313]\ttraining's binary_logloss: 0.0927034\n",
      "[4314]\ttraining's binary_logloss: 0.0926918\n",
      "[4315]\ttraining's binary_logloss: 0.0926807\n",
      "[4316]\ttraining's binary_logloss: 0.0926705\n",
      "[4317]\ttraining's binary_logloss: 0.0926596\n",
      "[4318]\ttraining's binary_logloss: 0.0926483\n",
      "[4319]\ttraining's binary_logloss: 0.0926367\n",
      "[4320]\ttraining's binary_logloss: 0.0926262\n",
      "[4321]\ttraining's binary_logloss: 0.0926149\n",
      "[4322]\ttraining's binary_logloss: 0.0926051\n",
      "[4323]\ttraining's binary_logloss: 0.0925929\n",
      "[4324]\ttraining's binary_logloss: 0.0925842\n",
      "[4325]\ttraining's binary_logloss: 0.0925742\n",
      "[4326]\ttraining's binary_logloss: 0.0925637\n",
      "[4327]\ttraining's binary_logloss: 0.0925546\n",
      "[4328]\ttraining's binary_logloss: 0.0925412\n",
      "[4329]\ttraining's binary_logloss: 0.0925307\n",
      "[4330]\ttraining's binary_logloss: 0.0925202\n",
      "[4331]\ttraining's binary_logloss: 0.0925094\n",
      "[4332]\ttraining's binary_logloss: 0.092498\n",
      "[4333]\ttraining's binary_logloss: 0.0924873\n",
      "[4334]\ttraining's binary_logloss: 0.0924769\n",
      "[4335]\ttraining's binary_logloss: 0.0924641\n",
      "[4336]\ttraining's binary_logloss: 0.0924539\n",
      "[4337]\ttraining's binary_logloss: 0.0924425\n",
      "[4338]\ttraining's binary_logloss: 0.0924317\n",
      "[4339]\ttraining's binary_logloss: 0.0924215\n",
      "[4340]\ttraining's binary_logloss: 0.0924126\n",
      "[4341]\ttraining's binary_logloss: 0.0924026\n",
      "[4342]\ttraining's binary_logloss: 0.0923912\n",
      "[4343]\ttraining's binary_logloss: 0.092381\n",
      "[4344]\ttraining's binary_logloss: 0.0923782\n",
      "[4345]\ttraining's binary_logloss: 0.0923665\n",
      "[4346]\ttraining's binary_logloss: 0.0923565\n",
      "[4347]\ttraining's binary_logloss: 0.0923448\n",
      "[4348]\ttraining's binary_logloss: 0.0923423\n",
      "[4349]\ttraining's binary_logloss: 0.0923327\n",
      "[4350]\ttraining's binary_logloss: 0.0923227\n",
      "[4351]\ttraining's binary_logloss: 0.0923138\n",
      "[4352]\ttraining's binary_logloss: 0.0923021\n",
      "[4353]\ttraining's binary_logloss: 0.0922926\n",
      "[4354]\ttraining's binary_logloss: 0.0922823\n",
      "[4355]\ttraining's binary_logloss: 0.0922737\n",
      "[4356]\ttraining's binary_logloss: 0.0922624\n",
      "[4357]\ttraining's binary_logloss: 0.0922527\n",
      "[4358]\ttraining's binary_logloss: 0.0922428\n",
      "[4359]\ttraining's binary_logloss: 0.0922315\n",
      "[4360]\ttraining's binary_logloss: 0.0922252\n",
      "[4361]\ttraining's binary_logloss: 0.0922157\n",
      "[4362]\ttraining's binary_logloss: 0.092206\n",
      "[4363]\ttraining's binary_logloss: 0.0921923\n",
      "[4364]\ttraining's binary_logloss: 0.0921848\n",
      "[4365]\ttraining's binary_logloss: 0.0921827\n",
      "[4366]\ttraining's binary_logloss: 0.0921727\n",
      "[4367]\ttraining's binary_logloss: 0.0921624\n",
      "[4368]\ttraining's binary_logloss: 0.0921518\n",
      "[4369]\ttraining's binary_logloss: 0.0921426\n",
      "[4370]\ttraining's binary_logloss: 0.0921322\n",
      "[4371]\ttraining's binary_logloss: 0.0921217\n",
      "[4372]\ttraining's binary_logloss: 0.0921122\n",
      "[4373]\ttraining's binary_logloss: 0.0921009\n",
      "[4374]\ttraining's binary_logloss: 0.0920975\n",
      "[4375]\ttraining's binary_logloss: 0.0920878\n",
      "[4376]\ttraining's binary_logloss: 0.0920785\n",
      "[4377]\ttraining's binary_logloss: 0.0920684\n",
      "[4378]\ttraining's binary_logloss: 0.0920586\n",
      "[4379]\ttraining's binary_logloss: 0.0920473\n",
      "[4380]\ttraining's binary_logloss: 0.0920378\n",
      "[4381]\ttraining's binary_logloss: 0.0920266\n",
      "[4382]\ttraining's binary_logloss: 0.0920168\n",
      "[4383]\ttraining's binary_logloss: 0.0920059\n",
      "[4384]\ttraining's binary_logloss: 0.0919943\n",
      "[4385]\ttraining's binary_logloss: 0.0919849\n",
      "[4386]\ttraining's binary_logloss: 0.0919745\n",
      "[4387]\ttraining's binary_logloss: 0.0919656\n",
      "[4388]\ttraining's binary_logloss: 0.0919627\n",
      "[4389]\ttraining's binary_logloss: 0.0919545\n",
      "[4390]\ttraining's binary_logloss: 0.0919437\n",
      "[4391]\ttraining's binary_logloss: 0.0919345\n",
      "[4392]\ttraining's binary_logloss: 0.0919283\n",
      "[4393]\ttraining's binary_logloss: 0.0919186\n",
      "[4394]\ttraining's binary_logloss: 0.0919096\n",
      "[4395]\ttraining's binary_logloss: 0.0919057\n",
      "[4396]\ttraining's binary_logloss: 0.0918954\n",
      "[4397]\ttraining's binary_logloss: 0.0918838\n",
      "[4398]\ttraining's binary_logloss: 0.091872\n",
      "[4399]\ttraining's binary_logloss: 0.0918621\n",
      "[4400]\ttraining's binary_logloss: 0.0918517\n",
      "[4401]\ttraining's binary_logloss: 0.0918417\n",
      "[4402]\ttraining's binary_logloss: 0.0918312\n",
      "[4403]\ttraining's binary_logloss: 0.091821\n",
      "[4404]\ttraining's binary_logloss: 0.0918111\n",
      "[4405]\ttraining's binary_logloss: 0.0917997\n",
      "[4406]\ttraining's binary_logloss: 0.0917884\n",
      "[4407]\ttraining's binary_logloss: 0.0917816\n",
      "[4408]\ttraining's binary_logloss: 0.0917709\n",
      "[4409]\ttraining's binary_logloss: 0.0917598\n",
      "[4410]\ttraining's binary_logloss: 0.0917486\n",
      "[4411]\ttraining's binary_logloss: 0.0917388\n",
      "[4412]\ttraining's binary_logloss: 0.0917277\n",
      "[4413]\ttraining's binary_logloss: 0.0917183\n",
      "[4414]\ttraining's binary_logloss: 0.0917074\n",
      "[4415]\ttraining's binary_logloss: 0.0916978\n",
      "[4416]\ttraining's binary_logloss: 0.0916876\n",
      "[4417]\ttraining's binary_logloss: 0.0916775\n",
      "[4418]\ttraining's binary_logloss: 0.0916688\n",
      "[4419]\ttraining's binary_logloss: 0.0916599\n",
      "[4420]\ttraining's binary_logloss: 0.0916495\n",
      "[4421]\ttraining's binary_logloss: 0.0916356\n",
      "[4422]\ttraining's binary_logloss: 0.0916258\n",
      "[4423]\ttraining's binary_logloss: 0.0916223\n",
      "[4424]\ttraining's binary_logloss: 0.0916116\n",
      "[4425]\ttraining's binary_logloss: 0.091601\n",
      "[4426]\ttraining's binary_logloss: 0.0915899\n",
      "[4427]\ttraining's binary_logloss: 0.0915775\n",
      "[4428]\ttraining's binary_logloss: 0.0915668\n",
      "[4429]\ttraining's binary_logloss: 0.0915541\n",
      "[4430]\ttraining's binary_logloss: 0.0915439\n",
      "[4431]\ttraining's binary_logloss: 0.0915328\n",
      "[4432]\ttraining's binary_logloss: 0.0915218\n",
      "[4433]\ttraining's binary_logloss: 0.0915131\n",
      "[4434]\ttraining's binary_logloss: 0.0915087\n",
      "[4435]\ttraining's binary_logloss: 0.0914979\n",
      "[4436]\ttraining's binary_logloss: 0.091488\n",
      "[4437]\ttraining's binary_logloss: 0.0914787\n",
      "[4438]\ttraining's binary_logloss: 0.0914689\n",
      "[4439]\ttraining's binary_logloss: 0.0914582\n",
      "[4440]\ttraining's binary_logloss: 0.0914481\n",
      "[4441]\ttraining's binary_logloss: 0.0914375\n",
      "[4442]\ttraining's binary_logloss: 0.0914266\n",
      "[4443]\ttraining's binary_logloss: 0.0914175\n",
      "[4444]\ttraining's binary_logloss: 0.0914078\n",
      "[4445]\ttraining's binary_logloss: 0.0913987\n",
      "[4446]\ttraining's binary_logloss: 0.0913941\n",
      "[4447]\ttraining's binary_logloss: 0.0913841\n",
      "[4448]\ttraining's binary_logloss: 0.0913719\n",
      "[4449]\ttraining's binary_logloss: 0.0913604\n",
      "[4450]\ttraining's binary_logloss: 0.091351\n",
      "[4451]\ttraining's binary_logloss: 0.091342\n",
      "[4452]\ttraining's binary_logloss: 0.0913305\n",
      "[4453]\ttraining's binary_logloss: 0.0913203\n",
      "[4454]\ttraining's binary_logloss: 0.0913098\n",
      "[4455]\ttraining's binary_logloss: 0.091301\n",
      "[4456]\ttraining's binary_logloss: 0.0912922\n",
      "[4457]\ttraining's binary_logloss: 0.0912815\n",
      "[4458]\ttraining's binary_logloss: 0.0912758\n",
      "[4459]\ttraining's binary_logloss: 0.0912649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4460]\ttraining's binary_logloss: 0.0912547\n",
      "[4461]\ttraining's binary_logloss: 0.0912474\n",
      "[4462]\ttraining's binary_logloss: 0.091237\n",
      "[4463]\ttraining's binary_logloss: 0.0912265\n",
      "[4464]\ttraining's binary_logloss: 0.0912221\n",
      "[4465]\ttraining's binary_logloss: 0.0912116\n",
      "[4466]\ttraining's binary_logloss: 0.0912019\n",
      "[4467]\ttraining's binary_logloss: 0.0911907\n",
      "[4468]\ttraining's binary_logloss: 0.0911791\n",
      "[4469]\ttraining's binary_logloss: 0.0911676\n",
      "[4470]\ttraining's binary_logloss: 0.0911553\n",
      "[4471]\ttraining's binary_logloss: 0.0911454\n",
      "[4472]\ttraining's binary_logloss: 0.0911352\n",
      "[4473]\ttraining's binary_logloss: 0.0911261\n",
      "[4474]\ttraining's binary_logloss: 0.0911151\n",
      "[4475]\ttraining's binary_logloss: 0.0911057\n",
      "[4476]\ttraining's binary_logloss: 0.0910964\n",
      "[4477]\ttraining's binary_logloss: 0.0910848\n",
      "[4478]\ttraining's binary_logloss: 0.0910748\n",
      "[4479]\ttraining's binary_logloss: 0.0910641\n",
      "[4480]\ttraining's binary_logloss: 0.0910544\n",
      "[4481]\ttraining's binary_logloss: 0.0910449\n",
      "[4482]\ttraining's binary_logloss: 0.0910332\n",
      "[4483]\ttraining's binary_logloss: 0.0910235\n",
      "[4484]\ttraining's binary_logloss: 0.0910138\n",
      "[4485]\ttraining's binary_logloss: 0.0910033\n",
      "[4486]\ttraining's binary_logloss: 0.0909932\n",
      "[4487]\ttraining's binary_logloss: 0.090984\n",
      "[4488]\ttraining's binary_logloss: 0.0909727\n",
      "[4489]\ttraining's binary_logloss: 0.0909634\n",
      "[4490]\ttraining's binary_logloss: 0.0909541\n",
      "[4491]\ttraining's binary_logloss: 0.090944\n",
      "[4492]\ttraining's binary_logloss: 0.0909338\n",
      "[4493]\ttraining's binary_logloss: 0.0909224\n",
      "[4494]\ttraining's binary_logloss: 0.0909121\n",
      "[4495]\ttraining's binary_logloss: 0.0909045\n",
      "[4496]\ttraining's binary_logloss: 0.0909009\n",
      "[4497]\ttraining's binary_logloss: 0.0908927\n",
      "[4498]\ttraining's binary_logloss: 0.0908835\n",
      "[4499]\ttraining's binary_logloss: 0.0908761\n",
      "[4500]\ttraining's binary_logloss: 0.0908649\n",
      "[4501]\ttraining's binary_logloss: 0.0908621\n",
      "[4502]\ttraining's binary_logloss: 0.0908548\n",
      "[4503]\ttraining's binary_logloss: 0.090853\n",
      "[4504]\ttraining's binary_logloss: 0.0908416\n",
      "[4505]\ttraining's binary_logloss: 0.0908303\n",
      "[4506]\ttraining's binary_logloss: 0.0908202\n",
      "[4507]\ttraining's binary_logloss: 0.09081\n",
      "[4508]\ttraining's binary_logloss: 0.0907992\n",
      "[4509]\ttraining's binary_logloss: 0.0907904\n",
      "[4510]\ttraining's binary_logloss: 0.0907801\n",
      "[4511]\ttraining's binary_logloss: 0.0907702\n",
      "[4512]\ttraining's binary_logloss: 0.0907685\n",
      "[4513]\ttraining's binary_logloss: 0.090756\n",
      "[4514]\ttraining's binary_logloss: 0.0907451\n",
      "[4515]\ttraining's binary_logloss: 0.0907344\n",
      "[4516]\ttraining's binary_logloss: 0.0907245\n",
      "[4517]\ttraining's binary_logloss: 0.0907142\n",
      "[4518]\ttraining's binary_logloss: 0.0907044\n",
      "[4519]\ttraining's binary_logloss: 0.0906953\n",
      "[4520]\ttraining's binary_logloss: 0.0906848\n",
      "[4521]\ttraining's binary_logloss: 0.0906746\n",
      "[4522]\ttraining's binary_logloss: 0.0906653\n",
      "[4523]\ttraining's binary_logloss: 0.0906539\n",
      "[4524]\ttraining's binary_logloss: 0.0906438\n",
      "[4525]\ttraining's binary_logloss: 0.0906337\n",
      "[4526]\ttraining's binary_logloss: 0.0906315\n",
      "[4527]\ttraining's binary_logloss: 0.0906261\n",
      "[4528]\ttraining's binary_logloss: 0.0906142\n",
      "[4529]\ttraining's binary_logloss: 0.0906017\n",
      "[4530]\ttraining's binary_logloss: 0.0905901\n",
      "[4531]\ttraining's binary_logloss: 0.0905855\n",
      "[4532]\ttraining's binary_logloss: 0.0905751\n",
      "[4533]\ttraining's binary_logloss: 0.0905643\n",
      "[4534]\ttraining's binary_logloss: 0.0905571\n",
      "[4535]\ttraining's binary_logloss: 0.0905458\n",
      "[4536]\ttraining's binary_logloss: 0.0905347\n",
      "[4537]\ttraining's binary_logloss: 0.0905314\n",
      "[4538]\ttraining's binary_logloss: 0.0905215\n",
      "[4539]\ttraining's binary_logloss: 0.0905113\n",
      "[4540]\ttraining's binary_logloss: 0.0905017\n",
      "[4541]\ttraining's binary_logloss: 0.0904881\n",
      "[4542]\ttraining's binary_logloss: 0.0904783\n",
      "[4543]\ttraining's binary_logloss: 0.0904652\n",
      "[4544]\ttraining's binary_logloss: 0.0904627\n",
      "[4545]\ttraining's binary_logloss: 0.0904553\n",
      "[4546]\ttraining's binary_logloss: 0.0904486\n",
      "[4547]\ttraining's binary_logloss: 0.0904378\n",
      "[4548]\ttraining's binary_logloss: 0.0904247\n",
      "[4549]\ttraining's binary_logloss: 0.0904153\n",
      "[4550]\ttraining's binary_logloss: 0.0904112\n",
      "[4551]\ttraining's binary_logloss: 0.0904005\n",
      "[4552]\ttraining's binary_logloss: 0.0903923\n",
      "[4553]\ttraining's binary_logloss: 0.0903812\n",
      "[4554]\ttraining's binary_logloss: 0.0903713\n",
      "[4555]\ttraining's binary_logloss: 0.0903601\n",
      "[4556]\ttraining's binary_logloss: 0.09035\n",
      "[4557]\ttraining's binary_logloss: 0.0903391\n",
      "[4558]\ttraining's binary_logloss: 0.0903296\n",
      "[4559]\ttraining's binary_logloss: 0.0903197\n",
      "[4560]\ttraining's binary_logloss: 0.0903093\n",
      "[4561]\ttraining's binary_logloss: 0.0902991\n",
      "[4562]\ttraining's binary_logloss: 0.090289\n",
      "[4563]\ttraining's binary_logloss: 0.0902829\n",
      "[4564]\ttraining's binary_logloss: 0.0902716\n",
      "[4565]\ttraining's binary_logloss: 0.0902619\n",
      "[4566]\ttraining's binary_logloss: 0.0902519\n",
      "[4567]\ttraining's binary_logloss: 0.0902422\n",
      "[4568]\ttraining's binary_logloss: 0.0902311\n",
      "[4569]\ttraining's binary_logloss: 0.0902214\n",
      "[4570]\ttraining's binary_logloss: 0.0902111\n",
      "[4571]\ttraining's binary_logloss: 0.0902012\n",
      "[4572]\ttraining's binary_logloss: 0.0901951\n",
      "[4573]\ttraining's binary_logloss: 0.0901849\n",
      "[4574]\ttraining's binary_logloss: 0.0901756\n",
      "[4575]\ttraining's binary_logloss: 0.0901654\n",
      "[4576]\ttraining's binary_logloss: 0.0901552\n",
      "[4577]\ttraining's binary_logloss: 0.0901441\n",
      "[4578]\ttraining's binary_logloss: 0.090134\n",
      "[4579]\ttraining's binary_logloss: 0.0901256\n",
      "[4580]\ttraining's binary_logloss: 0.0901164\n",
      "[4581]\ttraining's binary_logloss: 0.0901058\n",
      "[4582]\ttraining's binary_logloss: 0.0900951\n",
      "[4583]\ttraining's binary_logloss: 0.090084\n",
      "[4584]\ttraining's binary_logloss: 0.0900742\n",
      "[4585]\ttraining's binary_logloss: 0.0900631\n",
      "[4586]\ttraining's binary_logloss: 0.0900528\n",
      "[4587]\ttraining's binary_logloss: 0.0900425\n",
      "[4588]\ttraining's binary_logloss: 0.0900327\n",
      "[4589]\ttraining's binary_logloss: 0.0900216\n",
      "[4590]\ttraining's binary_logloss: 0.0900131\n",
      "[4591]\ttraining's binary_logloss: 0.0900024\n",
      "[4592]\ttraining's binary_logloss: 0.0899923\n",
      "[4593]\ttraining's binary_logloss: 0.0899826\n",
      "[4594]\ttraining's binary_logloss: 0.0899728\n",
      "[4595]\ttraining's binary_logloss: 0.089964\n",
      "[4596]\ttraining's binary_logloss: 0.0899587\n",
      "[4597]\ttraining's binary_logloss: 0.0899489\n",
      "[4598]\ttraining's binary_logloss: 0.0899386\n",
      "[4599]\ttraining's binary_logloss: 0.0899278\n",
      "[4600]\ttraining's binary_logloss: 0.0899186\n",
      "[4601]\ttraining's binary_logloss: 0.0899109\n",
      "[4602]\ttraining's binary_logloss: 0.0899022\n",
      "[4603]\ttraining's binary_logloss: 0.0898904\n",
      "[4604]\ttraining's binary_logloss: 0.0898794\n",
      "[4605]\ttraining's binary_logloss: 0.0898698\n",
      "[4606]\ttraining's binary_logloss: 0.0898591\n",
      "[4607]\ttraining's binary_logloss: 0.0898479\n",
      "[4608]\ttraining's binary_logloss: 0.0898377\n",
      "[4609]\ttraining's binary_logloss: 0.0898278\n",
      "[4610]\ttraining's binary_logloss: 0.0898179\n",
      "[4611]\ttraining's binary_logloss: 0.0898088\n",
      "[4612]\ttraining's binary_logloss: 0.0897991\n",
      "[4613]\ttraining's binary_logloss: 0.0897892\n",
      "[4614]\ttraining's binary_logloss: 0.0897822\n",
      "[4615]\ttraining's binary_logloss: 0.089773\n",
      "[4616]\ttraining's binary_logloss: 0.0897642\n",
      "[4617]\ttraining's binary_logloss: 0.0897556\n",
      "[4618]\ttraining's binary_logloss: 0.0897458\n",
      "[4619]\ttraining's binary_logloss: 0.0897356\n",
      "[4620]\ttraining's binary_logloss: 0.0897256\n",
      "[4621]\ttraining's binary_logloss: 0.0897156\n",
      "[4622]\ttraining's binary_logloss: 0.0897058\n",
      "[4623]\ttraining's binary_logloss: 0.0896967\n",
      "[4624]\ttraining's binary_logloss: 0.0896865\n",
      "[4625]\ttraining's binary_logloss: 0.0896766\n",
      "[4626]\ttraining's binary_logloss: 0.0896686\n",
      "[4627]\ttraining's binary_logloss: 0.0896633\n",
      "[4628]\ttraining's binary_logloss: 0.089655\n",
      "[4629]\ttraining's binary_logloss: 0.0896445\n",
      "[4630]\ttraining's binary_logloss: 0.0896325\n",
      "[4631]\ttraining's binary_logloss: 0.0896234\n",
      "[4632]\ttraining's binary_logloss: 0.089614\n",
      "[4633]\ttraining's binary_logloss: 0.0896019\n",
      "[4634]\ttraining's binary_logloss: 0.0895912\n",
      "[4635]\ttraining's binary_logloss: 0.0895806\n",
      "[4636]\ttraining's binary_logloss: 0.0895757\n",
      "[4637]\ttraining's binary_logloss: 0.0895657\n",
      "[4638]\ttraining's binary_logloss: 0.0895547\n",
      "[4639]\ttraining's binary_logloss: 0.0895457\n",
      "[4640]\ttraining's binary_logloss: 0.0895362\n",
      "[4641]\ttraining's binary_logloss: 0.0895234\n",
      "[4642]\ttraining's binary_logloss: 0.0895107\n",
      "[4643]\ttraining's binary_logloss: 0.0895014\n",
      "[4644]\ttraining's binary_logloss: 0.0894899\n",
      "[4645]\ttraining's binary_logloss: 0.0894799\n",
      "[4646]\ttraining's binary_logloss: 0.0894713\n",
      "[4647]\ttraining's binary_logloss: 0.0894673\n",
      "[4648]\ttraining's binary_logloss: 0.0894572\n",
      "[4649]\ttraining's binary_logloss: 0.0894467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4650]\ttraining's binary_logloss: 0.0894356\n",
      "[4651]\ttraining's binary_logloss: 0.0894251\n",
      "[4652]\ttraining's binary_logloss: 0.0894156\n",
      "[4653]\ttraining's binary_logloss: 0.0894041\n",
      "[4654]\ttraining's binary_logloss: 0.0893922\n",
      "[4655]\ttraining's binary_logloss: 0.0893796\n",
      "[4656]\ttraining's binary_logloss: 0.0893668\n",
      "[4657]\ttraining's binary_logloss: 0.0893543\n",
      "[4658]\ttraining's binary_logloss: 0.0893455\n",
      "[4659]\ttraining's binary_logloss: 0.0893359\n",
      "[4660]\ttraining's binary_logloss: 0.0893255\n",
      "[4661]\ttraining's binary_logloss: 0.0893157\n",
      "[4662]\ttraining's binary_logloss: 0.0893045\n",
      "[4663]\ttraining's binary_logloss: 0.0892948\n",
      "[4664]\ttraining's binary_logloss: 0.0892881\n",
      "[4665]\ttraining's binary_logloss: 0.0892756\n",
      "[4666]\ttraining's binary_logloss: 0.0892669\n",
      "[4667]\ttraining's binary_logloss: 0.0892573\n",
      "[4668]\ttraining's binary_logloss: 0.0892471\n",
      "[4669]\ttraining's binary_logloss: 0.089235\n",
      "[4670]\ttraining's binary_logloss: 0.0892248\n",
      "[4671]\ttraining's binary_logloss: 0.0892155\n",
      "[4672]\ttraining's binary_logloss: 0.0892032\n",
      "[4673]\ttraining's binary_logloss: 0.0891936\n",
      "[4674]\ttraining's binary_logloss: 0.089184\n",
      "[4675]\ttraining's binary_logloss: 0.089181\n",
      "[4676]\ttraining's binary_logloss: 0.0891701\n",
      "[4677]\ttraining's binary_logloss: 0.0891564\n",
      "[4678]\ttraining's binary_logloss: 0.0891549\n",
      "[4679]\ttraining's binary_logloss: 0.0891421\n",
      "[4680]\ttraining's binary_logloss: 0.089133\n",
      "[4681]\ttraining's binary_logloss: 0.0891237\n",
      "[4682]\ttraining's binary_logloss: 0.0891131\n",
      "[4683]\ttraining's binary_logloss: 0.0891035\n",
      "[4684]\ttraining's binary_logloss: 0.089092\n",
      "[4685]\ttraining's binary_logloss: 0.089084\n",
      "[4686]\ttraining's binary_logloss: 0.0890738\n",
      "[4687]\ttraining's binary_logloss: 0.0890627\n",
      "[4688]\ttraining's binary_logloss: 0.0890601\n",
      "[4689]\ttraining's binary_logloss: 0.0890505\n",
      "[4690]\ttraining's binary_logloss: 0.0890416\n",
      "[4691]\ttraining's binary_logloss: 0.0890338\n",
      "[4692]\ttraining's binary_logloss: 0.0890234\n",
      "[4693]\ttraining's binary_logloss: 0.0890118\n",
      "[4694]\ttraining's binary_logloss: 0.0889999\n",
      "[4695]\ttraining's binary_logloss: 0.0889868\n",
      "[4696]\ttraining's binary_logloss: 0.0889762\n",
      "[4697]\ttraining's binary_logloss: 0.0889664\n",
      "[4698]\ttraining's binary_logloss: 0.0889561\n",
      "[4699]\ttraining's binary_logloss: 0.0889464\n",
      "[4700]\ttraining's binary_logloss: 0.0889365\n",
      "[4701]\ttraining's binary_logloss: 0.0889248\n",
      "[4702]\ttraining's binary_logloss: 0.0889134\n",
      "[4703]\ttraining's binary_logloss: 0.0889013\n",
      "[4704]\ttraining's binary_logloss: 0.0888895\n",
      "[4705]\ttraining's binary_logloss: 0.0888769\n",
      "[4706]\ttraining's binary_logloss: 0.0888669\n",
      "[4707]\ttraining's binary_logloss: 0.088857\n",
      "[4708]\ttraining's binary_logloss: 0.0888459\n",
      "[4709]\ttraining's binary_logloss: 0.0888344\n",
      "[4710]\ttraining's binary_logloss: 0.0888246\n",
      "[4711]\ttraining's binary_logloss: 0.0888147\n",
      "[4712]\ttraining's binary_logloss: 0.0888047\n",
      "[4713]\ttraining's binary_logloss: 0.0887942\n",
      "[4714]\ttraining's binary_logloss: 0.0887833\n",
      "[4715]\ttraining's binary_logloss: 0.0887738\n",
      "[4716]\ttraining's binary_logloss: 0.0887636\n",
      "[4717]\ttraining's binary_logloss: 0.0887526\n",
      "[4718]\ttraining's binary_logloss: 0.0887409\n",
      "[4719]\ttraining's binary_logloss: 0.0887305\n",
      "[4720]\ttraining's binary_logloss: 0.0887203\n",
      "[4721]\ttraining's binary_logloss: 0.0887094\n",
      "[4722]\ttraining's binary_logloss: 0.0886976\n",
      "[4723]\ttraining's binary_logloss: 0.0886888\n",
      "[4724]\ttraining's binary_logloss: 0.0886782\n",
      "[4725]\ttraining's binary_logloss: 0.0886683\n",
      "[4726]\ttraining's binary_logloss: 0.0886583\n",
      "[4727]\ttraining's binary_logloss: 0.0886489\n",
      "[4728]\ttraining's binary_logloss: 0.0886375\n",
      "[4729]\ttraining's binary_logloss: 0.0886263\n",
      "[4730]\ttraining's binary_logloss: 0.0886187\n",
      "[4731]\ttraining's binary_logloss: 0.0886103\n",
      "[4732]\ttraining's binary_logloss: 0.0886007\n",
      "[4733]\ttraining's binary_logloss: 0.0885893\n",
      "[4734]\ttraining's binary_logloss: 0.0885792\n",
      "[4735]\ttraining's binary_logloss: 0.0885697\n",
      "[4736]\ttraining's binary_logloss: 0.088558\n",
      "[4737]\ttraining's binary_logloss: 0.0885482\n",
      "[4738]\ttraining's binary_logloss: 0.0885383\n",
      "[4739]\ttraining's binary_logloss: 0.0885285\n",
      "[4740]\ttraining's binary_logloss: 0.0885187\n",
      "[4741]\ttraining's binary_logloss: 0.0885079\n",
      "[4742]\ttraining's binary_logloss: 0.0884986\n",
      "[4743]\ttraining's binary_logloss: 0.0884889\n",
      "[4744]\ttraining's binary_logloss: 0.0884792\n",
      "[4745]\ttraining's binary_logloss: 0.0884698\n",
      "[4746]\ttraining's binary_logloss: 0.0884586\n",
      "[4747]\ttraining's binary_logloss: 0.0884471\n",
      "[4748]\ttraining's binary_logloss: 0.0884352\n",
      "[4749]\ttraining's binary_logloss: 0.0884251\n",
      "[4750]\ttraining's binary_logloss: 0.0884167\n",
      "[4751]\ttraining's binary_logloss: 0.0884059\n",
      "[4752]\ttraining's binary_logloss: 0.0883945\n",
      "[4753]\ttraining's binary_logloss: 0.0883835\n",
      "[4754]\ttraining's binary_logloss: 0.0883749\n",
      "[4755]\ttraining's binary_logloss: 0.0883632\n",
      "[4756]\ttraining's binary_logloss: 0.0883534\n",
      "[4757]\ttraining's binary_logloss: 0.0883445\n",
      "[4758]\ttraining's binary_logloss: 0.0883344\n",
      "[4759]\ttraining's binary_logloss: 0.0883294\n",
      "[4760]\ttraining's binary_logloss: 0.0883211\n",
      "[4761]\ttraining's binary_logloss: 0.0883164\n",
      "[4762]\ttraining's binary_logloss: 0.0882999\n",
      "[4763]\ttraining's binary_logloss: 0.08829\n",
      "[4764]\ttraining's binary_logloss: 0.0882817\n",
      "[4765]\ttraining's binary_logloss: 0.0882716\n",
      "[4766]\ttraining's binary_logloss: 0.0882619\n",
      "[4767]\ttraining's binary_logloss: 0.0882516\n",
      "[4768]\ttraining's binary_logloss: 0.0882421\n",
      "[4769]\ttraining's binary_logloss: 0.0882337\n",
      "[4770]\ttraining's binary_logloss: 0.0882229\n",
      "[4771]\ttraining's binary_logloss: 0.0882126\n",
      "[4772]\ttraining's binary_logloss: 0.0882039\n",
      "[4773]\ttraining's binary_logloss: 0.0881949\n",
      "[4774]\ttraining's binary_logloss: 0.0881834\n",
      "[4775]\ttraining's binary_logloss: 0.0881742\n",
      "[4776]\ttraining's binary_logloss: 0.0881641\n",
      "[4777]\ttraining's binary_logloss: 0.0881536\n",
      "[4778]\ttraining's binary_logloss: 0.0881455\n",
      "[4779]\ttraining's binary_logloss: 0.0881438\n",
      "[4780]\ttraining's binary_logloss: 0.0881336\n",
      "[4781]\ttraining's binary_logloss: 0.0881245\n",
      "[4782]\ttraining's binary_logloss: 0.0881132\n",
      "[4783]\ttraining's binary_logloss: 0.0881027\n",
      "[4784]\ttraining's binary_logloss: 0.0880937\n",
      "[4785]\ttraining's binary_logloss: 0.0880834\n",
      "[4786]\ttraining's binary_logloss: 0.0880739\n",
      "[4787]\ttraining's binary_logloss: 0.0880625\n",
      "[4788]\ttraining's binary_logloss: 0.0880523\n",
      "[4789]\ttraining's binary_logloss: 0.0880433\n",
      "[4790]\ttraining's binary_logloss: 0.0880333\n",
      "[4791]\ttraining's binary_logloss: 0.0880242\n",
      "[4792]\ttraining's binary_logloss: 0.0880136\n",
      "[4793]\ttraining's binary_logloss: 0.0880034\n",
      "[4794]\ttraining's binary_logloss: 0.0879918\n",
      "[4795]\ttraining's binary_logloss: 0.0879817\n",
      "[4796]\ttraining's binary_logloss: 0.0879716\n",
      "[4797]\ttraining's binary_logloss: 0.0879607\n",
      "[4798]\ttraining's binary_logloss: 0.0879545\n",
      "[4799]\ttraining's binary_logloss: 0.0879436\n",
      "[4800]\ttraining's binary_logloss: 0.0879351\n",
      "[4801]\ttraining's binary_logloss: 0.0879265\n",
      "[4802]\ttraining's binary_logloss: 0.0879174\n",
      "[4803]\ttraining's binary_logloss: 0.0879086\n",
      "[4804]\ttraining's binary_logloss: 0.0878981\n",
      "[4805]\ttraining's binary_logloss: 0.0878885\n",
      "[4806]\ttraining's binary_logloss: 0.0878788\n",
      "[4807]\ttraining's binary_logloss: 0.0878676\n",
      "[4808]\ttraining's binary_logloss: 0.0878618\n",
      "[4809]\ttraining's binary_logloss: 0.0878509\n",
      "[4810]\ttraining's binary_logloss: 0.0878457\n",
      "[4811]\ttraining's binary_logloss: 0.0878358\n",
      "[4812]\ttraining's binary_logloss: 0.0878248\n",
      "[4813]\ttraining's binary_logloss: 0.0878158\n",
      "[4814]\ttraining's binary_logloss: 0.0878067\n",
      "[4815]\ttraining's binary_logloss: 0.0877959\n",
      "[4816]\ttraining's binary_logloss: 0.0877862\n",
      "[4817]\ttraining's binary_logloss: 0.0877766\n",
      "[4818]\ttraining's binary_logloss: 0.0877675\n",
      "[4819]\ttraining's binary_logloss: 0.0877578\n",
      "[4820]\ttraining's binary_logloss: 0.0877485\n",
      "[4821]\ttraining's binary_logloss: 0.0877384\n",
      "[4822]\ttraining's binary_logloss: 0.0877318\n",
      "[4823]\ttraining's binary_logloss: 0.0877235\n",
      "[4824]\ttraining's binary_logloss: 0.0877138\n",
      "[4825]\ttraining's binary_logloss: 0.0877035\n",
      "[4826]\ttraining's binary_logloss: 0.0876931\n",
      "[4827]\ttraining's binary_logloss: 0.087685\n",
      "[4828]\ttraining's binary_logloss: 0.0876756\n",
      "[4829]\ttraining's binary_logloss: 0.087669\n",
      "[4830]\ttraining's binary_logloss: 0.0876608\n",
      "[4831]\ttraining's binary_logloss: 0.0876516\n",
      "[4832]\ttraining's binary_logloss: 0.0876427\n",
      "[4833]\ttraining's binary_logloss: 0.0876394\n",
      "[4834]\ttraining's binary_logloss: 0.0876299\n",
      "[4835]\ttraining's binary_logloss: 0.0876246\n",
      "[4836]\ttraining's binary_logloss: 0.0876161\n",
      "[4837]\ttraining's binary_logloss: 0.0876068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4838]\ttraining's binary_logloss: 0.0875963\n",
      "[4839]\ttraining's binary_logloss: 0.0875904\n",
      "[4840]\ttraining's binary_logloss: 0.0875808\n",
      "[4841]\ttraining's binary_logloss: 0.0875701\n",
      "[4842]\ttraining's binary_logloss: 0.0875622\n",
      "[4843]\ttraining's binary_logloss: 0.087552\n",
      "[4844]\ttraining's binary_logloss: 0.0875432\n",
      "[4845]\ttraining's binary_logloss: 0.0875321\n",
      "[4846]\ttraining's binary_logloss: 0.0875254\n",
      "[4847]\ttraining's binary_logloss: 0.0875169\n",
      "[4848]\ttraining's binary_logloss: 0.0875068\n",
      "[4849]\ttraining's binary_logloss: 0.087496\n",
      "[4850]\ttraining's binary_logloss: 0.0874841\n",
      "[4851]\ttraining's binary_logloss: 0.0874762\n",
      "[4852]\ttraining's binary_logloss: 0.0874668\n",
      "[4853]\ttraining's binary_logloss: 0.0874568\n",
      "[4854]\ttraining's binary_logloss: 0.0874471\n",
      "[4855]\ttraining's binary_logloss: 0.0874373\n",
      "[4856]\ttraining's binary_logloss: 0.087428\n",
      "[4857]\ttraining's binary_logloss: 0.0874176\n",
      "[4858]\ttraining's binary_logloss: 0.087416\n",
      "[4859]\ttraining's binary_logloss: 0.0874073\n",
      "[4860]\ttraining's binary_logloss: 0.0873973\n",
      "[4861]\ttraining's binary_logloss: 0.0873856\n",
      "[4862]\ttraining's binary_logloss: 0.0873748\n",
      "[4863]\ttraining's binary_logloss: 0.0873655\n",
      "[4864]\ttraining's binary_logloss: 0.0873555\n",
      "[4865]\ttraining's binary_logloss: 0.0873452\n",
      "[4866]\ttraining's binary_logloss: 0.0873364\n",
      "[4867]\ttraining's binary_logloss: 0.0873265\n",
      "[4868]\ttraining's binary_logloss: 0.0873165\n",
      "[4869]\ttraining's binary_logloss: 0.0873085\n",
      "[4870]\ttraining's binary_logloss: 0.0873068\n",
      "[4871]\ttraining's binary_logloss: 0.0872973\n",
      "[4872]\ttraining's binary_logloss: 0.0872849\n",
      "[4873]\ttraining's binary_logloss: 0.0872738\n",
      "[4874]\ttraining's binary_logloss: 0.087265\n",
      "[4875]\ttraining's binary_logloss: 0.0872622\n",
      "[4876]\ttraining's binary_logloss: 0.0872513\n",
      "[4877]\ttraining's binary_logloss: 0.0872421\n",
      "[4878]\ttraining's binary_logloss: 0.0872326\n",
      "[4879]\ttraining's binary_logloss: 0.0872248\n",
      "[4880]\ttraining's binary_logloss: 0.0872153\n",
      "[4881]\ttraining's binary_logloss: 0.0872053\n",
      "[4882]\ttraining's binary_logloss: 0.0871946\n",
      "[4883]\ttraining's binary_logloss: 0.0871849\n",
      "[4884]\ttraining's binary_logloss: 0.0871781\n",
      "[4885]\ttraining's binary_logloss: 0.0871687\n",
      "[4886]\ttraining's binary_logloss: 0.0871568\n",
      "[4887]\ttraining's binary_logloss: 0.0871474\n",
      "[4888]\ttraining's binary_logloss: 0.0871373\n",
      "[4889]\ttraining's binary_logloss: 0.0871266\n",
      "[4890]\ttraining's binary_logloss: 0.087117\n",
      "[4891]\ttraining's binary_logloss: 0.0871064\n",
      "[4892]\ttraining's binary_logloss: 0.0870966\n",
      "[4893]\ttraining's binary_logloss: 0.087089\n",
      "[4894]\ttraining's binary_logloss: 0.0870781\n",
      "[4895]\ttraining's binary_logloss: 0.087069\n",
      "[4896]\ttraining's binary_logloss: 0.0870589\n",
      "[4897]\ttraining's binary_logloss: 0.0870428\n",
      "[4898]\ttraining's binary_logloss: 0.0870317\n",
      "[4899]\ttraining's binary_logloss: 0.0870213\n",
      "[4900]\ttraining's binary_logloss: 0.0870126\n",
      "[4901]\ttraining's binary_logloss: 0.0870036\n",
      "[4902]\ttraining's binary_logloss: 0.0869925\n",
      "[4903]\ttraining's binary_logloss: 0.0869843\n",
      "[4904]\ttraining's binary_logloss: 0.0869755\n",
      "[4905]\ttraining's binary_logloss: 0.0869719\n",
      "[4906]\ttraining's binary_logloss: 0.0869621\n",
      "[4907]\ttraining's binary_logloss: 0.0869511\n",
      "[4908]\ttraining's binary_logloss: 0.086942\n",
      "[4909]\ttraining's binary_logloss: 0.0869336\n",
      "[4910]\ttraining's binary_logloss: 0.0869302\n",
      "[4911]\ttraining's binary_logloss: 0.086922\n",
      "[4912]\ttraining's binary_logloss: 0.0869187\n",
      "[4913]\ttraining's binary_logloss: 0.0869084\n",
      "[4914]\ttraining's binary_logloss: 0.0868993\n",
      "[4915]\ttraining's binary_logloss: 0.0868891\n",
      "[4916]\ttraining's binary_logloss: 0.0868799\n",
      "[4917]\ttraining's binary_logloss: 0.08687\n",
      "[4918]\ttraining's binary_logloss: 0.0868596\n",
      "[4919]\ttraining's binary_logloss: 0.0868497\n",
      "[4920]\ttraining's binary_logloss: 0.0868439\n",
      "[4921]\ttraining's binary_logloss: 0.0868356\n",
      "[4922]\ttraining's binary_logloss: 0.0868273\n",
      "[4923]\ttraining's binary_logloss: 0.0868139\n",
      "[4924]\ttraining's binary_logloss: 0.0868042\n",
      "[4925]\ttraining's binary_logloss: 0.0867983\n",
      "[4926]\ttraining's binary_logloss: 0.0867885\n",
      "[4927]\ttraining's binary_logloss: 0.0867793\n",
      "[4928]\ttraining's binary_logloss: 0.0867637\n",
      "[4929]\ttraining's binary_logloss: 0.0867571\n",
      "[4930]\ttraining's binary_logloss: 0.0867477\n",
      "[4931]\ttraining's binary_logloss: 0.0867371\n",
      "[4932]\ttraining's binary_logloss: 0.0867299\n",
      "[4933]\ttraining's binary_logloss: 0.086719\n",
      "[4934]\ttraining's binary_logloss: 0.0867088\n",
      "[4935]\ttraining's binary_logloss: 0.0866983\n",
      "[4936]\ttraining's binary_logloss: 0.0866887\n",
      "[4937]\ttraining's binary_logloss: 0.0866786\n",
      "[4938]\ttraining's binary_logloss: 0.0866731\n",
      "[4939]\ttraining's binary_logloss: 0.0866633\n",
      "[4940]\ttraining's binary_logloss: 0.0866536\n",
      "[4941]\ttraining's binary_logloss: 0.0866405\n",
      "[4942]\ttraining's binary_logloss: 0.0866321\n",
      "[4943]\ttraining's binary_logloss: 0.086622\n",
      "[4944]\ttraining's binary_logloss: 0.0866123\n",
      "[4945]\ttraining's binary_logloss: 0.0866041\n",
      "[4946]\ttraining's binary_logloss: 0.0865951\n",
      "[4947]\ttraining's binary_logloss: 0.0865857\n",
      "[4948]\ttraining's binary_logloss: 0.0865748\n",
      "[4949]\ttraining's binary_logloss: 0.0865647\n",
      "[4950]\ttraining's binary_logloss: 0.0865542\n",
      "[4951]\ttraining's binary_logloss: 0.0865452\n",
      "[4952]\ttraining's binary_logloss: 0.0865353\n",
      "[4953]\ttraining's binary_logloss: 0.0865251\n",
      "[4954]\ttraining's binary_logloss: 0.086515\n",
      "[4955]\ttraining's binary_logloss: 0.0865105\n",
      "[4956]\ttraining's binary_logloss: 0.0865051\n",
      "[4957]\ttraining's binary_logloss: 0.086502\n",
      "[4958]\ttraining's binary_logloss: 0.0864928\n",
      "[4959]\ttraining's binary_logloss: 0.086482\n",
      "[4960]\ttraining's binary_logloss: 0.0864738\n",
      "[4961]\ttraining's binary_logloss: 0.0864688\n",
      "[4962]\ttraining's binary_logloss: 0.0864602\n",
      "[4963]\ttraining's binary_logloss: 0.0864574\n",
      "[4964]\ttraining's binary_logloss: 0.0864468\n",
      "[4965]\ttraining's binary_logloss: 0.0864416\n",
      "[4966]\ttraining's binary_logloss: 0.0864317\n",
      "[4967]\ttraining's binary_logloss: 0.0864227\n",
      "[4968]\ttraining's binary_logloss: 0.0864142\n",
      "[4969]\ttraining's binary_logloss: 0.0864083\n",
      "[4970]\ttraining's binary_logloss: 0.0863985\n",
      "[4971]\ttraining's binary_logloss: 0.0863872\n",
      "[4972]\ttraining's binary_logloss: 0.0863781\n",
      "[4973]\ttraining's binary_logloss: 0.0863692\n",
      "[4974]\ttraining's binary_logloss: 0.0863573\n",
      "[4975]\ttraining's binary_logloss: 0.0863475\n",
      "[4976]\ttraining's binary_logloss: 0.0863375\n",
      "[4977]\ttraining's binary_logloss: 0.0863268\n",
      "[4978]\ttraining's binary_logloss: 0.0863183\n",
      "[4979]\ttraining's binary_logloss: 0.0863091\n",
      "[4980]\ttraining's binary_logloss: 0.0863002\n",
      "[4981]\ttraining's binary_logloss: 0.0862891\n",
      "[4982]\ttraining's binary_logloss: 0.0862794\n",
      "[4983]\ttraining's binary_logloss: 0.0862699\n",
      "[4984]\ttraining's binary_logloss: 0.0862592\n",
      "[4985]\ttraining's binary_logloss: 0.0862474\n",
      "[4986]\ttraining's binary_logloss: 0.0862357\n",
      "[4987]\ttraining's binary_logloss: 0.0862273\n",
      "[4988]\ttraining's binary_logloss: 0.0862172\n",
      "[4989]\ttraining's binary_logloss: 0.0862059\n",
      "[4990]\ttraining's binary_logloss: 0.0861958\n",
      "[4991]\ttraining's binary_logloss: 0.0861882\n",
      "[4992]\ttraining's binary_logloss: 0.0861783\n",
      "[4993]\ttraining's binary_logloss: 0.0861705\n",
      "[4994]\ttraining's binary_logloss: 0.0861608\n",
      "[4995]\ttraining's binary_logloss: 0.0861516\n",
      "[4996]\ttraining's binary_logloss: 0.0861415\n",
      "[4997]\ttraining's binary_logloss: 0.0861327\n",
      "[4998]\ttraining's binary_logloss: 0.086124\n",
      "[4999]\ttraining's binary_logloss: 0.0861188\n",
      "[5000]\ttraining's binary_logloss: 0.0861095\n",
      "[5001]\ttraining's binary_logloss: 0.0861002\n",
      "[5002]\ttraining's binary_logloss: 0.0860891\n",
      "[5003]\ttraining's binary_logloss: 0.0860796\n",
      "[5004]\ttraining's binary_logloss: 0.0860699\n",
      "[5005]\ttraining's binary_logloss: 0.0860654\n",
      "[5006]\ttraining's binary_logloss: 0.0860561\n",
      "[5007]\ttraining's binary_logloss: 0.086047\n",
      "[5008]\ttraining's binary_logloss: 0.0860342\n",
      "[5009]\ttraining's binary_logloss: 0.086025\n",
      "[5010]\ttraining's binary_logloss: 0.0860142\n",
      "[5011]\ttraining's binary_logloss: 0.0860085\n",
      "[5012]\ttraining's binary_logloss: 0.0859994\n",
      "[5013]\ttraining's binary_logloss: 0.0859979\n",
      "[5014]\ttraining's binary_logloss: 0.0859882\n",
      "[5015]\ttraining's binary_logloss: 0.08598\n",
      "[5016]\ttraining's binary_logloss: 0.0859681\n",
      "[5017]\ttraining's binary_logloss: 0.0859573\n",
      "[5018]\ttraining's binary_logloss: 0.0859456\n",
      "[5019]\ttraining's binary_logloss: 0.0859363\n",
      "[5020]\ttraining's binary_logloss: 0.0859256\n",
      "[5021]\ttraining's binary_logloss: 0.085917\n",
      "[5022]\ttraining's binary_logloss: 0.085909\n",
      "[5023]\ttraining's binary_logloss: 0.0859004\n",
      "[5024]\ttraining's binary_logloss: 0.0858907\n",
      "[5025]\ttraining's binary_logloss: 0.0858734\n",
      "[5026]\ttraining's binary_logloss: 0.0858634\n",
      "[5027]\ttraining's binary_logloss: 0.0858536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5028]\ttraining's binary_logloss: 0.085851\n",
      "[5029]\ttraining's binary_logloss: 0.0858415\n",
      "[5030]\ttraining's binary_logloss: 0.085831\n",
      "[5031]\ttraining's binary_logloss: 0.0858231\n",
      "[5032]\ttraining's binary_logloss: 0.0858111\n",
      "[5033]\ttraining's binary_logloss: 0.0858021\n",
      "[5034]\ttraining's binary_logloss: 0.08579\n",
      "[5035]\ttraining's binary_logloss: 0.0857801\n",
      "[5036]\ttraining's binary_logloss: 0.0857707\n",
      "[5037]\ttraining's binary_logloss: 0.0857618\n",
      "[5038]\ttraining's binary_logloss: 0.0857522\n",
      "[5039]\ttraining's binary_logloss: 0.0857428\n",
      "[5040]\ttraining's binary_logloss: 0.0857351\n",
      "[5041]\ttraining's binary_logloss: 0.0857216\n",
      "[5042]\ttraining's binary_logloss: 0.0857118\n",
      "[5043]\ttraining's binary_logloss: 0.085704\n",
      "[5044]\ttraining's binary_logloss: 0.0856951\n",
      "[5045]\ttraining's binary_logloss: 0.0856848\n",
      "[5046]\ttraining's binary_logloss: 0.0856765\n",
      "[5047]\ttraining's binary_logloss: 0.0856681\n",
      "[5048]\ttraining's binary_logloss: 0.085657\n",
      "[5049]\ttraining's binary_logloss: 0.0856458\n",
      "[5050]\ttraining's binary_logloss: 0.0856359\n",
      "[5051]\ttraining's binary_logloss: 0.0856251\n",
      "[5052]\ttraining's binary_logloss: 0.085617\n",
      "[5053]\ttraining's binary_logloss: 0.0856061\n",
      "[5054]\ttraining's binary_logloss: 0.0855966\n",
      "[5055]\ttraining's binary_logloss: 0.0855855\n",
      "[5056]\ttraining's binary_logloss: 0.0855826\n",
      "[5057]\ttraining's binary_logloss: 0.0855722\n",
      "[5058]\ttraining's binary_logloss: 0.0855632\n",
      "[5059]\ttraining's binary_logloss: 0.0855542\n",
      "[5060]\ttraining's binary_logloss: 0.085544\n",
      "[5061]\ttraining's binary_logloss: 0.0855351\n",
      "[5062]\ttraining's binary_logloss: 0.0855263\n",
      "[5063]\ttraining's binary_logloss: 0.0855174\n",
      "[5064]\ttraining's binary_logloss: 0.0855086\n",
      "[5065]\ttraining's binary_logloss: 0.0854989\n",
      "[5066]\ttraining's binary_logloss: 0.0854894\n",
      "[5067]\ttraining's binary_logloss: 0.0854784\n",
      "[5068]\ttraining's binary_logloss: 0.0854682\n",
      "[5069]\ttraining's binary_logloss: 0.0854591\n",
      "[5070]\ttraining's binary_logloss: 0.0854501\n",
      "[5071]\ttraining's binary_logloss: 0.0854416\n",
      "[5072]\ttraining's binary_logloss: 0.0854375\n",
      "[5073]\ttraining's binary_logloss: 0.0854283\n",
      "[5074]\ttraining's binary_logloss: 0.0854193\n",
      "[5075]\ttraining's binary_logloss: 0.0854098\n",
      "[5076]\ttraining's binary_logloss: 0.0854007\n",
      "[5077]\ttraining's binary_logloss: 0.0853909\n",
      "[5078]\ttraining's binary_logloss: 0.0853803\n",
      "[5079]\ttraining's binary_logloss: 0.0853721\n",
      "[5080]\ttraining's binary_logloss: 0.085364\n",
      "[5081]\ttraining's binary_logloss: 0.0853542\n",
      "[5082]\ttraining's binary_logloss: 0.0853432\n",
      "[5083]\ttraining's binary_logloss: 0.0853372\n",
      "[5084]\ttraining's binary_logloss: 0.085328\n",
      "[5085]\ttraining's binary_logloss: 0.0853174\n",
      "[5086]\ttraining's binary_logloss: 0.0853079\n",
      "[5087]\ttraining's binary_logloss: 0.0852963\n",
      "[5088]\ttraining's binary_logloss: 0.0852904\n",
      "[5089]\ttraining's binary_logloss: 0.0852806\n",
      "[5090]\ttraining's binary_logloss: 0.0852721\n",
      "[5091]\ttraining's binary_logloss: 0.0852651\n",
      "[5092]\ttraining's binary_logloss: 0.0852548\n",
      "[5093]\ttraining's binary_logloss: 0.0852455\n",
      "[5094]\ttraining's binary_logloss: 0.0852357\n",
      "[5095]\ttraining's binary_logloss: 0.0852258\n",
      "[5096]\ttraining's binary_logloss: 0.0852187\n",
      "[5097]\ttraining's binary_logloss: 0.0852086\n",
      "[5098]\ttraining's binary_logloss: 0.0851988\n",
      "[5099]\ttraining's binary_logloss: 0.0851918\n",
      "[5100]\ttraining's binary_logloss: 0.0851814\n",
      "[5101]\ttraining's binary_logloss: 0.0851733\n",
      "[5102]\ttraining's binary_logloss: 0.0851607\n",
      "[5103]\ttraining's binary_logloss: 0.0851519\n",
      "[5104]\ttraining's binary_logloss: 0.0851416\n",
      "[5105]\ttraining's binary_logloss: 0.0851317\n",
      "[5106]\ttraining's binary_logloss: 0.0851228\n",
      "[5107]\ttraining's binary_logloss: 0.085114\n",
      "[5108]\ttraining's binary_logloss: 0.0851039\n",
      "[5109]\ttraining's binary_logloss: 0.0850943\n",
      "[5110]\ttraining's binary_logloss: 0.0850848\n",
      "[5111]\ttraining's binary_logloss: 0.0850753\n",
      "[5112]\ttraining's binary_logloss: 0.0850665\n",
      "[5113]\ttraining's binary_logloss: 0.0850564\n",
      "[5114]\ttraining's binary_logloss: 0.0850472\n",
      "[5115]\ttraining's binary_logloss: 0.085037\n",
      "[5116]\ttraining's binary_logloss: 0.0850254\n",
      "[5117]\ttraining's binary_logloss: 0.0850153\n",
      "[5118]\ttraining's binary_logloss: 0.0850067\n",
      "[5119]\ttraining's binary_logloss: 0.0849965\n",
      "[5120]\ttraining's binary_logloss: 0.0849882\n",
      "[5121]\ttraining's binary_logloss: 0.0849832\n",
      "[5122]\ttraining's binary_logloss: 0.0849732\n",
      "[5123]\ttraining's binary_logloss: 0.0849609\n",
      "[5124]\ttraining's binary_logloss: 0.0849514\n",
      "[5125]\ttraining's binary_logloss: 0.0849422\n",
      "[5126]\ttraining's binary_logloss: 0.0849332\n",
      "[5127]\ttraining's binary_logloss: 0.084925\n",
      "[5128]\ttraining's binary_logloss: 0.0849152\n",
      "[5129]\ttraining's binary_logloss: 0.0849063\n",
      "[5130]\ttraining's binary_logloss: 0.0848976\n",
      "[5131]\ttraining's binary_logloss: 0.0848887\n",
      "[5132]\ttraining's binary_logloss: 0.084878\n",
      "[5133]\ttraining's binary_logloss: 0.084868\n",
      "[5134]\ttraining's binary_logloss: 0.0848577\n",
      "[5135]\ttraining's binary_logloss: 0.084847\n",
      "[5136]\ttraining's binary_logloss: 0.0848378\n",
      "[5137]\ttraining's binary_logloss: 0.0848271\n",
      "[5138]\ttraining's binary_logloss: 0.084818\n",
      "[5139]\ttraining's binary_logloss: 0.0848082\n",
      "[5140]\ttraining's binary_logloss: 0.0847989\n",
      "[5141]\ttraining's binary_logloss: 0.084791\n",
      "[5142]\ttraining's binary_logloss: 0.0847806\n",
      "[5143]\ttraining's binary_logloss: 0.0847698\n",
      "[5144]\ttraining's binary_logloss: 0.0847602\n",
      "[5145]\ttraining's binary_logloss: 0.0847494\n",
      "[5146]\ttraining's binary_logloss: 0.0847396\n",
      "[5147]\ttraining's binary_logloss: 0.0847309\n",
      "[5148]\ttraining's binary_logloss: 0.0847216\n",
      "[5149]\ttraining's binary_logloss: 0.0847167\n",
      "[5150]\ttraining's binary_logloss: 0.0847059\n",
      "[5151]\ttraining's binary_logloss: 0.0846969\n",
      "[5152]\ttraining's binary_logloss: 0.0846945\n",
      "[5153]\ttraining's binary_logloss: 0.0846833\n",
      "[5154]\ttraining's binary_logloss: 0.084675\n",
      "[5155]\ttraining's binary_logloss: 0.0846653\n",
      "[5156]\ttraining's binary_logloss: 0.0846576\n",
      "[5157]\ttraining's binary_logloss: 0.0846482\n",
      "[5158]\ttraining's binary_logloss: 0.0846387\n",
      "[5159]\ttraining's binary_logloss: 0.0846298\n",
      "[5160]\ttraining's binary_logloss: 0.08462\n",
      "[5161]\ttraining's binary_logloss: 0.0846155\n",
      "[5162]\ttraining's binary_logloss: 0.084613\n",
      "[5163]\ttraining's binary_logloss: 0.0846033\n",
      "[5164]\ttraining's binary_logloss: 0.0845931\n",
      "[5165]\ttraining's binary_logloss: 0.0845829\n",
      "[5166]\ttraining's binary_logloss: 0.0845736\n",
      "[5167]\ttraining's binary_logloss: 0.0845649\n",
      "[5168]\ttraining's binary_logloss: 0.0845561\n",
      "[5169]\ttraining's binary_logloss: 0.084548\n",
      "[5170]\ttraining's binary_logloss: 0.0845417\n",
      "[5171]\ttraining's binary_logloss: 0.0845328\n",
      "[5172]\ttraining's binary_logloss: 0.0845231\n",
      "[5173]\ttraining's binary_logloss: 0.0845135\n",
      "[5174]\ttraining's binary_logloss: 0.0845058\n",
      "[5175]\ttraining's binary_logloss: 0.0845007\n",
      "[5176]\ttraining's binary_logloss: 0.0844928\n",
      "[5177]\ttraining's binary_logloss: 0.0844833\n",
      "[5178]\ttraining's binary_logloss: 0.0844745\n",
      "[5179]\ttraining's binary_logloss: 0.0844673\n",
      "[5180]\ttraining's binary_logloss: 0.0844562\n",
      "[5181]\ttraining's binary_logloss: 0.0844503\n",
      "[5182]\ttraining's binary_logloss: 0.0844465\n",
      "[5183]\ttraining's binary_logloss: 0.0844404\n",
      "[5184]\ttraining's binary_logloss: 0.0844301\n",
      "[5185]\ttraining's binary_logloss: 0.0844205\n",
      "[5186]\ttraining's binary_logloss: 0.0844135\n",
      "[5187]\ttraining's binary_logloss: 0.084405\n",
      "[5188]\ttraining's binary_logloss: 0.0843957\n",
      "[5189]\ttraining's binary_logloss: 0.0843878\n",
      "[5190]\ttraining's binary_logloss: 0.0843808\n",
      "[5191]\ttraining's binary_logloss: 0.0843733\n",
      "[5192]\ttraining's binary_logloss: 0.084367\n",
      "[5193]\ttraining's binary_logloss: 0.084358\n",
      "[5194]\ttraining's binary_logloss: 0.0843496\n",
      "[5195]\ttraining's binary_logloss: 0.0843472\n",
      "[5196]\ttraining's binary_logloss: 0.084338\n",
      "[5197]\ttraining's binary_logloss: 0.0843342\n",
      "[5198]\ttraining's binary_logloss: 0.0843269\n",
      "[5199]\ttraining's binary_logloss: 0.0843176\n",
      "[5200]\ttraining's binary_logloss: 0.0843118\n",
      "[5201]\ttraining's binary_logloss: 0.0843076\n",
      "[5202]\ttraining's binary_logloss: 0.0842981\n",
      "[5203]\ttraining's binary_logloss: 0.0842862\n",
      "[5204]\ttraining's binary_logloss: 0.0842691\n",
      "[5205]\ttraining's binary_logloss: 0.084261\n",
      "[5206]\ttraining's binary_logloss: 0.0842514\n",
      "[5207]\ttraining's binary_logloss: 0.0842424\n",
      "[5208]\ttraining's binary_logloss: 0.084233\n",
      "[5209]\ttraining's binary_logloss: 0.0842264\n",
      "[5210]\ttraining's binary_logloss: 0.0842166\n",
      "[5211]\ttraining's binary_logloss: 0.084208\n",
      "[5212]\ttraining's binary_logloss: 0.0842\n",
      "[5213]\ttraining's binary_logloss: 0.084191\n",
      "[5214]\ttraining's binary_logloss: 0.0841828\n",
      "[5215]\ttraining's binary_logloss: 0.0841782\n",
      "[5216]\ttraining's binary_logloss: 0.0841701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5217]\ttraining's binary_logloss: 0.0841609\n",
      "[5218]\ttraining's binary_logloss: 0.0841524\n",
      "[5219]\ttraining's binary_logloss: 0.0841433\n",
      "[5220]\ttraining's binary_logloss: 0.084135\n",
      "[5221]\ttraining's binary_logloss: 0.0841261\n",
      "[5222]\ttraining's binary_logloss: 0.0841183\n",
      "[5223]\ttraining's binary_logloss: 0.0841139\n",
      "[5224]\ttraining's binary_logloss: 0.0841037\n",
      "[5225]\ttraining's binary_logloss: 0.0840944\n",
      "[5226]\ttraining's binary_logloss: 0.0840885\n",
      "[5227]\ttraining's binary_logloss: 0.0840801\n",
      "[5228]\ttraining's binary_logloss: 0.0840706\n",
      "[5229]\ttraining's binary_logloss: 0.0840658\n",
      "[5230]\ttraining's binary_logloss: 0.0840587\n",
      "[5231]\ttraining's binary_logloss: 0.0840533\n",
      "[5232]\ttraining's binary_logloss: 0.0840451\n",
      "[5233]\ttraining's binary_logloss: 0.0840379\n",
      "[5234]\ttraining's binary_logloss: 0.0840351\n",
      "[5235]\ttraining's binary_logloss: 0.0840259\n",
      "[5236]\ttraining's binary_logloss: 0.0840172\n",
      "[5237]\ttraining's binary_logloss: 0.0840077\n",
      "[5238]\ttraining's binary_logloss: 0.0839953\n",
      "[5239]\ttraining's binary_logloss: 0.0839891\n",
      "[5240]\ttraining's binary_logloss: 0.0839805\n",
      "[5241]\ttraining's binary_logloss: 0.083965\n",
      "[5242]\ttraining's binary_logloss: 0.083959\n",
      "[5243]\ttraining's binary_logloss: 0.0839507\n",
      "[5244]\ttraining's binary_logloss: 0.0839426\n",
      "[5245]\ttraining's binary_logloss: 0.0839356\n",
      "[5246]\ttraining's binary_logloss: 0.0839267\n",
      "[5247]\ttraining's binary_logloss: 0.0839175\n",
      "[5248]\ttraining's binary_logloss: 0.083914\n",
      "[5249]\ttraining's binary_logloss: 0.0839076\n",
      "[5250]\ttraining's binary_logloss: 0.0838998\n",
      "[5251]\ttraining's binary_logloss: 0.0838856\n",
      "[5252]\ttraining's binary_logloss: 0.0838754\n",
      "[5253]\ttraining's binary_logloss: 0.083871\n",
      "[5254]\ttraining's binary_logloss: 0.0838628\n",
      "[5255]\ttraining's binary_logloss: 0.0838542\n",
      "[5256]\ttraining's binary_logloss: 0.0838447\n",
      "[5257]\ttraining's binary_logloss: 0.083835\n",
      "[5258]\ttraining's binary_logloss: 0.0838261\n",
      "[5259]\ttraining's binary_logloss: 0.083821\n",
      "[5260]\ttraining's binary_logloss: 0.0838106\n",
      "[5261]\ttraining's binary_logloss: 0.0838011\n",
      "[5262]\ttraining's binary_logloss: 0.0837937\n",
      "[5263]\ttraining's binary_logloss: 0.0837915\n",
      "[5264]\ttraining's binary_logloss: 0.0837817\n",
      "[5265]\ttraining's binary_logloss: 0.0837719\n",
      "[5266]\ttraining's binary_logloss: 0.0837645\n",
      "[5267]\ttraining's binary_logloss: 0.0837545\n",
      "[5268]\ttraining's binary_logloss: 0.0837455\n",
      "[5269]\ttraining's binary_logloss: 0.0837372\n",
      "[5270]\ttraining's binary_logloss: 0.0837289\n",
      "[5271]\ttraining's binary_logloss: 0.0837201\n",
      "[5272]\ttraining's binary_logloss: 0.0837111\n",
      "[5273]\ttraining's binary_logloss: 0.083702\n",
      "[5274]\ttraining's binary_logloss: 0.0836934\n",
      "[5275]\ttraining's binary_logloss: 0.0836846\n",
      "[5276]\ttraining's binary_logloss: 0.0836775\n",
      "[5277]\ttraining's binary_logloss: 0.0836745\n",
      "[5278]\ttraining's binary_logloss: 0.083671\n",
      "[5279]\ttraining's binary_logloss: 0.083661\n",
      "[5280]\ttraining's binary_logloss: 0.0836522\n",
      "[5281]\ttraining's binary_logloss: 0.0836481\n",
      "[5282]\ttraining's binary_logloss: 0.083639\n",
      "[5283]\ttraining's binary_logloss: 0.0836303\n",
      "[5284]\ttraining's binary_logloss: 0.0836207\n",
      "[5285]\ttraining's binary_logloss: 0.0836112\n",
      "[5286]\ttraining's binary_logloss: 0.0836035\n",
      "[5287]\ttraining's binary_logloss: 0.0835958\n",
      "[5288]\ttraining's binary_logloss: 0.083586\n",
      "[5289]\ttraining's binary_logloss: 0.0835748\n",
      "[5290]\ttraining's binary_logloss: 0.0835658\n",
      "[5291]\ttraining's binary_logloss: 0.0835556\n",
      "[5292]\ttraining's binary_logloss: 0.0835467\n",
      "[5293]\ttraining's binary_logloss: 0.0835367\n",
      "[5294]\ttraining's binary_logloss: 0.0835267\n",
      "[5295]\ttraining's binary_logloss: 0.0835172\n",
      "[5296]\ttraining's binary_logloss: 0.0835084\n",
      "[5297]\ttraining's binary_logloss: 0.0834993\n",
      "[5298]\ttraining's binary_logloss: 0.0834894\n",
      "[5299]\ttraining's binary_logloss: 0.0834809\n",
      "[5300]\ttraining's binary_logloss: 0.0834711\n",
      "[5301]\ttraining's binary_logloss: 0.0834617\n",
      "[5302]\ttraining's binary_logloss: 0.0834529\n",
      "[5303]\ttraining's binary_logloss: 0.0834439\n",
      "[5304]\ttraining's binary_logloss: 0.0834346\n",
      "[5305]\ttraining's binary_logloss: 0.0834257\n",
      "[5306]\ttraining's binary_logloss: 0.0834177\n",
      "[5307]\ttraining's binary_logloss: 0.0834093\n",
      "[5308]\ttraining's binary_logloss: 0.0833998\n",
      "[5309]\ttraining's binary_logloss: 0.0833937\n",
      "[5310]\ttraining's binary_logloss: 0.0833854\n",
      "[5311]\ttraining's binary_logloss: 0.083375\n",
      "[5312]\ttraining's binary_logloss: 0.0833658\n",
      "[5313]\ttraining's binary_logloss: 0.0833596\n",
      "[5314]\ttraining's binary_logloss: 0.0833506\n",
      "[5315]\ttraining's binary_logloss: 0.0833406\n",
      "[5316]\ttraining's binary_logloss: 0.0833317\n",
      "[5317]\ttraining's binary_logloss: 0.0833236\n",
      "[5318]\ttraining's binary_logloss: 0.0833146\n",
      "[5319]\ttraining's binary_logloss: 0.0833059\n",
      "[5320]\ttraining's binary_logloss: 0.083298\n",
      "[5321]\ttraining's binary_logloss: 0.0832879\n",
      "[5322]\ttraining's binary_logloss: 0.0832794\n",
      "[5323]\ttraining's binary_logloss: 0.0832696\n",
      "[5324]\ttraining's binary_logloss: 0.0832597\n",
      "[5325]\ttraining's binary_logloss: 0.083249\n",
      "[5326]\ttraining's binary_logloss: 0.0832417\n",
      "[5327]\ttraining's binary_logloss: 0.0832328\n",
      "[5328]\ttraining's binary_logloss: 0.0832234\n",
      "[5329]\ttraining's binary_logloss: 0.083215\n",
      "[5330]\ttraining's binary_logloss: 0.0832057\n",
      "[5331]\ttraining's binary_logloss: 0.0831946\n",
      "[5332]\ttraining's binary_logloss: 0.0831868\n",
      "[5333]\ttraining's binary_logloss: 0.0831818\n",
      "[5334]\ttraining's binary_logloss: 0.0831721\n",
      "[5335]\ttraining's binary_logloss: 0.0831632\n",
      "[5336]\ttraining's binary_logloss: 0.0831538\n",
      "[5337]\ttraining's binary_logloss: 0.0831445\n",
      "[5338]\ttraining's binary_logloss: 0.0831352\n",
      "[5339]\ttraining's binary_logloss: 0.083127\n",
      "[5340]\ttraining's binary_logloss: 0.0831184\n",
      "[5341]\ttraining's binary_logloss: 0.0831094\n",
      "[5342]\ttraining's binary_logloss: 0.083099\n",
      "[5343]\ttraining's binary_logloss: 0.0830914\n",
      "[5344]\ttraining's binary_logloss: 0.0830833\n",
      "[5345]\ttraining's binary_logloss: 0.0830785\n",
      "[5346]\ttraining's binary_logloss: 0.083068\n",
      "[5347]\ttraining's binary_logloss: 0.0830584\n",
      "[5348]\ttraining's binary_logloss: 0.0830486\n",
      "[5349]\ttraining's binary_logloss: 0.0830398\n",
      "[5350]\ttraining's binary_logloss: 0.083031\n",
      "[5351]\ttraining's binary_logloss: 0.0830213\n",
      "[5352]\ttraining's binary_logloss: 0.0830114\n",
      "[5353]\ttraining's binary_logloss: 0.0830041\n",
      "[5354]\ttraining's binary_logloss: 0.0829946\n",
      "[5355]\ttraining's binary_logloss: 0.0829851\n",
      "[5356]\ttraining's binary_logloss: 0.0829771\n",
      "[5357]\ttraining's binary_logloss: 0.0829676\n",
      "[5358]\ttraining's binary_logloss: 0.0829581\n",
      "[5359]\ttraining's binary_logloss: 0.0829484\n",
      "[5360]\ttraining's binary_logloss: 0.0829421\n",
      "[5361]\ttraining's binary_logloss: 0.0829327\n",
      "[5362]\ttraining's binary_logloss: 0.0829228\n",
      "[5363]\ttraining's binary_logloss: 0.0829124\n",
      "[5364]\ttraining's binary_logloss: 0.082903\n",
      "[5365]\ttraining's binary_logloss: 0.0828955\n",
      "[5366]\ttraining's binary_logloss: 0.0828865\n",
      "[5367]\ttraining's binary_logloss: 0.0828773\n",
      "[5368]\ttraining's binary_logloss: 0.082867\n",
      "[5369]\ttraining's binary_logloss: 0.0828585\n",
      "[5370]\ttraining's binary_logloss: 0.0828489\n",
      "[5371]\ttraining's binary_logloss: 0.0828393\n",
      "[5372]\ttraining's binary_logloss: 0.0828306\n",
      "[5373]\ttraining's binary_logloss: 0.0828218\n",
      "[5374]\ttraining's binary_logloss: 0.0828152\n",
      "[5375]\ttraining's binary_logloss: 0.0828062\n",
      "[5376]\ttraining's binary_logloss: 0.0827966\n",
      "[5377]\ttraining's binary_logloss: 0.0827879\n",
      "[5378]\ttraining's binary_logloss: 0.0827867\n",
      "[5379]\ttraining's binary_logloss: 0.082778\n",
      "[5380]\ttraining's binary_logloss: 0.0827729\n",
      "[5381]\ttraining's binary_logloss: 0.0827639\n",
      "[5382]\ttraining's binary_logloss: 0.0827556\n",
      "[5383]\ttraining's binary_logloss: 0.0827458\n",
      "[5384]\ttraining's binary_logloss: 0.0827349\n",
      "[5385]\ttraining's binary_logloss: 0.0827282\n",
      "[5386]\ttraining's binary_logloss: 0.0827186\n",
      "[5387]\ttraining's binary_logloss: 0.0827097\n",
      "[5388]\ttraining's binary_logloss: 0.0827001\n",
      "[5389]\ttraining's binary_logloss: 0.0826906\n",
      "[5390]\ttraining's binary_logloss: 0.0826808\n",
      "[5391]\ttraining's binary_logloss: 0.0826728\n",
      "[5392]\ttraining's binary_logloss: 0.0826646\n",
      "[5393]\ttraining's binary_logloss: 0.0826541\n",
      "[5394]\ttraining's binary_logloss: 0.0826448\n",
      "[5395]\ttraining's binary_logloss: 0.0826364\n",
      "[5396]\ttraining's binary_logloss: 0.0826345\n",
      "[5397]\ttraining's binary_logloss: 0.0826293\n",
      "[5398]\ttraining's binary_logloss: 0.0826216\n",
      "[5399]\ttraining's binary_logloss: 0.0826117\n",
      "[5400]\ttraining's binary_logloss: 0.0826017\n",
      "[5401]\ttraining's binary_logloss: 0.0825922\n",
      "[5402]\ttraining's binary_logloss: 0.0825829\n",
      "[5403]\ttraining's binary_logloss: 0.082575\n",
      "[5404]\ttraining's binary_logloss: 0.0825658\n",
      "[5405]\ttraining's binary_logloss: 0.0825557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5406]\ttraining's binary_logloss: 0.0825502\n",
      "[5407]\ttraining's binary_logloss: 0.0825486\n",
      "[5408]\ttraining's binary_logloss: 0.0825453\n",
      "[5409]\ttraining's binary_logloss: 0.082536\n",
      "[5410]\ttraining's binary_logloss: 0.0825283\n",
      "[5411]\ttraining's binary_logloss: 0.0825184\n",
      "[5412]\ttraining's binary_logloss: 0.0825111\n",
      "[5413]\ttraining's binary_logloss: 0.0825014\n",
      "[5414]\ttraining's binary_logloss: 0.0824922\n",
      "[5415]\ttraining's binary_logloss: 0.0824906\n",
      "[5416]\ttraining's binary_logloss: 0.0824817\n",
      "[5417]\ttraining's binary_logloss: 0.0824738\n",
      "[5418]\ttraining's binary_logloss: 0.0824649\n",
      "[5419]\ttraining's binary_logloss: 0.0824576\n",
      "[5420]\ttraining's binary_logloss: 0.0824489\n",
      "[5421]\ttraining's binary_logloss: 0.0824406\n",
      "[5422]\ttraining's binary_logloss: 0.0824349\n",
      "[5423]\ttraining's binary_logloss: 0.0824256\n",
      "[5424]\ttraining's binary_logloss: 0.0824178\n",
      "[5425]\ttraining's binary_logloss: 0.082409\n",
      "[5426]\ttraining's binary_logloss: 0.0824025\n",
      "[5427]\ttraining's binary_logloss: 0.0823939\n",
      "[5428]\ttraining's binary_logloss: 0.0823855\n",
      "[5429]\ttraining's binary_logloss: 0.0823761\n",
      "[5430]\ttraining's binary_logloss: 0.0823673\n",
      "[5431]\ttraining's binary_logloss: 0.0823584\n",
      "[5432]\ttraining's binary_logloss: 0.08235\n",
      "[5433]\ttraining's binary_logloss: 0.0823415\n",
      "[5434]\ttraining's binary_logloss: 0.0823334\n",
      "[5435]\ttraining's binary_logloss: 0.0823254\n",
      "[5436]\ttraining's binary_logloss: 0.0823171\n",
      "[5437]\ttraining's binary_logloss: 0.0823082\n",
      "[5438]\ttraining's binary_logloss: 0.0822988\n",
      "[5439]\ttraining's binary_logloss: 0.0822899\n",
      "[5440]\ttraining's binary_logloss: 0.0822805\n",
      "[5441]\ttraining's binary_logloss: 0.082272\n",
      "[5442]\ttraining's binary_logloss: 0.0822645\n",
      "[5443]\ttraining's binary_logloss: 0.082255\n",
      "[5444]\ttraining's binary_logloss: 0.0822453\n",
      "[5445]\ttraining's binary_logloss: 0.0822357\n",
      "[5446]\ttraining's binary_logloss: 0.0822261\n",
      "[5447]\ttraining's binary_logloss: 0.0822176\n",
      "[5448]\ttraining's binary_logloss: 0.082208\n",
      "[5449]\ttraining's binary_logloss: 0.0821988\n",
      "[5450]\ttraining's binary_logloss: 0.08219\n",
      "[5451]\ttraining's binary_logloss: 0.0821807\n",
      "[5452]\ttraining's binary_logloss: 0.082173\n",
      "[5453]\ttraining's binary_logloss: 0.0821634\n",
      "[5454]\ttraining's binary_logloss: 0.0821533\n",
      "[5455]\ttraining's binary_logloss: 0.0821449\n",
      "[5456]\ttraining's binary_logloss: 0.0821431\n",
      "[5457]\ttraining's binary_logloss: 0.0821338\n",
      "[5458]\ttraining's binary_logloss: 0.0821254\n",
      "[5459]\ttraining's binary_logloss: 0.0821169\n",
      "[5460]\ttraining's binary_logloss: 0.0821079\n",
      "[5461]\ttraining's binary_logloss: 0.0820975\n",
      "[5462]\ttraining's binary_logloss: 0.08209\n",
      "[5463]\ttraining's binary_logloss: 0.0820816\n",
      "[5464]\ttraining's binary_logloss: 0.0820746\n",
      "[5465]\ttraining's binary_logloss: 0.0820649\n",
      "[5466]\ttraining's binary_logloss: 0.0820568\n",
      "[5467]\ttraining's binary_logloss: 0.0820488\n",
      "[5468]\ttraining's binary_logloss: 0.0820409\n",
      "[5469]\ttraining's binary_logloss: 0.0820333\n",
      "[5470]\ttraining's binary_logloss: 0.0820278\n",
      "[5471]\ttraining's binary_logloss: 0.0820207\n",
      "[5472]\ttraining's binary_logloss: 0.0820108\n",
      "[5473]\ttraining's binary_logloss: 0.082003\n",
      "[5474]\ttraining's binary_logloss: 0.0819923\n",
      "[5475]\ttraining's binary_logloss: 0.0819886\n",
      "[5476]\ttraining's binary_logloss: 0.0819804\n",
      "[5477]\ttraining's binary_logloss: 0.081971\n",
      "[5478]\ttraining's binary_logloss: 0.081962\n",
      "[5479]\ttraining's binary_logloss: 0.0819556\n",
      "[5480]\ttraining's binary_logloss: 0.0819469\n",
      "[5481]\ttraining's binary_logloss: 0.0819374\n",
      "[5482]\ttraining's binary_logloss: 0.0819282\n",
      "[5483]\ttraining's binary_logloss: 0.0819208\n",
      "[5484]\ttraining's binary_logloss: 0.0819149\n",
      "[5485]\ttraining's binary_logloss: 0.0819046\n",
      "[5486]\ttraining's binary_logloss: 0.081895\n",
      "[5487]\ttraining's binary_logloss: 0.0818856\n",
      "[5488]\ttraining's binary_logloss: 0.081876\n",
      "[5489]\ttraining's binary_logloss: 0.0818668\n",
      "[5490]\ttraining's binary_logloss: 0.081858\n",
      "[5491]\ttraining's binary_logloss: 0.0818514\n",
      "[5492]\ttraining's binary_logloss: 0.0818427\n",
      "[5493]\ttraining's binary_logloss: 0.0818349\n",
      "[5494]\ttraining's binary_logloss: 0.0818249\n",
      "[5495]\ttraining's binary_logloss: 0.0818162\n",
      "[5496]\ttraining's binary_logloss: 0.0818121\n",
      "[5497]\ttraining's binary_logloss: 0.0818035\n",
      "[5498]\ttraining's binary_logloss: 0.0817952\n",
      "[5499]\ttraining's binary_logloss: 0.0817868\n",
      "[5500]\ttraining's binary_logloss: 0.0817786\n",
      "[5501]\ttraining's binary_logloss: 0.0817678\n",
      "[5502]\ttraining's binary_logloss: 0.0817594\n",
      "[5503]\ttraining's binary_logloss: 0.0817538\n",
      "[5504]\ttraining's binary_logloss: 0.0817444\n",
      "[5505]\ttraining's binary_logloss: 0.0817368\n",
      "[5506]\ttraining's binary_logloss: 0.0817285\n",
      "[5507]\ttraining's binary_logloss: 0.0817215\n",
      "[5508]\ttraining's binary_logloss: 0.0817137\n",
      "[5509]\ttraining's binary_logloss: 0.0817044\n",
      "[5510]\ttraining's binary_logloss: 0.0816956\n",
      "[5511]\ttraining's binary_logloss: 0.0816853\n",
      "[5512]\ttraining's binary_logloss: 0.0816767\n",
      "[5513]\ttraining's binary_logloss: 0.0816677\n",
      "[5514]\ttraining's binary_logloss: 0.0816594\n",
      "[5515]\ttraining's binary_logloss: 0.0816511\n",
      "[5516]\ttraining's binary_logloss: 0.081642\n",
      "[5517]\ttraining's binary_logloss: 0.081633\n",
      "[5518]\ttraining's binary_logloss: 0.0816251\n",
      "[5519]\ttraining's binary_logloss: 0.081617\n",
      "[5520]\ttraining's binary_logloss: 0.0816074\n",
      "[5521]\ttraining's binary_logloss: 0.0815982\n",
      "[5522]\ttraining's binary_logloss: 0.0815908\n",
      "[5523]\ttraining's binary_logloss: 0.0815818\n",
      "[5524]\ttraining's binary_logloss: 0.0815725\n",
      "[5525]\ttraining's binary_logloss: 0.0815656\n",
      "[5526]\ttraining's binary_logloss: 0.0815567\n",
      "[5527]\ttraining's binary_logloss: 0.0815478\n",
      "[5528]\ttraining's binary_logloss: 0.08154\n",
      "[5529]\ttraining's binary_logloss: 0.0815334\n",
      "[5530]\ttraining's binary_logloss: 0.0815243\n",
      "[5531]\ttraining's binary_logloss: 0.081515\n",
      "[5532]\ttraining's binary_logloss: 0.0815044\n",
      "[5533]\ttraining's binary_logloss: 0.0814985\n",
      "[5534]\ttraining's binary_logloss: 0.0814894\n",
      "[5535]\ttraining's binary_logloss: 0.0814823\n",
      "[5536]\ttraining's binary_logloss: 0.0814726\n",
      "[5537]\ttraining's binary_logloss: 0.0814648\n",
      "[5538]\ttraining's binary_logloss: 0.0814552\n",
      "[5539]\ttraining's binary_logloss: 0.0814452\n",
      "[5540]\ttraining's binary_logloss: 0.0814372\n",
      "[5541]\ttraining's binary_logloss: 0.0814282\n",
      "[5542]\ttraining's binary_logloss: 0.0814222\n",
      "[5543]\ttraining's binary_logloss: 0.0814128\n",
      "[5544]\ttraining's binary_logloss: 0.0814033\n",
      "[5545]\ttraining's binary_logloss: 0.0813947\n",
      "[5546]\ttraining's binary_logloss: 0.0813849\n",
      "[5547]\ttraining's binary_logloss: 0.0813763\n",
      "[5548]\ttraining's binary_logloss: 0.0813663\n",
      "[5549]\ttraining's binary_logloss: 0.0813575\n",
      "[5550]\ttraining's binary_logloss: 0.0813483\n",
      "[5551]\ttraining's binary_logloss: 0.0813382\n",
      "[5552]\ttraining's binary_logloss: 0.0813301\n",
      "[5553]\ttraining's binary_logloss: 0.0813212\n",
      "[5554]\ttraining's binary_logloss: 0.0813111\n",
      "[5555]\ttraining's binary_logloss: 0.0813003\n",
      "[5556]\ttraining's binary_logloss: 0.0812924\n",
      "[5557]\ttraining's binary_logloss: 0.0812816\n",
      "[5558]\ttraining's binary_logloss: 0.081272\n",
      "[5559]\ttraining's binary_logloss: 0.0812638\n",
      "[5560]\ttraining's binary_logloss: 0.0812553\n",
      "[5561]\ttraining's binary_logloss: 0.0812454\n",
      "[5562]\ttraining's binary_logloss: 0.0812365\n",
      "[5563]\ttraining's binary_logloss: 0.0812262\n",
      "[5564]\ttraining's binary_logloss: 0.0812185\n",
      "[5565]\ttraining's binary_logloss: 0.08121\n",
      "[5566]\ttraining's binary_logloss: 0.0812009\n",
      "[5567]\ttraining's binary_logloss: 0.0811919\n",
      "[5568]\ttraining's binary_logloss: 0.0811855\n",
      "[5569]\ttraining's binary_logloss: 0.0811779\n",
      "[5570]\ttraining's binary_logloss: 0.0811676\n",
      "[5571]\ttraining's binary_logloss: 0.0811594\n",
      "[5572]\ttraining's binary_logloss: 0.0811504\n",
      "[5573]\ttraining's binary_logloss: 0.081145\n",
      "[5574]\ttraining's binary_logloss: 0.0811386\n",
      "[5575]\ttraining's binary_logloss: 0.0811291\n",
      "[5576]\ttraining's binary_logloss: 0.0811224\n",
      "[5577]\ttraining's binary_logloss: 0.0811132\n",
      "[5578]\ttraining's binary_logloss: 0.0811041\n",
      "[5579]\ttraining's binary_logloss: 0.0810937\n",
      "[5580]\ttraining's binary_logloss: 0.0810849\n",
      "[5581]\ttraining's binary_logloss: 0.0810752\n",
      "[5582]\ttraining's binary_logloss: 0.0810675\n",
      "[5583]\ttraining's binary_logloss: 0.0810572\n",
      "[5584]\ttraining's binary_logloss: 0.0810496\n",
      "[5585]\ttraining's binary_logloss: 0.0810405\n",
      "[5586]\ttraining's binary_logloss: 0.081037\n",
      "[5587]\ttraining's binary_logloss: 0.0810278\n",
      "[5588]\ttraining's binary_logloss: 0.0810197\n",
      "[5589]\ttraining's binary_logloss: 0.0810124\n",
      "[5590]\ttraining's binary_logloss: 0.0810039\n",
      "[5591]\ttraining's binary_logloss: 0.080998\n",
      "[5592]\ttraining's binary_logloss: 0.080989\n",
      "[5593]\ttraining's binary_logloss: 0.0809805\n",
      "[5594]\ttraining's binary_logloss: 0.0809765\n",
      "[5595]\ttraining's binary_logloss: 0.0809676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5596]\ttraining's binary_logloss: 0.0809619\n",
      "[5597]\ttraining's binary_logloss: 0.080952\n",
      "[5598]\ttraining's binary_logloss: 0.0809447\n",
      "[5599]\ttraining's binary_logloss: 0.0809406\n",
      "[5600]\ttraining's binary_logloss: 0.0809322\n",
      "[5601]\ttraining's binary_logloss: 0.0809254\n",
      "[5602]\ttraining's binary_logloss: 0.0809203\n",
      "[5603]\ttraining's binary_logloss: 0.0809103\n",
      "[5604]\ttraining's binary_logloss: 0.0809027\n",
      "[5605]\ttraining's binary_logloss: 0.0808931\n",
      "[5606]\ttraining's binary_logloss: 0.0808832\n",
      "[5607]\ttraining's binary_logloss: 0.0808751\n",
      "[5608]\ttraining's binary_logloss: 0.0808645\n",
      "[5609]\ttraining's binary_logloss: 0.0808564\n",
      "[5610]\ttraining's binary_logloss: 0.0808484\n",
      "[5611]\ttraining's binary_logloss: 0.0808389\n",
      "[5612]\ttraining's binary_logloss: 0.0808295\n",
      "[5613]\ttraining's binary_logloss: 0.0808208\n",
      "[5614]\ttraining's binary_logloss: 0.0808124\n",
      "[5615]\ttraining's binary_logloss: 0.0808078\n",
      "[5616]\ttraining's binary_logloss: 0.0807986\n",
      "[5617]\ttraining's binary_logloss: 0.0807923\n",
      "[5618]\ttraining's binary_logloss: 0.080783\n",
      "[5619]\ttraining's binary_logloss: 0.0807749\n",
      "[5620]\ttraining's binary_logloss: 0.0807661\n",
      "[5621]\ttraining's binary_logloss: 0.0807559\n",
      "[5622]\ttraining's binary_logloss: 0.0807486\n",
      "[5623]\ttraining's binary_logloss: 0.0807471\n",
      "[5624]\ttraining's binary_logloss: 0.0807379\n",
      "[5625]\ttraining's binary_logloss: 0.0807265\n",
      "[5626]\ttraining's binary_logloss: 0.0807169\n",
      "[5627]\ttraining's binary_logloss: 0.0807076\n",
      "[5628]\ttraining's binary_logloss: 0.0806984\n",
      "[5629]\ttraining's binary_logloss: 0.0806892\n",
      "[5630]\ttraining's binary_logloss: 0.0806802\n",
      "[5631]\ttraining's binary_logloss: 0.0806716\n",
      "[5632]\ttraining's binary_logloss: 0.0806619\n",
      "[5633]\ttraining's binary_logloss: 0.0806528\n",
      "[5634]\ttraining's binary_logloss: 0.0806445\n",
      "[5635]\ttraining's binary_logloss: 0.0806398\n",
      "[5636]\ttraining's binary_logloss: 0.0806318\n",
      "[5637]\ttraining's binary_logloss: 0.080624\n",
      "[5638]\ttraining's binary_logloss: 0.080619\n",
      "[5639]\ttraining's binary_logloss: 0.0806089\n",
      "[5640]\ttraining's binary_logloss: 0.0806001\n",
      "[5641]\ttraining's binary_logloss: 0.0805933\n",
      "[5642]\ttraining's binary_logloss: 0.080585\n",
      "[5643]\ttraining's binary_logloss: 0.080578\n",
      "[5644]\ttraining's binary_logloss: 0.0805723\n",
      "[5645]\ttraining's binary_logloss: 0.0805645\n",
      "[5646]\ttraining's binary_logloss: 0.0805542\n",
      "[5647]\ttraining's binary_logloss: 0.0805491\n",
      "[5648]\ttraining's binary_logloss: 0.0805391\n",
      "[5649]\ttraining's binary_logloss: 0.0805315\n",
      "[5650]\ttraining's binary_logloss: 0.0805266\n",
      "[5651]\ttraining's binary_logloss: 0.0805167\n",
      "[5652]\ttraining's binary_logloss: 0.0805062\n",
      "[5653]\ttraining's binary_logloss: 0.0804982\n",
      "[5654]\ttraining's binary_logloss: 0.0804897\n",
      "[5655]\ttraining's binary_logloss: 0.0804814\n",
      "[5656]\ttraining's binary_logloss: 0.0804725\n",
      "[5657]\ttraining's binary_logloss: 0.0804637\n",
      "[5658]\ttraining's binary_logloss: 0.080455\n",
      "[5659]\ttraining's binary_logloss: 0.0804461\n",
      "[5660]\ttraining's binary_logloss: 0.0804423\n",
      "[5661]\ttraining's binary_logloss: 0.0804386\n",
      "[5662]\ttraining's binary_logloss: 0.0804299\n",
      "[5663]\ttraining's binary_logloss: 0.0804214\n",
      "[5664]\ttraining's binary_logloss: 0.0804142\n",
      "[5665]\ttraining's binary_logloss: 0.0804059\n",
      "[5666]\ttraining's binary_logloss: 0.0804008\n",
      "[5667]\ttraining's binary_logloss: 0.0803951\n",
      "[5668]\ttraining's binary_logloss: 0.080387\n",
      "[5669]\ttraining's binary_logloss: 0.0803789\n",
      "[5670]\ttraining's binary_logloss: 0.080371\n",
      "[5671]\ttraining's binary_logloss: 0.0803651\n",
      "[5672]\ttraining's binary_logloss: 0.0803553\n",
      "[5673]\ttraining's binary_logloss: 0.0803502\n",
      "[5674]\ttraining's binary_logloss: 0.080341\n",
      "[5675]\ttraining's binary_logloss: 0.0803322\n",
      "[5676]\ttraining's binary_logloss: 0.0803222\n",
      "[5677]\ttraining's binary_logloss: 0.0803129\n",
      "[5678]\ttraining's binary_logloss: 0.0803035\n",
      "[5679]\ttraining's binary_logloss: 0.0802938\n",
      "[5680]\ttraining's binary_logloss: 0.0802833\n",
      "[5681]\ttraining's binary_logloss: 0.0802757\n",
      "[5682]\ttraining's binary_logloss: 0.0802667\n",
      "[5683]\ttraining's binary_logloss: 0.0802577\n",
      "[5684]\ttraining's binary_logloss: 0.0802491\n",
      "[5685]\ttraining's binary_logloss: 0.0802414\n",
      "[5686]\ttraining's binary_logloss: 0.0802336\n",
      "[5687]\ttraining's binary_logloss: 0.0802257\n",
      "[5688]\ttraining's binary_logloss: 0.0802169\n",
      "[5689]\ttraining's binary_logloss: 0.0802076\n",
      "[5690]\ttraining's binary_logloss: 0.0801979\n",
      "[5691]\ttraining's binary_logloss: 0.080189\n",
      "[5692]\ttraining's binary_logloss: 0.0801808\n",
      "[5693]\ttraining's binary_logloss: 0.0801739\n",
      "[5694]\ttraining's binary_logloss: 0.0801664\n",
      "[5695]\ttraining's binary_logloss: 0.0801571\n",
      "[5696]\ttraining's binary_logloss: 0.0801473\n",
      "[5697]\ttraining's binary_logloss: 0.0801385\n",
      "[5698]\ttraining's binary_logloss: 0.0801305\n",
      "[5699]\ttraining's binary_logloss: 0.0801251\n",
      "[5700]\ttraining's binary_logloss: 0.0801168\n",
      "[5701]\ttraining's binary_logloss: 0.0801089\n",
      "[5702]\ttraining's binary_logloss: 0.0801034\n",
      "[5703]\ttraining's binary_logloss: 0.0800933\n",
      "[5704]\ttraining's binary_logloss: 0.0800869\n",
      "[5705]\ttraining's binary_logloss: 0.0800795\n",
      "[5706]\ttraining's binary_logloss: 0.0800699\n",
      "[5707]\ttraining's binary_logloss: 0.0800629\n",
      "[5708]\ttraining's binary_logloss: 0.0800545\n",
      "[5709]\ttraining's binary_logloss: 0.080046\n",
      "[5710]\ttraining's binary_logloss: 0.0800366\n",
      "[5711]\ttraining's binary_logloss: 0.0800276\n",
      "[5712]\ttraining's binary_logloss: 0.0800192\n",
      "[5713]\ttraining's binary_logloss: 0.0800115\n",
      "[5714]\ttraining's binary_logloss: 0.0800068\n",
      "[5715]\ttraining's binary_logloss: 0.0799994\n",
      "[5716]\ttraining's binary_logloss: 0.0799909\n",
      "[5717]\ttraining's binary_logloss: 0.0799824\n",
      "[5718]\ttraining's binary_logloss: 0.0799753\n",
      "[5719]\ttraining's binary_logloss: 0.0799676\n",
      "[5720]\ttraining's binary_logloss: 0.0799597\n",
      "[5721]\ttraining's binary_logloss: 0.0799503\n",
      "[5722]\ttraining's binary_logloss: 0.0799466\n",
      "[5723]\ttraining's binary_logloss: 0.0799369\n",
      "[5724]\ttraining's binary_logloss: 0.0799285\n",
      "[5725]\ttraining's binary_logloss: 0.079923\n",
      "[5726]\ttraining's binary_logloss: 0.0799191\n",
      "[5727]\ttraining's binary_logloss: 0.0799133\n",
      "[5728]\ttraining's binary_logloss: 0.0799052\n",
      "[5729]\ttraining's binary_logloss: 0.0798956\n",
      "[5730]\ttraining's binary_logloss: 0.0798868\n",
      "[5731]\ttraining's binary_logloss: 0.0798848\n",
      "[5732]\ttraining's binary_logloss: 0.079876\n",
      "[5733]\ttraining's binary_logloss: 0.0798682\n",
      "[5734]\ttraining's binary_logloss: 0.0798621\n",
      "[5735]\ttraining's binary_logloss: 0.0798539\n",
      "[5736]\ttraining's binary_logloss: 0.0798433\n",
      "[5737]\ttraining's binary_logloss: 0.079834\n",
      "[5738]\ttraining's binary_logloss: 0.0798258\n",
      "[5739]\ttraining's binary_logloss: 0.079818\n",
      "[5740]\ttraining's binary_logloss: 0.0798099\n",
      "[5741]\ttraining's binary_logloss: 0.0798018\n",
      "[5742]\ttraining's binary_logloss: 0.0797932\n",
      "[5743]\ttraining's binary_logloss: 0.0797855\n",
      "[5744]\ttraining's binary_logloss: 0.0797763\n",
      "[5745]\ttraining's binary_logloss: 0.0797671\n",
      "[5746]\ttraining's binary_logloss: 0.0797585\n",
      "[5747]\ttraining's binary_logloss: 0.0797561\n",
      "[5748]\ttraining's binary_logloss: 0.0797478\n",
      "[5749]\ttraining's binary_logloss: 0.0797391\n",
      "[5750]\ttraining's binary_logloss: 0.0797306\n",
      "[5751]\ttraining's binary_logloss: 0.0797263\n",
      "[5752]\ttraining's binary_logloss: 0.0797163\n",
      "[5753]\ttraining's binary_logloss: 0.0797072\n",
      "[5754]\ttraining's binary_logloss: 0.0796989\n",
      "[5755]\ttraining's binary_logloss: 0.0796897\n",
      "[5756]\ttraining's binary_logloss: 0.0796809\n",
      "[5757]\ttraining's binary_logloss: 0.0796716\n",
      "[5758]\ttraining's binary_logloss: 0.0796632\n",
      "[5759]\ttraining's binary_logloss: 0.0796536\n",
      "[5760]\ttraining's binary_logloss: 0.0796452\n",
      "[5761]\ttraining's binary_logloss: 0.0796367\n",
      "[5762]\ttraining's binary_logloss: 0.0796276\n",
      "[5763]\ttraining's binary_logloss: 0.0796193\n",
      "[5764]\ttraining's binary_logloss: 0.0796101\n",
      "[5765]\ttraining's binary_logloss: 0.0796013\n",
      "[5766]\ttraining's binary_logloss: 0.0795933\n",
      "[5767]\ttraining's binary_logloss: 0.0795841\n",
      "[5768]\ttraining's binary_logloss: 0.0795756\n",
      "[5769]\ttraining's binary_logloss: 0.0795685\n",
      "[5770]\ttraining's binary_logloss: 0.0795603\n",
      "[5771]\ttraining's binary_logloss: 0.0795514\n",
      "[5772]\ttraining's binary_logloss: 0.0795427\n",
      "[5773]\ttraining's binary_logloss: 0.0795343\n",
      "[5774]\ttraining's binary_logloss: 0.0795239\n",
      "[5775]\ttraining's binary_logloss: 0.0795206\n",
      "[5776]\ttraining's binary_logloss: 0.0795119\n",
      "[5777]\ttraining's binary_logloss: 0.0795024\n",
      "[5778]\ttraining's binary_logloss: 0.0794934\n",
      "[5779]\ttraining's binary_logloss: 0.0794854\n",
      "[5780]\ttraining's binary_logloss: 0.0794834\n",
      "[5781]\ttraining's binary_logloss: 0.0794765\n",
      "[5782]\ttraining's binary_logloss: 0.079465\n",
      "[5783]\ttraining's binary_logloss: 0.0794572\n",
      "[5784]\ttraining's binary_logloss: 0.0794517\n",
      "[5785]\ttraining's binary_logloss: 0.0794445\n",
      "[5786]\ttraining's binary_logloss: 0.0794387\n",
      "[5787]\ttraining's binary_logloss: 0.0794351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5788]\ttraining's binary_logloss: 0.0794266\n",
      "[5789]\ttraining's binary_logloss: 0.0794193\n",
      "[5790]\ttraining's binary_logloss: 0.0794118\n",
      "[5791]\ttraining's binary_logloss: 0.0794037\n",
      "[5792]\ttraining's binary_logloss: 0.0793957\n",
      "[5793]\ttraining's binary_logloss: 0.079388\n",
      "[5794]\ttraining's binary_logloss: 0.0793794\n",
      "[5795]\ttraining's binary_logloss: 0.0793721\n",
      "[5796]\ttraining's binary_logloss: 0.0793632\n",
      "[5797]\ttraining's binary_logloss: 0.0793572\n",
      "[5798]\ttraining's binary_logloss: 0.0793487\n",
      "[5799]\ttraining's binary_logloss: 0.0793396\n",
      "[5800]\ttraining's binary_logloss: 0.0793344\n",
      "[5801]\ttraining's binary_logloss: 0.0793262\n",
      "[5802]\ttraining's binary_logloss: 0.0793194\n",
      "[5803]\ttraining's binary_logloss: 0.0793154\n",
      "[5804]\ttraining's binary_logloss: 0.0793069\n",
      "[5805]\ttraining's binary_logloss: 0.0792977\n",
      "[5806]\ttraining's binary_logloss: 0.0792879\n",
      "[5807]\ttraining's binary_logloss: 0.0792775\n",
      "[5808]\ttraining's binary_logloss: 0.0792685\n",
      "[5809]\ttraining's binary_logloss: 0.0792611\n",
      "[5810]\ttraining's binary_logloss: 0.0792507\n",
      "[5811]\ttraining's binary_logloss: 0.0792424\n",
      "[5812]\ttraining's binary_logloss: 0.0792336\n",
      "[5813]\ttraining's binary_logloss: 0.0792248\n",
      "[5814]\ttraining's binary_logloss: 0.0792172\n",
      "[5815]\ttraining's binary_logloss: 0.0792089\n",
      "[5816]\ttraining's binary_logloss: 0.0792007\n",
      "[5817]\ttraining's binary_logloss: 0.0791922\n",
      "[5818]\ttraining's binary_logloss: 0.0791844\n",
      "[5819]\ttraining's binary_logloss: 0.0791752\n",
      "[5820]\ttraining's binary_logloss: 0.0791664\n",
      "[5821]\ttraining's binary_logloss: 0.0791562\n",
      "[5822]\ttraining's binary_logloss: 0.0791486\n",
      "[5823]\ttraining's binary_logloss: 0.07914\n",
      "[5824]\ttraining's binary_logloss: 0.0791297\n",
      "[5825]\ttraining's binary_logloss: 0.0791218\n",
      "[5826]\ttraining's binary_logloss: 0.0791139\n",
      "[5827]\ttraining's binary_logloss: 0.0791053\n",
      "[5828]\ttraining's binary_logloss: 0.0790967\n",
      "[5829]\ttraining's binary_logloss: 0.0790881\n",
      "[5830]\ttraining's binary_logloss: 0.0790798\n",
      "[5831]\ttraining's binary_logloss: 0.0790706\n",
      "[5832]\ttraining's binary_logloss: 0.0790617\n",
      "[5833]\ttraining's binary_logloss: 0.0790522\n",
      "[5834]\ttraining's binary_logloss: 0.0790504\n",
      "[5835]\ttraining's binary_logloss: 0.0790441\n",
      "[5836]\ttraining's binary_logloss: 0.0790372\n",
      "[5837]\ttraining's binary_logloss: 0.0790292\n",
      "[5838]\ttraining's binary_logloss: 0.0790203\n",
      "[5839]\ttraining's binary_logloss: 0.0790122\n",
      "[5840]\ttraining's binary_logloss: 0.079003\n",
      "[5841]\ttraining's binary_logloss: 0.0789953\n",
      "[5842]\ttraining's binary_logloss: 0.0789892\n",
      "[5843]\ttraining's binary_logloss: 0.0789813\n",
      "[5844]\ttraining's binary_logloss: 0.0789712\n",
      "[5845]\ttraining's binary_logloss: 0.0789622\n",
      "[5846]\ttraining's binary_logloss: 0.0789525\n",
      "[5847]\ttraining's binary_logloss: 0.0789436\n",
      "[5848]\ttraining's binary_logloss: 0.078935\n",
      "[5849]\ttraining's binary_logloss: 0.0789274\n",
      "[5850]\ttraining's binary_logloss: 0.0789206\n",
      "[5851]\ttraining's binary_logloss: 0.0789136\n",
      "[5852]\ttraining's binary_logloss: 0.0789051\n",
      "[5853]\ttraining's binary_logloss: 0.0788972\n",
      "[5854]\ttraining's binary_logloss: 0.0788892\n",
      "[5855]\ttraining's binary_logloss: 0.0788794\n",
      "[5856]\ttraining's binary_logloss: 0.0788719\n",
      "[5857]\ttraining's binary_logloss: 0.0788624\n",
      "[5858]\ttraining's binary_logloss: 0.0788539\n",
      "[5859]\ttraining's binary_logloss: 0.0788461\n",
      "[5860]\ttraining's binary_logloss: 0.0788386\n",
      "[5861]\ttraining's binary_logloss: 0.0788306\n",
      "[5862]\ttraining's binary_logloss: 0.0788251\n",
      "[5863]\ttraining's binary_logloss: 0.0788169\n",
      "[5864]\ttraining's binary_logloss: 0.0788092\n",
      "[5865]\ttraining's binary_logloss: 0.0788002\n",
      "[5866]\ttraining's binary_logloss: 0.0787927\n",
      "[5867]\ttraining's binary_logloss: 0.0787826\n",
      "[5868]\ttraining's binary_logloss: 0.0787746\n",
      "[5869]\ttraining's binary_logloss: 0.0787687\n",
      "[5870]\ttraining's binary_logloss: 0.0787594\n",
      "[5871]\ttraining's binary_logloss: 0.0787506\n",
      "[5872]\ttraining's binary_logloss: 0.0787399\n",
      "[5873]\ttraining's binary_logloss: 0.0787319\n",
      "[5874]\ttraining's binary_logloss: 0.0787237\n",
      "[5875]\ttraining's binary_logloss: 0.0787144\n",
      "[5876]\ttraining's binary_logloss: 0.0787049\n",
      "[5877]\ttraining's binary_logloss: 0.0786956\n",
      "[5878]\ttraining's binary_logloss: 0.0786896\n",
      "[5879]\ttraining's binary_logloss: 0.0786795\n",
      "[5880]\ttraining's binary_logloss: 0.0786701\n",
      "[5881]\ttraining's binary_logloss: 0.0786624\n",
      "[5882]\ttraining's binary_logloss: 0.0786536\n",
      "[5883]\ttraining's binary_logloss: 0.0786491\n",
      "[5884]\ttraining's binary_logloss: 0.0786408\n",
      "[5885]\ttraining's binary_logloss: 0.0786331\n",
      "[5886]\ttraining's binary_logloss: 0.0786238\n",
      "[5887]\ttraining's binary_logloss: 0.0786149\n",
      "[5888]\ttraining's binary_logloss: 0.0786069\n",
      "[5889]\ttraining's binary_logloss: 0.0785984\n",
      "[5890]\ttraining's binary_logloss: 0.0785896\n",
      "[5891]\ttraining's binary_logloss: 0.0785804\n",
      "[5892]\ttraining's binary_logloss: 0.0785718\n",
      "[5893]\ttraining's binary_logloss: 0.0785678\n",
      "[5894]\ttraining's binary_logloss: 0.0785598\n",
      "[5895]\ttraining's binary_logloss: 0.0785506\n",
      "[5896]\ttraining's binary_logloss: 0.0785418\n",
      "[5897]\ttraining's binary_logloss: 0.0785337\n",
      "[5898]\ttraining's binary_logloss: 0.0785246\n",
      "[5899]\ttraining's binary_logloss: 0.0785173\n",
      "[5900]\ttraining's binary_logloss: 0.0785097\n",
      "[5901]\ttraining's binary_logloss: 0.0785018\n",
      "[5902]\ttraining's binary_logloss: 0.0784937\n",
      "[5903]\ttraining's binary_logloss: 0.0784858\n",
      "[5904]\ttraining's binary_logloss: 0.0784748\n",
      "[5905]\ttraining's binary_logloss: 0.0784672\n",
      "[5906]\ttraining's binary_logloss: 0.0784659\n",
      "[5907]\ttraining's binary_logloss: 0.0784616\n",
      "[5908]\ttraining's binary_logloss: 0.0784533\n",
      "[5909]\ttraining's binary_logloss: 0.0784453\n",
      "[5910]\ttraining's binary_logloss: 0.0784364\n",
      "[5911]\ttraining's binary_logloss: 0.0784278\n",
      "[5912]\ttraining's binary_logloss: 0.0784192\n",
      "[5913]\ttraining's binary_logloss: 0.0784088\n",
      "[5914]\ttraining's binary_logloss: 0.0784019\n",
      "[5915]\ttraining's binary_logloss: 0.0783948\n",
      "[5916]\ttraining's binary_logloss: 0.0783864\n",
      "[5917]\ttraining's binary_logloss: 0.0783784\n",
      "[5918]\ttraining's binary_logloss: 0.0783693\n",
      "[5919]\ttraining's binary_logloss: 0.0783596\n",
      "[5920]\ttraining's binary_logloss: 0.07835\n",
      "[5921]\ttraining's binary_logloss: 0.0783421\n",
      "[5922]\ttraining's binary_logloss: 0.0783332\n",
      "[5923]\ttraining's binary_logloss: 0.0783244\n",
      "[5924]\ttraining's binary_logloss: 0.0783185\n",
      "[5925]\ttraining's binary_logloss: 0.0783094\n",
      "[5926]\ttraining's binary_logloss: 0.0783018\n",
      "[5927]\ttraining's binary_logloss: 0.0782951\n",
      "[5928]\ttraining's binary_logloss: 0.078288\n",
      "[5929]\ttraining's binary_logloss: 0.0782797\n",
      "[5930]\ttraining's binary_logloss: 0.0782701\n",
      "[5931]\ttraining's binary_logloss: 0.0782624\n",
      "[5932]\ttraining's binary_logloss: 0.0782528\n",
      "[5933]\ttraining's binary_logloss: 0.0782444\n",
      "[5934]\ttraining's binary_logloss: 0.0782396\n",
      "[5935]\ttraining's binary_logloss: 0.0782295\n",
      "[5936]\ttraining's binary_logloss: 0.0782202\n",
      "[5937]\ttraining's binary_logloss: 0.078212\n",
      "[5938]\ttraining's binary_logloss: 0.0782035\n",
      "[5939]\ttraining's binary_logloss: 0.0781951\n",
      "[5940]\ttraining's binary_logloss: 0.0781869\n",
      "[5941]\ttraining's binary_logloss: 0.0781857\n",
      "[5942]\ttraining's binary_logloss: 0.0781771\n",
      "[5943]\ttraining's binary_logloss: 0.0781699\n",
      "[5944]\ttraining's binary_logloss: 0.0781619\n",
      "[5945]\ttraining's binary_logloss: 0.0781548\n",
      "[5946]\ttraining's binary_logloss: 0.0781488\n",
      "[5947]\ttraining's binary_logloss: 0.0781411\n",
      "[5948]\ttraining's binary_logloss: 0.0781313\n",
      "[5949]\ttraining's binary_logloss: 0.0781224\n",
      "[5950]\ttraining's binary_logloss: 0.0781148\n",
      "[5951]\ttraining's binary_logloss: 0.078106\n",
      "[5952]\ttraining's binary_logloss: 0.0780992\n",
      "[5953]\ttraining's binary_logloss: 0.0780906\n",
      "[5954]\ttraining's binary_logloss: 0.0780802\n",
      "[5955]\ttraining's binary_logloss: 0.0780715\n",
      "[5956]\ttraining's binary_logloss: 0.0780634\n",
      "[5957]\ttraining's binary_logloss: 0.0780542\n",
      "[5958]\ttraining's binary_logloss: 0.0780463\n",
      "[5959]\ttraining's binary_logloss: 0.0780387\n",
      "[5960]\ttraining's binary_logloss: 0.0780302\n",
      "[5961]\ttraining's binary_logloss: 0.0780279\n",
      "[5962]\ttraining's binary_logloss: 0.0780198\n",
      "[5963]\ttraining's binary_logloss: 0.0780122\n",
      "[5964]\ttraining's binary_logloss: 0.0780036\n",
      "[5965]\ttraining's binary_logloss: 0.0779949\n",
      "[5966]\ttraining's binary_logloss: 0.0779872\n",
      "[5967]\ttraining's binary_logloss: 0.0779826\n",
      "[5968]\ttraining's binary_logloss: 0.0779737\n",
      "[5969]\ttraining's binary_logloss: 0.0779651\n",
      "[5970]\ttraining's binary_logloss: 0.0779581\n",
      "[5971]\ttraining's binary_logloss: 0.0779494\n",
      "[5972]\ttraining's binary_logloss: 0.0779412\n",
      "[5973]\ttraining's binary_logloss: 0.0779329\n",
      "[5974]\ttraining's binary_logloss: 0.077924\n",
      "[5975]\ttraining's binary_logloss: 0.0779144\n",
      "[5976]\ttraining's binary_logloss: 0.0779067\n",
      "[5977]\ttraining's binary_logloss: 0.077898\n",
      "[5978]\ttraining's binary_logloss: 0.0778961\n",
      "[5979]\ttraining's binary_logloss: 0.0778875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5980]\ttraining's binary_logloss: 0.0778783\n",
      "[5981]\ttraining's binary_logloss: 0.0778701\n",
      "[5982]\ttraining's binary_logloss: 0.0778678\n",
      "[5983]\ttraining's binary_logloss: 0.0778579\n",
      "[5984]\ttraining's binary_logloss: 0.0778497\n",
      "[5985]\ttraining's binary_logloss: 0.0778434\n",
      "[5986]\ttraining's binary_logloss: 0.0778343\n",
      "[5987]\ttraining's binary_logloss: 0.0778259\n",
      "[5988]\ttraining's binary_logloss: 0.0778198\n",
      "[5989]\ttraining's binary_logloss: 0.0778104\n",
      "[5990]\ttraining's binary_logloss: 0.0777999\n",
      "[5991]\ttraining's binary_logloss: 0.0777922\n",
      "[5992]\ttraining's binary_logloss: 0.0777904\n",
      "[5993]\ttraining's binary_logloss: 0.077782\n",
      "[5994]\ttraining's binary_logloss: 0.077774\n",
      "[5995]\ttraining's binary_logloss: 0.0777646\n",
      "[5996]\ttraining's binary_logloss: 0.0777582\n",
      "[5997]\ttraining's binary_logloss: 0.0777495\n",
      "[5998]\ttraining's binary_logloss: 0.0777413\n",
      "[5999]\ttraining's binary_logloss: 0.0777322\n",
      "[6000]\ttraining's binary_logloss: 0.0777304\n",
      "[6001]\ttraining's binary_logloss: 0.0777246\n",
      "[6002]\ttraining's binary_logloss: 0.077717\n",
      "[6003]\ttraining's binary_logloss: 0.0777092\n",
      "[6004]\ttraining's binary_logloss: 0.0777041\n",
      "[6005]\ttraining's binary_logloss: 0.0776971\n",
      "[6006]\ttraining's binary_logloss: 0.0776892\n",
      "[6007]\ttraining's binary_logloss: 0.0776875\n",
      "[6008]\ttraining's binary_logloss: 0.0776788\n",
      "[6009]\ttraining's binary_logloss: 0.0776692\n",
      "[6010]\ttraining's binary_logloss: 0.0776611\n",
      "[6011]\ttraining's binary_logloss: 0.0776529\n",
      "[6012]\ttraining's binary_logloss: 0.0776446\n",
      "[6013]\ttraining's binary_logloss: 0.0776365\n",
      "[6014]\ttraining's binary_logloss: 0.0776353\n",
      "[6015]\ttraining's binary_logloss: 0.0776266\n",
      "[6016]\ttraining's binary_logloss: 0.0776181\n",
      "[6017]\ttraining's binary_logloss: 0.0776091\n",
      "[6018]\ttraining's binary_logloss: 0.0776038\n",
      "[6019]\ttraining's binary_logloss: 0.0775964\n",
      "[6020]\ttraining's binary_logloss: 0.0775879\n",
      "[6021]\ttraining's binary_logloss: 0.0775798\n",
      "[6022]\ttraining's binary_logloss: 0.0775712\n",
      "[6023]\ttraining's binary_logloss: 0.0775621\n",
      "[6024]\ttraining's binary_logloss: 0.0775531\n",
      "[6025]\ttraining's binary_logloss: 0.0775429\n",
      "[6026]\ttraining's binary_logloss: 0.0775331\n",
      "[6027]\ttraining's binary_logloss: 0.0775249\n",
      "[6028]\ttraining's binary_logloss: 0.0775159\n",
      "[6029]\ttraining's binary_logloss: 0.0775083\n",
      "[6030]\ttraining's binary_logloss: 0.0775005\n",
      "[6031]\ttraining's binary_logloss: 0.077493\n",
      "[6032]\ttraining's binary_logloss: 0.0774856\n",
      "[6033]\ttraining's binary_logloss: 0.077479\n",
      "[6034]\ttraining's binary_logloss: 0.0774678\n",
      "[6035]\ttraining's binary_logloss: 0.0774591\n",
      "[6036]\ttraining's binary_logloss: 0.0774498\n",
      "[6037]\ttraining's binary_logloss: 0.0774395\n",
      "[6038]\ttraining's binary_logloss: 0.0774304\n",
      "[6039]\ttraining's binary_logloss: 0.0774234\n",
      "[6040]\ttraining's binary_logloss: 0.0774143\n",
      "[6041]\ttraining's binary_logloss: 0.0774062\n",
      "[6042]\ttraining's binary_logloss: 0.0773976\n",
      "[6043]\ttraining's binary_logloss: 0.077389\n",
      "[6044]\ttraining's binary_logloss: 0.0773804\n",
      "[6045]\ttraining's binary_logloss: 0.0773697\n",
      "[6046]\ttraining's binary_logloss: 0.0773664\n",
      "[6047]\ttraining's binary_logloss: 0.0773613\n",
      "[6048]\ttraining's binary_logloss: 0.0773554\n",
      "[6049]\ttraining's binary_logloss: 0.0773504\n",
      "[6050]\ttraining's binary_logloss: 0.0773426\n",
      "[6051]\ttraining's binary_logloss: 0.0773345\n",
      "[6052]\ttraining's binary_logloss: 0.0773297\n",
      "[6053]\ttraining's binary_logloss: 0.0773214\n",
      "[6054]\ttraining's binary_logloss: 0.0773131\n",
      "[6055]\ttraining's binary_logloss: 0.0773035\n",
      "[6056]\ttraining's binary_logloss: 0.077295\n",
      "[6057]\ttraining's binary_logloss: 0.0772873\n",
      "[6058]\ttraining's binary_logloss: 0.0772805\n",
      "[6059]\ttraining's binary_logloss: 0.077273\n",
      "[6060]\ttraining's binary_logloss: 0.077265\n",
      "[6061]\ttraining's binary_logloss: 0.0772633\n",
      "[6062]\ttraining's binary_logloss: 0.0772542\n",
      "[6063]\ttraining's binary_logloss: 0.0772452\n",
      "[6064]\ttraining's binary_logloss: 0.0772358\n",
      "[6065]\ttraining's binary_logloss: 0.0772275\n",
      "[6066]\ttraining's binary_logloss: 0.0772193\n",
      "[6067]\ttraining's binary_logloss: 0.0772115\n",
      "[6068]\ttraining's binary_logloss: 0.0772043\n",
      "[6069]\ttraining's binary_logloss: 0.0771961\n",
      "[6070]\ttraining's binary_logloss: 0.0771878\n",
      "[6071]\ttraining's binary_logloss: 0.0771812\n",
      "[6072]\ttraining's binary_logloss: 0.0771765\n",
      "[6073]\ttraining's binary_logloss: 0.0771688\n",
      "[6074]\ttraining's binary_logloss: 0.0771592\n",
      "[6075]\ttraining's binary_logloss: 0.07715\n",
      "[6076]\ttraining's binary_logloss: 0.0771409\n",
      "[6077]\ttraining's binary_logloss: 0.0771329\n",
      "[6078]\ttraining's binary_logloss: 0.0771245\n",
      "[6079]\ttraining's binary_logloss: 0.0771147\n",
      "[6080]\ttraining's binary_logloss: 0.0771069\n",
      "[6081]\ttraining's binary_logloss: 0.0770982\n",
      "[6082]\ttraining's binary_logloss: 0.0770897\n",
      "[6083]\ttraining's binary_logloss: 0.0770831\n",
      "[6084]\ttraining's binary_logloss: 0.0770744\n",
      "[6085]\ttraining's binary_logloss: 0.0770654\n",
      "[6086]\ttraining's binary_logloss: 0.0770574\n",
      "[6087]\ttraining's binary_logloss: 0.0770496\n",
      "[6088]\ttraining's binary_logloss: 0.0770482\n",
      "[6089]\ttraining's binary_logloss: 0.0770408\n",
      "[6090]\ttraining's binary_logloss: 0.0770353\n",
      "[6091]\ttraining's binary_logloss: 0.0770264\n",
      "[6092]\ttraining's binary_logloss: 0.0770176\n",
      "[6093]\ttraining's binary_logloss: 0.0770092\n",
      "[6094]\ttraining's binary_logloss: 0.0770014\n",
      "[6095]\ttraining's binary_logloss: 0.0769928\n",
      "[6096]\ttraining's binary_logloss: 0.0769852\n",
      "[6097]\ttraining's binary_logloss: 0.0769782\n",
      "[6098]\ttraining's binary_logloss: 0.0769682\n",
      "[6099]\ttraining's binary_logloss: 0.0769598\n",
      "[6100]\ttraining's binary_logloss: 0.0769515\n",
      "[6101]\ttraining's binary_logloss: 0.0769435\n",
      "[6102]\ttraining's binary_logloss: 0.0769385\n",
      "[6103]\ttraining's binary_logloss: 0.0769305\n",
      "[6104]\ttraining's binary_logloss: 0.0769203\n",
      "[6105]\ttraining's binary_logloss: 0.0769125\n",
      "[6106]\ttraining's binary_logloss: 0.0769052\n",
      "[6107]\ttraining's binary_logloss: 0.076896\n",
      "[6108]\ttraining's binary_logloss: 0.0768898\n",
      "[6109]\ttraining's binary_logloss: 0.0768887\n",
      "[6110]\ttraining's binary_logloss: 0.0768797\n",
      "[6111]\ttraining's binary_logloss: 0.0768722\n",
      "[6112]\ttraining's binary_logloss: 0.0768639\n",
      "[6113]\ttraining's binary_logloss: 0.0768581\n",
      "[6114]\ttraining's binary_logloss: 0.0768571\n",
      "[6115]\ttraining's binary_logloss: 0.0768471\n",
      "[6116]\ttraining's binary_logloss: 0.0768377\n",
      "[6117]\ttraining's binary_logloss: 0.0768291\n",
      "[6118]\ttraining's binary_logloss: 0.0768204\n",
      "[6119]\ttraining's binary_logloss: 0.0768194\n",
      "[6120]\ttraining's binary_logloss: 0.0768123\n",
      "[6121]\ttraining's binary_logloss: 0.0768032\n",
      "[6122]\ttraining's binary_logloss: 0.0768014\n",
      "[6123]\ttraining's binary_logloss: 0.0767955\n",
      "[6124]\ttraining's binary_logloss: 0.0767918\n",
      "[6125]\ttraining's binary_logloss: 0.076783\n",
      "[6126]\ttraining's binary_logloss: 0.0767749\n",
      "[6127]\ttraining's binary_logloss: 0.0767668\n",
      "[6128]\ttraining's binary_logloss: 0.0767577\n",
      "[6129]\ttraining's binary_logloss: 0.0767481\n",
      "[6130]\ttraining's binary_logloss: 0.0767398\n",
      "[6131]\ttraining's binary_logloss: 0.0767351\n",
      "[6132]\ttraining's binary_logloss: 0.0767255\n",
      "[6133]\ttraining's binary_logloss: 0.0767174\n",
      "[6134]\ttraining's binary_logloss: 0.0767113\n",
      "[6135]\ttraining's binary_logloss: 0.0767022\n",
      "[6136]\ttraining's binary_logloss: 0.0766938\n",
      "[6137]\ttraining's binary_logloss: 0.0766868\n",
      "[6138]\ttraining's binary_logloss: 0.0766787\n",
      "[6139]\ttraining's binary_logloss: 0.0766717\n",
      "[6140]\ttraining's binary_logloss: 0.0766626\n",
      "[6141]\ttraining's binary_logloss: 0.0766546\n",
      "[6142]\ttraining's binary_logloss: 0.0766468\n",
      "[6143]\ttraining's binary_logloss: 0.0766387\n",
      "[6144]\ttraining's binary_logloss: 0.0766305\n",
      "[6145]\ttraining's binary_logloss: 0.0766213\n",
      "[6146]\ttraining's binary_logloss: 0.0766128\n",
      "[6147]\ttraining's binary_logloss: 0.0766043\n",
      "[6148]\ttraining's binary_logloss: 0.0765955\n",
      "[6149]\ttraining's binary_logloss: 0.076587\n",
      "[6150]\ttraining's binary_logloss: 0.076579\n",
      "[6151]\ttraining's binary_logloss: 0.0765734\n",
      "[6152]\ttraining's binary_logloss: 0.0765651\n",
      "[6153]\ttraining's binary_logloss: 0.0765578\n",
      "[6154]\ttraining's binary_logloss: 0.0765489\n",
      "[6155]\ttraining's binary_logloss: 0.0765401\n",
      "[6156]\ttraining's binary_logloss: 0.0765322\n",
      "[6157]\ttraining's binary_logloss: 0.0765259\n",
      "[6158]\ttraining's binary_logloss: 0.0765199\n",
      "[6159]\ttraining's binary_logloss: 0.0765112\n",
      "[6160]\ttraining's binary_logloss: 0.0765026\n",
      "[6161]\ttraining's binary_logloss: 0.0764947\n",
      "[6162]\ttraining's binary_logloss: 0.0764859\n",
      "[6163]\ttraining's binary_logloss: 0.0764757\n",
      "[6164]\ttraining's binary_logloss: 0.0764668\n",
      "[6165]\ttraining's binary_logloss: 0.0764574\n",
      "[6166]\ttraining's binary_logloss: 0.0764516\n",
      "[6167]\ttraining's binary_logloss: 0.076443\n",
      "[6168]\ttraining's binary_logloss: 0.0764348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6169]\ttraining's binary_logloss: 0.0764263\n",
      "[6170]\ttraining's binary_logloss: 0.0764175\n",
      "[6171]\ttraining's binary_logloss: 0.0764101\n",
      "[6172]\ttraining's binary_logloss: 0.0764015\n",
      "[6173]\ttraining's binary_logloss: 0.0763921\n",
      "[6174]\ttraining's binary_logloss: 0.076383\n",
      "[6175]\ttraining's binary_logloss: 0.0763758\n",
      "[6176]\ttraining's binary_logloss: 0.0763676\n",
      "[6177]\ttraining's binary_logloss: 0.076358\n",
      "[6178]\ttraining's binary_logloss: 0.076349\n",
      "[6179]\ttraining's binary_logloss: 0.0763415\n",
      "[6180]\ttraining's binary_logloss: 0.0763323\n",
      "[6181]\ttraining's binary_logloss: 0.0763311\n",
      "[6182]\ttraining's binary_logloss: 0.0763227\n",
      "[6183]\ttraining's binary_logloss: 0.0763127\n",
      "[6184]\ttraining's binary_logloss: 0.0763039\n",
      "[6185]\ttraining's binary_logloss: 0.0762954\n",
      "[6186]\ttraining's binary_logloss: 0.0762942\n",
      "[6187]\ttraining's binary_logloss: 0.0762857\n",
      "[6188]\ttraining's binary_logloss: 0.0762776\n",
      "[6189]\ttraining's binary_logloss: 0.0762717\n",
      "[6190]\ttraining's binary_logloss: 0.0762637\n",
      "[6191]\ttraining's binary_logloss: 0.0762556\n",
      "[6192]\ttraining's binary_logloss: 0.0762503\n",
      "[6193]\ttraining's binary_logloss: 0.0762417\n",
      "[6194]\ttraining's binary_logloss: 0.076235\n",
      "[6195]\ttraining's binary_logloss: 0.076227\n",
      "[6196]\ttraining's binary_logloss: 0.0762198\n",
      "[6197]\ttraining's binary_logloss: 0.0762146\n",
      "[6198]\ttraining's binary_logloss: 0.076208\n",
      "[6199]\ttraining's binary_logloss: 0.076203\n",
      "[6200]\ttraining's binary_logloss: 0.0761949\n",
      "[6201]\ttraining's binary_logloss: 0.0761869\n",
      "[6202]\ttraining's binary_logloss: 0.0761781\n",
      "[6203]\ttraining's binary_logloss: 0.0761703\n",
      "[6204]\ttraining's binary_logloss: 0.0761632\n",
      "[6205]\ttraining's binary_logloss: 0.0761552\n",
      "[6206]\ttraining's binary_logloss: 0.0761469\n",
      "[6207]\ttraining's binary_logloss: 0.0761376\n",
      "[6208]\ttraining's binary_logloss: 0.0761286\n",
      "[6209]\ttraining's binary_logloss: 0.0761196\n",
      "[6210]\ttraining's binary_logloss: 0.0761115\n",
      "[6211]\ttraining's binary_logloss: 0.076103\n",
      "[6212]\ttraining's binary_logloss: 0.0760933\n",
      "[6213]\ttraining's binary_logloss: 0.0760856\n",
      "[6214]\ttraining's binary_logloss: 0.0760767\n",
      "[6215]\ttraining's binary_logloss: 0.0760687\n",
      "[6216]\ttraining's binary_logloss: 0.0760597\n",
      "[6217]\ttraining's binary_logloss: 0.0760506\n",
      "[6218]\ttraining's binary_logloss: 0.0760428\n",
      "[6219]\ttraining's binary_logloss: 0.0760337\n",
      "[6220]\ttraining's binary_logloss: 0.0760265\n",
      "[6221]\ttraining's binary_logloss: 0.0760181\n",
      "[6222]\ttraining's binary_logloss: 0.0760095\n",
      "[6223]\ttraining's binary_logloss: 0.076002\n",
      "[6224]\ttraining's binary_logloss: 0.0759939\n",
      "[6225]\ttraining's binary_logloss: 0.0759842\n",
      "[6226]\ttraining's binary_logloss: 0.0759766\n",
      "[6227]\ttraining's binary_logloss: 0.0759684\n",
      "[6228]\ttraining's binary_logloss: 0.07596\n",
      "[6229]\ttraining's binary_logloss: 0.0759567\n",
      "[6230]\ttraining's binary_logloss: 0.0759488\n",
      "[6231]\ttraining's binary_logloss: 0.07594\n",
      "[6232]\ttraining's binary_logloss: 0.0759322\n",
      "[6233]\ttraining's binary_logloss: 0.0759273\n",
      "[6234]\ttraining's binary_logloss: 0.0759198\n",
      "[6235]\ttraining's binary_logloss: 0.0759114\n",
      "[6236]\ttraining's binary_logloss: 0.0759046\n",
      "[6237]\ttraining's binary_logloss: 0.0758967\n",
      "[6238]\ttraining's binary_logloss: 0.0758878\n",
      "[6239]\ttraining's binary_logloss: 0.0758795\n",
      "[6240]\ttraining's binary_logloss: 0.0758711\n",
      "[6241]\ttraining's binary_logloss: 0.0758613\n",
      "[6242]\ttraining's binary_logloss: 0.0758535\n",
      "[6243]\ttraining's binary_logloss: 0.075845\n",
      "[6244]\ttraining's binary_logloss: 0.0758372\n",
      "[6245]\ttraining's binary_logloss: 0.0758303\n",
      "[6246]\ttraining's binary_logloss: 0.0758231\n",
      "[6247]\ttraining's binary_logloss: 0.0758156\n",
      "[6248]\ttraining's binary_logloss: 0.0758082\n",
      "[6249]\ttraining's binary_logloss: 0.0758005\n",
      "[6250]\ttraining's binary_logloss: 0.0757922\n",
      "[6251]\ttraining's binary_logloss: 0.0757851\n",
      "[6252]\ttraining's binary_logloss: 0.0757788\n",
      "[6253]\ttraining's binary_logloss: 0.0757705\n",
      "[6254]\ttraining's binary_logloss: 0.0757633\n",
      "[6255]\ttraining's binary_logloss: 0.0757564\n",
      "[6256]\ttraining's binary_logloss: 0.0757492\n",
      "[6257]\ttraining's binary_logloss: 0.0757401\n",
      "[6258]\ttraining's binary_logloss: 0.0757314\n",
      "[6259]\ttraining's binary_logloss: 0.0757243\n",
      "[6260]\ttraining's binary_logloss: 0.0757163\n",
      "[6261]\ttraining's binary_logloss: 0.0757095\n",
      "[6262]\ttraining's binary_logloss: 0.0757024\n",
      "[6263]\ttraining's binary_logloss: 0.0756955\n",
      "[6264]\ttraining's binary_logloss: 0.0756869\n",
      "[6265]\ttraining's binary_logloss: 0.0756787\n",
      "[6266]\ttraining's binary_logloss: 0.0756704\n",
      "[6267]\ttraining's binary_logloss: 0.0756618\n",
      "[6268]\ttraining's binary_logloss: 0.0756554\n",
      "[6269]\ttraining's binary_logloss: 0.0756505\n",
      "[6270]\ttraining's binary_logloss: 0.0756425\n",
      "[6271]\ttraining's binary_logloss: 0.0756337\n",
      "[6272]\ttraining's binary_logloss: 0.0756256\n",
      "[6273]\ttraining's binary_logloss: 0.0756169\n",
      "[6274]\ttraining's binary_logloss: 0.0756097\n",
      "[6275]\ttraining's binary_logloss: 0.0756018\n",
      "[6276]\ttraining's binary_logloss: 0.0755944\n",
      "[6277]\ttraining's binary_logloss: 0.075587\n",
      "[6278]\ttraining's binary_logloss: 0.0755777\n",
      "[6279]\ttraining's binary_logloss: 0.075569\n",
      "[6280]\ttraining's binary_logloss: 0.0755611\n",
      "[6281]\ttraining's binary_logloss: 0.0755531\n",
      "[6282]\ttraining's binary_logloss: 0.0755453\n",
      "[6283]\ttraining's binary_logloss: 0.0755376\n",
      "[6284]\ttraining's binary_logloss: 0.0755314\n",
      "[6285]\ttraining's binary_logloss: 0.0755238\n",
      "[6286]\ttraining's binary_logloss: 0.0755143\n",
      "[6287]\ttraining's binary_logloss: 0.0755051\n",
      "[6288]\ttraining's binary_logloss: 0.0754968\n",
      "[6289]\ttraining's binary_logloss: 0.0754902\n",
      "[6290]\ttraining's binary_logloss: 0.0754821\n",
      "[6291]\ttraining's binary_logloss: 0.0754739\n",
      "[6292]\ttraining's binary_logloss: 0.0754643\n",
      "[6293]\ttraining's binary_logloss: 0.075456\n",
      "[6294]\ttraining's binary_logloss: 0.0754484\n",
      "[6295]\ttraining's binary_logloss: 0.0754396\n",
      "[6296]\ttraining's binary_logloss: 0.0754314\n",
      "[6297]\ttraining's binary_logloss: 0.0754249\n",
      "[6298]\ttraining's binary_logloss: 0.0754187\n",
      "[6299]\ttraining's binary_logloss: 0.0754114\n",
      "[6300]\ttraining's binary_logloss: 0.0754037\n",
      "[6301]\ttraining's binary_logloss: 0.0753959\n",
      "[6302]\ttraining's binary_logloss: 0.0753882\n",
      "[6303]\ttraining's binary_logloss: 0.0753839\n",
      "[6304]\ttraining's binary_logloss: 0.0753761\n",
      "[6305]\ttraining's binary_logloss: 0.0753685\n",
      "[6306]\ttraining's binary_logloss: 0.0753609\n",
      "[6307]\ttraining's binary_logloss: 0.0753517\n",
      "[6308]\ttraining's binary_logloss: 0.0753438\n",
      "[6309]\ttraining's binary_logloss: 0.0753386\n",
      "[6310]\ttraining's binary_logloss: 0.0753325\n",
      "[6311]\ttraining's binary_logloss: 0.0753305\n",
      "[6312]\ttraining's binary_logloss: 0.0753238\n",
      "[6313]\ttraining's binary_logloss: 0.0753152\n",
      "[6314]\ttraining's binary_logloss: 0.0753063\n",
      "[6315]\ttraining's binary_logloss: 0.0752989\n",
      "[6316]\ttraining's binary_logloss: 0.0752911\n",
      "[6317]\ttraining's binary_logloss: 0.0752879\n",
      "[6318]\ttraining's binary_logloss: 0.0752797\n",
      "[6319]\ttraining's binary_logloss: 0.0752726\n",
      "[6320]\ttraining's binary_logloss: 0.0752652\n",
      "[6321]\ttraining's binary_logloss: 0.0752584\n",
      "[6322]\ttraining's binary_logloss: 0.0752514\n",
      "[6323]\ttraining's binary_logloss: 0.0752416\n",
      "[6324]\ttraining's binary_logloss: 0.0752335\n",
      "[6325]\ttraining's binary_logloss: 0.0752292\n",
      "[6326]\ttraining's binary_logloss: 0.07522\n",
      "[6327]\ttraining's binary_logloss: 0.0752156\n",
      "[6328]\ttraining's binary_logloss: 0.0752079\n",
      "[6329]\ttraining's binary_logloss: 0.0752019\n",
      "[6330]\ttraining's binary_logloss: 0.0751933\n",
      "[6331]\ttraining's binary_logloss: 0.0751845\n",
      "[6332]\ttraining's binary_logloss: 0.075176\n",
      "[6333]\ttraining's binary_logloss: 0.0751708\n",
      "[6334]\ttraining's binary_logloss: 0.0751624\n",
      "[6335]\ttraining's binary_logloss: 0.0751594\n",
      "[6336]\ttraining's binary_logloss: 0.0751535\n",
      "[6337]\ttraining's binary_logloss: 0.0751453\n",
      "[6338]\ttraining's binary_logloss: 0.0751391\n",
      "[6339]\ttraining's binary_logloss: 0.0751302\n",
      "[6340]\ttraining's binary_logloss: 0.0751214\n",
      "[6341]\ttraining's binary_logloss: 0.0751129\n",
      "[6342]\ttraining's binary_logloss: 0.0751049\n",
      "[6343]\ttraining's binary_logloss: 0.0750959\n",
      "[6344]\ttraining's binary_logloss: 0.0750923\n",
      "[6345]\ttraining's binary_logloss: 0.0750848\n",
      "[6346]\ttraining's binary_logloss: 0.0750819\n",
      "[6347]\ttraining's binary_logloss: 0.0750729\n",
      "[6348]\ttraining's binary_logloss: 0.0750647\n",
      "[6349]\ttraining's binary_logloss: 0.0750574\n",
      "[6350]\ttraining's binary_logloss: 0.0750494\n",
      "[6351]\ttraining's binary_logloss: 0.0750422\n",
      "[6352]\ttraining's binary_logloss: 0.0750343\n",
      "[6353]\ttraining's binary_logloss: 0.0750268\n",
      "[6354]\ttraining's binary_logloss: 0.0750192\n",
      "[6355]\ttraining's binary_logloss: 0.0750121\n",
      "[6356]\ttraining's binary_logloss: 0.0750049\n",
      "[6357]\ttraining's binary_logloss: 0.0749963\n",
      "[6358]\ttraining's binary_logloss: 0.0749884\n",
      "[6359]\ttraining's binary_logloss: 0.0749804\n",
      "[6360]\ttraining's binary_logloss: 0.0749713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6361]\ttraining's binary_logloss: 0.0749639\n",
      "[6362]\ttraining's binary_logloss: 0.0749538\n",
      "[6363]\ttraining's binary_logloss: 0.0749467\n",
      "[6364]\ttraining's binary_logloss: 0.0749397\n",
      "[6365]\ttraining's binary_logloss: 0.0749366\n",
      "[6366]\ttraining's binary_logloss: 0.0749274\n",
      "[6367]\ttraining's binary_logloss: 0.0749218\n",
      "[6368]\ttraining's binary_logloss: 0.074914\n",
      "[6369]\ttraining's binary_logloss: 0.0749043\n",
      "[6370]\ttraining's binary_logloss: 0.0748963\n",
      "[6371]\ttraining's binary_logloss: 0.074892\n",
      "[6372]\ttraining's binary_logloss: 0.0748848\n",
      "[6373]\ttraining's binary_logloss: 0.0748832\n",
      "[6374]\ttraining's binary_logloss: 0.0748803\n",
      "[6375]\ttraining's binary_logloss: 0.074872\n",
      "[6376]\ttraining's binary_logloss: 0.0748641\n",
      "[6377]\ttraining's binary_logloss: 0.074856\n",
      "[6378]\ttraining's binary_logloss: 0.0748485\n",
      "[6379]\ttraining's binary_logloss: 0.0748394\n",
      "[6380]\ttraining's binary_logloss: 0.0748321\n",
      "[6381]\ttraining's binary_logloss: 0.0748295\n",
      "[6382]\ttraining's binary_logloss: 0.0748222\n",
      "[6383]\ttraining's binary_logloss: 0.0748206\n",
      "[6384]\ttraining's binary_logloss: 0.0748137\n",
      "[6385]\ttraining's binary_logloss: 0.0748045\n",
      "[6386]\ttraining's binary_logloss: 0.0747971\n",
      "[6387]\ttraining's binary_logloss: 0.0747887\n",
      "[6388]\ttraining's binary_logloss: 0.0747802\n",
      "[6389]\ttraining's binary_logloss: 0.0747714\n",
      "[6390]\ttraining's binary_logloss: 0.0747633\n",
      "[6391]\ttraining's binary_logloss: 0.0747556\n",
      "[6392]\ttraining's binary_logloss: 0.074751\n",
      "[6393]\ttraining's binary_logloss: 0.0747424\n",
      "[6394]\ttraining's binary_logloss: 0.0747382\n",
      "[6395]\ttraining's binary_logloss: 0.0747367\n",
      "[6396]\ttraining's binary_logloss: 0.0747293\n",
      "[6397]\ttraining's binary_logloss: 0.0747218\n",
      "[6398]\ttraining's binary_logloss: 0.074719\n",
      "[6399]\ttraining's binary_logloss: 0.074712\n",
      "[6400]\ttraining's binary_logloss: 0.0747042\n",
      "[6401]\ttraining's binary_logloss: 0.0747004\n",
      "[6402]\ttraining's binary_logloss: 0.0746925\n",
      "[6403]\ttraining's binary_logloss: 0.0746896\n",
      "[6404]\ttraining's binary_logloss: 0.0746809\n",
      "[6405]\ttraining's binary_logloss: 0.074672\n",
      "[6406]\ttraining's binary_logloss: 0.0746628\n",
      "[6407]\ttraining's binary_logloss: 0.0746552\n",
      "[6408]\ttraining's binary_logloss: 0.0746468\n",
      "[6409]\ttraining's binary_logloss: 0.0746403\n",
      "[6410]\ttraining's binary_logloss: 0.0746311\n",
      "[6411]\ttraining's binary_logloss: 0.0746285\n",
      "[6412]\ttraining's binary_logloss: 0.0746191\n",
      "[6413]\ttraining's binary_logloss: 0.074614\n",
      "[6414]\ttraining's binary_logloss: 0.0746058\n",
      "[6415]\ttraining's binary_logloss: 0.0745984\n",
      "[6416]\ttraining's binary_logloss: 0.0745922\n",
      "[6417]\ttraining's binary_logloss: 0.0745829\n",
      "[6418]\ttraining's binary_logloss: 0.0745736\n",
      "[6419]\ttraining's binary_logloss: 0.0745679\n",
      "[6420]\ttraining's binary_logloss: 0.07456\n",
      "[6421]\ttraining's binary_logloss: 0.0745517\n",
      "[6422]\ttraining's binary_logloss: 0.0745435\n",
      "[6423]\ttraining's binary_logloss: 0.0745366\n",
      "[6424]\ttraining's binary_logloss: 0.074529\n",
      "[6425]\ttraining's binary_logloss: 0.074524\n",
      "[6426]\ttraining's binary_logloss: 0.0745182\n",
      "[6427]\ttraining's binary_logloss: 0.0745095\n",
      "[6428]\ttraining's binary_logloss: 0.0745014\n",
      "[6429]\ttraining's binary_logloss: 0.074494\n",
      "[6430]\ttraining's binary_logloss: 0.0744874\n",
      "[6431]\ttraining's binary_logloss: 0.0744826\n",
      "[6432]\ttraining's binary_logloss: 0.0744783\n",
      "[6433]\ttraining's binary_logloss: 0.0744709\n",
      "[6434]\ttraining's binary_logloss: 0.074462\n",
      "[6435]\ttraining's binary_logloss: 0.0744585\n",
      "[6436]\ttraining's binary_logloss: 0.0744514\n",
      "[6437]\ttraining's binary_logloss: 0.0744429\n",
      "[6438]\ttraining's binary_logloss: 0.0744352\n",
      "[6439]\ttraining's binary_logloss: 0.0744276\n",
      "[6440]\ttraining's binary_logloss: 0.0744183\n",
      "[6441]\ttraining's binary_logloss: 0.0744105\n",
      "[6442]\ttraining's binary_logloss: 0.0744021\n",
      "[6443]\ttraining's binary_logloss: 0.0743951\n",
      "[6444]\ttraining's binary_logloss: 0.0743922\n",
      "[6445]\ttraining's binary_logloss: 0.074384\n",
      "[6446]\ttraining's binary_logloss: 0.0743762\n",
      "[6447]\ttraining's binary_logloss: 0.0743672\n",
      "[6448]\ttraining's binary_logloss: 0.07436\n",
      "[6449]\ttraining's binary_logloss: 0.0743529\n",
      "[6450]\ttraining's binary_logloss: 0.0743459\n",
      "[6451]\ttraining's binary_logloss: 0.0743389\n",
      "[6452]\ttraining's binary_logloss: 0.0743312\n",
      "[6453]\ttraining's binary_logloss: 0.0743221\n",
      "[6454]\ttraining's binary_logloss: 0.0743137\n",
      "[6455]\ttraining's binary_logloss: 0.0743062\n",
      "[6456]\ttraining's binary_logloss: 0.0742976\n",
      "[6457]\ttraining's binary_logloss: 0.0742906\n",
      "[6458]\ttraining's binary_logloss: 0.0742805\n",
      "[6459]\ttraining's binary_logloss: 0.0742753\n",
      "[6460]\ttraining's binary_logloss: 0.0742663\n",
      "[6461]\ttraining's binary_logloss: 0.0742584\n",
      "[6462]\ttraining's binary_logloss: 0.0742493\n",
      "[6463]\ttraining's binary_logloss: 0.0742412\n",
      "[6464]\ttraining's binary_logloss: 0.0742328\n",
      "[6465]\ttraining's binary_logloss: 0.0742239\n",
      "[6466]\ttraining's binary_logloss: 0.0742168\n",
      "[6467]\ttraining's binary_logloss: 0.0742115\n",
      "[6468]\ttraining's binary_logloss: 0.0742039\n",
      "[6469]\ttraining's binary_logloss: 0.074196\n",
      "[6470]\ttraining's binary_logloss: 0.0741898\n",
      "[6471]\ttraining's binary_logloss: 0.0741834\n",
      "[6472]\ttraining's binary_logloss: 0.0741761\n",
      "[6473]\ttraining's binary_logloss: 0.0741681\n",
      "[6474]\ttraining's binary_logloss: 0.0741588\n",
      "[6475]\ttraining's binary_logloss: 0.074151\n",
      "[6476]\ttraining's binary_logloss: 0.0741443\n",
      "[6477]\ttraining's binary_logloss: 0.0741353\n",
      "[6478]\ttraining's binary_logloss: 0.0741278\n",
      "[6479]\ttraining's binary_logloss: 0.0741207\n",
      "[6480]\ttraining's binary_logloss: 0.074114\n",
      "[6481]\ttraining's binary_logloss: 0.0741065\n",
      "[6482]\ttraining's binary_logloss: 0.0741015\n",
      "[6483]\ttraining's binary_logloss: 0.0740929\n",
      "[6484]\ttraining's binary_logloss: 0.0740846\n",
      "[6485]\ttraining's binary_logloss: 0.0740756\n",
      "[6486]\ttraining's binary_logloss: 0.0740664\n",
      "[6487]\ttraining's binary_logloss: 0.074058\n",
      "[6488]\ttraining's binary_logloss: 0.0740503\n",
      "[6489]\ttraining's binary_logloss: 0.0740422\n",
      "[6490]\ttraining's binary_logloss: 0.0740345\n",
      "[6491]\ttraining's binary_logloss: 0.0740259\n",
      "[6492]\ttraining's binary_logloss: 0.074016\n",
      "[6493]\ttraining's binary_logloss: 0.074008\n",
      "[6494]\ttraining's binary_logloss: 0.0740005\n",
      "[6495]\ttraining's binary_logloss: 0.0739943\n",
      "[6496]\ttraining's binary_logloss: 0.0739879\n",
      "[6497]\ttraining's binary_logloss: 0.0739795\n",
      "[6498]\ttraining's binary_logloss: 0.073971\n",
      "[6499]\ttraining's binary_logloss: 0.0739686\n",
      "[6500]\ttraining's binary_logloss: 0.0739596\n",
      "[6501]\ttraining's binary_logloss: 0.0739508\n",
      "[6502]\ttraining's binary_logloss: 0.0739435\n",
      "[6503]\ttraining's binary_logloss: 0.0739355\n",
      "[6504]\ttraining's binary_logloss: 0.0739285\n",
      "[6505]\ttraining's binary_logloss: 0.0739215\n",
      "[6506]\ttraining's binary_logloss: 0.0739129\n",
      "[6507]\ttraining's binary_logloss: 0.0739034\n",
      "[6508]\ttraining's binary_logloss: 0.0738947\n",
      "[6509]\ttraining's binary_logloss: 0.0738875\n",
      "[6510]\ttraining's binary_logloss: 0.0738797\n",
      "[6511]\ttraining's binary_logloss: 0.0738709\n",
      "[6512]\ttraining's binary_logloss: 0.0738627\n",
      "[6513]\ttraining's binary_logloss: 0.0738524\n",
      "[6514]\ttraining's binary_logloss: 0.0738431\n",
      "[6515]\ttraining's binary_logloss: 0.0738399\n",
      "[6516]\ttraining's binary_logloss: 0.0738325\n",
      "[6517]\ttraining's binary_logloss: 0.0738248\n",
      "[6518]\ttraining's binary_logloss: 0.0738162\n",
      "[6519]\ttraining's binary_logloss: 0.0738083\n",
      "[6520]\ttraining's binary_logloss: 0.0738015\n",
      "[6521]\ttraining's binary_logloss: 0.0737926\n",
      "[6522]\ttraining's binary_logloss: 0.0737845\n",
      "[6523]\ttraining's binary_logloss: 0.0737766\n",
      "[6524]\ttraining's binary_logloss: 0.0737687\n",
      "[6525]\ttraining's binary_logloss: 0.0737618\n",
      "[6526]\ttraining's binary_logloss: 0.0737545\n",
      "[6527]\ttraining's binary_logloss: 0.0737461\n",
      "[6528]\ttraining's binary_logloss: 0.0737416\n",
      "[6529]\ttraining's binary_logloss: 0.0737368\n",
      "[6530]\ttraining's binary_logloss: 0.0737284\n",
      "[6531]\ttraining's binary_logloss: 0.0737215\n",
      "[6532]\ttraining's binary_logloss: 0.0737153\n",
      "[6533]\ttraining's binary_logloss: 0.0737075\n",
      "[6534]\ttraining's binary_logloss: 0.0737004\n",
      "[6535]\ttraining's binary_logloss: 0.0736919\n",
      "[6536]\ttraining's binary_logloss: 0.0736835\n",
      "[6537]\ttraining's binary_logloss: 0.0736739\n",
      "[6538]\ttraining's binary_logloss: 0.0736665\n",
      "[6539]\ttraining's binary_logloss: 0.0736584\n",
      "[6540]\ttraining's binary_logloss: 0.0736497\n",
      "[6541]\ttraining's binary_logloss: 0.0736448\n",
      "[6542]\ttraining's binary_logloss: 0.0736362\n",
      "[6543]\ttraining's binary_logloss: 0.0736279\n",
      "[6544]\ttraining's binary_logloss: 0.0736237\n",
      "[6545]\ttraining's binary_logloss: 0.0736167\n",
      "[6546]\ttraining's binary_logloss: 0.0736091\n",
      "[6547]\ttraining's binary_logloss: 0.0736008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6548]\ttraining's binary_logloss: 0.073592\n",
      "[6549]\ttraining's binary_logloss: 0.0735836\n",
      "[6550]\ttraining's binary_logloss: 0.0735772\n",
      "[6551]\ttraining's binary_logloss: 0.07357\n",
      "[6552]\ttraining's binary_logloss: 0.0735636\n",
      "[6553]\ttraining's binary_logloss: 0.0735576\n",
      "[6554]\ttraining's binary_logloss: 0.0735526\n",
      "[6555]\ttraining's binary_logloss: 0.0735453\n",
      "[6556]\ttraining's binary_logloss: 0.0735383\n",
      "[6557]\ttraining's binary_logloss: 0.0735306\n",
      "[6558]\ttraining's binary_logloss: 0.0735225\n",
      "[6559]\ttraining's binary_logloss: 0.0735186\n",
      "[6560]\ttraining's binary_logloss: 0.0735116\n",
      "[6561]\ttraining's binary_logloss: 0.0735039\n",
      "[6562]\ttraining's binary_logloss: 0.0734968\n",
      "[6563]\ttraining's binary_logloss: 0.0734922\n",
      "[6564]\ttraining's binary_logloss: 0.0734843\n",
      "[6565]\ttraining's binary_logloss: 0.0734766\n",
      "[6566]\ttraining's binary_logloss: 0.073475\n",
      "[6567]\ttraining's binary_logloss: 0.0734726\n",
      "[6568]\ttraining's binary_logloss: 0.0734634\n",
      "[6569]\ttraining's binary_logloss: 0.0734598\n",
      "[6570]\ttraining's binary_logloss: 0.0734522\n",
      "[6571]\ttraining's binary_logloss: 0.0734455\n",
      "[6572]\ttraining's binary_logloss: 0.0734372\n",
      "[6573]\ttraining's binary_logloss: 0.0734288\n",
      "[6574]\ttraining's binary_logloss: 0.0734206\n",
      "[6575]\ttraining's binary_logloss: 0.0734123\n",
      "[6576]\ttraining's binary_logloss: 0.0734046\n",
      "[6577]\ttraining's binary_logloss: 0.0733978\n",
      "[6578]\ttraining's binary_logloss: 0.0733945\n",
      "[6579]\ttraining's binary_logloss: 0.0733864\n",
      "[6580]\ttraining's binary_logloss: 0.0733767\n",
      "[6581]\ttraining's binary_logloss: 0.0733683\n",
      "[6582]\ttraining's binary_logloss: 0.0733608\n",
      "[6583]\ttraining's binary_logloss: 0.0733529\n",
      "[6584]\ttraining's binary_logloss: 0.0733445\n",
      "[6585]\ttraining's binary_logloss: 0.0733365\n",
      "[6586]\ttraining's binary_logloss: 0.0733332\n",
      "[6587]\ttraining's binary_logloss: 0.0733257\n",
      "[6588]\ttraining's binary_logloss: 0.0733184\n",
      "[6589]\ttraining's binary_logloss: 0.0733102\n",
      "[6590]\ttraining's binary_logloss: 0.0733065\n",
      "[6591]\ttraining's binary_logloss: 0.073299\n",
      "[6592]\ttraining's binary_logloss: 0.0732915\n",
      "[6593]\ttraining's binary_logloss: 0.073287\n",
      "[6594]\ttraining's binary_logloss: 0.0732791\n",
      "[6595]\ttraining's binary_logloss: 0.0732713\n",
      "[6596]\ttraining's binary_logloss: 0.0732634\n",
      "[6597]\ttraining's binary_logloss: 0.073254\n",
      "[6598]\ttraining's binary_logloss: 0.0732465\n",
      "[6599]\ttraining's binary_logloss: 0.0732395\n",
      "[6600]\ttraining's binary_logloss: 0.0732352\n",
      "[6601]\ttraining's binary_logloss: 0.0732283\n",
      "[6602]\ttraining's binary_logloss: 0.0732198\n",
      "[6603]\ttraining's binary_logloss: 0.0732107\n",
      "[6604]\ttraining's binary_logloss: 0.0732037\n",
      "[6605]\ttraining's binary_logloss: 0.0731966\n",
      "[6606]\ttraining's binary_logloss: 0.0731894\n",
      "[6607]\ttraining's binary_logloss: 0.0731817\n",
      "[6608]\ttraining's binary_logloss: 0.0731752\n",
      "[6609]\ttraining's binary_logloss: 0.0731667\n",
      "[6610]\ttraining's binary_logloss: 0.0731594\n",
      "[6611]\ttraining's binary_logloss: 0.0731513\n",
      "[6612]\ttraining's binary_logloss: 0.0731444\n",
      "[6613]\ttraining's binary_logloss: 0.073137\n",
      "[6614]\ttraining's binary_logloss: 0.0731303\n",
      "[6615]\ttraining's binary_logloss: 0.0731221\n",
      "[6616]\ttraining's binary_logloss: 0.0731136\n",
      "[6617]\ttraining's binary_logloss: 0.0731065\n",
      "[6618]\ttraining's binary_logloss: 0.0730993\n",
      "[6619]\ttraining's binary_logloss: 0.0730912\n",
      "[6620]\ttraining's binary_logloss: 0.0730846\n",
      "[6621]\ttraining's binary_logloss: 0.0730792\n",
      "[6622]\ttraining's binary_logloss: 0.0730696\n",
      "[6623]\ttraining's binary_logloss: 0.0730629\n",
      "[6624]\ttraining's binary_logloss: 0.0730556\n",
      "[6625]\ttraining's binary_logloss: 0.0730471\n",
      "[6626]\ttraining's binary_logloss: 0.073043\n",
      "[6627]\ttraining's binary_logloss: 0.0730364\n",
      "[6628]\ttraining's binary_logloss: 0.0730293\n",
      "[6629]\ttraining's binary_logloss: 0.0730207\n",
      "[6630]\ttraining's binary_logloss: 0.0730134\n",
      "[6631]\ttraining's binary_logloss: 0.073006\n",
      "[6632]\ttraining's binary_logloss: 0.0729981\n",
      "[6633]\ttraining's binary_logloss: 0.0729899\n",
      "[6634]\ttraining's binary_logloss: 0.0729823\n",
      "[6635]\ttraining's binary_logloss: 0.0729748\n",
      "[6636]\ttraining's binary_logloss: 0.0729678\n",
      "[6637]\ttraining's binary_logloss: 0.0729588\n",
      "[6638]\ttraining's binary_logloss: 0.0729518\n",
      "[6639]\ttraining's binary_logloss: 0.0729487\n",
      "[6640]\ttraining's binary_logloss: 0.072944\n",
      "[6641]\ttraining's binary_logloss: 0.0729366\n",
      "[6642]\ttraining's binary_logloss: 0.0729293\n",
      "[6643]\ttraining's binary_logloss: 0.072926\n",
      "[6644]\ttraining's binary_logloss: 0.0729228\n",
      "[6645]\ttraining's binary_logloss: 0.0729146\n",
      "[6646]\ttraining's binary_logloss: 0.0729058\n",
      "[6647]\ttraining's binary_logloss: 0.0728965\n",
      "[6648]\ttraining's binary_logloss: 0.0728891\n",
      "[6649]\ttraining's binary_logloss: 0.072882\n",
      "[6650]\ttraining's binary_logloss: 0.0728732\n",
      "[6651]\ttraining's binary_logloss: 0.0728658\n",
      "[6652]\ttraining's binary_logloss: 0.0728571\n",
      "[6653]\ttraining's binary_logloss: 0.072849\n",
      "[6654]\ttraining's binary_logloss: 0.0728431\n",
      "[6655]\ttraining's binary_logloss: 0.0728355\n",
      "[6656]\ttraining's binary_logloss: 0.072828\n",
      "[6657]\ttraining's binary_logloss: 0.0728231\n",
      "[6658]\ttraining's binary_logloss: 0.072822\n",
      "[6659]\ttraining's binary_logloss: 0.0728129\n",
      "[6660]\ttraining's binary_logloss: 0.0728048\n",
      "[6661]\ttraining's binary_logloss: 0.0727967\n",
      "[6662]\ttraining's binary_logloss: 0.0727932\n",
      "[6663]\ttraining's binary_logloss: 0.0727828\n",
      "[6664]\ttraining's binary_logloss: 0.0727752\n",
      "[6665]\ttraining's binary_logloss: 0.0727675\n",
      "[6666]\ttraining's binary_logloss: 0.0727652\n",
      "[6667]\ttraining's binary_logloss: 0.072757\n",
      "[6668]\ttraining's binary_logloss: 0.0727493\n",
      "[6669]\ttraining's binary_logloss: 0.0727407\n",
      "[6670]\ttraining's binary_logloss: 0.0727321\n",
      "[6671]\ttraining's binary_logloss: 0.0727222\n",
      "[6672]\ttraining's binary_logloss: 0.0727125\n",
      "[6673]\ttraining's binary_logloss: 0.0727052\n",
      "[6674]\ttraining's binary_logloss: 0.0727028\n",
      "[6675]\ttraining's binary_logloss: 0.0726936\n",
      "[6676]\ttraining's binary_logloss: 0.0726919\n",
      "[6677]\ttraining's binary_logloss: 0.0726842\n",
      "[6678]\ttraining's binary_logloss: 0.0726762\n",
      "[6679]\ttraining's binary_logloss: 0.0726693\n",
      "[6680]\ttraining's binary_logloss: 0.0726603\n",
      "[6681]\ttraining's binary_logloss: 0.0726522\n",
      "[6682]\ttraining's binary_logloss: 0.0726443\n",
      "[6683]\ttraining's binary_logloss: 0.0726361\n",
      "[6684]\ttraining's binary_logloss: 0.0726296\n",
      "[6685]\ttraining's binary_logloss: 0.0726213\n",
      "[6686]\ttraining's binary_logloss: 0.0726128\n",
      "[6687]\ttraining's binary_logloss: 0.0726092\n",
      "[6688]\ttraining's binary_logloss: 0.0726068\n",
      "[6689]\ttraining's binary_logloss: 0.0725986\n",
      "[6690]\ttraining's binary_logloss: 0.0725904\n",
      "[6691]\ttraining's binary_logloss: 0.072582\n",
      "[6692]\ttraining's binary_logloss: 0.072574\n",
      "[6693]\ttraining's binary_logloss: 0.0725661\n",
      "[6694]\ttraining's binary_logloss: 0.072559\n",
      "[6695]\ttraining's binary_logloss: 0.0725525\n",
      "[6696]\ttraining's binary_logloss: 0.0725456\n",
      "[6697]\ttraining's binary_logloss: 0.0725376\n",
      "[6698]\ttraining's binary_logloss: 0.0725341\n",
      "[6699]\ttraining's binary_logloss: 0.0725284\n",
      "[6700]\ttraining's binary_logloss: 0.0725223\n",
      "[6701]\ttraining's binary_logloss: 0.0725146\n",
      "[6702]\ttraining's binary_logloss: 0.0725051\n",
      "[6703]\ttraining's binary_logloss: 0.0724968\n",
      "[6704]\ttraining's binary_logloss: 0.0724889\n",
      "[6705]\ttraining's binary_logloss: 0.0724816\n",
      "[6706]\ttraining's binary_logloss: 0.0724761\n",
      "[6707]\ttraining's binary_logloss: 0.07247\n",
      "[6708]\ttraining's binary_logloss: 0.0724623\n",
      "[6709]\ttraining's binary_logloss: 0.0724548\n",
      "[6710]\ttraining's binary_logloss: 0.0724485\n",
      "[6711]\ttraining's binary_logloss: 0.0724405\n",
      "[6712]\ttraining's binary_logloss: 0.0724316\n",
      "[6713]\ttraining's binary_logloss: 0.0724257\n",
      "[6714]\ttraining's binary_logloss: 0.0724176\n",
      "[6715]\ttraining's binary_logloss: 0.0724089\n",
      "[6716]\ttraining's binary_logloss: 0.0724005\n",
      "[6717]\ttraining's binary_logloss: 0.0723924\n",
      "[6718]\ttraining's binary_logloss: 0.0723852\n",
      "[6719]\ttraining's binary_logloss: 0.0723775\n",
      "[6720]\ttraining's binary_logloss: 0.0723696\n",
      "[6721]\ttraining's binary_logloss: 0.0723664\n",
      "[6722]\ttraining's binary_logloss: 0.0723596\n",
      "[6723]\ttraining's binary_logloss: 0.0723525\n",
      "[6724]\ttraining's binary_logloss: 0.0723439\n",
      "[6725]\ttraining's binary_logloss: 0.0723366\n",
      "[6726]\ttraining's binary_logloss: 0.0723335\n",
      "[6727]\ttraining's binary_logloss: 0.0723257\n",
      "[6728]\ttraining's binary_logloss: 0.0723173\n",
      "[6729]\ttraining's binary_logloss: 0.0723099\n",
      "[6730]\ttraining's binary_logloss: 0.0723035\n",
      "[6731]\ttraining's binary_logloss: 0.0722962\n",
      "[6732]\ttraining's binary_logloss: 0.0722885\n",
      "[6733]\ttraining's binary_logloss: 0.0722808\n",
      "[6734]\ttraining's binary_logloss: 0.0722736\n",
      "[6735]\ttraining's binary_logloss: 0.072267\n",
      "[6736]\ttraining's binary_logloss: 0.0722587\n",
      "[6737]\ttraining's binary_logloss: 0.0722524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6738]\ttraining's binary_logloss: 0.072243\n",
      "[6739]\ttraining's binary_logloss: 0.0722338\n",
      "[6740]\ttraining's binary_logloss: 0.0722285\n",
      "[6741]\ttraining's binary_logloss: 0.0722224\n",
      "[6742]\ttraining's binary_logloss: 0.0722139\n",
      "[6743]\ttraining's binary_logloss: 0.0722075\n",
      "[6744]\ttraining's binary_logloss: 0.0722047\n",
      "[6745]\ttraining's binary_logloss: 0.0721961\n",
      "[6746]\ttraining's binary_logloss: 0.0721869\n",
      "[6747]\ttraining's binary_logloss: 0.072182\n",
      "[6748]\ttraining's binary_logloss: 0.0721785\n",
      "[6749]\ttraining's binary_logloss: 0.0721727\n",
      "[6750]\ttraining's binary_logloss: 0.0721637\n",
      "[6751]\ttraining's binary_logloss: 0.0721562\n",
      "[6752]\ttraining's binary_logloss: 0.072149\n",
      "[6753]\ttraining's binary_logloss: 0.0721419\n",
      "[6754]\ttraining's binary_logloss: 0.0721348\n",
      "[6755]\ttraining's binary_logloss: 0.072127\n",
      "[6756]\ttraining's binary_logloss: 0.0721187\n",
      "[6757]\ttraining's binary_logloss: 0.0721114\n",
      "[6758]\ttraining's binary_logloss: 0.0721039\n",
      "[6759]\ttraining's binary_logloss: 0.0720962\n",
      "[6760]\ttraining's binary_logloss: 0.0720886\n",
      "[6761]\ttraining's binary_logloss: 0.0720801\n",
      "[6762]\ttraining's binary_logloss: 0.0720751\n",
      "[6763]\ttraining's binary_logloss: 0.0720655\n",
      "[6764]\ttraining's binary_logloss: 0.072058\n",
      "[6765]\ttraining's binary_logloss: 0.0720509\n",
      "[6766]\ttraining's binary_logloss: 0.0720425\n",
      "[6767]\ttraining's binary_logloss: 0.072035\n",
      "[6768]\ttraining's binary_logloss: 0.0720278\n",
      "[6769]\ttraining's binary_logloss: 0.0720195\n",
      "[6770]\ttraining's binary_logloss: 0.0720113\n",
      "[6771]\ttraining's binary_logloss: 0.0720015\n",
      "[6772]\ttraining's binary_logloss: 0.0719932\n",
      "[6773]\ttraining's binary_logloss: 0.0719855\n",
      "[6774]\ttraining's binary_logloss: 0.0719771\n",
      "[6775]\ttraining's binary_logloss: 0.0719688\n",
      "[6776]\ttraining's binary_logloss: 0.0719612\n",
      "[6777]\ttraining's binary_logloss: 0.0719534\n",
      "[6778]\ttraining's binary_logloss: 0.0719435\n",
      "[6779]\ttraining's binary_logloss: 0.071935\n",
      "[6780]\ttraining's binary_logloss: 0.0719271\n",
      "[6781]\ttraining's binary_logloss: 0.0719249\n",
      "[6782]\ttraining's binary_logloss: 0.0719193\n",
      "[6783]\ttraining's binary_logloss: 0.0719122\n",
      "[6784]\ttraining's binary_logloss: 0.071904\n",
      "[6785]\ttraining's binary_logloss: 0.0718984\n",
      "[6786]\ttraining's binary_logloss: 0.071891\n",
      "[6787]\ttraining's binary_logloss: 0.0718878\n",
      "[6788]\ttraining's binary_logloss: 0.0718818\n",
      "[6789]\ttraining's binary_logloss: 0.0718759\n",
      "[6790]\ttraining's binary_logloss: 0.0718683\n",
      "[6791]\ttraining's binary_logloss: 0.0718598\n",
      "[6792]\ttraining's binary_logloss: 0.071852\n",
      "[6793]\ttraining's binary_logloss: 0.0718443\n",
      "[6794]\ttraining's binary_logloss: 0.0718367\n",
      "[6795]\ttraining's binary_logloss: 0.0718301\n",
      "[6796]\ttraining's binary_logloss: 0.0718243\n",
      "[6797]\ttraining's binary_logloss: 0.071819\n",
      "[6798]\ttraining's binary_logloss: 0.071814\n",
      "[6799]\ttraining's binary_logloss: 0.0718058\n",
      "[6800]\ttraining's binary_logloss: 0.0717994\n",
      "[6801]\ttraining's binary_logloss: 0.0717914\n",
      "[6802]\ttraining's binary_logloss: 0.0717835\n",
      "[6803]\ttraining's binary_logloss: 0.0717761\n",
      "[6804]\ttraining's binary_logloss: 0.0717698\n",
      "[6805]\ttraining's binary_logloss: 0.0717629\n",
      "[6806]\ttraining's binary_logloss: 0.0717533\n",
      "[6807]\ttraining's binary_logloss: 0.0717499\n",
      "[6808]\ttraining's binary_logloss: 0.0717413\n",
      "[6809]\ttraining's binary_logloss: 0.0717359\n",
      "[6810]\ttraining's binary_logloss: 0.0717303\n",
      "[6811]\ttraining's binary_logloss: 0.0717229\n",
      "[6812]\ttraining's binary_logloss: 0.0717145\n",
      "[6813]\ttraining's binary_logloss: 0.0717077\n",
      "[6814]\ttraining's binary_logloss: 0.0717006\n",
      "[6815]\ttraining's binary_logloss: 0.0716954\n",
      "[6816]\ttraining's binary_logloss: 0.0716878\n",
      "[6817]\ttraining's binary_logloss: 0.0716808\n",
      "[6818]\ttraining's binary_logloss: 0.0716731\n",
      "[6819]\ttraining's binary_logloss: 0.0716701\n",
      "[6820]\ttraining's binary_logloss: 0.0716623\n",
      "[6821]\ttraining's binary_logloss: 0.0716536\n",
      "[6822]\ttraining's binary_logloss: 0.0716458\n",
      "[6823]\ttraining's binary_logloss: 0.0716376\n",
      "[6824]\ttraining's binary_logloss: 0.0716295\n",
      "[6825]\ttraining's binary_logloss: 0.0716213\n",
      "[6826]\ttraining's binary_logloss: 0.0716139\n",
      "[6827]\ttraining's binary_logloss: 0.0716053\n",
      "[6828]\ttraining's binary_logloss: 0.0715976\n",
      "[6829]\ttraining's binary_logloss: 0.0715902\n",
      "[6830]\ttraining's binary_logloss: 0.0715809\n",
      "[6831]\ttraining's binary_logloss: 0.0715774\n",
      "[6832]\ttraining's binary_logloss: 0.0715701\n",
      "[6833]\ttraining's binary_logloss: 0.071565\n",
      "[6834]\ttraining's binary_logloss: 0.0715574\n",
      "[6835]\ttraining's binary_logloss: 0.0715497\n",
      "[6836]\ttraining's binary_logloss: 0.0715418\n",
      "[6837]\ttraining's binary_logloss: 0.0715343\n",
      "[6838]\ttraining's binary_logloss: 0.0715272\n",
      "[6839]\ttraining's binary_logloss: 0.07152\n",
      "[6840]\ttraining's binary_logloss: 0.0715143\n",
      "[6841]\ttraining's binary_logloss: 0.0715096\n",
      "[6842]\ttraining's binary_logloss: 0.0715005\n",
      "[6843]\ttraining's binary_logloss: 0.0714931\n",
      "[6844]\ttraining's binary_logloss: 0.0714869\n",
      "[6845]\ttraining's binary_logloss: 0.0714808\n",
      "[6846]\ttraining's binary_logloss: 0.0714734\n",
      "[6847]\ttraining's binary_logloss: 0.0714703\n",
      "[6848]\ttraining's binary_logloss: 0.0714636\n",
      "[6849]\ttraining's binary_logloss: 0.0714578\n",
      "[6850]\ttraining's binary_logloss: 0.0714512\n",
      "[6851]\ttraining's binary_logloss: 0.0714469\n",
      "[6852]\ttraining's binary_logloss: 0.0714393\n",
      "[6853]\ttraining's binary_logloss: 0.0714341\n",
      "[6854]\ttraining's binary_logloss: 0.0714269\n",
      "[6855]\ttraining's binary_logloss: 0.0714194\n",
      "[6856]\ttraining's binary_logloss: 0.0714127\n",
      "[6857]\ttraining's binary_logloss: 0.0714072\n",
      "[6858]\ttraining's binary_logloss: 0.0714003\n",
      "[6859]\ttraining's binary_logloss: 0.0713929\n",
      "[6860]\ttraining's binary_logloss: 0.0713842\n",
      "[6861]\ttraining's binary_logloss: 0.0713774\n",
      "[6862]\ttraining's binary_logloss: 0.0713697\n",
      "[6863]\ttraining's binary_logloss: 0.0713633\n",
      "[6864]\ttraining's binary_logloss: 0.071356\n",
      "[6865]\ttraining's binary_logloss: 0.0713504\n",
      "[6866]\ttraining's binary_logloss: 0.0713432\n",
      "[6867]\ttraining's binary_logloss: 0.071335\n",
      "[6868]\ttraining's binary_logloss: 0.0713297\n",
      "[6869]\ttraining's binary_logloss: 0.0713249\n",
      "[6870]\ttraining's binary_logloss: 0.071317\n",
      "[6871]\ttraining's binary_logloss: 0.0713101\n",
      "[6872]\ttraining's binary_logloss: 0.0713024\n",
      "[6873]\ttraining's binary_logloss: 0.0712966\n",
      "[6874]\ttraining's binary_logloss: 0.0712899\n",
      "[6875]\ttraining's binary_logloss: 0.0712829\n",
      "[6876]\ttraining's binary_logloss: 0.071276\n",
      "[6877]\ttraining's binary_logloss: 0.071268\n",
      "[6878]\ttraining's binary_logloss: 0.0712608\n",
      "[6879]\ttraining's binary_logloss: 0.0712522\n",
      "[6880]\ttraining's binary_logloss: 0.0712436\n",
      "[6881]\ttraining's binary_logloss: 0.071237\n",
      "[6882]\ttraining's binary_logloss: 0.0712296\n",
      "[6883]\ttraining's binary_logloss: 0.0712228\n",
      "[6884]\ttraining's binary_logloss: 0.0712155\n",
      "[6885]\ttraining's binary_logloss: 0.0712078\n",
      "[6886]\ttraining's binary_logloss: 0.0712006\n",
      "[6887]\ttraining's binary_logloss: 0.0711959\n",
      "[6888]\ttraining's binary_logloss: 0.0711891\n",
      "[6889]\ttraining's binary_logloss: 0.0711796\n",
      "[6890]\ttraining's binary_logloss: 0.071172\n",
      "[6891]\ttraining's binary_logloss: 0.0711644\n",
      "[6892]\ttraining's binary_logloss: 0.0711598\n",
      "[6893]\ttraining's binary_logloss: 0.071151\n",
      "[6894]\ttraining's binary_logloss: 0.0711432\n",
      "[6895]\ttraining's binary_logloss: 0.0711359\n",
      "[6896]\ttraining's binary_logloss: 0.0711277\n",
      "[6897]\ttraining's binary_logloss: 0.0711191\n",
      "[6898]\ttraining's binary_logloss: 0.0711109\n",
      "[6899]\ttraining's binary_logloss: 0.0711045\n",
      "[6900]\ttraining's binary_logloss: 0.071096\n",
      "[6901]\ttraining's binary_logloss: 0.0710876\n",
      "[6902]\ttraining's binary_logloss: 0.0710807\n",
      "[6903]\ttraining's binary_logloss: 0.0710725\n",
      "[6904]\ttraining's binary_logloss: 0.0710659\n",
      "[6905]\ttraining's binary_logloss: 0.0710593\n",
      "[6906]\ttraining's binary_logloss: 0.0710558\n",
      "[6907]\ttraining's binary_logloss: 0.0710466\n",
      "[6908]\ttraining's binary_logloss: 0.0710401\n",
      "[6909]\ttraining's binary_logloss: 0.0710289\n",
      "[6910]\ttraining's binary_logloss: 0.0710221\n",
      "[6911]\ttraining's binary_logloss: 0.0710152\n",
      "[6912]\ttraining's binary_logloss: 0.0710096\n",
      "[6913]\ttraining's binary_logloss: 0.0710014\n",
      "[6914]\ttraining's binary_logloss: 0.0709942\n",
      "[6915]\ttraining's binary_logloss: 0.0709886\n",
      "[6916]\ttraining's binary_logloss: 0.0709811\n",
      "[6917]\ttraining's binary_logloss: 0.0709744\n",
      "[6918]\ttraining's binary_logloss: 0.0709714\n",
      "[6919]\ttraining's binary_logloss: 0.0709641\n",
      "[6920]\ttraining's binary_logloss: 0.0709562\n",
      "[6921]\ttraining's binary_logloss: 0.0709483\n",
      "[6922]\ttraining's binary_logloss: 0.0709413\n",
      "[6923]\ttraining's binary_logloss: 0.0709338\n",
      "[6924]\ttraining's binary_logloss: 0.0709265\n",
      "[6925]\ttraining's binary_logloss: 0.0709192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6926]\ttraining's binary_logloss: 0.0709113\n",
      "[6927]\ttraining's binary_logloss: 0.0709024\n",
      "[6928]\ttraining's binary_logloss: 0.0708947\n",
      "[6929]\ttraining's binary_logloss: 0.0708867\n",
      "[6930]\ttraining's binary_logloss: 0.0708792\n",
      "[6931]\ttraining's binary_logloss: 0.0708704\n",
      "[6932]\ttraining's binary_logloss: 0.0708629\n",
      "[6933]\ttraining's binary_logloss: 0.0708546\n",
      "[6934]\ttraining's binary_logloss: 0.0708473\n",
      "[6935]\ttraining's binary_logloss: 0.0708386\n",
      "[6936]\ttraining's binary_logloss: 0.0708319\n",
      "[6937]\ttraining's binary_logloss: 0.0708255\n",
      "[6938]\ttraining's binary_logloss: 0.0708217\n",
      "[6939]\ttraining's binary_logloss: 0.0708157\n",
      "[6940]\ttraining's binary_logloss: 0.0708079\n",
      "[6941]\ttraining's binary_logloss: 0.0708028\n",
      "[6942]\ttraining's binary_logloss: 0.0707954\n",
      "[6943]\ttraining's binary_logloss: 0.0707884\n",
      "[6944]\ttraining's binary_logloss: 0.0707803\n",
      "[6945]\ttraining's binary_logloss: 0.0707735\n",
      "[6946]\ttraining's binary_logloss: 0.0707667\n",
      "[6947]\ttraining's binary_logloss: 0.0707588\n",
      "[6948]\ttraining's binary_logloss: 0.0707525\n",
      "[6949]\ttraining's binary_logloss: 0.0707446\n",
      "[6950]\ttraining's binary_logloss: 0.0707376\n",
      "[6951]\ttraining's binary_logloss: 0.0707305\n",
      "[6952]\ttraining's binary_logloss: 0.0707238\n",
      "[6953]\ttraining's binary_logloss: 0.0707177\n",
      "[6954]\ttraining's binary_logloss: 0.0707097\n",
      "[6955]\ttraining's binary_logloss: 0.070702\n",
      "[6956]\ttraining's binary_logloss: 0.0706944\n",
      "[6957]\ttraining's binary_logloss: 0.0706864\n",
      "[6958]\ttraining's binary_logloss: 0.0706784\n",
      "[6959]\ttraining's binary_logloss: 0.0706719\n",
      "[6960]\ttraining's binary_logloss: 0.0706639\n",
      "[6961]\ttraining's binary_logloss: 0.0706556\n",
      "[6962]\ttraining's binary_logloss: 0.0706473\n",
      "[6963]\ttraining's binary_logloss: 0.070639\n",
      "[6964]\ttraining's binary_logloss: 0.0706311\n",
      "[6965]\ttraining's binary_logloss: 0.0706235\n",
      "[6966]\ttraining's binary_logloss: 0.0706152\n",
      "[6967]\ttraining's binary_logloss: 0.0706075\n",
      "[6968]\ttraining's binary_logloss: 0.0705999\n",
      "[6969]\ttraining's binary_logloss: 0.0705933\n",
      "[6970]\ttraining's binary_logloss: 0.0705853\n",
      "[6971]\ttraining's binary_logloss: 0.0705767\n",
      "[6972]\ttraining's binary_logloss: 0.0705692\n",
      "[6973]\ttraining's binary_logloss: 0.0705628\n",
      "[6974]\ttraining's binary_logloss: 0.0705541\n",
      "[6975]\ttraining's binary_logloss: 0.0705464\n",
      "[6976]\ttraining's binary_logloss: 0.0705389\n",
      "[6977]\ttraining's binary_logloss: 0.0705323\n",
      "[6978]\ttraining's binary_logloss: 0.0705298\n",
      "[6979]\ttraining's binary_logloss: 0.0705232\n",
      "[6980]\ttraining's binary_logloss: 0.0705153\n",
      "[6981]\ttraining's binary_logloss: 0.0705084\n",
      "[6982]\ttraining's binary_logloss: 0.0705008\n",
      "[6983]\ttraining's binary_logloss: 0.0704948\n",
      "[6984]\ttraining's binary_logloss: 0.0704874\n",
      "[6985]\ttraining's binary_logloss: 0.0704793\n",
      "[6986]\ttraining's binary_logloss: 0.0704726\n",
      "[6987]\ttraining's binary_logloss: 0.0704653\n",
      "[6988]\ttraining's binary_logloss: 0.0704574\n",
      "[6989]\ttraining's binary_logloss: 0.0704504\n",
      "[6990]\ttraining's binary_logloss: 0.0704479\n",
      "[6991]\ttraining's binary_logloss: 0.0704392\n",
      "[6992]\ttraining's binary_logloss: 0.0704313\n",
      "[6993]\ttraining's binary_logloss: 0.0704217\n",
      "[6994]\ttraining's binary_logloss: 0.0704149\n",
      "[6995]\ttraining's binary_logloss: 0.0704064\n",
      "[6996]\ttraining's binary_logloss: 0.0703992\n",
      "[6997]\ttraining's binary_logloss: 0.070394\n",
      "[6998]\ttraining's binary_logloss: 0.0703858\n",
      "[6999]\ttraining's binary_logloss: 0.0703805\n",
      "[7000]\ttraining's binary_logloss: 0.0703732\n",
      "[7001]\ttraining's binary_logloss: 0.0703648\n",
      "[7002]\ttraining's binary_logloss: 0.0703584\n",
      "[7003]\ttraining's binary_logloss: 0.0703512\n",
      "[7004]\ttraining's binary_logloss: 0.0703434\n",
      "[7005]\ttraining's binary_logloss: 0.0703385\n",
      "[7006]\ttraining's binary_logloss: 0.0703323\n",
      "[7007]\ttraining's binary_logloss: 0.0703249\n",
      "[7008]\ttraining's binary_logloss: 0.0703184\n",
      "[7009]\ttraining's binary_logloss: 0.0703138\n",
      "[7010]\ttraining's binary_logloss: 0.0703065\n",
      "[7011]\ttraining's binary_logloss: 0.0702992\n",
      "[7012]\ttraining's binary_logloss: 0.0702909\n",
      "[7013]\ttraining's binary_logloss: 0.0702841\n",
      "[7014]\ttraining's binary_logloss: 0.0702763\n",
      "[7015]\ttraining's binary_logloss: 0.0702685\n",
      "[7016]\ttraining's binary_logloss: 0.0702607\n",
      "[7017]\ttraining's binary_logloss: 0.0702544\n",
      "[7018]\ttraining's binary_logloss: 0.0702484\n",
      "[7019]\ttraining's binary_logloss: 0.070244\n",
      "[7020]\ttraining's binary_logloss: 0.0702368\n",
      "[7021]\ttraining's binary_logloss: 0.0702287\n",
      "[7022]\ttraining's binary_logloss: 0.0702259\n",
      "[7023]\ttraining's binary_logloss: 0.0702179\n",
      "[7024]\ttraining's binary_logloss: 0.0702099\n",
      "[7025]\ttraining's binary_logloss: 0.0702031\n",
      "[7026]\ttraining's binary_logloss: 0.0701946\n",
      "[7027]\ttraining's binary_logloss: 0.0701901\n",
      "[7028]\ttraining's binary_logloss: 0.0701828\n",
      "[7029]\ttraining's binary_logloss: 0.0701745\n",
      "[7030]\ttraining's binary_logloss: 0.0701681\n",
      "[7031]\ttraining's binary_logloss: 0.0701621\n",
      "[7032]\ttraining's binary_logloss: 0.0701531\n",
      "[7033]\ttraining's binary_logloss: 0.0701456\n",
      "[7034]\ttraining's binary_logloss: 0.0701381\n",
      "[7035]\ttraining's binary_logloss: 0.0701307\n",
      "[7036]\ttraining's binary_logloss: 0.0701233\n",
      "[7037]\ttraining's binary_logloss: 0.0701152\n",
      "[7038]\ttraining's binary_logloss: 0.0701081\n",
      "[7039]\ttraining's binary_logloss: 0.0701008\n",
      "[7040]\ttraining's binary_logloss: 0.070093\n",
      "[7041]\ttraining's binary_logloss: 0.070086\n",
      "[7042]\ttraining's binary_logloss: 0.0700776\n",
      "[7043]\ttraining's binary_logloss: 0.070069\n",
      "[7044]\ttraining's binary_logloss: 0.0700626\n",
      "[7045]\ttraining's binary_logloss: 0.0700582\n",
      "[7046]\ttraining's binary_logloss: 0.0700516\n",
      "[7047]\ttraining's binary_logloss: 0.0700449\n",
      "[7048]\ttraining's binary_logloss: 0.0700391\n",
      "[7049]\ttraining's binary_logloss: 0.07003\n",
      "[7050]\ttraining's binary_logloss: 0.0700246\n",
      "[7051]\ttraining's binary_logloss: 0.0700184\n",
      "[7052]\ttraining's binary_logloss: 0.0700109\n",
      "[7053]\ttraining's binary_logloss: 0.0700027\n",
      "[7054]\ttraining's binary_logloss: 0.0699948\n",
      "[7055]\ttraining's binary_logloss: 0.0699883\n",
      "[7056]\ttraining's binary_logloss: 0.0699806\n",
      "[7057]\ttraining's binary_logloss: 0.0699728\n",
      "[7058]\ttraining's binary_logloss: 0.0699663\n",
      "[7059]\ttraining's binary_logloss: 0.0699594\n",
      "[7060]\ttraining's binary_logloss: 0.069953\n",
      "[7061]\ttraining's binary_logloss: 0.0699458\n",
      "[7062]\ttraining's binary_logloss: 0.0699441\n",
      "[7063]\ttraining's binary_logloss: 0.0699376\n",
      "[7064]\ttraining's binary_logloss: 0.0699306\n",
      "[7065]\ttraining's binary_logloss: 0.0699219\n",
      "[7066]\ttraining's binary_logloss: 0.0699143\n",
      "[7067]\ttraining's binary_logloss: 0.0699081\n",
      "[7068]\ttraining's binary_logloss: 0.0699012\n",
      "[7069]\ttraining's binary_logloss: 0.069895\n",
      "[7070]\ttraining's binary_logloss: 0.069888\n",
      "[7071]\ttraining's binary_logloss: 0.0698809\n",
      "[7072]\ttraining's binary_logloss: 0.0698748\n",
      "[7073]\ttraining's binary_logloss: 0.0698713\n",
      "[7074]\ttraining's binary_logloss: 0.0698652\n",
      "[7075]\ttraining's binary_logloss: 0.0698576\n",
      "[7076]\ttraining's binary_logloss: 0.0698488\n",
      "[7077]\ttraining's binary_logloss: 0.0698424\n",
      "[7078]\ttraining's binary_logloss: 0.0698359\n",
      "[7079]\ttraining's binary_logloss: 0.0698288\n",
      "[7080]\ttraining's binary_logloss: 0.0698218\n",
      "[7081]\ttraining's binary_logloss: 0.0698152\n",
      "[7082]\ttraining's binary_logloss: 0.0698085\n",
      "[7083]\ttraining's binary_logloss: 0.0698014\n",
      "[7084]\ttraining's binary_logloss: 0.0697934\n",
      "[7085]\ttraining's binary_logloss: 0.0697853\n",
      "[7086]\ttraining's binary_logloss: 0.069778\n",
      "[7087]\ttraining's binary_logloss: 0.069772\n",
      "[7088]\ttraining's binary_logloss: 0.0697651\n",
      "[7089]\ttraining's binary_logloss: 0.0697583\n",
      "[7090]\ttraining's binary_logloss: 0.0697477\n",
      "[7091]\ttraining's binary_logloss: 0.0697398\n",
      "[7092]\ttraining's binary_logloss: 0.0697327\n",
      "[7093]\ttraining's binary_logloss: 0.0697274\n",
      "[7094]\ttraining's binary_logloss: 0.0697202\n",
      "[7095]\ttraining's binary_logloss: 0.0697143\n",
      "[7096]\ttraining's binary_logloss: 0.0697069\n",
      "[7097]\ttraining's binary_logloss: 0.0696993\n",
      "[7098]\ttraining's binary_logloss: 0.0696913\n",
      "[7099]\ttraining's binary_logloss: 0.0696848\n",
      "[7100]\ttraining's binary_logloss: 0.0696767\n",
      "[7101]\ttraining's binary_logloss: 0.0696692\n",
      "[7102]\ttraining's binary_logloss: 0.0696623\n",
      "[7103]\ttraining's binary_logloss: 0.0696547\n",
      "[7104]\ttraining's binary_logloss: 0.0696502\n",
      "[7105]\ttraining's binary_logloss: 0.0696433\n",
      "[7106]\ttraining's binary_logloss: 0.0696355\n",
      "[7107]\ttraining's binary_logloss: 0.0696284\n",
      "[7108]\ttraining's binary_logloss: 0.0696256\n",
      "[7109]\ttraining's binary_logloss: 0.0696212\n",
      "[7110]\ttraining's binary_logloss: 0.069614\n",
      "[7111]\ttraining's binary_logloss: 0.0696065\n",
      "[7112]\ttraining's binary_logloss: 0.0695983\n",
      "[7113]\ttraining's binary_logloss: 0.0695902\n",
      "[7114]\ttraining's binary_logloss: 0.0695823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7115]\ttraining's binary_logloss: 0.069576\n",
      "[7116]\ttraining's binary_logloss: 0.0695702\n",
      "[7117]\ttraining's binary_logloss: 0.0695636\n",
      "[7118]\ttraining's binary_logloss: 0.0695555\n",
      "[7119]\ttraining's binary_logloss: 0.0695511\n",
      "[7120]\ttraining's binary_logloss: 0.0695438\n",
      "[7121]\ttraining's binary_logloss: 0.0695367\n",
      "[7122]\ttraining's binary_logloss: 0.0695281\n",
      "[7123]\ttraining's binary_logloss: 0.0695196\n",
      "[7124]\ttraining's binary_logloss: 0.0695118\n",
      "[7125]\ttraining's binary_logloss: 0.0695044\n",
      "[7126]\ttraining's binary_logloss: 0.0694968\n",
      "[7127]\ttraining's binary_logloss: 0.0694928\n",
      "[7128]\ttraining's binary_logloss: 0.0694858\n",
      "[7129]\ttraining's binary_logloss: 0.0694782\n",
      "[7130]\ttraining's binary_logloss: 0.0694698\n",
      "[7131]\ttraining's binary_logloss: 0.0694624\n",
      "[7132]\ttraining's binary_logloss: 0.0694591\n",
      "[7133]\ttraining's binary_logloss: 0.0694528\n",
      "[7134]\ttraining's binary_logloss: 0.0694455\n",
      "[7135]\ttraining's binary_logloss: 0.0694381\n",
      "[7136]\ttraining's binary_logloss: 0.0694354\n",
      "[7137]\ttraining's binary_logloss: 0.0694256\n",
      "[7138]\ttraining's binary_logloss: 0.0694191\n",
      "[7139]\ttraining's binary_logloss: 0.0694117\n",
      "[7140]\ttraining's binary_logloss: 0.0694047\n",
      "[7141]\ttraining's binary_logloss: 0.0694013\n",
      "[7142]\ttraining's binary_logloss: 0.069394\n",
      "[7143]\ttraining's binary_logloss: 0.0693863\n",
      "[7144]\ttraining's binary_logloss: 0.0693794\n",
      "[7145]\ttraining's binary_logloss: 0.0693715\n",
      "[7146]\ttraining's binary_logloss: 0.0693617\n",
      "[7147]\ttraining's binary_logloss: 0.0693543\n",
      "[7148]\ttraining's binary_logloss: 0.0693505\n",
      "[7149]\ttraining's binary_logloss: 0.0693438\n",
      "[7150]\ttraining's binary_logloss: 0.0693363\n",
      "[7151]\ttraining's binary_logloss: 0.069329\n",
      "[7152]\ttraining's binary_logloss: 0.0693205\n",
      "[7153]\ttraining's binary_logloss: 0.069315\n",
      "[7154]\ttraining's binary_logloss: 0.0693084\n",
      "[7155]\ttraining's binary_logloss: 0.0693019\n",
      "[7156]\ttraining's binary_logloss: 0.0692994\n",
      "[7157]\ttraining's binary_logloss: 0.069292\n",
      "[7158]\ttraining's binary_logloss: 0.0692891\n",
      "[7159]\ttraining's binary_logloss: 0.0692875\n",
      "[7160]\ttraining's binary_logloss: 0.0692791\n",
      "[7161]\ttraining's binary_logloss: 0.0692698\n",
      "[7162]\ttraining's binary_logloss: 0.0692618\n",
      "[7163]\ttraining's binary_logloss: 0.0692534\n",
      "[7164]\ttraining's binary_logloss: 0.0692504\n",
      "[7165]\ttraining's binary_logloss: 0.0692432\n",
      "[7166]\ttraining's binary_logloss: 0.0692383\n",
      "[7167]\ttraining's binary_logloss: 0.0692309\n",
      "[7168]\ttraining's binary_logloss: 0.0692248\n",
      "[7169]\ttraining's binary_logloss: 0.0692178\n",
      "[7170]\ttraining's binary_logloss: 0.0692108\n",
      "[7171]\ttraining's binary_logloss: 0.0692029\n",
      "[7172]\ttraining's binary_logloss: 0.0691951\n",
      "[7173]\ttraining's binary_logloss: 0.0691874\n",
      "[7174]\ttraining's binary_logloss: 0.0691793\n",
      "[7175]\ttraining's binary_logloss: 0.0691729\n",
      "[7176]\ttraining's binary_logloss: 0.0691652\n",
      "[7177]\ttraining's binary_logloss: 0.0691587\n",
      "[7178]\ttraining's binary_logloss: 0.0691521\n",
      "[7179]\ttraining's binary_logloss: 0.0691443\n",
      "[7180]\ttraining's binary_logloss: 0.0691368\n",
      "[7181]\ttraining's binary_logloss: 0.0691295\n",
      "[7182]\ttraining's binary_logloss: 0.0691227\n",
      "[7183]\ttraining's binary_logloss: 0.0691157\n",
      "[7184]\ttraining's binary_logloss: 0.0691051\n",
      "[7185]\ttraining's binary_logloss: 0.069098\n",
      "[7186]\ttraining's binary_logloss: 0.0690908\n",
      "[7187]\ttraining's binary_logloss: 0.0690836\n",
      "[7188]\ttraining's binary_logloss: 0.0690816\n",
      "[7189]\ttraining's binary_logloss: 0.0690751\n",
      "[7190]\ttraining's binary_logloss: 0.0690685\n",
      "[7191]\ttraining's binary_logloss: 0.0690616\n",
      "[7192]\ttraining's binary_logloss: 0.0690552\n",
      "[7193]\ttraining's binary_logloss: 0.0690524\n",
      "[7194]\ttraining's binary_logloss: 0.0690503\n",
      "[7195]\ttraining's binary_logloss: 0.0690471\n",
      "[7196]\ttraining's binary_logloss: 0.0690408\n",
      "[7197]\ttraining's binary_logloss: 0.0690334\n",
      "[7198]\ttraining's binary_logloss: 0.0690262\n",
      "[7199]\ttraining's binary_logloss: 0.069022\n",
      "[7200]\ttraining's binary_logloss: 0.069014\n",
      "[7201]\ttraining's binary_logloss: 0.0690073\n",
      "[7202]\ttraining's binary_logloss: 0.0690002\n",
      "[7203]\ttraining's binary_logloss: 0.0689916\n",
      "[7204]\ttraining's binary_logloss: 0.0689836\n",
      "[7205]\ttraining's binary_logloss: 0.0689764\n",
      "[7206]\ttraining's binary_logloss: 0.0689687\n",
      "[7207]\ttraining's binary_logloss: 0.0689619\n",
      "[7208]\ttraining's binary_logloss: 0.0689535\n",
      "[7209]\ttraining's binary_logloss: 0.0689467\n",
      "[7210]\ttraining's binary_logloss: 0.0689387\n",
      "[7211]\ttraining's binary_logloss: 0.0689306\n",
      "[7212]\ttraining's binary_logloss: 0.068923\n",
      "[7213]\ttraining's binary_logloss: 0.0689167\n",
      "[7214]\ttraining's binary_logloss: 0.06891\n",
      "[7215]\ttraining's binary_logloss: 0.0689027\n",
      "[7216]\ttraining's binary_logloss: 0.0689012\n",
      "[7217]\ttraining's binary_logloss: 0.0688931\n",
      "[7218]\ttraining's binary_logloss: 0.0688857\n",
      "[7219]\ttraining's binary_logloss: 0.068879\n",
      "[7220]\ttraining's binary_logloss: 0.0688721\n",
      "[7221]\ttraining's binary_logloss: 0.068868\n",
      "[7222]\ttraining's binary_logloss: 0.068861\n",
      "[7223]\ttraining's binary_logloss: 0.0688534\n",
      "[7224]\ttraining's binary_logloss: 0.0688464\n",
      "[7225]\ttraining's binary_logloss: 0.0688391\n",
      "[7226]\ttraining's binary_logloss: 0.0688328\n",
      "[7227]\ttraining's binary_logloss: 0.0688269\n",
      "[7228]\ttraining's binary_logloss: 0.0688217\n",
      "[7229]\ttraining's binary_logloss: 0.068815\n",
      "[7230]\ttraining's binary_logloss: 0.0688066\n",
      "[7231]\ttraining's binary_logloss: 0.0687999\n",
      "[7232]\ttraining's binary_logloss: 0.0687937\n",
      "[7233]\ttraining's binary_logloss: 0.0687872\n",
      "[7234]\ttraining's binary_logloss: 0.0687807\n",
      "[7235]\ttraining's binary_logloss: 0.0687721\n",
      "[7236]\ttraining's binary_logloss: 0.0687651\n",
      "[7237]\ttraining's binary_logloss: 0.0687612\n",
      "[7238]\ttraining's binary_logloss: 0.0687589\n",
      "[7239]\ttraining's binary_logloss: 0.0687494\n",
      "[7240]\ttraining's binary_logloss: 0.0687432\n",
      "[7241]\ttraining's binary_logloss: 0.0687354\n",
      "[7242]\ttraining's binary_logloss: 0.0687312\n",
      "[7243]\ttraining's binary_logloss: 0.0687244\n",
      "[7244]\ttraining's binary_logloss: 0.0687173\n",
      "[7245]\ttraining's binary_logloss: 0.0687116\n",
      "[7246]\ttraining's binary_logloss: 0.0687029\n",
      "[7247]\ttraining's binary_logloss: 0.0686992\n",
      "[7248]\ttraining's binary_logloss: 0.0686974\n",
      "[7249]\ttraining's binary_logloss: 0.0686924\n",
      "[7250]\ttraining's binary_logloss: 0.0686846\n",
      "[7251]\ttraining's binary_logloss: 0.0686777\n",
      "[7252]\ttraining's binary_logloss: 0.06867\n",
      "[7253]\ttraining's binary_logloss: 0.0686617\n",
      "[7254]\ttraining's binary_logloss: 0.068655\n",
      "[7255]\ttraining's binary_logloss: 0.0686477\n",
      "[7256]\ttraining's binary_logloss: 0.0686406\n",
      "[7257]\ttraining's binary_logloss: 0.0686321\n",
      "[7258]\ttraining's binary_logloss: 0.0686253\n",
      "[7259]\ttraining's binary_logloss: 0.0686209\n",
      "[7260]\ttraining's binary_logloss: 0.0686133\n",
      "[7261]\ttraining's binary_logloss: 0.0686055\n",
      "[7262]\ttraining's binary_logloss: 0.0685989\n",
      "[7263]\ttraining's binary_logloss: 0.0685916\n",
      "[7264]\ttraining's binary_logloss: 0.0685873\n",
      "[7265]\ttraining's binary_logloss: 0.0685796\n",
      "[7266]\ttraining's binary_logloss: 0.0685725\n",
      "[7267]\ttraining's binary_logloss: 0.0685654\n",
      "[7268]\ttraining's binary_logloss: 0.0685609\n",
      "[7269]\ttraining's binary_logloss: 0.0685559\n",
      "[7270]\ttraining's binary_logloss: 0.0685487\n",
      "[7271]\ttraining's binary_logloss: 0.0685426\n",
      "[7272]\ttraining's binary_logloss: 0.0685357\n",
      "[7273]\ttraining's binary_logloss: 0.0685274\n",
      "[7274]\ttraining's binary_logloss: 0.0685195\n",
      "[7275]\ttraining's binary_logloss: 0.0685122\n",
      "[7276]\ttraining's binary_logloss: 0.0685041\n",
      "[7277]\ttraining's binary_logloss: 0.0684993\n",
      "[7278]\ttraining's binary_logloss: 0.0684916\n",
      "[7279]\ttraining's binary_logloss: 0.068485\n",
      "[7280]\ttraining's binary_logloss: 0.068477\n",
      "[7281]\ttraining's binary_logloss: 0.0684711\n",
      "[7282]\ttraining's binary_logloss: 0.0684632\n",
      "[7283]\ttraining's binary_logloss: 0.0684567\n",
      "[7284]\ttraining's binary_logloss: 0.0684483\n",
      "[7285]\ttraining's binary_logloss: 0.0684405\n",
      "[7286]\ttraining's binary_logloss: 0.0684329\n",
      "[7287]\ttraining's binary_logloss: 0.0684249\n",
      "[7288]\ttraining's binary_logloss: 0.068417\n",
      "[7289]\ttraining's binary_logloss: 0.0684099\n",
      "[7290]\ttraining's binary_logloss: 0.068402\n",
      "[7291]\ttraining's binary_logloss: 0.0683957\n",
      "[7292]\ttraining's binary_logloss: 0.0683915\n",
      "[7293]\ttraining's binary_logloss: 0.0683867\n",
      "[7294]\ttraining's binary_logloss: 0.0683804\n",
      "[7295]\ttraining's binary_logloss: 0.0683733\n",
      "[7296]\ttraining's binary_logloss: 0.0683666\n",
      "[7297]\ttraining's binary_logloss: 0.0683623\n",
      "[7298]\ttraining's binary_logloss: 0.0683545\n",
      "[7299]\ttraining's binary_logloss: 0.068348\n",
      "[7300]\ttraining's binary_logloss: 0.0683404\n",
      "[7301]\ttraining's binary_logloss: 0.0683324\n",
      "[7302]\ttraining's binary_logloss: 0.0683268\n",
      "[7303]\ttraining's binary_logloss: 0.0683212\n",
      "[7304]\ttraining's binary_logloss: 0.0683132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7305]\ttraining's binary_logloss: 0.0683072\n",
      "[7306]\ttraining's binary_logloss: 0.0683004\n",
      "[7307]\ttraining's binary_logloss: 0.0682943\n",
      "[7308]\ttraining's binary_logloss: 0.0682865\n",
      "[7309]\ttraining's binary_logloss: 0.0682797\n",
      "[7310]\ttraining's binary_logloss: 0.0682741\n",
      "[7311]\ttraining's binary_logloss: 0.0682723\n",
      "[7312]\ttraining's binary_logloss: 0.0682646\n",
      "[7313]\ttraining's binary_logloss: 0.0682568\n",
      "[7314]\ttraining's binary_logloss: 0.0682496\n",
      "[7315]\ttraining's binary_logloss: 0.0682429\n",
      "[7316]\ttraining's binary_logloss: 0.0682391\n",
      "[7317]\ttraining's binary_logloss: 0.0682315\n",
      "[7318]\ttraining's binary_logloss: 0.0682255\n",
      "[7319]\ttraining's binary_logloss: 0.0682195\n",
      "[7320]\ttraining's binary_logloss: 0.0682139\n",
      "[7321]\ttraining's binary_logloss: 0.0682053\n",
      "[7322]\ttraining's binary_logloss: 0.0681977\n",
      "[7323]\ttraining's binary_logloss: 0.0681887\n",
      "[7324]\ttraining's binary_logloss: 0.0681831\n",
      "[7325]\ttraining's binary_logloss: 0.0681767\n",
      "[7326]\ttraining's binary_logloss: 0.0681697\n",
      "[7327]\ttraining's binary_logloss: 0.0681641\n",
      "[7328]\ttraining's binary_logloss: 0.0681561\n",
      "[7329]\ttraining's binary_logloss: 0.0681518\n",
      "[7330]\ttraining's binary_logloss: 0.0681449\n",
      "[7331]\ttraining's binary_logloss: 0.068139\n",
      "[7332]\ttraining's binary_logloss: 0.0681329\n",
      "[7333]\ttraining's binary_logloss: 0.0681272\n",
      "[7334]\ttraining's binary_logloss: 0.0681217\n",
      "[7335]\ttraining's binary_logloss: 0.0681178\n",
      "[7336]\ttraining's binary_logloss: 0.0681099\n",
      "[7337]\ttraining's binary_logloss: 0.0681029\n",
      "[7338]\ttraining's binary_logloss: 0.0680983\n",
      "[7339]\ttraining's binary_logloss: 0.0680917\n",
      "[7340]\ttraining's binary_logloss: 0.0680841\n",
      "[7341]\ttraining's binary_logloss: 0.0680766\n",
      "[7342]\ttraining's binary_logloss: 0.0680696\n",
      "[7343]\ttraining's binary_logloss: 0.0680679\n",
      "[7344]\ttraining's binary_logloss: 0.0680606\n",
      "[7345]\ttraining's binary_logloss: 0.0680563\n",
      "[7346]\ttraining's binary_logloss: 0.0680489\n",
      "[7347]\ttraining's binary_logloss: 0.0680444\n",
      "[7348]\ttraining's binary_logloss: 0.0680369\n",
      "[7349]\ttraining's binary_logloss: 0.0680267\n",
      "[7350]\ttraining's binary_logloss: 0.0680183\n",
      "[7351]\ttraining's binary_logloss: 0.0680114\n",
      "[7352]\ttraining's binary_logloss: 0.0680058\n",
      "[7353]\ttraining's binary_logloss: 0.0679998\n",
      "[7354]\ttraining's binary_logloss: 0.0679918\n",
      "[7355]\ttraining's binary_logloss: 0.0679871\n",
      "[7356]\ttraining's binary_logloss: 0.0679797\n",
      "[7357]\ttraining's binary_logloss: 0.0679737\n",
      "[7358]\ttraining's binary_logloss: 0.067966\n",
      "[7359]\ttraining's binary_logloss: 0.0679594\n",
      "[7360]\ttraining's binary_logloss: 0.067952\n",
      "[7361]\ttraining's binary_logloss: 0.0679463\n",
      "[7362]\ttraining's binary_logloss: 0.0679385\n",
      "[7363]\ttraining's binary_logloss: 0.0679308\n",
      "[7364]\ttraining's binary_logloss: 0.0679237\n",
      "[7365]\ttraining's binary_logloss: 0.0679164\n",
      "[7366]\ttraining's binary_logloss: 0.06791\n",
      "[7367]\ttraining's binary_logloss: 0.067903\n",
      "[7368]\ttraining's binary_logloss: 0.0678951\n",
      "[7369]\ttraining's binary_logloss: 0.067889\n",
      "[7370]\ttraining's binary_logloss: 0.0678825\n",
      "[7371]\ttraining's binary_logloss: 0.0678742\n",
      "[7372]\ttraining's binary_logloss: 0.0678676\n",
      "[7373]\ttraining's binary_logloss: 0.0678602\n",
      "[7374]\ttraining's binary_logloss: 0.0678569\n",
      "[7375]\ttraining's binary_logloss: 0.0678501\n",
      "[7376]\ttraining's binary_logloss: 0.0678436\n",
      "[7377]\ttraining's binary_logloss: 0.0678367\n",
      "[7378]\ttraining's binary_logloss: 0.0678303\n",
      "[7379]\ttraining's binary_logloss: 0.0678234\n",
      "[7380]\ttraining's binary_logloss: 0.0678158\n",
      "[7381]\ttraining's binary_logloss: 0.0678082\n",
      "[7382]\ttraining's binary_logloss: 0.0678051\n",
      "[7383]\ttraining's binary_logloss: 0.0677986\n",
      "[7384]\ttraining's binary_logloss: 0.0677912\n",
      "[7385]\ttraining's binary_logloss: 0.0677844\n",
      "[7386]\ttraining's binary_logloss: 0.0677777\n",
      "[7387]\ttraining's binary_logloss: 0.0677705\n",
      "[7388]\ttraining's binary_logloss: 0.0677637\n",
      "[7389]\ttraining's binary_logloss: 0.0677569\n",
      "[7390]\ttraining's binary_logloss: 0.0677489\n",
      "[7391]\ttraining's binary_logloss: 0.0677411\n",
      "[7392]\ttraining's binary_logloss: 0.0677342\n",
      "[7393]\ttraining's binary_logloss: 0.0677262\n",
      "[7394]\ttraining's binary_logloss: 0.0677191\n",
      "[7395]\ttraining's binary_logloss: 0.0677125\n",
      "[7396]\ttraining's binary_logloss: 0.0677061\n",
      "[7397]\ttraining's binary_logloss: 0.0676993\n",
      "[7398]\ttraining's binary_logloss: 0.0676926\n",
      "[7399]\ttraining's binary_logloss: 0.0676842\n",
      "[7400]\ttraining's binary_logloss: 0.0676792\n",
      "[7401]\ttraining's binary_logloss: 0.0676737\n",
      "[7402]\ttraining's binary_logloss: 0.0676667\n",
      "[7403]\ttraining's binary_logloss: 0.0676587\n",
      "[7404]\ttraining's binary_logloss: 0.0676525\n",
      "[7405]\ttraining's binary_logloss: 0.0676444\n",
      "[7406]\ttraining's binary_logloss: 0.0676387\n",
      "[7407]\ttraining's binary_logloss: 0.0676325\n",
      "[7408]\ttraining's binary_logloss: 0.0676257\n",
      "[7409]\ttraining's binary_logloss: 0.0676187\n",
      "[7410]\ttraining's binary_logloss: 0.0676108\n",
      "[7411]\ttraining's binary_logloss: 0.0676052\n",
      "[7412]\ttraining's binary_logloss: 0.0675977\n",
      "[7413]\ttraining's binary_logloss: 0.0675888\n",
      "[7414]\ttraining's binary_logloss: 0.0675824\n",
      "[7415]\ttraining's binary_logloss: 0.067576\n",
      "[7416]\ttraining's binary_logloss: 0.0675693\n",
      "[7417]\ttraining's binary_logloss: 0.0675614\n",
      "[7418]\ttraining's binary_logloss: 0.0675541\n",
      "[7419]\ttraining's binary_logloss: 0.0675475\n",
      "[7420]\ttraining's binary_logloss: 0.067541\n",
      "[7421]\ttraining's binary_logloss: 0.0675342\n",
      "[7422]\ttraining's binary_logloss: 0.0675272\n",
      "[7423]\ttraining's binary_logloss: 0.0675252\n",
      "[7424]\ttraining's binary_logloss: 0.0675179\n",
      "[7425]\ttraining's binary_logloss: 0.0675102\n",
      "[7426]\ttraining's binary_logloss: 0.0675017\n",
      "[7427]\ttraining's binary_logloss: 0.0674944\n",
      "[7428]\ttraining's binary_logloss: 0.0674867\n",
      "[7429]\ttraining's binary_logloss: 0.0674816\n",
      "[7430]\ttraining's binary_logloss: 0.0674749\n",
      "[7431]\ttraining's binary_logloss: 0.0674691\n",
      "[7432]\ttraining's binary_logloss: 0.0674627\n",
      "[7433]\ttraining's binary_logloss: 0.0674572\n",
      "[7434]\ttraining's binary_logloss: 0.0674496\n",
      "[7435]\ttraining's binary_logloss: 0.0674428\n",
      "[7436]\ttraining's binary_logloss: 0.0674364\n",
      "[7437]\ttraining's binary_logloss: 0.0674338\n",
      "[7438]\ttraining's binary_logloss: 0.0674289\n",
      "[7439]\ttraining's binary_logloss: 0.0674221\n",
      "[7440]\ttraining's binary_logloss: 0.0674199\n",
      "[7441]\ttraining's binary_logloss: 0.0674149\n",
      "[7442]\ttraining's binary_logloss: 0.0674093\n",
      "[7443]\ttraining's binary_logloss: 0.0674062\n",
      "[7444]\ttraining's binary_logloss: 0.0674055\n",
      "[7445]\ttraining's binary_logloss: 0.0673987\n",
      "[7446]\ttraining's binary_logloss: 0.0673924\n",
      "[7447]\ttraining's binary_logloss: 0.0673846\n",
      "[7448]\ttraining's binary_logloss: 0.0673784\n",
      "[7449]\ttraining's binary_logloss: 0.0673715\n",
      "[7450]\ttraining's binary_logloss: 0.067369\n",
      "[7451]\ttraining's binary_logloss: 0.0673612\n",
      "[7452]\ttraining's binary_logloss: 0.0673551\n",
      "[7453]\ttraining's binary_logloss: 0.0673478\n",
      "[7454]\ttraining's binary_logloss: 0.0673406\n",
      "[7455]\ttraining's binary_logloss: 0.0673339\n",
      "[7456]\ttraining's binary_logloss: 0.0673262\n",
      "[7457]\ttraining's binary_logloss: 0.0673217\n",
      "[7458]\ttraining's binary_logloss: 0.0673155\n",
      "[7459]\ttraining's binary_logloss: 0.0673081\n",
      "[7460]\ttraining's binary_logloss: 0.0673012\n",
      "[7461]\ttraining's binary_logloss: 0.0672936\n",
      "[7462]\ttraining's binary_logloss: 0.0672857\n",
      "[7463]\ttraining's binary_logloss: 0.0672787\n",
      "[7464]\ttraining's binary_logloss: 0.0672725\n",
      "[7465]\ttraining's binary_logloss: 0.0672667\n",
      "[7466]\ttraining's binary_logloss: 0.0672599\n",
      "[7467]\ttraining's binary_logloss: 0.0672537\n",
      "[7468]\ttraining's binary_logloss: 0.0672497\n",
      "[7469]\ttraining's binary_logloss: 0.0672459\n",
      "[7470]\ttraining's binary_logloss: 0.0672384\n",
      "[7471]\ttraining's binary_logloss: 0.067233\n",
      "[7472]\ttraining's binary_logloss: 0.067227\n",
      "[7473]\ttraining's binary_logloss: 0.0672215\n",
      "[7474]\ttraining's binary_logloss: 0.0672137\n",
      "[7475]\ttraining's binary_logloss: 0.0672065\n",
      "[7476]\ttraining's binary_logloss: 0.0671987\n",
      "[7477]\ttraining's binary_logloss: 0.0671955\n",
      "[7478]\ttraining's binary_logloss: 0.0671887\n",
      "[7479]\ttraining's binary_logloss: 0.0671826\n",
      "[7480]\ttraining's binary_logloss: 0.0671748\n",
      "[7481]\ttraining's binary_logloss: 0.0671687\n",
      "[7482]\ttraining's binary_logloss: 0.0671613\n",
      "[7483]\ttraining's binary_logloss: 0.0671601\n",
      "[7484]\ttraining's binary_logloss: 0.067158\n",
      "[7485]\ttraining's binary_logloss: 0.0671506\n",
      "[7486]\ttraining's binary_logloss: 0.067144\n",
      "[7487]\ttraining's binary_logloss: 0.0671428\n",
      "[7488]\ttraining's binary_logloss: 0.0671363\n",
      "[7489]\ttraining's binary_logloss: 0.0671299\n",
      "[7490]\ttraining's binary_logloss: 0.067125\n",
      "[7491]\ttraining's binary_logloss: 0.0671188\n",
      "[7492]\ttraining's binary_logloss: 0.0671119\n",
      "[7493]\ttraining's binary_logloss: 0.0671098\n",
      "[7494]\ttraining's binary_logloss: 0.0671017\n",
      "[7495]\ttraining's binary_logloss: 0.0670957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7496]\ttraining's binary_logloss: 0.0670884\n",
      "[7497]\ttraining's binary_logloss: 0.067081\n",
      "[7498]\ttraining's binary_logloss: 0.0670745\n",
      "[7499]\ttraining's binary_logloss: 0.0670664\n",
      "[7500]\ttraining's binary_logloss: 0.0670599\n",
      "[7501]\ttraining's binary_logloss: 0.0670519\n",
      "[7502]\ttraining's binary_logloss: 0.0670442\n",
      "[7503]\ttraining's binary_logloss: 0.0670368\n",
      "[7504]\ttraining's binary_logloss: 0.0670305\n",
      "[7505]\ttraining's binary_logloss: 0.0670236\n",
      "[7506]\ttraining's binary_logloss: 0.0670181\n",
      "[7507]\ttraining's binary_logloss: 0.0670146\n",
      "[7508]\ttraining's binary_logloss: 0.0670091\n",
      "[7509]\ttraining's binary_logloss: 0.0670056\n",
      "[7510]\ttraining's binary_logloss: 0.066998\n",
      "[7511]\ttraining's binary_logloss: 0.0669906\n",
      "[7512]\ttraining's binary_logloss: 0.0669838\n",
      "[7513]\ttraining's binary_logloss: 0.0669769\n",
      "[7514]\ttraining's binary_logloss: 0.0669702\n",
      "[7515]\ttraining's binary_logloss: 0.066969\n",
      "[7516]\ttraining's binary_logloss: 0.0669654\n",
      "[7517]\ttraining's binary_logloss: 0.0669569\n",
      "[7518]\ttraining's binary_logloss: 0.06695\n",
      "[7519]\ttraining's binary_logloss: 0.0669426\n",
      "[7520]\ttraining's binary_logloss: 0.0669347\n",
      "[7521]\ttraining's binary_logloss: 0.0669297\n",
      "[7522]\ttraining's binary_logloss: 0.0669289\n",
      "[7523]\ttraining's binary_logloss: 0.0669241\n",
      "[7524]\ttraining's binary_logloss: 0.0669163\n",
      "[7525]\ttraining's binary_logloss: 0.0669093\n",
      "[7526]\ttraining's binary_logloss: 0.0669026\n",
      "[7527]\ttraining's binary_logloss: 0.0668959\n",
      "[7528]\ttraining's binary_logloss: 0.0668881\n",
      "[7529]\ttraining's binary_logloss: 0.0668806\n",
      "[7530]\ttraining's binary_logloss: 0.0668741\n",
      "[7531]\ttraining's binary_logloss: 0.0668671\n",
      "[7532]\ttraining's binary_logloss: 0.0668593\n",
      "[7533]\ttraining's binary_logloss: 0.0668509\n",
      "[7534]\ttraining's binary_logloss: 0.0668432\n",
      "[7535]\ttraining's binary_logloss: 0.0668358\n",
      "[7536]\ttraining's binary_logloss: 0.0668287\n",
      "[7537]\ttraining's binary_logloss: 0.0668243\n",
      "[7538]\ttraining's binary_logloss: 0.0668209\n",
      "[7539]\ttraining's binary_logloss: 0.066815\n",
      "[7540]\ttraining's binary_logloss: 0.0668085\n",
      "[7541]\ttraining's binary_logloss: 0.0668013\n",
      "[7542]\ttraining's binary_logloss: 0.0667972\n",
      "[7543]\ttraining's binary_logloss: 0.0667905\n",
      "[7544]\ttraining's binary_logloss: 0.0667837\n",
      "[7545]\ttraining's binary_logloss: 0.0667791\n",
      "[7546]\ttraining's binary_logloss: 0.0667729\n",
      "[7547]\ttraining's binary_logloss: 0.0667682\n",
      "[7548]\ttraining's binary_logloss: 0.0667619\n",
      "[7549]\ttraining's binary_logloss: 0.0667551\n",
      "[7550]\ttraining's binary_logloss: 0.0667477\n",
      "[7551]\ttraining's binary_logloss: 0.0667404\n",
      "[7552]\ttraining's binary_logloss: 0.0667331\n",
      "[7553]\ttraining's binary_logloss: 0.0667261\n",
      "[7554]\ttraining's binary_logloss: 0.0667195\n",
      "[7555]\ttraining's binary_logloss: 0.0667125\n",
      "[7556]\ttraining's binary_logloss: 0.0667099\n",
      "[7557]\ttraining's binary_logloss: 0.0667033\n",
      "[7558]\ttraining's binary_logloss: 0.0666968\n",
      "[7559]\ttraining's binary_logloss: 0.0666897\n",
      "[7560]\ttraining's binary_logloss: 0.0666822\n",
      "[7561]\ttraining's binary_logloss: 0.0666761\n",
      "[7562]\ttraining's binary_logloss: 0.06667\n",
      "[7563]\ttraining's binary_logloss: 0.0666631\n",
      "[7564]\ttraining's binary_logloss: 0.0666618\n",
      "[7565]\ttraining's binary_logloss: 0.0666549\n",
      "[7566]\ttraining's binary_logloss: 0.0666515\n",
      "[7567]\ttraining's binary_logloss: 0.0666467\n",
      "[7568]\ttraining's binary_logloss: 0.0666426\n",
      "[7569]\ttraining's binary_logloss: 0.0666348\n",
      "[7570]\ttraining's binary_logloss: 0.0666271\n",
      "[7571]\ttraining's binary_logloss: 0.0666198\n",
      "[7572]\ttraining's binary_logloss: 0.0666135\n",
      "[7573]\ttraining's binary_logloss: 0.0666112\n",
      "[7574]\ttraining's binary_logloss: 0.0666031\n",
      "[7575]\ttraining's binary_logloss: 0.0665969\n",
      "[7576]\ttraining's binary_logloss: 0.0665917\n",
      "[7577]\ttraining's binary_logloss: 0.0665879\n",
      "[7578]\ttraining's binary_logloss: 0.0665847\n",
      "[7579]\ttraining's binary_logloss: 0.0665794\n",
      "[7580]\ttraining's binary_logloss: 0.0665779\n",
      "[7581]\ttraining's binary_logloss: 0.0665722\n",
      "[7582]\ttraining's binary_logloss: 0.0665669\n",
      "[7583]\ttraining's binary_logloss: 0.0665617\n",
      "[7584]\ttraining's binary_logloss: 0.0665545\n",
      "[7585]\ttraining's binary_logloss: 0.0665469\n",
      "[7586]\ttraining's binary_logloss: 0.0665398\n",
      "[7587]\ttraining's binary_logloss: 0.0665324\n",
      "[7588]\ttraining's binary_logloss: 0.0665258\n",
      "[7589]\ttraining's binary_logloss: 0.0665185\n",
      "[7590]\ttraining's binary_logloss: 0.0665107\n",
      "[7591]\ttraining's binary_logloss: 0.0665042\n",
      "[7592]\ttraining's binary_logloss: 0.0665002\n",
      "[7593]\ttraining's binary_logloss: 0.0664923\n",
      "[7594]\ttraining's binary_logloss: 0.0664854\n",
      "[7595]\ttraining's binary_logloss: 0.0664803\n",
      "[7596]\ttraining's binary_logloss: 0.0664741\n",
      "[7597]\ttraining's binary_logloss: 0.0664666\n",
      "[7598]\ttraining's binary_logloss: 0.0664615\n",
      "[7599]\ttraining's binary_logloss: 0.0664536\n",
      "[7600]\ttraining's binary_logloss: 0.0664471\n",
      "[7601]\ttraining's binary_logloss: 0.0664408\n",
      "[7602]\ttraining's binary_logloss: 0.0664335\n",
      "[7603]\ttraining's binary_logloss: 0.0664287\n",
      "[7604]\ttraining's binary_logloss: 0.0664244\n",
      "[7605]\ttraining's binary_logloss: 0.0664172\n",
      "[7606]\ttraining's binary_logloss: 0.0664098\n",
      "[7607]\ttraining's binary_logloss: 0.0664032\n",
      "[7608]\ttraining's binary_logloss: 0.0663956\n",
      "[7609]\ttraining's binary_logloss: 0.0663889\n",
      "[7610]\ttraining's binary_logloss: 0.0663829\n",
      "[7611]\ttraining's binary_logloss: 0.0663757\n",
      "[7612]\ttraining's binary_logloss: 0.0663689\n",
      "[7613]\ttraining's binary_logloss: 0.0663625\n",
      "[7614]\ttraining's binary_logloss: 0.0663555\n",
      "[7615]\ttraining's binary_logloss: 0.0663496\n",
      "[7616]\ttraining's binary_logloss: 0.0663421\n",
      "[7617]\ttraining's binary_logloss: 0.0663357\n",
      "[7618]\ttraining's binary_logloss: 0.0663272\n",
      "[7619]\ttraining's binary_logloss: 0.0663211\n",
      "[7620]\ttraining's binary_logloss: 0.0663149\n",
      "[7621]\ttraining's binary_logloss: 0.066309\n",
      "[7622]\ttraining's binary_logloss: 0.0663024\n",
      "[7623]\ttraining's binary_logloss: 0.0662958\n",
      "[7624]\ttraining's binary_logloss: 0.0662913\n",
      "[7625]\ttraining's binary_logloss: 0.0662829\n",
      "[7626]\ttraining's binary_logloss: 0.0662782\n",
      "[7627]\ttraining's binary_logloss: 0.0662741\n",
      "[7628]\ttraining's binary_logloss: 0.0662675\n",
      "[7629]\ttraining's binary_logloss: 0.0662596\n",
      "[7630]\ttraining's binary_logloss: 0.0662528\n",
      "[7631]\ttraining's binary_logloss: 0.0662455\n",
      "[7632]\ttraining's binary_logloss: 0.0662383\n",
      "[7633]\ttraining's binary_logloss: 0.0662324\n",
      "[7634]\ttraining's binary_logloss: 0.0662263\n",
      "[7635]\ttraining's binary_logloss: 0.0662194\n",
      "[7636]\ttraining's binary_logloss: 0.0662137\n",
      "[7637]\ttraining's binary_logloss: 0.0662065\n",
      "[7638]\ttraining's binary_logloss: 0.0662001\n",
      "[7639]\ttraining's binary_logloss: 0.0661934\n",
      "[7640]\ttraining's binary_logloss: 0.0661906\n",
      "[7641]\ttraining's binary_logloss: 0.0661842\n",
      "[7642]\ttraining's binary_logloss: 0.0661791\n",
      "[7643]\ttraining's binary_logloss: 0.0661722\n",
      "[7644]\ttraining's binary_logloss: 0.0661645\n",
      "[7645]\ttraining's binary_logloss: 0.0661579\n",
      "[7646]\ttraining's binary_logloss: 0.0661511\n",
      "[7647]\ttraining's binary_logloss: 0.0661483\n",
      "[7648]\ttraining's binary_logloss: 0.0661454\n",
      "[7649]\ttraining's binary_logloss: 0.0661407\n",
      "[7650]\ttraining's binary_logloss: 0.0661364\n",
      "[7651]\ttraining's binary_logloss: 0.0661295\n",
      "[7652]\ttraining's binary_logloss: 0.0661219\n",
      "[7653]\ttraining's binary_logloss: 0.066116\n",
      "[7654]\ttraining's binary_logloss: 0.0661127\n",
      "[7655]\ttraining's binary_logloss: 0.0661056\n",
      "[7656]\ttraining's binary_logloss: 0.0660973\n",
      "[7657]\ttraining's binary_logloss: 0.0660906\n",
      "[7658]\ttraining's binary_logloss: 0.0660841\n",
      "[7659]\ttraining's binary_logloss: 0.0660766\n",
      "[7660]\ttraining's binary_logloss: 0.0660693\n",
      "[7661]\ttraining's binary_logloss: 0.066062\n",
      "[7662]\ttraining's binary_logloss: 0.0660556\n",
      "[7663]\ttraining's binary_logloss: 0.0660494\n",
      "[7664]\ttraining's binary_logloss: 0.0660422\n",
      "[7665]\ttraining's binary_logloss: 0.0660352\n",
      "[7666]\ttraining's binary_logloss: 0.0660311\n",
      "[7667]\ttraining's binary_logloss: 0.0660295\n",
      "[7668]\ttraining's binary_logloss: 0.0660251\n",
      "[7669]\ttraining's binary_logloss: 0.0660162\n",
      "[7670]\ttraining's binary_logloss: 0.066012\n",
      "[7671]\ttraining's binary_logloss: 0.0660052\n",
      "[7672]\ttraining's binary_logloss: 0.0659997\n",
      "[7673]\ttraining's binary_logloss: 0.0659914\n",
      "[7674]\ttraining's binary_logloss: 0.0659847\n",
      "[7675]\ttraining's binary_logloss: 0.065978\n",
      "[7676]\ttraining's binary_logloss: 0.0659737\n",
      "[7677]\ttraining's binary_logloss: 0.0659668\n",
      "[7678]\ttraining's binary_logloss: 0.0659606\n",
      "[7679]\ttraining's binary_logloss: 0.0659532\n",
      "[7680]\ttraining's binary_logloss: 0.065947\n",
      "[7681]\ttraining's binary_logloss: 0.0659422\n",
      "[7682]\ttraining's binary_logloss: 0.0659385\n",
      "[7683]\ttraining's binary_logloss: 0.0659308\n",
      "[7684]\ttraining's binary_logloss: 0.0659238\n",
      "[7685]\ttraining's binary_logloss: 0.0659155\n",
      "[7686]\ttraining's binary_logloss: 0.0659082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7687]\ttraining's binary_logloss: 0.0659022\n",
      "[7688]\ttraining's binary_logloss: 0.0658948\n",
      "[7689]\ttraining's binary_logloss: 0.0658871\n",
      "[7690]\ttraining's binary_logloss: 0.0658801\n",
      "[7691]\ttraining's binary_logloss: 0.0658725\n",
      "[7692]\ttraining's binary_logloss: 0.0658654\n",
      "[7693]\ttraining's binary_logloss: 0.0658591\n",
      "[7694]\ttraining's binary_logloss: 0.0658557\n",
      "[7695]\ttraining's binary_logloss: 0.0658485\n",
      "[7696]\ttraining's binary_logloss: 0.0658456\n",
      "[7697]\ttraining's binary_logloss: 0.0658394\n",
      "[7698]\ttraining's binary_logloss: 0.0658371\n",
      "[7699]\ttraining's binary_logloss: 0.0658308\n",
      "[7700]\ttraining's binary_logloss: 0.0658234\n",
      "[7701]\ttraining's binary_logloss: 0.0658162\n",
      "[7702]\ttraining's binary_logloss: 0.0658088\n",
      "[7703]\ttraining's binary_logloss: 0.0658029\n",
      "[7704]\ttraining's binary_logloss: 0.0657959\n",
      "[7705]\ttraining's binary_logloss: 0.065789\n",
      "[7706]\ttraining's binary_logloss: 0.0657862\n",
      "[7707]\ttraining's binary_logloss: 0.0657791\n",
      "[7708]\ttraining's binary_logloss: 0.0657734\n",
      "[7709]\ttraining's binary_logloss: 0.0657676\n",
      "[7710]\ttraining's binary_logloss: 0.0657603\n",
      "[7711]\ttraining's binary_logloss: 0.0657553\n",
      "[7712]\ttraining's binary_logloss: 0.0657488\n",
      "[7713]\ttraining's binary_logloss: 0.0657433\n",
      "[7714]\ttraining's binary_logloss: 0.0657387\n",
      "[7715]\ttraining's binary_logloss: 0.0657348\n",
      "[7716]\ttraining's binary_logloss: 0.0657283\n",
      "[7717]\ttraining's binary_logloss: 0.0657238\n",
      "[7718]\ttraining's binary_logloss: 0.0657176\n",
      "[7719]\ttraining's binary_logloss: 0.065713\n",
      "[7720]\ttraining's binary_logloss: 0.065705\n",
      "[7721]\ttraining's binary_logloss: 0.0657012\n",
      "[7722]\ttraining's binary_logloss: 0.065696\n",
      "[7723]\ttraining's binary_logloss: 0.0656927\n",
      "[7724]\ttraining's binary_logloss: 0.0656839\n",
      "[7725]\ttraining's binary_logloss: 0.0656771\n",
      "[7726]\ttraining's binary_logloss: 0.0656703\n",
      "[7727]\ttraining's binary_logloss: 0.0656644\n",
      "[7728]\ttraining's binary_logloss: 0.0656584\n",
      "[7729]\ttraining's binary_logloss: 0.0656539\n",
      "[7730]\ttraining's binary_logloss: 0.0656467\n",
      "[7731]\ttraining's binary_logloss: 0.0656409\n",
      "[7732]\ttraining's binary_logloss: 0.0656331\n",
      "[7733]\ttraining's binary_logloss: 0.0656274\n",
      "[7734]\ttraining's binary_logloss: 0.0656219\n",
      "[7735]\ttraining's binary_logloss: 0.0656154\n",
      "[7736]\ttraining's binary_logloss: 0.0656111\n",
      "[7737]\ttraining's binary_logloss: 0.065606\n",
      "[7738]\ttraining's binary_logloss: 0.065601\n",
      "[7739]\ttraining's binary_logloss: 0.0655968\n",
      "[7740]\ttraining's binary_logloss: 0.0655905\n",
      "[7741]\ttraining's binary_logloss: 0.0655841\n",
      "[7742]\ttraining's binary_logloss: 0.065577\n",
      "[7743]\ttraining's binary_logloss: 0.0655736\n",
      "[7744]\ttraining's binary_logloss: 0.0655666\n",
      "[7745]\ttraining's binary_logloss: 0.06556\n",
      "[7746]\ttraining's binary_logloss: 0.0655543\n",
      "[7747]\ttraining's binary_logloss: 0.0655474\n",
      "[7748]\ttraining's binary_logloss: 0.0655392\n",
      "[7749]\ttraining's binary_logloss: 0.0655329\n",
      "[7750]\ttraining's binary_logloss: 0.0655267\n",
      "[7751]\ttraining's binary_logloss: 0.0655231\n",
      "[7752]\ttraining's binary_logloss: 0.065517\n",
      "[7753]\ttraining's binary_logloss: 0.0655141\n",
      "[7754]\ttraining's binary_logloss: 0.0655059\n",
      "[7755]\ttraining's binary_logloss: 0.0654982\n",
      "[7756]\ttraining's binary_logloss: 0.0654923\n",
      "[7757]\ttraining's binary_logloss: 0.0654879\n",
      "[7758]\ttraining's binary_logloss: 0.0654801\n",
      "[7759]\ttraining's binary_logloss: 0.0654744\n",
      "[7760]\ttraining's binary_logloss: 0.0654665\n",
      "[7761]\ttraining's binary_logloss: 0.0654591\n",
      "[7762]\ttraining's binary_logloss: 0.0654515\n",
      "[7763]\ttraining's binary_logloss: 0.0654446\n",
      "[7764]\ttraining's binary_logloss: 0.0654378\n",
      "[7765]\ttraining's binary_logloss: 0.065434\n",
      "[7766]\ttraining's binary_logloss: 0.0654298\n",
      "[7767]\ttraining's binary_logloss: 0.065425\n",
      "[7768]\ttraining's binary_logloss: 0.0654217\n",
      "[7769]\ttraining's binary_logloss: 0.0654187\n",
      "[7770]\ttraining's binary_logloss: 0.0654129\n",
      "[7771]\ttraining's binary_logloss: 0.0654065\n",
      "[7772]\ttraining's binary_logloss: 0.0654015\n",
      "[7773]\ttraining's binary_logloss: 0.0653951\n",
      "[7774]\ttraining's binary_logloss: 0.0653884\n",
      "[7775]\ttraining's binary_logloss: 0.0653813\n",
      "[7776]\ttraining's binary_logloss: 0.0653747\n",
      "[7777]\ttraining's binary_logloss: 0.0653681\n",
      "[7778]\ttraining's binary_logloss: 0.0653608\n",
      "[7779]\ttraining's binary_logloss: 0.065354\n",
      "[7780]\ttraining's binary_logloss: 0.0653457\n",
      "[7781]\ttraining's binary_logloss: 0.0653407\n",
      "[7782]\ttraining's binary_logloss: 0.065333\n",
      "[7783]\ttraining's binary_logloss: 0.0653273\n",
      "[7784]\ttraining's binary_logloss: 0.0653194\n",
      "[7785]\ttraining's binary_logloss: 0.0653111\n",
      "[7786]\ttraining's binary_logloss: 0.0653049\n",
      "[7787]\ttraining's binary_logloss: 0.0653003\n",
      "[7788]\ttraining's binary_logloss: 0.0652938\n",
      "[7789]\ttraining's binary_logloss: 0.065287\n",
      "[7790]\ttraining's binary_logloss: 0.0652788\n",
      "[7791]\ttraining's binary_logloss: 0.0652725\n",
      "[7792]\ttraining's binary_logloss: 0.0652682\n",
      "[7793]\ttraining's binary_logloss: 0.0652608\n",
      "[7794]\ttraining's binary_logloss: 0.0652563\n",
      "[7795]\ttraining's binary_logloss: 0.0652506\n",
      "[7796]\ttraining's binary_logloss: 0.0652438\n",
      "[7797]\ttraining's binary_logloss: 0.0652369\n",
      "[7798]\ttraining's binary_logloss: 0.0652317\n",
      "[7799]\ttraining's binary_logloss: 0.0652251\n",
      "[7800]\ttraining's binary_logloss: 0.065218\n",
      "[7801]\ttraining's binary_logloss: 0.065211\n",
      "[7802]\ttraining's binary_logloss: 0.0652042\n",
      "[7803]\ttraining's binary_logloss: 0.0651981\n",
      "[7804]\ttraining's binary_logloss: 0.0651907\n",
      "[7805]\ttraining's binary_logloss: 0.0651844\n",
      "[7806]\ttraining's binary_logloss: 0.0651793\n",
      "[7807]\ttraining's binary_logloss: 0.065172\n",
      "[7808]\ttraining's binary_logloss: 0.0651656\n",
      "[7809]\ttraining's binary_logloss: 0.0651619\n",
      "[7810]\ttraining's binary_logloss: 0.0651557\n",
      "[7811]\ttraining's binary_logloss: 0.0651493\n",
      "[7812]\ttraining's binary_logloss: 0.0651423\n",
      "[7813]\ttraining's binary_logloss: 0.0651355\n",
      "[7814]\ttraining's binary_logloss: 0.0651279\n",
      "[7815]\ttraining's binary_logloss: 0.0651213\n",
      "[7816]\ttraining's binary_logloss: 0.0651145\n",
      "[7817]\ttraining's binary_logloss: 0.0651092\n",
      "[7818]\ttraining's binary_logloss: 0.0651025\n",
      "[7819]\ttraining's binary_logloss: 0.0650952\n",
      "[7820]\ttraining's binary_logloss: 0.0650894\n",
      "[7821]\ttraining's binary_logloss: 0.0650846\n",
      "[7822]\ttraining's binary_logloss: 0.0650782\n",
      "[7823]\ttraining's binary_logloss: 0.0650718\n",
      "[7824]\ttraining's binary_logloss: 0.065065\n",
      "[7825]\ttraining's binary_logloss: 0.06506\n",
      "[7826]\ttraining's binary_logloss: 0.0650558\n",
      "[7827]\ttraining's binary_logloss: 0.0650496\n",
      "[7828]\ttraining's binary_logloss: 0.0650437\n",
      "[7829]\ttraining's binary_logloss: 0.0650374\n",
      "[7830]\ttraining's binary_logloss: 0.065034\n",
      "[7831]\ttraining's binary_logloss: 0.0650328\n",
      "[7832]\ttraining's binary_logloss: 0.0650268\n",
      "[7833]\ttraining's binary_logloss: 0.0650211\n",
      "[7834]\ttraining's binary_logloss: 0.065016\n",
      "[7835]\ttraining's binary_logloss: 0.0650094\n",
      "[7836]\ttraining's binary_logloss: 0.0650024\n",
      "[7837]\ttraining's binary_logloss: 0.0649959\n",
      "[7838]\ttraining's binary_logloss: 0.0649894\n",
      "[7839]\ttraining's binary_logloss: 0.0649832\n",
      "[7840]\ttraining's binary_logloss: 0.0649771\n",
      "[7841]\ttraining's binary_logloss: 0.0649704\n",
      "[7842]\ttraining's binary_logloss: 0.064964\n",
      "[7843]\ttraining's binary_logloss: 0.0649582\n",
      "[7844]\ttraining's binary_logloss: 0.0649531\n",
      "[7845]\ttraining's binary_logloss: 0.0649452\n",
      "[7846]\ttraining's binary_logloss: 0.0649388\n",
      "[7847]\ttraining's binary_logloss: 0.0649313\n",
      "[7848]\ttraining's binary_logloss: 0.0649251\n",
      "[7849]\ttraining's binary_logloss: 0.0649182\n",
      "[7850]\ttraining's binary_logloss: 0.0649116\n",
      "[7851]\ttraining's binary_logloss: 0.0649052\n",
      "[7852]\ttraining's binary_logloss: 0.0649002\n",
      "[7853]\ttraining's binary_logloss: 0.0648922\n",
      "[7854]\ttraining's binary_logloss: 0.0648858\n",
      "[7855]\ttraining's binary_logloss: 0.0648797\n",
      "[7856]\ttraining's binary_logloss: 0.0648723\n",
      "[7857]\ttraining's binary_logloss: 0.0648644\n",
      "[7858]\ttraining's binary_logloss: 0.0648597\n",
      "[7859]\ttraining's binary_logloss: 0.0648525\n",
      "[7860]\ttraining's binary_logloss: 0.0648463\n",
      "[7861]\ttraining's binary_logloss: 0.0648405\n",
      "[7862]\ttraining's binary_logloss: 0.0648344\n",
      "[7863]\ttraining's binary_logloss: 0.064827\n",
      "[7864]\ttraining's binary_logloss: 0.0648198\n",
      "[7865]\ttraining's binary_logloss: 0.0648135\n",
      "[7866]\ttraining's binary_logloss: 0.0648069\n",
      "[7867]\ttraining's binary_logloss: 0.0648016\n",
      "[7868]\ttraining's binary_logloss: 0.0647952\n",
      "[7869]\ttraining's binary_logloss: 0.0647892\n",
      "[7870]\ttraining's binary_logloss: 0.0647825\n",
      "[7871]\ttraining's binary_logloss: 0.0647759\n",
      "[7872]\ttraining's binary_logloss: 0.0647699\n",
      "[7873]\ttraining's binary_logloss: 0.0647628\n",
      "[7874]\ttraining's binary_logloss: 0.0647558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7875]\ttraining's binary_logloss: 0.064749\n",
      "[7876]\ttraining's binary_logloss: 0.0647434\n",
      "[7877]\ttraining's binary_logloss: 0.0647359\n",
      "[7878]\ttraining's binary_logloss: 0.0647295\n",
      "[7879]\ttraining's binary_logloss: 0.0647225\n",
      "[7880]\ttraining's binary_logloss: 0.0647149\n",
      "[7881]\ttraining's binary_logloss: 0.0647075\n",
      "[7882]\ttraining's binary_logloss: 0.0647009\n",
      "[7883]\ttraining's binary_logloss: 0.0646941\n",
      "[7884]\ttraining's binary_logloss: 0.0646891\n",
      "[7885]\ttraining's binary_logloss: 0.0646835\n",
      "[7886]\ttraining's binary_logloss: 0.0646751\n",
      "[7887]\ttraining's binary_logloss: 0.0646678\n",
      "[7888]\ttraining's binary_logloss: 0.0646604\n",
      "[7889]\ttraining's binary_logloss: 0.0646533\n",
      "[7890]\ttraining's binary_logloss: 0.0646479\n",
      "[7891]\ttraining's binary_logloss: 0.0646404\n",
      "[7892]\ttraining's binary_logloss: 0.0646376\n",
      "[7893]\ttraining's binary_logloss: 0.0646323\n",
      "[7894]\ttraining's binary_logloss: 0.064625\n",
      "[7895]\ttraining's binary_logloss: 0.0646183\n",
      "[7896]\ttraining's binary_logloss: 0.0646116\n",
      "[7897]\ttraining's binary_logloss: 0.0646038\n",
      "[7898]\ttraining's binary_logloss: 0.0645965\n",
      "[7899]\ttraining's binary_logloss: 0.0645906\n",
      "[7900]\ttraining's binary_logloss: 0.0645846\n",
      "[7901]\ttraining's binary_logloss: 0.0645772\n",
      "[7902]\ttraining's binary_logloss: 0.0645751\n",
      "[7903]\ttraining's binary_logloss: 0.0645673\n",
      "[7904]\ttraining's binary_logloss: 0.0645603\n",
      "[7905]\ttraining's binary_logloss: 0.0645544\n",
      "[7906]\ttraining's binary_logloss: 0.0645488\n",
      "[7907]\ttraining's binary_logloss: 0.0645442\n",
      "[7908]\ttraining's binary_logloss: 0.0645374\n",
      "[7909]\ttraining's binary_logloss: 0.0645312\n",
      "[7910]\ttraining's binary_logloss: 0.0645238\n",
      "[7911]\ttraining's binary_logloss: 0.0645217\n",
      "[7912]\ttraining's binary_logloss: 0.0645165\n",
      "[7913]\ttraining's binary_logloss: 0.064509\n",
      "[7914]\ttraining's binary_logloss: 0.0645057\n",
      "[7915]\ttraining's binary_logloss: 0.0645007\n",
      "[7916]\ttraining's binary_logloss: 0.064494\n",
      "[7917]\ttraining's binary_logloss: 0.0644865\n",
      "[7918]\ttraining's binary_logloss: 0.0644802\n",
      "[7919]\ttraining's binary_logloss: 0.0644731\n",
      "[7920]\ttraining's binary_logloss: 0.0644656\n",
      "[7921]\ttraining's binary_logloss: 0.0644583\n",
      "[7922]\ttraining's binary_logloss: 0.0644534\n",
      "[7923]\ttraining's binary_logloss: 0.0644457\n",
      "[7924]\ttraining's binary_logloss: 0.0644392\n",
      "[7925]\ttraining's binary_logloss: 0.064433\n",
      "[7926]\ttraining's binary_logloss: 0.0644273\n",
      "[7927]\ttraining's binary_logloss: 0.0644224\n",
      "[7928]\ttraining's binary_logloss: 0.0644151\n",
      "[7929]\ttraining's binary_logloss: 0.0644087\n",
      "[7930]\ttraining's binary_logloss: 0.0644015\n",
      "[7931]\ttraining's binary_logloss: 0.0643946\n",
      "[7932]\ttraining's binary_logloss: 0.0643928\n",
      "[7933]\ttraining's binary_logloss: 0.0643851\n",
      "[7934]\ttraining's binary_logloss: 0.0643779\n",
      "[7935]\ttraining's binary_logloss: 0.0643706\n",
      "[7936]\ttraining's binary_logloss: 0.0643646\n",
      "[7937]\ttraining's binary_logloss: 0.0643606\n",
      "[7938]\ttraining's binary_logloss: 0.0643542\n",
      "[7939]\ttraining's binary_logloss: 0.0643472\n",
      "[7940]\ttraining's binary_logloss: 0.0643404\n",
      "[7941]\ttraining's binary_logloss: 0.0643355\n",
      "[7942]\ttraining's binary_logloss: 0.0643282\n",
      "[7943]\ttraining's binary_logloss: 0.0643256\n",
      "[7944]\ttraining's binary_logloss: 0.0643206\n",
      "[7945]\ttraining's binary_logloss: 0.0643135\n",
      "[7946]\ttraining's binary_logloss: 0.0643071\n",
      "[7947]\ttraining's binary_logloss: 0.0642993\n",
      "[7948]\ttraining's binary_logloss: 0.0642924\n",
      "[7949]\ttraining's binary_logloss: 0.0642853\n",
      "[7950]\ttraining's binary_logloss: 0.0642794\n",
      "[7951]\ttraining's binary_logloss: 0.0642726\n",
      "[7952]\ttraining's binary_logloss: 0.0642658\n",
      "[7953]\ttraining's binary_logloss: 0.0642584\n",
      "[7954]\ttraining's binary_logloss: 0.0642521\n",
      "[7955]\ttraining's binary_logloss: 0.0642444\n",
      "[7956]\ttraining's binary_logloss: 0.0642373\n",
      "[7957]\ttraining's binary_logloss: 0.0642326\n",
      "[7958]\ttraining's binary_logloss: 0.0642272\n",
      "[7959]\ttraining's binary_logloss: 0.0642194\n",
      "[7960]\ttraining's binary_logloss: 0.064213\n",
      "[7961]\ttraining's binary_logloss: 0.0642062\n",
      "[7962]\ttraining's binary_logloss: 0.064201\n",
      "[7963]\ttraining's binary_logloss: 0.0641943\n",
      "[7964]\ttraining's binary_logloss: 0.064189\n",
      "[7965]\ttraining's binary_logloss: 0.0641841\n",
      "[7966]\ttraining's binary_logloss: 0.0641793\n",
      "[7967]\ttraining's binary_logloss: 0.064172\n",
      "[7968]\ttraining's binary_logloss: 0.0641655\n",
      "[7969]\ttraining's binary_logloss: 0.0641589\n",
      "[7970]\ttraining's binary_logloss: 0.0641519\n",
      "[7971]\ttraining's binary_logloss: 0.0641442\n",
      "[7972]\ttraining's binary_logloss: 0.0641382\n",
      "[7973]\ttraining's binary_logloss: 0.0641314\n",
      "[7974]\ttraining's binary_logloss: 0.0641244\n",
      "[7975]\ttraining's binary_logloss: 0.064119\n",
      "[7976]\ttraining's binary_logloss: 0.064112\n",
      "[7977]\ttraining's binary_logloss: 0.0641047\n",
      "[7978]\ttraining's binary_logloss: 0.0640983\n",
      "[7979]\ttraining's binary_logloss: 0.0640963\n",
      "[7980]\ttraining's binary_logloss: 0.0640901\n",
      "[7981]\ttraining's binary_logloss: 0.0640831\n",
      "[7982]\ttraining's binary_logloss: 0.0640775\n",
      "[7983]\ttraining's binary_logloss: 0.0640713\n",
      "[7984]\ttraining's binary_logloss: 0.064064\n",
      "[7985]\ttraining's binary_logloss: 0.0640606\n",
      "[7986]\ttraining's binary_logloss: 0.0640552\n",
      "[7987]\ttraining's binary_logloss: 0.0640496\n",
      "[7988]\ttraining's binary_logloss: 0.0640435\n",
      "[7989]\ttraining's binary_logloss: 0.0640378\n",
      "[7990]\ttraining's binary_logloss: 0.0640326\n",
      "[7991]\ttraining's binary_logloss: 0.0640273\n",
      "[7992]\ttraining's binary_logloss: 0.0640218\n",
      "[7993]\ttraining's binary_logloss: 0.0640158\n",
      "[7994]\ttraining's binary_logloss: 0.0640086\n",
      "[7995]\ttraining's binary_logloss: 0.0640029\n",
      "[7996]\ttraining's binary_logloss: 0.0639986\n",
      "[7997]\ttraining's binary_logloss: 0.0639921\n",
      "[7998]\ttraining's binary_logloss: 0.06399\n",
      "[7999]\ttraining's binary_logloss: 0.0639835\n",
      "[8000]\ttraining's binary_logloss: 0.0639761\n",
      "[8001]\ttraining's binary_logloss: 0.0639697\n",
      "[8002]\ttraining's binary_logloss: 0.0639656\n",
      "[8003]\ttraining's binary_logloss: 0.063958\n",
      "[8004]\ttraining's binary_logloss: 0.0639512\n",
      "[8005]\ttraining's binary_logloss: 0.0639454\n",
      "[8006]\ttraining's binary_logloss: 0.0639391\n",
      "[8007]\ttraining's binary_logloss: 0.0639326\n",
      "[8008]\ttraining's binary_logloss: 0.0639293\n",
      "[8009]\ttraining's binary_logloss: 0.0639223\n",
      "[8010]\ttraining's binary_logloss: 0.0639154\n",
      "[8011]\ttraining's binary_logloss: 0.0639094\n",
      "[8012]\ttraining's binary_logloss: 0.0639022\n",
      "[8013]\ttraining's binary_logloss: 0.0638967\n",
      "[8014]\ttraining's binary_logloss: 0.0638953\n",
      "[8015]\ttraining's binary_logloss: 0.0638885\n",
      "[8016]\ttraining's binary_logloss: 0.0638833\n",
      "[8017]\ttraining's binary_logloss: 0.0638766\n",
      "[8018]\ttraining's binary_logloss: 0.0638702\n",
      "[8019]\ttraining's binary_logloss: 0.0638642\n",
      "[8020]\ttraining's binary_logloss: 0.0638591\n",
      "[8021]\ttraining's binary_logloss: 0.063855\n",
      "[8022]\ttraining's binary_logloss: 0.0638502\n",
      "[8023]\ttraining's binary_logloss: 0.0638425\n",
      "[8024]\ttraining's binary_logloss: 0.0638364\n",
      "[8025]\ttraining's binary_logloss: 0.0638303\n",
      "[8026]\ttraining's binary_logloss: 0.0638285\n",
      "[8027]\ttraining's binary_logloss: 0.0638216\n",
      "[8028]\ttraining's binary_logloss: 0.0638163\n",
      "[8029]\ttraining's binary_logloss: 0.0638106\n",
      "[8030]\ttraining's binary_logloss: 0.0638034\n",
      "[8031]\ttraining's binary_logloss: 0.0637976\n",
      "[8032]\ttraining's binary_logloss: 0.0637909\n",
      "[8033]\ttraining's binary_logloss: 0.0637832\n",
      "[8034]\ttraining's binary_logloss: 0.0637767\n",
      "[8035]\ttraining's binary_logloss: 0.0637738\n",
      "[8036]\ttraining's binary_logloss: 0.0637716\n",
      "[8037]\ttraining's binary_logloss: 0.0637671\n",
      "[8038]\ttraining's binary_logloss: 0.0637647\n",
      "[8039]\ttraining's binary_logloss: 0.0637574\n",
      "[8040]\ttraining's binary_logloss: 0.0637504\n",
      "[8041]\ttraining's binary_logloss: 0.0637457\n",
      "[8042]\ttraining's binary_logloss: 0.063739\n",
      "[8043]\ttraining's binary_logloss: 0.0637366\n",
      "[8044]\ttraining's binary_logloss: 0.0637312\n",
      "[8045]\ttraining's binary_logloss: 0.0637298\n",
      "[8046]\ttraining's binary_logloss: 0.063724\n",
      "[8047]\ttraining's binary_logloss: 0.0637179\n",
      "[8048]\ttraining's binary_logloss: 0.0637113\n",
      "[8049]\ttraining's binary_logloss: 0.0637039\n",
      "[8050]\ttraining's binary_logloss: 0.0636974\n",
      "[8051]\ttraining's binary_logloss: 0.063691\n",
      "[8052]\ttraining's binary_logloss: 0.0636882\n",
      "[8053]\ttraining's binary_logloss: 0.0636815\n",
      "[8054]\ttraining's binary_logloss: 0.0636747\n",
      "[8055]\ttraining's binary_logloss: 0.0636679\n",
      "[8056]\ttraining's binary_logloss: 0.0636619\n",
      "[8057]\ttraining's binary_logloss: 0.0636579\n",
      "[8058]\ttraining's binary_logloss: 0.063657\n",
      "[8059]\ttraining's binary_logloss: 0.0636497\n",
      "[8060]\ttraining's binary_logloss: 0.0636483\n",
      "[8061]\ttraining's binary_logloss: 0.0636426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8062]\ttraining's binary_logloss: 0.0636365\n",
      "[8063]\ttraining's binary_logloss: 0.0636294\n",
      "[8064]\ttraining's binary_logloss: 0.0636228\n",
      "[8065]\ttraining's binary_logloss: 0.0636162\n",
      "[8066]\ttraining's binary_logloss: 0.063613\n",
      "[8067]\ttraining's binary_logloss: 0.0636073\n",
      "[8068]\ttraining's binary_logloss: 0.0636036\n",
      "[8069]\ttraining's binary_logloss: 0.0635964\n",
      "[8070]\ttraining's binary_logloss: 0.0635902\n",
      "[8071]\ttraining's binary_logloss: 0.0635836\n",
      "[8072]\ttraining's binary_logloss: 0.0635757\n",
      "[8073]\ttraining's binary_logloss: 0.0635693\n",
      "[8074]\ttraining's binary_logloss: 0.063564\n",
      "[8075]\ttraining's binary_logloss: 0.0635579\n",
      "[8076]\ttraining's binary_logloss: 0.0635521\n",
      "[8077]\ttraining's binary_logloss: 0.063546\n",
      "[8078]\ttraining's binary_logloss: 0.0635398\n",
      "[8079]\ttraining's binary_logloss: 0.063532\n",
      "[8080]\ttraining's binary_logloss: 0.0635261\n",
      "[8081]\ttraining's binary_logloss: 0.0635233\n",
      "[8082]\ttraining's binary_logloss: 0.0635188\n",
      "[8083]\ttraining's binary_logloss: 0.0635117\n",
      "[8084]\ttraining's binary_logloss: 0.063504\n",
      "[8085]\ttraining's binary_logloss: 0.0634973\n",
      "[8086]\ttraining's binary_logloss: 0.0634943\n",
      "[8087]\ttraining's binary_logloss: 0.0634883\n",
      "[8088]\ttraining's binary_logloss: 0.0634811\n",
      "[8089]\ttraining's binary_logloss: 0.0634745\n",
      "[8090]\ttraining's binary_logloss: 0.0634697\n",
      "[8091]\ttraining's binary_logloss: 0.0634641\n",
      "[8092]\ttraining's binary_logloss: 0.0634572\n",
      "[8093]\ttraining's binary_logloss: 0.0634527\n",
      "[8094]\ttraining's binary_logloss: 0.0634468\n",
      "[8095]\ttraining's binary_logloss: 0.0634406\n",
      "[8096]\ttraining's binary_logloss: 0.0634344\n",
      "[8097]\ttraining's binary_logloss: 0.0634289\n",
      "[8098]\ttraining's binary_logloss: 0.0634244\n",
      "[8099]\ttraining's binary_logloss: 0.0634183\n",
      "[8100]\ttraining's binary_logloss: 0.0634152\n",
      "[8101]\ttraining's binary_logloss: 0.0634081\n",
      "[8102]\ttraining's binary_logloss: 0.0634016\n",
      "[8103]\ttraining's binary_logloss: 0.0633951\n",
      "[8104]\ttraining's binary_logloss: 0.0633902\n",
      "[8105]\ttraining's binary_logloss: 0.0633835\n",
      "[8106]\ttraining's binary_logloss: 0.0633796\n",
      "[8107]\ttraining's binary_logloss: 0.0633737\n",
      "[8108]\ttraining's binary_logloss: 0.0633675\n",
      "[8109]\ttraining's binary_logloss: 0.0633627\n",
      "[8110]\ttraining's binary_logloss: 0.0633565\n",
      "[8111]\ttraining's binary_logloss: 0.0633511\n",
      "[8112]\ttraining's binary_logloss: 0.063346\n",
      "[8113]\ttraining's binary_logloss: 0.063339\n",
      "[8114]\ttraining's binary_logloss: 0.0633319\n",
      "[8115]\ttraining's binary_logloss: 0.0633256\n",
      "[8116]\ttraining's binary_logloss: 0.0633181\n",
      "[8117]\ttraining's binary_logloss: 0.0633112\n",
      "[8118]\ttraining's binary_logloss: 0.0633051\n",
      "[8119]\ttraining's binary_logloss: 0.0633001\n",
      "[8120]\ttraining's binary_logloss: 0.0632945\n",
      "[8121]\ttraining's binary_logloss: 0.0632883\n",
      "[8122]\ttraining's binary_logloss: 0.0632832\n",
      "[8123]\ttraining's binary_logloss: 0.0632766\n",
      "[8124]\ttraining's binary_logloss: 0.0632693\n",
      "[8125]\ttraining's binary_logloss: 0.0632669\n",
      "[8126]\ttraining's binary_logloss: 0.0632609\n",
      "[8127]\ttraining's binary_logloss: 0.0632563\n",
      "[8128]\ttraining's binary_logloss: 0.0632497\n",
      "[8129]\ttraining's binary_logloss: 0.0632427\n",
      "[8130]\ttraining's binary_logloss: 0.0632402\n",
      "[8131]\ttraining's binary_logloss: 0.0632335\n",
      "[8132]\ttraining's binary_logloss: 0.0632296\n",
      "[8133]\ttraining's binary_logloss: 0.0632237\n",
      "[8134]\ttraining's binary_logloss: 0.0632178\n",
      "[8135]\ttraining's binary_logloss: 0.0632117\n",
      "[8136]\ttraining's binary_logloss: 0.0632057\n",
      "[8137]\ttraining's binary_logloss: 0.0631997\n",
      "[8138]\ttraining's binary_logloss: 0.063194\n",
      "[8139]\ttraining's binary_logloss: 0.0631873\n",
      "[8140]\ttraining's binary_logloss: 0.0631828\n",
      "[8141]\ttraining's binary_logloss: 0.0631771\n",
      "[8142]\ttraining's binary_logloss: 0.06317\n",
      "[8143]\ttraining's binary_logloss: 0.0631633\n",
      "[8144]\ttraining's binary_logloss: 0.0631563\n",
      "[8145]\ttraining's binary_logloss: 0.0631493\n",
      "[8146]\ttraining's binary_logloss: 0.0631418\n",
      "[8147]\ttraining's binary_logloss: 0.0631353\n",
      "[8148]\ttraining's binary_logloss: 0.0631284\n",
      "[8149]\ttraining's binary_logloss: 0.0631209\n",
      "[8150]\ttraining's binary_logloss: 0.0631142\n",
      "[8151]\ttraining's binary_logloss: 0.0631081\n",
      "[8152]\ttraining's binary_logloss: 0.0631011\n",
      "[8153]\ttraining's binary_logloss: 0.0630943\n",
      "[8154]\ttraining's binary_logloss: 0.0630874\n",
      "[8155]\ttraining's binary_logloss: 0.0630813\n",
      "[8156]\ttraining's binary_logloss: 0.0630748\n",
      "[8157]\ttraining's binary_logloss: 0.0630705\n",
      "[8158]\ttraining's binary_logloss: 0.0630637\n",
      "[8159]\ttraining's binary_logloss: 0.0630592\n",
      "[8160]\ttraining's binary_logloss: 0.0630526\n",
      "[8161]\ttraining's binary_logloss: 0.0630499\n",
      "[8162]\ttraining's binary_logloss: 0.0630467\n",
      "[8163]\ttraining's binary_logloss: 0.0630397\n",
      "[8164]\ttraining's binary_logloss: 0.0630353\n",
      "[8165]\ttraining's binary_logloss: 0.0630284\n",
      "[8166]\ttraining's binary_logloss: 0.0630247\n",
      "[8167]\ttraining's binary_logloss: 0.0630183\n",
      "[8168]\ttraining's binary_logloss: 0.0630122\n",
      "[8169]\ttraining's binary_logloss: 0.0630059\n",
      "[8170]\ttraining's binary_logloss: 0.0630009\n",
      "[8171]\ttraining's binary_logloss: 0.0629958\n",
      "[8172]\ttraining's binary_logloss: 0.0629876\n",
      "[8173]\ttraining's binary_logloss: 0.0629818\n",
      "[8174]\ttraining's binary_logloss: 0.0629748\n",
      "[8175]\ttraining's binary_logloss: 0.0629689\n",
      "[8176]\ttraining's binary_logloss: 0.0629643\n",
      "[8177]\ttraining's binary_logloss: 0.0629577\n",
      "[8178]\ttraining's binary_logloss: 0.062951\n",
      "[8179]\ttraining's binary_logloss: 0.0629445\n",
      "[8180]\ttraining's binary_logloss: 0.0629385\n",
      "[8181]\ttraining's binary_logloss: 0.0629321\n",
      "[8182]\ttraining's binary_logloss: 0.0629257\n",
      "[8183]\ttraining's binary_logloss: 0.0629186\n",
      "[8184]\ttraining's binary_logloss: 0.062912\n",
      "[8185]\ttraining's binary_logloss: 0.0629056\n",
      "[8186]\ttraining's binary_logloss: 0.0628994\n",
      "[8187]\ttraining's binary_logloss: 0.0628951\n",
      "[8188]\ttraining's binary_logloss: 0.0628907\n",
      "[8189]\ttraining's binary_logloss: 0.0628841\n",
      "[8190]\ttraining's binary_logloss: 0.0628785\n",
      "[8191]\ttraining's binary_logloss: 0.0628717\n",
      "[8192]\ttraining's binary_logloss: 0.0628658\n",
      "[8193]\ttraining's binary_logloss: 0.0628594\n",
      "[8194]\ttraining's binary_logloss: 0.0628532\n",
      "[8195]\ttraining's binary_logloss: 0.0628471\n",
      "[8196]\ttraining's binary_logloss: 0.0628408\n",
      "[8197]\ttraining's binary_logloss: 0.062836\n",
      "[8198]\ttraining's binary_logloss: 0.0628306\n",
      "[8199]\ttraining's binary_logloss: 0.0628289\n",
      "[8200]\ttraining's binary_logloss: 0.0628239\n",
      "[8201]\ttraining's binary_logloss: 0.0628168\n",
      "[8202]\ttraining's binary_logloss: 0.0628105\n",
      "[8203]\ttraining's binary_logloss: 0.062805\n",
      "[8204]\ttraining's binary_logloss: 0.0627982\n",
      "[8205]\ttraining's binary_logloss: 0.0627916\n",
      "[8206]\ttraining's binary_logloss: 0.0627852\n",
      "[8207]\ttraining's binary_logloss: 0.0627779\n",
      "[8208]\ttraining's binary_logloss: 0.0627732\n",
      "[8209]\ttraining's binary_logloss: 0.0627655\n",
      "[8210]\ttraining's binary_logloss: 0.0627594\n",
      "[8211]\ttraining's binary_logloss: 0.0627545\n",
      "[8212]\ttraining's binary_logloss: 0.0627488\n",
      "[8213]\ttraining's binary_logloss: 0.0627419\n",
      "[8214]\ttraining's binary_logloss: 0.0627349\n",
      "[8215]\ttraining's binary_logloss: 0.0627307\n",
      "[8216]\ttraining's binary_logloss: 0.0627233\n",
      "[8217]\ttraining's binary_logloss: 0.0627176\n",
      "[8218]\ttraining's binary_logloss: 0.0627108\n",
      "[8219]\ttraining's binary_logloss: 0.0627025\n",
      "[8220]\ttraining's binary_logloss: 0.0626943\n",
      "[8221]\ttraining's binary_logloss: 0.0626878\n",
      "[8222]\ttraining's binary_logloss: 0.0626797\n",
      "[8223]\ttraining's binary_logloss: 0.0626745\n",
      "[8224]\ttraining's binary_logloss: 0.0626678\n",
      "[8225]\ttraining's binary_logloss: 0.0626614\n",
      "[8226]\ttraining's binary_logloss: 0.0626548\n",
      "[8227]\ttraining's binary_logloss: 0.0626484\n",
      "[8228]\ttraining's binary_logloss: 0.0626446\n",
      "[8229]\ttraining's binary_logloss: 0.062638\n",
      "[8230]\ttraining's binary_logloss: 0.0626309\n",
      "[8231]\ttraining's binary_logloss: 0.0626245\n",
      "[8232]\ttraining's binary_logloss: 0.0626219\n",
      "[8233]\ttraining's binary_logloss: 0.0626153\n",
      "[8234]\ttraining's binary_logloss: 0.062608\n",
      "[8235]\ttraining's binary_logloss: 0.0626012\n",
      "[8236]\ttraining's binary_logloss: 0.0625947\n",
      "[8237]\ttraining's binary_logloss: 0.0625902\n",
      "[8238]\ttraining's binary_logloss: 0.0625838\n",
      "[8239]\ttraining's binary_logloss: 0.0625773\n",
      "[8240]\ttraining's binary_logloss: 0.0625713\n",
      "[8241]\ttraining's binary_logloss: 0.062565\n",
      "[8242]\ttraining's binary_logloss: 0.0625581\n",
      "[8243]\ttraining's binary_logloss: 0.0625502\n",
      "[8244]\ttraining's binary_logloss: 0.0625456\n",
      "[8245]\ttraining's binary_logloss: 0.0625392\n",
      "[8246]\ttraining's binary_logloss: 0.0625362\n",
      "[8247]\ttraining's binary_logloss: 0.0625319\n",
      "[8248]\ttraining's binary_logloss: 0.0625303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8249]\ttraining's binary_logloss: 0.0625243\n",
      "[8250]\ttraining's binary_logloss: 0.062517\n",
      "[8251]\ttraining's binary_logloss: 0.0625148\n",
      "[8252]\ttraining's binary_logloss: 0.0625089\n",
      "[8253]\ttraining's binary_logloss: 0.0625029\n",
      "[8254]\ttraining's binary_logloss: 0.0624947\n",
      "[8255]\ttraining's binary_logloss: 0.0624876\n",
      "[8256]\ttraining's binary_logloss: 0.0624851\n",
      "[8257]\ttraining's binary_logloss: 0.0624782\n",
      "[8258]\ttraining's binary_logloss: 0.0624765\n",
      "[8259]\ttraining's binary_logloss: 0.0624733\n",
      "[8260]\ttraining's binary_logloss: 0.0624684\n",
      "[8261]\ttraining's binary_logloss: 0.0624624\n",
      "[8262]\ttraining's binary_logloss: 0.0624597\n",
      "[8263]\ttraining's binary_logloss: 0.062452\n",
      "[8264]\ttraining's binary_logloss: 0.0624447\n",
      "[8265]\ttraining's binary_logloss: 0.0624399\n",
      "[8266]\ttraining's binary_logloss: 0.0624336\n",
      "[8267]\ttraining's binary_logloss: 0.0624273\n",
      "[8268]\ttraining's binary_logloss: 0.0624214\n",
      "[8269]\ttraining's binary_logloss: 0.0624194\n",
      "[8270]\ttraining's binary_logloss: 0.0624161\n",
      "[8271]\ttraining's binary_logloss: 0.0624103\n",
      "[8272]\ttraining's binary_logloss: 0.0624047\n",
      "[8273]\ttraining's binary_logloss: 0.0623982\n",
      "[8274]\ttraining's binary_logloss: 0.0623912\n",
      "[8275]\ttraining's binary_logloss: 0.0623851\n",
      "[8276]\ttraining's binary_logloss: 0.0623773\n",
      "[8277]\ttraining's binary_logloss: 0.0623705\n",
      "[8278]\ttraining's binary_logloss: 0.0623636\n",
      "[8279]\ttraining's binary_logloss: 0.062359\n",
      "[8280]\ttraining's binary_logloss: 0.0623531\n",
      "[8281]\ttraining's binary_logloss: 0.062348\n",
      "[8282]\ttraining's binary_logloss: 0.0623416\n",
      "[8283]\ttraining's binary_logloss: 0.062335\n",
      "[8284]\ttraining's binary_logloss: 0.0623281\n",
      "[8285]\ttraining's binary_logloss: 0.0623223\n",
      "[8286]\ttraining's binary_logloss: 0.0623151\n",
      "[8287]\ttraining's binary_logloss: 0.0623074\n",
      "[8288]\ttraining's binary_logloss: 0.062305\n",
      "[8289]\ttraining's binary_logloss: 0.0622981\n",
      "[8290]\ttraining's binary_logloss: 0.062294\n",
      "[8291]\ttraining's binary_logloss: 0.0622872\n",
      "[8292]\ttraining's binary_logloss: 0.0622814\n",
      "[8293]\ttraining's binary_logloss: 0.0622755\n",
      "[8294]\ttraining's binary_logloss: 0.062269\n",
      "[8295]\ttraining's binary_logloss: 0.0622633\n",
      "[8296]\ttraining's binary_logloss: 0.0622611\n",
      "[8297]\ttraining's binary_logloss: 0.062255\n",
      "[8298]\ttraining's binary_logloss: 0.0622534\n",
      "[8299]\ttraining's binary_logloss: 0.0622462\n",
      "[8300]\ttraining's binary_logloss: 0.0622404\n",
      "[8301]\ttraining's binary_logloss: 0.0622337\n",
      "[8302]\ttraining's binary_logloss: 0.0622268\n",
      "[8303]\ttraining's binary_logloss: 0.062221\n",
      "[8304]\ttraining's binary_logloss: 0.0622141\n",
      "[8305]\ttraining's binary_logloss: 0.0622083\n",
      "[8306]\ttraining's binary_logloss: 0.0622025\n",
      "[8307]\ttraining's binary_logloss: 0.0621966\n",
      "[8308]\ttraining's binary_logloss: 0.0621891\n",
      "[8309]\ttraining's binary_logloss: 0.0621834\n",
      "[8310]\ttraining's binary_logloss: 0.0621769\n",
      "[8311]\ttraining's binary_logloss: 0.0621713\n",
      "[8312]\ttraining's binary_logloss: 0.062163\n",
      "[8313]\ttraining's binary_logloss: 0.0621572\n",
      "[8314]\ttraining's binary_logloss: 0.0621499\n",
      "[8315]\ttraining's binary_logloss: 0.0621433\n",
      "[8316]\ttraining's binary_logloss: 0.0621362\n",
      "[8317]\ttraining's binary_logloss: 0.0621299\n",
      "[8318]\ttraining's binary_logloss: 0.0621233\n",
      "[8319]\ttraining's binary_logloss: 0.0621157\n",
      "[8320]\ttraining's binary_logloss: 0.0621101\n",
      "[8321]\ttraining's binary_logloss: 0.0621029\n",
      "[8322]\ttraining's binary_logloss: 0.0620968\n",
      "[8323]\ttraining's binary_logloss: 0.0620914\n",
      "[8324]\ttraining's binary_logloss: 0.0620841\n",
      "[8325]\ttraining's binary_logloss: 0.062077\n",
      "[8326]\ttraining's binary_logloss: 0.0620698\n",
      "[8327]\ttraining's binary_logloss: 0.0620641\n",
      "[8328]\ttraining's binary_logloss: 0.0620596\n",
      "[8329]\ttraining's binary_logloss: 0.0620531\n",
      "[8330]\ttraining's binary_logloss: 0.0620498\n",
      "[8331]\ttraining's binary_logloss: 0.0620431\n",
      "[8332]\ttraining's binary_logloss: 0.0620374\n",
      "[8333]\ttraining's binary_logloss: 0.0620309\n",
      "[8334]\ttraining's binary_logloss: 0.0620255\n",
      "[8335]\ttraining's binary_logloss: 0.0620201\n",
      "[8336]\ttraining's binary_logloss: 0.0620137\n",
      "[8337]\ttraining's binary_logloss: 0.0620127\n",
      "[8338]\ttraining's binary_logloss: 0.0620063\n",
      "[8339]\ttraining's binary_logloss: 0.0620003\n",
      "[8340]\ttraining's binary_logloss: 0.0619938\n",
      "[8341]\ttraining's binary_logloss: 0.0619876\n",
      "[8342]\ttraining's binary_logloss: 0.0619801\n",
      "[8343]\ttraining's binary_logloss: 0.0619735\n",
      "[8344]\ttraining's binary_logloss: 0.0619685\n",
      "[8345]\ttraining's binary_logloss: 0.0619623\n",
      "[8346]\ttraining's binary_logloss: 0.0619563\n",
      "[8347]\ttraining's binary_logloss: 0.0619508\n",
      "[8348]\ttraining's binary_logloss: 0.0619485\n",
      "[8349]\ttraining's binary_logloss: 0.061945\n",
      "[8350]\ttraining's binary_logloss: 0.0619387\n",
      "[8351]\ttraining's binary_logloss: 0.0619312\n",
      "[8352]\ttraining's binary_logloss: 0.0619234\n",
      "[8353]\ttraining's binary_logloss: 0.0619197\n",
      "[8354]\ttraining's binary_logloss: 0.0619126\n",
      "[8355]\ttraining's binary_logloss: 0.0619074\n",
      "[8356]\ttraining's binary_logloss: 0.0619035\n",
      "[8357]\ttraining's binary_logloss: 0.0618973\n",
      "[8358]\ttraining's binary_logloss: 0.0618906\n",
      "[8359]\ttraining's binary_logloss: 0.0618882\n",
      "[8360]\ttraining's binary_logloss: 0.0618816\n",
      "[8361]\ttraining's binary_logloss: 0.0618744\n",
      "[8362]\ttraining's binary_logloss: 0.0618681\n",
      "[8363]\ttraining's binary_logloss: 0.0618617\n",
      "[8364]\ttraining's binary_logloss: 0.0618552\n",
      "[8365]\ttraining's binary_logloss: 0.0618484\n",
      "[8366]\ttraining's binary_logloss: 0.0618432\n",
      "[8367]\ttraining's binary_logloss: 0.0618362\n",
      "[8368]\ttraining's binary_logloss: 0.0618293\n",
      "[8369]\ttraining's binary_logloss: 0.0618265\n",
      "[8370]\ttraining's binary_logloss: 0.0618188\n",
      "[8371]\ttraining's binary_logloss: 0.061812\n",
      "[8372]\ttraining's binary_logloss: 0.0618058\n",
      "[8373]\ttraining's binary_logloss: 0.0617998\n",
      "[8374]\ttraining's binary_logloss: 0.0617933\n",
      "[8375]\ttraining's binary_logloss: 0.0617872\n",
      "[8376]\ttraining's binary_logloss: 0.0617802\n",
      "[8377]\ttraining's binary_logloss: 0.0617746\n",
      "[8378]\ttraining's binary_logloss: 0.0617683\n",
      "[8379]\ttraining's binary_logloss: 0.0617619\n",
      "[8380]\ttraining's binary_logloss: 0.0617553\n",
      "[8381]\ttraining's binary_logloss: 0.0617529\n",
      "[8382]\ttraining's binary_logloss: 0.0617485\n",
      "[8383]\ttraining's binary_logloss: 0.0617429\n",
      "[8384]\ttraining's binary_logloss: 0.061737\n",
      "[8385]\ttraining's binary_logloss: 0.0617306\n",
      "[8386]\ttraining's binary_logloss: 0.0617241\n",
      "[8387]\ttraining's binary_logloss: 0.0617178\n",
      "[8388]\ttraining's binary_logloss: 0.061712\n",
      "[8389]\ttraining's binary_logloss: 0.0617055\n",
      "[8390]\ttraining's binary_logloss: 0.0617024\n",
      "[8391]\ttraining's binary_logloss: 0.0616984\n",
      "[8392]\ttraining's binary_logloss: 0.061692\n",
      "[8393]\ttraining's binary_logloss: 0.0616851\n",
      "[8394]\ttraining's binary_logloss: 0.0616791\n",
      "[8395]\ttraining's binary_logloss: 0.0616762\n",
      "[8396]\ttraining's binary_logloss: 0.061669\n",
      "[8397]\ttraining's binary_logloss: 0.0616647\n",
      "[8398]\ttraining's binary_logloss: 0.0616591\n",
      "[8399]\ttraining's binary_logloss: 0.0616528\n",
      "[8400]\ttraining's binary_logloss: 0.0616465\n",
      "[8401]\ttraining's binary_logloss: 0.0616442\n",
      "[8402]\ttraining's binary_logloss: 0.0616387\n",
      "[8403]\ttraining's binary_logloss: 0.0616345\n",
      "[8404]\ttraining's binary_logloss: 0.0616287\n",
      "[8405]\ttraining's binary_logloss: 0.0616223\n",
      "[8406]\ttraining's binary_logloss: 0.0616158\n",
      "[8407]\ttraining's binary_logloss: 0.0616094\n",
      "[8408]\ttraining's binary_logloss: 0.0616066\n",
      "[8409]\ttraining's binary_logloss: 0.0616037\n",
      "[8410]\ttraining's binary_logloss: 0.0615975\n",
      "[8411]\ttraining's binary_logloss: 0.0615895\n",
      "[8412]\ttraining's binary_logloss: 0.0615863\n",
      "[8413]\ttraining's binary_logloss: 0.0615819\n",
      "[8414]\ttraining's binary_logloss: 0.0615756\n",
      "[8415]\ttraining's binary_logloss: 0.0615683\n",
      "[8416]\ttraining's binary_logloss: 0.0615628\n",
      "[8417]\ttraining's binary_logloss: 0.0615563\n",
      "[8418]\ttraining's binary_logloss: 0.0615526\n",
      "[8419]\ttraining's binary_logloss: 0.0615486\n",
      "[8420]\ttraining's binary_logloss: 0.0615429\n",
      "[8421]\ttraining's binary_logloss: 0.0615362\n",
      "[8422]\ttraining's binary_logloss: 0.0615329\n",
      "[8423]\ttraining's binary_logloss: 0.0615261\n",
      "[8424]\ttraining's binary_logloss: 0.0615198\n",
      "[8425]\ttraining's binary_logloss: 0.0615131\n",
      "[8426]\ttraining's binary_logloss: 0.0615096\n",
      "[8427]\ttraining's binary_logloss: 0.0615033\n",
      "[8428]\ttraining's binary_logloss: 0.0614966\n",
      "[8429]\ttraining's binary_logloss: 0.0614936\n",
      "[8430]\ttraining's binary_logloss: 0.0614867\n",
      "[8431]\ttraining's binary_logloss: 0.0614822\n",
      "[8432]\ttraining's binary_logloss: 0.0614754\n",
      "[8433]\ttraining's binary_logloss: 0.0614707\n",
      "[8434]\ttraining's binary_logloss: 0.0614649\n",
      "[8435]\ttraining's binary_logloss: 0.0614578\n",
      "[8436]\ttraining's binary_logloss: 0.061452\n",
      "[8437]\ttraining's binary_logloss: 0.061447\n",
      "[8438]\ttraining's binary_logloss: 0.0614432\n",
      "[8439]\ttraining's binary_logloss: 0.0614359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8440]\ttraining's binary_logloss: 0.0614304\n",
      "[8441]\ttraining's binary_logloss: 0.0614243\n",
      "[8442]\ttraining's binary_logloss: 0.0614177\n",
      "[8443]\ttraining's binary_logloss: 0.0614118\n",
      "[8444]\ttraining's binary_logloss: 0.061405\n",
      "[8445]\ttraining's binary_logloss: 0.0613986\n",
      "[8446]\ttraining's binary_logloss: 0.061395\n",
      "[8447]\ttraining's binary_logloss: 0.0613915\n",
      "[8448]\ttraining's binary_logloss: 0.0613886\n",
      "[8449]\ttraining's binary_logloss: 0.0613823\n",
      "[8450]\ttraining's binary_logloss: 0.061375\n",
      "[8451]\ttraining's binary_logloss: 0.0613687\n",
      "[8452]\ttraining's binary_logloss: 0.0613626\n",
      "[8453]\ttraining's binary_logloss: 0.0613552\n",
      "[8454]\ttraining's binary_logloss: 0.0613488\n",
      "[8455]\ttraining's binary_logloss: 0.0613438\n",
      "[8456]\ttraining's binary_logloss: 0.0613374\n",
      "[8457]\ttraining's binary_logloss: 0.0613321\n",
      "[8458]\ttraining's binary_logloss: 0.061326\n",
      "[8459]\ttraining's binary_logloss: 0.0613196\n",
      "[8460]\ttraining's binary_logloss: 0.0613145\n",
      "[8461]\ttraining's binary_logloss: 0.0613091\n",
      "[8462]\ttraining's binary_logloss: 0.0613033\n",
      "[8463]\ttraining's binary_logloss: 0.0612982\n",
      "[8464]\ttraining's binary_logloss: 0.0612951\n",
      "[8465]\ttraining's binary_logloss: 0.0612877\n",
      "[8466]\ttraining's binary_logloss: 0.0612803\n",
      "[8467]\ttraining's binary_logloss: 0.0612742\n",
      "[8468]\ttraining's binary_logloss: 0.0612698\n",
      "[8469]\ttraining's binary_logloss: 0.0612646\n",
      "[8470]\ttraining's binary_logloss: 0.0612609\n",
      "[8471]\ttraining's binary_logloss: 0.0612548\n",
      "[8472]\ttraining's binary_logloss: 0.0612491\n",
      "[8473]\ttraining's binary_logloss: 0.0612434\n",
      "[8474]\ttraining's binary_logloss: 0.061239\n",
      "[8475]\ttraining's binary_logloss: 0.061236\n",
      "[8476]\ttraining's binary_logloss: 0.0612298\n",
      "[8477]\ttraining's binary_logloss: 0.0612256\n",
      "[8478]\ttraining's binary_logloss: 0.0612204\n",
      "[8479]\ttraining's binary_logloss: 0.0612141\n",
      "[8480]\ttraining's binary_logloss: 0.061208\n",
      "[8481]\ttraining's binary_logloss: 0.0612018\n",
      "[8482]\ttraining's binary_logloss: 0.0611957\n",
      "[8483]\ttraining's binary_logloss: 0.0611903\n",
      "[8484]\ttraining's binary_logloss: 0.0611844\n",
      "[8485]\ttraining's binary_logloss: 0.0611774\n",
      "[8486]\ttraining's binary_logloss: 0.061171\n",
      "[8487]\ttraining's binary_logloss: 0.0611646\n",
      "[8488]\ttraining's binary_logloss: 0.0611579\n",
      "[8489]\ttraining's binary_logloss: 0.0611516\n",
      "[8490]\ttraining's binary_logloss: 0.0611452\n",
      "[8491]\ttraining's binary_logloss: 0.0611389\n",
      "[8492]\ttraining's binary_logloss: 0.061132\n",
      "[8493]\ttraining's binary_logloss: 0.061128\n",
      "[8494]\ttraining's binary_logloss: 0.0611215\n",
      "[8495]\ttraining's binary_logloss: 0.0611154\n",
      "[8496]\ttraining's binary_logloss: 0.0611095\n",
      "[8497]\ttraining's binary_logloss: 0.0611028\n",
      "[8498]\ttraining's binary_logloss: 0.0610969\n",
      "[8499]\ttraining's binary_logloss: 0.0610893\n",
      "[8500]\ttraining's binary_logloss: 0.0610828\n",
      "[8501]\ttraining's binary_logloss: 0.0610772\n",
      "[8502]\ttraining's binary_logloss: 0.0610765\n",
      "[8503]\ttraining's binary_logloss: 0.0610703\n",
      "[8504]\ttraining's binary_logloss: 0.0610634\n",
      "[8505]\ttraining's binary_logloss: 0.0610568\n",
      "[8506]\ttraining's binary_logloss: 0.06105\n",
      "[8507]\ttraining's binary_logloss: 0.061044\n",
      "[8508]\ttraining's binary_logloss: 0.0610407\n",
      "[8509]\ttraining's binary_logloss: 0.0610344\n",
      "[8510]\ttraining's binary_logloss: 0.0610284\n",
      "[8511]\ttraining's binary_logloss: 0.0610252\n",
      "[8512]\ttraining's binary_logloss: 0.0610189\n",
      "[8513]\ttraining's binary_logloss: 0.0610126\n",
      "[8514]\ttraining's binary_logloss: 0.0610059\n",
      "[8515]\ttraining's binary_logloss: 0.0610001\n",
      "[8516]\ttraining's binary_logloss: 0.0609939\n",
      "[8517]\ttraining's binary_logloss: 0.0609866\n",
      "[8518]\ttraining's binary_logloss: 0.0609802\n",
      "[8519]\ttraining's binary_logloss: 0.0609731\n",
      "[8520]\ttraining's binary_logloss: 0.0609672\n",
      "[8521]\ttraining's binary_logloss: 0.0609667\n",
      "[8522]\ttraining's binary_logloss: 0.0609607\n",
      "[8523]\ttraining's binary_logloss: 0.0609542\n",
      "[8524]\ttraining's binary_logloss: 0.0609481\n",
      "[8525]\ttraining's binary_logloss: 0.0609433\n",
      "[8526]\ttraining's binary_logloss: 0.0609372\n",
      "[8527]\ttraining's binary_logloss: 0.0609314\n",
      "[8528]\ttraining's binary_logloss: 0.0609243\n",
      "[8529]\ttraining's binary_logloss: 0.0609183\n",
      "[8530]\ttraining's binary_logloss: 0.0609116\n",
      "[8531]\ttraining's binary_logloss: 0.0609046\n",
      "[8532]\ttraining's binary_logloss: 0.0608978\n",
      "[8533]\ttraining's binary_logloss: 0.0608917\n",
      "[8534]\ttraining's binary_logloss: 0.0608862\n",
      "[8535]\ttraining's binary_logloss: 0.0608791\n",
      "[8536]\ttraining's binary_logloss: 0.0608722\n",
      "[8537]\ttraining's binary_logloss: 0.0608692\n",
      "[8538]\ttraining's binary_logloss: 0.0608623\n",
      "[8539]\ttraining's binary_logloss: 0.0608588\n",
      "[8540]\ttraining's binary_logloss: 0.0608526\n",
      "[8541]\ttraining's binary_logloss: 0.0608456\n",
      "[8542]\ttraining's binary_logloss: 0.0608443\n",
      "[8543]\ttraining's binary_logloss: 0.0608384\n",
      "[8544]\ttraining's binary_logloss: 0.060832\n",
      "[8545]\ttraining's binary_logloss: 0.0608265\n",
      "[8546]\ttraining's binary_logloss: 0.0608251\n",
      "[8547]\ttraining's binary_logloss: 0.0608212\n",
      "[8548]\ttraining's binary_logloss: 0.0608151\n",
      "[8549]\ttraining's binary_logloss: 0.0608108\n",
      "[8550]\ttraining's binary_logloss: 0.060805\n",
      "[8551]\ttraining's binary_logloss: 0.0607986\n",
      "[8552]\ttraining's binary_logloss: 0.0607937\n",
      "[8553]\ttraining's binary_logloss: 0.0607875\n",
      "[8554]\ttraining's binary_logloss: 0.0607813\n",
      "[8555]\ttraining's binary_logloss: 0.0607765\n",
      "[8556]\ttraining's binary_logloss: 0.0607697\n",
      "[8557]\ttraining's binary_logloss: 0.0607631\n",
      "[8558]\ttraining's binary_logloss: 0.0607569\n",
      "[8559]\ttraining's binary_logloss: 0.0607497\n",
      "[8560]\ttraining's binary_logloss: 0.0607472\n",
      "[8561]\ttraining's binary_logloss: 0.0607424\n",
      "[8562]\ttraining's binary_logloss: 0.0607363\n",
      "[8563]\ttraining's binary_logloss: 0.0607304\n",
      "[8564]\ttraining's binary_logloss: 0.0607226\n",
      "[8565]\ttraining's binary_logloss: 0.060717\n",
      "[8566]\ttraining's binary_logloss: 0.0607112\n",
      "[8567]\ttraining's binary_logloss: 0.0607049\n",
      "[8568]\ttraining's binary_logloss: 0.0606998\n",
      "[8569]\ttraining's binary_logloss: 0.0606943\n",
      "[8570]\ttraining's binary_logloss: 0.0606877\n",
      "[8571]\ttraining's binary_logloss: 0.0606809\n",
      "[8572]\ttraining's binary_logloss: 0.0606747\n",
      "[8573]\ttraining's binary_logloss: 0.060668\n",
      "[8574]\ttraining's binary_logloss: 0.060663\n",
      "[8575]\ttraining's binary_logloss: 0.060656\n",
      "[8576]\ttraining's binary_logloss: 0.0606492\n",
      "[8577]\ttraining's binary_logloss: 0.0606423\n",
      "[8578]\ttraining's binary_logloss: 0.0606363\n",
      "[8579]\ttraining's binary_logloss: 0.0606308\n",
      "[8580]\ttraining's binary_logloss: 0.0606245\n",
      "[8581]\ttraining's binary_logloss: 0.0606176\n",
      "[8582]\ttraining's binary_logloss: 0.0606124\n",
      "[8583]\ttraining's binary_logloss: 0.060606\n",
      "[8584]\ttraining's binary_logloss: 0.0605998\n",
      "[8585]\ttraining's binary_logloss: 0.0605946\n",
      "[8586]\ttraining's binary_logloss: 0.0605877\n",
      "[8587]\ttraining's binary_logloss: 0.0605819\n",
      "[8588]\ttraining's binary_logloss: 0.0605754\n",
      "[8589]\ttraining's binary_logloss: 0.0605693\n",
      "[8590]\ttraining's binary_logloss: 0.0605631\n",
      "[8591]\ttraining's binary_logloss: 0.0605563\n",
      "[8592]\ttraining's binary_logloss: 0.0605503\n",
      "[8593]\ttraining's binary_logloss: 0.0605427\n",
      "[8594]\ttraining's binary_logloss: 0.0605367\n",
      "[8595]\ttraining's binary_logloss: 0.060532\n",
      "[8596]\ttraining's binary_logloss: 0.0605288\n",
      "[8597]\ttraining's binary_logloss: 0.0605231\n",
      "[8598]\ttraining's binary_logloss: 0.0605179\n",
      "[8599]\ttraining's binary_logloss: 0.0605119\n",
      "[8600]\ttraining's binary_logloss: 0.0605053\n",
      "[8601]\ttraining's binary_logloss: 0.0604995\n",
      "[8602]\ttraining's binary_logloss: 0.0604949\n",
      "[8603]\ttraining's binary_logloss: 0.060488\n",
      "[8604]\ttraining's binary_logloss: 0.0604808\n",
      "[8605]\ttraining's binary_logloss: 0.060474\n",
      "[8606]\ttraining's binary_logloss: 0.0604675\n",
      "[8607]\ttraining's binary_logloss: 0.0604608\n",
      "[8608]\ttraining's binary_logloss: 0.0604548\n",
      "[8609]\ttraining's binary_logloss: 0.0604485\n",
      "[8610]\ttraining's binary_logloss: 0.0604429\n",
      "[8611]\ttraining's binary_logloss: 0.0604372\n",
      "[8612]\ttraining's binary_logloss: 0.060431\n",
      "[8613]\ttraining's binary_logloss: 0.0604248\n",
      "[8614]\ttraining's binary_logloss: 0.0604183\n",
      "[8615]\ttraining's binary_logloss: 0.0604113\n",
      "[8616]\ttraining's binary_logloss: 0.0604066\n",
      "[8617]\ttraining's binary_logloss: 0.0604008\n",
      "[8618]\ttraining's binary_logloss: 0.0603934\n",
      "[8619]\ttraining's binary_logloss: 0.0603872\n",
      "[8620]\ttraining's binary_logloss: 0.0603797\n",
      "[8621]\ttraining's binary_logloss: 0.0603734\n",
      "[8622]\ttraining's binary_logloss: 0.0603672\n",
      "[8623]\ttraining's binary_logloss: 0.0603609\n",
      "[8624]\ttraining's binary_logloss: 0.0603551\n",
      "[8625]\ttraining's binary_logloss: 0.0603481\n",
      "[8626]\ttraining's binary_logloss: 0.0603422\n",
      "[8627]\ttraining's binary_logloss: 0.0603376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8628]\ttraining's binary_logloss: 0.0603317\n",
      "[8629]\ttraining's binary_logloss: 0.0603258\n",
      "[8630]\ttraining's binary_logloss: 0.0603206\n",
      "[8631]\ttraining's binary_logloss: 0.0603146\n",
      "[8632]\ttraining's binary_logloss: 0.060309\n",
      "[8633]\ttraining's binary_logloss: 0.0603034\n",
      "[8634]\ttraining's binary_logloss: 0.0602991\n",
      "[8635]\ttraining's binary_logloss: 0.0602927\n",
      "[8636]\ttraining's binary_logloss: 0.0602867\n",
      "[8637]\ttraining's binary_logloss: 0.0602812\n",
      "[8638]\ttraining's binary_logloss: 0.0602762\n",
      "[8639]\ttraining's binary_logloss: 0.0602703\n",
      "[8640]\ttraining's binary_logloss: 0.0602655\n",
      "[8641]\ttraining's binary_logloss: 0.0602596\n",
      "[8642]\ttraining's binary_logloss: 0.0602532\n",
      "[8643]\ttraining's binary_logloss: 0.0602495\n",
      "[8644]\ttraining's binary_logloss: 0.0602443\n",
      "[8645]\ttraining's binary_logloss: 0.0602422\n",
      "[8646]\ttraining's binary_logloss: 0.0602355\n",
      "[8647]\ttraining's binary_logloss: 0.0602293\n",
      "[8648]\ttraining's binary_logloss: 0.0602228\n",
      "[8649]\ttraining's binary_logloss: 0.0602181\n",
      "[8650]\ttraining's binary_logloss: 0.0602112\n",
      "[8651]\ttraining's binary_logloss: 0.060208\n",
      "[8652]\ttraining's binary_logloss: 0.0602025\n",
      "[8653]\ttraining's binary_logloss: 0.0601973\n",
      "[8654]\ttraining's binary_logloss: 0.0601955\n",
      "[8655]\ttraining's binary_logloss: 0.0601888\n",
      "[8656]\ttraining's binary_logloss: 0.0601818\n",
      "[8657]\ttraining's binary_logloss: 0.0601769\n",
      "[8658]\ttraining's binary_logloss: 0.0601706\n",
      "[8659]\ttraining's binary_logloss: 0.0601647\n",
      "[8660]\ttraining's binary_logloss: 0.0601598\n",
      "[8661]\ttraining's binary_logloss: 0.0601587\n",
      "[8662]\ttraining's binary_logloss: 0.0601535\n",
      "[8663]\ttraining's binary_logloss: 0.0601481\n",
      "[8664]\ttraining's binary_logloss: 0.0601412\n",
      "[8665]\ttraining's binary_logloss: 0.0601354\n",
      "[8666]\ttraining's binary_logloss: 0.0601294\n",
      "[8667]\ttraining's binary_logloss: 0.0601236\n",
      "[8668]\ttraining's binary_logloss: 0.0601224\n",
      "[8669]\ttraining's binary_logloss: 0.0601157\n",
      "[8670]\ttraining's binary_logloss: 0.0601093\n",
      "[8671]\ttraining's binary_logloss: 0.0601041\n",
      "[8672]\ttraining's binary_logloss: 0.060098\n",
      "[8673]\ttraining's binary_logloss: 0.0600916\n",
      "[8674]\ttraining's binary_logloss: 0.060086\n",
      "[8675]\ttraining's binary_logloss: 0.0600823\n",
      "[8676]\ttraining's binary_logloss: 0.0600756\n",
      "[8677]\ttraining's binary_logloss: 0.0600702\n",
      "[8678]\ttraining's binary_logloss: 0.0600641\n",
      "[8679]\ttraining's binary_logloss: 0.0600578\n",
      "[8680]\ttraining's binary_logloss: 0.0600541\n",
      "[8681]\ttraining's binary_logloss: 0.0600493\n",
      "[8682]\ttraining's binary_logloss: 0.0600425\n",
      "[8683]\ttraining's binary_logloss: 0.0600359\n",
      "[8684]\ttraining's binary_logloss: 0.0600304\n",
      "[8685]\ttraining's binary_logloss: 0.0600231\n",
      "[8686]\ttraining's binary_logloss: 0.0600185\n",
      "[8687]\ttraining's binary_logloss: 0.0600124\n",
      "[8688]\ttraining's binary_logloss: 0.0600061\n",
      "[8689]\ttraining's binary_logloss: 0.0600009\n",
      "[8690]\ttraining's binary_logloss: 0.059995\n",
      "[8691]\ttraining's binary_logloss: 0.0599887\n",
      "[8692]\ttraining's binary_logloss: 0.0599824\n",
      "[8693]\ttraining's binary_logloss: 0.0599797\n",
      "[8694]\ttraining's binary_logloss: 0.0599745\n",
      "[8695]\ttraining's binary_logloss: 0.0599686\n",
      "[8696]\ttraining's binary_logloss: 0.059961\n",
      "[8697]\ttraining's binary_logloss: 0.0599544\n",
      "[8698]\ttraining's binary_logloss: 0.0599516\n",
      "[8699]\ttraining's binary_logloss: 0.0599449\n",
      "[8700]\ttraining's binary_logloss: 0.0599379\n",
      "[8701]\ttraining's binary_logloss: 0.0599316\n",
      "[8702]\ttraining's binary_logloss: 0.0599263\n",
      "[8703]\ttraining's binary_logloss: 0.05992\n",
      "[8704]\ttraining's binary_logloss: 0.0599135\n",
      "[8705]\ttraining's binary_logloss: 0.059907\n",
      "[8706]\ttraining's binary_logloss: 0.0599016\n",
      "[8707]\ttraining's binary_logloss: 0.0598965\n",
      "[8708]\ttraining's binary_logloss: 0.0598898\n",
      "[8709]\ttraining's binary_logloss: 0.0598847\n",
      "[8710]\ttraining's binary_logloss: 0.0598792\n",
      "[8711]\ttraining's binary_logloss: 0.0598722\n",
      "[8712]\ttraining's binary_logloss: 0.0598677\n",
      "[8713]\ttraining's binary_logloss: 0.0598632\n",
      "[8714]\ttraining's binary_logloss: 0.0598571\n",
      "[8715]\ttraining's binary_logloss: 0.0598507\n",
      "[8716]\ttraining's binary_logloss: 0.0598441\n",
      "[8717]\ttraining's binary_logloss: 0.0598373\n",
      "[8718]\ttraining's binary_logloss: 0.0598302\n",
      "[8719]\ttraining's binary_logloss: 0.0598234\n",
      "[8720]\ttraining's binary_logloss: 0.0598188\n",
      "[8721]\ttraining's binary_logloss: 0.0598128\n",
      "[8722]\ttraining's binary_logloss: 0.0598067\n",
      "[8723]\ttraining's binary_logloss: 0.0597997\n",
      "[8724]\ttraining's binary_logloss: 0.0597929\n",
      "[8725]\ttraining's binary_logloss: 0.0597866\n",
      "[8726]\ttraining's binary_logloss: 0.0597821\n",
      "[8727]\ttraining's binary_logloss: 0.0597784\n",
      "[8728]\ttraining's binary_logloss: 0.0597729\n",
      "[8729]\ttraining's binary_logloss: 0.0597662\n",
      "[8730]\ttraining's binary_logloss: 0.059758\n",
      "[8731]\ttraining's binary_logloss: 0.0597533\n",
      "[8732]\ttraining's binary_logloss: 0.059751\n",
      "[8733]\ttraining's binary_logloss: 0.0597449\n",
      "[8734]\ttraining's binary_logloss: 0.0597389\n",
      "[8735]\ttraining's binary_logloss: 0.0597328\n",
      "[8736]\ttraining's binary_logloss: 0.0597276\n",
      "[8737]\ttraining's binary_logloss: 0.059722\n",
      "[8738]\ttraining's binary_logloss: 0.0597168\n",
      "[8739]\ttraining's binary_logloss: 0.0597116\n",
      "[8740]\ttraining's binary_logloss: 0.0597058\n",
      "[8741]\ttraining's binary_logloss: 0.0596992\n",
      "[8742]\ttraining's binary_logloss: 0.0596949\n",
      "[8743]\ttraining's binary_logloss: 0.0596935\n",
      "[8744]\ttraining's binary_logloss: 0.0596867\n",
      "[8745]\ttraining's binary_logloss: 0.0596812\n",
      "[8746]\ttraining's binary_logloss: 0.05968\n",
      "[8747]\ttraining's binary_logloss: 0.0596741\n",
      "[8748]\ttraining's binary_logloss: 0.0596675\n",
      "[8749]\ttraining's binary_logloss: 0.0596609\n",
      "[8750]\ttraining's binary_logloss: 0.0596544\n",
      "[8751]\ttraining's binary_logloss: 0.059649\n",
      "[8752]\ttraining's binary_logloss: 0.0596474\n",
      "[8753]\ttraining's binary_logloss: 0.0596411\n",
      "[8754]\ttraining's binary_logloss: 0.0596367\n",
      "[8755]\ttraining's binary_logloss: 0.0596307\n",
      "[8756]\ttraining's binary_logloss: 0.059625\n",
      "[8757]\ttraining's binary_logloss: 0.0596209\n",
      "[8758]\ttraining's binary_logloss: 0.0596173\n",
      "[8759]\ttraining's binary_logloss: 0.0596101\n",
      "[8760]\ttraining's binary_logloss: 0.0596043\n",
      "[8761]\ttraining's binary_logloss: 0.0595977\n",
      "[8762]\ttraining's binary_logloss: 0.059591\n",
      "[8763]\ttraining's binary_logloss: 0.0595855\n",
      "[8764]\ttraining's binary_logloss: 0.0595794\n",
      "[8765]\ttraining's binary_logloss: 0.0595724\n",
      "[8766]\ttraining's binary_logloss: 0.059567\n",
      "[8767]\ttraining's binary_logloss: 0.0595641\n",
      "[8768]\ttraining's binary_logloss: 0.0595576\n",
      "[8769]\ttraining's binary_logloss: 0.0595533\n",
      "[8770]\ttraining's binary_logloss: 0.059551\n",
      "[8771]\ttraining's binary_logloss: 0.0595467\n",
      "[8772]\ttraining's binary_logloss: 0.0595408\n",
      "[8773]\ttraining's binary_logloss: 0.0595352\n",
      "[8774]\ttraining's binary_logloss: 0.0595286\n",
      "[8775]\ttraining's binary_logloss: 0.0595232\n",
      "[8776]\ttraining's binary_logloss: 0.0595166\n",
      "[8777]\ttraining's binary_logloss: 0.059515\n",
      "[8778]\ttraining's binary_logloss: 0.0595094\n",
      "[8779]\ttraining's binary_logloss: 0.0595045\n",
      "[8780]\ttraining's binary_logloss: 0.0595\n",
      "[8781]\ttraining's binary_logloss: 0.0594936\n",
      "[8782]\ttraining's binary_logloss: 0.0594872\n",
      "[8783]\ttraining's binary_logloss: 0.0594846\n",
      "[8784]\ttraining's binary_logloss: 0.0594782\n",
      "[8785]\ttraining's binary_logloss: 0.05947\n",
      "[8786]\ttraining's binary_logloss: 0.0594679\n",
      "[8787]\ttraining's binary_logloss: 0.0594664\n",
      "[8788]\ttraining's binary_logloss: 0.0594617\n",
      "[8789]\ttraining's binary_logloss: 0.0594572\n",
      "[8790]\ttraining's binary_logloss: 0.0594513\n",
      "[8791]\ttraining's binary_logloss: 0.059445\n",
      "[8792]\ttraining's binary_logloss: 0.0594388\n",
      "[8793]\ttraining's binary_logloss: 0.0594341\n",
      "[8794]\ttraining's binary_logloss: 0.0594275\n",
      "[8795]\ttraining's binary_logloss: 0.0594223\n",
      "[8796]\ttraining's binary_logloss: 0.0594152\n",
      "[8797]\ttraining's binary_logloss: 0.0594091\n",
      "[8798]\ttraining's binary_logloss: 0.0594038\n",
      "[8799]\ttraining's binary_logloss: 0.0593972\n",
      "[8800]\ttraining's binary_logloss: 0.0593914\n",
      "[8801]\ttraining's binary_logloss: 0.0593856\n",
      "[8802]\ttraining's binary_logloss: 0.0593817\n",
      "[8803]\ttraining's binary_logloss: 0.0593761\n",
      "[8804]\ttraining's binary_logloss: 0.05937\n",
      "[8805]\ttraining's binary_logloss: 0.0593663\n",
      "[8806]\ttraining's binary_logloss: 0.0593614\n",
      "[8807]\ttraining's binary_logloss: 0.059356\n",
      "[8808]\ttraining's binary_logloss: 0.0593495\n",
      "[8809]\ttraining's binary_logloss: 0.0593439\n",
      "[8810]\ttraining's binary_logloss: 0.0593383\n",
      "[8811]\ttraining's binary_logloss: 0.0593323\n",
      "[8812]\ttraining's binary_logloss: 0.0593261\n",
      "[8813]\ttraining's binary_logloss: 0.0593192\n",
      "[8814]\ttraining's binary_logloss: 0.0593137\n",
      "[8815]\ttraining's binary_logloss: 0.0593094\n",
      "[8816]\ttraining's binary_logloss: 0.0593029\n",
      "[8817]\ttraining's binary_logloss: 0.0592973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8818]\ttraining's binary_logloss: 0.0592925\n",
      "[8819]\ttraining's binary_logloss: 0.0592885\n",
      "[8820]\ttraining's binary_logloss: 0.0592835\n",
      "[8821]\ttraining's binary_logloss: 0.0592767\n",
      "[8822]\ttraining's binary_logloss: 0.0592709\n",
      "[8823]\ttraining's binary_logloss: 0.059265\n",
      "[8824]\ttraining's binary_logloss: 0.0592585\n",
      "[8825]\ttraining's binary_logloss: 0.0592528\n",
      "[8826]\ttraining's binary_logloss: 0.0592477\n",
      "[8827]\ttraining's binary_logloss: 0.059242\n",
      "[8828]\ttraining's binary_logloss: 0.0592366\n",
      "[8829]\ttraining's binary_logloss: 0.0592313\n",
      "[8830]\ttraining's binary_logloss: 0.0592248\n",
      "[8831]\ttraining's binary_logloss: 0.0592199\n",
      "[8832]\ttraining's binary_logloss: 0.0592134\n",
      "[8833]\ttraining's binary_logloss: 0.0592077\n",
      "[8834]\ttraining's binary_logloss: 0.0592051\n",
      "[8835]\ttraining's binary_logloss: 0.0591991\n",
      "[8836]\ttraining's binary_logloss: 0.0591927\n",
      "[8837]\ttraining's binary_logloss: 0.0591878\n",
      "[8838]\ttraining's binary_logloss: 0.0591827\n",
      "[8839]\ttraining's binary_logloss: 0.0591764\n",
      "[8840]\ttraining's binary_logloss: 0.0591691\n",
      "[8841]\ttraining's binary_logloss: 0.059163\n",
      "[8842]\ttraining's binary_logloss: 0.0591572\n",
      "[8843]\ttraining's binary_logloss: 0.0591524\n",
      "[8844]\ttraining's binary_logloss: 0.0591472\n",
      "[8845]\ttraining's binary_logloss: 0.059141\n",
      "[8846]\ttraining's binary_logloss: 0.0591339\n",
      "[8847]\ttraining's binary_logloss: 0.0591277\n",
      "[8848]\ttraining's binary_logloss: 0.0591247\n",
      "[8849]\ttraining's binary_logloss: 0.0591183\n",
      "[8850]\ttraining's binary_logloss: 0.0591141\n",
      "[8851]\ttraining's binary_logloss: 0.0591082\n",
      "[8852]\ttraining's binary_logloss: 0.0591017\n",
      "[8853]\ttraining's binary_logloss: 0.0590964\n",
      "[8854]\ttraining's binary_logloss: 0.0590906\n",
      "[8855]\ttraining's binary_logloss: 0.0590842\n",
      "[8856]\ttraining's binary_logloss: 0.0590774\n",
      "[8857]\ttraining's binary_logloss: 0.0590721\n",
      "[8858]\ttraining's binary_logloss: 0.059068\n",
      "[8859]\ttraining's binary_logloss: 0.0590614\n",
      "[8860]\ttraining's binary_logloss: 0.0590545\n",
      "[8861]\ttraining's binary_logloss: 0.0590489\n",
      "[8862]\ttraining's binary_logloss: 0.059042\n",
      "[8863]\ttraining's binary_logloss: 0.0590378\n",
      "[8864]\ttraining's binary_logloss: 0.0590321\n",
      "[8865]\ttraining's binary_logloss: 0.0590253\n",
      "[8866]\ttraining's binary_logloss: 0.0590193\n",
      "[8867]\ttraining's binary_logloss: 0.0590138\n",
      "[8868]\ttraining's binary_logloss: 0.0590078\n",
      "[8869]\ttraining's binary_logloss: 0.0590021\n",
      "[8870]\ttraining's binary_logloss: 0.0589959\n",
      "[8871]\ttraining's binary_logloss: 0.0589901\n",
      "[8872]\ttraining's binary_logloss: 0.0589841\n",
      "[8873]\ttraining's binary_logloss: 0.058978\n",
      "[8874]\ttraining's binary_logloss: 0.0589735\n",
      "[8875]\ttraining's binary_logloss: 0.0589674\n",
      "[8876]\ttraining's binary_logloss: 0.0589612\n",
      "[8877]\ttraining's binary_logloss: 0.058956\n",
      "[8878]\ttraining's binary_logloss: 0.05895\n",
      "[8879]\ttraining's binary_logloss: 0.0589439\n",
      "[8880]\ttraining's binary_logloss: 0.0589389\n",
      "[8881]\ttraining's binary_logloss: 0.0589325\n",
      "[8882]\ttraining's binary_logloss: 0.0589266\n",
      "[8883]\ttraining's binary_logloss: 0.0589201\n",
      "[8884]\ttraining's binary_logloss: 0.0589142\n",
      "[8885]\ttraining's binary_logloss: 0.0589086\n",
      "[8886]\ttraining's binary_logloss: 0.0589022\n",
      "[8887]\ttraining's binary_logloss: 0.0588991\n",
      "[8888]\ttraining's binary_logloss: 0.0588933\n",
      "[8889]\ttraining's binary_logloss: 0.058888\n",
      "[8890]\ttraining's binary_logloss: 0.0588824\n",
      "[8891]\ttraining's binary_logloss: 0.0588796\n",
      "[8892]\ttraining's binary_logloss: 0.0588756\n",
      "[8893]\ttraining's binary_logloss: 0.0588699\n",
      "[8894]\ttraining's binary_logloss: 0.0588647\n",
      "[8895]\ttraining's binary_logloss: 0.0588633\n",
      "[8896]\ttraining's binary_logloss: 0.0588579\n",
      "[8897]\ttraining's binary_logloss: 0.0588518\n",
      "[8898]\ttraining's binary_logloss: 0.058849\n",
      "[8899]\ttraining's binary_logloss: 0.0588432\n",
      "[8900]\ttraining's binary_logloss: 0.0588371\n",
      "[8901]\ttraining's binary_logloss: 0.0588348\n",
      "[8902]\ttraining's binary_logloss: 0.0588286\n",
      "[8903]\ttraining's binary_logloss: 0.0588238\n",
      "[8904]\ttraining's binary_logloss: 0.0588168\n",
      "[8905]\ttraining's binary_logloss: 0.058811\n",
      "[8906]\ttraining's binary_logloss: 0.0588053\n",
      "[8907]\ttraining's binary_logloss: 0.0588029\n",
      "[8908]\ttraining's binary_logloss: 0.0587986\n",
      "[8909]\ttraining's binary_logloss: 0.0587927\n",
      "[8910]\ttraining's binary_logloss: 0.0587914\n",
      "[8911]\ttraining's binary_logloss: 0.0587849\n",
      "[8912]\ttraining's binary_logloss: 0.0587808\n",
      "[8913]\ttraining's binary_logloss: 0.0587794\n",
      "[8914]\ttraining's binary_logloss: 0.0587764\n",
      "[8915]\ttraining's binary_logloss: 0.0587707\n",
      "[8916]\ttraining's binary_logloss: 0.0587645\n",
      "[8917]\ttraining's binary_logloss: 0.058761\n",
      "[8918]\ttraining's binary_logloss: 0.0587565\n",
      "[8919]\ttraining's binary_logloss: 0.0587518\n",
      "[8920]\ttraining's binary_logloss: 0.0587482\n",
      "[8921]\ttraining's binary_logloss: 0.058747\n",
      "[8922]\ttraining's binary_logloss: 0.0587403\n",
      "[8923]\ttraining's binary_logloss: 0.0587339\n",
      "[8924]\ttraining's binary_logloss: 0.0587287\n",
      "[8925]\ttraining's binary_logloss: 0.0587233\n",
      "[8926]\ttraining's binary_logloss: 0.0587196\n",
      "[8927]\ttraining's binary_logloss: 0.0587149\n",
      "[8928]\ttraining's binary_logloss: 0.0587085\n",
      "[8929]\ttraining's binary_logloss: 0.0587033\n",
      "[8930]\ttraining's binary_logloss: 0.0586978\n",
      "[8931]\ttraining's binary_logloss: 0.0586923\n",
      "[8932]\ttraining's binary_logloss: 0.0586861\n",
      "[8933]\ttraining's binary_logloss: 0.0586824\n",
      "[8934]\ttraining's binary_logloss: 0.0586757\n",
      "[8935]\ttraining's binary_logloss: 0.0586691\n",
      "[8936]\ttraining's binary_logloss: 0.0586645\n",
      "[8937]\ttraining's binary_logloss: 0.0586604\n",
      "[8938]\ttraining's binary_logloss: 0.0586538\n",
      "[8939]\ttraining's binary_logloss: 0.0586475\n",
      "[8940]\ttraining's binary_logloss: 0.0586405\n",
      "[8941]\ttraining's binary_logloss: 0.0586362\n",
      "[8942]\ttraining's binary_logloss: 0.0586302\n",
      "[8943]\ttraining's binary_logloss: 0.0586248\n",
      "[8944]\ttraining's binary_logloss: 0.0586193\n",
      "[8945]\ttraining's binary_logloss: 0.0586134\n",
      "[8946]\ttraining's binary_logloss: 0.058608\n",
      "[8947]\ttraining's binary_logloss: 0.0586018\n",
      "[8948]\ttraining's binary_logloss: 0.0585959\n",
      "[8949]\ttraining's binary_logloss: 0.0585897\n",
      "[8950]\ttraining's binary_logloss: 0.0585864\n",
      "[8951]\ttraining's binary_logloss: 0.058582\n",
      "[8952]\ttraining's binary_logloss: 0.0585789\n",
      "[8953]\ttraining's binary_logloss: 0.0585734\n",
      "[8954]\ttraining's binary_logloss: 0.0585672\n",
      "[8955]\ttraining's binary_logloss: 0.0585626\n",
      "[8956]\ttraining's binary_logloss: 0.0585571\n",
      "[8957]\ttraining's binary_logloss: 0.0585523\n",
      "[8958]\ttraining's binary_logloss: 0.0585468\n",
      "[8959]\ttraining's binary_logloss: 0.058542\n",
      "[8960]\ttraining's binary_logloss: 0.0585378\n",
      "[8961]\ttraining's binary_logloss: 0.0585319\n",
      "[8962]\ttraining's binary_logloss: 0.0585263\n",
      "[8963]\ttraining's binary_logloss: 0.0585204\n",
      "[8964]\ttraining's binary_logloss: 0.0585173\n",
      "[8965]\ttraining's binary_logloss: 0.0585118\n",
      "[8966]\ttraining's binary_logloss: 0.0585083\n",
      "[8967]\ttraining's binary_logloss: 0.0585021\n",
      "[8968]\ttraining's binary_logloss: 0.0584987\n",
      "[8969]\ttraining's binary_logloss: 0.058493\n",
      "[8970]\ttraining's binary_logloss: 0.0584871\n",
      "[8971]\ttraining's binary_logloss: 0.0584827\n",
      "[8972]\ttraining's binary_logloss: 0.0584811\n",
      "[8973]\ttraining's binary_logloss: 0.0584752\n",
      "[8974]\ttraining's binary_logloss: 0.0584693\n",
      "[8975]\ttraining's binary_logloss: 0.058463\n",
      "[8976]\ttraining's binary_logloss: 0.0584566\n",
      "[8977]\ttraining's binary_logloss: 0.058454\n",
      "[8978]\ttraining's binary_logloss: 0.0584485\n",
      "[8979]\ttraining's binary_logloss: 0.0584432\n",
      "[8980]\ttraining's binary_logloss: 0.0584376\n",
      "[8981]\ttraining's binary_logloss: 0.0584312\n",
      "[8982]\ttraining's binary_logloss: 0.0584249\n",
      "[8983]\ttraining's binary_logloss: 0.0584197\n",
      "[8984]\ttraining's binary_logloss: 0.0584146\n",
      "[8985]\ttraining's binary_logloss: 0.0584082\n",
      "[8986]\ttraining's binary_logloss: 0.0584033\n",
      "[8987]\ttraining's binary_logloss: 0.0583989\n",
      "[8988]\ttraining's binary_logloss: 0.0583929\n",
      "[8989]\ttraining's binary_logloss: 0.0583871\n",
      "[8990]\ttraining's binary_logloss: 0.058382\n",
      "[8991]\ttraining's binary_logloss: 0.0583762\n",
      "[8992]\ttraining's binary_logloss: 0.058372\n",
      "[8993]\ttraining's binary_logloss: 0.0583664\n",
      "[8994]\ttraining's binary_logloss: 0.0583603\n",
      "[8995]\ttraining's binary_logloss: 0.0583549\n",
      "[8996]\ttraining's binary_logloss: 0.0583482\n",
      "[8997]\ttraining's binary_logloss: 0.0583422\n",
      "[8998]\ttraining's binary_logloss: 0.0583349\n",
      "[8999]\ttraining's binary_logloss: 0.0583294\n",
      "[9000]\ttraining's binary_logloss: 0.0583232\n",
      "[9001]\ttraining's binary_logloss: 0.0583171\n",
      "[9002]\ttraining's binary_logloss: 0.0583108\n",
      "[9003]\ttraining's binary_logloss: 0.0583045\n",
      "[9004]\ttraining's binary_logloss: 0.0582975\n",
      "[9005]\ttraining's binary_logloss: 0.0582916\n",
      "[9006]\ttraining's binary_logloss: 0.0582868\n",
      "[9007]\ttraining's binary_logloss: 0.0582806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9008]\ttraining's binary_logloss: 0.0582746\n",
      "[9009]\ttraining's binary_logloss: 0.0582679\n",
      "[9010]\ttraining's binary_logloss: 0.0582617\n",
      "[9011]\ttraining's binary_logloss: 0.0582557\n",
      "[9012]\ttraining's binary_logloss: 0.05825\n",
      "[9013]\ttraining's binary_logloss: 0.0582432\n",
      "[9014]\ttraining's binary_logloss: 0.0582395\n",
      "[9015]\ttraining's binary_logloss: 0.0582339\n",
      "[9016]\ttraining's binary_logloss: 0.0582282\n",
      "[9017]\ttraining's binary_logloss: 0.0582219\n",
      "[9018]\ttraining's binary_logloss: 0.0582161\n",
      "[9019]\ttraining's binary_logloss: 0.0582092\n",
      "[9020]\ttraining's binary_logloss: 0.0582041\n",
      "[9021]\ttraining's binary_logloss: 0.0582005\n",
      "[9022]\ttraining's binary_logloss: 0.058196\n",
      "[9023]\ttraining's binary_logloss: 0.0581904\n",
      "[9024]\ttraining's binary_logloss: 0.0581859\n",
      "[9025]\ttraining's binary_logloss: 0.0581796\n",
      "[9026]\ttraining's binary_logloss: 0.0581743\n",
      "[9027]\ttraining's binary_logloss: 0.0581716\n",
      "[9028]\ttraining's binary_logloss: 0.0581658\n",
      "[9029]\ttraining's binary_logloss: 0.0581603\n",
      "[9030]\ttraining's binary_logloss: 0.0581543\n",
      "[9031]\ttraining's binary_logloss: 0.0581484\n",
      "[9032]\ttraining's binary_logloss: 0.0581438\n",
      "[9033]\ttraining's binary_logloss: 0.0581375\n",
      "[9034]\ttraining's binary_logloss: 0.0581321\n",
      "[9035]\ttraining's binary_logloss: 0.0581255\n",
      "[9036]\ttraining's binary_logloss: 0.0581196\n",
      "[9037]\ttraining's binary_logloss: 0.0581135\n",
      "[9038]\ttraining's binary_logloss: 0.0581077\n",
      "[9039]\ttraining's binary_logloss: 0.0581027\n",
      "[9040]\ttraining's binary_logloss: 0.0580978\n",
      "[9041]\ttraining's binary_logloss: 0.0580919\n",
      "[9042]\ttraining's binary_logloss: 0.0580865\n",
      "[9043]\ttraining's binary_logloss: 0.0580807\n",
      "[9044]\ttraining's binary_logloss: 0.0580741\n",
      "[9045]\ttraining's binary_logloss: 0.0580681\n",
      "[9046]\ttraining's binary_logloss: 0.0580628\n",
      "[9047]\ttraining's binary_logloss: 0.0580567\n",
      "[9048]\ttraining's binary_logloss: 0.0580514\n",
      "[9049]\ttraining's binary_logloss: 0.0580446\n",
      "[9050]\ttraining's binary_logloss: 0.0580393\n",
      "[9051]\ttraining's binary_logloss: 0.0580332\n",
      "[9052]\ttraining's binary_logloss: 0.0580286\n",
      "[9053]\ttraining's binary_logloss: 0.0580245\n",
      "[9054]\ttraining's binary_logloss: 0.0580175\n",
      "[9055]\ttraining's binary_logloss: 0.0580145\n",
      "[9056]\ttraining's binary_logloss: 0.0580093\n",
      "[9057]\ttraining's binary_logloss: 0.0580033\n",
      "[9058]\ttraining's binary_logloss: 0.0579967\n",
      "[9059]\ttraining's binary_logloss: 0.0579911\n",
      "[9060]\ttraining's binary_logloss: 0.0579851\n",
      "[9061]\ttraining's binary_logloss: 0.0579786\n",
      "[9062]\ttraining's binary_logloss: 0.0579756\n",
      "[9063]\ttraining's binary_logloss: 0.057969\n",
      "[9064]\ttraining's binary_logloss: 0.0579631\n",
      "[9065]\ttraining's binary_logloss: 0.0579572\n",
      "[9066]\ttraining's binary_logloss: 0.0579548\n",
      "[9067]\ttraining's binary_logloss: 0.0579492\n",
      "[9068]\ttraining's binary_logloss: 0.0579433\n",
      "[9069]\ttraining's binary_logloss: 0.0579376\n",
      "[9070]\ttraining's binary_logloss: 0.0579338\n",
      "[9071]\ttraining's binary_logloss: 0.0579278\n",
      "[9072]\ttraining's binary_logloss: 0.0579216\n",
      "[9073]\ttraining's binary_logloss: 0.0579155\n",
      "[9074]\ttraining's binary_logloss: 0.0579096\n",
      "[9075]\ttraining's binary_logloss: 0.0579052\n",
      "[9076]\ttraining's binary_logloss: 0.0578991\n",
      "[9077]\ttraining's binary_logloss: 0.0578938\n",
      "[9078]\ttraining's binary_logloss: 0.0578882\n",
      "[9079]\ttraining's binary_logloss: 0.0578822\n",
      "[9080]\ttraining's binary_logloss: 0.0578774\n",
      "[9081]\ttraining's binary_logloss: 0.0578713\n",
      "[9082]\ttraining's binary_logloss: 0.0578642\n",
      "[9083]\ttraining's binary_logloss: 0.0578582\n",
      "[9084]\ttraining's binary_logloss: 0.0578541\n",
      "[9085]\ttraining's binary_logloss: 0.0578479\n",
      "[9086]\ttraining's binary_logloss: 0.0578413\n",
      "[9087]\ttraining's binary_logloss: 0.0578352\n",
      "[9088]\ttraining's binary_logloss: 0.0578298\n",
      "[9089]\ttraining's binary_logloss: 0.0578247\n",
      "[9090]\ttraining's binary_logloss: 0.0578183\n",
      "[9091]\ttraining's binary_logloss: 0.0578123\n",
      "[9092]\ttraining's binary_logloss: 0.0578067\n",
      "[9093]\ttraining's binary_logloss: 0.0578011\n",
      "[9094]\ttraining's binary_logloss: 0.0577968\n",
      "[9095]\ttraining's binary_logloss: 0.0577912\n",
      "[9096]\ttraining's binary_logloss: 0.0577857\n",
      "[9097]\ttraining's binary_logloss: 0.057782\n",
      "[9098]\ttraining's binary_logloss: 0.0577757\n",
      "[9099]\ttraining's binary_logloss: 0.05777\n",
      "[9100]\ttraining's binary_logloss: 0.0577656\n",
      "[9101]\ttraining's binary_logloss: 0.0577597\n",
      "[9102]\ttraining's binary_logloss: 0.0577574\n",
      "[9103]\ttraining's binary_logloss: 0.0577521\n",
      "[9104]\ttraining's binary_logloss: 0.057751\n",
      "[9105]\ttraining's binary_logloss: 0.0577469\n",
      "[9106]\ttraining's binary_logloss: 0.0577448\n",
      "[9107]\ttraining's binary_logloss: 0.0577391\n",
      "[9108]\ttraining's binary_logloss: 0.057734\n",
      "[9109]\ttraining's binary_logloss: 0.0577286\n",
      "[9110]\ttraining's binary_logloss: 0.0577222\n",
      "[9111]\ttraining's binary_logloss: 0.0577156\n",
      "[9112]\ttraining's binary_logloss: 0.0577097\n",
      "[9113]\ttraining's binary_logloss: 0.0577042\n",
      "[9114]\ttraining's binary_logloss: 0.057699\n",
      "[9115]\ttraining's binary_logloss: 0.0576928\n",
      "[9116]\ttraining's binary_logloss: 0.0576869\n",
      "[9117]\ttraining's binary_logloss: 0.0576796\n",
      "[9118]\ttraining's binary_logloss: 0.0576732\n",
      "[9119]\ttraining's binary_logloss: 0.0576693\n",
      "[9120]\ttraining's binary_logloss: 0.0576634\n",
      "[9121]\ttraining's binary_logloss: 0.0576608\n",
      "[9122]\ttraining's binary_logloss: 0.0576544\n",
      "[9123]\ttraining's binary_logloss: 0.0576488\n",
      "[9124]\ttraining's binary_logloss: 0.0576463\n",
      "[9125]\ttraining's binary_logloss: 0.057641\n",
      "[9126]\ttraining's binary_logloss: 0.0576339\n",
      "[9127]\ttraining's binary_logloss: 0.0576296\n",
      "[9128]\ttraining's binary_logloss: 0.0576275\n",
      "[9129]\ttraining's binary_logloss: 0.0576252\n",
      "[9130]\ttraining's binary_logloss: 0.0576201\n",
      "[9131]\ttraining's binary_logloss: 0.0576137\n",
      "[9132]\ttraining's binary_logloss: 0.0576126\n",
      "[9133]\ttraining's binary_logloss: 0.0576071\n",
      "[9134]\ttraining's binary_logloss: 0.0576002\n",
      "[9135]\ttraining's binary_logloss: 0.0575992\n",
      "[9136]\ttraining's binary_logloss: 0.0575958\n",
      "[9137]\ttraining's binary_logloss: 0.05759\n",
      "[9138]\ttraining's binary_logloss: 0.0575853\n",
      "[9139]\ttraining's binary_logloss: 0.0575791\n",
      "[9140]\ttraining's binary_logloss: 0.0575729\n",
      "[9141]\ttraining's binary_logloss: 0.0575664\n",
      "[9142]\ttraining's binary_logloss: 0.0575621\n",
      "[9143]\ttraining's binary_logloss: 0.0575565\n",
      "[9144]\ttraining's binary_logloss: 0.0575513\n",
      "[9145]\ttraining's binary_logloss: 0.0575455\n",
      "[9146]\ttraining's binary_logloss: 0.0575397\n",
      "[9147]\ttraining's binary_logloss: 0.0575341\n",
      "[9148]\ttraining's binary_logloss: 0.0575274\n",
      "[9149]\ttraining's binary_logloss: 0.0575216\n",
      "[9150]\ttraining's binary_logloss: 0.0575154\n",
      "[9151]\ttraining's binary_logloss: 0.0575097\n",
      "[9152]\ttraining's binary_logloss: 0.057504\n",
      "[9153]\ttraining's binary_logloss: 0.057501\n",
      "[9154]\ttraining's binary_logloss: 0.0574985\n",
      "[9155]\ttraining's binary_logloss: 0.057495\n",
      "[9156]\ttraining's binary_logloss: 0.0574894\n",
      "[9157]\ttraining's binary_logloss: 0.0574837\n",
      "[9158]\ttraining's binary_logloss: 0.0574785\n",
      "[9159]\ttraining's binary_logloss: 0.0574724\n",
      "[9160]\ttraining's binary_logloss: 0.0574668\n",
      "[9161]\ttraining's binary_logloss: 0.0574607\n",
      "[9162]\ttraining's binary_logloss: 0.0574547\n",
      "[9163]\ttraining's binary_logloss: 0.0574495\n",
      "[9164]\ttraining's binary_logloss: 0.0574434\n",
      "[9165]\ttraining's binary_logloss: 0.0574377\n",
      "[9166]\ttraining's binary_logloss: 0.057432\n",
      "[9167]\ttraining's binary_logloss: 0.0574273\n",
      "[9168]\ttraining's binary_logloss: 0.0574224\n",
      "[9169]\ttraining's binary_logloss: 0.057417\n",
      "[9170]\ttraining's binary_logloss: 0.0574111\n",
      "[9171]\ttraining's binary_logloss: 0.0574055\n",
      "[9172]\ttraining's binary_logloss: 0.0574017\n",
      "[9173]\ttraining's binary_logloss: 0.0573961\n",
      "[9174]\ttraining's binary_logloss: 0.0573895\n",
      "[9175]\ttraining's binary_logloss: 0.0573833\n",
      "[9176]\ttraining's binary_logloss: 0.0573782\n",
      "[9177]\ttraining's binary_logloss: 0.0573725\n",
      "[9178]\ttraining's binary_logloss: 0.0573659\n",
      "[9179]\ttraining's binary_logloss: 0.0573592\n",
      "[9180]\ttraining's binary_logloss: 0.0573525\n",
      "[9181]\ttraining's binary_logloss: 0.0573471\n",
      "[9182]\ttraining's binary_logloss: 0.0573434\n",
      "[9183]\ttraining's binary_logloss: 0.0573368\n",
      "[9184]\ttraining's binary_logloss: 0.0573315\n",
      "[9185]\ttraining's binary_logloss: 0.0573264\n",
      "[9186]\ttraining's binary_logloss: 0.0573206\n",
      "[9187]\ttraining's binary_logloss: 0.0573153\n",
      "[9188]\ttraining's binary_logloss: 0.0573121\n",
      "[9189]\ttraining's binary_logloss: 0.0573074\n",
      "[9190]\ttraining's binary_logloss: 0.0573016\n",
      "[9191]\ttraining's binary_logloss: 0.0572953\n",
      "[9192]\ttraining's binary_logloss: 0.0572897\n",
      "[9193]\ttraining's binary_logloss: 0.0572841\n",
      "[9194]\ttraining's binary_logloss: 0.0572779\n",
      "[9195]\ttraining's binary_logloss: 0.0572733\n",
      "[9196]\ttraining's binary_logloss: 0.0572676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9197]\ttraining's binary_logloss: 0.0572609\n",
      "[9198]\ttraining's binary_logloss: 0.0572555\n",
      "[9199]\ttraining's binary_logloss: 0.0572495\n",
      "[9200]\ttraining's binary_logloss: 0.0572441\n",
      "[9201]\ttraining's binary_logloss: 0.0572382\n",
      "[9202]\ttraining's binary_logloss: 0.0572316\n",
      "[9203]\ttraining's binary_logloss: 0.0572251\n",
      "[9204]\ttraining's binary_logloss: 0.0572207\n",
      "[9205]\ttraining's binary_logloss: 0.057217\n",
      "[9206]\ttraining's binary_logloss: 0.0572118\n",
      "[9207]\ttraining's binary_logloss: 0.057207\n",
      "[9208]\ttraining's binary_logloss: 0.0572012\n",
      "[9209]\ttraining's binary_logloss: 0.057197\n",
      "[9210]\ttraining's binary_logloss: 0.0571916\n",
      "[9211]\ttraining's binary_logloss: 0.0571854\n",
      "[9212]\ttraining's binary_logloss: 0.0571786\n",
      "[9213]\ttraining's binary_logloss: 0.0571725\n",
      "[9214]\ttraining's binary_logloss: 0.0571672\n",
      "[9215]\ttraining's binary_logloss: 0.0571616\n",
      "[9216]\ttraining's binary_logloss: 0.0571566\n",
      "[9217]\ttraining's binary_logloss: 0.0571507\n",
      "[9218]\ttraining's binary_logloss: 0.0571453\n",
      "[9219]\ttraining's binary_logloss: 0.057139\n",
      "[9220]\ttraining's binary_logloss: 0.0571339\n",
      "[9221]\ttraining's binary_logloss: 0.057127\n",
      "[9222]\ttraining's binary_logloss: 0.0571212\n",
      "[9223]\ttraining's binary_logloss: 0.0571138\n",
      "[9224]\ttraining's binary_logloss: 0.0571076\n",
      "[9225]\ttraining's binary_logloss: 0.0571016\n",
      "[9226]\ttraining's binary_logloss: 0.0570951\n",
      "[9227]\ttraining's binary_logloss: 0.0570894\n",
      "[9228]\ttraining's binary_logloss: 0.0570837\n",
      "[9229]\ttraining's binary_logloss: 0.0570777\n",
      "[9230]\ttraining's binary_logloss: 0.057072\n",
      "[9231]\ttraining's binary_logloss: 0.0570665\n",
      "[9232]\ttraining's binary_logloss: 0.0570626\n",
      "[9233]\ttraining's binary_logloss: 0.0570616\n",
      "[9234]\ttraining's binary_logloss: 0.0570559\n",
      "[9235]\ttraining's binary_logloss: 0.057053\n",
      "[9236]\ttraining's binary_logloss: 0.0570468\n",
      "[9237]\ttraining's binary_logloss: 0.0570415\n",
      "[9238]\ttraining's binary_logloss: 0.0570389\n",
      "[9239]\ttraining's binary_logloss: 0.0570331\n",
      "[9240]\ttraining's binary_logloss: 0.0570273\n",
      "[9241]\ttraining's binary_logloss: 0.0570247\n",
      "[9242]\ttraining's binary_logloss: 0.0570183\n",
      "[9243]\ttraining's binary_logloss: 0.0570123\n",
      "[9244]\ttraining's binary_logloss: 0.0570078\n",
      "[9245]\ttraining's binary_logloss: 0.0570015\n",
      "[9246]\ttraining's binary_logloss: 0.0569961\n",
      "[9247]\ttraining's binary_logloss: 0.0569898\n",
      "[9248]\ttraining's binary_logloss: 0.0569846\n",
      "[9249]\ttraining's binary_logloss: 0.0569793\n",
      "[9250]\ttraining's binary_logloss: 0.056974\n",
      "[9251]\ttraining's binary_logloss: 0.0569681\n",
      "[9252]\ttraining's binary_logloss: 0.0569638\n",
      "[9253]\ttraining's binary_logloss: 0.0569578\n",
      "[9254]\ttraining's binary_logloss: 0.056952\n",
      "[9255]\ttraining's binary_logloss: 0.0569464\n",
      "[9256]\ttraining's binary_logloss: 0.0569419\n",
      "[9257]\ttraining's binary_logloss: 0.0569366\n",
      "[9258]\ttraining's binary_logloss: 0.0569342\n",
      "[9259]\ttraining's binary_logloss: 0.0569278\n",
      "[9260]\ttraining's binary_logloss: 0.0569256\n",
      "[9261]\ttraining's binary_logloss: 0.05692\n",
      "[9262]\ttraining's binary_logloss: 0.0569152\n",
      "[9263]\ttraining's binary_logloss: 0.056912\n",
      "[9264]\ttraining's binary_logloss: 0.0569077\n",
      "[9265]\ttraining's binary_logloss: 0.0569013\n",
      "[9266]\ttraining's binary_logloss: 0.0568959\n",
      "[9267]\ttraining's binary_logloss: 0.0568935\n",
      "[9268]\ttraining's binary_logloss: 0.0568899\n",
      "[9269]\ttraining's binary_logloss: 0.0568846\n",
      "[9270]\ttraining's binary_logloss: 0.0568791\n",
      "[9271]\ttraining's binary_logloss: 0.0568733\n",
      "[9272]\ttraining's binary_logloss: 0.0568673\n",
      "[9273]\ttraining's binary_logloss: 0.0568618\n",
      "[9274]\ttraining's binary_logloss: 0.05686\n",
      "[9275]\ttraining's binary_logloss: 0.0568565\n",
      "[9276]\ttraining's binary_logloss: 0.0568515\n",
      "[9277]\ttraining's binary_logloss: 0.0568463\n",
      "[9278]\ttraining's binary_logloss: 0.0568406\n",
      "[9279]\ttraining's binary_logloss: 0.0568359\n",
      "[9280]\ttraining's binary_logloss: 0.056832\n",
      "[9281]\ttraining's binary_logloss: 0.0568257\n",
      "[9282]\ttraining's binary_logloss: 0.05682\n",
      "[9283]\ttraining's binary_logloss: 0.0568146\n",
      "[9284]\ttraining's binary_logloss: 0.056811\n",
      "[9285]\ttraining's binary_logloss: 0.0568049\n",
      "[9286]\ttraining's binary_logloss: 0.0568031\n",
      "[9287]\ttraining's binary_logloss: 0.0567986\n",
      "[9288]\ttraining's binary_logloss: 0.0567919\n",
      "[9289]\ttraining's binary_logloss: 0.0567862\n",
      "[9290]\ttraining's binary_logloss: 0.0567805\n",
      "[9291]\ttraining's binary_logloss: 0.0567735\n",
      "[9292]\ttraining's binary_logloss: 0.0567682\n",
      "[9293]\ttraining's binary_logloss: 0.0567623\n",
      "[9294]\ttraining's binary_logloss: 0.0567573\n",
      "[9295]\ttraining's binary_logloss: 0.056753\n",
      "[9296]\ttraining's binary_logloss: 0.0567464\n",
      "[9297]\ttraining's binary_logloss: 0.0567414\n",
      "[9298]\ttraining's binary_logloss: 0.0567346\n",
      "[9299]\ttraining's binary_logloss: 0.0567276\n",
      "[9300]\ttraining's binary_logloss: 0.0567237\n",
      "[9301]\ttraining's binary_logloss: 0.0567191\n",
      "[9302]\ttraining's binary_logloss: 0.0567125\n",
      "[9303]\ttraining's binary_logloss: 0.0567061\n",
      "[9304]\ttraining's binary_logloss: 0.0567\n",
      "[9305]\ttraining's binary_logloss: 0.056694\n",
      "[9306]\ttraining's binary_logloss: 0.0566887\n",
      "[9307]\ttraining's binary_logloss: 0.0566826\n",
      "[9308]\ttraining's binary_logloss: 0.0566777\n",
      "[9309]\ttraining's binary_logloss: 0.0566769\n",
      "[9310]\ttraining's binary_logloss: 0.0566717\n",
      "[9311]\ttraining's binary_logloss: 0.0566673\n",
      "[9312]\ttraining's binary_logloss: 0.0566612\n",
      "[9313]\ttraining's binary_logloss: 0.0566587\n",
      "[9314]\ttraining's binary_logloss: 0.0566562\n",
      "[9315]\ttraining's binary_logloss: 0.0566517\n",
      "[9316]\ttraining's binary_logloss: 0.0566459\n",
      "[9317]\ttraining's binary_logloss: 0.0566405\n",
      "[9318]\ttraining's binary_logloss: 0.0566354\n",
      "[9319]\ttraining's binary_logloss: 0.0566296\n",
      "[9320]\ttraining's binary_logloss: 0.0566242\n",
      "[9321]\ttraining's binary_logloss: 0.0566197\n",
      "[9322]\ttraining's binary_logloss: 0.0566165\n",
      "[9323]\ttraining's binary_logloss: 0.0566147\n",
      "[9324]\ttraining's binary_logloss: 0.0566129\n",
      "[9325]\ttraining's binary_logloss: 0.0566076\n",
      "[9326]\ttraining's binary_logloss: 0.0566034\n",
      "[9327]\ttraining's binary_logloss: 0.0565978\n",
      "[9328]\ttraining's binary_logloss: 0.0565954\n",
      "[9329]\ttraining's binary_logloss: 0.0565913\n",
      "[9330]\ttraining's binary_logloss: 0.0565895\n",
      "[9331]\ttraining's binary_logloss: 0.0565878\n",
      "[9332]\ttraining's binary_logloss: 0.0565812\n",
      "[9333]\ttraining's binary_logloss: 0.0565784\n",
      "[9334]\ttraining's binary_logloss: 0.0565729\n",
      "[9335]\ttraining's binary_logloss: 0.0565677\n",
      "[9336]\ttraining's binary_logloss: 0.0565614\n",
      "[9337]\ttraining's binary_logloss: 0.056556\n",
      "[9338]\ttraining's binary_logloss: 0.0565521\n",
      "[9339]\ttraining's binary_logloss: 0.0565466\n",
      "[9340]\ttraining's binary_logloss: 0.0565413\n",
      "[9341]\ttraining's binary_logloss: 0.0565346\n",
      "[9342]\ttraining's binary_logloss: 0.0565301\n",
      "[9343]\ttraining's binary_logloss: 0.0565238\n",
      "[9344]\ttraining's binary_logloss: 0.0565212\n",
      "[9345]\ttraining's binary_logloss: 0.0565191\n",
      "[9346]\ttraining's binary_logloss: 0.0565136\n",
      "[9347]\ttraining's binary_logloss: 0.05651\n",
      "[9348]\ttraining's binary_logloss: 0.0565051\n",
      "[9349]\ttraining's binary_logloss: 0.0565036\n",
      "[9350]\ttraining's binary_logloss: 0.0564978\n",
      "[9351]\ttraining's binary_logloss: 0.0564954\n",
      "[9352]\ttraining's binary_logloss: 0.0564896\n",
      "[9353]\ttraining's binary_logloss: 0.0564854\n",
      "[9354]\ttraining's binary_logloss: 0.0564818\n",
      "[9355]\ttraining's binary_logloss: 0.0564765\n",
      "[9356]\ttraining's binary_logloss: 0.0564707\n",
      "[9357]\ttraining's binary_logloss: 0.0564648\n",
      "[9358]\ttraining's binary_logloss: 0.0564588\n",
      "[9359]\ttraining's binary_logloss: 0.0564532\n",
      "[9360]\ttraining's binary_logloss: 0.0564497\n",
      "[9361]\ttraining's binary_logloss: 0.0564437\n",
      "[9362]\ttraining's binary_logloss: 0.0564366\n",
      "[9363]\ttraining's binary_logloss: 0.0564307\n",
      "[9364]\ttraining's binary_logloss: 0.056425\n",
      "[9365]\ttraining's binary_logloss: 0.0564208\n",
      "[9366]\ttraining's binary_logloss: 0.0564157\n",
      "[9367]\ttraining's binary_logloss: 0.0564128\n",
      "[9368]\ttraining's binary_logloss: 0.0564063\n",
      "[9369]\ttraining's binary_logloss: 0.0564002\n",
      "[9370]\ttraining's binary_logloss: 0.0563946\n",
      "[9371]\ttraining's binary_logloss: 0.0563908\n",
      "[9372]\ttraining's binary_logloss: 0.0563871\n",
      "[9373]\ttraining's binary_logloss: 0.0563806\n",
      "[9374]\ttraining's binary_logloss: 0.0563767\n",
      "[9375]\ttraining's binary_logloss: 0.0563738\n",
      "[9376]\ttraining's binary_logloss: 0.0563716\n",
      "[9377]\ttraining's binary_logloss: 0.0563706\n",
      "[9378]\ttraining's binary_logloss: 0.0563648\n",
      "[9379]\ttraining's binary_logloss: 0.0563587\n",
      "[9380]\ttraining's binary_logloss: 0.0563531\n",
      "[9381]\ttraining's binary_logloss: 0.0563476\n",
      "[9382]\ttraining's binary_logloss: 0.0563418\n",
      "[9383]\ttraining's binary_logloss: 0.0563355\n",
      "[9384]\ttraining's binary_logloss: 0.0563346\n",
      "[9385]\ttraining's binary_logloss: 0.0563294\n",
      "[9386]\ttraining's binary_logloss: 0.0563239\n",
      "[9387]\ttraining's binary_logloss: 0.0563184\n",
      "[9388]\ttraining's binary_logloss: 0.0563142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9389]\ttraining's binary_logloss: 0.0563107\n",
      "[9390]\ttraining's binary_logloss: 0.0563042\n",
      "[9391]\ttraining's binary_logloss: 0.0563032\n",
      "[9392]\ttraining's binary_logloss: 0.0563006\n",
      "[9393]\ttraining's binary_logloss: 0.0562963\n",
      "[9394]\ttraining's binary_logloss: 0.0562908\n",
      "[9395]\ttraining's binary_logloss: 0.0562865\n",
      "[9396]\ttraining's binary_logloss: 0.0562801\n",
      "[9397]\ttraining's binary_logloss: 0.0562743\n",
      "[9398]\ttraining's binary_logloss: 0.0562694\n",
      "[9399]\ttraining's binary_logloss: 0.0562642\n",
      "[9400]\ttraining's binary_logloss: 0.0562586\n",
      "[9401]\ttraining's binary_logloss: 0.0562513\n",
      "[9402]\ttraining's binary_logloss: 0.0562464\n",
      "[9403]\ttraining's binary_logloss: 0.0562398\n",
      "[9404]\ttraining's binary_logloss: 0.0562363\n",
      "[9405]\ttraining's binary_logloss: 0.056234\n",
      "[9406]\ttraining's binary_logloss: 0.0562321\n",
      "[9407]\ttraining's binary_logloss: 0.0562256\n",
      "[9408]\ttraining's binary_logloss: 0.0562234\n",
      "[9409]\ttraining's binary_logloss: 0.0562208\n",
      "[9410]\ttraining's binary_logloss: 0.0562144\n",
      "[9411]\ttraining's binary_logloss: 0.0562094\n",
      "[9412]\ttraining's binary_logloss: 0.0562035\n",
      "[9413]\ttraining's binary_logloss: 0.0561973\n",
      "[9414]\ttraining's binary_logloss: 0.0561927\n",
      "[9415]\ttraining's binary_logloss: 0.0561863\n",
      "[9416]\ttraining's binary_logloss: 0.0561798\n",
      "[9417]\ttraining's binary_logloss: 0.0561731\n",
      "[9418]\ttraining's binary_logloss: 0.056167\n",
      "[9419]\ttraining's binary_logloss: 0.0561612\n",
      "[9420]\ttraining's binary_logloss: 0.0561554\n",
      "[9421]\ttraining's binary_logloss: 0.0561502\n",
      "[9422]\ttraining's binary_logloss: 0.0561445\n",
      "[9423]\ttraining's binary_logloss: 0.0561398\n",
      "[9424]\ttraining's binary_logloss: 0.0561374\n",
      "[9425]\ttraining's binary_logloss: 0.0561337\n",
      "[9426]\ttraining's binary_logloss: 0.0561307\n",
      "[9427]\ttraining's binary_logloss: 0.0561239\n",
      "[9428]\ttraining's binary_logloss: 0.0561187\n",
      "[9429]\ttraining's binary_logloss: 0.0561124\n",
      "[9430]\ttraining's binary_logloss: 0.056107\n",
      "[9431]\ttraining's binary_logloss: 0.0561043\n",
      "[9432]\ttraining's binary_logloss: 0.0561009\n",
      "[9433]\ttraining's binary_logloss: 0.0560968\n",
      "[9434]\ttraining's binary_logloss: 0.0560908\n",
      "[9435]\ttraining's binary_logloss: 0.056088\n",
      "[9436]\ttraining's binary_logloss: 0.056083\n",
      "[9437]\ttraining's binary_logloss: 0.0560759\n",
      "[9438]\ttraining's binary_logloss: 0.0560724\n",
      "[9439]\ttraining's binary_logloss: 0.056066\n",
      "[9440]\ttraining's binary_logloss: 0.0560596\n",
      "[9441]\ttraining's binary_logloss: 0.0560544\n",
      "[9442]\ttraining's binary_logloss: 0.0560488\n",
      "[9443]\ttraining's binary_logloss: 0.0560455\n",
      "[9444]\ttraining's binary_logloss: 0.0560396\n",
      "[9445]\ttraining's binary_logloss: 0.0560367\n",
      "[9446]\ttraining's binary_logloss: 0.0560309\n",
      "[9447]\ttraining's binary_logloss: 0.0560258\n",
      "[9448]\ttraining's binary_logloss: 0.0560202\n",
      "[9449]\ttraining's binary_logloss: 0.0560145\n",
      "[9450]\ttraining's binary_logloss: 0.0560092\n",
      "[9451]\ttraining's binary_logloss: 0.0560033\n",
      "[9452]\ttraining's binary_logloss: 0.0560017\n",
      "[9453]\ttraining's binary_logloss: 0.0560009\n",
      "[9454]\ttraining's binary_logloss: 0.055995\n",
      "[9455]\ttraining's binary_logloss: 0.0559903\n",
      "[9456]\ttraining's binary_logloss: 0.0559842\n",
      "[9457]\ttraining's binary_logloss: 0.0559802\n",
      "[9458]\ttraining's binary_logloss: 0.0559744\n",
      "[9459]\ttraining's binary_logloss: 0.0559686\n",
      "[9460]\ttraining's binary_logloss: 0.0559635\n",
      "[9461]\ttraining's binary_logloss: 0.0559587\n",
      "[9462]\ttraining's binary_logloss: 0.0559523\n",
      "[9463]\ttraining's binary_logloss: 0.055946\n",
      "[9464]\ttraining's binary_logloss: 0.0559404\n",
      "[9465]\ttraining's binary_logloss: 0.0559347\n",
      "[9466]\ttraining's binary_logloss: 0.05593\n",
      "[9467]\ttraining's binary_logloss: 0.0559253\n",
      "[9468]\ttraining's binary_logloss: 0.0559179\n",
      "[9469]\ttraining's binary_logloss: 0.0559125\n",
      "[9470]\ttraining's binary_logloss: 0.0559073\n",
      "[9471]\ttraining's binary_logloss: 0.0559028\n",
      "[9472]\ttraining's binary_logloss: 0.0558975\n",
      "[9473]\ttraining's binary_logloss: 0.0558914\n",
      "[9474]\ttraining's binary_logloss: 0.055889\n",
      "[9475]\ttraining's binary_logloss: 0.0558832\n",
      "[9476]\ttraining's binary_logloss: 0.0558775\n",
      "[9477]\ttraining's binary_logloss: 0.0558719\n",
      "[9478]\ttraining's binary_logloss: 0.0558659\n",
      "[9479]\ttraining's binary_logloss: 0.0558604\n",
      "[9480]\ttraining's binary_logloss: 0.0558543\n",
      "[9481]\ttraining's binary_logloss: 0.0558486\n",
      "[9482]\ttraining's binary_logloss: 0.0558434\n",
      "[9483]\ttraining's binary_logloss: 0.0558375\n",
      "[9484]\ttraining's binary_logloss: 0.0558313\n",
      "[9485]\ttraining's binary_logloss: 0.0558257\n",
      "[9486]\ttraining's binary_logloss: 0.0558188\n",
      "[9487]\ttraining's binary_logloss: 0.0558148\n",
      "[9488]\ttraining's binary_logloss: 0.0558092\n",
      "[9489]\ttraining's binary_logloss: 0.0558037\n",
      "[9490]\ttraining's binary_logloss: 0.0557979\n",
      "[9491]\ttraining's binary_logloss: 0.0557912\n",
      "[9492]\ttraining's binary_logloss: 0.0557849\n",
      "[9493]\ttraining's binary_logloss: 0.0557792\n",
      "[9494]\ttraining's binary_logloss: 0.0557746\n",
      "[9495]\ttraining's binary_logloss: 0.0557699\n",
      "[9496]\ttraining's binary_logloss: 0.0557649\n",
      "[9497]\ttraining's binary_logloss: 0.0557587\n",
      "[9498]\ttraining's binary_logloss: 0.055753\n",
      "[9499]\ttraining's binary_logloss: 0.0557486\n",
      "[9500]\ttraining's binary_logloss: 0.0557421\n",
      "[9501]\ttraining's binary_logloss: 0.0557365\n",
      "[9502]\ttraining's binary_logloss: 0.0557313\n",
      "[9503]\ttraining's binary_logloss: 0.0557258\n",
      "[9504]\ttraining's binary_logloss: 0.0557204\n",
      "[9505]\ttraining's binary_logloss: 0.0557144\n",
      "[9506]\ttraining's binary_logloss: 0.055709\n",
      "[9507]\ttraining's binary_logloss: 0.0557028\n",
      "[9508]\ttraining's binary_logloss: 0.0556989\n",
      "[9509]\ttraining's binary_logloss: 0.0556947\n",
      "[9510]\ttraining's binary_logloss: 0.0556895\n",
      "[9511]\ttraining's binary_logloss: 0.0556856\n",
      "[9512]\ttraining's binary_logloss: 0.0556803\n",
      "[9513]\ttraining's binary_logloss: 0.0556757\n",
      "[9514]\ttraining's binary_logloss: 0.0556703\n",
      "[9515]\ttraining's binary_logloss: 0.0556638\n",
      "[9516]\ttraining's binary_logloss: 0.0556596\n",
      "[9517]\ttraining's binary_logloss: 0.0556576\n",
      "[9518]\ttraining's binary_logloss: 0.0556524\n",
      "[9519]\ttraining's binary_logloss: 0.0556471\n",
      "[9520]\ttraining's binary_logloss: 0.0556412\n",
      "[9521]\ttraining's binary_logloss: 0.0556357\n",
      "[9522]\ttraining's binary_logloss: 0.0556305\n",
      "[9523]\ttraining's binary_logloss: 0.055625\n",
      "[9524]\ttraining's binary_logloss: 0.0556201\n",
      "[9525]\ttraining's binary_logloss: 0.0556145\n",
      "[9526]\ttraining's binary_logloss: 0.0556136\n",
      "[9527]\ttraining's binary_logloss: 0.0556073\n",
      "[9528]\ttraining's binary_logloss: 0.055602\n",
      "[9529]\ttraining's binary_logloss: 0.0555959\n",
      "[9530]\ttraining's binary_logloss: 0.0555906\n",
      "[9531]\ttraining's binary_logloss: 0.0555848\n",
      "[9532]\ttraining's binary_logloss: 0.0555797\n",
      "[9533]\ttraining's binary_logloss: 0.0555778\n",
      "[9534]\ttraining's binary_logloss: 0.055573\n",
      "[9535]\ttraining's binary_logloss: 0.0555678\n",
      "[9536]\ttraining's binary_logloss: 0.0555621\n",
      "[9537]\ttraining's binary_logloss: 0.055557\n",
      "[9538]\ttraining's binary_logloss: 0.0555522\n",
      "[9539]\ttraining's binary_logloss: 0.0555466\n",
      "[9540]\ttraining's binary_logloss: 0.0555405\n",
      "[9541]\ttraining's binary_logloss: 0.0555338\n",
      "[9542]\ttraining's binary_logloss: 0.055528\n",
      "[9543]\ttraining's binary_logloss: 0.0555224\n",
      "[9544]\ttraining's binary_logloss: 0.0555175\n",
      "[9545]\ttraining's binary_logloss: 0.0555121\n",
      "[9546]\ttraining's binary_logloss: 0.0555096\n",
      "[9547]\ttraining's binary_logloss: 0.0555043\n",
      "[9548]\ttraining's binary_logloss: 0.0554976\n",
      "[9549]\ttraining's binary_logloss: 0.0554924\n",
      "[9550]\ttraining's binary_logloss: 0.055487\n",
      "[9551]\ttraining's binary_logloss: 0.0554819\n",
      "[9552]\ttraining's binary_logloss: 0.0554764\n",
      "[9553]\ttraining's binary_logloss: 0.0554712\n",
      "[9554]\ttraining's binary_logloss: 0.0554654\n",
      "[9555]\ttraining's binary_logloss: 0.0554609\n",
      "[9556]\ttraining's binary_logloss: 0.0554558\n",
      "[9557]\ttraining's binary_logloss: 0.0554508\n",
      "[9558]\ttraining's binary_logloss: 0.0554456\n",
      "[9559]\ttraining's binary_logloss: 0.0554397\n",
      "[9560]\ttraining's binary_logloss: 0.055434\n",
      "[9561]\ttraining's binary_logloss: 0.0554294\n",
      "[9562]\ttraining's binary_logloss: 0.0554243\n",
      "[9563]\ttraining's binary_logloss: 0.0554199\n",
      "[9564]\ttraining's binary_logloss: 0.0554148\n",
      "[9565]\ttraining's binary_logloss: 0.0554093\n",
      "[9566]\ttraining's binary_logloss: 0.0554039\n",
      "[9567]\ttraining's binary_logloss: 0.0553984\n",
      "[9568]\ttraining's binary_logloss: 0.0553921\n",
      "[9569]\ttraining's binary_logloss: 0.055389\n",
      "[9570]\ttraining's binary_logloss: 0.0553829\n",
      "[9571]\ttraining's binary_logloss: 0.0553776\n",
      "[9572]\ttraining's binary_logloss: 0.0553717\n",
      "[9573]\ttraining's binary_logloss: 0.055366\n",
      "[9574]\ttraining's binary_logloss: 0.0553618\n",
      "[9575]\ttraining's binary_logloss: 0.0553581\n",
      "[9576]\ttraining's binary_logloss: 0.0553516\n",
      "[9577]\ttraining's binary_logloss: 0.0553461\n",
      "[9578]\ttraining's binary_logloss: 0.0553401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9579]\ttraining's binary_logloss: 0.0553393\n",
      "[9580]\ttraining's binary_logloss: 0.0553335\n",
      "[9581]\ttraining's binary_logloss: 0.0553282\n",
      "[9582]\ttraining's binary_logloss: 0.0553237\n",
      "[9583]\ttraining's binary_logloss: 0.055318\n",
      "[9584]\ttraining's binary_logloss: 0.0553123\n",
      "[9585]\ttraining's binary_logloss: 0.0553063\n",
      "[9586]\ttraining's binary_logloss: 0.0553003\n",
      "[9587]\ttraining's binary_logloss: 0.0552947\n",
      "[9588]\ttraining's binary_logloss: 0.055289\n",
      "[9589]\ttraining's binary_logloss: 0.0552831\n",
      "[9590]\ttraining's binary_logloss: 0.0552782\n",
      "[9591]\ttraining's binary_logloss: 0.0552745\n",
      "[9592]\ttraining's binary_logloss: 0.0552712\n",
      "[9593]\ttraining's binary_logloss: 0.0552652\n",
      "[9594]\ttraining's binary_logloss: 0.0552599\n",
      "[9595]\ttraining's binary_logloss: 0.0552559\n",
      "[9596]\ttraining's binary_logloss: 0.0552498\n",
      "[9597]\ttraining's binary_logloss: 0.0552443\n",
      "[9598]\ttraining's binary_logloss: 0.0552383\n",
      "[9599]\ttraining's binary_logloss: 0.0552371\n",
      "[9600]\ttraining's binary_logloss: 0.0552312\n",
      "[9601]\ttraining's binary_logloss: 0.055226\n",
      "[9602]\ttraining's binary_logloss: 0.0552207\n",
      "[9603]\ttraining's binary_logloss: 0.0552152\n",
      "[9604]\ttraining's binary_logloss: 0.0552085\n",
      "[9605]\ttraining's binary_logloss: 0.0552032\n",
      "[9606]\ttraining's binary_logloss: 0.0551975\n",
      "[9607]\ttraining's binary_logloss: 0.0551928\n",
      "[9608]\ttraining's binary_logloss: 0.0551883\n",
      "[9609]\ttraining's binary_logloss: 0.0551863\n",
      "[9610]\ttraining's binary_logloss: 0.0551805\n",
      "[9611]\ttraining's binary_logloss: 0.055176\n",
      "[9612]\ttraining's binary_logloss: 0.0551707\n",
      "[9613]\ttraining's binary_logloss: 0.0551681\n",
      "[9614]\ttraining's binary_logloss: 0.0551632\n",
      "[9615]\ttraining's binary_logloss: 0.0551578\n",
      "[9616]\ttraining's binary_logloss: 0.0551524\n",
      "[9617]\ttraining's binary_logloss: 0.0551506\n",
      "[9618]\ttraining's binary_logloss: 0.0551477\n",
      "[9619]\ttraining's binary_logloss: 0.0551432\n",
      "[9620]\ttraining's binary_logloss: 0.0551374\n",
      "[9621]\ttraining's binary_logloss: 0.0551327\n",
      "[9622]\ttraining's binary_logloss: 0.0551267\n",
      "[9623]\ttraining's binary_logloss: 0.0551212\n",
      "[9624]\ttraining's binary_logloss: 0.0551162\n",
      "[9625]\ttraining's binary_logloss: 0.0551108\n",
      "[9626]\ttraining's binary_logloss: 0.0551053\n",
      "[9627]\ttraining's binary_logloss: 0.0551028\n",
      "[9628]\ttraining's binary_logloss: 0.0550965\n",
      "[9629]\ttraining's binary_logloss: 0.0550912\n",
      "[9630]\ttraining's binary_logloss: 0.0550853\n",
      "[9631]\ttraining's binary_logloss: 0.0550802\n",
      "[9632]\ttraining's binary_logloss: 0.0550746\n",
      "[9633]\ttraining's binary_logloss: 0.0550688\n",
      "[9634]\ttraining's binary_logloss: 0.0550657\n",
      "[9635]\ttraining's binary_logloss: 0.055061\n",
      "[9636]\ttraining's binary_logloss: 0.0550577\n",
      "[9637]\ttraining's binary_logloss: 0.0550537\n",
      "[9638]\ttraining's binary_logloss: 0.0550514\n",
      "[9639]\ttraining's binary_logloss: 0.055046\n",
      "[9640]\ttraining's binary_logloss: 0.0550424\n",
      "[9641]\ttraining's binary_logloss: 0.0550375\n",
      "[9642]\ttraining's binary_logloss: 0.0550318\n",
      "[9643]\ttraining's binary_logloss: 0.0550261\n",
      "[9644]\ttraining's binary_logloss: 0.0550208\n",
      "[9645]\ttraining's binary_logloss: 0.0550149\n",
      "[9646]\ttraining's binary_logloss: 0.0550097\n",
      "[9647]\ttraining's binary_logloss: 0.0550064\n",
      "[9648]\ttraining's binary_logloss: 0.054999\n",
      "[9649]\ttraining's binary_logloss: 0.0549955\n",
      "[9650]\ttraining's binary_logloss: 0.0549906\n",
      "[9651]\ttraining's binary_logloss: 0.054985\n",
      "[9652]\ttraining's binary_logloss: 0.0549791\n",
      "[9653]\ttraining's binary_logloss: 0.0549753\n",
      "[9654]\ttraining's binary_logloss: 0.0549717\n",
      "[9655]\ttraining's binary_logloss: 0.0549682\n",
      "[9656]\ttraining's binary_logloss: 0.0549625\n",
      "[9657]\ttraining's binary_logloss: 0.0549569\n",
      "[9658]\ttraining's binary_logloss: 0.0549507\n",
      "[9659]\ttraining's binary_logloss: 0.0549453\n",
      "[9660]\ttraining's binary_logloss: 0.0549402\n",
      "[9661]\ttraining's binary_logloss: 0.0549349\n",
      "[9662]\ttraining's binary_logloss: 0.0549306\n",
      "[9663]\ttraining's binary_logloss: 0.0549265\n",
      "[9664]\ttraining's binary_logloss: 0.0549213\n",
      "[9665]\ttraining's binary_logloss: 0.0549158\n",
      "[9666]\ttraining's binary_logloss: 0.0549123\n",
      "[9667]\ttraining's binary_logloss: 0.0549075\n",
      "[9668]\ttraining's binary_logloss: 0.0549053\n",
      "[9669]\ttraining's binary_logloss: 0.0548998\n",
      "[9670]\ttraining's binary_logloss: 0.0548966\n",
      "[9671]\ttraining's binary_logloss: 0.0548928\n",
      "[9672]\ttraining's binary_logloss: 0.0548875\n",
      "[9673]\ttraining's binary_logloss: 0.054882\n",
      "[9674]\ttraining's binary_logloss: 0.0548763\n",
      "[9675]\ttraining's binary_logloss: 0.0548712\n",
      "[9676]\ttraining's binary_logloss: 0.0548658\n",
      "[9677]\ttraining's binary_logloss: 0.0548619\n",
      "[9678]\ttraining's binary_logloss: 0.0548566\n",
      "[9679]\ttraining's binary_logloss: 0.0548524\n",
      "[9680]\ttraining's binary_logloss: 0.0548466\n",
      "[9681]\ttraining's binary_logloss: 0.0548416\n",
      "[9682]\ttraining's binary_logloss: 0.0548363\n",
      "[9683]\ttraining's binary_logloss: 0.0548323\n",
      "[9684]\ttraining's binary_logloss: 0.0548271\n",
      "[9685]\ttraining's binary_logloss: 0.0548215\n",
      "[9686]\ttraining's binary_logloss: 0.0548159\n",
      "[9687]\ttraining's binary_logloss: 0.0548125\n",
      "[9688]\ttraining's binary_logloss: 0.054807\n",
      "[9689]\ttraining's binary_logloss: 0.0548019\n",
      "[9690]\ttraining's binary_logloss: 0.0547962\n",
      "[9691]\ttraining's binary_logloss: 0.054791\n",
      "[9692]\ttraining's binary_logloss: 0.0547854\n",
      "[9693]\ttraining's binary_logloss: 0.0547803\n",
      "[9694]\ttraining's binary_logloss: 0.0547741\n",
      "[9695]\ttraining's binary_logloss: 0.0547689\n",
      "[9696]\ttraining's binary_logloss: 0.0547683\n",
      "[9697]\ttraining's binary_logloss: 0.0547623\n",
      "[9698]\ttraining's binary_logloss: 0.0547572\n",
      "[9699]\ttraining's binary_logloss: 0.0547522\n",
      "[9700]\ttraining's binary_logloss: 0.0547472\n",
      "[9701]\ttraining's binary_logloss: 0.0547448\n",
      "[9702]\ttraining's binary_logloss: 0.0547388\n",
      "[9703]\ttraining's binary_logloss: 0.0547367\n",
      "[9704]\ttraining's binary_logloss: 0.0547361\n",
      "[9705]\ttraining's binary_logloss: 0.0547314\n",
      "[9706]\ttraining's binary_logloss: 0.054726\n",
      "[9707]\ttraining's binary_logloss: 0.054722\n",
      "[9708]\ttraining's binary_logloss: 0.0547203\n",
      "[9709]\ttraining's binary_logloss: 0.0547157\n",
      "[9710]\ttraining's binary_logloss: 0.0547137\n",
      "[9711]\ttraining's binary_logloss: 0.0547079\n",
      "[9712]\ttraining's binary_logloss: 0.0547073\n",
      "[9713]\ttraining's binary_logloss: 0.0547023\n",
      "[9714]\ttraining's binary_logloss: 0.0546991\n",
      "[9715]\ttraining's binary_logloss: 0.054694\n",
      "[9716]\ttraining's binary_logloss: 0.054688\n",
      "[9717]\ttraining's binary_logloss: 0.0546834\n",
      "[9718]\ttraining's binary_logloss: 0.0546779\n",
      "[9719]\ttraining's binary_logloss: 0.0546719\n",
      "[9720]\ttraining's binary_logloss: 0.0546671\n",
      "[9721]\ttraining's binary_logloss: 0.0546613\n",
      "[9722]\ttraining's binary_logloss: 0.0546556\n",
      "[9723]\ttraining's binary_logloss: 0.0546535\n",
      "[9724]\ttraining's binary_logloss: 0.0546517\n",
      "[9725]\ttraining's binary_logloss: 0.0546458\n",
      "[9726]\ttraining's binary_logloss: 0.0546438\n",
      "[9727]\ttraining's binary_logloss: 0.0546394\n",
      "[9728]\ttraining's binary_logloss: 0.054637\n",
      "[9729]\ttraining's binary_logloss: 0.0546308\n",
      "[9730]\ttraining's binary_logloss: 0.0546276\n",
      "[9731]\ttraining's binary_logloss: 0.0546225\n",
      "[9732]\ttraining's binary_logloss: 0.0546178\n",
      "[9733]\ttraining's binary_logloss: 0.0546147\n",
      "[9734]\ttraining's binary_logloss: 0.0546093\n",
      "[9735]\ttraining's binary_logloss: 0.0546033\n",
      "[9736]\ttraining's binary_logloss: 0.0545976\n",
      "[9737]\ttraining's binary_logloss: 0.0545941\n",
      "[9738]\ttraining's binary_logloss: 0.0545881\n",
      "[9739]\ttraining's binary_logloss: 0.0545832\n",
      "[9740]\ttraining's binary_logloss: 0.0545775\n",
      "[9741]\ttraining's binary_logloss: 0.054574\n",
      "[9742]\ttraining's binary_logloss: 0.0545682\n",
      "[9743]\ttraining's binary_logloss: 0.0545641\n",
      "[9744]\ttraining's binary_logloss: 0.0545598\n",
      "[9745]\ttraining's binary_logloss: 0.054559\n",
      "[9746]\ttraining's binary_logloss: 0.054556\n",
      "[9747]\ttraining's binary_logloss: 0.0545534\n",
      "[9748]\ttraining's binary_logloss: 0.0545478\n",
      "[9749]\ttraining's binary_logloss: 0.0545427\n",
      "[9750]\ttraining's binary_logloss: 0.0545372\n",
      "[9751]\ttraining's binary_logloss: 0.0545344\n",
      "[9752]\ttraining's binary_logloss: 0.0545301\n",
      "[9753]\ttraining's binary_logloss: 0.0545246\n",
      "[9754]\ttraining's binary_logloss: 0.0545194\n",
      "[9755]\ttraining's binary_logloss: 0.0545154\n",
      "[9756]\ttraining's binary_logloss: 0.0545104\n",
      "[9757]\ttraining's binary_logloss: 0.0545043\n",
      "[9758]\ttraining's binary_logloss: 0.0544986\n",
      "[9759]\ttraining's binary_logloss: 0.0544922\n",
      "[9760]\ttraining's binary_logloss: 0.0544867\n",
      "[9761]\ttraining's binary_logloss: 0.0544816\n",
      "[9762]\ttraining's binary_logloss: 0.0544778\n",
      "[9763]\ttraining's binary_logloss: 0.0544721\n",
      "[9764]\ttraining's binary_logloss: 0.0544678\n",
      "[9765]\ttraining's binary_logloss: 0.0544616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9766]\ttraining's binary_logloss: 0.0544572\n",
      "[9767]\ttraining's binary_logloss: 0.0544514\n",
      "[9768]\ttraining's binary_logloss: 0.0544481\n",
      "[9769]\ttraining's binary_logloss: 0.0544414\n",
      "[9770]\ttraining's binary_logloss: 0.0544364\n",
      "[9771]\ttraining's binary_logloss: 0.0544305\n",
      "[9772]\ttraining's binary_logloss: 0.0544252\n",
      "[9773]\ttraining's binary_logloss: 0.0544202\n",
      "[9774]\ttraining's binary_logloss: 0.0544132\n",
      "[9775]\ttraining's binary_logloss: 0.0544085\n",
      "[9776]\ttraining's binary_logloss: 0.0544036\n",
      "[9777]\ttraining's binary_logloss: 0.0543998\n",
      "[9778]\ttraining's binary_logloss: 0.0543962\n",
      "[9779]\ttraining's binary_logloss: 0.0543906\n",
      "[9780]\ttraining's binary_logloss: 0.0543853\n",
      "[9781]\ttraining's binary_logloss: 0.0543816\n",
      "[9782]\ttraining's binary_logloss: 0.0543762\n",
      "[9783]\ttraining's binary_logloss: 0.0543712\n",
      "[9784]\ttraining's binary_logloss: 0.0543665\n",
      "[9785]\ttraining's binary_logloss: 0.0543603\n",
      "[9786]\ttraining's binary_logloss: 0.0543538\n",
      "[9787]\ttraining's binary_logloss: 0.0543487\n",
      "[9788]\ttraining's binary_logloss: 0.0543456\n",
      "[9789]\ttraining's binary_logloss: 0.0543401\n",
      "[9790]\ttraining's binary_logloss: 0.0543343\n",
      "[9791]\ttraining's binary_logloss: 0.0543289\n",
      "[9792]\ttraining's binary_logloss: 0.0543232\n",
      "[9793]\ttraining's binary_logloss: 0.0543171\n",
      "[9794]\ttraining's binary_logloss: 0.0543117\n",
      "[9795]\ttraining's binary_logloss: 0.0543067\n",
      "[9796]\ttraining's binary_logloss: 0.0543031\n",
      "[9797]\ttraining's binary_logloss: 0.0542967\n",
      "[9798]\ttraining's binary_logloss: 0.054291\n",
      "[9799]\ttraining's binary_logloss: 0.0542855\n",
      "[9800]\ttraining's binary_logloss: 0.054283\n",
      "[9801]\ttraining's binary_logloss: 0.0542774\n",
      "[9802]\ttraining's binary_logloss: 0.0542715\n",
      "[9803]\ttraining's binary_logloss: 0.0542658\n",
      "[9804]\ttraining's binary_logloss: 0.0542604\n",
      "[9805]\ttraining's binary_logloss: 0.0542573\n",
      "[9806]\ttraining's binary_logloss: 0.054254\n",
      "[9807]\ttraining's binary_logloss: 0.0542483\n",
      "[9808]\ttraining's binary_logloss: 0.0542428\n",
      "[9809]\ttraining's binary_logloss: 0.0542399\n",
      "[9810]\ttraining's binary_logloss: 0.0542345\n",
      "[9811]\ttraining's binary_logloss: 0.054229\n",
      "[9812]\ttraining's binary_logloss: 0.0542263\n",
      "[9813]\ttraining's binary_logloss: 0.0542213\n",
      "[9814]\ttraining's binary_logloss: 0.0542169\n",
      "[9815]\ttraining's binary_logloss: 0.0542114\n",
      "[9816]\ttraining's binary_logloss: 0.0542058\n",
      "[9817]\ttraining's binary_logloss: 0.0542005\n",
      "[9818]\ttraining's binary_logloss: 0.054195\n",
      "[9819]\ttraining's binary_logloss: 0.05419\n",
      "[9820]\ttraining's binary_logloss: 0.0541844\n",
      "[9821]\ttraining's binary_logloss: 0.0541815\n",
      "[9822]\ttraining's binary_logloss: 0.0541746\n",
      "[9823]\ttraining's binary_logloss: 0.0541706\n",
      "[9824]\ttraining's binary_logloss: 0.054166\n",
      "[9825]\ttraining's binary_logloss: 0.0541607\n",
      "[9826]\ttraining's binary_logloss: 0.0541581\n",
      "[9827]\ttraining's binary_logloss: 0.0541527\n",
      "[9828]\ttraining's binary_logloss: 0.0541519\n",
      "[9829]\ttraining's binary_logloss: 0.0541466\n",
      "[9830]\ttraining's binary_logloss: 0.0541409\n",
      "[9831]\ttraining's binary_logloss: 0.0541339\n",
      "[9832]\ttraining's binary_logloss: 0.0541313\n",
      "[9833]\ttraining's binary_logloss: 0.0541256\n",
      "[9834]\ttraining's binary_logloss: 0.0541196\n",
      "[9835]\ttraining's binary_logloss: 0.0541181\n",
      "[9836]\ttraining's binary_logloss: 0.0541132\n",
      "[9837]\ttraining's binary_logloss: 0.0541069\n",
      "[9838]\ttraining's binary_logloss: 0.0541017\n",
      "[9839]\ttraining's binary_logloss: 0.0540955\n",
      "[9840]\ttraining's binary_logloss: 0.0540899\n",
      "[9841]\ttraining's binary_logloss: 0.054085\n",
      "[9842]\ttraining's binary_logloss: 0.054079\n",
      "[9843]\ttraining's binary_logloss: 0.0540744\n",
      "[9844]\ttraining's binary_logloss: 0.0540704\n",
      "[9845]\ttraining's binary_logloss: 0.0540645\n",
      "[9846]\ttraining's binary_logloss: 0.0540592\n",
      "[9847]\ttraining's binary_logloss: 0.0540527\n",
      "[9848]\ttraining's binary_logloss: 0.0540485\n",
      "[9849]\ttraining's binary_logloss: 0.0540419\n",
      "[9850]\ttraining's binary_logloss: 0.0540359\n",
      "[9851]\ttraining's binary_logloss: 0.0540296\n",
      "[9852]\ttraining's binary_logloss: 0.054024\n",
      "[9853]\ttraining's binary_logloss: 0.0540182\n",
      "[9854]\ttraining's binary_logloss: 0.0540132\n",
      "[9855]\ttraining's binary_logloss: 0.0540096\n",
      "[9856]\ttraining's binary_logloss: 0.0540053\n",
      "[9857]\ttraining's binary_logloss: 0.0539998\n",
      "[9858]\ttraining's binary_logloss: 0.0539939\n",
      "[9859]\ttraining's binary_logloss: 0.0539888\n",
      "[9860]\ttraining's binary_logloss: 0.0539839\n",
      "[9861]\ttraining's binary_logloss: 0.0539779\n",
      "[9862]\ttraining's binary_logloss: 0.0539724\n",
      "[9863]\ttraining's binary_logloss: 0.0539686\n",
      "[9864]\ttraining's binary_logloss: 0.0539626\n",
      "[9865]\ttraining's binary_logloss: 0.0539568\n",
      "[9866]\ttraining's binary_logloss: 0.0539535\n",
      "[9867]\ttraining's binary_logloss: 0.0539486\n",
      "[9868]\ttraining's binary_logloss: 0.0539428\n",
      "[9869]\ttraining's binary_logloss: 0.0539379\n",
      "[9870]\ttraining's binary_logloss: 0.0539325\n",
      "[9871]\ttraining's binary_logloss: 0.0539265\n",
      "[9872]\ttraining's binary_logloss: 0.0539203\n",
      "[9873]\ttraining's binary_logloss: 0.0539145\n",
      "[9874]\ttraining's binary_logloss: 0.0539091\n",
      "[9875]\ttraining's binary_logloss: 0.0539027\n",
      "[9876]\ttraining's binary_logloss: 0.0538989\n",
      "[9877]\ttraining's binary_logloss: 0.0538952\n",
      "[9878]\ttraining's binary_logloss: 0.0538902\n",
      "[9879]\ttraining's binary_logloss: 0.0538843\n",
      "[9880]\ttraining's binary_logloss: 0.053878\n",
      "[9881]\ttraining's binary_logloss: 0.0538722\n",
      "[9882]\ttraining's binary_logloss: 0.0538664\n",
      "[9883]\ttraining's binary_logloss: 0.0538601\n",
      "[9884]\ttraining's binary_logloss: 0.0538549\n",
      "[9885]\ttraining's binary_logloss: 0.0538493\n",
      "[9886]\ttraining's binary_logloss: 0.0538439\n",
      "[9887]\ttraining's binary_logloss: 0.0538381\n",
      "[9888]\ttraining's binary_logloss: 0.0538312\n",
      "[9889]\ttraining's binary_logloss: 0.0538258\n",
      "[9890]\ttraining's binary_logloss: 0.0538216\n",
      "[9891]\ttraining's binary_logloss: 0.0538161\n",
      "[9892]\ttraining's binary_logloss: 0.0538106\n",
      "[9893]\ttraining's binary_logloss: 0.0538059\n",
      "[9894]\ttraining's binary_logloss: 0.0537992\n",
      "[9895]\ttraining's binary_logloss: 0.0537932\n",
      "[9896]\ttraining's binary_logloss: 0.053789\n",
      "[9897]\ttraining's binary_logloss: 0.0537833\n",
      "[9898]\ttraining's binary_logloss: 0.0537778\n",
      "[9899]\ttraining's binary_logloss: 0.0537733\n",
      "[9900]\ttraining's binary_logloss: 0.0537678\n",
      "[9901]\ttraining's binary_logloss: 0.0537642\n",
      "[9902]\ttraining's binary_logloss: 0.0537589\n",
      "[9903]\ttraining's binary_logloss: 0.0537531\n",
      "[9904]\ttraining's binary_logloss: 0.053748\n",
      "[9905]\ttraining's binary_logloss: 0.0537444\n",
      "[9906]\ttraining's binary_logloss: 0.0537387\n",
      "[9907]\ttraining's binary_logloss: 0.0537327\n",
      "[9908]\ttraining's binary_logloss: 0.0537279\n",
      "[9909]\ttraining's binary_logloss: 0.0537251\n",
      "[9910]\ttraining's binary_logloss: 0.0537196\n",
      "[9911]\ttraining's binary_logloss: 0.0537149\n",
      "[9912]\ttraining's binary_logloss: 0.0537096\n",
      "[9913]\ttraining's binary_logloss: 0.0537069\n",
      "[9914]\ttraining's binary_logloss: 0.0537\n",
      "[9915]\ttraining's binary_logloss: 0.0536959\n",
      "[9916]\ttraining's binary_logloss: 0.0536906\n",
      "[9917]\ttraining's binary_logloss: 0.0536851\n",
      "[9918]\ttraining's binary_logloss: 0.0536798\n",
      "[9919]\ttraining's binary_logloss: 0.0536741\n",
      "[9920]\ttraining's binary_logloss: 0.0536705\n",
      "[9921]\ttraining's binary_logloss: 0.0536648\n",
      "[9922]\ttraining's binary_logloss: 0.0536589\n",
      "[9923]\ttraining's binary_logloss: 0.0536552\n",
      "[9924]\ttraining's binary_logloss: 0.0536522\n",
      "[9925]\ttraining's binary_logloss: 0.0536478\n",
      "[9926]\ttraining's binary_logloss: 0.0536441\n",
      "[9927]\ttraining's binary_logloss: 0.053638\n",
      "[9928]\ttraining's binary_logloss: 0.0536344\n",
      "[9929]\ttraining's binary_logloss: 0.0536301\n",
      "[9930]\ttraining's binary_logloss: 0.0536251\n",
      "[9931]\ttraining's binary_logloss: 0.0536184\n",
      "[9932]\ttraining's binary_logloss: 0.0536124\n",
      "[9933]\ttraining's binary_logloss: 0.0536079\n",
      "[9934]\ttraining's binary_logloss: 0.0536025\n",
      "[9935]\ttraining's binary_logloss: 0.0535966\n",
      "[9936]\ttraining's binary_logloss: 0.0535938\n",
      "[9937]\ttraining's binary_logloss: 0.0535881\n",
      "[9938]\ttraining's binary_logloss: 0.0535822\n",
      "[9939]\ttraining's binary_logloss: 0.0535768\n",
      "[9940]\ttraining's binary_logloss: 0.0535752\n",
      "[9941]\ttraining's binary_logloss: 0.0535703\n",
      "[9942]\ttraining's binary_logloss: 0.0535664\n",
      "[9943]\ttraining's binary_logloss: 0.0535605\n",
      "[9944]\ttraining's binary_logloss: 0.0535555\n",
      "[9945]\ttraining's binary_logloss: 0.0535516\n",
      "[9946]\ttraining's binary_logloss: 0.0535467\n",
      "[9947]\ttraining's binary_logloss: 0.0535408\n",
      "[9948]\ttraining's binary_logloss: 0.053536\n",
      "[9949]\ttraining's binary_logloss: 0.0535304\n",
      "[9950]\ttraining's binary_logloss: 0.0535252\n",
      "[9951]\ttraining's binary_logloss: 0.0535199\n",
      "[9952]\ttraining's binary_logloss: 0.0535145\n",
      "[9953]\ttraining's binary_logloss: 0.0535093\n",
      "[9954]\ttraining's binary_logloss: 0.0535042\n",
      "[9955]\ttraining's binary_logloss: 0.0534991\n",
      "[9956]\ttraining's binary_logloss: 0.0534933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9957]\ttraining's binary_logloss: 0.053488\n",
      "[9958]\ttraining's binary_logloss: 0.0534833\n",
      "[9959]\ttraining's binary_logloss: 0.0534779\n",
      "[9960]\ttraining's binary_logloss: 0.0534721\n",
      "[9961]\ttraining's binary_logloss: 0.0534674\n",
      "[9962]\ttraining's binary_logloss: 0.0534619\n",
      "[9963]\ttraining's binary_logloss: 0.0534569\n",
      "[9964]\ttraining's binary_logloss: 0.0534508\n",
      "[9965]\ttraining's binary_logloss: 0.0534461\n",
      "[9966]\ttraining's binary_logloss: 0.0534433\n",
      "[9967]\ttraining's binary_logloss: 0.0534374\n",
      "[9968]\ttraining's binary_logloss: 0.0534313\n",
      "[9969]\ttraining's binary_logloss: 0.0534261\n",
      "[9970]\ttraining's binary_logloss: 0.0534205\n",
      "[9971]\ttraining's binary_logloss: 0.0534148\n",
      "[9972]\ttraining's binary_logloss: 0.0534102\n",
      "[9973]\ttraining's binary_logloss: 0.0534054\n",
      "[9974]\ttraining's binary_logloss: 0.0534028\n",
      "[9975]\ttraining's binary_logloss: 0.0533973\n",
      "[9976]\ttraining's binary_logloss: 0.0533917\n",
      "[9977]\ttraining's binary_logloss: 0.053387\n",
      "[9978]\ttraining's binary_logloss: 0.0533816\n",
      "[9979]\ttraining's binary_logloss: 0.0533762\n",
      "[9980]\ttraining's binary_logloss: 0.0533709\n",
      "[9981]\ttraining's binary_logloss: 0.0533674\n",
      "[9982]\ttraining's binary_logloss: 0.0533625\n",
      "[9983]\ttraining's binary_logloss: 0.0533568\n",
      "[9984]\ttraining's binary_logloss: 0.0533507\n",
      "[9985]\ttraining's binary_logloss: 0.0533452\n",
      "[9986]\ttraining's binary_logloss: 0.0533401\n",
      "[9987]\ttraining's binary_logloss: 0.0533344\n",
      "[9988]\ttraining's binary_logloss: 0.0533293\n",
      "[9989]\ttraining's binary_logloss: 0.0533276\n",
      "[9990]\ttraining's binary_logloss: 0.0533224\n",
      "[9991]\ttraining's binary_logloss: 0.0533169\n",
      "[9992]\ttraining's binary_logloss: 0.0533116\n",
      "[9993]\ttraining's binary_logloss: 0.0533061\n",
      "[9994]\ttraining's binary_logloss: 0.0533026\n",
      "[9995]\ttraining's binary_logloss: 0.0532979\n",
      "[9996]\ttraining's binary_logloss: 0.0532928\n",
      "[9997]\ttraining's binary_logloss: 0.0532902\n",
      "[9998]\ttraining's binary_logloss: 0.0532849\n",
      "[9999]\ttraining's binary_logloss: 0.0532814\n",
      "[10000]\ttraining's binary_logloss: 0.0532784\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    nthread=4,\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=34,\n",
    "    colsample_bytree=0.9497036,\n",
    "    subsample=0.8715623,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.041545473,\n",
    "    reg_lambda=0.0735294,\n",
    "    min_split_gain=0.0222415,\n",
    "    min_child_weight=39.3259775,\n",
    "    silent=-1,)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric='f1')\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5bee9560",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test: 0.9531178403571475\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"Score F1 sur l'ensemble de test: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d28afe95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[39169   407]\n",
      " [ 3174 36401]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d88a76ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Initialiser les listes pour stocker les résultats\n",
    "threshold_array = np.linspace(0, 1, 100)\n",
    "f1_list = []\n",
    "\n",
    "# Calculer le F1 pour différents seuils\n",
    "for threshold in threshold_array:\n",
    "    # Labels prédits pour un seuil donné\n",
    "    label_pred_threshold = (probas_pred > threshold).astype(int)\n",
    "    # Calcul du f1 pour un seuil donné\n",
    "    f1_threshold = f1_score(\n",
    "        y_true=y_test, y_pred=label_pred_threshold\n",
    "    )\n",
    "\n",
    "    f1_list.append(f1_threshold)\n",
    "\n",
    "# Trouver l'indice du maximum de la liste des scores F1\n",
    "best_threshold_index = np.argmax(f1_list)\n",
    "\n",
    "# Récupérer le seuil correspondant\n",
    "best_threshold = threshold_array[best_threshold_index]\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.plot(threshold_array, f1_list)\n",
    "plt.xlabel('Seuil')\n",
    "plt.ylabel('Score F1')\n",
    "plt.title('Score F1 en fonction du seuil')\n",
    "plt.scatter(best_threshold, f1_list[best_threshold_index], color='red', label=f'Max F1 at threshold {best_threshold:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ed38ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché avec le seuil optimal: 0.0738537794299876\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_with_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1] > best_threshold).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_with_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché avec le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8deec070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[42240   162]\n",
      " [ 3575   149]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_hide_test, predictions_with_optimal_threshold)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc0d5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché sans le seuil optimal: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_without_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1]).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_without_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché sans le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508789e7",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c417ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 197877, 1: 17377})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "150f6851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac1a0cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 17377, 1: 17377})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_resampled)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "82f429e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n",
      "[1]\ttraining's binary_logloss: 0.677543\n",
      "[2]\ttraining's binary_logloss: 0.662591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttraining's binary_logloss: 0.648213\n",
      "[4]\ttraining's binary_logloss: 0.634358\n",
      "[5]\ttraining's binary_logloss: 0.620909\n",
      "[6]\ttraining's binary_logloss: 0.608042\n",
      "[7]\ttraining's binary_logloss: 0.595529\n",
      "[8]\ttraining's binary_logloss: 0.584148\n",
      "[9]\ttraining's binary_logloss: 0.572275\n",
      "[10]\ttraining's binary_logloss: 0.560948\n",
      "[11]\ttraining's binary_logloss: 0.550046\n",
      "[12]\ttraining's binary_logloss: 0.539493\n",
      "[13]\ttraining's binary_logloss: 0.529302\n",
      "[14]\ttraining's binary_logloss: 0.519201\n",
      "[15]\ttraining's binary_logloss: 0.509622\n",
      "[16]\ttraining's binary_logloss: 0.500294\n",
      "[17]\ttraining's binary_logloss: 0.491403\n",
      "[18]\ttraining's binary_logloss: 0.482766\n",
      "[19]\ttraining's binary_logloss: 0.474799\n",
      "[20]\ttraining's binary_logloss: 0.466565\n",
      "[21]\ttraining's binary_logloss: 0.459049\n",
      "[22]\ttraining's binary_logloss: 0.451645\n",
      "[23]\ttraining's binary_logloss: 0.443854\n",
      "[24]\ttraining's binary_logloss: 0.436306\n",
      "[25]\ttraining's binary_logloss: 0.429142\n",
      "[26]\ttraining's binary_logloss: 0.422024\n",
      "[27]\ttraining's binary_logloss: 0.415197\n",
      "[28]\ttraining's binary_logloss: 0.408546\n",
      "[29]\ttraining's binary_logloss: 0.402134\n",
      "[30]\ttraining's binary_logloss: 0.395955\n",
      "[31]\ttraining's binary_logloss: 0.389937\n",
      "[32]\ttraining's binary_logloss: 0.383964\n",
      "[33]\ttraining's binary_logloss: 0.378277\n",
      "[34]\ttraining's binary_logloss: 0.37277\n",
      "[35]\ttraining's binary_logloss: 0.367349\n",
      "[36]\ttraining's binary_logloss: 0.361887\n",
      "[37]\ttraining's binary_logloss: 0.35698\n",
      "[38]\ttraining's binary_logloss: 0.351801\n",
      "[39]\ttraining's binary_logloss: 0.346646\n",
      "[40]\ttraining's binary_logloss: 0.341876\n",
      "[41]\ttraining's binary_logloss: 0.337183\n",
      "[42]\ttraining's binary_logloss: 0.332574\n",
      "[43]\ttraining's binary_logloss: 0.327769\n",
      "[44]\ttraining's binary_logloss: 0.323439\n",
      "[45]\ttraining's binary_logloss: 0.31903\n",
      "[46]\ttraining's binary_logloss: 0.314458\n",
      "[47]\ttraining's binary_logloss: 0.310413\n",
      "[48]\ttraining's binary_logloss: 0.306171\n",
      "[49]\ttraining's binary_logloss: 0.302362\n",
      "[50]\ttraining's binary_logloss: 0.298397\n",
      "[51]\ttraining's binary_logloss: 0.294499\n",
      "[52]\ttraining's binary_logloss: 0.290836\n",
      "[53]\ttraining's binary_logloss: 0.287495\n",
      "[54]\ttraining's binary_logloss: 0.283673\n",
      "[55]\ttraining's binary_logloss: 0.280314\n",
      "[56]\ttraining's binary_logloss: 0.276987\n",
      "[57]\ttraining's binary_logloss: 0.273708\n",
      "[58]\ttraining's binary_logloss: 0.270531\n",
      "[59]\ttraining's binary_logloss: 0.267412\n",
      "[60]\ttraining's binary_logloss: 0.264522\n",
      "[61]\ttraining's binary_logloss: 0.261406\n",
      "[62]\ttraining's binary_logloss: 0.258322\n",
      "[63]\ttraining's binary_logloss: 0.255335\n",
      "[64]\ttraining's binary_logloss: 0.252583\n",
      "[65]\ttraining's binary_logloss: 0.249975\n",
      "[66]\ttraining's binary_logloss: 0.247428\n",
      "[67]\ttraining's binary_logloss: 0.24443\n",
      "[68]\ttraining's binary_logloss: 0.241839\n",
      "[69]\ttraining's binary_logloss: 0.239345\n",
      "[70]\ttraining's binary_logloss: 0.236804\n",
      "[71]\ttraining's binary_logloss: 0.234196\n",
      "[72]\ttraining's binary_logloss: 0.231737\n",
      "[73]\ttraining's binary_logloss: 0.229475\n",
      "[74]\ttraining's binary_logloss: 0.226822\n",
      "[75]\ttraining's binary_logloss: 0.224722\n",
      "[76]\ttraining's binary_logloss: 0.222038\n",
      "[77]\ttraining's binary_logloss: 0.219403\n",
      "[78]\ttraining's binary_logloss: 0.217391\n",
      "[79]\ttraining's binary_logloss: 0.215027\n",
      "[80]\ttraining's binary_logloss: 0.21275\n",
      "[81]\ttraining's binary_logloss: 0.21058\n",
      "[82]\ttraining's binary_logloss: 0.208315\n",
      "[83]\ttraining's binary_logloss: 0.206124\n",
      "[84]\ttraining's binary_logloss: 0.204101\n",
      "[85]\ttraining's binary_logloss: 0.202099\n",
      "[86]\ttraining's binary_logloss: 0.200123\n",
      "[87]\ttraining's binary_logloss: 0.198124\n",
      "[88]\ttraining's binary_logloss: 0.196045\n",
      "[89]\ttraining's binary_logloss: 0.194196\n",
      "[90]\ttraining's binary_logloss: 0.192272\n",
      "[91]\ttraining's binary_logloss: 0.190313\n",
      "[92]\ttraining's binary_logloss: 0.188565\n",
      "[93]\ttraining's binary_logloss: 0.186838\n",
      "[94]\ttraining's binary_logloss: 0.185128\n",
      "[95]\ttraining's binary_logloss: 0.183389\n",
      "[96]\ttraining's binary_logloss: 0.18143\n",
      "[97]\ttraining's binary_logloss: 0.179661\n",
      "[98]\ttraining's binary_logloss: 0.178069\n",
      "[99]\ttraining's binary_logloss: 0.176485\n",
      "[100]\ttraining's binary_logloss: 0.17462\n",
      "[101]\ttraining's binary_logloss: 0.173074\n",
      "[102]\ttraining's binary_logloss: 0.171595\n",
      "[103]\ttraining's binary_logloss: 0.169744\n",
      "[104]\ttraining's binary_logloss: 0.168356\n",
      "[105]\ttraining's binary_logloss: 0.167047\n",
      "[106]\ttraining's binary_logloss: 0.165413\n",
      "[107]\ttraining's binary_logloss: 0.164004\n",
      "[108]\ttraining's binary_logloss: 0.162433\n",
      "[109]\ttraining's binary_logloss: 0.161028\n",
      "[110]\ttraining's binary_logloss: 0.159515\n",
      "[111]\ttraining's binary_logloss: 0.158119\n",
      "[112]\ttraining's binary_logloss: 0.156863\n",
      "[113]\ttraining's binary_logloss: 0.155546\n",
      "[114]\ttraining's binary_logloss: 0.154139\n",
      "[115]\ttraining's binary_logloss: 0.152973\n",
      "[116]\ttraining's binary_logloss: 0.151693\n",
      "[117]\ttraining's binary_logloss: 0.150527\n",
      "[118]\ttraining's binary_logloss: 0.14912\n",
      "[119]\ttraining's binary_logloss: 0.147806\n",
      "[120]\ttraining's binary_logloss: 0.146626\n",
      "[121]\ttraining's binary_logloss: 0.145321\n",
      "[122]\ttraining's binary_logloss: 0.144239\n",
      "[123]\ttraining's binary_logloss: 0.142976\n",
      "[124]\ttraining's binary_logloss: 0.141877\n",
      "[125]\ttraining's binary_logloss: 0.140838\n",
      "[126]\ttraining's binary_logloss: 0.139652\n",
      "[127]\ttraining's binary_logloss: 0.13855\n",
      "[128]\ttraining's binary_logloss: 0.137164\n",
      "[129]\ttraining's binary_logloss: 0.136047\n",
      "[130]\ttraining's binary_logloss: 0.134798\n",
      "[131]\ttraining's binary_logloss: 0.133595\n",
      "[132]\ttraining's binary_logloss: 0.132397\n",
      "[133]\ttraining's binary_logloss: 0.131566\n",
      "[134]\ttraining's binary_logloss: 0.13044\n",
      "[135]\ttraining's binary_logloss: 0.129309\n",
      "[136]\ttraining's binary_logloss: 0.128158\n",
      "[137]\ttraining's binary_logloss: 0.127008\n",
      "[138]\ttraining's binary_logloss: 0.125899\n",
      "[139]\ttraining's binary_logloss: 0.124831\n",
      "[140]\ttraining's binary_logloss: 0.12377\n",
      "[141]\ttraining's binary_logloss: 0.122758\n",
      "[142]\ttraining's binary_logloss: 0.122037\n",
      "[143]\ttraining's binary_logloss: 0.121024\n",
      "[144]\ttraining's binary_logloss: 0.120055\n",
      "[145]\ttraining's binary_logloss: 0.119067\n",
      "[146]\ttraining's binary_logloss: 0.11834\n",
      "[147]\ttraining's binary_logloss: 0.117399\n",
      "[148]\ttraining's binary_logloss: 0.116449\n",
      "[149]\ttraining's binary_logloss: 0.115531\n",
      "[150]\ttraining's binary_logloss: 0.114659\n",
      "[151]\ttraining's binary_logloss: 0.113723\n",
      "[152]\ttraining's binary_logloss: 0.112828\n",
      "[153]\ttraining's binary_logloss: 0.111996\n",
      "[154]\ttraining's binary_logloss: 0.111126\n",
      "[155]\ttraining's binary_logloss: 0.110276\n",
      "[156]\ttraining's binary_logloss: 0.109692\n",
      "[157]\ttraining's binary_logloss: 0.108919\n",
      "[158]\ttraining's binary_logloss: 0.108082\n",
      "[159]\ttraining's binary_logloss: 0.107186\n",
      "[160]\ttraining's binary_logloss: 0.106424\n",
      "[161]\ttraining's binary_logloss: 0.105688\n",
      "[162]\ttraining's binary_logloss: 0.104932\n",
      "[163]\ttraining's binary_logloss: 0.104238\n",
      "[164]\ttraining's binary_logloss: 0.103723\n",
      "[165]\ttraining's binary_logloss: 0.102864\n",
      "[166]\ttraining's binary_logloss: 0.10213\n",
      "[167]\ttraining's binary_logloss: 0.101336\n",
      "[168]\ttraining's binary_logloss: 0.100553\n",
      "[169]\ttraining's binary_logloss: 0.0999628\n",
      "[170]\ttraining's binary_logloss: 0.0995041\n",
      "[171]\ttraining's binary_logloss: 0.0988291\n",
      "[172]\ttraining's binary_logloss: 0.0980661\n",
      "[173]\ttraining's binary_logloss: 0.0975616\n",
      "[174]\ttraining's binary_logloss: 0.0970597\n",
      "[175]\ttraining's binary_logloss: 0.0965049\n",
      "[176]\ttraining's binary_logloss: 0.0957649\n",
      "[177]\ttraining's binary_logloss: 0.0952398\n",
      "[178]\ttraining's binary_logloss: 0.0946413\n",
      "[179]\ttraining's binary_logloss: 0.0941946\n",
      "[180]\ttraining's binary_logloss: 0.0936845\n",
      "[181]\ttraining's binary_logloss: 0.0930297\n",
      "[182]\ttraining's binary_logloss: 0.0926429\n",
      "[183]\ttraining's binary_logloss: 0.0922019\n",
      "[184]\ttraining's binary_logloss: 0.091581\n",
      "[185]\ttraining's binary_logloss: 0.0911626\n",
      "[186]\ttraining's binary_logloss: 0.0906481\n",
      "[187]\ttraining's binary_logloss: 0.090184\n",
      "[188]\ttraining's binary_logloss: 0.0896516\n",
      "[189]\ttraining's binary_logloss: 0.0892864\n",
      "[190]\ttraining's binary_logloss: 0.0888589\n",
      "[191]\ttraining's binary_logloss: 0.0885133\n",
      "[192]\ttraining's binary_logloss: 0.0879194\n",
      "[193]\ttraining's binary_logloss: 0.087573\n",
      "[194]\ttraining's binary_logloss: 0.0871692\n",
      "[195]\ttraining's binary_logloss: 0.0867493\n",
      "[196]\ttraining's binary_logloss: 0.0862114\n",
      "[197]\ttraining's binary_logloss: 0.0858831\n",
      "[198]\ttraining's binary_logloss: 0.0853936\n",
      "[199]\ttraining's binary_logloss: 0.0850106\n",
      "[200]\ttraining's binary_logloss: 0.0846416\n",
      "[201]\ttraining's binary_logloss: 0.0842467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\ttraining's binary_logloss: 0.0837288\n",
      "[203]\ttraining's binary_logloss: 0.0834156\n",
      "[204]\ttraining's binary_logloss: 0.0829047\n",
      "[205]\ttraining's binary_logloss: 0.0825675\n",
      "[206]\ttraining's binary_logloss: 0.0822017\n",
      "[207]\ttraining's binary_logloss: 0.0818977\n",
      "[208]\ttraining's binary_logloss: 0.0815941\n",
      "[209]\ttraining's binary_logloss: 0.0810972\n",
      "[210]\ttraining's binary_logloss: 0.0806767\n",
      "[211]\ttraining's binary_logloss: 0.0803655\n",
      "[212]\ttraining's binary_logloss: 0.080019\n",
      "[213]\ttraining's binary_logloss: 0.0797005\n",
      "[214]\ttraining's binary_logloss: 0.0793231\n",
      "[215]\ttraining's binary_logloss: 0.0789976\n",
      "[216]\ttraining's binary_logloss: 0.0786207\n",
      "[217]\ttraining's binary_logloss: 0.0783097\n",
      "[218]\ttraining's binary_logloss: 0.077907\n",
      "[219]\ttraining's binary_logloss: 0.0776109\n",
      "[220]\ttraining's binary_logloss: 0.077268\n",
      "[221]\ttraining's binary_logloss: 0.0769852\n",
      "[222]\ttraining's binary_logloss: 0.0766449\n",
      "[223]\ttraining's binary_logloss: 0.0762519\n",
      "[224]\ttraining's binary_logloss: 0.0759889\n",
      "[225]\ttraining's binary_logloss: 0.0756846\n",
      "[226]\ttraining's binary_logloss: 0.0754257\n",
      "[227]\ttraining's binary_logloss: 0.0751036\n",
      "[228]\ttraining's binary_logloss: 0.0748287\n",
      "[229]\ttraining's binary_logloss: 0.074525\n",
      "[230]\ttraining's binary_logloss: 0.0742175\n",
      "[231]\ttraining's binary_logloss: 0.0738797\n",
      "[232]\ttraining's binary_logloss: 0.0736288\n",
      "[233]\ttraining's binary_logloss: 0.0733347\n",
      "[234]\ttraining's binary_logloss: 0.0730556\n",
      "[235]\ttraining's binary_logloss: 0.0728343\n",
      "[236]\ttraining's binary_logloss: 0.0725153\n",
      "[237]\ttraining's binary_logloss: 0.072252\n",
      "[238]\ttraining's binary_logloss: 0.0718821\n",
      "[239]\ttraining's binary_logloss: 0.0716621\n",
      "[240]\ttraining's binary_logloss: 0.0713849\n",
      "[241]\ttraining's binary_logloss: 0.0711393\n",
      "[242]\ttraining's binary_logloss: 0.0708457\n",
      "[243]\ttraining's binary_logloss: 0.0704886\n",
      "[244]\ttraining's binary_logloss: 0.0702323\n",
      "[245]\ttraining's binary_logloss: 0.0699827\n",
      "[246]\ttraining's binary_logloss: 0.0696207\n",
      "[247]\ttraining's binary_logloss: 0.0694037\n",
      "[248]\ttraining's binary_logloss: 0.0691461\n",
      "[249]\ttraining's binary_logloss: 0.0689006\n",
      "[250]\ttraining's binary_logloss: 0.06865\n",
      "[251]\ttraining's binary_logloss: 0.0684112\n",
      "[252]\ttraining's binary_logloss: 0.0681721\n",
      "[253]\ttraining's binary_logloss: 0.0679066\n",
      "[254]\ttraining's binary_logloss: 0.0676957\n",
      "[255]\ttraining's binary_logloss: 0.0673826\n",
      "[256]\ttraining's binary_logloss: 0.0671638\n",
      "[257]\ttraining's binary_logloss: 0.066974\n",
      "[258]\ttraining's binary_logloss: 0.0667722\n",
      "[259]\ttraining's binary_logloss: 0.0665713\n",
      "[260]\ttraining's binary_logloss: 0.0663584\n",
      "[261]\ttraining's binary_logloss: 0.066137\n",
      "[262]\ttraining's binary_logloss: 0.0659396\n",
      "[263]\ttraining's binary_logloss: 0.065708\n",
      "[264]\ttraining's binary_logloss: 0.0655182\n",
      "[265]\ttraining's binary_logloss: 0.0652341\n",
      "[266]\ttraining's binary_logloss: 0.0650305\n",
      "[267]\ttraining's binary_logloss: 0.0648356\n",
      "[268]\ttraining's binary_logloss: 0.0646254\n",
      "[269]\ttraining's binary_logloss: 0.0644321\n",
      "[270]\ttraining's binary_logloss: 0.064245\n",
      "[271]\ttraining's binary_logloss: 0.0639742\n",
      "[272]\ttraining's binary_logloss: 0.0638061\n",
      "[273]\ttraining's binary_logloss: 0.063616\n",
      "[274]\ttraining's binary_logloss: 0.0634487\n",
      "[275]\ttraining's binary_logloss: 0.0633007\n",
      "[276]\ttraining's binary_logloss: 0.0630273\n",
      "[277]\ttraining's binary_logloss: 0.0628271\n",
      "[278]\ttraining's binary_logloss: 0.0626356\n",
      "[279]\ttraining's binary_logloss: 0.0624628\n",
      "[280]\ttraining's binary_logloss: 0.0622898\n",
      "[281]\ttraining's binary_logloss: 0.0621506\n",
      "[282]\ttraining's binary_logloss: 0.0619891\n",
      "[283]\ttraining's binary_logloss: 0.0618279\n",
      "[284]\ttraining's binary_logloss: 0.0616545\n",
      "[285]\ttraining's binary_logloss: 0.0615046\n",
      "[286]\ttraining's binary_logloss: 0.061232\n",
      "[287]\ttraining's binary_logloss: 0.0610542\n",
      "[288]\ttraining's binary_logloss: 0.0608828\n",
      "[289]\ttraining's binary_logloss: 0.0607123\n",
      "[290]\ttraining's binary_logloss: 0.0605576\n",
      "[291]\ttraining's binary_logloss: 0.0603971\n",
      "[292]\ttraining's binary_logloss: 0.0602285\n",
      "[293]\ttraining's binary_logloss: 0.0600929\n",
      "[294]\ttraining's binary_logloss: 0.0599317\n",
      "[295]\ttraining's binary_logloss: 0.0597865\n",
      "[296]\ttraining's binary_logloss: 0.0595189\n",
      "[297]\ttraining's binary_logloss: 0.0593739\n",
      "[298]\ttraining's binary_logloss: 0.0592172\n",
      "[299]\ttraining's binary_logloss: 0.0590657\n",
      "[300]\ttraining's binary_logloss: 0.0589219\n",
      "[301]\ttraining's binary_logloss: 0.0587792\n",
      "[302]\ttraining's binary_logloss: 0.058594\n",
      "[303]\ttraining's binary_logloss: 0.0584765\n",
      "[304]\ttraining's binary_logloss: 0.058337\n",
      "[305]\ttraining's binary_logloss: 0.0581963\n",
      "[306]\ttraining's binary_logloss: 0.0580526\n",
      "[307]\ttraining's binary_logloss: 0.0579194\n",
      "[308]\ttraining's binary_logloss: 0.0576665\n",
      "[309]\ttraining's binary_logloss: 0.057537\n",
      "[310]\ttraining's binary_logloss: 0.0573953\n",
      "[311]\ttraining's binary_logloss: 0.0572537\n",
      "[312]\ttraining's binary_logloss: 0.0571122\n",
      "[313]\ttraining's binary_logloss: 0.0568735\n",
      "[314]\ttraining's binary_logloss: 0.0567515\n",
      "[315]\ttraining's binary_logloss: 0.056613\n",
      "[316]\ttraining's binary_logloss: 0.056504\n",
      "[317]\ttraining's binary_logloss: 0.0563795\n",
      "[318]\ttraining's binary_logloss: 0.0562409\n",
      "[319]\ttraining's binary_logloss: 0.0561209\n",
      "[320]\ttraining's binary_logloss: 0.0558944\n",
      "[321]\ttraining's binary_logloss: 0.0557669\n",
      "[322]\ttraining's binary_logloss: 0.0556364\n",
      "[323]\ttraining's binary_logloss: 0.0555231\n",
      "[324]\ttraining's binary_logloss: 0.0554097\n",
      "[325]\ttraining's binary_logloss: 0.0552893\n",
      "[326]\ttraining's binary_logloss: 0.0550584\n",
      "[327]\ttraining's binary_logloss: 0.0549428\n",
      "[328]\ttraining's binary_logloss: 0.0547887\n",
      "[329]\ttraining's binary_logloss: 0.0546538\n",
      "[330]\ttraining's binary_logloss: 0.0545333\n",
      "[331]\ttraining's binary_logloss: 0.0544389\n",
      "[332]\ttraining's binary_logloss: 0.054323\n",
      "[333]\ttraining's binary_logloss: 0.0542096\n",
      "[334]\ttraining's binary_logloss: 0.0539947\n",
      "[335]\ttraining's binary_logloss: 0.0538902\n",
      "[336]\ttraining's binary_logloss: 0.0537702\n",
      "[337]\ttraining's binary_logloss: 0.0536811\n",
      "[338]\ttraining's binary_logloss: 0.0535714\n",
      "[339]\ttraining's binary_logloss: 0.0534576\n",
      "[340]\ttraining's binary_logloss: 0.0533523\n",
      "[341]\ttraining's binary_logloss: 0.053154\n",
      "[342]\ttraining's binary_logloss: 0.053048\n",
      "[343]\ttraining's binary_logloss: 0.0529364\n",
      "[344]\ttraining's binary_logloss: 0.0528236\n",
      "[345]\ttraining's binary_logloss: 0.0527235\n",
      "[346]\ttraining's binary_logloss: 0.0526326\n",
      "[347]\ttraining's binary_logloss: 0.0525381\n",
      "[348]\ttraining's binary_logloss: 0.0524486\n",
      "[349]\ttraining's binary_logloss: 0.0522718\n",
      "[350]\ttraining's binary_logloss: 0.0521587\n",
      "[351]\ttraining's binary_logloss: 0.0520621\n",
      "[352]\ttraining's binary_logloss: 0.051976\n",
      "[353]\ttraining's binary_logloss: 0.051874\n",
      "[354]\ttraining's binary_logloss: 0.0517625\n",
      "[355]\ttraining's binary_logloss: 0.0516513\n",
      "[356]\ttraining's binary_logloss: 0.0515533\n",
      "[357]\ttraining's binary_logloss: 0.0514438\n",
      "[358]\ttraining's binary_logloss: 0.0512783\n",
      "[359]\ttraining's binary_logloss: 0.0511592\n",
      "[360]\ttraining's binary_logloss: 0.0510689\n",
      "[361]\ttraining's binary_logloss: 0.050974\n",
      "[362]\ttraining's binary_logloss: 0.0508761\n",
      "[363]\ttraining's binary_logloss: 0.0507157\n",
      "[364]\ttraining's binary_logloss: 0.0506167\n",
      "[365]\ttraining's binary_logloss: 0.0505073\n",
      "[366]\ttraining's binary_logloss: 0.0504175\n",
      "[367]\ttraining's binary_logloss: 0.0503406\n",
      "[368]\ttraining's binary_logloss: 0.0502419\n",
      "[369]\ttraining's binary_logloss: 0.0501004\n",
      "[370]\ttraining's binary_logloss: 0.0500064\n",
      "[371]\ttraining's binary_logloss: 0.0499183\n",
      "[372]\ttraining's binary_logloss: 0.0498268\n",
      "[373]\ttraining's binary_logloss: 0.0497362\n",
      "[374]\ttraining's binary_logloss: 0.0496408\n",
      "[375]\ttraining's binary_logloss: 0.0494725\n",
      "[376]\ttraining's binary_logloss: 0.0493913\n",
      "[377]\ttraining's binary_logloss: 0.0492946\n",
      "[378]\ttraining's binary_logloss: 0.0491919\n",
      "[379]\ttraining's binary_logloss: 0.0491152\n",
      "[380]\ttraining's binary_logloss: 0.0490315\n",
      "[381]\ttraining's binary_logloss: 0.0489572\n",
      "[382]\ttraining's binary_logloss: 0.0488611\n",
      "[383]\ttraining's binary_logloss: 0.0487878\n",
      "[384]\ttraining's binary_logloss: 0.0486288\n",
      "[385]\ttraining's binary_logloss: 0.0485481\n",
      "[386]\ttraining's binary_logloss: 0.048472\n",
      "[387]\ttraining's binary_logloss: 0.0484009\n",
      "[388]\ttraining's binary_logloss: 0.048323\n",
      "[389]\ttraining's binary_logloss: 0.0482443\n",
      "[390]\ttraining's binary_logloss: 0.0480975\n",
      "[391]\ttraining's binary_logloss: 0.0480181\n",
      "[392]\ttraining's binary_logloss: 0.0479257\n",
      "[393]\ttraining's binary_logloss: 0.0477866\n",
      "[394]\ttraining's binary_logloss: 0.0476412\n",
      "[395]\ttraining's binary_logloss: 0.0475552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\ttraining's binary_logloss: 0.0474679\n",
      "[397]\ttraining's binary_logloss: 0.0473871\n",
      "[398]\ttraining's binary_logloss: 0.0473056\n",
      "[399]\ttraining's binary_logloss: 0.047221\n",
      "[400]\ttraining's binary_logloss: 0.0471505\n",
      "[401]\ttraining's binary_logloss: 0.0470673\n",
      "[402]\ttraining's binary_logloss: 0.046994\n",
      "[403]\ttraining's binary_logloss: 0.0469113\n",
      "[404]\ttraining's binary_logloss: 0.0468373\n",
      "[405]\ttraining's binary_logloss: 0.0467521\n",
      "[406]\ttraining's binary_logloss: 0.0466551\n",
      "[407]\ttraining's binary_logloss: 0.0465714\n",
      "[408]\ttraining's binary_logloss: 0.0464484\n",
      "[409]\ttraining's binary_logloss: 0.0463605\n",
      "[410]\ttraining's binary_logloss: 0.046284\n",
      "[411]\ttraining's binary_logloss: 0.0462061\n",
      "[412]\ttraining's binary_logloss: 0.0461392\n",
      "[413]\ttraining's binary_logloss: 0.0460697\n",
      "[414]\ttraining's binary_logloss: 0.0460014\n",
      "[415]\ttraining's binary_logloss: 0.0459387\n",
      "[416]\ttraining's binary_logloss: 0.045857\n",
      "[417]\ttraining's binary_logloss: 0.0457814\n",
      "[418]\ttraining's binary_logloss: 0.0457058\n",
      "[419]\ttraining's binary_logloss: 0.0455789\n",
      "[420]\ttraining's binary_logloss: 0.0455128\n",
      "[421]\ttraining's binary_logloss: 0.0454548\n",
      "[422]\ttraining's binary_logloss: 0.0453819\n",
      "[423]\ttraining's binary_logloss: 0.0452991\n",
      "[424]\ttraining's binary_logloss: 0.0452176\n",
      "[425]\ttraining's binary_logloss: 0.0451416\n",
      "[426]\ttraining's binary_logloss: 0.0450737\n",
      "[427]\ttraining's binary_logloss: 0.0450017\n",
      "[428]\ttraining's binary_logloss: 0.0449299\n",
      "[429]\ttraining's binary_logloss: 0.0448589\n",
      "[430]\ttraining's binary_logloss: 0.0448045\n",
      "[431]\ttraining's binary_logloss: 0.0447435\n",
      "[432]\ttraining's binary_logloss: 0.04466\n",
      "[433]\ttraining's binary_logloss: 0.0445483\n",
      "[434]\ttraining's binary_logloss: 0.0444681\n",
      "[435]\ttraining's binary_logloss: 0.044402\n",
      "[436]\ttraining's binary_logloss: 0.0443365\n",
      "[437]\ttraining's binary_logloss: 0.0442769\n",
      "[438]\ttraining's binary_logloss: 0.0441704\n",
      "[439]\ttraining's binary_logloss: 0.0441034\n",
      "[440]\ttraining's binary_logloss: 0.044037\n",
      "[441]\ttraining's binary_logloss: 0.0439755\n",
      "[442]\ttraining's binary_logloss: 0.0439061\n",
      "[443]\ttraining's binary_logloss: 0.0438468\n",
      "[444]\ttraining's binary_logloss: 0.0437837\n",
      "[445]\ttraining's binary_logloss: 0.0437216\n",
      "[446]\ttraining's binary_logloss: 0.0436216\n",
      "[447]\ttraining's binary_logloss: 0.043551\n",
      "[448]\ttraining's binary_logloss: 0.0434883\n",
      "[449]\ttraining's binary_logloss: 0.043427\n",
      "[450]\ttraining's binary_logloss: 0.0433712\n",
      "[451]\ttraining's binary_logloss: 0.0432979\n",
      "[452]\ttraining's binary_logloss: 0.0432309\n",
      "[453]\ttraining's binary_logloss: 0.0431615\n",
      "[454]\ttraining's binary_logloss: 0.043101\n",
      "[455]\ttraining's binary_logloss: 0.0429804\n",
      "[456]\ttraining's binary_logloss: 0.0429179\n",
      "[457]\ttraining's binary_logloss: 0.0428549\n",
      "[458]\ttraining's binary_logloss: 0.0427919\n",
      "[459]\ttraining's binary_logloss: 0.0427243\n",
      "[460]\ttraining's binary_logloss: 0.0426682\n",
      "[461]\ttraining's binary_logloss: 0.0426141\n",
      "[462]\ttraining's binary_logloss: 0.0425077\n",
      "[463]\ttraining's binary_logloss: 0.0424547\n",
      "[464]\ttraining's binary_logloss: 0.0423986\n",
      "[465]\ttraining's binary_logloss: 0.0423258\n",
      "[466]\ttraining's binary_logloss: 0.0422626\n",
      "[467]\ttraining's binary_logloss: 0.0421947\n",
      "[468]\ttraining's binary_logloss: 0.0421313\n",
      "[469]\ttraining's binary_logloss: 0.0420608\n",
      "[470]\ttraining's binary_logloss: 0.0420134\n",
      "[471]\ttraining's binary_logloss: 0.0419569\n",
      "[472]\ttraining's binary_logloss: 0.0418965\n",
      "[473]\ttraining's binary_logloss: 0.0418477\n",
      "[474]\ttraining's binary_logloss: 0.0417993\n",
      "[475]\ttraining's binary_logloss: 0.0417396\n",
      "[476]\ttraining's binary_logloss: 0.0416807\n",
      "[477]\ttraining's binary_logloss: 0.0415952\n",
      "[478]\ttraining's binary_logloss: 0.0415451\n",
      "[479]\ttraining's binary_logloss: 0.041485\n",
      "[480]\ttraining's binary_logloss: 0.0414352\n",
      "[481]\ttraining's binary_logloss: 0.0413792\n",
      "[482]\ttraining's binary_logloss: 0.0413217\n",
      "[483]\ttraining's binary_logloss: 0.0412605\n",
      "[484]\ttraining's binary_logloss: 0.0412124\n",
      "[485]\ttraining's binary_logloss: 0.0411509\n",
      "[486]\ttraining's binary_logloss: 0.0410844\n",
      "[487]\ttraining's binary_logloss: 0.0410318\n",
      "[488]\ttraining's binary_logloss: 0.0409814\n",
      "[489]\ttraining's binary_logloss: 0.0409048\n",
      "[490]\ttraining's binary_logloss: 0.0408492\n",
      "[491]\ttraining's binary_logloss: 0.0407943\n",
      "[492]\ttraining's binary_logloss: 0.0407394\n",
      "[493]\ttraining's binary_logloss: 0.040685\n",
      "[494]\ttraining's binary_logloss: 0.0406369\n",
      "[495]\ttraining's binary_logloss: 0.0405816\n",
      "[496]\ttraining's binary_logloss: 0.0405062\n",
      "[497]\ttraining's binary_logloss: 0.0404618\n",
      "[498]\ttraining's binary_logloss: 0.0404163\n",
      "[499]\ttraining's binary_logloss: 0.0403725\n",
      "[500]\ttraining's binary_logloss: 0.0403162\n",
      "[501]\ttraining's binary_logloss: 0.0402718\n",
      "[502]\ttraining's binary_logloss: 0.0402126\n",
      "[503]\ttraining's binary_logloss: 0.0401496\n",
      "[504]\ttraining's binary_logloss: 0.0400972\n",
      "[505]\ttraining's binary_logloss: 0.040049\n",
      "[506]\ttraining's binary_logloss: 0.0400048\n",
      "[507]\ttraining's binary_logloss: 0.0399623\n",
      "[508]\ttraining's binary_logloss: 0.0399132\n",
      "[509]\ttraining's binary_logloss: 0.0398568\n",
      "[510]\ttraining's binary_logloss: 0.0398107\n",
      "[511]\ttraining's binary_logloss: 0.0397597\n",
      "[512]\ttraining's binary_logloss: 0.0396977\n",
      "[513]\ttraining's binary_logloss: 0.0396445\n",
      "[514]\ttraining's binary_logloss: 0.0396063\n",
      "[515]\ttraining's binary_logloss: 0.0395549\n",
      "[516]\ttraining's binary_logloss: 0.0395098\n",
      "[517]\ttraining's binary_logloss: 0.0394568\n",
      "[518]\ttraining's binary_logloss: 0.0394129\n",
      "[519]\ttraining's binary_logloss: 0.0393671\n",
      "[520]\ttraining's binary_logloss: 0.0393179\n",
      "[521]\ttraining's binary_logloss: 0.0392682\n",
      "[522]\ttraining's binary_logloss: 0.0392228\n",
      "[523]\ttraining's binary_logloss: 0.0391755\n",
      "[524]\ttraining's binary_logloss: 0.039127\n",
      "[525]\ttraining's binary_logloss: 0.0390863\n",
      "[526]\ttraining's binary_logloss: 0.039046\n",
      "[527]\ttraining's binary_logloss: 0.0389801\n",
      "[528]\ttraining's binary_logloss: 0.0389363\n",
      "[529]\ttraining's binary_logloss: 0.0388934\n",
      "[530]\ttraining's binary_logloss: 0.0388532\n",
      "[531]\ttraining's binary_logloss: 0.0388079\n",
      "[532]\ttraining's binary_logloss: 0.0387568\n",
      "[533]\ttraining's binary_logloss: 0.0387066\n",
      "[534]\ttraining's binary_logloss: 0.0386728\n",
      "[535]\ttraining's binary_logloss: 0.0386279\n",
      "[536]\ttraining's binary_logloss: 0.0385863\n",
      "[537]\ttraining's binary_logloss: 0.0385442\n",
      "[538]\ttraining's binary_logloss: 0.0384985\n",
      "[539]\ttraining's binary_logloss: 0.0384419\n",
      "[540]\ttraining's binary_logloss: 0.0384004\n",
      "[541]\ttraining's binary_logloss: 0.0383664\n",
      "[542]\ttraining's binary_logloss: 0.0383016\n",
      "[543]\ttraining's binary_logloss: 0.0382581\n",
      "[544]\ttraining's binary_logloss: 0.0382088\n",
      "[545]\ttraining's binary_logloss: 0.038167\n",
      "[546]\ttraining's binary_logloss: 0.0381206\n",
      "[547]\ttraining's binary_logloss: 0.0380566\n",
      "[548]\ttraining's binary_logloss: 0.0380094\n",
      "[549]\ttraining's binary_logloss: 0.0379576\n",
      "[550]\ttraining's binary_logloss: 0.0379119\n",
      "[551]\ttraining's binary_logloss: 0.0378654\n",
      "[552]\ttraining's binary_logloss: 0.0378228\n",
      "[553]\ttraining's binary_logloss: 0.0377811\n",
      "[554]\ttraining's binary_logloss: 0.0377385\n",
      "[555]\ttraining's binary_logloss: 0.0376983\n",
      "[556]\ttraining's binary_logloss: 0.037638\n",
      "[557]\ttraining's binary_logloss: 0.0376005\n",
      "[558]\ttraining's binary_logloss: 0.0375605\n",
      "[559]\ttraining's binary_logloss: 0.0375242\n",
      "[560]\ttraining's binary_logloss: 0.0374831\n",
      "[561]\ttraining's binary_logloss: 0.0374428\n",
      "[562]\ttraining's binary_logloss: 0.0374016\n",
      "[563]\ttraining's binary_logloss: 0.0373608\n",
      "[564]\ttraining's binary_logloss: 0.0373138\n",
      "[565]\ttraining's binary_logloss: 0.0372419\n",
      "[566]\ttraining's binary_logloss: 0.0371984\n",
      "[567]\ttraining's binary_logloss: 0.0371438\n",
      "[568]\ttraining's binary_logloss: 0.0371047\n",
      "[569]\ttraining's binary_logloss: 0.0370504\n",
      "[570]\ttraining's binary_logloss: 0.0370115\n",
      "[571]\ttraining's binary_logloss: 0.0369651\n",
      "[572]\ttraining's binary_logloss: 0.0369256\n",
      "[573]\ttraining's binary_logloss: 0.0368849\n",
      "[574]\ttraining's binary_logloss: 0.0368468\n",
      "[575]\ttraining's binary_logloss: 0.0368107\n",
      "[576]\ttraining's binary_logloss: 0.0367722\n",
      "[577]\ttraining's binary_logloss: 0.0367295\n",
      "[578]\ttraining's binary_logloss: 0.036692\n",
      "[579]\ttraining's binary_logloss: 0.036649\n",
      "[580]\ttraining's binary_logloss: 0.0365981\n",
      "[581]\ttraining's binary_logloss: 0.0365547\n",
      "[582]\ttraining's binary_logloss: 0.0365139\n",
      "[583]\ttraining's binary_logloss: 0.036476\n",
      "[584]\ttraining's binary_logloss: 0.0364353\n",
      "[585]\ttraining's binary_logloss: 0.0363947\n",
      "[586]\ttraining's binary_logloss: 0.0363574\n",
      "[587]\ttraining's binary_logloss: 0.0363262\n",
      "[588]\ttraining's binary_logloss: 0.0362839\n",
      "[589]\ttraining's binary_logloss: 0.036241\n",
      "[590]\ttraining's binary_logloss: 0.0362003\n",
      "[591]\ttraining's binary_logloss: 0.0361447\n",
      "[592]\ttraining's binary_logloss: 0.0361127\n",
      "[593]\ttraining's binary_logloss: 0.0360696\n",
      "[594]\ttraining's binary_logloss: 0.0360266\n",
      "[595]\ttraining's binary_logloss: 0.0359904\n",
      "[596]\ttraining's binary_logloss: 0.0359399\n",
      "[597]\ttraining's binary_logloss: 0.0359023\n",
      "[598]\ttraining's binary_logloss: 0.035866\n",
      "[599]\ttraining's binary_logloss: 0.0358283\n",
      "[600]\ttraining's binary_logloss: 0.0357843\n",
      "[601]\ttraining's binary_logloss: 0.0357485\n",
      "[602]\ttraining's binary_logloss: 0.0357114\n",
      "[603]\ttraining's binary_logloss: 0.0356753\n",
      "[604]\ttraining's binary_logloss: 0.0356431\n",
      "[605]\ttraining's binary_logloss: 0.0355931\n",
      "[606]\ttraining's binary_logloss: 0.0355591\n",
      "[607]\ttraining's binary_logloss: 0.0355271\n",
      "[608]\ttraining's binary_logloss: 0.0354826\n",
      "[609]\ttraining's binary_logloss: 0.0354416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[610]\ttraining's binary_logloss: 0.0354071\n",
      "[611]\ttraining's binary_logloss: 0.0353739\n",
      "[612]\ttraining's binary_logloss: 0.0353388\n",
      "[613]\ttraining's binary_logloss: 0.0353039\n",
      "[614]\ttraining's binary_logloss: 0.0352561\n",
      "[615]\ttraining's binary_logloss: 0.0352241\n",
      "[616]\ttraining's binary_logloss: 0.0351883\n",
      "[617]\ttraining's binary_logloss: 0.0351542\n",
      "[618]\ttraining's binary_logloss: 0.0351209\n",
      "[619]\ttraining's binary_logloss: 0.0350806\n",
      "[620]\ttraining's binary_logloss: 0.0350452\n",
      "[621]\ttraining's binary_logloss: 0.0350136\n",
      "[622]\ttraining's binary_logloss: 0.0349791\n",
      "[623]\ttraining's binary_logloss: 0.0349428\n",
      "[624]\ttraining's binary_logloss: 0.0349102\n",
      "[625]\ttraining's binary_logloss: 0.0348629\n",
      "[626]\ttraining's binary_logloss: 0.0348243\n",
      "[627]\ttraining's binary_logloss: 0.0347969\n",
      "[628]\ttraining's binary_logloss: 0.0347636\n",
      "[629]\ttraining's binary_logloss: 0.0347246\n",
      "[630]\ttraining's binary_logloss: 0.0346838\n",
      "[631]\ttraining's binary_logloss: 0.0346507\n",
      "[632]\ttraining's binary_logloss: 0.0346181\n",
      "[633]\ttraining's binary_logloss: 0.0345876\n",
      "[634]\ttraining's binary_logloss: 0.0345519\n",
      "[635]\ttraining's binary_logloss: 0.0345234\n",
      "[636]\ttraining's binary_logloss: 0.0344875\n",
      "[637]\ttraining's binary_logloss: 0.034454\n",
      "[638]\ttraining's binary_logloss: 0.0344169\n",
      "[639]\ttraining's binary_logloss: 0.0343795\n",
      "[640]\ttraining's binary_logloss: 0.0343518\n",
      "[641]\ttraining's binary_logloss: 0.0343204\n",
      "[642]\ttraining's binary_logloss: 0.0342892\n",
      "[643]\ttraining's binary_logloss: 0.0342551\n",
      "[644]\ttraining's binary_logloss: 0.0342233\n",
      "[645]\ttraining's binary_logloss: 0.0341959\n",
      "[646]\ttraining's binary_logloss: 0.0341721\n",
      "[647]\ttraining's binary_logloss: 0.0341354\n",
      "[648]\ttraining's binary_logloss: 0.0340992\n",
      "[649]\ttraining's binary_logloss: 0.0340697\n",
      "[650]\ttraining's binary_logloss: 0.0340365\n",
      "[651]\ttraining's binary_logloss: 0.034001\n",
      "[652]\ttraining's binary_logloss: 0.0339682\n",
      "[653]\ttraining's binary_logloss: 0.0339353\n",
      "[654]\ttraining's binary_logloss: 0.0339047\n",
      "[655]\ttraining's binary_logloss: 0.0338688\n",
      "[656]\ttraining's binary_logloss: 0.0338314\n",
      "[657]\ttraining's binary_logloss: 0.0337983\n",
      "[658]\ttraining's binary_logloss: 0.0337656\n",
      "[659]\ttraining's binary_logloss: 0.0337362\n",
      "[660]\ttraining's binary_logloss: 0.0337092\n",
      "[661]\ttraining's binary_logloss: 0.0336792\n",
      "[662]\ttraining's binary_logloss: 0.0336504\n",
      "[663]\ttraining's binary_logloss: 0.0336208\n",
      "[664]\ttraining's binary_logloss: 0.0335903\n",
      "[665]\ttraining's binary_logloss: 0.0335606\n",
      "[666]\ttraining's binary_logloss: 0.0335321\n",
      "[667]\ttraining's binary_logloss: 0.0335038\n",
      "[668]\ttraining's binary_logloss: 0.0334701\n",
      "[669]\ttraining's binary_logloss: 0.0334385\n",
      "[670]\ttraining's binary_logloss: 0.033407\n",
      "[671]\ttraining's binary_logloss: 0.0333712\n",
      "[672]\ttraining's binary_logloss: 0.0333447\n",
      "[673]\ttraining's binary_logloss: 0.0333097\n",
      "[674]\ttraining's binary_logloss: 0.033276\n",
      "[675]\ttraining's binary_logloss: 0.0332478\n",
      "[676]\ttraining's binary_logloss: 0.0332193\n",
      "[677]\ttraining's binary_logloss: 0.0331911\n",
      "[678]\ttraining's binary_logloss: 0.0331604\n",
      "[679]\ttraining's binary_logloss: 0.0331268\n",
      "[680]\ttraining's binary_logloss: 0.0330943\n",
      "[681]\ttraining's binary_logloss: 0.033067\n",
      "[682]\ttraining's binary_logloss: 0.0330299\n",
      "[683]\ttraining's binary_logloss: 0.0329992\n",
      "[684]\ttraining's binary_logloss: 0.0329706\n",
      "[685]\ttraining's binary_logloss: 0.0329423\n",
      "[686]\ttraining's binary_logloss: 0.0329143\n",
      "[687]\ttraining's binary_logloss: 0.032886\n",
      "[688]\ttraining's binary_logloss: 0.0328547\n",
      "[689]\ttraining's binary_logloss: 0.0328228\n",
      "[690]\ttraining's binary_logloss: 0.0327959\n",
      "[691]\ttraining's binary_logloss: 0.0327707\n",
      "[692]\ttraining's binary_logloss: 0.0327312\n",
      "[693]\ttraining's binary_logloss: 0.0327032\n",
      "[694]\ttraining's binary_logloss: 0.0326711\n",
      "[695]\ttraining's binary_logloss: 0.0326458\n",
      "[696]\ttraining's binary_logloss: 0.0326093\n",
      "[697]\ttraining's binary_logloss: 0.0325752\n",
      "[698]\ttraining's binary_logloss: 0.0325437\n",
      "[699]\ttraining's binary_logloss: 0.0325175\n",
      "[700]\ttraining's binary_logloss: 0.0324825\n",
      "[701]\ttraining's binary_logloss: 0.0324572\n",
      "[702]\ttraining's binary_logloss: 0.0324276\n",
      "[703]\ttraining's binary_logloss: 0.0323928\n",
      "[704]\ttraining's binary_logloss: 0.0323665\n",
      "[705]\ttraining's binary_logloss: 0.0323394\n",
      "[706]\ttraining's binary_logloss: 0.0323101\n",
      "[707]\ttraining's binary_logloss: 0.0322835\n",
      "[708]\ttraining's binary_logloss: 0.0322582\n",
      "[709]\ttraining's binary_logloss: 0.0322351\n",
      "[710]\ttraining's binary_logloss: 0.0322068\n",
      "[711]\ttraining's binary_logloss: 0.0321763\n",
      "[712]\ttraining's binary_logloss: 0.0321473\n",
      "[713]\ttraining's binary_logloss: 0.0321192\n",
      "[714]\ttraining's binary_logloss: 0.0320931\n",
      "[715]\ttraining's binary_logloss: 0.0320652\n",
      "[716]\ttraining's binary_logloss: 0.0320352\n",
      "[717]\ttraining's binary_logloss: 0.0320098\n",
      "[718]\ttraining's binary_logloss: 0.0319842\n",
      "[719]\ttraining's binary_logloss: 0.0319546\n",
      "[720]\ttraining's binary_logloss: 0.0319263\n",
      "[721]\ttraining's binary_logloss: 0.0319025\n",
      "[722]\ttraining's binary_logloss: 0.0318726\n",
      "[723]\ttraining's binary_logloss: 0.0318456\n",
      "[724]\ttraining's binary_logloss: 0.0318166\n",
      "[725]\ttraining's binary_logloss: 0.0317888\n",
      "[726]\ttraining's binary_logloss: 0.0317638\n",
      "[727]\ttraining's binary_logloss: 0.0317345\n",
      "[728]\ttraining's binary_logloss: 0.0317107\n",
      "[729]\ttraining's binary_logloss: 0.031674\n",
      "[730]\ttraining's binary_logloss: 0.0316415\n",
      "[731]\ttraining's binary_logloss: 0.0316145\n",
      "[732]\ttraining's binary_logloss: 0.0315886\n",
      "[733]\ttraining's binary_logloss: 0.0315602\n",
      "[734]\ttraining's binary_logloss: 0.0315363\n",
      "[735]\ttraining's binary_logloss: 0.0315102\n",
      "[736]\ttraining's binary_logloss: 0.0314862\n",
      "[737]\ttraining's binary_logloss: 0.0314555\n",
      "[738]\ttraining's binary_logloss: 0.0314267\n",
      "[739]\ttraining's binary_logloss: 0.0314003\n",
      "[740]\ttraining's binary_logloss: 0.0313788\n",
      "[741]\ttraining's binary_logloss: 0.0313517\n",
      "[742]\ttraining's binary_logloss: 0.0313252\n",
      "[743]\ttraining's binary_logloss: 0.031302\n",
      "[744]\ttraining's binary_logloss: 0.0312735\n",
      "[745]\ttraining's binary_logloss: 0.0312507\n",
      "[746]\ttraining's binary_logloss: 0.0312264\n",
      "[747]\ttraining's binary_logloss: 0.0312003\n",
      "[748]\ttraining's binary_logloss: 0.0311769\n",
      "[749]\ttraining's binary_logloss: 0.0311524\n",
      "[750]\ttraining's binary_logloss: 0.0311252\n",
      "[751]\ttraining's binary_logloss: 0.0310996\n",
      "[752]\ttraining's binary_logloss: 0.0310738\n",
      "[753]\ttraining's binary_logloss: 0.0310439\n",
      "[754]\ttraining's binary_logloss: 0.031018\n",
      "[755]\ttraining's binary_logloss: 0.0309952\n",
      "[756]\ttraining's binary_logloss: 0.0309704\n",
      "[757]\ttraining's binary_logloss: 0.0309453\n",
      "[758]\ttraining's binary_logloss: 0.0309229\n",
      "[759]\ttraining's binary_logloss: 0.0308974\n",
      "[760]\ttraining's binary_logloss: 0.0308776\n",
      "[761]\ttraining's binary_logloss: 0.0308551\n",
      "[762]\ttraining's binary_logloss: 0.0308326\n",
      "[763]\ttraining's binary_logloss: 0.0308036\n",
      "[764]\ttraining's binary_logloss: 0.0307784\n",
      "[765]\ttraining's binary_logloss: 0.0307544\n",
      "[766]\ttraining's binary_logloss: 0.0307318\n",
      "[767]\ttraining's binary_logloss: 0.0307081\n",
      "[768]\ttraining's binary_logloss: 0.0306816\n",
      "[769]\ttraining's binary_logloss: 0.030654\n",
      "[770]\ttraining's binary_logloss: 0.0306299\n",
      "[771]\ttraining's binary_logloss: 0.0306029\n",
      "[772]\ttraining's binary_logloss: 0.0305787\n",
      "[773]\ttraining's binary_logloss: 0.0305546\n",
      "[774]\ttraining's binary_logloss: 0.0305349\n",
      "[775]\ttraining's binary_logloss: 0.0305114\n",
      "[776]\ttraining's binary_logloss: 0.0304862\n",
      "[777]\ttraining's binary_logloss: 0.0304599\n",
      "[778]\ttraining's binary_logloss: 0.030433\n",
      "[779]\ttraining's binary_logloss: 0.0304066\n",
      "[780]\ttraining's binary_logloss: 0.0303793\n",
      "[781]\ttraining's binary_logloss: 0.0303568\n",
      "[782]\ttraining's binary_logloss: 0.0303356\n",
      "[783]\ttraining's binary_logloss: 0.0303139\n",
      "[784]\ttraining's binary_logloss: 0.0302883\n",
      "[785]\ttraining's binary_logloss: 0.0302652\n",
      "[786]\ttraining's binary_logloss: 0.0302371\n",
      "[787]\ttraining's binary_logloss: 0.0302153\n",
      "[788]\ttraining's binary_logloss: 0.0301927\n",
      "[789]\ttraining's binary_logloss: 0.030167\n",
      "[790]\ttraining's binary_logloss: 0.0301452\n",
      "[791]\ttraining's binary_logloss: 0.0301247\n",
      "[792]\ttraining's binary_logloss: 0.0300982\n",
      "[793]\ttraining's binary_logloss: 0.0300734\n",
      "[794]\ttraining's binary_logloss: 0.0300487\n",
      "[795]\ttraining's binary_logloss: 0.0300271\n",
      "[796]\ttraining's binary_logloss: 0.0300046\n",
      "[797]\ttraining's binary_logloss: 0.0299811\n",
      "[798]\ttraining's binary_logloss: 0.0299609\n",
      "[799]\ttraining's binary_logloss: 0.0299429\n",
      "[800]\ttraining's binary_logloss: 0.0299226\n",
      "[801]\ttraining's binary_logloss: 0.0298988\n",
      "[802]\ttraining's binary_logloss: 0.0298769\n",
      "[803]\ttraining's binary_logloss: 0.0298517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804]\ttraining's binary_logloss: 0.0298262\n",
      "[805]\ttraining's binary_logloss: 0.0298041\n",
      "[806]\ttraining's binary_logloss: 0.0297804\n",
      "[807]\ttraining's binary_logloss: 0.029759\n",
      "[808]\ttraining's binary_logloss: 0.0297416\n",
      "[809]\ttraining's binary_logloss: 0.0297217\n",
      "[810]\ttraining's binary_logloss: 0.0296996\n",
      "[811]\ttraining's binary_logloss: 0.0296745\n",
      "[812]\ttraining's binary_logloss: 0.0296562\n",
      "[813]\ttraining's binary_logloss: 0.0296306\n",
      "[814]\ttraining's binary_logloss: 0.0296072\n",
      "[815]\ttraining's binary_logloss: 0.0295863\n",
      "[816]\ttraining's binary_logloss: 0.0295609\n",
      "[817]\ttraining's binary_logloss: 0.0295405\n",
      "[818]\ttraining's binary_logloss: 0.0295217\n",
      "[819]\ttraining's binary_logloss: 0.0294991\n",
      "[820]\ttraining's binary_logloss: 0.029478\n",
      "[821]\ttraining's binary_logloss: 0.0294518\n",
      "[822]\ttraining's binary_logloss: 0.0294304\n",
      "[823]\ttraining's binary_logloss: 0.0294101\n",
      "[824]\ttraining's binary_logloss: 0.0293896\n",
      "[825]\ttraining's binary_logloss: 0.0293691\n",
      "[826]\ttraining's binary_logloss: 0.0293463\n",
      "[827]\ttraining's binary_logloss: 0.0293251\n",
      "[828]\ttraining's binary_logloss: 0.0293011\n",
      "[829]\ttraining's binary_logloss: 0.0292811\n",
      "[830]\ttraining's binary_logloss: 0.0292592\n",
      "[831]\ttraining's binary_logloss: 0.0292371\n",
      "[832]\ttraining's binary_logloss: 0.029221\n",
      "[833]\ttraining's binary_logloss: 0.0292034\n",
      "[834]\ttraining's binary_logloss: 0.0291803\n",
      "[835]\ttraining's binary_logloss: 0.0291602\n",
      "[836]\ttraining's binary_logloss: 0.0291386\n",
      "[837]\ttraining's binary_logloss: 0.0291202\n",
      "[838]\ttraining's binary_logloss: 0.0290991\n",
      "[839]\ttraining's binary_logloss: 0.0290797\n",
      "[840]\ttraining's binary_logloss: 0.0290637\n",
      "[841]\ttraining's binary_logloss: 0.0290428\n",
      "[842]\ttraining's binary_logloss: 0.0290188\n",
      "[843]\ttraining's binary_logloss: 0.0289981\n",
      "[844]\ttraining's binary_logloss: 0.0289733\n",
      "[845]\ttraining's binary_logloss: 0.0289506\n",
      "[846]\ttraining's binary_logloss: 0.0289295\n",
      "[847]\ttraining's binary_logloss: 0.0289128\n",
      "[848]\ttraining's binary_logloss: 0.0288903\n",
      "[849]\ttraining's binary_logloss: 0.0288712\n",
      "[850]\ttraining's binary_logloss: 0.0288545\n",
      "[851]\ttraining's binary_logloss: 0.028833\n",
      "[852]\ttraining's binary_logloss: 0.0288134\n",
      "[853]\ttraining's binary_logloss: 0.0287921\n",
      "[854]\ttraining's binary_logloss: 0.0287719\n",
      "[855]\ttraining's binary_logloss: 0.0287541\n",
      "[856]\ttraining's binary_logloss: 0.0287323\n",
      "[857]\ttraining's binary_logloss: 0.0287132\n",
      "[858]\ttraining's binary_logloss: 0.0286936\n",
      "[859]\ttraining's binary_logloss: 0.0286735\n",
      "[860]\ttraining's binary_logloss: 0.0286517\n",
      "[861]\ttraining's binary_logloss: 0.0286266\n",
      "[862]\ttraining's binary_logloss: 0.0286029\n",
      "[863]\ttraining's binary_logloss: 0.0285842\n",
      "[864]\ttraining's binary_logloss: 0.0285629\n",
      "[865]\ttraining's binary_logloss: 0.028542\n",
      "[866]\ttraining's binary_logloss: 0.0285184\n",
      "[867]\ttraining's binary_logloss: 0.0284986\n",
      "[868]\ttraining's binary_logloss: 0.0284827\n",
      "[869]\ttraining's binary_logloss: 0.0284641\n",
      "[870]\ttraining's binary_logloss: 0.0284447\n",
      "[871]\ttraining's binary_logloss: 0.0284267\n",
      "[872]\ttraining's binary_logloss: 0.0284074\n",
      "[873]\ttraining's binary_logloss: 0.0283879\n",
      "[874]\ttraining's binary_logloss: 0.0283698\n",
      "[875]\ttraining's binary_logloss: 0.0283481\n",
      "[876]\ttraining's binary_logloss: 0.0283254\n",
      "[877]\ttraining's binary_logloss: 0.028303\n",
      "[878]\ttraining's binary_logloss: 0.0282856\n",
      "[879]\ttraining's binary_logloss: 0.0282643\n",
      "[880]\ttraining's binary_logloss: 0.0282493\n",
      "[881]\ttraining's binary_logloss: 0.0282302\n",
      "[882]\ttraining's binary_logloss: 0.0282108\n",
      "[883]\ttraining's binary_logloss: 0.0281927\n",
      "[884]\ttraining's binary_logloss: 0.0281759\n",
      "[885]\ttraining's binary_logloss: 0.0281566\n",
      "[886]\ttraining's binary_logloss: 0.0281404\n",
      "[887]\ttraining's binary_logloss: 0.0281192\n",
      "[888]\ttraining's binary_logloss: 0.0280982\n",
      "[889]\ttraining's binary_logloss: 0.0280789\n",
      "[890]\ttraining's binary_logloss: 0.02806\n",
      "[891]\ttraining's binary_logloss: 0.0280457\n",
      "[892]\ttraining's binary_logloss: 0.0280266\n",
      "[893]\ttraining's binary_logloss: 0.0280055\n",
      "[894]\ttraining's binary_logloss: 0.0279908\n",
      "[895]\ttraining's binary_logloss: 0.0279685\n",
      "[896]\ttraining's binary_logloss: 0.0279489\n",
      "[897]\ttraining's binary_logloss: 0.0279301\n",
      "[898]\ttraining's binary_logloss: 0.0279126\n",
      "[899]\ttraining's binary_logloss: 0.0278941\n",
      "[900]\ttraining's binary_logloss: 0.0278759\n",
      "[901]\ttraining's binary_logloss: 0.0278578\n",
      "[902]\ttraining's binary_logloss: 0.0278381\n",
      "[903]\ttraining's binary_logloss: 0.0278215\n",
      "[904]\ttraining's binary_logloss: 0.0278036\n",
      "[905]\ttraining's binary_logloss: 0.0277848\n",
      "[906]\ttraining's binary_logloss: 0.0277625\n",
      "[907]\ttraining's binary_logloss: 0.0277437\n",
      "[908]\ttraining's binary_logloss: 0.0277286\n",
      "[909]\ttraining's binary_logloss: 0.027713\n",
      "[910]\ttraining's binary_logloss: 0.027698\n",
      "[911]\ttraining's binary_logloss: 0.0276816\n",
      "[912]\ttraining's binary_logloss: 0.0276659\n",
      "[913]\ttraining's binary_logloss: 0.0276498\n",
      "[914]\ttraining's binary_logloss: 0.0276298\n",
      "[915]\ttraining's binary_logloss: 0.0276116\n",
      "[916]\ttraining's binary_logloss: 0.027593\n",
      "[917]\ttraining's binary_logloss: 0.0275752\n",
      "[918]\ttraining's binary_logloss: 0.0275595\n",
      "[919]\ttraining's binary_logloss: 0.0275457\n",
      "[920]\ttraining's binary_logloss: 0.0275266\n",
      "[921]\ttraining's binary_logloss: 0.0275077\n",
      "[922]\ttraining's binary_logloss: 0.0274892\n",
      "[923]\ttraining's binary_logloss: 0.0274718\n",
      "[924]\ttraining's binary_logloss: 0.0274554\n",
      "[925]\ttraining's binary_logloss: 0.0274381\n",
      "[926]\ttraining's binary_logloss: 0.0274222\n",
      "[927]\ttraining's binary_logloss: 0.0274069\n",
      "[928]\ttraining's binary_logloss: 0.0273884\n",
      "[929]\ttraining's binary_logloss: 0.0273713\n",
      "[930]\ttraining's binary_logloss: 0.0273544\n",
      "[931]\ttraining's binary_logloss: 0.0273369\n",
      "[932]\ttraining's binary_logloss: 0.0273194\n",
      "[933]\ttraining's binary_logloss: 0.0273017\n",
      "[934]\ttraining's binary_logloss: 0.0272849\n",
      "[935]\ttraining's binary_logloss: 0.0272674\n",
      "[936]\ttraining's binary_logloss: 0.0272516\n",
      "[937]\ttraining's binary_logloss: 0.02723\n",
      "[938]\ttraining's binary_logloss: 0.0272115\n",
      "[939]\ttraining's binary_logloss: 0.027192\n",
      "[940]\ttraining's binary_logloss: 0.0271768\n",
      "[941]\ttraining's binary_logloss: 0.0271595\n",
      "[942]\ttraining's binary_logloss: 0.027142\n",
      "[943]\ttraining's binary_logloss: 0.0271247\n",
      "[944]\ttraining's binary_logloss: 0.0271074\n",
      "[945]\ttraining's binary_logloss: 0.0270857\n",
      "[946]\ttraining's binary_logloss: 0.0270693\n",
      "[947]\ttraining's binary_logloss: 0.0270529\n",
      "[948]\ttraining's binary_logloss: 0.0270382\n",
      "[949]\ttraining's binary_logloss: 0.0270211\n",
      "[950]\ttraining's binary_logloss: 0.0270069\n",
      "[951]\ttraining's binary_logloss: 0.0269911\n",
      "[952]\ttraining's binary_logloss: 0.0269735\n",
      "[953]\ttraining's binary_logloss: 0.0269571\n",
      "[954]\ttraining's binary_logloss: 0.0269412\n",
      "[955]\ttraining's binary_logloss: 0.0269247\n",
      "[956]\ttraining's binary_logloss: 0.0269072\n",
      "[957]\ttraining's binary_logloss: 0.0268895\n",
      "[958]\ttraining's binary_logloss: 0.026873\n",
      "[959]\ttraining's binary_logloss: 0.0268553\n",
      "[960]\ttraining's binary_logloss: 0.0268398\n",
      "[961]\ttraining's binary_logloss: 0.0268259\n",
      "[962]\ttraining's binary_logloss: 0.0268121\n",
      "[963]\ttraining's binary_logloss: 0.026799\n",
      "[964]\ttraining's binary_logloss: 0.0267801\n",
      "[965]\ttraining's binary_logloss: 0.0267635\n",
      "[966]\ttraining's binary_logloss: 0.0267452\n",
      "[967]\ttraining's binary_logloss: 0.0267274\n",
      "[968]\ttraining's binary_logloss: 0.0267132\n",
      "[969]\ttraining's binary_logloss: 0.0267001\n",
      "[970]\ttraining's binary_logloss: 0.0266811\n",
      "[971]\ttraining's binary_logloss: 0.0266661\n",
      "[972]\ttraining's binary_logloss: 0.0266498\n",
      "[973]\ttraining's binary_logloss: 0.0266306\n",
      "[974]\ttraining's binary_logloss: 0.026615\n",
      "[975]\ttraining's binary_logloss: 0.0266013\n",
      "[976]\ttraining's binary_logloss: 0.0265805\n",
      "[977]\ttraining's binary_logloss: 0.0265615\n",
      "[978]\ttraining's binary_logloss: 0.0265457\n",
      "[979]\ttraining's binary_logloss: 0.0265297\n",
      "[980]\ttraining's binary_logloss: 0.0265131\n",
      "[981]\ttraining's binary_logloss: 0.026499\n",
      "[982]\ttraining's binary_logloss: 0.026483\n",
      "[983]\ttraining's binary_logloss: 0.0264684\n",
      "[984]\ttraining's binary_logloss: 0.0264521\n",
      "[985]\ttraining's binary_logloss: 0.0264327\n",
      "[986]\ttraining's binary_logloss: 0.0264211\n",
      "[987]\ttraining's binary_logloss: 0.0264063\n",
      "[988]\ttraining's binary_logloss: 0.0263925\n",
      "[989]\ttraining's binary_logloss: 0.0263792\n",
      "[990]\ttraining's binary_logloss: 0.0263652\n",
      "[991]\ttraining's binary_logloss: 0.0263516\n",
      "[992]\ttraining's binary_logloss: 0.0263368\n",
      "[993]\ttraining's binary_logloss: 0.0263217\n",
      "[994]\ttraining's binary_logloss: 0.0263079\n",
      "[995]\ttraining's binary_logloss: 0.0262934\n",
      "[996]\ttraining's binary_logloss: 0.0262781\n",
      "[997]\ttraining's binary_logloss: 0.0262599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[998]\ttraining's binary_logloss: 0.0262447\n",
      "[999]\ttraining's binary_logloss: 0.026232\n",
      "[1000]\ttraining's binary_logloss: 0.0262175\n",
      "[1001]\ttraining's binary_logloss: 0.0262019\n",
      "[1002]\ttraining's binary_logloss: 0.0261868\n",
      "[1003]\ttraining's binary_logloss: 0.0261709\n",
      "[1004]\ttraining's binary_logloss: 0.0261572\n",
      "[1005]\ttraining's binary_logloss: 0.026143\n",
      "[1006]\ttraining's binary_logloss: 0.026131\n",
      "[1007]\ttraining's binary_logloss: 0.0261179\n",
      "[1008]\ttraining's binary_logloss: 0.0261024\n",
      "[1009]\ttraining's binary_logloss: 0.0260877\n",
      "[1010]\ttraining's binary_logloss: 0.0260734\n",
      "[1011]\ttraining's binary_logloss: 0.0260562\n",
      "[1012]\ttraining's binary_logloss: 0.0260425\n",
      "[1013]\ttraining's binary_logloss: 0.026029\n",
      "[1014]\ttraining's binary_logloss: 0.0260127\n",
      "[1015]\ttraining's binary_logloss: 0.0259986\n",
      "[1016]\ttraining's binary_logloss: 0.0259854\n",
      "[1017]\ttraining's binary_logloss: 0.0259724\n",
      "[1018]\ttraining's binary_logloss: 0.0259568\n",
      "[1019]\ttraining's binary_logloss: 0.0259395\n",
      "[1020]\ttraining's binary_logloss: 0.0259223\n",
      "[1021]\ttraining's binary_logloss: 0.0259088\n",
      "[1022]\ttraining's binary_logloss: 0.0258965\n",
      "[1023]\ttraining's binary_logloss: 0.0258785\n",
      "[1024]\ttraining's binary_logloss: 0.025865\n",
      "[1025]\ttraining's binary_logloss: 0.0258519\n",
      "[1026]\ttraining's binary_logloss: 0.0258367\n",
      "[1027]\ttraining's binary_logloss: 0.0258221\n",
      "[1028]\ttraining's binary_logloss: 0.0258095\n",
      "[1029]\ttraining's binary_logloss: 0.0257956\n",
      "[1030]\ttraining's binary_logloss: 0.0257778\n",
      "[1031]\ttraining's binary_logloss: 0.025766\n",
      "[1032]\ttraining's binary_logloss: 0.0257509\n",
      "[1033]\ttraining's binary_logloss: 0.0257356\n",
      "[1034]\ttraining's binary_logloss: 0.0257226\n",
      "[1035]\ttraining's binary_logloss: 0.0257088\n",
      "[1036]\ttraining's binary_logloss: 0.0256951\n",
      "[1037]\ttraining's binary_logloss: 0.025681\n",
      "[1038]\ttraining's binary_logloss: 0.0256657\n",
      "[1039]\ttraining's binary_logloss: 0.025651\n",
      "[1040]\ttraining's binary_logloss: 0.0256366\n",
      "[1041]\ttraining's binary_logloss: 0.0256233\n",
      "[1042]\ttraining's binary_logloss: 0.0256062\n",
      "[1043]\ttraining's binary_logloss: 0.0255915\n",
      "[1044]\ttraining's binary_logloss: 0.0255778\n",
      "[1045]\ttraining's binary_logloss: 0.0255614\n",
      "[1046]\ttraining's binary_logloss: 0.0255478\n",
      "[1047]\ttraining's binary_logloss: 0.0255326\n",
      "[1048]\ttraining's binary_logloss: 0.025518\n",
      "[1049]\ttraining's binary_logloss: 0.0255019\n",
      "[1050]\ttraining's binary_logloss: 0.0254889\n",
      "[1051]\ttraining's binary_logloss: 0.0254742\n",
      "[1052]\ttraining's binary_logloss: 0.0254573\n",
      "[1053]\ttraining's binary_logloss: 0.0254433\n",
      "[1054]\ttraining's binary_logloss: 0.0254301\n",
      "[1055]\ttraining's binary_logloss: 0.0254146\n",
      "[1056]\ttraining's binary_logloss: 0.0254007\n",
      "[1057]\ttraining's binary_logloss: 0.0253848\n",
      "[1058]\ttraining's binary_logloss: 0.0253714\n",
      "[1059]\ttraining's binary_logloss: 0.0253522\n",
      "[1060]\ttraining's binary_logloss: 0.0253394\n",
      "[1061]\ttraining's binary_logloss: 0.0253259\n",
      "[1062]\ttraining's binary_logloss: 0.0253128\n",
      "[1063]\ttraining's binary_logloss: 0.0252977\n",
      "[1064]\ttraining's binary_logloss: 0.025284\n",
      "[1065]\ttraining's binary_logloss: 0.0252693\n",
      "[1066]\ttraining's binary_logloss: 0.0252569\n",
      "[1067]\ttraining's binary_logloss: 0.0252449\n",
      "[1068]\ttraining's binary_logloss: 0.0252313\n",
      "[1069]\ttraining's binary_logloss: 0.0252194\n",
      "[1070]\ttraining's binary_logloss: 0.0252066\n",
      "[1071]\ttraining's binary_logloss: 0.0251939\n",
      "[1072]\ttraining's binary_logloss: 0.0251821\n",
      "[1073]\ttraining's binary_logloss: 0.0251686\n",
      "[1074]\ttraining's binary_logloss: 0.0251531\n",
      "[1075]\ttraining's binary_logloss: 0.025141\n",
      "[1076]\ttraining's binary_logloss: 0.0251275\n",
      "[1077]\ttraining's binary_logloss: 0.0251132\n",
      "[1078]\ttraining's binary_logloss: 0.0250998\n",
      "[1079]\ttraining's binary_logloss: 0.0250881\n",
      "[1080]\ttraining's binary_logloss: 0.0250761\n",
      "[1081]\ttraining's binary_logloss: 0.0250606\n",
      "[1082]\ttraining's binary_logloss: 0.025047\n",
      "[1083]\ttraining's binary_logloss: 0.0250334\n",
      "[1084]\ttraining's binary_logloss: 0.0250187\n",
      "[1085]\ttraining's binary_logloss: 0.0250066\n",
      "[1086]\ttraining's binary_logloss: 0.0249929\n",
      "[1087]\ttraining's binary_logloss: 0.0249817\n",
      "[1088]\ttraining's binary_logloss: 0.0249685\n",
      "[1089]\ttraining's binary_logloss: 0.0249545\n",
      "[1090]\ttraining's binary_logloss: 0.0249407\n",
      "[1091]\ttraining's binary_logloss: 0.0249273\n",
      "[1092]\ttraining's binary_logloss: 0.0249134\n",
      "[1093]\ttraining's binary_logloss: 0.024897\n",
      "[1094]\ttraining's binary_logloss: 0.024884\n",
      "[1095]\ttraining's binary_logloss: 0.0248716\n",
      "[1096]\ttraining's binary_logloss: 0.0248562\n",
      "[1097]\ttraining's binary_logloss: 0.0248445\n",
      "[1098]\ttraining's binary_logloss: 0.0248303\n",
      "[1099]\ttraining's binary_logloss: 0.0248173\n",
      "[1100]\ttraining's binary_logloss: 0.0248047\n",
      "[1101]\ttraining's binary_logloss: 0.0247925\n",
      "[1102]\ttraining's binary_logloss: 0.0247797\n",
      "[1103]\ttraining's binary_logloss: 0.0247668\n",
      "[1104]\ttraining's binary_logloss: 0.0247546\n",
      "[1105]\ttraining's binary_logloss: 0.0247415\n",
      "[1106]\ttraining's binary_logloss: 0.0247278\n",
      "[1107]\ttraining's binary_logloss: 0.0247165\n",
      "[1108]\ttraining's binary_logloss: 0.0247075\n",
      "[1109]\ttraining's binary_logloss: 0.0246971\n",
      "[1110]\ttraining's binary_logloss: 0.024685\n",
      "[1111]\ttraining's binary_logloss: 0.0246724\n",
      "[1112]\ttraining's binary_logloss: 0.0246614\n",
      "[1113]\ttraining's binary_logloss: 0.0246484\n",
      "[1114]\ttraining's binary_logloss: 0.0246368\n",
      "[1115]\ttraining's binary_logloss: 0.0246265\n",
      "[1116]\ttraining's binary_logloss: 0.0246113\n",
      "[1117]\ttraining's binary_logloss: 0.0245987\n",
      "[1118]\ttraining's binary_logloss: 0.0245868\n",
      "[1119]\ttraining's binary_logloss: 0.0245739\n",
      "[1120]\ttraining's binary_logloss: 0.024562\n",
      "[1121]\ttraining's binary_logloss: 0.0245495\n",
      "[1122]\ttraining's binary_logloss: 0.0245362\n",
      "[1123]\ttraining's binary_logloss: 0.0245227\n",
      "[1124]\ttraining's binary_logloss: 0.0245092\n",
      "[1125]\ttraining's binary_logloss: 0.0244965\n",
      "[1126]\ttraining's binary_logloss: 0.0244817\n",
      "[1127]\ttraining's binary_logloss: 0.0244649\n",
      "[1128]\ttraining's binary_logloss: 0.0244529\n",
      "[1129]\ttraining's binary_logloss: 0.0244403\n",
      "[1130]\ttraining's binary_logloss: 0.0244246\n",
      "[1131]\ttraining's binary_logloss: 0.0244128\n",
      "[1132]\ttraining's binary_logloss: 0.0243986\n",
      "[1133]\ttraining's binary_logloss: 0.0243884\n",
      "[1134]\ttraining's binary_logloss: 0.024377\n",
      "[1135]\ttraining's binary_logloss: 0.0243654\n",
      "[1136]\ttraining's binary_logloss: 0.0243535\n",
      "[1137]\ttraining's binary_logloss: 0.0243392\n",
      "[1138]\ttraining's binary_logloss: 0.0243272\n",
      "[1139]\ttraining's binary_logloss: 0.0243148\n",
      "[1140]\ttraining's binary_logloss: 0.0243042\n",
      "[1141]\ttraining's binary_logloss: 0.0242936\n",
      "[1142]\ttraining's binary_logloss: 0.0242811\n",
      "[1143]\ttraining's binary_logloss: 0.0242669\n",
      "[1144]\ttraining's binary_logloss: 0.0242546\n",
      "[1145]\ttraining's binary_logloss: 0.024242\n",
      "[1146]\ttraining's binary_logloss: 0.0242314\n",
      "[1147]\ttraining's binary_logloss: 0.0242188\n",
      "[1148]\ttraining's binary_logloss: 0.0242076\n",
      "[1149]\ttraining's binary_logloss: 0.0241965\n",
      "[1150]\ttraining's binary_logloss: 0.0241849\n",
      "[1151]\ttraining's binary_logloss: 0.0241706\n",
      "[1152]\ttraining's binary_logloss: 0.0241562\n",
      "[1153]\ttraining's binary_logloss: 0.0241426\n",
      "[1154]\ttraining's binary_logloss: 0.0241255\n",
      "[1155]\ttraining's binary_logloss: 0.0241135\n",
      "[1156]\ttraining's binary_logloss: 0.0241016\n",
      "[1157]\ttraining's binary_logloss: 0.0240871\n",
      "[1158]\ttraining's binary_logloss: 0.0240747\n",
      "[1159]\ttraining's binary_logloss: 0.0240625\n",
      "[1160]\ttraining's binary_logloss: 0.0240514\n",
      "[1161]\ttraining's binary_logloss: 0.0240391\n",
      "[1162]\ttraining's binary_logloss: 0.0240264\n",
      "[1163]\ttraining's binary_logloss: 0.0240156\n",
      "[1164]\ttraining's binary_logloss: 0.0240046\n",
      "[1165]\ttraining's binary_logloss: 0.0239899\n",
      "[1166]\ttraining's binary_logloss: 0.0239787\n",
      "[1167]\ttraining's binary_logloss: 0.0239675\n",
      "[1168]\ttraining's binary_logloss: 0.023952\n",
      "[1169]\ttraining's binary_logloss: 0.02394\n",
      "[1170]\ttraining's binary_logloss: 0.0239269\n",
      "[1171]\ttraining's binary_logloss: 0.0239163\n",
      "[1172]\ttraining's binary_logloss: 0.0239038\n",
      "[1173]\ttraining's binary_logloss: 0.023894\n",
      "[1174]\ttraining's binary_logloss: 0.0238832\n",
      "[1175]\ttraining's binary_logloss: 0.0238732\n",
      "[1176]\ttraining's binary_logloss: 0.0238619\n",
      "[1177]\ttraining's binary_logloss: 0.0238485\n",
      "[1178]\ttraining's binary_logloss: 0.0238376\n",
      "[1179]\ttraining's binary_logloss: 0.0238293\n",
      "[1180]\ttraining's binary_logloss: 0.0238185\n",
      "[1181]\ttraining's binary_logloss: 0.0238077\n",
      "[1182]\ttraining's binary_logloss: 0.0237935\n",
      "[1183]\ttraining's binary_logloss: 0.0237805\n",
      "[1184]\ttraining's binary_logloss: 0.02377\n",
      "[1185]\ttraining's binary_logloss: 0.0237583\n",
      "[1186]\ttraining's binary_logloss: 0.0237468\n",
      "[1187]\ttraining's binary_logloss: 0.0237353\n",
      "[1188]\ttraining's binary_logloss: 0.023723\n",
      "[1189]\ttraining's binary_logloss: 0.0237125\n",
      "[1190]\ttraining's binary_logloss: 0.0237016\n",
      "[1191]\ttraining's binary_logloss: 0.0236884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1192]\ttraining's binary_logloss: 0.0236748\n",
      "[1193]\ttraining's binary_logloss: 0.0236638\n",
      "[1194]\ttraining's binary_logloss: 0.0236517\n",
      "[1195]\ttraining's binary_logloss: 0.023638\n",
      "[1196]\ttraining's binary_logloss: 0.0236281\n",
      "[1197]\ttraining's binary_logloss: 0.0236157\n",
      "[1198]\ttraining's binary_logloss: 0.023607\n",
      "[1199]\ttraining's binary_logloss: 0.0235976\n",
      "[1200]\ttraining's binary_logloss: 0.0235854\n",
      "[1201]\ttraining's binary_logloss: 0.023574\n",
      "[1202]\ttraining's binary_logloss: 0.023563\n",
      "[1203]\ttraining's binary_logloss: 0.0235508\n",
      "[1204]\ttraining's binary_logloss: 0.0235393\n",
      "[1205]\ttraining's binary_logloss: 0.023529\n",
      "[1206]\ttraining's binary_logloss: 0.0235177\n",
      "[1207]\ttraining's binary_logloss: 0.0235057\n",
      "[1208]\ttraining's binary_logloss: 0.0234947\n",
      "[1209]\ttraining's binary_logloss: 0.0234844\n",
      "[1210]\ttraining's binary_logloss: 0.0234732\n",
      "[1211]\ttraining's binary_logloss: 0.02346\n",
      "[1212]\ttraining's binary_logloss: 0.0234488\n",
      "[1213]\ttraining's binary_logloss: 0.0234359\n",
      "[1214]\ttraining's binary_logloss: 0.023425\n",
      "[1215]\ttraining's binary_logloss: 0.0234139\n",
      "[1216]\ttraining's binary_logloss: 0.0234037\n",
      "[1217]\ttraining's binary_logloss: 0.0233935\n",
      "[1218]\ttraining's binary_logloss: 0.0233832\n",
      "[1219]\ttraining's binary_logloss: 0.0233673\n",
      "[1220]\ttraining's binary_logloss: 0.0233586\n",
      "[1221]\ttraining's binary_logloss: 0.0233479\n",
      "[1222]\ttraining's binary_logloss: 0.0233369\n",
      "[1223]\ttraining's binary_logloss: 0.0233262\n",
      "[1224]\ttraining's binary_logloss: 0.0233168\n",
      "[1225]\ttraining's binary_logloss: 0.0233049\n",
      "[1226]\ttraining's binary_logloss: 0.0232937\n",
      "[1227]\ttraining's binary_logloss: 0.0232798\n",
      "[1228]\ttraining's binary_logloss: 0.0232694\n",
      "[1229]\ttraining's binary_logloss: 0.0232575\n",
      "[1230]\ttraining's binary_logloss: 0.023244\n",
      "[1231]\ttraining's binary_logloss: 0.0232347\n",
      "[1232]\ttraining's binary_logloss: 0.0232218\n",
      "[1233]\ttraining's binary_logloss: 0.02321\n",
      "[1234]\ttraining's binary_logloss: 0.0231971\n",
      "[1235]\ttraining's binary_logloss: 0.0231867\n",
      "[1236]\ttraining's binary_logloss: 0.0231736\n",
      "[1237]\ttraining's binary_logloss: 0.0231629\n",
      "[1238]\ttraining's binary_logloss: 0.0231506\n",
      "[1239]\ttraining's binary_logloss: 0.0231396\n",
      "[1240]\ttraining's binary_logloss: 0.023129\n",
      "[1241]\ttraining's binary_logloss: 0.0231186\n",
      "[1242]\ttraining's binary_logloss: 0.0231071\n",
      "[1243]\ttraining's binary_logloss: 0.0230945\n",
      "[1244]\ttraining's binary_logloss: 0.023083\n",
      "[1245]\ttraining's binary_logloss: 0.0230737\n",
      "[1246]\ttraining's binary_logloss: 0.0230634\n",
      "[1247]\ttraining's binary_logloss: 0.0230521\n",
      "[1248]\ttraining's binary_logloss: 0.0230422\n",
      "[1249]\ttraining's binary_logloss: 0.0230328\n",
      "[1250]\ttraining's binary_logloss: 0.0230196\n",
      "[1251]\ttraining's binary_logloss: 0.0230075\n",
      "[1252]\ttraining's binary_logloss: 0.0229979\n",
      "[1253]\ttraining's binary_logloss: 0.0229864\n",
      "[1254]\ttraining's binary_logloss: 0.0229759\n",
      "[1255]\ttraining's binary_logloss: 0.0229648\n",
      "[1256]\ttraining's binary_logloss: 0.0229494\n",
      "[1257]\ttraining's binary_logloss: 0.0229409\n",
      "[1258]\ttraining's binary_logloss: 0.0229287\n",
      "[1259]\ttraining's binary_logloss: 0.0229207\n",
      "[1260]\ttraining's binary_logloss: 0.0229102\n",
      "[1261]\ttraining's binary_logloss: 0.0229008\n",
      "[1262]\ttraining's binary_logloss: 0.0228918\n",
      "[1263]\ttraining's binary_logloss: 0.0228827\n",
      "[1264]\ttraining's binary_logloss: 0.0228713\n",
      "[1265]\ttraining's binary_logloss: 0.0228611\n",
      "[1266]\ttraining's binary_logloss: 0.0228503\n",
      "[1267]\ttraining's binary_logloss: 0.0228408\n",
      "[1268]\ttraining's binary_logloss: 0.0228304\n",
      "[1269]\ttraining's binary_logloss: 0.0228206\n",
      "[1270]\ttraining's binary_logloss: 0.0228107\n",
      "[1271]\ttraining's binary_logloss: 0.0228008\n",
      "[1272]\ttraining's binary_logloss: 0.0227871\n",
      "[1273]\ttraining's binary_logloss: 0.0227767\n",
      "[1274]\ttraining's binary_logloss: 0.0227682\n",
      "[1275]\ttraining's binary_logloss: 0.0227565\n",
      "[1276]\ttraining's binary_logloss: 0.0227474\n",
      "[1277]\ttraining's binary_logloss: 0.0227372\n",
      "[1278]\ttraining's binary_logloss: 0.0227247\n",
      "[1279]\ttraining's binary_logloss: 0.0227156\n",
      "[1280]\ttraining's binary_logloss: 0.0227075\n",
      "[1281]\ttraining's binary_logloss: 0.0226982\n",
      "[1282]\ttraining's binary_logloss: 0.0226863\n",
      "[1283]\ttraining's binary_logloss: 0.0226756\n",
      "[1284]\ttraining's binary_logloss: 0.0226668\n",
      "[1285]\ttraining's binary_logloss: 0.0226552\n",
      "[1286]\ttraining's binary_logloss: 0.0226451\n",
      "[1287]\ttraining's binary_logloss: 0.0226355\n",
      "[1288]\ttraining's binary_logloss: 0.0226273\n",
      "[1289]\ttraining's binary_logloss: 0.0226157\n",
      "[1290]\ttraining's binary_logloss: 0.0226058\n",
      "[1291]\ttraining's binary_logloss: 0.0225963\n",
      "[1292]\ttraining's binary_logloss: 0.0225852\n",
      "[1293]\ttraining's binary_logloss: 0.0225731\n",
      "[1294]\ttraining's binary_logloss: 0.0225634\n",
      "[1295]\ttraining's binary_logloss: 0.0225554\n",
      "[1296]\ttraining's binary_logloss: 0.0225446\n",
      "[1297]\ttraining's binary_logloss: 0.022533\n",
      "[1298]\ttraining's binary_logloss: 0.0225238\n",
      "[1299]\ttraining's binary_logloss: 0.0225151\n",
      "[1300]\ttraining's binary_logloss: 0.0225037\n",
      "[1301]\ttraining's binary_logloss: 0.0224939\n",
      "[1302]\ttraining's binary_logloss: 0.0224838\n",
      "[1303]\ttraining's binary_logloss: 0.0224762\n",
      "[1304]\ttraining's binary_logloss: 0.0224678\n",
      "[1305]\ttraining's binary_logloss: 0.0224588\n",
      "[1306]\ttraining's binary_logloss: 0.0224473\n",
      "[1307]\ttraining's binary_logloss: 0.0224365\n",
      "[1308]\ttraining's binary_logloss: 0.0224269\n",
      "[1309]\ttraining's binary_logloss: 0.0224184\n",
      "[1310]\ttraining's binary_logloss: 0.0224055\n",
      "[1311]\ttraining's binary_logloss: 0.0223951\n",
      "[1312]\ttraining's binary_logloss: 0.0223821\n",
      "[1313]\ttraining's binary_logloss: 0.0223718\n",
      "[1314]\ttraining's binary_logloss: 0.0223602\n",
      "[1315]\ttraining's binary_logloss: 0.0223503\n",
      "[1316]\ttraining's binary_logloss: 0.022339\n",
      "[1317]\ttraining's binary_logloss: 0.0223288\n",
      "[1318]\ttraining's binary_logloss: 0.0223196\n",
      "[1319]\ttraining's binary_logloss: 0.0223099\n",
      "[1320]\ttraining's binary_logloss: 0.0223013\n",
      "[1321]\ttraining's binary_logloss: 0.022292\n",
      "[1322]\ttraining's binary_logloss: 0.0222832\n",
      "[1323]\ttraining's binary_logloss: 0.0222726\n",
      "[1324]\ttraining's binary_logloss: 0.022263\n",
      "[1325]\ttraining's binary_logloss: 0.0222555\n",
      "[1326]\ttraining's binary_logloss: 0.0222466\n",
      "[1327]\ttraining's binary_logloss: 0.0222379\n",
      "[1328]\ttraining's binary_logloss: 0.0222292\n",
      "[1329]\ttraining's binary_logloss: 0.0222168\n",
      "[1330]\ttraining's binary_logloss: 0.0222077\n",
      "[1331]\ttraining's binary_logloss: 0.0221989\n",
      "[1332]\ttraining's binary_logloss: 0.0221888\n",
      "[1333]\ttraining's binary_logloss: 0.0221801\n",
      "[1334]\ttraining's binary_logloss: 0.0221686\n",
      "[1335]\ttraining's binary_logloss: 0.0221587\n",
      "[1336]\ttraining's binary_logloss: 0.0221476\n",
      "[1337]\ttraining's binary_logloss: 0.0221388\n",
      "[1338]\ttraining's binary_logloss: 0.0221298\n",
      "[1339]\ttraining's binary_logloss: 0.0221191\n",
      "[1340]\ttraining's binary_logloss: 0.0221105\n",
      "[1341]\ttraining's binary_logloss: 0.0221015\n",
      "[1342]\ttraining's binary_logloss: 0.02209\n",
      "[1343]\ttraining's binary_logloss: 0.0220803\n",
      "[1344]\ttraining's binary_logloss: 0.022069\n",
      "[1345]\ttraining's binary_logloss: 0.0220572\n",
      "[1346]\ttraining's binary_logloss: 0.0220482\n",
      "[1347]\ttraining's binary_logloss: 0.0220411\n",
      "[1348]\ttraining's binary_logloss: 0.0220328\n",
      "[1349]\ttraining's binary_logloss: 0.0220232\n",
      "[1350]\ttraining's binary_logloss: 0.0220156\n",
      "[1351]\ttraining's binary_logloss: 0.0220064\n",
      "[1352]\ttraining's binary_logloss: 0.0219956\n",
      "[1353]\ttraining's binary_logloss: 0.0219853\n",
      "[1354]\ttraining's binary_logloss: 0.0219769\n",
      "[1355]\ttraining's binary_logloss: 0.0219676\n",
      "[1356]\ttraining's binary_logloss: 0.0219591\n",
      "[1357]\ttraining's binary_logloss: 0.0219523\n",
      "[1358]\ttraining's binary_logloss: 0.021943\n",
      "[1359]\ttraining's binary_logloss: 0.0219338\n",
      "[1360]\ttraining's binary_logloss: 0.0219251\n",
      "[1361]\ttraining's binary_logloss: 0.0219165\n",
      "[1362]\ttraining's binary_logloss: 0.0219089\n",
      "[1363]\ttraining's binary_logloss: 0.0218995\n",
      "[1364]\ttraining's binary_logloss: 0.0218896\n",
      "[1365]\ttraining's binary_logloss: 0.0218812\n",
      "[1366]\ttraining's binary_logloss: 0.0218724\n",
      "[1367]\ttraining's binary_logloss: 0.021859\n",
      "[1368]\ttraining's binary_logloss: 0.0218501\n",
      "[1369]\ttraining's binary_logloss: 0.0218413\n",
      "[1370]\ttraining's binary_logloss: 0.0218321\n",
      "[1371]\ttraining's binary_logloss: 0.021824\n",
      "[1372]\ttraining's binary_logloss: 0.0218143\n",
      "[1373]\ttraining's binary_logloss: 0.0218035\n",
      "[1374]\ttraining's binary_logloss: 0.0217956\n",
      "[1375]\ttraining's binary_logloss: 0.0217853\n",
      "[1376]\ttraining's binary_logloss: 0.0217765\n",
      "[1377]\ttraining's binary_logloss: 0.0217656\n",
      "[1378]\ttraining's binary_logloss: 0.0217588\n",
      "[1379]\ttraining's binary_logloss: 0.0217476\n",
      "[1380]\ttraining's binary_logloss: 0.0217383\n",
      "[1381]\ttraining's binary_logloss: 0.02173\n",
      "[1382]\ttraining's binary_logloss: 0.0217213\n",
      "[1383]\ttraining's binary_logloss: 0.0217135\n",
      "[1384]\ttraining's binary_logloss: 0.0217048\n",
      "[1385]\ttraining's binary_logloss: 0.0216945\n",
      "[1386]\ttraining's binary_logloss: 0.0216831\n",
      "[1387]\ttraining's binary_logloss: 0.0216759\n",
      "[1388]\ttraining's binary_logloss: 0.0216696\n",
      "[1389]\ttraining's binary_logloss: 0.0216619\n",
      "[1390]\ttraining's binary_logloss: 0.0216543\n",
      "[1391]\ttraining's binary_logloss: 0.0216441\n",
      "[1392]\ttraining's binary_logloss: 0.0216363\n",
      "[1393]\ttraining's binary_logloss: 0.0216274\n",
      "[1394]\ttraining's binary_logloss: 0.0216203\n",
      "[1395]\ttraining's binary_logloss: 0.0216116\n",
      "[1396]\ttraining's binary_logloss: 0.0216029\n",
      "[1397]\ttraining's binary_logloss: 0.0215927\n",
      "[1398]\ttraining's binary_logloss: 0.0215846\n",
      "[1399]\ttraining's binary_logloss: 0.0215762\n",
      "[1400]\ttraining's binary_logloss: 0.0215689\n",
      "[1401]\ttraining's binary_logloss: 0.0215586\n",
      "[1402]\ttraining's binary_logloss: 0.0215519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1403]\ttraining's binary_logloss: 0.0215442\n",
      "[1404]\ttraining's binary_logloss: 0.0215341\n",
      "[1405]\ttraining's binary_logloss: 0.0215263\n",
      "[1406]\ttraining's binary_logloss: 0.0215171\n",
      "[1407]\ttraining's binary_logloss: 0.0215095\n",
      "[1408]\ttraining's binary_logloss: 0.0215005\n",
      "[1409]\ttraining's binary_logloss: 0.0214878\n",
      "[1410]\ttraining's binary_logloss: 0.0214793\n",
      "[1411]\ttraining's binary_logloss: 0.0214702\n",
      "[1412]\ttraining's binary_logloss: 0.0214622\n",
      "[1413]\ttraining's binary_logloss: 0.0214538\n",
      "[1414]\ttraining's binary_logloss: 0.0214446\n",
      "[1415]\ttraining's binary_logloss: 0.0214346\n",
      "[1416]\ttraining's binary_logloss: 0.0214265\n",
      "[1417]\ttraining's binary_logloss: 0.0214179\n",
      "[1418]\ttraining's binary_logloss: 0.0214112\n",
      "[1419]\ttraining's binary_logloss: 0.021403\n",
      "[1420]\ttraining's binary_logloss: 0.0213951\n",
      "[1421]\ttraining's binary_logloss: 0.0213863\n",
      "[1422]\ttraining's binary_logloss: 0.0213805\n",
      "[1423]\ttraining's binary_logloss: 0.0213689\n",
      "[1424]\ttraining's binary_logloss: 0.0213623\n",
      "[1425]\ttraining's binary_logloss: 0.0213547\n",
      "[1426]\ttraining's binary_logloss: 0.0213464\n",
      "[1427]\ttraining's binary_logloss: 0.0213383\n",
      "[1428]\ttraining's binary_logloss: 0.0213303\n",
      "[1429]\ttraining's binary_logloss: 0.0213225\n",
      "[1430]\ttraining's binary_logloss: 0.0213134\n",
      "[1431]\ttraining's binary_logloss: 0.0213029\n",
      "[1432]\ttraining's binary_logloss: 0.0212946\n",
      "[1433]\ttraining's binary_logloss: 0.021286\n",
      "[1434]\ttraining's binary_logloss: 0.0212788\n",
      "[1435]\ttraining's binary_logloss: 0.021272\n",
      "[1436]\ttraining's binary_logloss: 0.0212653\n",
      "[1437]\ttraining's binary_logloss: 0.0212576\n",
      "[1438]\ttraining's binary_logloss: 0.0212474\n",
      "[1439]\ttraining's binary_logloss: 0.0212377\n",
      "[1440]\ttraining's binary_logloss: 0.0212296\n",
      "[1441]\ttraining's binary_logloss: 0.0212231\n",
      "[1442]\ttraining's binary_logloss: 0.0212143\n",
      "[1443]\ttraining's binary_logloss: 0.0212067\n",
      "[1444]\ttraining's binary_logloss: 0.0211978\n",
      "[1445]\ttraining's binary_logloss: 0.0211897\n",
      "[1446]\ttraining's binary_logloss: 0.0211816\n",
      "[1447]\ttraining's binary_logloss: 0.0211733\n",
      "[1448]\ttraining's binary_logloss: 0.0211635\n",
      "[1449]\ttraining's binary_logloss: 0.021155\n",
      "[1450]\ttraining's binary_logloss: 0.021147\n",
      "[1451]\ttraining's binary_logloss: 0.0211399\n",
      "[1452]\ttraining's binary_logloss: 0.0211302\n",
      "[1453]\ttraining's binary_logloss: 0.0211209\n",
      "[1454]\ttraining's binary_logloss: 0.0211119\n",
      "[1455]\ttraining's binary_logloss: 0.0211058\n",
      "[1456]\ttraining's binary_logloss: 0.0210995\n",
      "[1457]\ttraining's binary_logloss: 0.0210919\n",
      "[1458]\ttraining's binary_logloss: 0.021084\n",
      "[1459]\ttraining's binary_logloss: 0.0210758\n",
      "[1460]\ttraining's binary_logloss: 0.0210673\n",
      "[1461]\ttraining's binary_logloss: 0.0210614\n",
      "[1462]\ttraining's binary_logloss: 0.0210557\n",
      "[1463]\ttraining's binary_logloss: 0.0210474\n",
      "[1464]\ttraining's binary_logloss: 0.0210375\n",
      "[1465]\ttraining's binary_logloss: 0.0210291\n",
      "[1466]\ttraining's binary_logloss: 0.0210201\n",
      "[1467]\ttraining's binary_logloss: 0.0210147\n",
      "[1468]\ttraining's binary_logloss: 0.021007\n",
      "[1469]\ttraining's binary_logloss: 0.0209999\n",
      "[1470]\ttraining's binary_logloss: 0.0209927\n",
      "[1471]\ttraining's binary_logloss: 0.0209845\n",
      "[1472]\ttraining's binary_logloss: 0.0209784\n",
      "[1473]\ttraining's binary_logloss: 0.0209693\n",
      "[1474]\ttraining's binary_logloss: 0.0209611\n",
      "[1475]\ttraining's binary_logloss: 0.0209534\n",
      "[1476]\ttraining's binary_logloss: 0.0209451\n",
      "[1477]\ttraining's binary_logloss: 0.0209376\n",
      "[1478]\ttraining's binary_logloss: 0.02093\n",
      "[1479]\ttraining's binary_logloss: 0.0209234\n",
      "[1480]\ttraining's binary_logloss: 0.0209168\n",
      "[1481]\ttraining's binary_logloss: 0.0209088\n",
      "[1482]\ttraining's binary_logloss: 0.0208991\n",
      "[1483]\ttraining's binary_logloss: 0.0208877\n",
      "[1484]\ttraining's binary_logloss: 0.0208793\n",
      "[1485]\ttraining's binary_logloss: 0.0208686\n",
      "[1486]\ttraining's binary_logloss: 0.0208615\n",
      "[1487]\ttraining's binary_logloss: 0.0208553\n",
      "[1488]\ttraining's binary_logloss: 0.0208466\n",
      "[1489]\ttraining's binary_logloss: 0.020838\n",
      "[1490]\ttraining's binary_logloss: 0.0208298\n",
      "[1491]\ttraining's binary_logloss: 0.0208236\n",
      "[1492]\ttraining's binary_logloss: 0.0208136\n",
      "[1493]\ttraining's binary_logloss: 0.0208029\n",
      "[1494]\ttraining's binary_logloss: 0.0207951\n",
      "[1495]\ttraining's binary_logloss: 0.0207862\n",
      "[1496]\ttraining's binary_logloss: 0.0207784\n",
      "[1497]\ttraining's binary_logloss: 0.0207718\n",
      "[1498]\ttraining's binary_logloss: 0.0207599\n",
      "[1499]\ttraining's binary_logloss: 0.02075\n",
      "[1500]\ttraining's binary_logloss: 0.0207414\n",
      "[1501]\ttraining's binary_logloss: 0.0207343\n",
      "[1502]\ttraining's binary_logloss: 0.0207269\n",
      "[1503]\ttraining's binary_logloss: 0.0207195\n",
      "[1504]\ttraining's binary_logloss: 0.02071\n",
      "[1505]\ttraining's binary_logloss: 0.0207028\n",
      "[1506]\ttraining's binary_logloss: 0.0206975\n",
      "[1507]\ttraining's binary_logloss: 0.0206897\n",
      "[1508]\ttraining's binary_logloss: 0.0206824\n",
      "[1509]\ttraining's binary_logloss: 0.0206743\n",
      "[1510]\ttraining's binary_logloss: 0.0206652\n",
      "[1511]\ttraining's binary_logloss: 0.0206561\n",
      "[1512]\ttraining's binary_logloss: 0.0206489\n",
      "[1513]\ttraining's binary_logloss: 0.0206415\n",
      "[1514]\ttraining's binary_logloss: 0.0206333\n",
      "[1515]\ttraining's binary_logloss: 0.0206258\n",
      "[1516]\ttraining's binary_logloss: 0.0206183\n",
      "[1517]\ttraining's binary_logloss: 0.0206117\n",
      "[1518]\ttraining's binary_logloss: 0.0206044\n",
      "[1519]\ttraining's binary_logloss: 0.0205966\n",
      "[1520]\ttraining's binary_logloss: 0.0205889\n",
      "[1521]\ttraining's binary_logloss: 0.0205792\n",
      "[1522]\ttraining's binary_logloss: 0.0205704\n",
      "[1523]\ttraining's binary_logloss: 0.0205633\n",
      "[1524]\ttraining's binary_logloss: 0.0205555\n",
      "[1525]\ttraining's binary_logloss: 0.0205489\n",
      "[1526]\ttraining's binary_logloss: 0.0205417\n",
      "[1527]\ttraining's binary_logloss: 0.0205356\n",
      "[1528]\ttraining's binary_logloss: 0.0205305\n",
      "[1529]\ttraining's binary_logloss: 0.0205217\n",
      "[1530]\ttraining's binary_logloss: 0.0205157\n",
      "[1531]\ttraining's binary_logloss: 0.0205074\n",
      "[1532]\ttraining's binary_logloss: 0.0204973\n",
      "[1533]\ttraining's binary_logloss: 0.020488\n",
      "[1534]\ttraining's binary_logloss: 0.0204799\n",
      "[1535]\ttraining's binary_logloss: 0.0204734\n",
      "[1536]\ttraining's binary_logloss: 0.0204648\n",
      "[1537]\ttraining's binary_logloss: 0.020456\n",
      "[1538]\ttraining's binary_logloss: 0.0204476\n",
      "[1539]\ttraining's binary_logloss: 0.0204406\n",
      "[1540]\ttraining's binary_logloss: 0.0204315\n",
      "[1541]\ttraining's binary_logloss: 0.0204239\n",
      "[1542]\ttraining's binary_logloss: 0.0204141\n",
      "[1543]\ttraining's binary_logloss: 0.0204061\n",
      "[1544]\ttraining's binary_logloss: 0.0203981\n",
      "[1545]\ttraining's binary_logloss: 0.0203898\n",
      "[1546]\ttraining's binary_logloss: 0.0203838\n",
      "[1547]\ttraining's binary_logloss: 0.0203747\n",
      "[1548]\ttraining's binary_logloss: 0.0203691\n",
      "[1549]\ttraining's binary_logloss: 0.0203613\n",
      "[1550]\ttraining's binary_logloss: 0.020352\n",
      "[1551]\ttraining's binary_logloss: 0.0203461\n",
      "[1552]\ttraining's binary_logloss: 0.0203358\n",
      "[1553]\ttraining's binary_logloss: 0.0203284\n",
      "[1554]\ttraining's binary_logloss: 0.0203196\n",
      "[1555]\ttraining's binary_logloss: 0.0203101\n",
      "[1556]\ttraining's binary_logloss: 0.0203009\n",
      "[1557]\ttraining's binary_logloss: 0.0202954\n",
      "[1558]\ttraining's binary_logloss: 0.020287\n",
      "[1559]\ttraining's binary_logloss: 0.0202778\n",
      "[1560]\ttraining's binary_logloss: 0.0202703\n",
      "[1561]\ttraining's binary_logloss: 0.0202602\n",
      "[1562]\ttraining's binary_logloss: 0.0202531\n",
      "[1563]\ttraining's binary_logloss: 0.0202451\n",
      "[1564]\ttraining's binary_logloss: 0.0202381\n",
      "[1565]\ttraining's binary_logloss: 0.0202299\n",
      "[1566]\ttraining's binary_logloss: 0.0202214\n",
      "[1567]\ttraining's binary_logloss: 0.0202115\n",
      "[1568]\ttraining's binary_logloss: 0.0202036\n",
      "[1569]\ttraining's binary_logloss: 0.0201964\n",
      "[1570]\ttraining's binary_logloss: 0.0201897\n",
      "[1571]\ttraining's binary_logloss: 0.0201807\n",
      "[1572]\ttraining's binary_logloss: 0.0201736\n",
      "[1573]\ttraining's binary_logloss: 0.0201656\n",
      "[1574]\ttraining's binary_logloss: 0.0201598\n",
      "[1575]\ttraining's binary_logloss: 0.0201526\n",
      "[1576]\ttraining's binary_logloss: 0.0201467\n",
      "[1577]\ttraining's binary_logloss: 0.0201415\n",
      "[1578]\ttraining's binary_logloss: 0.0201341\n",
      "[1579]\ttraining's binary_logloss: 0.020128\n",
      "[1580]\ttraining's binary_logloss: 0.0201211\n",
      "[1581]\ttraining's binary_logloss: 0.0201145\n",
      "[1582]\ttraining's binary_logloss: 0.0201066\n",
      "[1583]\ttraining's binary_logloss: 0.0200991\n",
      "[1584]\ttraining's binary_logloss: 0.0200923\n",
      "[1585]\ttraining's binary_logloss: 0.0200848\n",
      "[1586]\ttraining's binary_logloss: 0.0200764\n",
      "[1587]\ttraining's binary_logloss: 0.0200714\n",
      "[1588]\ttraining's binary_logloss: 0.0200661\n",
      "[1589]\ttraining's binary_logloss: 0.0200588\n",
      "[1590]\ttraining's binary_logloss: 0.0200523\n",
      "[1591]\ttraining's binary_logloss: 0.0200458\n",
      "[1592]\ttraining's binary_logloss: 0.0200377\n",
      "[1593]\ttraining's binary_logloss: 0.0200315\n",
      "[1594]\ttraining's binary_logloss: 0.0200238\n",
      "[1595]\ttraining's binary_logloss: 0.0200173\n",
      "[1596]\ttraining's binary_logloss: 0.020012\n",
      "[1597]\ttraining's binary_logloss: 0.020004\n",
      "[1598]\ttraining's binary_logloss: 0.0199983\n",
      "[1599]\ttraining's binary_logloss: 0.0199923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttraining's binary_logloss: 0.0199835\n",
      "[1601]\ttraining's binary_logloss: 0.0199771\n",
      "[1602]\ttraining's binary_logloss: 0.0199706\n",
      "[1603]\ttraining's binary_logloss: 0.0199614\n",
      "[1604]\ttraining's binary_logloss: 0.019955\n",
      "[1605]\ttraining's binary_logloss: 0.0199446\n",
      "[1606]\ttraining's binary_logloss: 0.019937\n",
      "[1607]\ttraining's binary_logloss: 0.0199289\n",
      "[1608]\ttraining's binary_logloss: 0.0199215\n",
      "[1609]\ttraining's binary_logloss: 0.0199163\n",
      "[1610]\ttraining's binary_logloss: 0.0199076\n",
      "[1611]\ttraining's binary_logloss: 0.0199002\n",
      "[1612]\ttraining's binary_logloss: 0.0198928\n",
      "[1613]\ttraining's binary_logloss: 0.0198862\n",
      "[1614]\ttraining's binary_logloss: 0.0198791\n",
      "[1615]\ttraining's binary_logloss: 0.0198695\n",
      "[1616]\ttraining's binary_logloss: 0.019862\n",
      "[1617]\ttraining's binary_logloss: 0.0198536\n",
      "[1618]\ttraining's binary_logloss: 0.0198477\n",
      "[1619]\ttraining's binary_logloss: 0.0198376\n",
      "[1620]\ttraining's binary_logloss: 0.0198318\n",
      "[1621]\ttraining's binary_logloss: 0.0198239\n",
      "[1622]\ttraining's binary_logloss: 0.0198169\n",
      "[1623]\ttraining's binary_logloss: 0.0198096\n",
      "[1624]\ttraining's binary_logloss: 0.0198019\n",
      "[1625]\ttraining's binary_logloss: 0.0197946\n",
      "[1626]\ttraining's binary_logloss: 0.0197897\n",
      "[1627]\ttraining's binary_logloss: 0.019783\n",
      "[1628]\ttraining's binary_logloss: 0.0197756\n",
      "[1629]\ttraining's binary_logloss: 0.0197677\n",
      "[1630]\ttraining's binary_logloss: 0.0197619\n",
      "[1631]\ttraining's binary_logloss: 0.0197553\n",
      "[1632]\ttraining's binary_logloss: 0.0197454\n",
      "[1633]\ttraining's binary_logloss: 0.0197392\n",
      "[1634]\ttraining's binary_logloss: 0.0197337\n",
      "[1635]\ttraining's binary_logloss: 0.0197271\n",
      "[1636]\ttraining's binary_logloss: 0.0197208\n",
      "[1637]\ttraining's binary_logloss: 0.0197157\n",
      "[1638]\ttraining's binary_logloss: 0.0197069\n",
      "[1639]\ttraining's binary_logloss: 0.0197006\n",
      "[1640]\ttraining's binary_logloss: 0.0196951\n",
      "[1641]\ttraining's binary_logloss: 0.0196893\n",
      "[1642]\ttraining's binary_logloss: 0.0196844\n",
      "[1643]\ttraining's binary_logloss: 0.019676\n",
      "[1644]\ttraining's binary_logloss: 0.0196667\n",
      "[1645]\ttraining's binary_logloss: 0.0196588\n",
      "[1646]\ttraining's binary_logloss: 0.019652\n",
      "[1647]\ttraining's binary_logloss: 0.0196437\n",
      "[1648]\ttraining's binary_logloss: 0.0196363\n",
      "[1649]\ttraining's binary_logloss: 0.0196306\n",
      "[1650]\ttraining's binary_logloss: 0.0196232\n",
      "[1651]\ttraining's binary_logloss: 0.019616\n",
      "[1652]\ttraining's binary_logloss: 0.0196085\n",
      "[1653]\ttraining's binary_logloss: 0.0196007\n",
      "[1654]\ttraining's binary_logloss: 0.0195933\n",
      "[1655]\ttraining's binary_logloss: 0.019588\n",
      "[1656]\ttraining's binary_logloss: 0.0195792\n",
      "[1657]\ttraining's binary_logloss: 0.0195704\n",
      "[1658]\ttraining's binary_logloss: 0.0195649\n",
      "[1659]\ttraining's binary_logloss: 0.0195593\n",
      "[1660]\ttraining's binary_logloss: 0.0195516\n",
      "[1661]\ttraining's binary_logloss: 0.0195463\n",
      "[1662]\ttraining's binary_logloss: 0.0195393\n",
      "[1663]\ttraining's binary_logloss: 0.0195339\n",
      "[1664]\ttraining's binary_logloss: 0.0195275\n",
      "[1665]\ttraining's binary_logloss: 0.0195193\n",
      "[1666]\ttraining's binary_logloss: 0.019513\n",
      "[1667]\ttraining's binary_logloss: 0.0195073\n",
      "[1668]\ttraining's binary_logloss: 0.019502\n",
      "[1669]\ttraining's binary_logloss: 0.0194948\n",
      "[1670]\ttraining's binary_logloss: 0.019489\n",
      "[1671]\ttraining's binary_logloss: 0.019482\n",
      "[1672]\ttraining's binary_logloss: 0.0194748\n",
      "[1673]\ttraining's binary_logloss: 0.0194699\n",
      "[1674]\ttraining's binary_logloss: 0.0194623\n",
      "[1675]\ttraining's binary_logloss: 0.0194564\n",
      "[1676]\ttraining's binary_logloss: 0.0194465\n",
      "[1677]\ttraining's binary_logloss: 0.0194371\n",
      "[1678]\ttraining's binary_logloss: 0.0194291\n",
      "[1679]\ttraining's binary_logloss: 0.0194224\n",
      "[1680]\ttraining's binary_logloss: 0.0194145\n",
      "[1681]\ttraining's binary_logloss: 0.0194093\n",
      "[1682]\ttraining's binary_logloss: 0.0194038\n",
      "[1683]\ttraining's binary_logloss: 0.0193968\n",
      "[1684]\ttraining's binary_logloss: 0.0193928\n",
      "[1685]\ttraining's binary_logloss: 0.0193849\n",
      "[1686]\ttraining's binary_logloss: 0.0193787\n",
      "[1687]\ttraining's binary_logloss: 0.0193717\n",
      "[1688]\ttraining's binary_logloss: 0.0193639\n",
      "[1689]\ttraining's binary_logloss: 0.0193571\n",
      "[1690]\ttraining's binary_logloss: 0.0193498\n",
      "[1691]\ttraining's binary_logloss: 0.0193451\n",
      "[1692]\ttraining's binary_logloss: 0.0193381\n",
      "[1693]\ttraining's binary_logloss: 0.0193331\n",
      "[1694]\ttraining's binary_logloss: 0.0193258\n",
      "[1695]\ttraining's binary_logloss: 0.019319\n",
      "[1696]\ttraining's binary_logloss: 0.0193111\n",
      "[1697]\ttraining's binary_logloss: 0.0193057\n",
      "[1698]\ttraining's binary_logloss: 0.0192996\n",
      "[1699]\ttraining's binary_logloss: 0.0192946\n",
      "[1700]\ttraining's binary_logloss: 0.0192869\n",
      "[1701]\ttraining's binary_logloss: 0.0192791\n",
      "[1702]\ttraining's binary_logloss: 0.0192715\n",
      "[1703]\ttraining's binary_logloss: 0.0192645\n",
      "[1704]\ttraining's binary_logloss: 0.0192594\n",
      "[1705]\ttraining's binary_logloss: 0.0192534\n",
      "[1706]\ttraining's binary_logloss: 0.0192463\n",
      "[1707]\ttraining's binary_logloss: 0.0192401\n",
      "[1708]\ttraining's binary_logloss: 0.0192351\n",
      "[1709]\ttraining's binary_logloss: 0.0192287\n",
      "[1710]\ttraining's binary_logloss: 0.019222\n",
      "[1711]\ttraining's binary_logloss: 0.0192138\n",
      "[1712]\ttraining's binary_logloss: 0.0192085\n",
      "[1713]\ttraining's binary_logloss: 0.0192025\n",
      "[1714]\ttraining's binary_logloss: 0.0191962\n",
      "[1715]\ttraining's binary_logloss: 0.0191924\n",
      "[1716]\ttraining's binary_logloss: 0.0191869\n",
      "[1717]\ttraining's binary_logloss: 0.0191805\n",
      "[1718]\ttraining's binary_logloss: 0.0191738\n",
      "[1719]\ttraining's binary_logloss: 0.0191667\n",
      "[1720]\ttraining's binary_logloss: 0.0191596\n",
      "[1721]\ttraining's binary_logloss: 0.0191552\n",
      "[1722]\ttraining's binary_logloss: 0.0191499\n",
      "[1723]\ttraining's binary_logloss: 0.0191461\n",
      "[1724]\ttraining's binary_logloss: 0.0191409\n",
      "[1725]\ttraining's binary_logloss: 0.0191345\n",
      "[1726]\ttraining's binary_logloss: 0.0191265\n",
      "[1727]\ttraining's binary_logloss: 0.0191198\n",
      "[1728]\ttraining's binary_logloss: 0.0191144\n",
      "[1729]\ttraining's binary_logloss: 0.0191095\n",
      "[1730]\ttraining's binary_logloss: 0.019103\n",
      "[1731]\ttraining's binary_logloss: 0.0190963\n",
      "[1732]\ttraining's binary_logloss: 0.0190906\n",
      "[1733]\ttraining's binary_logloss: 0.0190858\n",
      "[1734]\ttraining's binary_logloss: 0.0190807\n",
      "[1735]\ttraining's binary_logloss: 0.0190747\n",
      "[1736]\ttraining's binary_logloss: 0.0190676\n",
      "[1737]\ttraining's binary_logloss: 0.0190626\n",
      "[1738]\ttraining's binary_logloss: 0.0190532\n",
      "[1739]\ttraining's binary_logloss: 0.019048\n",
      "[1740]\ttraining's binary_logloss: 0.0190411\n",
      "[1741]\ttraining's binary_logloss: 0.0190339\n",
      "[1742]\ttraining's binary_logloss: 0.0190257\n",
      "[1743]\ttraining's binary_logloss: 0.0190185\n",
      "[1744]\ttraining's binary_logloss: 0.01901\n",
      "[1745]\ttraining's binary_logloss: 0.0190028\n",
      "[1746]\ttraining's binary_logloss: 0.0189961\n",
      "[1747]\ttraining's binary_logloss: 0.0189913\n",
      "[1748]\ttraining's binary_logloss: 0.018985\n",
      "[1749]\ttraining's binary_logloss: 0.0189802\n",
      "[1750]\ttraining's binary_logloss: 0.0189754\n",
      "[1751]\ttraining's binary_logloss: 0.0189703\n",
      "[1752]\ttraining's binary_logloss: 0.0189627\n",
      "[1753]\ttraining's binary_logloss: 0.0189554\n",
      "[1754]\ttraining's binary_logloss: 0.0189471\n",
      "[1755]\ttraining's binary_logloss: 0.0189416\n",
      "[1756]\ttraining's binary_logloss: 0.018937\n",
      "[1757]\ttraining's binary_logloss: 0.0189311\n",
      "[1758]\ttraining's binary_logloss: 0.0189243\n",
      "[1759]\ttraining's binary_logloss: 0.0189184\n",
      "[1760]\ttraining's binary_logloss: 0.0189117\n",
      "[1761]\ttraining's binary_logloss: 0.0189063\n",
      "[1762]\ttraining's binary_logloss: 0.0188994\n",
      "[1763]\ttraining's binary_logloss: 0.0188925\n",
      "[1764]\ttraining's binary_logloss: 0.0188849\n",
      "[1765]\ttraining's binary_logloss: 0.01888\n",
      "[1766]\ttraining's binary_logloss: 0.018875\n",
      "[1767]\ttraining's binary_logloss: 0.0188702\n",
      "[1768]\ttraining's binary_logloss: 0.0188633\n",
      "[1769]\ttraining's binary_logloss: 0.0188582\n",
      "[1770]\ttraining's binary_logloss: 0.0188515\n",
      "[1771]\ttraining's binary_logloss: 0.0188455\n",
      "[1772]\ttraining's binary_logloss: 0.0188409\n",
      "[1773]\ttraining's binary_logloss: 0.0188357\n",
      "[1774]\ttraining's binary_logloss: 0.0188277\n",
      "[1775]\ttraining's binary_logloss: 0.0188208\n",
      "[1776]\ttraining's binary_logloss: 0.0188142\n",
      "[1777]\ttraining's binary_logloss: 0.0188096\n",
      "[1778]\ttraining's binary_logloss: 0.0188039\n",
      "[1779]\ttraining's binary_logloss: 0.0187979\n",
      "[1780]\ttraining's binary_logloss: 0.0187901\n",
      "[1781]\ttraining's binary_logloss: 0.018784\n",
      "[1782]\ttraining's binary_logloss: 0.0187783\n",
      "[1783]\ttraining's binary_logloss: 0.0187714\n",
      "[1784]\ttraining's binary_logloss: 0.018764\n",
      "[1785]\ttraining's binary_logloss: 0.0187595\n",
      "[1786]\ttraining's binary_logloss: 0.0187545\n",
      "[1787]\ttraining's binary_logloss: 0.0187479\n",
      "[1788]\ttraining's binary_logloss: 0.0187414\n",
      "[1789]\ttraining's binary_logloss: 0.0187346\n",
      "[1790]\ttraining's binary_logloss: 0.018731\n",
      "[1791]\ttraining's binary_logloss: 0.018725\n",
      "[1792]\ttraining's binary_logloss: 0.0187201\n",
      "[1793]\ttraining's binary_logloss: 0.0187134\n",
      "[1794]\ttraining's binary_logloss: 0.018709\n",
      "[1795]\ttraining's binary_logloss: 0.0187033\n",
      "[1796]\ttraining's binary_logloss: 0.0186968\n",
      "[1797]\ttraining's binary_logloss: 0.0186895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1798]\ttraining's binary_logloss: 0.0186817\n",
      "[1799]\ttraining's binary_logloss: 0.0186764\n",
      "[1800]\ttraining's binary_logloss: 0.0186729\n",
      "[1801]\ttraining's binary_logloss: 0.0186661\n",
      "[1802]\ttraining's binary_logloss: 0.0186595\n",
      "[1803]\ttraining's binary_logloss: 0.0186548\n",
      "[1804]\ttraining's binary_logloss: 0.0186498\n",
      "[1805]\ttraining's binary_logloss: 0.0186432\n",
      "[1806]\ttraining's binary_logloss: 0.0186365\n",
      "[1807]\ttraining's binary_logloss: 0.0186292\n",
      "[1808]\ttraining's binary_logloss: 0.0186225\n",
      "[1809]\ttraining's binary_logloss: 0.0186167\n",
      "[1810]\ttraining's binary_logloss: 0.0186104\n",
      "[1811]\ttraining's binary_logloss: 0.0186037\n",
      "[1812]\ttraining's binary_logloss: 0.0185999\n",
      "[1813]\ttraining's binary_logloss: 0.0185953\n",
      "[1814]\ttraining's binary_logloss: 0.0185908\n",
      "[1815]\ttraining's binary_logloss: 0.0185854\n",
      "[1816]\ttraining's binary_logloss: 0.0185792\n",
      "[1817]\ttraining's binary_logloss: 0.0185718\n",
      "[1818]\ttraining's binary_logloss: 0.0185676\n",
      "[1819]\ttraining's binary_logloss: 0.0185628\n",
      "[1820]\ttraining's binary_logloss: 0.0185555\n",
      "[1821]\ttraining's binary_logloss: 0.0185511\n",
      "[1822]\ttraining's binary_logloss: 0.0185451\n",
      "[1823]\ttraining's binary_logloss: 0.0185394\n",
      "[1824]\ttraining's binary_logloss: 0.018533\n",
      "[1825]\ttraining's binary_logloss: 0.0185273\n",
      "[1826]\ttraining's binary_logloss: 0.0185201\n",
      "[1827]\ttraining's binary_logloss: 0.0185146\n",
      "[1828]\ttraining's binary_logloss: 0.0185086\n",
      "[1829]\ttraining's binary_logloss: 0.0185023\n",
      "[1830]\ttraining's binary_logloss: 0.0184959\n",
      "[1831]\ttraining's binary_logloss: 0.0184909\n",
      "[1832]\ttraining's binary_logloss: 0.0184862\n",
      "[1833]\ttraining's binary_logloss: 0.0184808\n",
      "[1834]\ttraining's binary_logloss: 0.0184767\n",
      "[1835]\ttraining's binary_logloss: 0.0184718\n",
      "[1836]\ttraining's binary_logloss: 0.0184662\n",
      "[1837]\ttraining's binary_logloss: 0.0184615\n",
      "[1838]\ttraining's binary_logloss: 0.0184548\n",
      "[1839]\ttraining's binary_logloss: 0.0184474\n",
      "[1840]\ttraining's binary_logloss: 0.0184427\n",
      "[1841]\ttraining's binary_logloss: 0.0184382\n",
      "[1842]\ttraining's binary_logloss: 0.0184318\n",
      "[1843]\ttraining's binary_logloss: 0.0184236\n",
      "[1844]\ttraining's binary_logloss: 0.0184168\n",
      "[1845]\ttraining's binary_logloss: 0.0184097\n",
      "[1846]\ttraining's binary_logloss: 0.0184032\n",
      "[1847]\ttraining's binary_logloss: 0.018398\n",
      "[1848]\ttraining's binary_logloss: 0.0183935\n",
      "[1849]\ttraining's binary_logloss: 0.0183885\n",
      "[1850]\ttraining's binary_logloss: 0.018381\n",
      "[1851]\ttraining's binary_logloss: 0.0183751\n",
      "[1852]\ttraining's binary_logloss: 0.018369\n",
      "[1853]\ttraining's binary_logloss: 0.0183647\n",
      "[1854]\ttraining's binary_logloss: 0.0183584\n",
      "[1855]\ttraining's binary_logloss: 0.0183515\n",
      "[1856]\ttraining's binary_logloss: 0.018345\n",
      "[1857]\ttraining's binary_logloss: 0.0183396\n",
      "[1858]\ttraining's binary_logloss: 0.0183357\n",
      "[1859]\ttraining's binary_logloss: 0.0183287\n",
      "[1860]\ttraining's binary_logloss: 0.0183217\n",
      "[1861]\ttraining's binary_logloss: 0.0183143\n",
      "[1862]\ttraining's binary_logloss: 0.0183098\n",
      "[1863]\ttraining's binary_logloss: 0.0183053\n",
      "[1864]\ttraining's binary_logloss: 0.0182991\n",
      "[1865]\ttraining's binary_logloss: 0.018294\n",
      "[1866]\ttraining's binary_logloss: 0.0182893\n",
      "[1867]\ttraining's binary_logloss: 0.0182842\n",
      "[1868]\ttraining's binary_logloss: 0.0182798\n",
      "[1869]\ttraining's binary_logloss: 0.0182748\n",
      "[1870]\ttraining's binary_logloss: 0.0182697\n",
      "[1871]\ttraining's binary_logloss: 0.0182628\n",
      "[1872]\ttraining's binary_logloss: 0.0182584\n",
      "[1873]\ttraining's binary_logloss: 0.018253\n",
      "[1874]\ttraining's binary_logloss: 0.0182469\n",
      "[1875]\ttraining's binary_logloss: 0.018242\n",
      "[1876]\ttraining's binary_logloss: 0.0182366\n",
      "[1877]\ttraining's binary_logloss: 0.0182317\n",
      "[1878]\ttraining's binary_logloss: 0.0182267\n",
      "[1879]\ttraining's binary_logloss: 0.0182221\n",
      "[1880]\ttraining's binary_logloss: 0.0182151\n",
      "[1881]\ttraining's binary_logloss: 0.0182123\n",
      "[1882]\ttraining's binary_logloss: 0.018207\n",
      "[1883]\ttraining's binary_logloss: 0.0182016\n",
      "[1884]\ttraining's binary_logloss: 0.0181971\n",
      "[1885]\ttraining's binary_logloss: 0.0181924\n",
      "[1886]\ttraining's binary_logloss: 0.0181879\n",
      "[1887]\ttraining's binary_logloss: 0.0181803\n",
      "[1888]\ttraining's binary_logloss: 0.0181759\n",
      "[1889]\ttraining's binary_logloss: 0.0181693\n",
      "[1890]\ttraining's binary_logloss: 0.0181645\n",
      "[1891]\ttraining's binary_logloss: 0.0181572\n",
      "[1892]\ttraining's binary_logloss: 0.018152\n",
      "[1893]\ttraining's binary_logloss: 0.0181429\n",
      "[1894]\ttraining's binary_logloss: 0.0181368\n",
      "[1895]\ttraining's binary_logloss: 0.0181299\n",
      "[1896]\ttraining's binary_logloss: 0.0181254\n",
      "[1897]\ttraining's binary_logloss: 0.018119\n",
      "[1898]\ttraining's binary_logloss: 0.0181137\n",
      "[1899]\ttraining's binary_logloss: 0.018109\n",
      "[1900]\ttraining's binary_logloss: 0.0181034\n",
      "[1901]\ttraining's binary_logloss: 0.0180966\n",
      "[1902]\ttraining's binary_logloss: 0.0180901\n",
      "[1903]\ttraining's binary_logloss: 0.0180858\n",
      "[1904]\ttraining's binary_logloss: 0.0180807\n",
      "[1905]\ttraining's binary_logloss: 0.0180737\n",
      "[1906]\ttraining's binary_logloss: 0.018068\n",
      "[1907]\ttraining's binary_logloss: 0.0180624\n",
      "[1908]\ttraining's binary_logloss: 0.0180562\n",
      "[1909]\ttraining's binary_logloss: 0.0180525\n",
      "[1910]\ttraining's binary_logloss: 0.0180474\n",
      "[1911]\ttraining's binary_logloss: 0.0180418\n",
      "[1912]\ttraining's binary_logloss: 0.0180379\n",
      "[1913]\ttraining's binary_logloss: 0.0180322\n",
      "[1914]\ttraining's binary_logloss: 0.018028\n",
      "[1915]\ttraining's binary_logloss: 0.0180224\n",
      "[1916]\ttraining's binary_logloss: 0.0180156\n",
      "[1917]\ttraining's binary_logloss: 0.0180105\n",
      "[1918]\ttraining's binary_logloss: 0.018006\n",
      "[1919]\ttraining's binary_logloss: 0.0180019\n",
      "[1920]\ttraining's binary_logloss: 0.0179963\n",
      "[1921]\ttraining's binary_logloss: 0.0179901\n",
      "[1922]\ttraining's binary_logloss: 0.0179848\n",
      "[1923]\ttraining's binary_logloss: 0.0179795\n",
      "[1924]\ttraining's binary_logloss: 0.0179731\n",
      "[1925]\ttraining's binary_logloss: 0.0179682\n",
      "[1926]\ttraining's binary_logloss: 0.0179624\n",
      "[1927]\ttraining's binary_logloss: 0.0179574\n",
      "[1928]\ttraining's binary_logloss: 0.017953\n",
      "[1929]\ttraining's binary_logloss: 0.017946\n",
      "[1930]\ttraining's binary_logloss: 0.0179395\n",
      "[1931]\ttraining's binary_logloss: 0.0179328\n",
      "[1932]\ttraining's binary_logloss: 0.0179292\n",
      "[1933]\ttraining's binary_logloss: 0.0179246\n",
      "[1934]\ttraining's binary_logloss: 0.0179196\n",
      "[1935]\ttraining's binary_logloss: 0.0179153\n",
      "[1936]\ttraining's binary_logloss: 0.0179102\n",
      "[1937]\ttraining's binary_logloss: 0.0179028\n",
      "[1938]\ttraining's binary_logloss: 0.0178966\n",
      "[1939]\ttraining's binary_logloss: 0.0178903\n",
      "[1940]\ttraining's binary_logloss: 0.0178862\n",
      "[1941]\ttraining's binary_logloss: 0.0178819\n",
      "[1942]\ttraining's binary_logloss: 0.0178771\n",
      "[1943]\ttraining's binary_logloss: 0.0178705\n",
      "[1944]\ttraining's binary_logloss: 0.0178678\n",
      "[1945]\ttraining's binary_logloss: 0.0178627\n",
      "[1946]\ttraining's binary_logloss: 0.0178587\n",
      "[1947]\ttraining's binary_logloss: 0.0178537\n",
      "[1948]\ttraining's binary_logloss: 0.017849\n",
      "[1949]\ttraining's binary_logloss: 0.0178442\n",
      "[1950]\ttraining's binary_logloss: 0.0178404\n",
      "[1951]\ttraining's binary_logloss: 0.017835\n",
      "[1952]\ttraining's binary_logloss: 0.0178304\n",
      "[1953]\ttraining's binary_logloss: 0.0178267\n",
      "[1954]\ttraining's binary_logloss: 0.0178218\n",
      "[1955]\ttraining's binary_logloss: 0.017818\n",
      "[1956]\ttraining's binary_logloss: 0.0178137\n",
      "[1957]\ttraining's binary_logloss: 0.0178075\n",
      "[1958]\ttraining's binary_logloss: 0.0178026\n",
      "[1959]\ttraining's binary_logloss: 0.0177989\n",
      "[1960]\ttraining's binary_logloss: 0.0177944\n",
      "[1961]\ttraining's binary_logloss: 0.017788\n",
      "[1962]\ttraining's binary_logloss: 0.0177828\n",
      "[1963]\ttraining's binary_logloss: 0.0177776\n",
      "[1964]\ttraining's binary_logloss: 0.0177712\n",
      "[1965]\ttraining's binary_logloss: 0.0177663\n",
      "[1966]\ttraining's binary_logloss: 0.0177625\n",
      "[1967]\ttraining's binary_logloss: 0.0177594\n",
      "[1968]\ttraining's binary_logloss: 0.0177533\n",
      "[1969]\ttraining's binary_logloss: 0.0177477\n",
      "[1970]\ttraining's binary_logloss: 0.017742\n",
      "[1971]\ttraining's binary_logloss: 0.017738\n",
      "[1972]\ttraining's binary_logloss: 0.0177313\n",
      "[1973]\ttraining's binary_logloss: 0.0177252\n",
      "[1974]\ttraining's binary_logloss: 0.0177207\n",
      "[1975]\ttraining's binary_logloss: 0.0177151\n",
      "[1976]\ttraining's binary_logloss: 0.017709\n",
      "[1977]\ttraining's binary_logloss: 0.0177047\n",
      "[1978]\ttraining's binary_logloss: 0.0176993\n",
      "[1979]\ttraining's binary_logloss: 0.0176955\n",
      "[1980]\ttraining's binary_logloss: 0.0176917\n",
      "[1981]\ttraining's binary_logloss: 0.0176864\n",
      "[1982]\ttraining's binary_logloss: 0.0176817\n",
      "[1983]\ttraining's binary_logloss: 0.0176769\n",
      "[1984]\ttraining's binary_logloss: 0.0176718\n",
      "[1985]\ttraining's binary_logloss: 0.0176686\n",
      "[1986]\ttraining's binary_logloss: 0.0176647\n",
      "[1987]\ttraining's binary_logloss: 0.0176617\n",
      "[1988]\ttraining's binary_logloss: 0.017657\n",
      "[1989]\ttraining's binary_logloss: 0.0176514\n",
      "[1990]\ttraining's binary_logloss: 0.0176452\n",
      "[1991]\ttraining's binary_logloss: 0.0176387\n",
      "[1992]\ttraining's binary_logloss: 0.0176354\n",
      "[1993]\ttraining's binary_logloss: 0.0176299\n",
      "[1994]\ttraining's binary_logloss: 0.0176243\n",
      "[1995]\ttraining's binary_logloss: 0.0176184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1996]\ttraining's binary_logloss: 0.0176147\n",
      "[1997]\ttraining's binary_logloss: 0.0176087\n",
      "[1998]\ttraining's binary_logloss: 0.0176049\n",
      "[1999]\ttraining's binary_logloss: 0.0175993\n",
      "[2000]\ttraining's binary_logloss: 0.0175938\n",
      "[2001]\ttraining's binary_logloss: 0.0175886\n",
      "[2002]\ttraining's binary_logloss: 0.0175841\n",
      "[2003]\ttraining's binary_logloss: 0.0175803\n",
      "[2004]\ttraining's binary_logloss: 0.0175756\n",
      "[2005]\ttraining's binary_logloss: 0.0175694\n",
      "[2006]\ttraining's binary_logloss: 0.0175658\n",
      "[2007]\ttraining's binary_logloss: 0.0175603\n",
      "[2008]\ttraining's binary_logloss: 0.017556\n",
      "[2009]\ttraining's binary_logloss: 0.0175517\n",
      "[2010]\ttraining's binary_logloss: 0.0175466\n",
      "[2011]\ttraining's binary_logloss: 0.0175396\n",
      "[2012]\ttraining's binary_logloss: 0.0175351\n",
      "[2013]\ttraining's binary_logloss: 0.0175293\n",
      "[2014]\ttraining's binary_logloss: 0.0175231\n",
      "[2015]\ttraining's binary_logloss: 0.0175194\n",
      "[2016]\ttraining's binary_logloss: 0.0175141\n",
      "[2017]\ttraining's binary_logloss: 0.0175078\n",
      "[2018]\ttraining's binary_logloss: 0.0175032\n",
      "[2019]\ttraining's binary_logloss: 0.0174984\n",
      "[2020]\ttraining's binary_logloss: 0.0174942\n",
      "[2021]\ttraining's binary_logloss: 0.0174877\n",
      "[2022]\ttraining's binary_logloss: 0.0174844\n",
      "[2023]\ttraining's binary_logloss: 0.0174798\n",
      "[2024]\ttraining's binary_logloss: 0.0174757\n",
      "[2025]\ttraining's binary_logloss: 0.0174697\n",
      "[2026]\ttraining's binary_logloss: 0.0174651\n",
      "[2027]\ttraining's binary_logloss: 0.017459\n",
      "[2028]\ttraining's binary_logloss: 0.0174545\n",
      "[2029]\ttraining's binary_logloss: 0.01745\n",
      "[2030]\ttraining's binary_logloss: 0.0174436\n",
      "[2031]\ttraining's binary_logloss: 0.0174403\n",
      "[2032]\ttraining's binary_logloss: 0.0174361\n",
      "[2033]\ttraining's binary_logloss: 0.0174321\n",
      "[2034]\ttraining's binary_logloss: 0.0174269\n",
      "[2035]\ttraining's binary_logloss: 0.0174217\n",
      "[2036]\ttraining's binary_logloss: 0.0174168\n",
      "[2037]\ttraining's binary_logloss: 0.0174114\n",
      "[2038]\ttraining's binary_logloss: 0.017408\n",
      "[2039]\ttraining's binary_logloss: 0.0174009\n",
      "[2040]\ttraining's binary_logloss: 0.0173926\n",
      "[2041]\ttraining's binary_logloss: 0.0173866\n",
      "[2042]\ttraining's binary_logloss: 0.0173806\n",
      "[2043]\ttraining's binary_logloss: 0.0173751\n",
      "[2044]\ttraining's binary_logloss: 0.0173712\n",
      "[2045]\ttraining's binary_logloss: 0.0173676\n",
      "[2046]\ttraining's binary_logloss: 0.0173647\n",
      "[2047]\ttraining's binary_logloss: 0.0173602\n",
      "[2048]\ttraining's binary_logloss: 0.0173557\n",
      "[2049]\ttraining's binary_logloss: 0.0173512\n",
      "[2050]\ttraining's binary_logloss: 0.0173457\n",
      "[2051]\ttraining's binary_logloss: 0.0173409\n",
      "[2052]\ttraining's binary_logloss: 0.0173377\n",
      "[2053]\ttraining's binary_logloss: 0.0173337\n",
      "[2054]\ttraining's binary_logloss: 0.017328\n",
      "[2055]\ttraining's binary_logloss: 0.0173223\n",
      "[2056]\ttraining's binary_logloss: 0.0173166\n",
      "[2057]\ttraining's binary_logloss: 0.0173131\n",
      "[2058]\ttraining's binary_logloss: 0.0173091\n",
      "[2059]\ttraining's binary_logloss: 0.0173044\n",
      "[2060]\ttraining's binary_logloss: 0.0173013\n",
      "[2061]\ttraining's binary_logloss: 0.0172978\n",
      "[2062]\ttraining's binary_logloss: 0.0172942\n",
      "[2063]\ttraining's binary_logloss: 0.0172888\n",
      "[2064]\ttraining's binary_logloss: 0.017285\n",
      "[2065]\ttraining's binary_logloss: 0.0172799\n",
      "[2066]\ttraining's binary_logloss: 0.0172764\n",
      "[2067]\ttraining's binary_logloss: 0.017272\n",
      "[2068]\ttraining's binary_logloss: 0.0172675\n",
      "[2069]\ttraining's binary_logloss: 0.0172627\n",
      "[2070]\ttraining's binary_logloss: 0.0172568\n",
      "[2071]\ttraining's binary_logloss: 0.0172528\n",
      "[2072]\ttraining's binary_logloss: 0.0172469\n",
      "[2073]\ttraining's binary_logloss: 0.017242\n",
      "[2074]\ttraining's binary_logloss: 0.0172375\n",
      "[2075]\ttraining's binary_logloss: 0.0172336\n",
      "[2076]\ttraining's binary_logloss: 0.0172275\n",
      "[2077]\ttraining's binary_logloss: 0.0172222\n",
      "[2078]\ttraining's binary_logloss: 0.0172178\n",
      "[2079]\ttraining's binary_logloss: 0.0172128\n",
      "[2080]\ttraining's binary_logloss: 0.0172082\n",
      "[2081]\ttraining's binary_logloss: 0.0172051\n",
      "[2082]\ttraining's binary_logloss: 0.0172006\n",
      "[2083]\ttraining's binary_logloss: 0.0171969\n",
      "[2084]\ttraining's binary_logloss: 0.0171931\n",
      "[2085]\ttraining's binary_logloss: 0.0171876\n",
      "[2086]\ttraining's binary_logloss: 0.0171825\n",
      "[2087]\ttraining's binary_logloss: 0.0171767\n",
      "[2088]\ttraining's binary_logloss: 0.0171722\n",
      "[2089]\ttraining's binary_logloss: 0.0171694\n",
      "[2090]\ttraining's binary_logloss: 0.0171641\n",
      "[2091]\ttraining's binary_logloss: 0.0171597\n",
      "[2092]\ttraining's binary_logloss: 0.0171546\n",
      "[2093]\ttraining's binary_logloss: 0.0171516\n",
      "[2094]\ttraining's binary_logloss: 0.017147\n",
      "[2095]\ttraining's binary_logloss: 0.017142\n",
      "[2096]\ttraining's binary_logloss: 0.0171379\n",
      "[2097]\ttraining's binary_logloss: 0.0171349\n",
      "[2098]\ttraining's binary_logloss: 0.0171305\n",
      "[2099]\ttraining's binary_logloss: 0.0171264\n",
      "[2100]\ttraining's binary_logloss: 0.0171227\n",
      "[2101]\ttraining's binary_logloss: 0.0171174\n",
      "[2102]\ttraining's binary_logloss: 0.0171139\n",
      "[2103]\ttraining's binary_logloss: 0.0171084\n",
      "[2104]\ttraining's binary_logloss: 0.0171027\n",
      "[2105]\ttraining's binary_logloss: 0.0170978\n",
      "[2106]\ttraining's binary_logloss: 0.0170933\n",
      "[2107]\ttraining's binary_logloss: 0.0170901\n",
      "[2108]\ttraining's binary_logloss: 0.0170863\n",
      "[2109]\ttraining's binary_logloss: 0.0170819\n",
      "[2110]\ttraining's binary_logloss: 0.0170773\n",
      "[2111]\ttraining's binary_logloss: 0.0170724\n",
      "[2112]\ttraining's binary_logloss: 0.0170668\n",
      "[2113]\ttraining's binary_logloss: 0.0170625\n",
      "[2114]\ttraining's binary_logloss: 0.0170578\n",
      "[2115]\ttraining's binary_logloss: 0.0170535\n",
      "[2116]\ttraining's binary_logloss: 0.0170477\n",
      "[2117]\ttraining's binary_logloss: 0.0170435\n",
      "[2118]\ttraining's binary_logloss: 0.0170387\n",
      "[2119]\ttraining's binary_logloss: 0.0170354\n",
      "[2120]\ttraining's binary_logloss: 0.0170308\n",
      "[2121]\ttraining's binary_logloss: 0.0170253\n",
      "[2122]\ttraining's binary_logloss: 0.0170217\n",
      "[2123]\ttraining's binary_logloss: 0.0170186\n",
      "[2124]\ttraining's binary_logloss: 0.0170144\n",
      "[2125]\ttraining's binary_logloss: 0.0170086\n",
      "[2126]\ttraining's binary_logloss: 0.0170039\n",
      "[2127]\ttraining's binary_logloss: 0.0170003\n",
      "[2128]\ttraining's binary_logloss: 0.0169968\n",
      "[2129]\ttraining's binary_logloss: 0.0169927\n",
      "[2130]\ttraining's binary_logloss: 0.0169879\n",
      "[2131]\ttraining's binary_logloss: 0.0169852\n",
      "[2132]\ttraining's binary_logloss: 0.0169813\n",
      "[2133]\ttraining's binary_logloss: 0.0169755\n",
      "[2134]\ttraining's binary_logloss: 0.0169711\n",
      "[2135]\ttraining's binary_logloss: 0.0169661\n",
      "[2136]\ttraining's binary_logloss: 0.016962\n",
      "[2137]\ttraining's binary_logloss: 0.0169568\n",
      "[2138]\ttraining's binary_logloss: 0.0169511\n",
      "[2139]\ttraining's binary_logloss: 0.0169475\n",
      "[2140]\ttraining's binary_logloss: 0.0169417\n",
      "[2141]\ttraining's binary_logloss: 0.0169352\n",
      "[2142]\ttraining's binary_logloss: 0.0169323\n",
      "[2143]\ttraining's binary_logloss: 0.0169273\n",
      "[2144]\ttraining's binary_logloss: 0.0169217\n",
      "[2145]\ttraining's binary_logloss: 0.0169178\n",
      "[2146]\ttraining's binary_logloss: 0.0169145\n",
      "[2147]\ttraining's binary_logloss: 0.016909\n",
      "[2148]\ttraining's binary_logloss: 0.0169046\n",
      "[2149]\ttraining's binary_logloss: 0.0169003\n",
      "[2150]\ttraining's binary_logloss: 0.0168959\n",
      "[2151]\ttraining's binary_logloss: 0.0168925\n",
      "[2152]\ttraining's binary_logloss: 0.0168879\n",
      "[2153]\ttraining's binary_logloss: 0.0168831\n",
      "[2154]\ttraining's binary_logloss: 0.0168798\n",
      "[2155]\ttraining's binary_logloss: 0.0168771\n",
      "[2156]\ttraining's binary_logloss: 0.0168719\n",
      "[2157]\ttraining's binary_logloss: 0.0168685\n",
      "[2158]\ttraining's binary_logloss: 0.0168646\n",
      "[2159]\ttraining's binary_logloss: 0.0168594\n",
      "[2160]\ttraining's binary_logloss: 0.0168551\n",
      "[2161]\ttraining's binary_logloss: 0.0168471\n",
      "[2162]\ttraining's binary_logloss: 0.016843\n",
      "[2163]\ttraining's binary_logloss: 0.016837\n",
      "[2164]\ttraining's binary_logloss: 0.0168315\n",
      "[2165]\ttraining's binary_logloss: 0.016827\n",
      "[2166]\ttraining's binary_logloss: 0.016822\n",
      "[2167]\ttraining's binary_logloss: 0.0168173\n",
      "[2168]\ttraining's binary_logloss: 0.0168141\n",
      "[2169]\ttraining's binary_logloss: 0.0168108\n",
      "[2170]\ttraining's binary_logloss: 0.0168075\n",
      "[2171]\ttraining's binary_logloss: 0.0168049\n",
      "[2172]\ttraining's binary_logloss: 0.0168014\n",
      "[2173]\ttraining's binary_logloss: 0.0167966\n",
      "[2174]\ttraining's binary_logloss: 0.0167926\n",
      "[2175]\ttraining's binary_logloss: 0.0167899\n",
      "[2176]\ttraining's binary_logloss: 0.0167867\n",
      "[2177]\ttraining's binary_logloss: 0.0167824\n",
      "[2178]\ttraining's binary_logloss: 0.0167782\n",
      "[2179]\ttraining's binary_logloss: 0.0167745\n",
      "[2180]\ttraining's binary_logloss: 0.0167709\n",
      "[2181]\ttraining's binary_logloss: 0.0167675\n",
      "[2182]\ttraining's binary_logloss: 0.0167643\n",
      "[2183]\ttraining's binary_logloss: 0.0167593\n",
      "[2184]\ttraining's binary_logloss: 0.016754\n",
      "[2185]\ttraining's binary_logloss: 0.0167499\n",
      "[2186]\ttraining's binary_logloss: 0.0167452\n",
      "[2187]\ttraining's binary_logloss: 0.0167411\n",
      "[2188]\ttraining's binary_logloss: 0.0167355\n",
      "[2189]\ttraining's binary_logloss: 0.0167309\n",
      "[2190]\ttraining's binary_logloss: 0.0167262\n",
      "[2191]\ttraining's binary_logloss: 0.0167209\n",
      "[2192]\ttraining's binary_logloss: 0.0167164\n",
      "[2193]\ttraining's binary_logloss: 0.0167126\n",
      "[2194]\ttraining's binary_logloss: 0.0167085\n",
      "[2195]\ttraining's binary_logloss: 0.0167031\n",
      "[2196]\ttraining's binary_logloss: 0.0167006\n",
      "[2197]\ttraining's binary_logloss: 0.0166966\n",
      "[2198]\ttraining's binary_logloss: 0.0166922\n",
      "[2199]\ttraining's binary_logloss: 0.0166881\n",
      "[2200]\ttraining's binary_logloss: 0.0166838\n",
      "[2201]\ttraining's binary_logloss: 0.0166797\n",
      "[2202]\ttraining's binary_logloss: 0.0166741\n",
      "[2203]\ttraining's binary_logloss: 0.0166719\n",
      "[2204]\ttraining's binary_logloss: 0.0166641\n",
      "[2205]\ttraining's binary_logloss: 0.0166587\n",
      "[2206]\ttraining's binary_logloss: 0.0166543\n",
      "[2207]\ttraining's binary_logloss: 0.0166514\n",
      "[2208]\ttraining's binary_logloss: 0.0166478\n",
      "[2209]\ttraining's binary_logloss: 0.0166423\n",
      "[2210]\ttraining's binary_logloss: 0.0166373\n",
      "[2211]\ttraining's binary_logloss: 0.0166333\n",
      "[2212]\ttraining's binary_logloss: 0.0166282\n",
      "[2213]\ttraining's binary_logloss: 0.0166249\n",
      "[2214]\ttraining's binary_logloss: 0.0166207\n",
      "[2215]\ttraining's binary_logloss: 0.0166167\n",
      "[2216]\ttraining's binary_logloss: 0.0166123\n",
      "[2217]\ttraining's binary_logloss: 0.0166088\n",
      "[2218]\ttraining's binary_logloss: 0.0166055\n",
      "[2219]\ttraining's binary_logloss: 0.0166019\n",
      "[2220]\ttraining's binary_logloss: 0.016598\n",
      "[2221]\ttraining's binary_logloss: 0.0165958\n",
      "[2222]\ttraining's binary_logloss: 0.0165923\n",
      "[2223]\ttraining's binary_logloss: 0.0165886\n",
      "[2224]\ttraining's binary_logloss: 0.016584\n",
      "[2225]\ttraining's binary_logloss: 0.0165792\n",
      "[2226]\ttraining's binary_logloss: 0.0165745\n",
      "[2227]\ttraining's binary_logloss: 0.0165699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2228]\ttraining's binary_logloss: 0.0165662\n",
      "[2229]\ttraining's binary_logloss: 0.0165588\n",
      "[2230]\ttraining's binary_logloss: 0.0165564\n",
      "[2231]\ttraining's binary_logloss: 0.0165528\n",
      "[2232]\ttraining's binary_logloss: 0.016548\n",
      "[2233]\ttraining's binary_logloss: 0.0165427\n",
      "[2234]\ttraining's binary_logloss: 0.0165368\n",
      "[2235]\ttraining's binary_logloss: 0.0165332\n",
      "[2236]\ttraining's binary_logloss: 0.0165285\n",
      "[2237]\ttraining's binary_logloss: 0.0165232\n",
      "[2238]\ttraining's binary_logloss: 0.0165189\n",
      "[2239]\ttraining's binary_logloss: 0.0165143\n",
      "[2240]\ttraining's binary_logloss: 0.0165093\n",
      "[2241]\ttraining's binary_logloss: 0.0165046\n",
      "[2242]\ttraining's binary_logloss: 0.0165021\n",
      "[2243]\ttraining's binary_logloss: 0.0164985\n",
      "[2244]\ttraining's binary_logloss: 0.0164931\n",
      "[2245]\ttraining's binary_logloss: 0.01649\n",
      "[2246]\ttraining's binary_logloss: 0.0164843\n",
      "[2247]\ttraining's binary_logloss: 0.0164789\n",
      "[2248]\ttraining's binary_logloss: 0.0164751\n",
      "[2249]\ttraining's binary_logloss: 0.0164707\n",
      "[2250]\ttraining's binary_logloss: 0.0164648\n",
      "[2251]\ttraining's binary_logloss: 0.0164616\n",
      "[2252]\ttraining's binary_logloss: 0.0164587\n",
      "[2253]\ttraining's binary_logloss: 0.0164553\n",
      "[2254]\ttraining's binary_logloss: 0.0164507\n",
      "[2255]\ttraining's binary_logloss: 0.0164454\n",
      "[2256]\ttraining's binary_logloss: 0.0164431\n",
      "[2257]\ttraining's binary_logloss: 0.0164379\n",
      "[2258]\ttraining's binary_logloss: 0.016434\n",
      "[2259]\ttraining's binary_logloss: 0.0164292\n",
      "[2260]\ttraining's binary_logloss: 0.0164223\n",
      "[2261]\ttraining's binary_logloss: 0.0164178\n",
      "[2262]\ttraining's binary_logloss: 0.0164156\n",
      "[2263]\ttraining's binary_logloss: 0.0164109\n",
      "[2264]\ttraining's binary_logloss: 0.0164079\n",
      "[2265]\ttraining's binary_logloss: 0.0164035\n",
      "[2266]\ttraining's binary_logloss: 0.0163998\n",
      "[2267]\ttraining's binary_logloss: 0.0163964\n",
      "[2268]\ttraining's binary_logloss: 0.0163922\n",
      "[2269]\ttraining's binary_logloss: 0.0163876\n",
      "[2270]\ttraining's binary_logloss: 0.0163836\n",
      "[2271]\ttraining's binary_logloss: 0.0163805\n",
      "[2272]\ttraining's binary_logloss: 0.016375\n",
      "[2273]\ttraining's binary_logloss: 0.0163717\n",
      "[2274]\ttraining's binary_logloss: 0.0163672\n",
      "[2275]\ttraining's binary_logloss: 0.0163631\n",
      "[2276]\ttraining's binary_logloss: 0.0163601\n",
      "[2277]\ttraining's binary_logloss: 0.0163563\n",
      "[2278]\ttraining's binary_logloss: 0.0163515\n",
      "[2279]\ttraining's binary_logloss: 0.016347\n",
      "[2280]\ttraining's binary_logloss: 0.0163427\n",
      "[2281]\ttraining's binary_logloss: 0.0163376\n",
      "[2282]\ttraining's binary_logloss: 0.0163327\n",
      "[2283]\ttraining's binary_logloss: 0.0163305\n",
      "[2284]\ttraining's binary_logloss: 0.016326\n",
      "[2285]\ttraining's binary_logloss: 0.0163215\n",
      "[2286]\ttraining's binary_logloss: 0.0163169\n",
      "[2287]\ttraining's binary_logloss: 0.0163105\n",
      "[2288]\ttraining's binary_logloss: 0.0163052\n",
      "[2289]\ttraining's binary_logloss: 0.0163\n",
      "[2290]\ttraining's binary_logloss: 0.0162978\n",
      "[2291]\ttraining's binary_logloss: 0.0162943\n",
      "[2292]\ttraining's binary_logloss: 0.0162912\n",
      "[2293]\ttraining's binary_logloss: 0.0162872\n",
      "[2294]\ttraining's binary_logloss: 0.0162828\n",
      "[2295]\ttraining's binary_logloss: 0.0162789\n",
      "[2296]\ttraining's binary_logloss: 0.0162768\n",
      "[2297]\ttraining's binary_logloss: 0.0162735\n",
      "[2298]\ttraining's binary_logloss: 0.0162695\n",
      "[2299]\ttraining's binary_logloss: 0.0162666\n",
      "[2300]\ttraining's binary_logloss: 0.0162634\n",
      "[2301]\ttraining's binary_logloss: 0.0162606\n",
      "[2302]\ttraining's binary_logloss: 0.0162566\n",
      "[2303]\ttraining's binary_logloss: 0.0162523\n",
      "[2304]\ttraining's binary_logloss: 0.0162476\n",
      "[2305]\ttraining's binary_logloss: 0.0162454\n",
      "[2306]\ttraining's binary_logloss: 0.016242\n",
      "[2307]\ttraining's binary_logloss: 0.016237\n",
      "[2308]\ttraining's binary_logloss: 0.0162326\n",
      "[2309]\ttraining's binary_logloss: 0.0162286\n",
      "[2310]\ttraining's binary_logloss: 0.0162265\n",
      "[2311]\ttraining's binary_logloss: 0.0162222\n",
      "[2312]\ttraining's binary_logloss: 0.0162184\n",
      "[2313]\ttraining's binary_logloss: 0.0162134\n",
      "[2314]\ttraining's binary_logloss: 0.0162082\n",
      "[2315]\ttraining's binary_logloss: 0.0162043\n",
      "[2316]\ttraining's binary_logloss: 0.0162022\n",
      "[2317]\ttraining's binary_logloss: 0.0161985\n",
      "[2318]\ttraining's binary_logloss: 0.0161937\n",
      "[2319]\ttraining's binary_logloss: 0.0161895\n",
      "[2320]\ttraining's binary_logloss: 0.0161853\n",
      "[2321]\ttraining's binary_logloss: 0.0161817\n",
      "[2322]\ttraining's binary_logloss: 0.0161768\n",
      "[2323]\ttraining's binary_logloss: 0.016173\n",
      "[2324]\ttraining's binary_logloss: 0.0161711\n",
      "[2325]\ttraining's binary_logloss: 0.0161681\n",
      "[2326]\ttraining's binary_logloss: 0.0161634\n",
      "[2327]\ttraining's binary_logloss: 0.0161605\n",
      "[2328]\ttraining's binary_logloss: 0.0161572\n",
      "[2329]\ttraining's binary_logloss: 0.0161526\n",
      "[2330]\ttraining's binary_logloss: 0.0161497\n",
      "[2331]\ttraining's binary_logloss: 0.0161476\n",
      "[2332]\ttraining's binary_logloss: 0.0161435\n",
      "[2333]\ttraining's binary_logloss: 0.0161404\n",
      "[2334]\ttraining's binary_logloss: 0.0161371\n",
      "[2335]\ttraining's binary_logloss: 0.0161335\n",
      "[2336]\ttraining's binary_logloss: 0.0161298\n",
      "[2337]\ttraining's binary_logloss: 0.0161277\n",
      "[2338]\ttraining's binary_logloss: 0.0161242\n",
      "[2339]\ttraining's binary_logloss: 0.0161194\n",
      "[2340]\ttraining's binary_logloss: 0.0161147\n",
      "[2341]\ttraining's binary_logloss: 0.0161111\n",
      "[2342]\ttraining's binary_logloss: 0.0161063\n",
      "[2343]\ttraining's binary_logloss: 0.0161038\n",
      "[2344]\ttraining's binary_logloss: 0.0160998\n",
      "[2345]\ttraining's binary_logloss: 0.016095\n",
      "[2346]\ttraining's binary_logloss: 0.0160914\n",
      "[2347]\ttraining's binary_logloss: 0.0160872\n",
      "[2348]\ttraining's binary_logloss: 0.0160822\n",
      "[2349]\ttraining's binary_logloss: 0.0160782\n",
      "[2350]\ttraining's binary_logloss: 0.0160739\n",
      "[2351]\ttraining's binary_logloss: 0.0160687\n",
      "[2352]\ttraining's binary_logloss: 0.0160643\n",
      "[2353]\ttraining's binary_logloss: 0.0160624\n",
      "[2354]\ttraining's binary_logloss: 0.0160585\n",
      "[2355]\ttraining's binary_logloss: 0.0160554\n",
      "[2356]\ttraining's binary_logloss: 0.0160526\n",
      "[2357]\ttraining's binary_logloss: 0.0160497\n",
      "[2358]\ttraining's binary_logloss: 0.0160464\n",
      "[2359]\ttraining's binary_logloss: 0.0160435\n",
      "[2360]\ttraining's binary_logloss: 0.0160407\n",
      "[2361]\ttraining's binary_logloss: 0.0160361\n",
      "[2362]\ttraining's binary_logloss: 0.0160341\n",
      "[2363]\ttraining's binary_logloss: 0.0160309\n",
      "[2364]\ttraining's binary_logloss: 0.0160271\n",
      "[2365]\ttraining's binary_logloss: 0.0160253\n",
      "[2366]\ttraining's binary_logloss: 0.0160208\n",
      "[2367]\ttraining's binary_logloss: 0.0160156\n",
      "[2368]\ttraining's binary_logloss: 0.0160112\n",
      "[2369]\ttraining's binary_logloss: 0.016007\n",
      "[2370]\ttraining's binary_logloss: 0.016002\n",
      "[2371]\ttraining's binary_logloss: 0.0159961\n",
      "[2372]\ttraining's binary_logloss: 0.0159933\n",
      "[2373]\ttraining's binary_logloss: 0.0159888\n",
      "[2374]\ttraining's binary_logloss: 0.0159849\n",
      "[2375]\ttraining's binary_logloss: 0.0159818\n",
      "[2376]\ttraining's binary_logloss: 0.0159799\n",
      "[2377]\ttraining's binary_logloss: 0.015976\n",
      "[2378]\ttraining's binary_logloss: 0.0159724\n",
      "[2379]\ttraining's binary_logloss: 0.0159685\n",
      "[2380]\ttraining's binary_logloss: 0.015965\n",
      "[2381]\ttraining's binary_logloss: 0.0159622\n",
      "[2382]\ttraining's binary_logloss: 0.0159568\n",
      "[2383]\ttraining's binary_logloss: 0.0159538\n",
      "[2384]\ttraining's binary_logloss: 0.0159499\n",
      "[2385]\ttraining's binary_logloss: 0.0159468\n",
      "[2386]\ttraining's binary_logloss: 0.0159441\n",
      "[2387]\ttraining's binary_logloss: 0.0159406\n",
      "[2388]\ttraining's binary_logloss: 0.0159359\n",
      "[2389]\ttraining's binary_logloss: 0.0159305\n",
      "[2390]\ttraining's binary_logloss: 0.0159269\n",
      "[2391]\ttraining's binary_logloss: 0.0159236\n",
      "[2392]\ttraining's binary_logloss: 0.0159193\n",
      "[2393]\ttraining's binary_logloss: 0.0159156\n",
      "[2394]\ttraining's binary_logloss: 0.0159125\n",
      "[2395]\ttraining's binary_logloss: 0.015909\n",
      "[2396]\ttraining's binary_logloss: 0.0159045\n",
      "[2397]\ttraining's binary_logloss: 0.0159002\n",
      "[2398]\ttraining's binary_logloss: 0.0158963\n",
      "[2399]\ttraining's binary_logloss: 0.0158932\n",
      "[2400]\ttraining's binary_logloss: 0.0158901\n",
      "[2401]\ttraining's binary_logloss: 0.0158873\n",
      "[2402]\ttraining's binary_logloss: 0.0158853\n",
      "[2403]\ttraining's binary_logloss: 0.0158823\n",
      "[2404]\ttraining's binary_logloss: 0.0158783\n",
      "[2405]\ttraining's binary_logloss: 0.0158753\n",
      "[2406]\ttraining's binary_logloss: 0.0158711\n",
      "[2407]\ttraining's binary_logloss: 0.0158673\n",
      "[2408]\ttraining's binary_logloss: 0.0158637\n",
      "[2409]\ttraining's binary_logloss: 0.0158597\n",
      "[2410]\ttraining's binary_logloss: 0.0158568\n",
      "[2411]\ttraining's binary_logloss: 0.0158532\n",
      "[2412]\ttraining's binary_logloss: 0.0158471\n",
      "[2413]\ttraining's binary_logloss: 0.0158424\n",
      "[2414]\ttraining's binary_logloss: 0.0158404\n",
      "[2415]\ttraining's binary_logloss: 0.0158368\n",
      "[2416]\ttraining's binary_logloss: 0.0158325\n",
      "[2417]\ttraining's binary_logloss: 0.0158296\n",
      "[2418]\ttraining's binary_logloss: 0.0158266\n",
      "[2419]\ttraining's binary_logloss: 0.0158219\n",
      "[2420]\ttraining's binary_logloss: 0.015819\n",
      "[2421]\ttraining's binary_logloss: 0.0158152\n",
      "[2422]\ttraining's binary_logloss: 0.0158114\n",
      "[2423]\ttraining's binary_logloss: 0.015808\n",
      "[2424]\ttraining's binary_logloss: 0.0158034\n",
      "[2425]\ttraining's binary_logloss: 0.0157997\n",
      "[2426]\ttraining's binary_logloss: 0.015795\n",
      "[2427]\ttraining's binary_logloss: 0.0157915\n",
      "[2428]\ttraining's binary_logloss: 0.0157861\n",
      "[2429]\ttraining's binary_logloss: 0.0157824\n",
      "[2430]\ttraining's binary_logloss: 0.0157799\n",
      "[2431]\ttraining's binary_logloss: 0.0157772\n",
      "[2432]\ttraining's binary_logloss: 0.0157737\n",
      "[2433]\ttraining's binary_logloss: 0.0157694\n",
      "[2434]\ttraining's binary_logloss: 0.0157661\n",
      "[2435]\ttraining's binary_logloss: 0.0157641\n",
      "[2436]\ttraining's binary_logloss: 0.0157613\n",
      "[2437]\ttraining's binary_logloss: 0.0157575\n",
      "[2438]\ttraining's binary_logloss: 0.015755\n",
      "[2439]\ttraining's binary_logloss: 0.0157522\n",
      "[2440]\ttraining's binary_logloss: 0.015747\n",
      "[2441]\ttraining's binary_logloss: 0.0157427\n",
      "[2442]\ttraining's binary_logloss: 0.0157407\n",
      "[2443]\ttraining's binary_logloss: 0.0157365\n",
      "[2444]\ttraining's binary_logloss: 0.0157323\n",
      "[2445]\ttraining's binary_logloss: 0.0157282\n",
      "[2446]\ttraining's binary_logloss: 0.0157249\n",
      "[2447]\ttraining's binary_logloss: 0.0157188\n",
      "[2448]\ttraining's binary_logloss: 0.0157149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2449]\ttraining's binary_logloss: 0.0157114\n",
      "[2450]\ttraining's binary_logloss: 0.0157079\n",
      "[2451]\ttraining's binary_logloss: 0.0157061\n",
      "[2452]\ttraining's binary_logloss: 0.0157034\n",
      "[2453]\ttraining's binary_logloss: 0.0156988\n",
      "[2454]\ttraining's binary_logloss: 0.0156939\n",
      "[2455]\ttraining's binary_logloss: 0.0156901\n",
      "[2456]\ttraining's binary_logloss: 0.0156857\n",
      "[2457]\ttraining's binary_logloss: 0.0156811\n",
      "[2458]\ttraining's binary_logloss: 0.0156777\n",
      "[2459]\ttraining's binary_logloss: 0.0156746\n",
      "[2460]\ttraining's binary_logloss: 0.0156717\n",
      "[2461]\ttraining's binary_logloss: 0.0156664\n",
      "[2462]\ttraining's binary_logloss: 0.0156624\n",
      "[2463]\ttraining's binary_logloss: 0.0156585\n",
      "[2464]\ttraining's binary_logloss: 0.0156553\n",
      "[2465]\ttraining's binary_logloss: 0.0156526\n",
      "[2466]\ttraining's binary_logloss: 0.0156494\n",
      "[2467]\ttraining's binary_logloss: 0.0156463\n",
      "[2468]\ttraining's binary_logloss: 0.0156431\n",
      "[2469]\ttraining's binary_logloss: 0.0156389\n",
      "[2470]\ttraining's binary_logloss: 0.0156332\n",
      "[2471]\ttraining's binary_logloss: 0.0156306\n",
      "[2472]\ttraining's binary_logloss: 0.0156261\n",
      "[2473]\ttraining's binary_logloss: 0.0156213\n",
      "[2474]\ttraining's binary_logloss: 0.0156173\n",
      "[2475]\ttraining's binary_logloss: 0.0156141\n",
      "[2476]\ttraining's binary_logloss: 0.0156108\n",
      "[2477]\ttraining's binary_logloss: 0.015606\n",
      "[2478]\ttraining's binary_logloss: 0.0156018\n",
      "[2479]\ttraining's binary_logloss: 0.0155968\n",
      "[2480]\ttraining's binary_logloss: 0.0155942\n",
      "[2481]\ttraining's binary_logloss: 0.0155912\n",
      "[2482]\ttraining's binary_logloss: 0.0155884\n",
      "[2483]\ttraining's binary_logloss: 0.0155864\n",
      "[2484]\ttraining's binary_logloss: 0.0155838\n",
      "[2485]\ttraining's binary_logloss: 0.0155811\n",
      "[2486]\ttraining's binary_logloss: 0.0155776\n",
      "[2487]\ttraining's binary_logloss: 0.0155729\n",
      "[2488]\ttraining's binary_logloss: 0.0155687\n",
      "[2489]\ttraining's binary_logloss: 0.0155646\n",
      "[2490]\ttraining's binary_logloss: 0.0155613\n",
      "[2491]\ttraining's binary_logloss: 0.0155572\n",
      "[2492]\ttraining's binary_logloss: 0.0155531\n",
      "[2493]\ttraining's binary_logloss: 0.0155513\n",
      "[2494]\ttraining's binary_logloss: 0.0155476\n",
      "[2495]\ttraining's binary_logloss: 0.0155431\n",
      "[2496]\ttraining's binary_logloss: 0.0155387\n",
      "[2497]\ttraining's binary_logloss: 0.0155346\n",
      "[2498]\ttraining's binary_logloss: 0.01553\n",
      "[2499]\ttraining's binary_logloss: 0.0155242\n",
      "[2500]\ttraining's binary_logloss: 0.0155206\n",
      "[2501]\ttraining's binary_logloss: 0.0155185\n",
      "[2502]\ttraining's binary_logloss: 0.0155156\n",
      "[2503]\ttraining's binary_logloss: 0.0155127\n",
      "[2504]\ttraining's binary_logloss: 0.0155101\n",
      "[2505]\ttraining's binary_logloss: 0.0155076\n",
      "[2506]\ttraining's binary_logloss: 0.0155034\n",
      "[2507]\ttraining's binary_logloss: 0.015499\n",
      "[2508]\ttraining's binary_logloss: 0.0154949\n",
      "[2509]\ttraining's binary_logloss: 0.0154912\n",
      "[2510]\ttraining's binary_logloss: 0.0154876\n",
      "[2511]\ttraining's binary_logloss: 0.0154847\n",
      "[2512]\ttraining's binary_logloss: 0.0154821\n",
      "[2513]\ttraining's binary_logloss: 0.0154801\n",
      "[2514]\ttraining's binary_logloss: 0.015477\n",
      "[2515]\ttraining's binary_logloss: 0.0154744\n",
      "[2516]\ttraining's binary_logloss: 0.0154714\n",
      "[2517]\ttraining's binary_logloss: 0.0154678\n",
      "[2518]\ttraining's binary_logloss: 0.0154622\n",
      "[2519]\ttraining's binary_logloss: 0.0154594\n",
      "[2520]\ttraining's binary_logloss: 0.015456\n",
      "[2521]\ttraining's binary_logloss: 0.0154519\n",
      "[2522]\ttraining's binary_logloss: 0.0154466\n",
      "[2523]\ttraining's binary_logloss: 0.0154431\n",
      "[2524]\ttraining's binary_logloss: 0.0154382\n",
      "[2525]\ttraining's binary_logloss: 0.0154343\n",
      "[2526]\ttraining's binary_logloss: 0.0154317\n",
      "[2527]\ttraining's binary_logloss: 0.0154296\n",
      "[2528]\ttraining's binary_logloss: 0.0154269\n",
      "[2529]\ttraining's binary_logloss: 0.0154252\n",
      "[2530]\ttraining's binary_logloss: 0.0154227\n",
      "[2531]\ttraining's binary_logloss: 0.0154195\n",
      "[2532]\ttraining's binary_logloss: 0.0154158\n",
      "[2533]\ttraining's binary_logloss: 0.0154121\n",
      "[2534]\ttraining's binary_logloss: 0.0154099\n",
      "[2535]\ttraining's binary_logloss: 0.0154068\n",
      "[2536]\ttraining's binary_logloss: 0.0154042\n",
      "[2537]\ttraining's binary_logloss: 0.0154006\n",
      "[2538]\ttraining's binary_logloss: 0.0153966\n",
      "[2539]\ttraining's binary_logloss: 0.0153926\n",
      "[2540]\ttraining's binary_logloss: 0.0153882\n",
      "[2541]\ttraining's binary_logloss: 0.015384\n",
      "[2542]\ttraining's binary_logloss: 0.01538\n",
      "[2543]\ttraining's binary_logloss: 0.0153762\n",
      "[2544]\ttraining's binary_logloss: 0.0153724\n",
      "[2545]\ttraining's binary_logloss: 0.0153679\n",
      "[2546]\ttraining's binary_logloss: 0.0153647\n",
      "[2547]\ttraining's binary_logloss: 0.0153626\n",
      "[2548]\ttraining's binary_logloss: 0.0153597\n",
      "[2549]\ttraining's binary_logloss: 0.0153553\n",
      "[2550]\ttraining's binary_logloss: 0.0153508\n",
      "[2551]\ttraining's binary_logloss: 0.0153477\n",
      "[2552]\ttraining's binary_logloss: 0.015346\n",
      "[2553]\ttraining's binary_logloss: 0.0153434\n",
      "[2554]\ttraining's binary_logloss: 0.0153397\n",
      "[2555]\ttraining's binary_logloss: 0.0153378\n",
      "[2556]\ttraining's binary_logloss: 0.015335\n",
      "[2557]\ttraining's binary_logloss: 0.0153319\n",
      "[2558]\ttraining's binary_logloss: 0.015328\n",
      "[2559]\ttraining's binary_logloss: 0.0153233\n",
      "[2560]\ttraining's binary_logloss: 0.0153195\n",
      "[2561]\ttraining's binary_logloss: 0.0153143\n",
      "[2562]\ttraining's binary_logloss: 0.0153109\n",
      "[2563]\ttraining's binary_logloss: 0.015307\n",
      "[2564]\ttraining's binary_logloss: 0.015304\n",
      "[2565]\ttraining's binary_logloss: 0.0152989\n",
      "[2566]\ttraining's binary_logloss: 0.0152944\n",
      "[2567]\ttraining's binary_logloss: 0.0152912\n",
      "[2568]\ttraining's binary_logloss: 0.0152868\n",
      "[2569]\ttraining's binary_logloss: 0.0152834\n",
      "[2570]\ttraining's binary_logloss: 0.0152791\n",
      "[2571]\ttraining's binary_logloss: 0.0152763\n",
      "[2572]\ttraining's binary_logloss: 0.0152738\n",
      "[2573]\ttraining's binary_logloss: 0.0152713\n",
      "[2574]\ttraining's binary_logloss: 0.0152668\n",
      "[2575]\ttraining's binary_logloss: 0.0152644\n",
      "[2576]\ttraining's binary_logloss: 0.0152605\n",
      "[2577]\ttraining's binary_logloss: 0.0152566\n",
      "[2578]\ttraining's binary_logloss: 0.0152526\n",
      "[2579]\ttraining's binary_logloss: 0.0152477\n",
      "[2580]\ttraining's binary_logloss: 0.0152441\n",
      "[2581]\ttraining's binary_logloss: 0.0152414\n",
      "[2582]\ttraining's binary_logloss: 0.0152376\n",
      "[2583]\ttraining's binary_logloss: 0.0152333\n",
      "[2584]\ttraining's binary_logloss: 0.0152314\n",
      "[2585]\ttraining's binary_logloss: 0.0152287\n",
      "[2586]\ttraining's binary_logloss: 0.0152258\n",
      "[2587]\ttraining's binary_logloss: 0.0152241\n",
      "[2588]\ttraining's binary_logloss: 0.0152197\n",
      "[2589]\ttraining's binary_logloss: 0.0152172\n",
      "[2590]\ttraining's binary_logloss: 0.015213\n",
      "[2591]\ttraining's binary_logloss: 0.01521\n",
      "[2592]\ttraining's binary_logloss: 0.0152062\n",
      "[2593]\ttraining's binary_logloss: 0.0152027\n",
      "[2594]\ttraining's binary_logloss: 0.0151988\n",
      "[2595]\ttraining's binary_logloss: 0.0151947\n",
      "[2596]\ttraining's binary_logloss: 0.0151916\n",
      "[2597]\ttraining's binary_logloss: 0.0151878\n",
      "[2598]\ttraining's binary_logloss: 0.0151839\n",
      "[2599]\ttraining's binary_logloss: 0.0151812\n",
      "[2600]\ttraining's binary_logloss: 0.0151788\n",
      "[2601]\ttraining's binary_logloss: 0.0151751\n",
      "[2602]\ttraining's binary_logloss: 0.015172\n",
      "[2603]\ttraining's binary_logloss: 0.0151694\n",
      "[2604]\ttraining's binary_logloss: 0.0151676\n",
      "[2605]\ttraining's binary_logloss: 0.0151642\n",
      "[2606]\ttraining's binary_logloss: 0.015161\n",
      "[2607]\ttraining's binary_logloss: 0.0151572\n",
      "[2608]\ttraining's binary_logloss: 0.0151535\n",
      "[2609]\ttraining's binary_logloss: 0.0151497\n",
      "[2610]\ttraining's binary_logloss: 0.0151453\n",
      "[2611]\ttraining's binary_logloss: 0.0151419\n",
      "[2612]\ttraining's binary_logloss: 0.0151395\n",
      "[2613]\ttraining's binary_logloss: 0.0151366\n",
      "[2614]\ttraining's binary_logloss: 0.0151308\n",
      "[2615]\ttraining's binary_logloss: 0.0151269\n",
      "[2616]\ttraining's binary_logloss: 0.0151245\n",
      "[2617]\ttraining's binary_logloss: 0.0151226\n",
      "[2618]\ttraining's binary_logloss: 0.0151187\n",
      "[2619]\ttraining's binary_logloss: 0.0151153\n",
      "[2620]\ttraining's binary_logloss: 0.0151112\n",
      "[2621]\ttraining's binary_logloss: 0.0151085\n",
      "[2622]\ttraining's binary_logloss: 0.0151053\n",
      "[2623]\ttraining's binary_logloss: 0.0151012\n",
      "[2624]\ttraining's binary_logloss: 0.0150987\n",
      "[2625]\ttraining's binary_logloss: 0.0150945\n",
      "[2626]\ttraining's binary_logloss: 0.0150898\n",
      "[2627]\ttraining's binary_logloss: 0.0150855\n",
      "[2628]\ttraining's binary_logloss: 0.0150818\n",
      "[2629]\ttraining's binary_logloss: 0.0150782\n",
      "[2630]\ttraining's binary_logloss: 0.0150765\n",
      "[2631]\ttraining's binary_logloss: 0.0150733\n",
      "[2632]\ttraining's binary_logloss: 0.0150697\n",
      "[2633]\ttraining's binary_logloss: 0.0150657\n",
      "[2634]\ttraining's binary_logloss: 0.0150641\n",
      "[2635]\ttraining's binary_logloss: 0.0150603\n",
      "[2636]\ttraining's binary_logloss: 0.0150579\n",
      "[2637]\ttraining's binary_logloss: 0.0150545\n",
      "[2638]\ttraining's binary_logloss: 0.015052\n",
      "[2639]\ttraining's binary_logloss: 0.0150503\n",
      "[2640]\ttraining's binary_logloss: 0.0150474\n",
      "[2641]\ttraining's binary_logloss: 0.0150441\n",
      "[2642]\ttraining's binary_logloss: 0.0150413\n",
      "[2643]\ttraining's binary_logloss: 0.0150374\n",
      "[2644]\ttraining's binary_logloss: 0.0150345\n",
      "[2645]\ttraining's binary_logloss: 0.0150309\n",
      "[2646]\ttraining's binary_logloss: 0.0150266\n",
      "[2647]\ttraining's binary_logloss: 0.0150238\n",
      "[2648]\ttraining's binary_logloss: 0.0150204\n",
      "[2649]\ttraining's binary_logloss: 0.015016\n",
      "[2650]\ttraining's binary_logloss: 0.0150136\n",
      "[2651]\ttraining's binary_logloss: 0.0150117\n",
      "[2652]\ttraining's binary_logloss: 0.0150077\n",
      "[2653]\ttraining's binary_logloss: 0.0150053\n",
      "[2654]\ttraining's binary_logloss: 0.0150035\n",
      "[2655]\ttraining's binary_logloss: 0.0150007\n",
      "[2656]\ttraining's binary_logloss: 0.014997\n",
      "[2657]\ttraining's binary_logloss: 0.0149954\n",
      "[2658]\ttraining's binary_logloss: 0.0149924\n",
      "[2659]\ttraining's binary_logloss: 0.014989\n",
      "[2660]\ttraining's binary_logloss: 0.0149856\n",
      "[2661]\ttraining's binary_logloss: 0.0149839\n",
      "[2662]\ttraining's binary_logloss: 0.0149801\n",
      "[2663]\ttraining's binary_logloss: 0.0149762\n",
      "[2664]\ttraining's binary_logloss: 0.0149727\n",
      "[2665]\ttraining's binary_logloss: 0.0149709\n",
      "[2666]\ttraining's binary_logloss: 0.0149681\n",
      "[2667]\ttraining's binary_logloss: 0.0149649\n",
      "[2668]\ttraining's binary_logloss: 0.0149612\n",
      "[2669]\ttraining's binary_logloss: 0.014958\n",
      "[2670]\ttraining's binary_logloss: 0.0149544\n",
      "[2671]\ttraining's binary_logloss: 0.0149514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2672]\ttraining's binary_logloss: 0.0149471\n",
      "[2673]\ttraining's binary_logloss: 0.0149439\n",
      "[2674]\ttraining's binary_logloss: 0.0149407\n",
      "[2675]\ttraining's binary_logloss: 0.0149382\n",
      "[2676]\ttraining's binary_logloss: 0.0149356\n",
      "[2677]\ttraining's binary_logloss: 0.014933\n",
      "[2678]\ttraining's binary_logloss: 0.0149305\n",
      "[2679]\ttraining's binary_logloss: 0.0149288\n",
      "[2680]\ttraining's binary_logloss: 0.0149259\n",
      "[2681]\ttraining's binary_logloss: 0.0149235\n",
      "[2682]\ttraining's binary_logloss: 0.01492\n",
      "[2683]\ttraining's binary_logloss: 0.0149183\n",
      "[2684]\ttraining's binary_logloss: 0.0149159\n",
      "[2685]\ttraining's binary_logloss: 0.0149121\n",
      "[2686]\ttraining's binary_logloss: 0.0149092\n",
      "[2687]\ttraining's binary_logloss: 0.0149061\n",
      "[2688]\ttraining's binary_logloss: 0.0149024\n",
      "[2689]\ttraining's binary_logloss: 0.0148984\n",
      "[2690]\ttraining's binary_logloss: 0.0148949\n",
      "[2691]\ttraining's binary_logloss: 0.0148933\n",
      "[2692]\ttraining's binary_logloss: 0.0148906\n",
      "[2693]\ttraining's binary_logloss: 0.0148874\n",
      "[2694]\ttraining's binary_logloss: 0.014884\n",
      "[2695]\ttraining's binary_logloss: 0.0148793\n",
      "[2696]\ttraining's binary_logloss: 0.0148763\n",
      "[2697]\ttraining's binary_logloss: 0.0148732\n",
      "[2698]\ttraining's binary_logloss: 0.0148716\n",
      "[2699]\ttraining's binary_logloss: 0.0148693\n",
      "[2700]\ttraining's binary_logloss: 0.0148665\n",
      "[2701]\ttraining's binary_logloss: 0.014864\n",
      "[2702]\ttraining's binary_logloss: 0.01486\n",
      "[2703]\ttraining's binary_logloss: 0.014857\n",
      "[2704]\ttraining's binary_logloss: 0.0148535\n",
      "[2705]\ttraining's binary_logloss: 0.0148493\n",
      "[2706]\ttraining's binary_logloss: 0.0148458\n",
      "[2707]\ttraining's binary_logloss: 0.0148422\n",
      "[2708]\ttraining's binary_logloss: 0.014839\n",
      "[2709]\ttraining's binary_logloss: 0.0148367\n",
      "[2710]\ttraining's binary_logloss: 0.0148336\n",
      "[2711]\ttraining's binary_logloss: 0.0148286\n",
      "[2712]\ttraining's binary_logloss: 0.0148248\n",
      "[2713]\ttraining's binary_logloss: 0.0148218\n",
      "[2714]\ttraining's binary_logloss: 0.0148182\n",
      "[2715]\ttraining's binary_logloss: 0.0148146\n",
      "[2716]\ttraining's binary_logloss: 0.0148116\n",
      "[2717]\ttraining's binary_logloss: 0.0148068\n",
      "[2718]\ttraining's binary_logloss: 0.0148044\n",
      "[2719]\ttraining's binary_logloss: 0.0148026\n",
      "[2720]\ttraining's binary_logloss: 0.0147993\n",
      "[2721]\ttraining's binary_logloss: 0.0147958\n",
      "[2722]\ttraining's binary_logloss: 0.014793\n",
      "[2723]\ttraining's binary_logloss: 0.0147892\n",
      "[2724]\ttraining's binary_logloss: 0.0147862\n",
      "[2725]\ttraining's binary_logloss: 0.0147814\n",
      "[2726]\ttraining's binary_logloss: 0.0147787\n",
      "[2727]\ttraining's binary_logloss: 0.0147745\n",
      "[2728]\ttraining's binary_logloss: 0.0147716\n",
      "[2729]\ttraining's binary_logloss: 0.0147689\n",
      "[2730]\ttraining's binary_logloss: 0.0147666\n",
      "[2731]\ttraining's binary_logloss: 0.0147632\n",
      "[2732]\ttraining's binary_logloss: 0.0147612\n",
      "[2733]\ttraining's binary_logloss: 0.0147595\n",
      "[2734]\ttraining's binary_logloss: 0.0147558\n",
      "[2735]\ttraining's binary_logloss: 0.0147527\n",
      "[2736]\ttraining's binary_logloss: 0.0147485\n",
      "[2737]\ttraining's binary_logloss: 0.0147458\n",
      "[2738]\ttraining's binary_logloss: 0.014742\n",
      "[2739]\ttraining's binary_logloss: 0.0147391\n",
      "[2740]\ttraining's binary_logloss: 0.0147362\n",
      "[2741]\ttraining's binary_logloss: 0.0147334\n",
      "[2742]\ttraining's binary_logloss: 0.0147306\n",
      "[2743]\ttraining's binary_logloss: 0.0147278\n",
      "[2744]\ttraining's binary_logloss: 0.0147231\n",
      "[2745]\ttraining's binary_logloss: 0.0147202\n",
      "[2746]\ttraining's binary_logloss: 0.0147162\n",
      "[2747]\ttraining's binary_logloss: 0.0147132\n",
      "[2748]\ttraining's binary_logloss: 0.0147088\n",
      "[2749]\ttraining's binary_logloss: 0.0147072\n",
      "[2750]\ttraining's binary_logloss: 0.0147047\n",
      "[2751]\ttraining's binary_logloss: 0.0147012\n",
      "[2752]\ttraining's binary_logloss: 0.0146976\n",
      "[2753]\ttraining's binary_logloss: 0.014694\n",
      "[2754]\ttraining's binary_logloss: 0.0146915\n",
      "[2755]\ttraining's binary_logloss: 0.0146883\n",
      "[2756]\ttraining's binary_logloss: 0.014685\n",
      "[2757]\ttraining's binary_logloss: 0.0146812\n",
      "[2758]\ttraining's binary_logloss: 0.0146778\n",
      "[2759]\ttraining's binary_logloss: 0.0146753\n",
      "[2760]\ttraining's binary_logloss: 0.0146708\n",
      "[2761]\ttraining's binary_logloss: 0.014667\n",
      "[2762]\ttraining's binary_logloss: 0.0146651\n",
      "[2763]\ttraining's binary_logloss: 0.0146633\n",
      "[2764]\ttraining's binary_logloss: 0.0146595\n",
      "[2765]\ttraining's binary_logloss: 0.014657\n",
      "[2766]\ttraining's binary_logloss: 0.0146537\n",
      "[2767]\ttraining's binary_logloss: 0.014652\n",
      "[2768]\ttraining's binary_logloss: 0.0146503\n",
      "[2769]\ttraining's binary_logloss: 0.0146479\n",
      "[2770]\ttraining's binary_logloss: 0.0146442\n",
      "[2771]\ttraining's binary_logloss: 0.0146425\n",
      "[2772]\ttraining's binary_logloss: 0.0146391\n",
      "[2773]\ttraining's binary_logloss: 0.0146361\n",
      "[2774]\ttraining's binary_logloss: 0.0146326\n",
      "[2775]\ttraining's binary_logloss: 0.0146303\n",
      "[2776]\ttraining's binary_logloss: 0.0146287\n",
      "[2777]\ttraining's binary_logloss: 0.0146253\n",
      "[2778]\ttraining's binary_logloss: 0.0146215\n",
      "[2779]\ttraining's binary_logloss: 0.014619\n",
      "[2780]\ttraining's binary_logloss: 0.0146161\n",
      "[2781]\ttraining's binary_logloss: 0.0146145\n",
      "[2782]\ttraining's binary_logloss: 0.0146122\n",
      "[2783]\ttraining's binary_logloss: 0.0146085\n",
      "[2784]\ttraining's binary_logloss: 0.0146053\n",
      "[2785]\ttraining's binary_logloss: 0.0146016\n",
      "[2786]\ttraining's binary_logloss: 0.0145974\n",
      "[2787]\ttraining's binary_logloss: 0.0145956\n",
      "[2788]\ttraining's binary_logloss: 0.0145937\n",
      "[2789]\ttraining's binary_logloss: 0.0145903\n",
      "[2790]\ttraining's binary_logloss: 0.0145869\n",
      "[2791]\ttraining's binary_logloss: 0.0145853\n",
      "[2792]\ttraining's binary_logloss: 0.0145816\n",
      "[2793]\ttraining's binary_logloss: 0.0145794\n",
      "[2794]\ttraining's binary_logloss: 0.0145747\n",
      "[2795]\ttraining's binary_logloss: 0.0145708\n",
      "[2796]\ttraining's binary_logloss: 0.014568\n",
      "[2797]\ttraining's binary_logloss: 0.0145655\n",
      "[2798]\ttraining's binary_logloss: 0.0145631\n",
      "[2799]\ttraining's binary_logloss: 0.0145614\n",
      "[2800]\ttraining's binary_logloss: 0.0145595\n",
      "[2801]\ttraining's binary_logloss: 0.0145564\n",
      "[2802]\ttraining's binary_logloss: 0.0145537\n",
      "[2803]\ttraining's binary_logloss: 0.014552\n",
      "[2804]\ttraining's binary_logloss: 0.0145497\n",
      "[2805]\ttraining's binary_logloss: 0.0145468\n",
      "[2806]\ttraining's binary_logloss: 0.014543\n",
      "[2807]\ttraining's binary_logloss: 0.0145394\n",
      "[2808]\ttraining's binary_logloss: 0.014535\n",
      "[2809]\ttraining's binary_logloss: 0.0145333\n",
      "[2810]\ttraining's binary_logloss: 0.0145305\n",
      "[2811]\ttraining's binary_logloss: 0.0145262\n",
      "[2812]\ttraining's binary_logloss: 0.014522\n",
      "[2813]\ttraining's binary_logloss: 0.014519\n",
      "[2814]\ttraining's binary_logloss: 0.0145172\n",
      "[2815]\ttraining's binary_logloss: 0.0145145\n",
      "[2816]\ttraining's binary_logloss: 0.0145119\n",
      "[2817]\ttraining's binary_logloss: 0.0145085\n",
      "[2818]\ttraining's binary_logloss: 0.0145041\n",
      "[2819]\ttraining's binary_logloss: 0.0145013\n",
      "[2820]\ttraining's binary_logloss: 0.0144979\n",
      "[2821]\ttraining's binary_logloss: 0.0144946\n",
      "[2822]\ttraining's binary_logloss: 0.014493\n",
      "[2823]\ttraining's binary_logloss: 0.0144906\n",
      "[2824]\ttraining's binary_logloss: 0.0144871\n",
      "[2825]\ttraining's binary_logloss: 0.0144844\n",
      "[2826]\ttraining's binary_logloss: 0.0144823\n",
      "[2827]\ttraining's binary_logloss: 0.0144799\n",
      "[2828]\ttraining's binary_logloss: 0.0144778\n",
      "[2829]\ttraining's binary_logloss: 0.0144743\n",
      "[2830]\ttraining's binary_logloss: 0.0144702\n",
      "[2831]\ttraining's binary_logloss: 0.0144666\n",
      "[2832]\ttraining's binary_logloss: 0.0144636\n",
      "[2833]\ttraining's binary_logloss: 0.0144609\n",
      "[2834]\ttraining's binary_logloss: 0.014459\n",
      "[2835]\ttraining's binary_logloss: 0.0144556\n",
      "[2836]\ttraining's binary_logloss: 0.0144518\n",
      "[2837]\ttraining's binary_logloss: 0.0144494\n",
      "[2838]\ttraining's binary_logloss: 0.0144466\n",
      "[2839]\ttraining's binary_logloss: 0.0144425\n",
      "[2840]\ttraining's binary_logloss: 0.0144398\n",
      "[2841]\ttraining's binary_logloss: 0.0144366\n",
      "[2842]\ttraining's binary_logloss: 0.0144333\n",
      "[2843]\ttraining's binary_logloss: 0.01443\n",
      "[2844]\ttraining's binary_logloss: 0.0144267\n",
      "[2845]\ttraining's binary_logloss: 0.0144237\n",
      "[2846]\ttraining's binary_logloss: 0.0144218\n",
      "[2847]\ttraining's binary_logloss: 0.0144196\n",
      "[2848]\ttraining's binary_logloss: 0.0144179\n",
      "[2849]\ttraining's binary_logloss: 0.0144153\n",
      "[2850]\ttraining's binary_logloss: 0.0144127\n",
      "[2851]\ttraining's binary_logloss: 0.014411\n",
      "[2852]\ttraining's binary_logloss: 0.0144088\n",
      "[2853]\ttraining's binary_logloss: 0.0144061\n",
      "[2854]\ttraining's binary_logloss: 0.0144037\n",
      "[2855]\ttraining's binary_logloss: 0.0144001\n",
      "[2856]\ttraining's binary_logloss: 0.0143972\n",
      "[2857]\ttraining's binary_logloss: 0.0143956\n",
      "[2858]\ttraining's binary_logloss: 0.0143934\n",
      "[2859]\ttraining's binary_logloss: 0.014391\n",
      "[2860]\ttraining's binary_logloss: 0.0143873\n",
      "[2861]\ttraining's binary_logloss: 0.0143846\n",
      "[2862]\ttraining's binary_logloss: 0.0143818\n",
      "[2863]\ttraining's binary_logloss: 0.0143786\n",
      "[2864]\ttraining's binary_logloss: 0.0143761\n",
      "[2865]\ttraining's binary_logloss: 0.0143727\n",
      "[2866]\ttraining's binary_logloss: 0.0143702\n",
      "[2867]\ttraining's binary_logloss: 0.0143673\n",
      "[2868]\ttraining's binary_logloss: 0.014364\n",
      "[2869]\ttraining's binary_logloss: 0.0143606\n",
      "[2870]\ttraining's binary_logloss: 0.0143581\n",
      "[2871]\ttraining's binary_logloss: 0.0143558\n",
      "[2872]\ttraining's binary_logloss: 0.0143523\n",
      "[2873]\ttraining's binary_logloss: 0.0143498\n",
      "[2874]\ttraining's binary_logloss: 0.0143461\n",
      "[2875]\ttraining's binary_logloss: 0.0143431\n",
      "[2876]\ttraining's binary_logloss: 0.0143403\n",
      "[2877]\ttraining's binary_logloss: 0.0143371\n",
      "[2878]\ttraining's binary_logloss: 0.014334\n",
      "[2879]\ttraining's binary_logloss: 0.014331\n",
      "[2880]\ttraining's binary_logloss: 0.0143291\n",
      "[2881]\ttraining's binary_logloss: 0.0143257\n",
      "[2882]\ttraining's binary_logloss: 0.0143228\n",
      "[2883]\ttraining's binary_logloss: 0.0143199\n",
      "[2884]\ttraining's binary_logloss: 0.0143169\n",
      "[2885]\ttraining's binary_logloss: 0.0143154\n",
      "[2886]\ttraining's binary_logloss: 0.014313\n",
      "[2887]\ttraining's binary_logloss: 0.0143097\n",
      "[2888]\ttraining's binary_logloss: 0.0143076\n",
      "[2889]\ttraining's binary_logloss: 0.0143061\n",
      "[2890]\ttraining's binary_logloss: 0.0143043\n",
      "[2891]\ttraining's binary_logloss: 0.0143026\n",
      "[2892]\ttraining's binary_logloss: 0.0142999\n",
      "[2893]\ttraining's binary_logloss: 0.0142962\n",
      "[2894]\ttraining's binary_logloss: 0.0142941\n",
      "[2895]\ttraining's binary_logloss: 0.0142904\n",
      "[2896]\ttraining's binary_logloss: 0.0142887\n",
      "[2897]\ttraining's binary_logloss: 0.0142858\n",
      "[2898]\ttraining's binary_logloss: 0.0142832\n",
      "[2899]\ttraining's binary_logloss: 0.0142793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2900]\ttraining's binary_logloss: 0.0142756\n",
      "[2901]\ttraining's binary_logloss: 0.0142722\n",
      "[2902]\ttraining's binary_logloss: 0.014269\n",
      "[2903]\ttraining's binary_logloss: 0.014265\n",
      "[2904]\ttraining's binary_logloss: 0.0142634\n",
      "[2905]\ttraining's binary_logloss: 0.0142611\n",
      "[2906]\ttraining's binary_logloss: 0.0142578\n",
      "[2907]\ttraining's binary_logloss: 0.0142553\n",
      "[2908]\ttraining's binary_logloss: 0.0142524\n",
      "[2909]\ttraining's binary_logloss: 0.0142491\n",
      "[2910]\ttraining's binary_logloss: 0.014245\n",
      "[2911]\ttraining's binary_logloss: 0.0142428\n",
      "[2912]\ttraining's binary_logloss: 0.0142401\n",
      "[2913]\ttraining's binary_logloss: 0.0142365\n",
      "[2914]\ttraining's binary_logloss: 0.0142338\n",
      "[2915]\ttraining's binary_logloss: 0.0142311\n",
      "[2916]\ttraining's binary_logloss: 0.0142275\n",
      "[2917]\ttraining's binary_logloss: 0.0142238\n",
      "[2918]\ttraining's binary_logloss: 0.0142213\n",
      "[2919]\ttraining's binary_logloss: 0.0142178\n",
      "[2920]\ttraining's binary_logloss: 0.014216\n",
      "[2921]\ttraining's binary_logloss: 0.0142138\n",
      "[2922]\ttraining's binary_logloss: 0.014211\n",
      "[2923]\ttraining's binary_logloss: 0.0142066\n",
      "[2924]\ttraining's binary_logloss: 0.0142025\n",
      "[2925]\ttraining's binary_logloss: 0.0142001\n",
      "[2926]\ttraining's binary_logloss: 0.0141986\n",
      "[2927]\ttraining's binary_logloss: 0.0141968\n",
      "[2928]\ttraining's binary_logloss: 0.0141936\n",
      "[2929]\ttraining's binary_logloss: 0.0141905\n",
      "[2930]\ttraining's binary_logloss: 0.0141869\n",
      "[2931]\ttraining's binary_logloss: 0.0141852\n",
      "[2932]\ttraining's binary_logloss: 0.0141832\n",
      "[2933]\ttraining's binary_logloss: 0.0141795\n",
      "[2934]\ttraining's binary_logloss: 0.0141757\n",
      "[2935]\ttraining's binary_logloss: 0.0141719\n",
      "[2936]\ttraining's binary_logloss: 0.0141693\n",
      "[2937]\ttraining's binary_logloss: 0.0141652\n",
      "[2938]\ttraining's binary_logloss: 0.0141625\n",
      "[2939]\ttraining's binary_logloss: 0.0141593\n",
      "[2940]\ttraining's binary_logloss: 0.0141563\n",
      "[2941]\ttraining's binary_logloss: 0.0141535\n",
      "[2942]\ttraining's binary_logloss: 0.0141514\n",
      "[2943]\ttraining's binary_logloss: 0.0141474\n",
      "[2944]\ttraining's binary_logloss: 0.014145\n",
      "[2945]\ttraining's binary_logloss: 0.0141435\n",
      "[2946]\ttraining's binary_logloss: 0.0141416\n",
      "[2947]\ttraining's binary_logloss: 0.0141387\n",
      "[2948]\ttraining's binary_logloss: 0.0141363\n",
      "[2949]\ttraining's binary_logloss: 0.0141336\n",
      "[2950]\ttraining's binary_logloss: 0.0141298\n",
      "[2951]\ttraining's binary_logloss: 0.0141272\n",
      "[2952]\ttraining's binary_logloss: 0.0141247\n",
      "[2953]\ttraining's binary_logloss: 0.0141209\n",
      "[2954]\ttraining's binary_logloss: 0.0141177\n",
      "[2955]\ttraining's binary_logloss: 0.0141146\n",
      "[2956]\ttraining's binary_logloss: 0.0141123\n",
      "[2957]\ttraining's binary_logloss: 0.0141106\n",
      "[2958]\ttraining's binary_logloss: 0.0141079\n",
      "[2959]\ttraining's binary_logloss: 0.0141048\n",
      "[2960]\ttraining's binary_logloss: 0.0141017\n",
      "[2961]\ttraining's binary_logloss: 0.0140994\n",
      "[2962]\ttraining's binary_logloss: 0.0140963\n",
      "[2963]\ttraining's binary_logloss: 0.0140938\n",
      "[2964]\ttraining's binary_logloss: 0.0140909\n",
      "[2965]\ttraining's binary_logloss: 0.0140888\n",
      "[2966]\ttraining's binary_logloss: 0.0140861\n",
      "[2967]\ttraining's binary_logloss: 0.0140836\n",
      "[2968]\ttraining's binary_logloss: 0.0140797\n",
      "[2969]\ttraining's binary_logloss: 0.0140756\n",
      "[2970]\ttraining's binary_logloss: 0.0140732\n",
      "[2971]\ttraining's binary_logloss: 0.0140708\n",
      "[2972]\ttraining's binary_logloss: 0.0140678\n",
      "[2973]\ttraining's binary_logloss: 0.0140642\n",
      "[2974]\ttraining's binary_logloss: 0.0140614\n",
      "[2975]\ttraining's binary_logloss: 0.0140585\n",
      "[2976]\ttraining's binary_logloss: 0.0140551\n",
      "[2977]\ttraining's binary_logloss: 0.0140517\n",
      "[2978]\ttraining's binary_logloss: 0.0140502\n",
      "[2979]\ttraining's binary_logloss: 0.0140484\n",
      "[2980]\ttraining's binary_logloss: 0.0140454\n",
      "[2981]\ttraining's binary_logloss: 0.0140423\n",
      "[2982]\ttraining's binary_logloss: 0.0140407\n",
      "[2983]\ttraining's binary_logloss: 0.0140391\n",
      "[2984]\ttraining's binary_logloss: 0.0140376\n",
      "[2985]\ttraining's binary_logloss: 0.014035\n",
      "[2986]\ttraining's binary_logloss: 0.0140335\n",
      "[2987]\ttraining's binary_logloss: 0.0140303\n",
      "[2988]\ttraining's binary_logloss: 0.0140287\n",
      "[2989]\ttraining's binary_logloss: 0.0140262\n",
      "[2990]\ttraining's binary_logloss: 0.0140244\n",
      "[2991]\ttraining's binary_logloss: 0.0140203\n",
      "[2992]\ttraining's binary_logloss: 0.0140162\n",
      "[2993]\ttraining's binary_logloss: 0.0140117\n",
      "[2994]\ttraining's binary_logloss: 0.0140103\n",
      "[2995]\ttraining's binary_logloss: 0.014008\n",
      "[2996]\ttraining's binary_logloss: 0.0140058\n",
      "[2997]\ttraining's binary_logloss: 0.0140028\n",
      "[2998]\ttraining's binary_logloss: 0.0139995\n",
      "[2999]\ttraining's binary_logloss: 0.0139977\n",
      "[3000]\ttraining's binary_logloss: 0.013996\n",
      "[3001]\ttraining's binary_logloss: 0.0139939\n",
      "[3002]\ttraining's binary_logloss: 0.0139923\n",
      "[3003]\ttraining's binary_logloss: 0.0139894\n",
      "[3004]\ttraining's binary_logloss: 0.0139866\n",
      "[3005]\ttraining's binary_logloss: 0.0139836\n",
      "[3006]\ttraining's binary_logloss: 0.0139806\n",
      "[3007]\ttraining's binary_logloss: 0.0139771\n",
      "[3008]\ttraining's binary_logloss: 0.0139734\n",
      "[3009]\ttraining's binary_logloss: 0.0139692\n",
      "[3010]\ttraining's binary_logloss: 0.0139655\n",
      "[3011]\ttraining's binary_logloss: 0.0139625\n",
      "[3012]\ttraining's binary_logloss: 0.0139594\n",
      "[3013]\ttraining's binary_logloss: 0.0139567\n",
      "[3014]\ttraining's binary_logloss: 0.0139533\n",
      "[3015]\ttraining's binary_logloss: 0.0139509\n",
      "[3016]\ttraining's binary_logloss: 0.0139482\n",
      "[3017]\ttraining's binary_logloss: 0.0139452\n",
      "[3018]\ttraining's binary_logloss: 0.0139428\n",
      "[3019]\ttraining's binary_logloss: 0.0139412\n",
      "[3020]\ttraining's binary_logloss: 0.0139395\n",
      "[3021]\ttraining's binary_logloss: 0.0139371\n",
      "[3022]\ttraining's binary_logloss: 0.0139357\n",
      "[3023]\ttraining's binary_logloss: 0.0139333\n",
      "[3024]\ttraining's binary_logloss: 0.0139306\n",
      "[3025]\ttraining's binary_logloss: 0.0139279\n",
      "[3026]\ttraining's binary_logloss: 0.0139245\n",
      "[3027]\ttraining's binary_logloss: 0.0139222\n",
      "[3028]\ttraining's binary_logloss: 0.0139188\n",
      "[3029]\ttraining's binary_logloss: 0.0139173\n",
      "[3030]\ttraining's binary_logloss: 0.0139143\n",
      "[3031]\ttraining's binary_logloss: 0.0139109\n",
      "[3032]\ttraining's binary_logloss: 0.0139092\n",
      "[3033]\ttraining's binary_logloss: 0.0139076\n",
      "[3034]\ttraining's binary_logloss: 0.0139048\n",
      "[3035]\ttraining's binary_logloss: 0.0139012\n",
      "[3036]\ttraining's binary_logloss: 0.0138978\n",
      "[3037]\ttraining's binary_logloss: 0.0138961\n",
      "[3038]\ttraining's binary_logloss: 0.0138947\n",
      "[3039]\ttraining's binary_logloss: 0.0138925\n",
      "[3040]\ttraining's binary_logloss: 0.0138899\n",
      "[3041]\ttraining's binary_logloss: 0.0138865\n",
      "[3042]\ttraining's binary_logloss: 0.013885\n",
      "[3043]\ttraining's binary_logloss: 0.0138825\n",
      "[3044]\ttraining's binary_logloss: 0.0138809\n",
      "[3045]\ttraining's binary_logloss: 0.0138792\n",
      "[3046]\ttraining's binary_logloss: 0.0138756\n",
      "[3047]\ttraining's binary_logloss: 0.0138734\n",
      "[3048]\ttraining's binary_logloss: 0.0138695\n",
      "[3049]\ttraining's binary_logloss: 0.0138652\n",
      "[3050]\ttraining's binary_logloss: 0.0138623\n",
      "[3051]\ttraining's binary_logloss: 0.013859\n",
      "[3052]\ttraining's binary_logloss: 0.0138576\n",
      "[3053]\ttraining's binary_logloss: 0.013855\n",
      "[3054]\ttraining's binary_logloss: 0.0138519\n",
      "[3055]\ttraining's binary_logloss: 0.0138487\n",
      "[3056]\ttraining's binary_logloss: 0.0138469\n",
      "[3057]\ttraining's binary_logloss: 0.0138436\n",
      "[3058]\ttraining's binary_logloss: 0.0138411\n",
      "[3059]\ttraining's binary_logloss: 0.0138383\n",
      "[3060]\ttraining's binary_logloss: 0.0138354\n",
      "[3061]\ttraining's binary_logloss: 0.0138329\n",
      "[3062]\ttraining's binary_logloss: 0.0138293\n",
      "[3063]\ttraining's binary_logloss: 0.0138255\n",
      "[3064]\ttraining's binary_logloss: 0.0138229\n",
      "[3065]\ttraining's binary_logloss: 0.0138193\n",
      "[3066]\ttraining's binary_logloss: 0.0138165\n",
      "[3067]\ttraining's binary_logloss: 0.0138125\n",
      "[3068]\ttraining's binary_logloss: 0.0138111\n",
      "[3069]\ttraining's binary_logloss: 0.0138096\n",
      "[3070]\ttraining's binary_logloss: 0.0138069\n",
      "[3071]\ttraining's binary_logloss: 0.013804\n",
      "[3072]\ttraining's binary_logloss: 0.0138009\n",
      "[3073]\ttraining's binary_logloss: 0.0137992\n",
      "[3074]\ttraining's binary_logloss: 0.0137974\n",
      "[3075]\ttraining's binary_logloss: 0.0137949\n",
      "[3076]\ttraining's binary_logloss: 0.0137918\n",
      "[3077]\ttraining's binary_logloss: 0.0137903\n",
      "[3078]\ttraining's binary_logloss: 0.0137886\n",
      "[3079]\ttraining's binary_logloss: 0.0137851\n",
      "[3080]\ttraining's binary_logloss: 0.0137815\n",
      "[3081]\ttraining's binary_logloss: 0.0137785\n",
      "[3082]\ttraining's binary_logloss: 0.0137762\n",
      "[3083]\ttraining's binary_logloss: 0.0137734\n",
      "[3084]\ttraining's binary_logloss: 0.01377\n",
      "[3085]\ttraining's binary_logloss: 0.0137662\n",
      "[3086]\ttraining's binary_logloss: 0.0137629\n",
      "[3087]\ttraining's binary_logloss: 0.0137599\n",
      "[3088]\ttraining's binary_logloss: 0.0137571\n",
      "[3089]\ttraining's binary_logloss: 0.013755\n",
      "[3090]\ttraining's binary_logloss: 0.0137525\n",
      "[3091]\ttraining's binary_logloss: 0.0137511\n",
      "[3092]\ttraining's binary_logloss: 0.0137495\n",
      "[3093]\ttraining's binary_logloss: 0.0137467\n",
      "[3094]\ttraining's binary_logloss: 0.0137433\n",
      "[3095]\ttraining's binary_logloss: 0.0137403\n",
      "[3096]\ttraining's binary_logloss: 0.0137377\n",
      "[3097]\ttraining's binary_logloss: 0.0137345\n",
      "[3098]\ttraining's binary_logloss: 0.0137321\n",
      "[3099]\ttraining's binary_logloss: 0.0137299\n",
      "[3100]\ttraining's binary_logloss: 0.013727\n",
      "[3101]\ttraining's binary_logloss: 0.0137242\n",
      "[3102]\ttraining's binary_logloss: 0.0137215\n",
      "[3103]\ttraining's binary_logloss: 0.0137186\n",
      "[3104]\ttraining's binary_logloss: 0.013716\n",
      "[3105]\ttraining's binary_logloss: 0.0137146\n",
      "[3106]\ttraining's binary_logloss: 0.0137116\n",
      "[3107]\ttraining's binary_logloss: 0.0137095\n",
      "[3108]\ttraining's binary_logloss: 0.013708\n",
      "[3109]\ttraining's binary_logloss: 0.0137064\n",
      "[3110]\ttraining's binary_logloss: 0.0137037\n",
      "[3111]\ttraining's binary_logloss: 0.0137016\n",
      "[3112]\ttraining's binary_logloss: 0.013699\n",
      "[3113]\ttraining's binary_logloss: 0.0136964\n",
      "[3114]\ttraining's binary_logloss: 0.013695\n",
      "[3115]\ttraining's binary_logloss: 0.0136916\n",
      "[3116]\ttraining's binary_logloss: 0.0136887\n",
      "[3117]\ttraining's binary_logloss: 0.013686\n",
      "[3118]\ttraining's binary_logloss: 0.0136827\n",
      "[3119]\ttraining's binary_logloss: 0.0136797\n",
      "[3120]\ttraining's binary_logloss: 0.013677\n",
      "[3121]\ttraining's binary_logloss: 0.0136748\n",
      "[3122]\ttraining's binary_logloss: 0.0136717\n",
      "[3123]\ttraining's binary_logloss: 0.0136688\n",
      "[3124]\ttraining's binary_logloss: 0.0136657\n",
      "[3125]\ttraining's binary_logloss: 0.013662\n",
      "[3126]\ttraining's binary_logloss: 0.013659\n",
      "[3127]\ttraining's binary_logloss: 0.0136567\n",
      "[3128]\ttraining's binary_logloss: 0.0136532\n",
      "[3129]\ttraining's binary_logloss: 0.0136515\n",
      "[3130]\ttraining's binary_logloss: 0.0136489\n",
      "[3131]\ttraining's binary_logloss: 0.0136463\n",
      "[3132]\ttraining's binary_logloss: 0.0136435\n",
      "[3133]\ttraining's binary_logloss: 0.0136409\n",
      "[3134]\ttraining's binary_logloss: 0.0136384\n",
      "[3135]\ttraining's binary_logloss: 0.0136353\n",
      "[3136]\ttraining's binary_logloss: 0.013633\n",
      "[3137]\ttraining's binary_logloss: 0.0136315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3138]\ttraining's binary_logloss: 0.013629\n",
      "[3139]\ttraining's binary_logloss: 0.0136258\n",
      "[3140]\ttraining's binary_logloss: 0.0136229\n",
      "[3141]\ttraining's binary_logloss: 0.0136211\n",
      "[3142]\ttraining's binary_logloss: 0.0136198\n",
      "[3143]\ttraining's binary_logloss: 0.0136166\n",
      "[3144]\ttraining's binary_logloss: 0.0136151\n",
      "[3145]\ttraining's binary_logloss: 0.0136136\n",
      "[3146]\ttraining's binary_logloss: 0.0136114\n",
      "[3147]\ttraining's binary_logloss: 0.0136097\n",
      "[3148]\ttraining's binary_logloss: 0.0136071\n",
      "[3149]\ttraining's binary_logloss: 0.0136057\n",
      "[3150]\ttraining's binary_logloss: 0.013604\n",
      "[3151]\ttraining's binary_logloss: 0.013601\n",
      "[3152]\ttraining's binary_logloss: 0.0135989\n",
      "[3153]\ttraining's binary_logloss: 0.0135972\n",
      "[3154]\ttraining's binary_logloss: 0.0135936\n",
      "[3155]\ttraining's binary_logloss: 0.0135919\n",
      "[3156]\ttraining's binary_logloss: 0.0135884\n",
      "[3157]\ttraining's binary_logloss: 0.0135852\n",
      "[3158]\ttraining's binary_logloss: 0.0135817\n",
      "[3159]\ttraining's binary_logloss: 0.0135785\n",
      "[3160]\ttraining's binary_logloss: 0.013575\n",
      "[3161]\ttraining's binary_logloss: 0.0135725\n",
      "[3162]\ttraining's binary_logloss: 0.0135698\n",
      "[3163]\ttraining's binary_logloss: 0.0135674\n",
      "[3164]\ttraining's binary_logloss: 0.0135644\n",
      "[3165]\ttraining's binary_logloss: 0.0135617\n",
      "[3166]\ttraining's binary_logloss: 0.0135591\n",
      "[3167]\ttraining's binary_logloss: 0.0135555\n",
      "[3168]\ttraining's binary_logloss: 0.013553\n",
      "[3169]\ttraining's binary_logloss: 0.0135515\n",
      "[3170]\ttraining's binary_logloss: 0.0135488\n",
      "[3171]\ttraining's binary_logloss: 0.0135463\n",
      "[3172]\ttraining's binary_logloss: 0.0135434\n",
      "[3173]\ttraining's binary_logloss: 0.0135421\n",
      "[3174]\ttraining's binary_logloss: 0.0135406\n",
      "[3175]\ttraining's binary_logloss: 0.0135385\n",
      "[3176]\ttraining's binary_logloss: 0.0135363\n",
      "[3177]\ttraining's binary_logloss: 0.0135336\n",
      "[3178]\ttraining's binary_logloss: 0.0135322\n",
      "[3179]\ttraining's binary_logloss: 0.0135291\n",
      "[3180]\ttraining's binary_logloss: 0.0135269\n",
      "[3181]\ttraining's binary_logloss: 0.0135236\n",
      "[3182]\ttraining's binary_logloss: 0.0135215\n",
      "[3183]\ttraining's binary_logloss: 0.0135187\n",
      "[3184]\ttraining's binary_logloss: 0.013517\n",
      "[3185]\ttraining's binary_logloss: 0.0135154\n",
      "[3186]\ttraining's binary_logloss: 0.0135126\n",
      "[3187]\ttraining's binary_logloss: 0.0135111\n",
      "[3188]\ttraining's binary_logloss: 0.0135083\n",
      "[3189]\ttraining's binary_logloss: 0.0135056\n",
      "[3190]\ttraining's binary_logloss: 0.0135025\n",
      "[3191]\ttraining's binary_logloss: 0.0135002\n",
      "[3192]\ttraining's binary_logloss: 0.0134978\n",
      "[3193]\ttraining's binary_logloss: 0.0134946\n",
      "[3194]\ttraining's binary_logloss: 0.013491\n",
      "[3195]\ttraining's binary_logloss: 0.0134889\n",
      "[3196]\ttraining's binary_logloss: 0.0134856\n",
      "[3197]\ttraining's binary_logloss: 0.0134838\n",
      "[3198]\ttraining's binary_logloss: 0.0134807\n",
      "[3199]\ttraining's binary_logloss: 0.0134786\n",
      "[3200]\ttraining's binary_logloss: 0.0134759\n",
      "[3201]\ttraining's binary_logloss: 0.0134725\n",
      "[3202]\ttraining's binary_logloss: 0.0134699\n",
      "[3203]\ttraining's binary_logloss: 0.0134677\n",
      "[3204]\ttraining's binary_logloss: 0.0134662\n",
      "[3205]\ttraining's binary_logloss: 0.0134637\n",
      "[3206]\ttraining's binary_logloss: 0.0134617\n",
      "[3207]\ttraining's binary_logloss: 0.0134591\n",
      "[3208]\ttraining's binary_logloss: 0.0134575\n",
      "[3209]\ttraining's binary_logloss: 0.0134552\n",
      "[3210]\ttraining's binary_logloss: 0.0134525\n",
      "[3211]\ttraining's binary_logloss: 0.0134502\n",
      "[3212]\ttraining's binary_logloss: 0.0134476\n",
      "[3213]\ttraining's binary_logloss: 0.0134449\n",
      "[3214]\ttraining's binary_logloss: 0.0134424\n",
      "[3215]\ttraining's binary_logloss: 0.0134397\n",
      "[3216]\ttraining's binary_logloss: 0.0134381\n",
      "[3217]\ttraining's binary_logloss: 0.0134366\n",
      "[3218]\ttraining's binary_logloss: 0.013434\n",
      "[3219]\ttraining's binary_logloss: 0.0134326\n",
      "[3220]\ttraining's binary_logloss: 0.013431\n",
      "[3221]\ttraining's binary_logloss: 0.0134284\n",
      "[3222]\ttraining's binary_logloss: 0.0134259\n",
      "[3223]\ttraining's binary_logloss: 0.0134234\n",
      "[3224]\ttraining's binary_logloss: 0.013421\n",
      "[3225]\ttraining's binary_logloss: 0.0134194\n",
      "[3226]\ttraining's binary_logloss: 0.0134159\n",
      "[3227]\ttraining's binary_logloss: 0.0134144\n",
      "[3228]\ttraining's binary_logloss: 0.0134128\n",
      "[3229]\ttraining's binary_logloss: 0.0134103\n",
      "[3230]\ttraining's binary_logloss: 0.0134089\n",
      "[3231]\ttraining's binary_logloss: 0.0134073\n",
      "[3232]\ttraining's binary_logloss: 0.0134047\n",
      "[3233]\ttraining's binary_logloss: 0.0134022\n",
      "[3234]\ttraining's binary_logloss: 0.0133991\n",
      "[3235]\ttraining's binary_logloss: 0.0133963\n",
      "[3236]\ttraining's binary_logloss: 0.0133937\n",
      "[3237]\ttraining's binary_logloss: 0.0133921\n",
      "[3238]\ttraining's binary_logloss: 0.0133899\n",
      "[3239]\ttraining's binary_logloss: 0.0133884\n",
      "[3240]\ttraining's binary_logloss: 0.0133869\n",
      "[3241]\ttraining's binary_logloss: 0.0133848\n",
      "[3242]\ttraining's binary_logloss: 0.0133823\n",
      "[3243]\ttraining's binary_logloss: 0.013379\n",
      "[3244]\ttraining's binary_logloss: 0.0133766\n",
      "[3245]\ttraining's binary_logloss: 0.0133752\n",
      "[3246]\ttraining's binary_logloss: 0.0133726\n",
      "[3247]\ttraining's binary_logloss: 0.0133698\n",
      "[3248]\ttraining's binary_logloss: 0.0133683\n",
      "[3249]\ttraining's binary_logloss: 0.0133658\n",
      "[3250]\ttraining's binary_logloss: 0.0133637\n",
      "[3251]\ttraining's binary_logloss: 0.0133619\n",
      "[3252]\ttraining's binary_logloss: 0.0133604\n",
      "[3253]\ttraining's binary_logloss: 0.013358\n",
      "[3254]\ttraining's binary_logloss: 0.0133564\n",
      "[3255]\ttraining's binary_logloss: 0.0133543\n",
      "[3256]\ttraining's binary_logloss: 0.0133527\n",
      "[3257]\ttraining's binary_logloss: 0.0133513\n",
      "[3258]\ttraining's binary_logloss: 0.0133486\n",
      "[3259]\ttraining's binary_logloss: 0.0133471\n",
      "[3260]\ttraining's binary_logloss: 0.013345\n",
      "[3261]\ttraining's binary_logloss: 0.0133431\n",
      "[3262]\ttraining's binary_logloss: 0.0133411\n",
      "[3263]\ttraining's binary_logloss: 0.0133396\n",
      "[3264]\ttraining's binary_logloss: 0.0133381\n",
      "[3265]\ttraining's binary_logloss: 0.0133357\n",
      "[3266]\ttraining's binary_logloss: 0.0133331\n",
      "[3267]\ttraining's binary_logloss: 0.01333\n",
      "[3268]\ttraining's binary_logloss: 0.0133283\n",
      "[3269]\ttraining's binary_logloss: 0.0133249\n",
      "[3270]\ttraining's binary_logloss: 0.0133223\n",
      "[3271]\ttraining's binary_logloss: 0.0133197\n",
      "[3272]\ttraining's binary_logloss: 0.0133171\n",
      "[3273]\ttraining's binary_logloss: 0.0133158\n",
      "[3274]\ttraining's binary_logloss: 0.0133127\n",
      "[3275]\ttraining's binary_logloss: 0.0133104\n",
      "[3276]\ttraining's binary_logloss: 0.0133078\n",
      "[3277]\ttraining's binary_logloss: 0.0133049\n",
      "[3278]\ttraining's binary_logloss: 0.0133016\n",
      "[3279]\ttraining's binary_logloss: 0.0132995\n",
      "[3280]\ttraining's binary_logloss: 0.0132968\n",
      "[3281]\ttraining's binary_logloss: 0.013293\n",
      "[3282]\ttraining's binary_logloss: 0.0132915\n",
      "[3283]\ttraining's binary_logloss: 0.0132885\n",
      "[3284]\ttraining's binary_logloss: 0.0132859\n",
      "[3285]\ttraining's binary_logloss: 0.0132833\n",
      "[3286]\ttraining's binary_logloss: 0.013281\n",
      "[3287]\ttraining's binary_logloss: 0.0132781\n",
      "[3288]\ttraining's binary_logloss: 0.0132765\n",
      "[3289]\ttraining's binary_logloss: 0.0132736\n",
      "[3290]\ttraining's binary_logloss: 0.0132711\n",
      "[3291]\ttraining's binary_logloss: 0.0132677\n",
      "[3292]\ttraining's binary_logloss: 0.0132651\n",
      "[3293]\ttraining's binary_logloss: 0.0132625\n",
      "[3294]\ttraining's binary_logloss: 0.0132597\n",
      "[3295]\ttraining's binary_logloss: 0.0132567\n",
      "[3296]\ttraining's binary_logloss: 0.0132548\n",
      "[3297]\ttraining's binary_logloss: 0.0132532\n",
      "[3298]\ttraining's binary_logloss: 0.0132517\n",
      "[3299]\ttraining's binary_logloss: 0.0132501\n",
      "[3300]\ttraining's binary_logloss: 0.0132487\n",
      "[3301]\ttraining's binary_logloss: 0.0132471\n",
      "[3302]\ttraining's binary_logloss: 0.0132459\n",
      "[3303]\ttraining's binary_logloss: 0.0132435\n",
      "[3304]\ttraining's binary_logloss: 0.0132409\n",
      "[3305]\ttraining's binary_logloss: 0.0132383\n",
      "[3306]\ttraining's binary_logloss: 0.0132366\n",
      "[3307]\ttraining's binary_logloss: 0.013234\n",
      "[3308]\ttraining's binary_logloss: 0.0132317\n",
      "[3309]\ttraining's binary_logloss: 0.0132293\n",
      "[3310]\ttraining's binary_logloss: 0.0132261\n",
      "[3311]\ttraining's binary_logloss: 0.0132232\n",
      "[3312]\ttraining's binary_logloss: 0.013221\n",
      "[3313]\ttraining's binary_logloss: 0.0132188\n",
      "[3314]\ttraining's binary_logloss: 0.0132159\n",
      "[3315]\ttraining's binary_logloss: 0.0132136\n",
      "[3316]\ttraining's binary_logloss: 0.0132106\n",
      "[3317]\ttraining's binary_logloss: 0.0132091\n",
      "[3318]\ttraining's binary_logloss: 0.0132076\n",
      "[3319]\ttraining's binary_logloss: 0.0132062\n",
      "[3320]\ttraining's binary_logloss: 0.0132047\n",
      "[3321]\ttraining's binary_logloss: 0.0132022\n",
      "[3322]\ttraining's binary_logloss: 0.0132002\n",
      "[3323]\ttraining's binary_logloss: 0.0131981\n",
      "[3324]\ttraining's binary_logloss: 0.0131967\n",
      "[3325]\ttraining's binary_logloss: 0.0131953\n",
      "[3326]\ttraining's binary_logloss: 0.0131937\n",
      "[3327]\ttraining's binary_logloss: 0.0131913\n",
      "[3328]\ttraining's binary_logloss: 0.0131884\n",
      "[3329]\ttraining's binary_logloss: 0.0131861\n",
      "[3330]\ttraining's binary_logloss: 0.0131835\n",
      "[3331]\ttraining's binary_logloss: 0.0131821\n",
      "[3332]\ttraining's binary_logloss: 0.0131797\n",
      "[3333]\ttraining's binary_logloss: 0.0131774\n",
      "[3334]\ttraining's binary_logloss: 0.0131743\n",
      "[3335]\ttraining's binary_logloss: 0.0131711\n",
      "[3336]\ttraining's binary_logloss: 0.0131698\n",
      "[3337]\ttraining's binary_logloss: 0.0131682\n",
      "[3338]\ttraining's binary_logloss: 0.0131667\n",
      "[3339]\ttraining's binary_logloss: 0.0131639\n",
      "[3340]\ttraining's binary_logloss: 0.0131613\n",
      "[3341]\ttraining's binary_logloss: 0.0131583\n",
      "[3342]\ttraining's binary_logloss: 0.013155\n",
      "[3343]\ttraining's binary_logloss: 0.0131525\n",
      "[3344]\ttraining's binary_logloss: 0.0131494\n",
      "[3345]\ttraining's binary_logloss: 0.013148\n",
      "[3346]\ttraining's binary_logloss: 0.013145\n",
      "[3347]\ttraining's binary_logloss: 0.0131426\n",
      "[3348]\ttraining's binary_logloss: 0.0131405\n",
      "[3349]\ttraining's binary_logloss: 0.0131388\n",
      "[3350]\ttraining's binary_logloss: 0.0131363\n",
      "[3351]\ttraining's binary_logloss: 0.0131341\n",
      "[3352]\ttraining's binary_logloss: 0.0131315\n",
      "[3353]\ttraining's binary_logloss: 0.01313\n",
      "[3354]\ttraining's binary_logloss: 0.0131286\n",
      "[3355]\ttraining's binary_logloss: 0.013127\n",
      "[3356]\ttraining's binary_logloss: 0.0131258\n",
      "[3357]\ttraining's binary_logloss: 0.0131243\n",
      "[3358]\ttraining's binary_logloss: 0.0131216\n",
      "[3359]\ttraining's binary_logloss: 0.0131203\n",
      "[3360]\ttraining's binary_logloss: 0.0131187\n",
      "[3361]\ttraining's binary_logloss: 0.0131166\n",
      "[3362]\ttraining's binary_logloss: 0.0131142\n",
      "[3363]\ttraining's binary_logloss: 0.0131128\n",
      "[3364]\ttraining's binary_logloss: 0.0131097\n",
      "[3365]\ttraining's binary_logloss: 0.0131065\n",
      "[3366]\ttraining's binary_logloss: 0.0131045\n",
      "[3367]\ttraining's binary_logloss: 0.013102\n",
      "[3368]\ttraining's binary_logloss: 0.0130999\n",
      "[3369]\ttraining's binary_logloss: 0.0130969\n",
      "[3370]\ttraining's binary_logloss: 0.0130946\n",
      "[3371]\ttraining's binary_logloss: 0.0130924\n",
      "[3372]\ttraining's binary_logloss: 0.0130895\n",
      "[3373]\ttraining's binary_logloss: 0.0130867\n",
      "[3374]\ttraining's binary_logloss: 0.0130848\n",
      "[3375]\ttraining's binary_logloss: 0.0130834\n",
      "[3376]\ttraining's binary_logloss: 0.0130819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3377]\ttraining's binary_logloss: 0.0130786\n",
      "[3378]\ttraining's binary_logloss: 0.0130769\n",
      "[3379]\ttraining's binary_logloss: 0.0130746\n",
      "[3380]\ttraining's binary_logloss: 0.0130732\n",
      "[3381]\ttraining's binary_logloss: 0.0130704\n",
      "[3382]\ttraining's binary_logloss: 0.0130689\n",
      "[3383]\ttraining's binary_logloss: 0.0130676\n",
      "[3384]\ttraining's binary_logloss: 0.0130662\n",
      "[3385]\ttraining's binary_logloss: 0.0130635\n",
      "[3386]\ttraining's binary_logloss: 0.0130615\n",
      "[3387]\ttraining's binary_logloss: 0.0130592\n",
      "[3388]\ttraining's binary_logloss: 0.013056\n",
      "[3389]\ttraining's binary_logloss: 0.0130531\n",
      "[3390]\ttraining's binary_logloss: 0.0130504\n",
      "[3391]\ttraining's binary_logloss: 0.0130481\n",
      "[3392]\ttraining's binary_logloss: 0.0130467\n",
      "[3393]\ttraining's binary_logloss: 0.0130451\n",
      "[3394]\ttraining's binary_logloss: 0.0130439\n",
      "[3395]\ttraining's binary_logloss: 0.0130423\n",
      "[3396]\ttraining's binary_logloss: 0.0130403\n",
      "[3397]\ttraining's binary_logloss: 0.013039\n",
      "[3398]\ttraining's binary_logloss: 0.0130375\n",
      "[3399]\ttraining's binary_logloss: 0.0130354\n",
      "[3400]\ttraining's binary_logloss: 0.013034\n",
      "[3401]\ttraining's binary_logloss: 0.0130315\n",
      "[3402]\ttraining's binary_logloss: 0.0130289\n",
      "[3403]\ttraining's binary_logloss: 0.0130268\n",
      "[3404]\ttraining's binary_logloss: 0.0130253\n",
      "[3405]\ttraining's binary_logloss: 0.0130229\n",
      "[3406]\ttraining's binary_logloss: 0.0130216\n",
      "[3407]\ttraining's binary_logloss: 0.0130189\n",
      "[3408]\ttraining's binary_logloss: 0.0130174\n",
      "[3409]\ttraining's binary_logloss: 0.0130157\n",
      "[3410]\ttraining's binary_logloss: 0.0130133\n",
      "[3411]\ttraining's binary_logloss: 0.0130105\n",
      "[3412]\ttraining's binary_logloss: 0.0130077\n",
      "[3413]\ttraining's binary_logloss: 0.0130052\n",
      "[3414]\ttraining's binary_logloss: 0.0130039\n",
      "[3415]\ttraining's binary_logloss: 0.0130019\n",
      "[3416]\ttraining's binary_logloss: 0.0129997\n",
      "[3417]\ttraining's binary_logloss: 0.0129968\n",
      "[3418]\ttraining's binary_logloss: 0.0129951\n",
      "[3419]\ttraining's binary_logloss: 0.0129939\n",
      "[3420]\ttraining's binary_logloss: 0.012992\n",
      "[3421]\ttraining's binary_logloss: 0.0129907\n",
      "[3422]\ttraining's binary_logloss: 0.012988\n",
      "[3423]\ttraining's binary_logloss: 0.0129853\n",
      "[3424]\ttraining's binary_logloss: 0.0129837\n",
      "[3425]\ttraining's binary_logloss: 0.0129813\n",
      "[3426]\ttraining's binary_logloss: 0.0129799\n",
      "[3427]\ttraining's binary_logloss: 0.0129779\n",
      "[3428]\ttraining's binary_logloss: 0.0129761\n",
      "[3429]\ttraining's binary_logloss: 0.0129748\n",
      "[3430]\ttraining's binary_logloss: 0.0129734\n",
      "[3431]\ttraining's binary_logloss: 0.0129721\n",
      "[3432]\ttraining's binary_logloss: 0.0129706\n",
      "[3433]\ttraining's binary_logloss: 0.0129682\n",
      "[3434]\ttraining's binary_logloss: 0.0129668\n",
      "[3435]\ttraining's binary_logloss: 0.0129652\n",
      "[3436]\ttraining's binary_logloss: 0.0129627\n",
      "[3437]\ttraining's binary_logloss: 0.0129609\n",
      "[3438]\ttraining's binary_logloss: 0.0129589\n",
      "[3439]\ttraining's binary_logloss: 0.0129565\n",
      "[3440]\ttraining's binary_logloss: 0.0129546\n",
      "[3441]\ttraining's binary_logloss: 0.0129523\n",
      "[3442]\ttraining's binary_logloss: 0.0129495\n",
      "[3443]\ttraining's binary_logloss: 0.012946\n",
      "[3444]\ttraining's binary_logloss: 0.0129445\n",
      "[3445]\ttraining's binary_logloss: 0.0129424\n",
      "[3446]\ttraining's binary_logloss: 0.0129409\n",
      "[3447]\ttraining's binary_logloss: 0.0129381\n",
      "[3448]\ttraining's binary_logloss: 0.0129347\n",
      "[3449]\ttraining's binary_logloss: 0.0129334\n",
      "[3450]\ttraining's binary_logloss: 0.0129319\n",
      "[3451]\ttraining's binary_logloss: 0.0129293\n",
      "[3452]\ttraining's binary_logloss: 0.0129266\n",
      "[3453]\ttraining's binary_logloss: 0.0129242\n",
      "[3454]\ttraining's binary_logloss: 0.0129216\n",
      "[3455]\ttraining's binary_logloss: 0.0129203\n",
      "[3456]\ttraining's binary_logloss: 0.0129188\n",
      "[3457]\ttraining's binary_logloss: 0.012917\n",
      "[3458]\ttraining's binary_logloss: 0.0129157\n",
      "[3459]\ttraining's binary_logloss: 0.0129142\n",
      "[3460]\ttraining's binary_logloss: 0.0129113\n",
      "[3461]\ttraining's binary_logloss: 0.0129074\n",
      "[3462]\ttraining's binary_logloss: 0.0129062\n",
      "[3463]\ttraining's binary_logloss: 0.0129037\n",
      "[3464]\ttraining's binary_logloss: 0.0129015\n",
      "[3465]\ttraining's binary_logloss: 0.0128989\n",
      "[3466]\ttraining's binary_logloss: 0.0128964\n",
      "[3467]\ttraining's binary_logloss: 0.012895\n",
      "[3468]\ttraining's binary_logloss: 0.0128923\n",
      "[3469]\ttraining's binary_logloss: 0.0128905\n",
      "[3470]\ttraining's binary_logloss: 0.0128881\n",
      "[3471]\ttraining's binary_logloss: 0.0128868\n",
      "[3472]\ttraining's binary_logloss: 0.0128853\n",
      "[3473]\ttraining's binary_logloss: 0.0128836\n",
      "[3474]\ttraining's binary_logloss: 0.0128824\n",
      "[3475]\ttraining's binary_logloss: 0.0128801\n",
      "[3476]\ttraining's binary_logloss: 0.0128786\n",
      "[3477]\ttraining's binary_logloss: 0.0128773\n",
      "[3478]\ttraining's binary_logloss: 0.012875\n",
      "[3479]\ttraining's binary_logloss: 0.0128724\n",
      "[3480]\ttraining's binary_logloss: 0.0128708\n",
      "[3481]\ttraining's binary_logloss: 0.0128685\n",
      "[3482]\ttraining's binary_logloss: 0.0128667\n",
      "[3483]\ttraining's binary_logloss: 0.0128655\n",
      "[3484]\ttraining's binary_logloss: 0.012864\n",
      "[3485]\ttraining's binary_logloss: 0.0128612\n",
      "[3486]\ttraining's binary_logloss: 0.0128598\n",
      "[3487]\ttraining's binary_logloss: 0.0128584\n",
      "[3488]\ttraining's binary_logloss: 0.0128561\n",
      "[3489]\ttraining's binary_logloss: 0.0128549\n",
      "[3490]\ttraining's binary_logloss: 0.0128534\n",
      "[3491]\ttraining's binary_logloss: 0.0128512\n",
      "[3492]\ttraining's binary_logloss: 0.012849\n",
      "[3493]\ttraining's binary_logloss: 0.012847\n",
      "[3494]\ttraining's binary_logloss: 0.0128442\n",
      "[3495]\ttraining's binary_logloss: 0.012842\n",
      "[3496]\ttraining's binary_logloss: 0.0128393\n",
      "[3497]\ttraining's binary_logloss: 0.0128381\n",
      "[3498]\ttraining's binary_logloss: 0.0128367\n",
      "[3499]\ttraining's binary_logloss: 0.0128341\n",
      "[3500]\ttraining's binary_logloss: 0.0128316\n",
      "[3501]\ttraining's binary_logloss: 0.0128292\n",
      "[3502]\ttraining's binary_logloss: 0.0128268\n",
      "[3503]\ttraining's binary_logloss: 0.0128243\n",
      "[3504]\ttraining's binary_logloss: 0.012821\n",
      "[3505]\ttraining's binary_logloss: 0.0128187\n",
      "[3506]\ttraining's binary_logloss: 0.0128176\n",
      "[3507]\ttraining's binary_logloss: 0.0128151\n",
      "[3508]\ttraining's binary_logloss: 0.0128129\n",
      "[3509]\ttraining's binary_logloss: 0.0128105\n",
      "[3510]\ttraining's binary_logloss: 0.0128077\n",
      "[3511]\ttraining's binary_logloss: 0.0128053\n",
      "[3512]\ttraining's binary_logloss: 0.0128039\n",
      "[3513]\ttraining's binary_logloss: 0.0128022\n",
      "[3514]\ttraining's binary_logloss: 0.012801\n",
      "[3515]\ttraining's binary_logloss: 0.0127988\n",
      "[3516]\ttraining's binary_logloss: 0.0127974\n",
      "[3517]\ttraining's binary_logloss: 0.0127962\n",
      "[3518]\ttraining's binary_logloss: 0.0127948\n",
      "[3519]\ttraining's binary_logloss: 0.0127919\n",
      "[3520]\ttraining's binary_logloss: 0.0127893\n",
      "[3521]\ttraining's binary_logloss: 0.012787\n",
      "[3522]\ttraining's binary_logloss: 0.0127849\n",
      "[3523]\ttraining's binary_logloss: 0.0127826\n",
      "[3524]\ttraining's binary_logloss: 0.0127799\n",
      "[3525]\ttraining's binary_logloss: 0.0127771\n",
      "[3526]\ttraining's binary_logloss: 0.012775\n",
      "[3527]\ttraining's binary_logloss: 0.0127728\n",
      "[3528]\ttraining's binary_logloss: 0.0127701\n",
      "[3529]\ttraining's binary_logloss: 0.0127683\n",
      "[3530]\ttraining's binary_logloss: 0.0127658\n",
      "[3531]\ttraining's binary_logloss: 0.0127635\n",
      "[3532]\ttraining's binary_logloss: 0.0127624\n",
      "[3533]\ttraining's binary_logloss: 0.0127609\n",
      "[3534]\ttraining's binary_logloss: 0.0127583\n",
      "[3535]\ttraining's binary_logloss: 0.0127557\n",
      "[3536]\ttraining's binary_logloss: 0.0127535\n",
      "[3537]\ttraining's binary_logloss: 0.0127523\n",
      "[3538]\ttraining's binary_logloss: 0.0127508\n",
      "[3539]\ttraining's binary_logloss: 0.0127486\n",
      "[3540]\ttraining's binary_logloss: 0.0127464\n",
      "[3541]\ttraining's binary_logloss: 0.0127441\n",
      "[3542]\ttraining's binary_logloss: 0.0127427\n",
      "[3543]\ttraining's binary_logloss: 0.0127414\n",
      "[3544]\ttraining's binary_logloss: 0.0127401\n",
      "[3545]\ttraining's binary_logloss: 0.0127388\n",
      "[3546]\ttraining's binary_logloss: 0.0127369\n",
      "[3547]\ttraining's binary_logloss: 0.0127345\n",
      "[3548]\ttraining's binary_logloss: 0.0127328\n",
      "[3549]\ttraining's binary_logloss: 0.0127305\n",
      "[3550]\ttraining's binary_logloss: 0.0127275\n",
      "[3551]\ttraining's binary_logloss: 0.0127252\n",
      "[3552]\ttraining's binary_logloss: 0.0127231\n",
      "[3553]\ttraining's binary_logloss: 0.0127211\n",
      "[3554]\ttraining's binary_logloss: 0.0127188\n",
      "[3555]\ttraining's binary_logloss: 0.0127156\n",
      "[3556]\ttraining's binary_logloss: 0.0127142\n",
      "[3557]\ttraining's binary_logloss: 0.012713\n",
      "[3558]\ttraining's binary_logloss: 0.0127115\n",
      "[3559]\ttraining's binary_logloss: 0.0127096\n",
      "[3560]\ttraining's binary_logloss: 0.0127084\n",
      "[3561]\ttraining's binary_logloss: 0.012707\n",
      "[3562]\ttraining's binary_logloss: 0.0127043\n",
      "[3563]\ttraining's binary_logloss: 0.0127031\n",
      "[3564]\ttraining's binary_logloss: 0.0127016\n",
      "[3565]\ttraining's binary_logloss: 0.0126991\n",
      "[3566]\ttraining's binary_logloss: 0.0126966\n",
      "[3567]\ttraining's binary_logloss: 0.0126945\n",
      "[3568]\ttraining's binary_logloss: 0.0126918\n",
      "[3569]\ttraining's binary_logloss: 0.0126893\n",
      "[3570]\ttraining's binary_logloss: 0.0126868\n",
      "[3571]\ttraining's binary_logloss: 0.0126856\n",
      "[3572]\ttraining's binary_logloss: 0.0126843\n",
      "[3573]\ttraining's binary_logloss: 0.0126824\n",
      "[3574]\ttraining's binary_logloss: 0.0126803\n",
      "[3575]\ttraining's binary_logloss: 0.0126778\n",
      "[3576]\ttraining's binary_logloss: 0.0126751\n",
      "[3577]\ttraining's binary_logloss: 0.0126723\n",
      "[3578]\ttraining's binary_logloss: 0.0126701\n",
      "[3579]\ttraining's binary_logloss: 0.0126689\n",
      "[3580]\ttraining's binary_logloss: 0.0126672\n",
      "[3581]\ttraining's binary_logloss: 0.0126652\n",
      "[3582]\ttraining's binary_logloss: 0.012664\n",
      "[3583]\ttraining's binary_logloss: 0.0126619\n",
      "[3584]\ttraining's binary_logloss: 0.0126592\n",
      "[3585]\ttraining's binary_logloss: 0.0126568\n",
      "[3586]\ttraining's binary_logloss: 0.0126549\n",
      "[3587]\ttraining's binary_logloss: 0.0126523\n",
      "[3588]\ttraining's binary_logloss: 0.0126499\n",
      "[3589]\ttraining's binary_logloss: 0.0126484\n",
      "[3590]\ttraining's binary_logloss: 0.0126461\n",
      "[3591]\ttraining's binary_logloss: 0.0126435\n",
      "[3592]\ttraining's binary_logloss: 0.0126408\n",
      "[3593]\ttraining's binary_logloss: 0.0126395\n",
      "[3594]\ttraining's binary_logloss: 0.0126371\n",
      "[3595]\ttraining's binary_logloss: 0.0126357\n",
      "[3596]\ttraining's binary_logloss: 0.012633\n",
      "[3597]\ttraining's binary_logloss: 0.0126304\n",
      "[3598]\ttraining's binary_logloss: 0.0126292\n",
      "[3599]\ttraining's binary_logloss: 0.0126263\n",
      "[3600]\ttraining's binary_logloss: 0.012624\n",
      "[3601]\ttraining's binary_logloss: 0.0126223\n",
      "[3602]\ttraining's binary_logloss: 0.0126211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3603]\ttraining's binary_logloss: 0.0126195\n",
      "[3604]\ttraining's binary_logloss: 0.0126172\n",
      "[3605]\ttraining's binary_logloss: 0.012616\n",
      "[3606]\ttraining's binary_logloss: 0.0126139\n",
      "[3607]\ttraining's binary_logloss: 0.0126112\n",
      "[3608]\ttraining's binary_logloss: 0.0126091\n",
      "[3609]\ttraining's binary_logloss: 0.012607\n",
      "[3610]\ttraining's binary_logloss: 0.0126057\n",
      "[3611]\ttraining's binary_logloss: 0.0126045\n",
      "[3612]\ttraining's binary_logloss: 0.0126031\n",
      "[3613]\ttraining's binary_logloss: 0.0126007\n",
      "[3614]\ttraining's binary_logloss: 0.0126\n",
      "[3615]\ttraining's binary_logloss: 0.0125983\n",
      "[3616]\ttraining's binary_logloss: 0.0125966\n",
      "[3617]\ttraining's binary_logloss: 0.0125952\n",
      "[3618]\ttraining's binary_logloss: 0.012593\n",
      "[3619]\ttraining's binary_logloss: 0.0125898\n",
      "[3620]\ttraining's binary_logloss: 0.0125871\n",
      "[3621]\ttraining's binary_logloss: 0.0125846\n",
      "[3622]\ttraining's binary_logloss: 0.0125821\n",
      "[3623]\ttraining's binary_logloss: 0.0125795\n",
      "[3624]\ttraining's binary_logloss: 0.0125777\n",
      "[3625]\ttraining's binary_logloss: 0.0125763\n",
      "[3626]\ttraining's binary_logloss: 0.0125741\n",
      "[3627]\ttraining's binary_logloss: 0.0125721\n",
      "[3628]\ttraining's binary_logloss: 0.0125697\n",
      "[3629]\ttraining's binary_logloss: 0.0125677\n",
      "[3630]\ttraining's binary_logloss: 0.0125654\n",
      "[3631]\ttraining's binary_logloss: 0.0125634\n",
      "[3632]\ttraining's binary_logloss: 0.0125606\n",
      "[3633]\ttraining's binary_logloss: 0.0125584\n",
      "[3634]\ttraining's binary_logloss: 0.0125563\n",
      "[3635]\ttraining's binary_logloss: 0.0125543\n",
      "[3636]\ttraining's binary_logloss: 0.0125521\n",
      "[3637]\ttraining's binary_logloss: 0.0125502\n",
      "[3638]\ttraining's binary_logloss: 0.0125481\n",
      "[3639]\ttraining's binary_logloss: 0.0125455\n",
      "[3640]\ttraining's binary_logloss: 0.0125434\n",
      "[3641]\ttraining's binary_logloss: 0.0125422\n",
      "[3642]\ttraining's binary_logloss: 0.0125408\n",
      "[3643]\ttraining's binary_logloss: 0.0125386\n",
      "[3644]\ttraining's binary_logloss: 0.0125375\n",
      "[3645]\ttraining's binary_logloss: 0.0125354\n",
      "[3646]\ttraining's binary_logloss: 0.0125338\n",
      "[3647]\ttraining's binary_logloss: 0.0125324\n",
      "[3648]\ttraining's binary_logloss: 0.0125312\n",
      "[3649]\ttraining's binary_logloss: 0.0125299\n",
      "[3650]\ttraining's binary_logloss: 0.0125287\n",
      "[3651]\ttraining's binary_logloss: 0.0125273\n",
      "[3652]\ttraining's binary_logloss: 0.012525\n",
      "[3653]\ttraining's binary_logloss: 0.0125231\n",
      "[3654]\ttraining's binary_logloss: 0.0125209\n",
      "[3655]\ttraining's binary_logloss: 0.0125202\n",
      "[3656]\ttraining's binary_logloss: 0.0125188\n",
      "[3657]\ttraining's binary_logloss: 0.0125176\n",
      "[3658]\ttraining's binary_logloss: 0.0125162\n",
      "[3659]\ttraining's binary_logloss: 0.0125141\n",
      "[3660]\ttraining's binary_logloss: 0.0125128\n",
      "[3661]\ttraining's binary_logloss: 0.0125109\n",
      "[3662]\ttraining's binary_logloss: 0.0125084\n",
      "[3663]\ttraining's binary_logloss: 0.0125062\n",
      "[3664]\ttraining's binary_logloss: 0.0125035\n",
      "[3665]\ttraining's binary_logloss: 0.012501\n",
      "[3666]\ttraining's binary_logloss: 0.0124995\n",
      "[3667]\ttraining's binary_logloss: 0.0124974\n",
      "[3668]\ttraining's binary_logloss: 0.0124961\n",
      "[3669]\ttraining's binary_logloss: 0.0124948\n",
      "[3670]\ttraining's binary_logloss: 0.0124925\n",
      "[3671]\ttraining's binary_logloss: 0.0124901\n",
      "[3672]\ttraining's binary_logloss: 0.0124886\n",
      "[3673]\ttraining's binary_logloss: 0.0124874\n",
      "[3674]\ttraining's binary_logloss: 0.0124857\n",
      "[3675]\ttraining's binary_logloss: 0.0124845\n",
      "[3676]\ttraining's binary_logloss: 0.012483\n",
      "[3677]\ttraining's binary_logloss: 0.0124809\n",
      "[3678]\ttraining's binary_logloss: 0.0124798\n",
      "[3679]\ttraining's binary_logloss: 0.0124776\n",
      "[3680]\ttraining's binary_logloss: 0.0124763\n",
      "[3681]\ttraining's binary_logloss: 0.0124744\n",
      "[3682]\ttraining's binary_logloss: 0.0124722\n",
      "[3683]\ttraining's binary_logloss: 0.0124698\n",
      "[3684]\ttraining's binary_logloss: 0.0124673\n",
      "[3685]\ttraining's binary_logloss: 0.0124661\n",
      "[3686]\ttraining's binary_logloss: 0.0124647\n",
      "[3687]\ttraining's binary_logloss: 0.0124623\n",
      "[3688]\ttraining's binary_logloss: 0.0124609\n",
      "[3689]\ttraining's binary_logloss: 0.012459\n",
      "[3690]\ttraining's binary_logloss: 0.0124568\n",
      "[3691]\ttraining's binary_logloss: 0.0124544\n",
      "[3692]\ttraining's binary_logloss: 0.0124522\n",
      "[3693]\ttraining's binary_logloss: 0.0124515\n",
      "[3694]\ttraining's binary_logloss: 0.0124492\n",
      "[3695]\ttraining's binary_logloss: 0.0124465\n",
      "[3696]\ttraining's binary_logloss: 0.0124452\n",
      "[3697]\ttraining's binary_logloss: 0.012443\n",
      "[3698]\ttraining's binary_logloss: 0.0124418\n",
      "[3699]\ttraining's binary_logloss: 0.0124405\n",
      "[3700]\ttraining's binary_logloss: 0.0124387\n",
      "[3701]\ttraining's binary_logloss: 0.0124362\n",
      "[3702]\ttraining's binary_logloss: 0.012434\n",
      "[3703]\ttraining's binary_logloss: 0.0124333\n",
      "[3704]\ttraining's binary_logloss: 0.0124316\n",
      "[3705]\ttraining's binary_logloss: 0.0124295\n",
      "[3706]\ttraining's binary_logloss: 0.0124269\n",
      "[3707]\ttraining's binary_logloss: 0.0124246\n",
      "[3708]\ttraining's binary_logloss: 0.0124227\n",
      "[3709]\ttraining's binary_logloss: 0.0124207\n",
      "[3710]\ttraining's binary_logloss: 0.012419\n",
      "[3711]\ttraining's binary_logloss: 0.0124163\n",
      "[3712]\ttraining's binary_logloss: 0.0124143\n",
      "[3713]\ttraining's binary_logloss: 0.0124132\n",
      "[3714]\ttraining's binary_logloss: 0.0124109\n",
      "[3715]\ttraining's binary_logloss: 0.0124087\n",
      "[3716]\ttraining's binary_logloss: 0.0124073\n",
      "[3717]\ttraining's binary_logloss: 0.0124048\n",
      "[3718]\ttraining's binary_logloss: 0.0124029\n",
      "[3719]\ttraining's binary_logloss: 0.0124007\n",
      "[3720]\ttraining's binary_logloss: 0.0123984\n",
      "[3721]\ttraining's binary_logloss: 0.0123966\n",
      "[3722]\ttraining's binary_logloss: 0.012394\n",
      "[3723]\ttraining's binary_logloss: 0.0123928\n",
      "[3724]\ttraining's binary_logloss: 0.0123905\n",
      "[3725]\ttraining's binary_logloss: 0.0123887\n",
      "[3726]\ttraining's binary_logloss: 0.0123869\n",
      "[3727]\ttraining's binary_logloss: 0.0123847\n",
      "[3728]\ttraining's binary_logloss: 0.0123824\n",
      "[3729]\ttraining's binary_logloss: 0.0123802\n",
      "[3730]\ttraining's binary_logloss: 0.012378\n",
      "[3731]\ttraining's binary_logloss: 0.012376\n",
      "[3732]\ttraining's binary_logloss: 0.012374\n",
      "[3733]\ttraining's binary_logloss: 0.0123726\n",
      "[3734]\ttraining's binary_logloss: 0.0123703\n",
      "[3735]\ttraining's binary_logloss: 0.0123674\n",
      "[3736]\ttraining's binary_logloss: 0.0123652\n",
      "[3737]\ttraining's binary_logloss: 0.0123628\n",
      "[3738]\ttraining's binary_logloss: 0.0123607\n",
      "[3739]\ttraining's binary_logloss: 0.0123584\n",
      "[3740]\ttraining's binary_logloss: 0.0123565\n",
      "[3741]\ttraining's binary_logloss: 0.0123537\n",
      "[3742]\ttraining's binary_logloss: 0.0123513\n",
      "[3743]\ttraining's binary_logloss: 0.0123493\n",
      "[3744]\ttraining's binary_logloss: 0.012347\n",
      "[3745]\ttraining's binary_logloss: 0.0123456\n",
      "[3746]\ttraining's binary_logloss: 0.0123431\n",
      "[3747]\ttraining's binary_logloss: 0.0123409\n",
      "[3748]\ttraining's binary_logloss: 0.0123398\n",
      "[3749]\ttraining's binary_logloss: 0.0123374\n",
      "[3750]\ttraining's binary_logloss: 0.012336\n",
      "[3751]\ttraining's binary_logloss: 0.0123348\n",
      "[3752]\ttraining's binary_logloss: 0.0123336\n",
      "[3753]\ttraining's binary_logloss: 0.0123307\n",
      "[3754]\ttraining's binary_logloss: 0.0123286\n",
      "[3755]\ttraining's binary_logloss: 0.0123267\n",
      "[3756]\ttraining's binary_logloss: 0.012326\n",
      "[3757]\ttraining's binary_logloss: 0.0123239\n",
      "[3758]\ttraining's binary_logloss: 0.0123226\n",
      "[3759]\ttraining's binary_logloss: 0.0123205\n",
      "[3760]\ttraining's binary_logloss: 0.0123187\n",
      "[3761]\ttraining's binary_logloss: 0.0123167\n",
      "[3762]\ttraining's binary_logloss: 0.0123149\n",
      "[3763]\ttraining's binary_logloss: 0.0123127\n",
      "[3764]\ttraining's binary_logloss: 0.0123106\n",
      "[3765]\ttraining's binary_logloss: 0.0123079\n",
      "[3766]\ttraining's binary_logloss: 0.0123057\n",
      "[3767]\ttraining's binary_logloss: 0.0123031\n",
      "[3768]\ttraining's binary_logloss: 0.0123005\n",
      "[3769]\ttraining's binary_logloss: 0.0122986\n",
      "[3770]\ttraining's binary_logloss: 0.012295\n",
      "[3771]\ttraining's binary_logloss: 0.0122928\n",
      "[3772]\ttraining's binary_logloss: 0.012291\n",
      "[3773]\ttraining's binary_logloss: 0.0122897\n",
      "[3774]\ttraining's binary_logloss: 0.0122885\n",
      "[3775]\ttraining's binary_logloss: 0.0122871\n",
      "[3776]\ttraining's binary_logloss: 0.0122864\n",
      "[3777]\ttraining's binary_logloss: 0.012285\n",
      "[3778]\ttraining's binary_logloss: 0.0122832\n",
      "[3779]\ttraining's binary_logloss: 0.012282\n",
      "[3780]\ttraining's binary_logloss: 0.0122806\n",
      "[3781]\ttraining's binary_logloss: 0.0122787\n",
      "[3782]\ttraining's binary_logloss: 0.012278\n",
      "[3783]\ttraining's binary_logloss: 0.0122768\n",
      "[3784]\ttraining's binary_logloss: 0.0122753\n",
      "[3785]\ttraining's binary_logloss: 0.0122741\n",
      "[3786]\ttraining's binary_logloss: 0.0122727\n",
      "[3787]\ttraining's binary_logloss: 0.0122705\n",
      "[3788]\ttraining's binary_logloss: 0.0122686\n",
      "[3789]\ttraining's binary_logloss: 0.0122673\n",
      "[3790]\ttraining's binary_logloss: 0.012266\n",
      "[3791]\ttraining's binary_logloss: 0.0122641\n",
      "[3792]\ttraining's binary_logloss: 0.0122626\n",
      "[3793]\ttraining's binary_logloss: 0.0122605\n",
      "[3794]\ttraining's binary_logloss: 0.0122592\n",
      "[3795]\ttraining's binary_logloss: 0.0122564\n",
      "[3796]\ttraining's binary_logloss: 0.0122551\n",
      "[3797]\ttraining's binary_logloss: 0.0122526\n",
      "[3798]\ttraining's binary_logloss: 0.0122505\n",
      "[3799]\ttraining's binary_logloss: 0.0122498\n",
      "[3800]\ttraining's binary_logloss: 0.0122477\n",
      "[3801]\ttraining's binary_logloss: 0.0122464\n",
      "[3802]\ttraining's binary_logloss: 0.0122443\n",
      "[3803]\ttraining's binary_logloss: 0.0122412\n",
      "[3804]\ttraining's binary_logloss: 0.0122405\n",
      "[3805]\ttraining's binary_logloss: 0.0122386\n",
      "[3806]\ttraining's binary_logloss: 0.0122374\n",
      "[3807]\ttraining's binary_logloss: 0.0122359\n",
      "[3808]\ttraining's binary_logloss: 0.0122348\n",
      "[3809]\ttraining's binary_logloss: 0.0122334\n",
      "[3810]\ttraining's binary_logloss: 0.0122321\n",
      "[3811]\ttraining's binary_logloss: 0.0122303\n",
      "[3812]\ttraining's binary_logloss: 0.0122296\n",
      "[3813]\ttraining's binary_logloss: 0.0122283\n",
      "[3814]\ttraining's binary_logloss: 0.0122259\n",
      "[3815]\ttraining's binary_logloss: 0.0122244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3816]\ttraining's binary_logloss: 0.0122223\n",
      "[3817]\ttraining's binary_logloss: 0.0122203\n",
      "[3818]\ttraining's binary_logloss: 0.0122182\n",
      "[3819]\ttraining's binary_logloss: 0.0122165\n",
      "[3820]\ttraining's binary_logloss: 0.0122145\n",
      "[3821]\ttraining's binary_logloss: 0.012212\n",
      "[3822]\ttraining's binary_logloss: 0.0122106\n",
      "[3823]\ttraining's binary_logloss: 0.0122083\n",
      "[3824]\ttraining's binary_logloss: 0.0122077\n",
      "[3825]\ttraining's binary_logloss: 0.0122057\n",
      "[3826]\ttraining's binary_logloss: 0.0122035\n",
      "[3827]\ttraining's binary_logloss: 0.0122021\n",
      "[3828]\ttraining's binary_logloss: 0.0122002\n",
      "[3829]\ttraining's binary_logloss: 0.012199\n",
      "[3830]\ttraining's binary_logloss: 0.0121979\n",
      "[3831]\ttraining's binary_logloss: 0.0121965\n",
      "[3832]\ttraining's binary_logloss: 0.0121955\n",
      "[3833]\ttraining's binary_logloss: 0.0121932\n",
      "[3834]\ttraining's binary_logloss: 0.0121918\n",
      "[3835]\ttraining's binary_logloss: 0.0121906\n",
      "[3836]\ttraining's binary_logloss: 0.0121892\n",
      "[3837]\ttraining's binary_logloss: 0.0121879\n",
      "[3838]\ttraining's binary_logloss: 0.0121858\n",
      "[3839]\ttraining's binary_logloss: 0.0121844\n",
      "[3840]\ttraining's binary_logloss: 0.0121819\n",
      "[3841]\ttraining's binary_logloss: 0.0121802\n",
      "[3842]\ttraining's binary_logloss: 0.0121784\n",
      "[3843]\ttraining's binary_logloss: 0.0121758\n",
      "[3844]\ttraining's binary_logloss: 0.0121739\n",
      "[3845]\ttraining's binary_logloss: 0.0121727\n",
      "[3846]\ttraining's binary_logloss: 0.0121716\n",
      "[3847]\ttraining's binary_logloss: 0.0121691\n",
      "[3848]\ttraining's binary_logloss: 0.012166\n",
      "[3849]\ttraining's binary_logloss: 0.0121635\n",
      "[3850]\ttraining's binary_logloss: 0.0121614\n",
      "[3851]\ttraining's binary_logloss: 0.0121595\n",
      "[3852]\ttraining's binary_logloss: 0.0121579\n",
      "[3853]\ttraining's binary_logloss: 0.012156\n",
      "[3854]\ttraining's binary_logloss: 0.0121543\n",
      "[3855]\ttraining's binary_logloss: 0.0121522\n",
      "[3856]\ttraining's binary_logloss: 0.0121511\n",
      "[3857]\ttraining's binary_logloss: 0.0121492\n",
      "[3858]\ttraining's binary_logloss: 0.0121468\n",
      "[3859]\ttraining's binary_logloss: 0.0121448\n",
      "[3860]\ttraining's binary_logloss: 0.0121429\n",
      "[3861]\ttraining's binary_logloss: 0.0121413\n",
      "[3862]\ttraining's binary_logloss: 0.0121401\n",
      "[3863]\ttraining's binary_logloss: 0.0121383\n",
      "[3864]\ttraining's binary_logloss: 0.0121361\n",
      "[3865]\ttraining's binary_logloss: 0.012133\n",
      "[3866]\ttraining's binary_logloss: 0.0121311\n",
      "[3867]\ttraining's binary_logloss: 0.0121296\n",
      "[3868]\ttraining's binary_logloss: 0.0121284\n",
      "[3869]\ttraining's binary_logloss: 0.0121272\n",
      "[3870]\ttraining's binary_logloss: 0.0121254\n",
      "[3871]\ttraining's binary_logloss: 0.012123\n",
      "[3872]\ttraining's binary_logloss: 0.0121223\n",
      "[3873]\ttraining's binary_logloss: 0.0121208\n",
      "[3874]\ttraining's binary_logloss: 0.0121197\n",
      "[3875]\ttraining's binary_logloss: 0.0121185\n",
      "[3876]\ttraining's binary_logloss: 0.0121167\n",
      "[3877]\ttraining's binary_logloss: 0.0121143\n",
      "[3878]\ttraining's binary_logloss: 0.0121122\n",
      "[3879]\ttraining's binary_logloss: 0.0121111\n",
      "[3880]\ttraining's binary_logloss: 0.0121098\n",
      "[3881]\ttraining's binary_logloss: 0.0121086\n",
      "[3882]\ttraining's binary_logloss: 0.0121075\n",
      "[3883]\ttraining's binary_logloss: 0.0121058\n",
      "[3884]\ttraining's binary_logloss: 0.0121036\n",
      "[3885]\ttraining's binary_logloss: 0.0121024\n",
      "[3886]\ttraining's binary_logloss: 0.0121005\n",
      "[3887]\ttraining's binary_logloss: 0.0120981\n",
      "[3888]\ttraining's binary_logloss: 0.0120963\n",
      "[3889]\ttraining's binary_logloss: 0.0120942\n",
      "[3890]\ttraining's binary_logloss: 0.0120926\n",
      "[3891]\ttraining's binary_logloss: 0.0120905\n",
      "[3892]\ttraining's binary_logloss: 0.0120894\n",
      "[3893]\ttraining's binary_logloss: 0.0120881\n",
      "[3894]\ttraining's binary_logloss: 0.012086\n",
      "[3895]\ttraining's binary_logloss: 0.0120825\n",
      "[3896]\ttraining's binary_logloss: 0.0120808\n",
      "[3897]\ttraining's binary_logloss: 0.0120789\n",
      "[3898]\ttraining's binary_logloss: 0.0120778\n",
      "[3899]\ttraining's binary_logloss: 0.0120765\n",
      "[3900]\ttraining's binary_logloss: 0.0120747\n",
      "[3901]\ttraining's binary_logloss: 0.012074\n",
      "[3902]\ttraining's binary_logloss: 0.0120726\n",
      "[3903]\ttraining's binary_logloss: 0.0120706\n",
      "[3904]\ttraining's binary_logloss: 0.0120677\n",
      "[3905]\ttraining's binary_logloss: 0.0120657\n",
      "[3906]\ttraining's binary_logloss: 0.0120635\n",
      "[3907]\ttraining's binary_logloss: 0.0120628\n",
      "[3908]\ttraining's binary_logloss: 0.0120607\n",
      "[3909]\ttraining's binary_logloss: 0.0120583\n",
      "[3910]\ttraining's binary_logloss: 0.0120562\n",
      "[3911]\ttraining's binary_logloss: 0.0120544\n",
      "[3912]\ttraining's binary_logloss: 0.0120526\n",
      "[3913]\ttraining's binary_logloss: 0.0120502\n",
      "[3914]\ttraining's binary_logloss: 0.0120482\n",
      "[3915]\ttraining's binary_logloss: 0.0120471\n",
      "[3916]\ttraining's binary_logloss: 0.0120457\n",
      "[3917]\ttraining's binary_logloss: 0.0120427\n",
      "[3918]\ttraining's binary_logloss: 0.0120408\n",
      "[3919]\ttraining's binary_logloss: 0.0120385\n",
      "[3920]\ttraining's binary_logloss: 0.0120366\n",
      "[3921]\ttraining's binary_logloss: 0.0120345\n",
      "[3922]\ttraining's binary_logloss: 0.0120331\n",
      "[3923]\ttraining's binary_logloss: 0.0120307\n",
      "[3924]\ttraining's binary_logloss: 0.0120295\n",
      "[3925]\ttraining's binary_logloss: 0.0120285\n",
      "[3926]\ttraining's binary_logloss: 0.012027\n",
      "[3927]\ttraining's binary_logloss: 0.0120263\n",
      "[3928]\ttraining's binary_logloss: 0.012025\n",
      "[3929]\ttraining's binary_logloss: 0.0120243\n",
      "[3930]\ttraining's binary_logloss: 0.0120231\n",
      "[3931]\ttraining's binary_logloss: 0.0120221\n",
      "[3932]\ttraining's binary_logloss: 0.0120207\n",
      "[3933]\ttraining's binary_logloss: 0.0120196\n",
      "[3934]\ttraining's binary_logloss: 0.0120176\n",
      "[3935]\ttraining's binary_logloss: 0.0120164\n",
      "[3936]\ttraining's binary_logloss: 0.0120153\n",
      "[3937]\ttraining's binary_logloss: 0.012014\n",
      "[3938]\ttraining's binary_logloss: 0.012013\n",
      "[3939]\ttraining's binary_logloss: 0.0120118\n",
      "[3940]\ttraining's binary_logloss: 0.0120098\n",
      "[3941]\ttraining's binary_logloss: 0.0120081\n",
      "[3942]\ttraining's binary_logloss: 0.012006\n",
      "[3943]\ttraining's binary_logloss: 0.0120043\n",
      "[3944]\ttraining's binary_logloss: 0.0120023\n",
      "[3945]\ttraining's binary_logloss: 0.0120007\n",
      "[3946]\ttraining's binary_logloss: 0.0119986\n",
      "[3947]\ttraining's binary_logloss: 0.0119963\n",
      "[3948]\ttraining's binary_logloss: 0.0119948\n",
      "[3949]\ttraining's binary_logloss: 0.0119937\n",
      "[3950]\ttraining's binary_logloss: 0.0119925\n",
      "[3951]\ttraining's binary_logloss: 0.0119909\n",
      "[3952]\ttraining's binary_logloss: 0.0119888\n",
      "[3953]\ttraining's binary_logloss: 0.0119869\n",
      "[3954]\ttraining's binary_logloss: 0.0119848\n",
      "[3955]\ttraining's binary_logloss: 0.0119832\n",
      "[3956]\ttraining's binary_logloss: 0.0119812\n",
      "[3957]\ttraining's binary_logloss: 0.01198\n",
      "[3958]\ttraining's binary_logloss: 0.011978\n",
      "[3959]\ttraining's binary_logloss: 0.0119766\n",
      "[3960]\ttraining's binary_logloss: 0.0119754\n",
      "[3961]\ttraining's binary_logloss: 0.0119742\n",
      "[3962]\ttraining's binary_logloss: 0.011972\n",
      "[3963]\ttraining's binary_logloss: 0.0119697\n",
      "[3964]\ttraining's binary_logloss: 0.0119677\n",
      "[3965]\ttraining's binary_logloss: 0.0119649\n",
      "[3966]\ttraining's binary_logloss: 0.0119631\n",
      "[3967]\ttraining's binary_logloss: 0.0119612\n",
      "[3968]\ttraining's binary_logloss: 0.0119596\n",
      "[3969]\ttraining's binary_logloss: 0.0119575\n",
      "[3970]\ttraining's binary_logloss: 0.0119557\n",
      "[3971]\ttraining's binary_logloss: 0.011954\n",
      "[3972]\ttraining's binary_logloss: 0.0119525\n",
      "[3973]\ttraining's binary_logloss: 0.0119505\n",
      "[3974]\ttraining's binary_logloss: 0.0119484\n",
      "[3975]\ttraining's binary_logloss: 0.011947\n",
      "[3976]\ttraining's binary_logloss: 0.0119458\n",
      "[3977]\ttraining's binary_logloss: 0.0119446\n",
      "[3978]\ttraining's binary_logloss: 0.0119426\n",
      "[3979]\ttraining's binary_logloss: 0.0119414\n",
      "[3980]\ttraining's binary_logloss: 0.0119402\n",
      "[3981]\ttraining's binary_logloss: 0.0119384\n",
      "[3982]\ttraining's binary_logloss: 0.0119372\n",
      "[3983]\ttraining's binary_logloss: 0.0119356\n",
      "[3984]\ttraining's binary_logloss: 0.0119343\n",
      "[3985]\ttraining's binary_logloss: 0.0119332\n",
      "[3986]\ttraining's binary_logloss: 0.0119318\n",
      "[3987]\ttraining's binary_logloss: 0.0119307\n",
      "[3988]\ttraining's binary_logloss: 0.0119289\n",
      "[3989]\ttraining's binary_logloss: 0.0119276\n",
      "[3990]\ttraining's binary_logloss: 0.0119253\n",
      "[3991]\ttraining's binary_logloss: 0.0119241\n",
      "[3992]\ttraining's binary_logloss: 0.0119226\n",
      "[3993]\ttraining's binary_logloss: 0.0119212\n",
      "[3994]\ttraining's binary_logloss: 0.0119194\n",
      "[3995]\ttraining's binary_logloss: 0.0119174\n",
      "[3996]\ttraining's binary_logloss: 0.0119164\n",
      "[3997]\ttraining's binary_logloss: 0.0119153\n",
      "[3998]\ttraining's binary_logloss: 0.0119127\n",
      "[3999]\ttraining's binary_logloss: 0.0119114\n",
      "[4000]\ttraining's binary_logloss: 0.0119108\n",
      "[4001]\ttraining's binary_logloss: 0.0119094\n",
      "[4002]\ttraining's binary_logloss: 0.0119071\n",
      "[4003]\ttraining's binary_logloss: 0.011906\n",
      "[4004]\ttraining's binary_logloss: 0.0119047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4005]\ttraining's binary_logloss: 0.0119032\n",
      "[4006]\ttraining's binary_logloss: 0.011901\n",
      "[4007]\ttraining's binary_logloss: 0.0118997\n",
      "[4008]\ttraining's binary_logloss: 0.0118987\n",
      "[4009]\ttraining's binary_logloss: 0.0118975\n",
      "[4010]\ttraining's binary_logloss: 0.0118963\n",
      "[4011]\ttraining's binary_logloss: 0.0118953\n",
      "[4012]\ttraining's binary_logloss: 0.0118942\n",
      "[4013]\ttraining's binary_logloss: 0.0118917\n",
      "[4014]\ttraining's binary_logloss: 0.0118895\n",
      "[4015]\ttraining's binary_logloss: 0.0118877\n",
      "[4016]\ttraining's binary_logloss: 0.011887\n",
      "[4017]\ttraining's binary_logloss: 0.0118846\n",
      "[4018]\ttraining's binary_logloss: 0.0118827\n",
      "[4019]\ttraining's binary_logloss: 0.0118816\n",
      "[4020]\ttraining's binary_logloss: 0.0118797\n",
      "[4021]\ttraining's binary_logloss: 0.0118781\n",
      "[4022]\ttraining's binary_logloss: 0.0118775\n",
      "[4023]\ttraining's binary_logloss: 0.0118753\n",
      "[4024]\ttraining's binary_logloss: 0.0118741\n",
      "[4025]\ttraining's binary_logloss: 0.0118718\n",
      "[4026]\ttraining's binary_logloss: 0.01187\n",
      "[4027]\ttraining's binary_logloss: 0.0118678\n",
      "[4028]\ttraining's binary_logloss: 0.0118668\n",
      "[4029]\ttraining's binary_logloss: 0.0118647\n",
      "[4030]\ttraining's binary_logloss: 0.0118636\n",
      "[4031]\ttraining's binary_logloss: 0.0118613\n",
      "[4032]\ttraining's binary_logloss: 0.0118594\n",
      "[4033]\ttraining's binary_logloss: 0.0118583\n",
      "[4034]\ttraining's binary_logloss: 0.0118571\n",
      "[4035]\ttraining's binary_logloss: 0.0118558\n",
      "[4036]\ttraining's binary_logloss: 0.0118538\n",
      "[4037]\ttraining's binary_logloss: 0.0118526\n",
      "[4038]\ttraining's binary_logloss: 0.0118515\n",
      "[4039]\ttraining's binary_logloss: 0.0118504\n",
      "[4040]\ttraining's binary_logloss: 0.011849\n",
      "[4041]\ttraining's binary_logloss: 0.011847\n",
      "[4042]\ttraining's binary_logloss: 0.0118448\n",
      "[4043]\ttraining's binary_logloss: 0.0118434\n",
      "[4044]\ttraining's binary_logloss: 0.0118419\n",
      "[4045]\ttraining's binary_logloss: 0.0118409\n",
      "[4046]\ttraining's binary_logloss: 0.0118398\n",
      "[4047]\ttraining's binary_logloss: 0.0118387\n",
      "[4048]\ttraining's binary_logloss: 0.0118376\n",
      "[4049]\ttraining's binary_logloss: 0.0118359\n",
      "[4050]\ttraining's binary_logloss: 0.0118344\n",
      "[4051]\ttraining's binary_logloss: 0.0118331\n",
      "[4052]\ttraining's binary_logloss: 0.0118321\n",
      "[4053]\ttraining's binary_logloss: 0.0118308\n",
      "[4054]\ttraining's binary_logloss: 0.0118288\n",
      "[4055]\ttraining's binary_logloss: 0.0118275\n",
      "[4056]\ttraining's binary_logloss: 0.0118257\n",
      "[4057]\ttraining's binary_logloss: 0.0118246\n",
      "[4058]\ttraining's binary_logloss: 0.0118239\n",
      "[4059]\ttraining's binary_logloss: 0.0118227\n",
      "[4060]\ttraining's binary_logloss: 0.0118203\n",
      "[4061]\ttraining's binary_logloss: 0.0118193\n",
      "[4062]\ttraining's binary_logloss: 0.0118179\n",
      "[4063]\ttraining's binary_logloss: 0.0118167\n",
      "[4064]\ttraining's binary_logloss: 0.0118153\n",
      "[4065]\ttraining's binary_logloss: 0.0118142\n",
      "[4066]\ttraining's binary_logloss: 0.011812\n",
      "[4067]\ttraining's binary_logloss: 0.0118106\n",
      "[4068]\ttraining's binary_logloss: 0.0118091\n",
      "[4069]\ttraining's binary_logloss: 0.0118073\n",
      "[4070]\ttraining's binary_logloss: 0.011806\n",
      "[4071]\ttraining's binary_logloss: 0.011804\n",
      "[4072]\ttraining's binary_logloss: 0.0118022\n",
      "[4073]\ttraining's binary_logloss: 0.0117999\n",
      "[4074]\ttraining's binary_logloss: 0.0117978\n",
      "[4075]\ttraining's binary_logloss: 0.0117968\n",
      "[4076]\ttraining's binary_logloss: 0.0117957\n",
      "[4077]\ttraining's binary_logloss: 0.011795\n",
      "[4078]\ttraining's binary_logloss: 0.0117938\n",
      "[4079]\ttraining's binary_logloss: 0.0117932\n",
      "[4080]\ttraining's binary_logloss: 0.011792\n",
      "[4081]\ttraining's binary_logloss: 0.0117899\n",
      "[4082]\ttraining's binary_logloss: 0.0117889\n",
      "[4083]\ttraining's binary_logloss: 0.0117864\n",
      "[4084]\ttraining's binary_logloss: 0.0117852\n",
      "[4085]\ttraining's binary_logloss: 0.011783\n",
      "[4086]\ttraining's binary_logloss: 0.0117809\n",
      "[4087]\ttraining's binary_logloss: 0.011779\n",
      "[4088]\ttraining's binary_logloss: 0.0117775\n",
      "[4089]\ttraining's binary_logloss: 0.0117762\n",
      "[4090]\ttraining's binary_logloss: 0.0117748\n",
      "[4091]\ttraining's binary_logloss: 0.0117734\n",
      "[4092]\ttraining's binary_logloss: 0.0117724\n",
      "[4093]\ttraining's binary_logloss: 0.0117712\n",
      "[4094]\ttraining's binary_logloss: 0.0117693\n",
      "[4095]\ttraining's binary_logloss: 0.0117672\n",
      "[4096]\ttraining's binary_logloss: 0.0117661\n",
      "[4097]\ttraining's binary_logloss: 0.0117646\n",
      "[4098]\ttraining's binary_logloss: 0.0117637\n",
      "[4099]\ttraining's binary_logloss: 0.0117625\n",
      "[4100]\ttraining's binary_logloss: 0.0117614\n",
      "[4101]\ttraining's binary_logloss: 0.0117597\n",
      "[4102]\ttraining's binary_logloss: 0.0117581\n",
      "[4103]\ttraining's binary_logloss: 0.0117557\n",
      "[4104]\ttraining's binary_logloss: 0.0117547\n",
      "[4105]\ttraining's binary_logloss: 0.0117528\n",
      "[4106]\ttraining's binary_logloss: 0.0117517\n",
      "[4107]\ttraining's binary_logloss: 0.0117494\n",
      "[4108]\ttraining's binary_logloss: 0.0117477\n",
      "[4109]\ttraining's binary_logloss: 0.0117455\n",
      "[4110]\ttraining's binary_logloss: 0.0117436\n",
      "[4111]\ttraining's binary_logloss: 0.0117423\n",
      "[4112]\ttraining's binary_logloss: 0.0117416\n",
      "[4113]\ttraining's binary_logloss: 0.0117405\n",
      "[4114]\ttraining's binary_logloss: 0.0117395\n",
      "[4115]\ttraining's binary_logloss: 0.0117383\n",
      "[4116]\ttraining's binary_logloss: 0.0117372\n",
      "[4117]\ttraining's binary_logloss: 0.0117362\n",
      "[4118]\ttraining's binary_logloss: 0.0117351\n",
      "[4119]\ttraining's binary_logloss: 0.0117345\n",
      "[4120]\ttraining's binary_logloss: 0.0117334\n",
      "[4121]\ttraining's binary_logloss: 0.0117317\n",
      "[4122]\ttraining's binary_logloss: 0.0117296\n",
      "[4123]\ttraining's binary_logloss: 0.0117273\n",
      "[4124]\ttraining's binary_logloss: 0.0117263\n",
      "[4125]\ttraining's binary_logloss: 0.0117249\n",
      "[4126]\ttraining's binary_logloss: 0.011723\n",
      "[4127]\ttraining's binary_logloss: 0.0117212\n",
      "[4128]\ttraining's binary_logloss: 0.0117194\n",
      "[4129]\ttraining's binary_logloss: 0.0117178\n",
      "[4130]\ttraining's binary_logloss: 0.0117172\n",
      "[4131]\ttraining's binary_logloss: 0.0117161\n",
      "[4132]\ttraining's binary_logloss: 0.011714\n",
      "[4133]\ttraining's binary_logloss: 0.0117121\n",
      "[4134]\ttraining's binary_logloss: 0.0117097\n",
      "[4135]\ttraining's binary_logloss: 0.0117086\n",
      "[4136]\ttraining's binary_logloss: 0.0117076\n",
      "[4137]\ttraining's binary_logloss: 0.0117066\n",
      "[4138]\ttraining's binary_logloss: 0.0117055\n",
      "[4139]\ttraining's binary_logloss: 0.0117034\n",
      "[4140]\ttraining's binary_logloss: 0.011701\n",
      "[4141]\ttraining's binary_logloss: 0.0116991\n",
      "[4142]\ttraining's binary_logloss: 0.0116985\n",
      "[4143]\ttraining's binary_logloss: 0.0116966\n",
      "[4144]\ttraining's binary_logloss: 0.0116948\n",
      "[4145]\ttraining's binary_logloss: 0.0116933\n",
      "[4146]\ttraining's binary_logloss: 0.0116912\n",
      "[4147]\ttraining's binary_logloss: 0.0116894\n",
      "[4148]\ttraining's binary_logloss: 0.0116888\n",
      "[4149]\ttraining's binary_logloss: 0.0116871\n",
      "[4150]\ttraining's binary_logloss: 0.0116851\n",
      "[4151]\ttraining's binary_logloss: 0.0116834\n",
      "[4152]\ttraining's binary_logloss: 0.0116823\n",
      "[4153]\ttraining's binary_logloss: 0.0116801\n",
      "[4154]\ttraining's binary_logloss: 0.0116774\n",
      "[4155]\ttraining's binary_logloss: 0.0116752\n",
      "[4156]\ttraining's binary_logloss: 0.0116734\n",
      "[4157]\ttraining's binary_logloss: 0.0116716\n",
      "[4158]\ttraining's binary_logloss: 0.0116703\n",
      "[4159]\ttraining's binary_logloss: 0.0116686\n",
      "[4160]\ttraining's binary_logloss: 0.0116676\n",
      "[4161]\ttraining's binary_logloss: 0.0116655\n",
      "[4162]\ttraining's binary_logloss: 0.0116637\n",
      "[4163]\ttraining's binary_logloss: 0.0116626\n",
      "[4164]\ttraining's binary_logloss: 0.0116603\n",
      "[4165]\ttraining's binary_logloss: 0.0116582\n",
      "[4166]\ttraining's binary_logloss: 0.0116564\n",
      "[4167]\ttraining's binary_logloss: 0.0116553\n",
      "[4168]\ttraining's binary_logloss: 0.0116535\n",
      "[4169]\ttraining's binary_logloss: 0.0116523\n",
      "[4170]\ttraining's binary_logloss: 0.0116514\n",
      "[4171]\ttraining's binary_logloss: 0.0116503\n",
      "[4172]\ttraining's binary_logloss: 0.011648\n",
      "[4173]\ttraining's binary_logloss: 0.0116474\n",
      "[4174]\ttraining's binary_logloss: 0.0116464\n",
      "[4175]\ttraining's binary_logloss: 0.0116446\n",
      "[4176]\ttraining's binary_logloss: 0.0116433\n",
      "[4177]\ttraining's binary_logloss: 0.011641\n",
      "[4178]\ttraining's binary_logloss: 0.01164\n",
      "[4179]\ttraining's binary_logloss: 0.0116387\n",
      "[4180]\ttraining's binary_logloss: 0.0116376\n",
      "[4181]\ttraining's binary_logloss: 0.0116367\n",
      "[4182]\ttraining's binary_logloss: 0.0116356\n",
      "[4183]\ttraining's binary_logloss: 0.0116344\n",
      "[4184]\ttraining's binary_logloss: 0.011633\n",
      "[4185]\ttraining's binary_logloss: 0.011631\n",
      "[4186]\ttraining's binary_logloss: 0.0116293\n",
      "[4187]\ttraining's binary_logloss: 0.0116283\n",
      "[4188]\ttraining's binary_logloss: 0.0116271\n",
      "[4189]\ttraining's binary_logloss: 0.0116256\n",
      "[4190]\ttraining's binary_logloss: 0.0116245\n",
      "[4191]\ttraining's binary_logloss: 0.0116223\n",
      "[4192]\ttraining's binary_logloss: 0.0116204\n",
      "[4193]\ttraining's binary_logloss: 0.0116192\n",
      "[4194]\ttraining's binary_logloss: 0.0116172\n",
      "[4195]\ttraining's binary_logloss: 0.011615\n",
      "[4196]\ttraining's binary_logloss: 0.0116136\n",
      "[4197]\ttraining's binary_logloss: 0.0116125\n",
      "[4198]\ttraining's binary_logloss: 0.0116106\n",
      "[4199]\ttraining's binary_logloss: 0.0116095\n",
      "[4200]\ttraining's binary_logloss: 0.011608\n",
      "[4201]\ttraining's binary_logloss: 0.0116063\n",
      "[4202]\ttraining's binary_logloss: 0.0116039\n",
      "[4203]\ttraining's binary_logloss: 0.0116028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4204]\ttraining's binary_logloss: 0.011601\n",
      "[4205]\ttraining's binary_logloss: 0.0116\n",
      "[4206]\ttraining's binary_logloss: 0.011599\n",
      "[4207]\ttraining's binary_logloss: 0.011598\n",
      "[4208]\ttraining's binary_logloss: 0.0115971\n",
      "[4209]\ttraining's binary_logloss: 0.0115952\n",
      "[4210]\ttraining's binary_logloss: 0.011593\n",
      "[4211]\ttraining's binary_logloss: 0.0115916\n",
      "[4212]\ttraining's binary_logloss: 0.0115905\n",
      "[4213]\ttraining's binary_logloss: 0.011589\n",
      "[4214]\ttraining's binary_logloss: 0.0115871\n",
      "[4215]\ttraining's binary_logloss: 0.011585\n",
      "[4216]\ttraining's binary_logloss: 0.0115833\n",
      "[4217]\ttraining's binary_logloss: 0.0115815\n",
      "[4218]\ttraining's binary_logloss: 0.0115804\n",
      "[4219]\ttraining's binary_logloss: 0.0115789\n",
      "[4220]\ttraining's binary_logloss: 0.0115779\n",
      "[4221]\ttraining's binary_logloss: 0.0115756\n",
      "[4222]\ttraining's binary_logloss: 0.0115741\n",
      "[4223]\ttraining's binary_logloss: 0.0115722\n",
      "[4224]\ttraining's binary_logloss: 0.01157\n",
      "[4225]\ttraining's binary_logloss: 0.011568\n",
      "[4226]\ttraining's binary_logloss: 0.0115674\n",
      "[4227]\ttraining's binary_logloss: 0.0115657\n",
      "[4228]\ttraining's binary_logloss: 0.0115636\n",
      "[4229]\ttraining's binary_logloss: 0.0115614\n",
      "[4230]\ttraining's binary_logloss: 0.0115593\n",
      "[4231]\ttraining's binary_logloss: 0.011558\n",
      "[4232]\ttraining's binary_logloss: 0.0115567\n",
      "[4233]\ttraining's binary_logloss: 0.0115548\n",
      "[4234]\ttraining's binary_logloss: 0.0115529\n",
      "[4235]\ttraining's binary_logloss: 0.0115513\n",
      "[4236]\ttraining's binary_logloss: 0.0115507\n",
      "[4237]\ttraining's binary_logloss: 0.0115496\n",
      "[4238]\ttraining's binary_logloss: 0.011549\n",
      "[4239]\ttraining's binary_logloss: 0.0115471\n",
      "[4240]\ttraining's binary_logloss: 0.0115455\n",
      "[4241]\ttraining's binary_logloss: 0.0115431\n",
      "[4242]\ttraining's binary_logloss: 0.0115415\n",
      "[4243]\ttraining's binary_logloss: 0.0115395\n",
      "[4244]\ttraining's binary_logloss: 0.0115378\n",
      "[4245]\ttraining's binary_logloss: 0.0115366\n",
      "[4246]\ttraining's binary_logloss: 0.0115356\n",
      "[4247]\ttraining's binary_logloss: 0.0115343\n",
      "[4248]\ttraining's binary_logloss: 0.011533\n",
      "[4249]\ttraining's binary_logloss: 0.0115321\n",
      "[4250]\ttraining's binary_logloss: 0.011531\n",
      "[4251]\ttraining's binary_logloss: 0.0115287\n",
      "[4252]\ttraining's binary_logloss: 0.0115275\n",
      "[4253]\ttraining's binary_logloss: 0.0115265\n",
      "[4254]\ttraining's binary_logloss: 0.0115259\n",
      "[4255]\ttraining's binary_logloss: 0.0115253\n",
      "[4256]\ttraining's binary_logloss: 0.0115238\n",
      "[4257]\ttraining's binary_logloss: 0.0115223\n",
      "[4258]\ttraining's binary_logloss: 0.0115196\n",
      "[4259]\ttraining's binary_logloss: 0.0115183\n",
      "[4260]\ttraining's binary_logloss: 0.0115173\n",
      "[4261]\ttraining's binary_logloss: 0.0115164\n",
      "[4262]\ttraining's binary_logloss: 0.0115153\n",
      "[4263]\ttraining's binary_logloss: 0.0115142\n",
      "[4264]\ttraining's binary_logloss: 0.0115124\n",
      "[4265]\ttraining's binary_logloss: 0.0115112\n",
      "[4266]\ttraining's binary_logloss: 0.0115094\n",
      "[4267]\ttraining's binary_logloss: 0.0115083\n",
      "[4268]\ttraining's binary_logloss: 0.0115072\n",
      "[4269]\ttraining's binary_logloss: 0.0115054\n",
      "[4270]\ttraining's binary_logloss: 0.0115038\n",
      "[4271]\ttraining's binary_logloss: 0.0115021\n",
      "[4272]\ttraining's binary_logloss: 0.0115005\n",
      "[4273]\ttraining's binary_logloss: 0.0114993\n",
      "[4274]\ttraining's binary_logloss: 0.011498\n",
      "[4275]\ttraining's binary_logloss: 0.0114974\n",
      "[4276]\ttraining's binary_logloss: 0.0114962\n",
      "[4277]\ttraining's binary_logloss: 0.0114956\n",
      "[4278]\ttraining's binary_logloss: 0.0114946\n",
      "[4279]\ttraining's binary_logloss: 0.0114926\n",
      "[4280]\ttraining's binary_logloss: 0.0114908\n",
      "[4281]\ttraining's binary_logloss: 0.0114893\n",
      "[4282]\ttraining's binary_logloss: 0.0114874\n",
      "[4283]\ttraining's binary_logloss: 0.011486\n",
      "[4284]\ttraining's binary_logloss: 0.0114841\n",
      "[4285]\ttraining's binary_logloss: 0.0114825\n",
      "[4286]\ttraining's binary_logloss: 0.0114819\n",
      "[4287]\ttraining's binary_logloss: 0.0114805\n",
      "[4288]\ttraining's binary_logloss: 0.0114788\n",
      "[4289]\ttraining's binary_logloss: 0.0114771\n",
      "[4290]\ttraining's binary_logloss: 0.0114755\n",
      "[4291]\ttraining's binary_logloss: 0.0114743\n",
      "[4292]\ttraining's binary_logloss: 0.0114734\n",
      "[4293]\ttraining's binary_logloss: 0.0114709\n",
      "[4294]\ttraining's binary_logloss: 0.0114699\n",
      "[4295]\ttraining's binary_logloss: 0.011469\n",
      "[4296]\ttraining's binary_logloss: 0.011468\n",
      "[4297]\ttraining's binary_logloss: 0.0114674\n",
      "[4298]\ttraining's binary_logloss: 0.0114663\n",
      "[4299]\ttraining's binary_logloss: 0.0114646\n",
      "[4300]\ttraining's binary_logloss: 0.0114634\n",
      "[4301]\ttraining's binary_logloss: 0.0114619\n",
      "[4302]\ttraining's binary_logloss: 0.0114602\n",
      "[4303]\ttraining's binary_logloss: 0.011459\n",
      "[4304]\ttraining's binary_logloss: 0.0114577\n",
      "[4305]\ttraining's binary_logloss: 0.0114554\n",
      "[4306]\ttraining's binary_logloss: 0.011454\n",
      "[4307]\ttraining's binary_logloss: 0.0114526\n",
      "[4308]\ttraining's binary_logloss: 0.0114508\n",
      "[4309]\ttraining's binary_logloss: 0.0114485\n",
      "[4310]\ttraining's binary_logloss: 0.0114475\n",
      "[4311]\ttraining's binary_logloss: 0.0114463\n",
      "[4312]\ttraining's binary_logloss: 0.0114449\n",
      "[4313]\ttraining's binary_logloss: 0.0114441\n",
      "[4314]\ttraining's binary_logloss: 0.011443\n",
      "[4315]\ttraining's binary_logloss: 0.011442\n",
      "[4316]\ttraining's binary_logloss: 0.0114411\n",
      "[4317]\ttraining's binary_logloss: 0.01144\n",
      "[4318]\ttraining's binary_logloss: 0.0114389\n",
      "[4319]\ttraining's binary_logloss: 0.0114376\n",
      "[4320]\ttraining's binary_logloss: 0.0114359\n",
      "[4321]\ttraining's binary_logloss: 0.0114337\n",
      "[4322]\ttraining's binary_logloss: 0.0114315\n",
      "[4323]\ttraining's binary_logloss: 0.0114296\n",
      "[4324]\ttraining's binary_logloss: 0.0114275\n",
      "[4325]\ttraining's binary_logloss: 0.0114257\n",
      "[4326]\ttraining's binary_logloss: 0.0114244\n",
      "[4327]\ttraining's binary_logloss: 0.0114228\n",
      "[4328]\ttraining's binary_logloss: 0.0114217\n",
      "[4329]\ttraining's binary_logloss: 0.0114191\n",
      "[4330]\ttraining's binary_logloss: 0.0114175\n",
      "[4331]\ttraining's binary_logloss: 0.0114155\n",
      "[4332]\ttraining's binary_logloss: 0.0114145\n",
      "[4333]\ttraining's binary_logloss: 0.0114123\n",
      "[4334]\ttraining's binary_logloss: 0.0114111\n",
      "[4335]\ttraining's binary_logloss: 0.01141\n",
      "[4336]\ttraining's binary_logloss: 0.011409\n",
      "[4337]\ttraining's binary_logloss: 0.0114084\n",
      "[4338]\ttraining's binary_logloss: 0.0114067\n",
      "[4339]\ttraining's binary_logloss: 0.0114051\n",
      "[4340]\ttraining's binary_logloss: 0.011404\n",
      "[4341]\ttraining's binary_logloss: 0.011403\n",
      "[4342]\ttraining's binary_logloss: 0.0114011\n",
      "[4343]\ttraining's binary_logloss: 0.0113987\n",
      "[4344]\ttraining's binary_logloss: 0.0113966\n",
      "[4345]\ttraining's binary_logloss: 0.0113951\n",
      "[4346]\ttraining's binary_logloss: 0.0113933\n",
      "[4347]\ttraining's binary_logloss: 0.011392\n",
      "[4348]\ttraining's binary_logloss: 0.011391\n",
      "[4349]\ttraining's binary_logloss: 0.0113901\n",
      "[4350]\ttraining's binary_logloss: 0.0113891\n",
      "[4351]\ttraining's binary_logloss: 0.0113882\n",
      "[4352]\ttraining's binary_logloss: 0.0113872\n",
      "[4353]\ttraining's binary_logloss: 0.0113863\n",
      "[4354]\ttraining's binary_logloss: 0.0113854\n",
      "[4355]\ttraining's binary_logloss: 0.0113841\n",
      "[4356]\ttraining's binary_logloss: 0.0113827\n",
      "[4357]\ttraining's binary_logloss: 0.0113817\n",
      "[4358]\ttraining's binary_logloss: 0.0113807\n",
      "[4359]\ttraining's binary_logloss: 0.0113801\n",
      "[4360]\ttraining's binary_logloss: 0.0113779\n",
      "[4361]\ttraining's binary_logloss: 0.0113761\n",
      "[4362]\ttraining's binary_logloss: 0.0113742\n",
      "[4363]\ttraining's binary_logloss: 0.0113723\n",
      "[4364]\ttraining's binary_logloss: 0.0113701\n",
      "[4365]\ttraining's binary_logloss: 0.011368\n",
      "[4366]\ttraining's binary_logloss: 0.0113666\n",
      "[4367]\ttraining's binary_logloss: 0.0113649\n",
      "[4368]\ttraining's binary_logloss: 0.011363\n",
      "[4369]\ttraining's binary_logloss: 0.0113611\n",
      "[4370]\ttraining's binary_logloss: 0.0113594\n",
      "[4371]\ttraining's binary_logloss: 0.0113576\n",
      "[4372]\ttraining's binary_logloss: 0.0113564\n",
      "[4373]\ttraining's binary_logloss: 0.0113544\n",
      "[4374]\ttraining's binary_logloss: 0.011352\n",
      "[4375]\ttraining's binary_logloss: 0.0113504\n",
      "[4376]\ttraining's binary_logloss: 0.0113482\n",
      "[4377]\ttraining's binary_logloss: 0.0113467\n",
      "[4378]\ttraining's binary_logloss: 0.0113447\n",
      "[4379]\ttraining's binary_logloss: 0.011343\n",
      "[4380]\ttraining's binary_logloss: 0.0113419\n",
      "[4381]\ttraining's binary_logloss: 0.0113408\n",
      "[4382]\ttraining's binary_logloss: 0.0113392\n",
      "[4383]\ttraining's binary_logloss: 0.0113376\n",
      "[4384]\ttraining's binary_logloss: 0.0113365\n",
      "[4385]\ttraining's binary_logloss: 0.0113347\n",
      "[4386]\ttraining's binary_logloss: 0.0113325\n",
      "[4387]\ttraining's binary_logloss: 0.0113316\n",
      "[4388]\ttraining's binary_logloss: 0.0113303\n",
      "[4389]\ttraining's binary_logloss: 0.0113282\n",
      "[4390]\ttraining's binary_logloss: 0.0113272\n",
      "[4391]\ttraining's binary_logloss: 0.0113266\n",
      "[4392]\ttraining's binary_logloss: 0.0113256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4393]\ttraining's binary_logloss: 0.011325\n",
      "[4394]\ttraining's binary_logloss: 0.0113238\n",
      "[4395]\ttraining's binary_logloss: 0.0113221\n",
      "[4396]\ttraining's binary_logloss: 0.0113209\n",
      "[4397]\ttraining's binary_logloss: 0.0113196\n",
      "[4398]\ttraining's binary_logloss: 0.0113179\n",
      "[4399]\ttraining's binary_logloss: 0.0113165\n",
      "[4400]\ttraining's binary_logloss: 0.0113155\n",
      "[4401]\ttraining's binary_logloss: 0.0113145\n",
      "[4402]\ttraining's binary_logloss: 0.0113128\n",
      "[4403]\ttraining's binary_logloss: 0.0113117\n",
      "[4404]\ttraining's binary_logloss: 0.0113106\n",
      "[4405]\ttraining's binary_logloss: 0.0113087\n",
      "[4406]\ttraining's binary_logloss: 0.0113065\n",
      "[4407]\ttraining's binary_logloss: 0.0113052\n",
      "[4408]\ttraining's binary_logloss: 0.0113041\n",
      "[4409]\ttraining's binary_logloss: 0.0113025\n",
      "[4410]\ttraining's binary_logloss: 0.0113015\n",
      "[4411]\ttraining's binary_logloss: 0.0113009\n",
      "[4412]\ttraining's binary_logloss: 0.0112998\n",
      "[4413]\ttraining's binary_logloss: 0.0112982\n",
      "[4414]\ttraining's binary_logloss: 0.0112973\n",
      "[4415]\ttraining's binary_logloss: 0.0112964\n",
      "[4416]\ttraining's binary_logloss: 0.0112954\n",
      "[4417]\ttraining's binary_logloss: 0.0112945\n",
      "[4418]\ttraining's binary_logloss: 0.0112933\n",
      "[4419]\ttraining's binary_logloss: 0.0112922\n",
      "[4420]\ttraining's binary_logloss: 0.0112905\n",
      "[4421]\ttraining's binary_logloss: 0.0112895\n",
      "[4422]\ttraining's binary_logloss: 0.0112876\n",
      "[4423]\ttraining's binary_logloss: 0.0112862\n",
      "[4424]\ttraining's binary_logloss: 0.0112845\n",
      "[4425]\ttraining's binary_logloss: 0.0112834\n",
      "[4426]\ttraining's binary_logloss: 0.0112824\n",
      "[4427]\ttraining's binary_logloss: 0.0112818\n",
      "[4428]\ttraining's binary_logloss: 0.0112804\n",
      "[4429]\ttraining's binary_logloss: 0.0112794\n",
      "[4430]\ttraining's binary_logloss: 0.0112786\n",
      "[4431]\ttraining's binary_logloss: 0.0112776\n",
      "[4432]\ttraining's binary_logloss: 0.011277\n",
      "[4433]\ttraining's binary_logloss: 0.0112761\n",
      "[4434]\ttraining's binary_logloss: 0.0112752\n",
      "[4435]\ttraining's binary_logloss: 0.0112731\n",
      "[4436]\ttraining's binary_logloss: 0.0112719\n",
      "[4437]\ttraining's binary_logloss: 0.0112703\n",
      "[4438]\ttraining's binary_logloss: 0.0112697\n",
      "[4439]\ttraining's binary_logloss: 0.0112687\n",
      "[4440]\ttraining's binary_logloss: 0.0112669\n",
      "[4441]\ttraining's binary_logloss: 0.0112653\n",
      "[4442]\ttraining's binary_logloss: 0.0112635\n",
      "[4443]\ttraining's binary_logloss: 0.0112625\n",
      "[4444]\ttraining's binary_logloss: 0.0112616\n",
      "[4445]\ttraining's binary_logloss: 0.0112595\n",
      "[4446]\ttraining's binary_logloss: 0.011258\n",
      "[4447]\ttraining's binary_logloss: 0.0112568\n",
      "[4448]\ttraining's binary_logloss: 0.0112557\n",
      "[4449]\ttraining's binary_logloss: 0.0112546\n",
      "[4450]\ttraining's binary_logloss: 0.0112529\n",
      "[4451]\ttraining's binary_logloss: 0.0112507\n",
      "[4452]\ttraining's binary_logloss: 0.0112493\n",
      "[4453]\ttraining's binary_logloss: 0.0112481\n",
      "[4454]\ttraining's binary_logloss: 0.0112463\n",
      "[4455]\ttraining's binary_logloss: 0.0112444\n",
      "[4456]\ttraining's binary_logloss: 0.0112433\n",
      "[4457]\ttraining's binary_logloss: 0.0112419\n",
      "[4458]\ttraining's binary_logloss: 0.0112406\n",
      "[4459]\ttraining's binary_logloss: 0.0112393\n",
      "[4460]\ttraining's binary_logloss: 0.0112384\n",
      "[4461]\ttraining's binary_logloss: 0.0112378\n",
      "[4462]\ttraining's binary_logloss: 0.0112363\n",
      "[4463]\ttraining's binary_logloss: 0.011235\n",
      "[4464]\ttraining's binary_logloss: 0.0112335\n",
      "[4465]\ttraining's binary_logloss: 0.0112316\n",
      "[4466]\ttraining's binary_logloss: 0.0112301\n",
      "[4467]\ttraining's binary_logloss: 0.0112288\n",
      "[4468]\ttraining's binary_logloss: 0.0112275\n",
      "[4469]\ttraining's binary_logloss: 0.0112262\n",
      "[4470]\ttraining's binary_logloss: 0.0112245\n",
      "[4471]\ttraining's binary_logloss: 0.0112232\n",
      "[4472]\ttraining's binary_logloss: 0.011222\n",
      "[4473]\ttraining's binary_logloss: 0.011221\n",
      "[4474]\ttraining's binary_logloss: 0.0112199\n",
      "[4475]\ttraining's binary_logloss: 0.0112184\n",
      "[4476]\ttraining's binary_logloss: 0.0112174\n",
      "[4477]\ttraining's binary_logloss: 0.0112158\n",
      "[4478]\ttraining's binary_logloss: 0.0112137\n",
      "[4479]\ttraining's binary_logloss: 0.0112124\n",
      "[4480]\ttraining's binary_logloss: 0.0112113\n",
      "[4481]\ttraining's binary_logloss: 0.0112103\n",
      "[4482]\ttraining's binary_logloss: 0.0112092\n",
      "[4483]\ttraining's binary_logloss: 0.0112082\n",
      "[4484]\ttraining's binary_logloss: 0.0112063\n",
      "[4485]\ttraining's binary_logloss: 0.0112054\n",
      "[4486]\ttraining's binary_logloss: 0.0112049\n",
      "[4487]\ttraining's binary_logloss: 0.0112039\n",
      "[4488]\ttraining's binary_logloss: 0.011203\n",
      "[4489]\ttraining's binary_logloss: 0.0112021\n",
      "[4490]\ttraining's binary_logloss: 0.0112009\n",
      "[4491]\ttraining's binary_logloss: 0.0111999\n",
      "[4492]\ttraining's binary_logloss: 0.0111987\n",
      "[4493]\ttraining's binary_logloss: 0.011197\n",
      "[4494]\ttraining's binary_logloss: 0.0111954\n",
      "[4495]\ttraining's binary_logloss: 0.0111938\n",
      "[4496]\ttraining's binary_logloss: 0.0111917\n",
      "[4497]\ttraining's binary_logloss: 0.0111905\n",
      "[4498]\ttraining's binary_logloss: 0.0111895\n",
      "[4499]\ttraining's binary_logloss: 0.0111883\n",
      "[4500]\ttraining's binary_logloss: 0.011187\n",
      "[4501]\ttraining's binary_logloss: 0.0111857\n",
      "[4502]\ttraining's binary_logloss: 0.011184\n",
      "[4503]\ttraining's binary_logloss: 0.011183\n",
      "[4504]\ttraining's binary_logloss: 0.0111824\n",
      "[4505]\ttraining's binary_logloss: 0.0111815\n",
      "[4506]\ttraining's binary_logloss: 0.0111805\n",
      "[4507]\ttraining's binary_logloss: 0.01118\n",
      "[4508]\ttraining's binary_logloss: 0.0111793\n",
      "[4509]\ttraining's binary_logloss: 0.0111785\n",
      "[4510]\ttraining's binary_logloss: 0.0111775\n",
      "[4511]\ttraining's binary_logloss: 0.0111765\n",
      "[4512]\ttraining's binary_logloss: 0.0111754\n",
      "[4513]\ttraining's binary_logloss: 0.0111746\n",
      "[4514]\ttraining's binary_logloss: 0.0111737\n",
      "[4515]\ttraining's binary_logloss: 0.0111727\n",
      "[4516]\ttraining's binary_logloss: 0.0111716\n",
      "[4517]\ttraining's binary_logloss: 0.01117\n",
      "[4518]\ttraining's binary_logloss: 0.0111691\n",
      "[4519]\ttraining's binary_logloss: 0.0111682\n",
      "[4520]\ttraining's binary_logloss: 0.011167\n",
      "[4521]\ttraining's binary_logloss: 0.0111661\n",
      "[4522]\ttraining's binary_logloss: 0.0111649\n",
      "[4523]\ttraining's binary_logloss: 0.0111641\n",
      "[4524]\ttraining's binary_logloss: 0.011162\n",
      "[4525]\ttraining's binary_logloss: 0.0111601\n",
      "[4526]\ttraining's binary_logloss: 0.0111583\n",
      "[4527]\ttraining's binary_logloss: 0.0111569\n",
      "[4528]\ttraining's binary_logloss: 0.011155\n",
      "[4529]\ttraining's binary_logloss: 0.0111529\n",
      "[4530]\ttraining's binary_logloss: 0.0111512\n",
      "[4531]\ttraining's binary_logloss: 0.0111499\n",
      "[4532]\ttraining's binary_logloss: 0.0111483\n",
      "[4533]\ttraining's binary_logloss: 0.011146\n",
      "[4534]\ttraining's binary_logloss: 0.0111443\n",
      "[4535]\ttraining's binary_logloss: 0.0111434\n",
      "[4536]\ttraining's binary_logloss: 0.0111417\n",
      "[4537]\ttraining's binary_logloss: 0.0111405\n",
      "[4538]\ttraining's binary_logloss: 0.0111388\n",
      "[4539]\ttraining's binary_logloss: 0.0111374\n",
      "[4540]\ttraining's binary_logloss: 0.0111361\n",
      "[4541]\ttraining's binary_logloss: 0.0111356\n",
      "[4542]\ttraining's binary_logloss: 0.0111347\n",
      "[4543]\ttraining's binary_logloss: 0.0111337\n",
      "[4544]\ttraining's binary_logloss: 0.0111324\n",
      "[4545]\ttraining's binary_logloss: 0.011131\n",
      "[4546]\ttraining's binary_logloss: 0.0111297\n",
      "[4547]\ttraining's binary_logloss: 0.0111286\n",
      "[4548]\ttraining's binary_logloss: 0.0111267\n",
      "[4549]\ttraining's binary_logloss: 0.0111261\n",
      "[4550]\ttraining's binary_logloss: 0.0111252\n",
      "[4551]\ttraining's binary_logloss: 0.011123\n",
      "[4552]\ttraining's binary_logloss: 0.0111221\n",
      "[4553]\ttraining's binary_logloss: 0.0111216\n",
      "[4554]\ttraining's binary_logloss: 0.0111205\n",
      "[4555]\ttraining's binary_logloss: 0.0111194\n",
      "[4556]\ttraining's binary_logloss: 0.0111183\n",
      "[4557]\ttraining's binary_logloss: 0.0111174\n",
      "[4558]\ttraining's binary_logloss: 0.0111169\n",
      "[4559]\ttraining's binary_logloss: 0.0111149\n",
      "[4560]\ttraining's binary_logloss: 0.0111139\n",
      "[4561]\ttraining's binary_logloss: 0.011113\n",
      "[4562]\ttraining's binary_logloss: 0.011112\n",
      "[4563]\ttraining's binary_logloss: 0.0111112\n",
      "[4564]\ttraining's binary_logloss: 0.0111094\n",
      "[4565]\ttraining's binary_logloss: 0.0111079\n",
      "[4566]\ttraining's binary_logloss: 0.0111063\n",
      "[4567]\ttraining's binary_logloss: 0.0111051\n",
      "[4568]\ttraining's binary_logloss: 0.0111041\n",
      "[4569]\ttraining's binary_logloss: 0.0111036\n",
      "[4570]\ttraining's binary_logloss: 0.011103\n",
      "[4571]\ttraining's binary_logloss: 0.0111019\n",
      "[4572]\ttraining's binary_logloss: 0.0111004\n",
      "[4573]\ttraining's binary_logloss: 0.0110984\n",
      "[4574]\ttraining's binary_logloss: 0.0110964\n",
      "[4575]\ttraining's binary_logloss: 0.0110953\n",
      "[4576]\ttraining's binary_logloss: 0.0110941\n",
      "[4577]\ttraining's binary_logloss: 0.0110928\n",
      "[4578]\ttraining's binary_logloss: 0.0110916\n",
      "[4579]\ttraining's binary_logloss: 0.0110903\n",
      "[4580]\ttraining's binary_logloss: 0.0110887\n",
      "[4581]\ttraining's binary_logloss: 0.0110868\n",
      "[4582]\ttraining's binary_logloss: 0.011085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4583]\ttraining's binary_logloss: 0.0110831\n",
      "[4584]\ttraining's binary_logloss: 0.0110822\n",
      "[4585]\ttraining's binary_logloss: 0.0110814\n",
      "[4586]\ttraining's binary_logloss: 0.0110797\n",
      "[4587]\ttraining's binary_logloss: 0.0110788\n",
      "[4588]\ttraining's binary_logloss: 0.0110771\n",
      "[4589]\ttraining's binary_logloss: 0.0110752\n",
      "[4590]\ttraining's binary_logloss: 0.0110738\n",
      "[4591]\ttraining's binary_logloss: 0.0110727\n",
      "[4592]\ttraining's binary_logloss: 0.0110719\n",
      "[4593]\ttraining's binary_logloss: 0.011071\n",
      "[4594]\ttraining's binary_logloss: 0.01107\n",
      "[4595]\ttraining's binary_logloss: 0.0110694\n",
      "[4596]\ttraining's binary_logloss: 0.0110685\n",
      "[4597]\ttraining's binary_logloss: 0.0110676\n",
      "[4598]\ttraining's binary_logloss: 0.0110667\n",
      "[4599]\ttraining's binary_logloss: 0.0110658\n",
      "[4600]\ttraining's binary_logloss: 0.0110647\n",
      "[4601]\ttraining's binary_logloss: 0.0110637\n",
      "[4602]\ttraining's binary_logloss: 0.0110617\n",
      "[4603]\ttraining's binary_logloss: 0.0110602\n",
      "[4604]\ttraining's binary_logloss: 0.0110581\n",
      "[4605]\ttraining's binary_logloss: 0.0110572\n",
      "[4606]\ttraining's binary_logloss: 0.0110557\n",
      "[4607]\ttraining's binary_logloss: 0.0110547\n",
      "[4608]\ttraining's binary_logloss: 0.0110539\n",
      "[4609]\ttraining's binary_logloss: 0.0110528\n",
      "[4610]\ttraining's binary_logloss: 0.0110519\n",
      "[4611]\ttraining's binary_logloss: 0.0110506\n",
      "[4612]\ttraining's binary_logloss: 0.0110489\n",
      "[4613]\ttraining's binary_logloss: 0.011047\n",
      "[4614]\ttraining's binary_logloss: 0.0110454\n",
      "[4615]\ttraining's binary_logloss: 0.0110438\n",
      "[4616]\ttraining's binary_logloss: 0.0110419\n",
      "[4617]\ttraining's binary_logloss: 0.0110404\n",
      "[4618]\ttraining's binary_logloss: 0.011039\n",
      "[4619]\ttraining's binary_logloss: 0.0110381\n",
      "[4620]\ttraining's binary_logloss: 0.011036\n",
      "[4621]\ttraining's binary_logloss: 0.0110341\n",
      "[4622]\ttraining's binary_logloss: 0.0110325\n",
      "[4623]\ttraining's binary_logloss: 0.0110315\n",
      "[4624]\ttraining's binary_logloss: 0.0110301\n",
      "[4625]\ttraining's binary_logloss: 0.0110289\n",
      "[4626]\ttraining's binary_logloss: 0.0110268\n",
      "[4627]\ttraining's binary_logloss: 0.0110249\n",
      "[4628]\ttraining's binary_logloss: 0.0110234\n",
      "[4629]\ttraining's binary_logloss: 0.0110222\n",
      "[4630]\ttraining's binary_logloss: 0.0110213\n",
      "[4631]\ttraining's binary_logloss: 0.0110205\n",
      "[4632]\ttraining's binary_logloss: 0.0110191\n",
      "[4633]\ttraining's binary_logloss: 0.0110185\n",
      "[4634]\ttraining's binary_logloss: 0.0110174\n",
      "[4635]\ttraining's binary_logloss: 0.0110168\n",
      "[4636]\ttraining's binary_logloss: 0.0110162\n",
      "[4637]\ttraining's binary_logloss: 0.0110157\n",
      "[4638]\ttraining's binary_logloss: 0.0110146\n",
      "[4639]\ttraining's binary_logloss: 0.011013\n",
      "[4640]\ttraining's binary_logloss: 0.0110112\n",
      "[4641]\ttraining's binary_logloss: 0.0110101\n",
      "[4642]\ttraining's binary_logloss: 0.0110084\n",
      "[4643]\ttraining's binary_logloss: 0.0110076\n",
      "[4644]\ttraining's binary_logloss: 0.0110066\n",
      "[4645]\ttraining's binary_logloss: 0.0110052\n",
      "[4646]\ttraining's binary_logloss: 0.0110043\n",
      "[4647]\ttraining's binary_logloss: 0.0110029\n",
      "[4648]\ttraining's binary_logloss: 0.0110009\n",
      "[4649]\ttraining's binary_logloss: 0.0109995\n",
      "[4650]\ttraining's binary_logloss: 0.0109982\n",
      "[4651]\ttraining's binary_logloss: 0.0109968\n",
      "[4652]\ttraining's binary_logloss: 0.0109958\n",
      "[4653]\ttraining's binary_logloss: 0.010995\n",
      "[4654]\ttraining's binary_logloss: 0.0109941\n",
      "[4655]\ttraining's binary_logloss: 0.0109932\n",
      "[4656]\ttraining's binary_logloss: 0.0109921\n",
      "[4657]\ttraining's binary_logloss: 0.0109916\n",
      "[4658]\ttraining's binary_logloss: 0.01099\n",
      "[4659]\ttraining's binary_logloss: 0.0109891\n",
      "[4660]\ttraining's binary_logloss: 0.0109883\n",
      "[4661]\ttraining's binary_logloss: 0.0109874\n",
      "[4662]\ttraining's binary_logloss: 0.0109864\n",
      "[4663]\ttraining's binary_logloss: 0.0109849\n",
      "[4664]\ttraining's binary_logloss: 0.0109837\n",
      "[4665]\ttraining's binary_logloss: 0.0109818\n",
      "[4666]\ttraining's binary_logloss: 0.0109798\n",
      "[4667]\ttraining's binary_logloss: 0.010978\n",
      "[4668]\ttraining's binary_logloss: 0.0109763\n",
      "[4669]\ttraining's binary_logloss: 0.0109755\n",
      "[4670]\ttraining's binary_logloss: 0.0109746\n",
      "[4671]\ttraining's binary_logloss: 0.0109731\n",
      "[4672]\ttraining's binary_logloss: 0.0109721\n",
      "[4673]\ttraining's binary_logloss: 0.0109716\n",
      "[4674]\ttraining's binary_logloss: 0.0109706\n",
      "[4675]\ttraining's binary_logloss: 0.0109698\n",
      "[4676]\ttraining's binary_logloss: 0.0109689\n",
      "[4677]\ttraining's binary_logloss: 0.0109684\n",
      "[4678]\ttraining's binary_logloss: 0.0109676\n",
      "[4679]\ttraining's binary_logloss: 0.0109663\n",
      "[4680]\ttraining's binary_logloss: 0.0109655\n",
      "[4681]\ttraining's binary_logloss: 0.0109642\n",
      "[4682]\ttraining's binary_logloss: 0.0109631\n",
      "[4683]\ttraining's binary_logloss: 0.0109615\n",
      "[4684]\ttraining's binary_logloss: 0.0109602\n",
      "[4685]\ttraining's binary_logloss: 0.010958\n",
      "[4686]\ttraining's binary_logloss: 0.0109572\n",
      "[4687]\ttraining's binary_logloss: 0.0109564\n",
      "[4688]\ttraining's binary_logloss: 0.0109555\n",
      "[4689]\ttraining's binary_logloss: 0.0109546\n",
      "[4690]\ttraining's binary_logloss: 0.0109529\n",
      "[4691]\ttraining's binary_logloss: 0.0109517\n",
      "[4692]\ttraining's binary_logloss: 0.0109503\n",
      "[4693]\ttraining's binary_logloss: 0.0109489\n",
      "[4694]\ttraining's binary_logloss: 0.0109484\n",
      "[4695]\ttraining's binary_logloss: 0.0109474\n",
      "[4696]\ttraining's binary_logloss: 0.0109457\n",
      "[4697]\ttraining's binary_logloss: 0.0109444\n",
      "[4698]\ttraining's binary_logloss: 0.0109436\n",
      "[4699]\ttraining's binary_logloss: 0.0109425\n",
      "[4700]\ttraining's binary_logloss: 0.0109413\n",
      "[4701]\ttraining's binary_logloss: 0.0109405\n",
      "[4702]\ttraining's binary_logloss: 0.0109397\n",
      "[4703]\ttraining's binary_logloss: 0.0109388\n",
      "[4704]\ttraining's binary_logloss: 0.0109364\n",
      "[4705]\ttraining's binary_logloss: 0.0109343\n",
      "[4706]\ttraining's binary_logloss: 0.0109331\n",
      "[4707]\ttraining's binary_logloss: 0.0109321\n",
      "[4708]\ttraining's binary_logloss: 0.0109301\n",
      "[4709]\ttraining's binary_logloss: 0.0109287\n",
      "[4710]\ttraining's binary_logloss: 0.0109276\n",
      "[4711]\ttraining's binary_logloss: 0.0109258\n",
      "[4712]\ttraining's binary_logloss: 0.0109243\n",
      "[4713]\ttraining's binary_logloss: 0.0109233\n",
      "[4714]\ttraining's binary_logloss: 0.0109219\n",
      "[4715]\ttraining's binary_logloss: 0.0109209\n",
      "[4716]\ttraining's binary_logloss: 0.01092\n",
      "[4717]\ttraining's binary_logloss: 0.010919\n",
      "[4718]\ttraining's binary_logloss: 0.0109179\n",
      "[4719]\ttraining's binary_logloss: 0.0109167\n",
      "[4720]\ttraining's binary_logloss: 0.0109157\n",
      "[4721]\ttraining's binary_logloss: 0.0109136\n",
      "[4722]\ttraining's binary_logloss: 0.0109126\n",
      "[4723]\ttraining's binary_logloss: 0.0109115\n",
      "[4724]\ttraining's binary_logloss: 0.0109107\n",
      "[4725]\ttraining's binary_logloss: 0.0109102\n",
      "[4726]\ttraining's binary_logloss: 0.0109088\n",
      "[4727]\ttraining's binary_logloss: 0.0109074\n",
      "[4728]\ttraining's binary_logloss: 0.0109068\n",
      "[4729]\ttraining's binary_logloss: 0.0109057\n",
      "[4730]\ttraining's binary_logloss: 0.010905\n",
      "[4731]\ttraining's binary_logloss: 0.0109031\n",
      "[4732]\ttraining's binary_logloss: 0.0109023\n",
      "[4733]\ttraining's binary_logloss: 0.0109014\n",
      "[4734]\ttraining's binary_logloss: 0.0108998\n",
      "[4735]\ttraining's binary_logloss: 0.0108986\n",
      "[4736]\ttraining's binary_logloss: 0.0108974\n",
      "[4737]\ttraining's binary_logloss: 0.0108965\n",
      "[4738]\ttraining's binary_logloss: 0.010896\n",
      "[4739]\ttraining's binary_logloss: 0.0108949\n",
      "[4740]\ttraining's binary_logloss: 0.0108944\n",
      "[4741]\ttraining's binary_logloss: 0.0108935\n",
      "[4742]\ttraining's binary_logloss: 0.0108924\n",
      "[4743]\ttraining's binary_logloss: 0.0108914\n",
      "[4744]\ttraining's binary_logloss: 0.0108901\n",
      "[4745]\ttraining's binary_logloss: 0.0108887\n",
      "[4746]\ttraining's binary_logloss: 0.0108879\n",
      "[4747]\ttraining's binary_logloss: 0.0108863\n",
      "[4748]\ttraining's binary_logloss: 0.0108845\n",
      "[4749]\ttraining's binary_logloss: 0.0108839\n",
      "[4750]\ttraining's binary_logloss: 0.0108825\n",
      "[4751]\ttraining's binary_logloss: 0.0108806\n",
      "[4752]\ttraining's binary_logloss: 0.0108796\n",
      "[4753]\ttraining's binary_logloss: 0.0108787\n",
      "[4754]\ttraining's binary_logloss: 0.0108774\n",
      "[4755]\ttraining's binary_logloss: 0.0108768\n",
      "[4756]\ttraining's binary_logloss: 0.010875\n",
      "[4757]\ttraining's binary_logloss: 0.010874\n",
      "[4758]\ttraining's binary_logloss: 0.0108723\n",
      "[4759]\ttraining's binary_logloss: 0.0108709\n",
      "[4760]\ttraining's binary_logloss: 0.0108696\n",
      "[4761]\ttraining's binary_logloss: 0.0108679\n",
      "[4762]\ttraining's binary_logloss: 0.0108668\n",
      "[4763]\ttraining's binary_logloss: 0.0108657\n",
      "[4764]\ttraining's binary_logloss: 0.0108647\n",
      "[4765]\ttraining's binary_logloss: 0.010863\n",
      "[4766]\ttraining's binary_logloss: 0.010861\n",
      "[4767]\ttraining's binary_logloss: 0.0108597\n",
      "[4768]\ttraining's binary_logloss: 0.0108584\n",
      "[4769]\ttraining's binary_logloss: 0.0108568\n",
      "[4770]\ttraining's binary_logloss: 0.0108556\n",
      "[4771]\ttraining's binary_logloss: 0.0108545\n",
      "[4772]\ttraining's binary_logloss: 0.0108538\n",
      "[4773]\ttraining's binary_logloss: 0.010852\n",
      "[4774]\ttraining's binary_logloss: 0.0108505\n",
      "[4775]\ttraining's binary_logloss: 0.010849\n",
      "[4776]\ttraining's binary_logloss: 0.0108484\n",
      "[4777]\ttraining's binary_logloss: 0.0108479\n",
      "[4778]\ttraining's binary_logloss: 0.010847\n",
      "[4779]\ttraining's binary_logloss: 0.0108464\n",
      "[4780]\ttraining's binary_logloss: 0.0108456\n",
      "[4781]\ttraining's binary_logloss: 0.010844\n",
      "[4782]\ttraining's binary_logloss: 0.0108428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4783]\ttraining's binary_logloss: 0.0108418\n",
      "[4784]\ttraining's binary_logloss: 0.0108405\n",
      "[4785]\ttraining's binary_logloss: 0.0108396\n",
      "[4786]\ttraining's binary_logloss: 0.0108391\n",
      "[4787]\ttraining's binary_logloss: 0.0108382\n",
      "[4788]\ttraining's binary_logloss: 0.0108374\n",
      "[4789]\ttraining's binary_logloss: 0.0108364\n",
      "[4790]\ttraining's binary_logloss: 0.0108347\n",
      "[4791]\ttraining's binary_logloss: 0.0108335\n",
      "[4792]\ttraining's binary_logloss: 0.0108323\n",
      "[4793]\ttraining's binary_logloss: 0.0108307\n",
      "[4794]\ttraining's binary_logloss: 0.0108296\n",
      "[4795]\ttraining's binary_logloss: 0.0108284\n",
      "[4796]\ttraining's binary_logloss: 0.0108263\n",
      "[4797]\ttraining's binary_logloss: 0.010825\n",
      "[4798]\ttraining's binary_logloss: 0.010824\n",
      "[4799]\ttraining's binary_logloss: 0.0108225\n",
      "[4800]\ttraining's binary_logloss: 0.0108219\n",
      "[4801]\ttraining's binary_logloss: 0.0108211\n",
      "[4802]\ttraining's binary_logloss: 0.0108206\n",
      "[4803]\ttraining's binary_logloss: 0.0108198\n",
      "[4804]\ttraining's binary_logloss: 0.0108188\n",
      "[4805]\ttraining's binary_logloss: 0.0108173\n",
      "[4806]\ttraining's binary_logloss: 0.0108157\n",
      "[4807]\ttraining's binary_logloss: 0.0108144\n",
      "[4808]\ttraining's binary_logloss: 0.0108136\n",
      "[4809]\ttraining's binary_logloss: 0.0108131\n",
      "[4810]\ttraining's binary_logloss: 0.0108117\n",
      "[4811]\ttraining's binary_logloss: 0.0108099\n",
      "[4812]\ttraining's binary_logloss: 0.0108094\n",
      "[4813]\ttraining's binary_logloss: 0.0108085\n",
      "[4814]\ttraining's binary_logloss: 0.0108072\n",
      "[4815]\ttraining's binary_logloss: 0.0108063\n",
      "[4816]\ttraining's binary_logloss: 0.0108044\n",
      "[4817]\ttraining's binary_logloss: 0.0108028\n",
      "[4818]\ttraining's binary_logloss: 0.0108017\n",
      "[4819]\ttraining's binary_logloss: 0.0108002\n",
      "[4820]\ttraining's binary_logloss: 0.0107989\n",
      "[4821]\ttraining's binary_logloss: 0.0107981\n",
      "[4822]\ttraining's binary_logloss: 0.0107975\n",
      "[4823]\ttraining's binary_logloss: 0.0107956\n",
      "[4824]\ttraining's binary_logloss: 0.0107947\n",
      "[4825]\ttraining's binary_logloss: 0.0107933\n",
      "[4826]\ttraining's binary_logloss: 0.0107914\n",
      "[4827]\ttraining's binary_logloss: 0.0107897\n",
      "[4828]\ttraining's binary_logloss: 0.0107887\n",
      "[4829]\ttraining's binary_logloss: 0.0107882\n",
      "[4830]\ttraining's binary_logloss: 0.0107874\n",
      "[4831]\ttraining's binary_logloss: 0.0107865\n",
      "[4832]\ttraining's binary_logloss: 0.0107852\n",
      "[4833]\ttraining's binary_logloss: 0.0107834\n",
      "[4834]\ttraining's binary_logloss: 0.0107825\n",
      "[4835]\ttraining's binary_logloss: 0.0107816\n",
      "[4836]\ttraining's binary_logloss: 0.0107804\n",
      "[4837]\ttraining's binary_logloss: 0.0107789\n",
      "[4838]\ttraining's binary_logloss: 0.0107773\n",
      "[4839]\ttraining's binary_logloss: 0.0107756\n",
      "[4840]\ttraining's binary_logloss: 0.0107744\n",
      "[4841]\ttraining's binary_logloss: 0.0107732\n",
      "[4842]\ttraining's binary_logloss: 0.0107722\n",
      "[4843]\ttraining's binary_logloss: 0.0107708\n",
      "[4844]\ttraining's binary_logloss: 0.0107695\n",
      "[4845]\ttraining's binary_logloss: 0.0107682\n",
      "[4846]\ttraining's binary_logloss: 0.0107674\n",
      "[4847]\ttraining's binary_logloss: 0.0107668\n",
      "[4848]\ttraining's binary_logloss: 0.0107663\n",
      "[4849]\ttraining's binary_logloss: 0.0107652\n",
      "[4850]\ttraining's binary_logloss: 0.0107639\n",
      "[4851]\ttraining's binary_logloss: 0.0107629\n",
      "[4852]\ttraining's binary_logloss: 0.0107613\n",
      "[4853]\ttraining's binary_logloss: 0.0107602\n",
      "[4854]\ttraining's binary_logloss: 0.0107594\n",
      "[4855]\ttraining's binary_logloss: 0.0107587\n",
      "[4856]\ttraining's binary_logloss: 0.0107578\n",
      "[4857]\ttraining's binary_logloss: 0.0107567\n",
      "[4858]\ttraining's binary_logloss: 0.0107549\n",
      "[4859]\ttraining's binary_logloss: 0.0107541\n",
      "[4860]\ttraining's binary_logloss: 0.0107533\n",
      "[4861]\ttraining's binary_logloss: 0.0107524\n",
      "[4862]\ttraining's binary_logloss: 0.0107509\n",
      "[4863]\ttraining's binary_logloss: 0.0107491\n",
      "[4864]\ttraining's binary_logloss: 0.0107475\n",
      "[4865]\ttraining's binary_logloss: 0.0107463\n",
      "[4866]\ttraining's binary_logloss: 0.0107448\n",
      "[4867]\ttraining's binary_logloss: 0.0107432\n",
      "[4868]\ttraining's binary_logloss: 0.010742\n",
      "[4869]\ttraining's binary_logloss: 0.0107415\n",
      "[4870]\ttraining's binary_logloss: 0.0107397\n",
      "[4871]\ttraining's binary_logloss: 0.0107386\n",
      "[4872]\ttraining's binary_logloss: 0.0107376\n",
      "[4873]\ttraining's binary_logloss: 0.0107364\n",
      "[4874]\ttraining's binary_logloss: 0.0107354\n",
      "[4875]\ttraining's binary_logloss: 0.0107339\n",
      "[4876]\ttraining's binary_logloss: 0.0107324\n",
      "[4877]\ttraining's binary_logloss: 0.0107309\n",
      "[4878]\ttraining's binary_logloss: 0.0107297\n",
      "[4879]\ttraining's binary_logloss: 0.010728\n",
      "[4880]\ttraining's binary_logloss: 0.0107271\n",
      "[4881]\ttraining's binary_logloss: 0.0107258\n",
      "[4882]\ttraining's binary_logloss: 0.010725\n",
      "[4883]\ttraining's binary_logloss: 0.0107245\n",
      "[4884]\ttraining's binary_logloss: 0.0107232\n",
      "[4885]\ttraining's binary_logloss: 0.0107215\n",
      "[4886]\ttraining's binary_logloss: 0.010721\n",
      "[4887]\ttraining's binary_logloss: 0.0107193\n",
      "[4888]\ttraining's binary_logloss: 0.0107182\n",
      "[4889]\ttraining's binary_logloss: 0.0107164\n",
      "[4890]\ttraining's binary_logloss: 0.0107156\n",
      "[4891]\ttraining's binary_logloss: 0.0107141\n",
      "[4892]\ttraining's binary_logloss: 0.010713\n",
      "[4893]\ttraining's binary_logloss: 0.0107116\n",
      "[4894]\ttraining's binary_logloss: 0.0107106\n",
      "[4895]\ttraining's binary_logloss: 0.0107094\n",
      "[4896]\ttraining's binary_logloss: 0.0107083\n",
      "[4897]\ttraining's binary_logloss: 0.0107074\n",
      "[4898]\ttraining's binary_logloss: 0.0107057\n",
      "[4899]\ttraining's binary_logloss: 0.0107046\n",
      "[4900]\ttraining's binary_logloss: 0.0107041\n",
      "[4901]\ttraining's binary_logloss: 0.0107032\n",
      "[4902]\ttraining's binary_logloss: 0.0107022\n",
      "[4903]\ttraining's binary_logloss: 0.0107014\n",
      "[4904]\ttraining's binary_logloss: 0.0107006\n",
      "[4905]\ttraining's binary_logloss: 0.0106995\n",
      "[4906]\ttraining's binary_logloss: 0.0106989\n",
      "[4907]\ttraining's binary_logloss: 0.0106979\n",
      "[4908]\ttraining's binary_logloss: 0.0106965\n",
      "[4909]\ttraining's binary_logloss: 0.0106955\n",
      "[4910]\ttraining's binary_logloss: 0.010695\n",
      "[4911]\ttraining's binary_logloss: 0.0106942\n",
      "[4912]\ttraining's binary_logloss: 0.0106929\n",
      "[4913]\ttraining's binary_logloss: 0.0106924\n",
      "[4914]\ttraining's binary_logloss: 0.0106915\n",
      "[4915]\ttraining's binary_logloss: 0.0106899\n",
      "[4916]\ttraining's binary_logloss: 0.0106886\n",
      "[4917]\ttraining's binary_logloss: 0.0106871\n",
      "[4918]\ttraining's binary_logloss: 0.0106848\n",
      "[4919]\ttraining's binary_logloss: 0.0106833\n",
      "[4920]\ttraining's binary_logloss: 0.0106822\n",
      "[4921]\ttraining's binary_logloss: 0.0106812\n",
      "[4922]\ttraining's binary_logloss: 0.0106802\n",
      "[4923]\ttraining's binary_logloss: 0.0106797\n",
      "[4924]\ttraining's binary_logloss: 0.0106792\n",
      "[4925]\ttraining's binary_logloss: 0.0106784\n",
      "[4926]\ttraining's binary_logloss: 0.0106775\n",
      "[4927]\ttraining's binary_logloss: 0.0106767\n",
      "[4928]\ttraining's binary_logloss: 0.0106756\n",
      "[4929]\ttraining's binary_logloss: 0.0106741\n",
      "[4930]\ttraining's binary_logloss: 0.0106733\n",
      "[4931]\ttraining's binary_logloss: 0.0106715\n",
      "[4932]\ttraining's binary_logloss: 0.0106707\n",
      "[4933]\ttraining's binary_logloss: 0.01067\n",
      "[4934]\ttraining's binary_logloss: 0.0106689\n",
      "[4935]\ttraining's binary_logloss: 0.0106679\n",
      "[4936]\ttraining's binary_logloss: 0.0106665\n",
      "[4937]\ttraining's binary_logloss: 0.0106657\n",
      "[4938]\ttraining's binary_logloss: 0.0106648\n",
      "[4939]\ttraining's binary_logloss: 0.010664\n",
      "[4940]\ttraining's binary_logloss: 0.0106635\n",
      "[4941]\ttraining's binary_logloss: 0.0106622\n",
      "[4942]\ttraining's binary_logloss: 0.0106612\n",
      "[4943]\ttraining's binary_logloss: 0.0106598\n",
      "[4944]\ttraining's binary_logloss: 0.0106581\n",
      "[4945]\ttraining's binary_logloss: 0.0106566\n",
      "[4946]\ttraining's binary_logloss: 0.0106555\n",
      "[4947]\ttraining's binary_logloss: 0.0106541\n",
      "[4948]\ttraining's binary_logloss: 0.0106528\n",
      "[4949]\ttraining's binary_logloss: 0.0106516\n",
      "[4950]\ttraining's binary_logloss: 0.0106506\n",
      "[4951]\ttraining's binary_logloss: 0.0106488\n",
      "[4952]\ttraining's binary_logloss: 0.0106476\n",
      "[4953]\ttraining's binary_logloss: 0.010646\n",
      "[4954]\ttraining's binary_logloss: 0.0106447\n",
      "[4955]\ttraining's binary_logloss: 0.0106432\n",
      "[4956]\ttraining's binary_logloss: 0.0106427\n",
      "[4957]\ttraining's binary_logloss: 0.0106418\n",
      "[4958]\ttraining's binary_logloss: 0.0106411\n",
      "[4959]\ttraining's binary_logloss: 0.0106403\n",
      "[4960]\ttraining's binary_logloss: 0.0106391\n",
      "[4961]\ttraining's binary_logloss: 0.0106377\n",
      "[4962]\ttraining's binary_logloss: 0.0106361\n",
      "[4963]\ttraining's binary_logloss: 0.0106353\n",
      "[4964]\ttraining's binary_logloss: 0.0106348\n",
      "[4965]\ttraining's binary_logloss: 0.0106335\n",
      "[4966]\ttraining's binary_logloss: 0.0106325\n",
      "[4967]\ttraining's binary_logloss: 0.0106309\n",
      "[4968]\ttraining's binary_logloss: 0.01063\n",
      "[4969]\ttraining's binary_logloss: 0.0106281\n",
      "[4970]\ttraining's binary_logloss: 0.0106276\n",
      "[4971]\ttraining's binary_logloss: 0.0106258\n",
      "[4972]\ttraining's binary_logloss: 0.0106248\n",
      "[4973]\ttraining's binary_logloss: 0.0106233\n",
      "[4974]\ttraining's binary_logloss: 0.0106221\n",
      "[4975]\ttraining's binary_logloss: 0.0106204\n",
      "[4976]\ttraining's binary_logloss: 0.0106193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4977]\ttraining's binary_logloss: 0.0106175\n",
      "[4978]\ttraining's binary_logloss: 0.0106167\n",
      "[4979]\ttraining's binary_logloss: 0.0106157\n",
      "[4980]\ttraining's binary_logloss: 0.0106143\n",
      "[4981]\ttraining's binary_logloss: 0.0106128\n",
      "[4982]\ttraining's binary_logloss: 0.0106116\n",
      "[4983]\ttraining's binary_logloss: 0.01061\n",
      "[4984]\ttraining's binary_logloss: 0.0106081\n",
      "[4985]\ttraining's binary_logloss: 0.0106076\n",
      "[4986]\ttraining's binary_logloss: 0.0106063\n",
      "[4987]\ttraining's binary_logloss: 0.0106048\n",
      "[4988]\ttraining's binary_logloss: 0.0106033\n",
      "[4989]\ttraining's binary_logloss: 0.0106023\n",
      "[4990]\ttraining's binary_logloss: 0.0106015\n",
      "[4991]\ttraining's binary_logloss: 0.0106008\n",
      "[4992]\ttraining's binary_logloss: 0.0105998\n",
      "[4993]\ttraining's binary_logloss: 0.0105982\n",
      "[4994]\ttraining's binary_logloss: 0.0105966\n",
      "[4995]\ttraining's binary_logloss: 0.0105955\n",
      "[4996]\ttraining's binary_logloss: 0.0105941\n",
      "[4997]\ttraining's binary_logloss: 0.0105927\n",
      "[4998]\ttraining's binary_logloss: 0.010592\n",
      "[4999]\ttraining's binary_logloss: 0.010591\n",
      "[5000]\ttraining's binary_logloss: 0.01059\n",
      "[5001]\ttraining's binary_logloss: 0.0105887\n",
      "[5002]\ttraining's binary_logloss: 0.0105873\n",
      "[5003]\ttraining's binary_logloss: 0.0105861\n",
      "[5004]\ttraining's binary_logloss: 0.0105856\n",
      "[5005]\ttraining's binary_logloss: 0.0105844\n",
      "[5006]\ttraining's binary_logloss: 0.0105839\n",
      "[5007]\ttraining's binary_logloss: 0.0105828\n",
      "[5008]\ttraining's binary_logloss: 0.0105821\n",
      "[5009]\ttraining's binary_logloss: 0.0105807\n",
      "[5010]\ttraining's binary_logloss: 0.0105791\n",
      "[5011]\ttraining's binary_logloss: 0.010578\n",
      "[5012]\ttraining's binary_logloss: 0.010577\n",
      "[5013]\ttraining's binary_logloss: 0.0105757\n",
      "[5014]\ttraining's binary_logloss: 0.0105743\n",
      "[5015]\ttraining's binary_logloss: 0.0105735\n",
      "[5016]\ttraining's binary_logloss: 0.0105719\n",
      "[5017]\ttraining's binary_logloss: 0.0105706\n",
      "[5018]\ttraining's binary_logloss: 0.0105696\n",
      "[5019]\ttraining's binary_logloss: 0.0105683\n",
      "[5020]\ttraining's binary_logloss: 0.0105669\n",
      "[5021]\ttraining's binary_logloss: 0.0105658\n",
      "[5022]\ttraining's binary_logloss: 0.0105645\n",
      "[5023]\ttraining's binary_logloss: 0.0105641\n",
      "[5024]\ttraining's binary_logloss: 0.0105631\n",
      "[5025]\ttraining's binary_logloss: 0.0105626\n",
      "[5026]\ttraining's binary_logloss: 0.0105618\n",
      "[5027]\ttraining's binary_logloss: 0.0105611\n",
      "[5028]\ttraining's binary_logloss: 0.0105603\n",
      "[5029]\ttraining's binary_logloss: 0.0105592\n",
      "[5030]\ttraining's binary_logloss: 0.0105587\n",
      "[5031]\ttraining's binary_logloss: 0.0105582\n",
      "[5032]\ttraining's binary_logloss: 0.0105575\n",
      "[5033]\ttraining's binary_logloss: 0.0105558\n",
      "[5034]\ttraining's binary_logloss: 0.0105545\n",
      "[5035]\ttraining's binary_logloss: 0.0105533\n",
      "[5036]\ttraining's binary_logloss: 0.0105523\n",
      "[5037]\ttraining's binary_logloss: 0.0105512\n",
      "[5038]\ttraining's binary_logloss: 0.0105498\n",
      "[5039]\ttraining's binary_logloss: 0.0105485\n",
      "[5040]\ttraining's binary_logloss: 0.0105475\n",
      "[5041]\ttraining's binary_logloss: 0.0105464\n",
      "[5042]\ttraining's binary_logloss: 0.0105454\n",
      "[5043]\ttraining's binary_logloss: 0.0105441\n",
      "[5044]\ttraining's binary_logloss: 0.0105429\n",
      "[5045]\ttraining's binary_logloss: 0.0105416\n",
      "[5046]\ttraining's binary_logloss: 0.0105399\n",
      "[5047]\ttraining's binary_logloss: 0.010538\n",
      "[5048]\ttraining's binary_logloss: 0.010537\n",
      "[5049]\ttraining's binary_logloss: 0.0105357\n",
      "[5050]\ttraining's binary_logloss: 0.0105344\n",
      "[5051]\ttraining's binary_logloss: 0.0105332\n",
      "[5052]\ttraining's binary_logloss: 0.0105318\n",
      "[5053]\ttraining's binary_logloss: 0.0105313\n",
      "[5054]\ttraining's binary_logloss: 0.0105306\n",
      "[5055]\ttraining's binary_logloss: 0.0105292\n",
      "[5056]\ttraining's binary_logloss: 0.010528\n",
      "[5057]\ttraining's binary_logloss: 0.0105264\n",
      "[5058]\ttraining's binary_logloss: 0.0105251\n",
      "[5059]\ttraining's binary_logloss: 0.0105236\n",
      "[5060]\ttraining's binary_logloss: 0.0105226\n",
      "[5061]\ttraining's binary_logloss: 0.0105207\n",
      "[5062]\ttraining's binary_logloss: 0.0105193\n",
      "[5063]\ttraining's binary_logloss: 0.0105183\n",
      "[5064]\ttraining's binary_logloss: 0.0105173\n",
      "[5065]\ttraining's binary_logloss: 0.0105161\n",
      "[5066]\ttraining's binary_logloss: 0.0105152\n",
      "[5067]\ttraining's binary_logloss: 0.0105137\n",
      "[5068]\ttraining's binary_logloss: 0.010512\n",
      "[5069]\ttraining's binary_logloss: 0.0105106\n",
      "[5070]\ttraining's binary_logloss: 0.0105094\n",
      "[5071]\ttraining's binary_logloss: 0.0105081\n",
      "[5072]\ttraining's binary_logloss: 0.0105065\n",
      "[5073]\ttraining's binary_logloss: 0.0105054\n",
      "[5074]\ttraining's binary_logloss: 0.0105044\n",
      "[5075]\ttraining's binary_logloss: 0.0105039\n",
      "[5076]\ttraining's binary_logloss: 0.0105031\n",
      "[5077]\ttraining's binary_logloss: 0.010502\n",
      "[5078]\ttraining's binary_logloss: 0.0105011\n",
      "[5079]\ttraining's binary_logloss: 0.0104996\n",
      "[5080]\ttraining's binary_logloss: 0.0104987\n",
      "[5081]\ttraining's binary_logloss: 0.0104976\n",
      "[5082]\ttraining's binary_logloss: 0.0104968\n",
      "[5083]\ttraining's binary_logloss: 0.0104963\n",
      "[5084]\ttraining's binary_logloss: 0.0104958\n",
      "[5085]\ttraining's binary_logloss: 0.0104944\n",
      "[5086]\ttraining's binary_logloss: 0.0104926\n",
      "[5087]\ttraining's binary_logloss: 0.0104921\n",
      "[5088]\ttraining's binary_logloss: 0.0104906\n",
      "[5089]\ttraining's binary_logloss: 0.0104893\n",
      "[5090]\ttraining's binary_logloss: 0.0104877\n",
      "[5091]\ttraining's binary_logloss: 0.0104866\n",
      "[5092]\ttraining's binary_logloss: 0.0104856\n",
      "[5093]\ttraining's binary_logloss: 0.0104846\n",
      "[5094]\ttraining's binary_logloss: 0.0104837\n",
      "[5095]\ttraining's binary_logloss: 0.0104832\n",
      "[5096]\ttraining's binary_logloss: 0.0104824\n",
      "[5097]\ttraining's binary_logloss: 0.0104814\n",
      "[5098]\ttraining's binary_logloss: 0.0104806\n",
      "[5099]\ttraining's binary_logloss: 0.0104798\n",
      "[5100]\ttraining's binary_logloss: 0.0104791\n",
      "[5101]\ttraining's binary_logloss: 0.0104786\n",
      "[5102]\ttraining's binary_logloss: 0.0104771\n",
      "[5103]\ttraining's binary_logloss: 0.0104762\n",
      "[5104]\ttraining's binary_logloss: 0.0104751\n",
      "[5105]\ttraining's binary_logloss: 0.010474\n",
      "[5106]\ttraining's binary_logloss: 0.0104731\n",
      "[5107]\ttraining's binary_logloss: 0.0104724\n",
      "[5108]\ttraining's binary_logloss: 0.0104716\n",
      "[5109]\ttraining's binary_logloss: 0.0104702\n",
      "[5110]\ttraining's binary_logloss: 0.0104687\n",
      "[5111]\ttraining's binary_logloss: 0.0104675\n",
      "[5112]\ttraining's binary_logloss: 0.0104667\n",
      "[5113]\ttraining's binary_logloss: 0.0104662\n",
      "[5114]\ttraining's binary_logloss: 0.0104655\n",
      "[5115]\ttraining's binary_logloss: 0.0104645\n",
      "[5116]\ttraining's binary_logloss: 0.0104636\n",
      "[5117]\ttraining's binary_logloss: 0.0104624\n",
      "[5118]\ttraining's binary_logloss: 0.0104619\n",
      "[5119]\ttraining's binary_logloss: 0.0104614\n",
      "[5120]\ttraining's binary_logloss: 0.0104604\n",
      "[5121]\ttraining's binary_logloss: 0.0104593\n",
      "[5122]\ttraining's binary_logloss: 0.0104581\n",
      "[5123]\ttraining's binary_logloss: 0.0104576\n",
      "[5124]\ttraining's binary_logloss: 0.0104567\n",
      "[5125]\ttraining's binary_logloss: 0.0104563\n",
      "[5126]\ttraining's binary_logloss: 0.0104553\n",
      "[5127]\ttraining's binary_logloss: 0.0104538\n",
      "[5128]\ttraining's binary_logloss: 0.0104526\n",
      "[5129]\ttraining's binary_logloss: 0.0104519\n",
      "[5130]\ttraining's binary_logloss: 0.010451\n",
      "[5131]\ttraining's binary_logloss: 0.0104502\n",
      "[5132]\ttraining's binary_logloss: 0.0104498\n",
      "[5133]\ttraining's binary_logloss: 0.0104488\n",
      "[5134]\ttraining's binary_logloss: 0.0104479\n",
      "[5135]\ttraining's binary_logloss: 0.0104471\n",
      "[5136]\ttraining's binary_logloss: 0.0104459\n",
      "[5137]\ttraining's binary_logloss: 0.0104437\n",
      "[5138]\ttraining's binary_logloss: 0.0104426\n",
      "[5139]\ttraining's binary_logloss: 0.0104409\n",
      "[5140]\ttraining's binary_logloss: 0.0104401\n",
      "[5141]\ttraining's binary_logloss: 0.0104389\n",
      "[5142]\ttraining's binary_logloss: 0.0104376\n",
      "[5143]\ttraining's binary_logloss: 0.0104363\n",
      "[5144]\ttraining's binary_logloss: 0.0104353\n",
      "[5145]\ttraining's binary_logloss: 0.0104345\n",
      "[5146]\ttraining's binary_logloss: 0.0104329\n",
      "[5147]\ttraining's binary_logloss: 0.0104313\n",
      "[5148]\ttraining's binary_logloss: 0.0104301\n",
      "[5149]\ttraining's binary_logloss: 0.0104285\n",
      "[5150]\ttraining's binary_logloss: 0.010428\n",
      "[5151]\ttraining's binary_logloss: 0.0104271\n",
      "[5152]\ttraining's binary_logloss: 0.010426\n",
      "[5153]\ttraining's binary_logloss: 0.0104255\n",
      "[5154]\ttraining's binary_logloss: 0.0104243\n",
      "[5155]\ttraining's binary_logloss: 0.0104231\n",
      "[5156]\ttraining's binary_logloss: 0.0104224\n",
      "[5157]\ttraining's binary_logloss: 0.0104211\n",
      "[5158]\ttraining's binary_logloss: 0.0104203\n",
      "[5159]\ttraining's binary_logloss: 0.0104188\n",
      "[5160]\ttraining's binary_logloss: 0.0104177\n",
      "[5161]\ttraining's binary_logloss: 0.0104167\n",
      "[5162]\ttraining's binary_logloss: 0.010416\n",
      "[5163]\ttraining's binary_logloss: 0.0104147\n",
      "[5164]\ttraining's binary_logloss: 0.0104142\n",
      "[5165]\ttraining's binary_logloss: 0.010413\n",
      "[5166]\ttraining's binary_logloss: 0.0104121\n",
      "[5167]\ttraining's binary_logloss: 0.0104109\n",
      "[5168]\ttraining's binary_logloss: 0.0104098\n",
      "[5169]\ttraining's binary_logloss: 0.0104087\n",
      "[5170]\ttraining's binary_logloss: 0.0104071\n",
      "[5171]\ttraining's binary_logloss: 0.0104059\n",
      "[5172]\ttraining's binary_logloss: 0.0104052\n",
      "[5173]\ttraining's binary_logloss: 0.0104042\n",
      "[5174]\ttraining's binary_logloss: 0.0104033\n",
      "[5175]\ttraining's binary_logloss: 0.0104019\n",
      "[5176]\ttraining's binary_logloss: 0.010401\n",
      "[5177]\ttraining's binary_logloss: 0.0104001\n",
      "[5178]\ttraining's binary_logloss: 0.0103986\n",
      "[5179]\ttraining's binary_logloss: 0.0103978\n",
      "[5180]\ttraining's binary_logloss: 0.0103971\n",
      "[5181]\ttraining's binary_logloss: 0.0103966\n",
      "[5182]\ttraining's binary_logloss: 0.0103961\n",
      "[5183]\ttraining's binary_logloss: 0.0103948\n",
      "[5184]\ttraining's binary_logloss: 0.010394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5185]\ttraining's binary_logloss: 0.0103935\n",
      "[5186]\ttraining's binary_logloss: 0.0103926\n",
      "[5187]\ttraining's binary_logloss: 0.0103916\n",
      "[5188]\ttraining's binary_logloss: 0.0103907\n",
      "[5189]\ttraining's binary_logloss: 0.0103896\n",
      "[5190]\ttraining's binary_logloss: 0.0103886\n",
      "[5191]\ttraining's binary_logloss: 0.0103871\n",
      "[5192]\ttraining's binary_logloss: 0.0103861\n",
      "[5193]\ttraining's binary_logloss: 0.010385\n",
      "[5194]\ttraining's binary_logloss: 0.0103836\n",
      "[5195]\ttraining's binary_logloss: 0.0103824\n",
      "[5196]\ttraining's binary_logloss: 0.0103802\n",
      "[5197]\ttraining's binary_logloss: 0.0103798\n",
      "[5198]\ttraining's binary_logloss: 0.0103788\n",
      "[5199]\ttraining's binary_logloss: 0.0103783\n",
      "[5200]\ttraining's binary_logloss: 0.0103779\n",
      "[5201]\ttraining's binary_logloss: 0.0103772\n",
      "[5202]\ttraining's binary_logloss: 0.0103765\n",
      "[5203]\ttraining's binary_logloss: 0.0103753\n",
      "[5204]\ttraining's binary_logloss: 0.0103742\n",
      "[5205]\ttraining's binary_logloss: 0.0103734\n",
      "[5206]\ttraining's binary_logloss: 0.0103726\n",
      "[5207]\ttraining's binary_logloss: 0.0103718\n",
      "[5208]\ttraining's binary_logloss: 0.0103706\n",
      "[5209]\ttraining's binary_logloss: 0.0103698\n",
      "[5210]\ttraining's binary_logloss: 0.0103684\n",
      "[5211]\ttraining's binary_logloss: 0.010367\n",
      "[5212]\ttraining's binary_logloss: 0.0103659\n",
      "[5213]\ttraining's binary_logloss: 0.0103648\n",
      "[5214]\ttraining's binary_logloss: 0.0103643\n",
      "[5215]\ttraining's binary_logloss: 0.0103636\n",
      "[5216]\ttraining's binary_logloss: 0.0103625\n",
      "[5217]\ttraining's binary_logloss: 0.0103611\n",
      "[5218]\ttraining's binary_logloss: 0.0103595\n",
      "[5219]\ttraining's binary_logloss: 0.0103588\n",
      "[5220]\ttraining's binary_logloss: 0.0103574\n",
      "[5221]\ttraining's binary_logloss: 0.0103564\n",
      "[5222]\ttraining's binary_logloss: 0.0103556\n",
      "[5223]\ttraining's binary_logloss: 0.0103544\n",
      "[5224]\ttraining's binary_logloss: 0.0103535\n",
      "[5225]\ttraining's binary_logloss: 0.0103522\n",
      "[5226]\ttraining's binary_logloss: 0.0103511\n",
      "[5227]\ttraining's binary_logloss: 0.0103499\n",
      "[5228]\ttraining's binary_logloss: 0.0103484\n",
      "[5229]\ttraining's binary_logloss: 0.0103472\n",
      "[5230]\ttraining's binary_logloss: 0.0103468\n",
      "[5231]\ttraining's binary_logloss: 0.0103463\n",
      "[5232]\ttraining's binary_logloss: 0.0103456\n",
      "[5233]\ttraining's binary_logloss: 0.0103448\n",
      "[5234]\ttraining's binary_logloss: 0.0103438\n",
      "[5235]\ttraining's binary_logloss: 0.0103428\n",
      "[5236]\ttraining's binary_logloss: 0.0103421\n",
      "[5237]\ttraining's binary_logloss: 0.0103414\n",
      "[5238]\ttraining's binary_logloss: 0.0103401\n",
      "[5239]\ttraining's binary_logloss: 0.0103394\n",
      "[5240]\ttraining's binary_logloss: 0.0103389\n",
      "[5241]\ttraining's binary_logloss: 0.010338\n",
      "[5242]\ttraining's binary_logloss: 0.0103375\n",
      "[5243]\ttraining's binary_logloss: 0.0103365\n",
      "[5244]\ttraining's binary_logloss: 0.0103351\n",
      "[5245]\ttraining's binary_logloss: 0.0103342\n",
      "[5246]\ttraining's binary_logloss: 0.0103335\n",
      "[5247]\ttraining's binary_logloss: 0.0103328\n",
      "[5248]\ttraining's binary_logloss: 0.0103319\n",
      "[5249]\ttraining's binary_logloss: 0.0103315\n",
      "[5250]\ttraining's binary_logloss: 0.0103299\n",
      "[5251]\ttraining's binary_logloss: 0.0103291\n",
      "[5252]\ttraining's binary_logloss: 0.0103275\n",
      "[5253]\ttraining's binary_logloss: 0.0103264\n",
      "[5254]\ttraining's binary_logloss: 0.0103254\n",
      "[5255]\ttraining's binary_logloss: 0.0103245\n",
      "[5256]\ttraining's binary_logloss: 0.0103238\n",
      "[5257]\ttraining's binary_logloss: 0.0103233\n",
      "[5258]\ttraining's binary_logloss: 0.0103221\n",
      "[5259]\ttraining's binary_logloss: 0.0103211\n",
      "[5260]\ttraining's binary_logloss: 0.0103203\n",
      "[5261]\ttraining's binary_logloss: 0.0103193\n",
      "[5262]\ttraining's binary_logloss: 0.0103186\n",
      "[5263]\ttraining's binary_logloss: 0.0103177\n",
      "[5264]\ttraining's binary_logloss: 0.0103165\n",
      "[5265]\ttraining's binary_logloss: 0.010315\n",
      "[5266]\ttraining's binary_logloss: 0.010314\n",
      "[5267]\ttraining's binary_logloss: 0.0103128\n",
      "[5268]\ttraining's binary_logloss: 0.0103111\n",
      "[5269]\ttraining's binary_logloss: 0.0103106\n",
      "[5270]\ttraining's binary_logloss: 0.0103099\n",
      "[5271]\ttraining's binary_logloss: 0.010309\n",
      "[5272]\ttraining's binary_logloss: 0.0103076\n",
      "[5273]\ttraining's binary_logloss: 0.0103062\n",
      "[5274]\ttraining's binary_logloss: 0.0103055\n",
      "[5275]\ttraining's binary_logloss: 0.0103046\n",
      "[5276]\ttraining's binary_logloss: 0.0103038\n",
      "[5277]\ttraining's binary_logloss: 0.0103034\n",
      "[5278]\ttraining's binary_logloss: 0.0103024\n",
      "[5279]\ttraining's binary_logloss: 0.0103014\n",
      "[5280]\ttraining's binary_logloss: 0.0103002\n",
      "[5281]\ttraining's binary_logloss: 0.0102994\n",
      "[5282]\ttraining's binary_logloss: 0.0102984\n",
      "[5283]\ttraining's binary_logloss: 0.0102969\n",
      "[5284]\ttraining's binary_logloss: 0.0102965\n",
      "[5285]\ttraining's binary_logloss: 0.010295\n",
      "[5286]\ttraining's binary_logloss: 0.0102942\n",
      "[5287]\ttraining's binary_logloss: 0.0102929\n",
      "[5288]\ttraining's binary_logloss: 0.0102915\n",
      "[5289]\ttraining's binary_logloss: 0.0102905\n",
      "[5290]\ttraining's binary_logloss: 0.0102885\n",
      "[5291]\ttraining's binary_logloss: 0.0102867\n",
      "[5292]\ttraining's binary_logloss: 0.0102855\n",
      "[5293]\ttraining's binary_logloss: 0.0102838\n",
      "[5294]\ttraining's binary_logloss: 0.0102821\n",
      "[5295]\ttraining's binary_logloss: 0.0102806\n",
      "[5296]\ttraining's binary_logloss: 0.0102796\n",
      "[5297]\ttraining's binary_logloss: 0.0102779\n",
      "[5298]\ttraining's binary_logloss: 0.0102762\n",
      "[5299]\ttraining's binary_logloss: 0.0102752\n",
      "[5300]\ttraining's binary_logloss: 0.0102735\n",
      "[5301]\ttraining's binary_logloss: 0.0102724\n",
      "[5302]\ttraining's binary_logloss: 0.0102704\n",
      "[5303]\ttraining's binary_logloss: 0.0102694\n",
      "[5304]\ttraining's binary_logloss: 0.0102685\n",
      "[5305]\ttraining's binary_logloss: 0.0102675\n",
      "[5306]\ttraining's binary_logloss: 0.0102667\n",
      "[5307]\ttraining's binary_logloss: 0.0102663\n",
      "[5308]\ttraining's binary_logloss: 0.0102656\n",
      "[5309]\ttraining's binary_logloss: 0.0102652\n",
      "[5310]\ttraining's binary_logloss: 0.010264\n",
      "[5311]\ttraining's binary_logloss: 0.0102627\n",
      "[5312]\ttraining's binary_logloss: 0.0102616\n",
      "[5313]\ttraining's binary_logloss: 0.0102602\n",
      "[5314]\ttraining's binary_logloss: 0.0102589\n",
      "[5315]\ttraining's binary_logloss: 0.0102574\n",
      "[5316]\ttraining's binary_logloss: 0.0102563\n",
      "[5317]\ttraining's binary_logloss: 0.0102559\n",
      "[5318]\ttraining's binary_logloss: 0.0102551\n",
      "[5319]\ttraining's binary_logloss: 0.0102542\n",
      "[5320]\ttraining's binary_logloss: 0.0102535\n",
      "[5321]\ttraining's binary_logloss: 0.0102528\n",
      "[5322]\ttraining's binary_logloss: 0.0102524\n",
      "[5323]\ttraining's binary_logloss: 0.0102517\n",
      "[5324]\ttraining's binary_logloss: 0.0102507\n",
      "[5325]\ttraining's binary_logloss: 0.0102501\n",
      "[5326]\ttraining's binary_logloss: 0.0102493\n",
      "[5327]\ttraining's binary_logloss: 0.0102488\n",
      "[5328]\ttraining's binary_logloss: 0.0102479\n",
      "[5329]\ttraining's binary_logloss: 0.0102468\n",
      "[5330]\ttraining's binary_logloss: 0.0102459\n",
      "[5331]\ttraining's binary_logloss: 0.0102444\n",
      "[5332]\ttraining's binary_logloss: 0.0102439\n",
      "[5333]\ttraining's binary_logloss: 0.0102421\n",
      "[5334]\ttraining's binary_logloss: 0.0102412\n",
      "[5335]\ttraining's binary_logloss: 0.0102403\n",
      "[5336]\ttraining's binary_logloss: 0.0102389\n",
      "[5337]\ttraining's binary_logloss: 0.0102378\n",
      "[5338]\ttraining's binary_logloss: 0.0102373\n",
      "[5339]\ttraining's binary_logloss: 0.0102366\n",
      "[5340]\ttraining's binary_logloss: 0.0102354\n",
      "[5341]\ttraining's binary_logloss: 0.0102345\n",
      "[5342]\ttraining's binary_logloss: 0.0102338\n",
      "[5343]\ttraining's binary_logloss: 0.0102326\n",
      "[5344]\ttraining's binary_logloss: 0.0102316\n",
      "[5345]\ttraining's binary_logloss: 0.0102304\n",
      "[5346]\ttraining's binary_logloss: 0.0102292\n",
      "[5347]\ttraining's binary_logloss: 0.0102288\n",
      "[5348]\ttraining's binary_logloss: 0.0102278\n",
      "[5349]\ttraining's binary_logloss: 0.0102261\n",
      "[5350]\ttraining's binary_logloss: 0.0102255\n",
      "[5351]\ttraining's binary_logloss: 0.010225\n",
      "[5352]\ttraining's binary_logloss: 0.0102238\n",
      "[5353]\ttraining's binary_logloss: 0.0102228\n",
      "[5354]\ttraining's binary_logloss: 0.0102215\n",
      "[5355]\ttraining's binary_logloss: 0.0102211\n",
      "[5356]\ttraining's binary_logloss: 0.0102199\n",
      "[5357]\ttraining's binary_logloss: 0.0102187\n",
      "[5358]\ttraining's binary_logloss: 0.0102176\n",
      "[5359]\ttraining's binary_logloss: 0.0102167\n",
      "[5360]\ttraining's binary_logloss: 0.0102156\n",
      "[5361]\ttraining's binary_logloss: 0.010214\n",
      "[5362]\ttraining's binary_logloss: 0.0102127\n",
      "[5363]\ttraining's binary_logloss: 0.010212\n",
      "[5364]\ttraining's binary_logloss: 0.0102111\n",
      "[5365]\ttraining's binary_logloss: 0.0102096\n",
      "[5366]\ttraining's binary_logloss: 0.0102086\n",
      "[5367]\ttraining's binary_logloss: 0.0102078\n",
      "[5368]\ttraining's binary_logloss: 0.0102062\n",
      "[5369]\ttraining's binary_logloss: 0.0102053\n",
      "[5370]\ttraining's binary_logloss: 0.0102043\n",
      "[5371]\ttraining's binary_logloss: 0.0102036\n",
      "[5372]\ttraining's binary_logloss: 0.0102032\n",
      "[5373]\ttraining's binary_logloss: 0.0102014\n",
      "[5374]\ttraining's binary_logloss: 0.0102004\n",
      "[5375]\ttraining's binary_logloss: 0.010199\n",
      "[5376]\ttraining's binary_logloss: 0.010198\n",
      "[5377]\ttraining's binary_logloss: 0.0101967\n",
      "[5378]\ttraining's binary_logloss: 0.0101948\n",
      "[5379]\ttraining's binary_logloss: 0.0101931\n",
      "[5380]\ttraining's binary_logloss: 0.0101919\n",
      "[5381]\ttraining's binary_logloss: 0.0101909\n",
      "[5382]\ttraining's binary_logloss: 0.0101901\n",
      "[5383]\ttraining's binary_logloss: 0.0101895\n",
      "[5384]\ttraining's binary_logloss: 0.0101886\n",
      "[5385]\ttraining's binary_logloss: 0.0101879\n",
      "[5386]\ttraining's binary_logloss: 0.0101872\n",
      "[5387]\ttraining's binary_logloss: 0.0101856\n",
      "[5388]\ttraining's binary_logloss: 0.0101852\n",
      "[5389]\ttraining's binary_logloss: 0.0101845\n",
      "[5390]\ttraining's binary_logloss: 0.0101836\n",
      "[5391]\ttraining's binary_logloss: 0.0101832\n",
      "[5392]\ttraining's binary_logloss: 0.0101827\n",
      "[5393]\ttraining's binary_logloss: 0.010182\n",
      "[5394]\ttraining's binary_logloss: 0.0101811\n",
      "[5395]\ttraining's binary_logloss: 0.0101802\n",
      "[5396]\ttraining's binary_logloss: 0.0101796\n",
      "[5397]\ttraining's binary_logloss: 0.0101789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5398]\ttraining's binary_logloss: 0.0101773\n",
      "[5399]\ttraining's binary_logloss: 0.0101757\n",
      "[5400]\ttraining's binary_logloss: 0.0101747\n",
      "[5401]\ttraining's binary_logloss: 0.0101739\n",
      "[5402]\ttraining's binary_logloss: 0.0101728\n",
      "[5403]\ttraining's binary_logloss: 0.0101713\n",
      "[5404]\ttraining's binary_logloss: 0.0101704\n",
      "[5405]\ttraining's binary_logloss: 0.0101694\n",
      "[5406]\ttraining's binary_logloss: 0.0101678\n",
      "[5407]\ttraining's binary_logloss: 0.010167\n",
      "[5408]\ttraining's binary_logloss: 0.0101653\n",
      "[5409]\ttraining's binary_logloss: 0.0101645\n",
      "[5410]\ttraining's binary_logloss: 0.0101636\n",
      "[5411]\ttraining's binary_logloss: 0.0101632\n",
      "[5412]\ttraining's binary_logloss: 0.010162\n",
      "[5413]\ttraining's binary_logloss: 0.0101611\n",
      "[5414]\ttraining's binary_logloss: 0.0101601\n",
      "[5415]\ttraining's binary_logloss: 0.0101594\n",
      "[5416]\ttraining's binary_logloss: 0.0101583\n",
      "[5417]\ttraining's binary_logloss: 0.0101571\n",
      "[5418]\ttraining's binary_logloss: 0.0101562\n",
      "[5419]\ttraining's binary_logloss: 0.0101552\n",
      "[5420]\ttraining's binary_logloss: 0.0101547\n",
      "[5421]\ttraining's binary_logloss: 0.0101532\n",
      "[5422]\ttraining's binary_logloss: 0.0101515\n",
      "[5423]\ttraining's binary_logloss: 0.0101505\n",
      "[5424]\ttraining's binary_logloss: 0.0101496\n",
      "[5425]\ttraining's binary_logloss: 0.0101488\n",
      "[5426]\ttraining's binary_logloss: 0.0101481\n",
      "[5427]\ttraining's binary_logloss: 0.0101473\n",
      "[5428]\ttraining's binary_logloss: 0.0101468\n",
      "[5429]\ttraining's binary_logloss: 0.0101461\n",
      "[5430]\ttraining's binary_logloss: 0.0101452\n",
      "[5431]\ttraining's binary_logloss: 0.0101446\n",
      "[5432]\ttraining's binary_logloss: 0.0101441\n",
      "[5433]\ttraining's binary_logloss: 0.0101437\n",
      "[5434]\ttraining's binary_logloss: 0.0101426\n",
      "[5435]\ttraining's binary_logloss: 0.010142\n",
      "[5436]\ttraining's binary_logloss: 0.0101412\n",
      "[5437]\ttraining's binary_logloss: 0.0101402\n",
      "[5438]\ttraining's binary_logloss: 0.010139\n",
      "[5439]\ttraining's binary_logloss: 0.0101379\n",
      "[5440]\ttraining's binary_logloss: 0.0101364\n",
      "[5441]\ttraining's binary_logloss: 0.0101352\n",
      "[5442]\ttraining's binary_logloss: 0.0101344\n",
      "[5443]\ttraining's binary_logloss: 0.0101334\n",
      "[5444]\ttraining's binary_logloss: 0.0101318\n",
      "[5445]\ttraining's binary_logloss: 0.0101305\n",
      "[5446]\ttraining's binary_logloss: 0.0101291\n",
      "[5447]\ttraining's binary_logloss: 0.0101282\n",
      "[5448]\ttraining's binary_logloss: 0.0101268\n",
      "[5449]\ttraining's binary_logloss: 0.0101256\n",
      "[5450]\ttraining's binary_logloss: 0.0101246\n",
      "[5451]\ttraining's binary_logloss: 0.0101231\n",
      "[5452]\ttraining's binary_logloss: 0.0101218\n",
      "[5453]\ttraining's binary_logloss: 0.0101201\n",
      "[5454]\ttraining's binary_logloss: 0.0101187\n",
      "[5455]\ttraining's binary_logloss: 0.0101183\n",
      "[5456]\ttraining's binary_logloss: 0.0101168\n",
      "[5457]\ttraining's binary_logloss: 0.010115\n",
      "[5458]\ttraining's binary_logloss: 0.0101135\n",
      "[5459]\ttraining's binary_logloss: 0.010112\n",
      "[5460]\ttraining's binary_logloss: 0.010111\n",
      "[5461]\ttraining's binary_logloss: 0.0101101\n",
      "[5462]\ttraining's binary_logloss: 0.0101094\n",
      "[5463]\ttraining's binary_logloss: 0.0101085\n",
      "[5464]\ttraining's binary_logloss: 0.0101079\n",
      "[5465]\ttraining's binary_logloss: 0.0101075\n",
      "[5466]\ttraining's binary_logloss: 0.010107\n",
      "[5467]\ttraining's binary_logloss: 0.0101055\n",
      "[5468]\ttraining's binary_logloss: 0.0101045\n",
      "[5469]\ttraining's binary_logloss: 0.0101034\n",
      "[5470]\ttraining's binary_logloss: 0.0101021\n",
      "[5471]\ttraining's binary_logloss: 0.0101011\n",
      "[5472]\ttraining's binary_logloss: 0.0101007\n",
      "[5473]\ttraining's binary_logloss: 0.0100992\n",
      "[5474]\ttraining's binary_logloss: 0.0100977\n",
      "[5475]\ttraining's binary_logloss: 0.0100969\n",
      "[5476]\ttraining's binary_logloss: 0.010096\n",
      "[5477]\ttraining's binary_logloss: 0.0100953\n",
      "[5478]\ttraining's binary_logloss: 0.0100946\n",
      "[5479]\ttraining's binary_logloss: 0.0100932\n",
      "[5480]\ttraining's binary_logloss: 0.0100922\n",
      "[5481]\ttraining's binary_logloss: 0.010091\n",
      "[5482]\ttraining's binary_logloss: 0.0100901\n",
      "[5483]\ttraining's binary_logloss: 0.0100885\n",
      "[5484]\ttraining's binary_logloss: 0.0100876\n",
      "[5485]\ttraining's binary_logloss: 0.0100863\n",
      "[5486]\ttraining's binary_logloss: 0.0100853\n",
      "[5487]\ttraining's binary_logloss: 0.010084\n",
      "[5488]\ttraining's binary_logloss: 0.0100831\n",
      "[5489]\ttraining's binary_logloss: 0.0100824\n",
      "[5490]\ttraining's binary_logloss: 0.0100818\n",
      "[5491]\ttraining's binary_logloss: 0.0100813\n",
      "[5492]\ttraining's binary_logloss: 0.0100804\n",
      "[5493]\ttraining's binary_logloss: 0.0100795\n",
      "[5494]\ttraining's binary_logloss: 0.0100787\n",
      "[5495]\ttraining's binary_logloss: 0.0100775\n",
      "[5496]\ttraining's binary_logloss: 0.0100768\n",
      "[5497]\ttraining's binary_logloss: 0.0100751\n",
      "[5498]\ttraining's binary_logloss: 0.0100742\n",
      "[5499]\ttraining's binary_logloss: 0.0100734\n",
      "[5500]\ttraining's binary_logloss: 0.0100716\n",
      "[5501]\ttraining's binary_logloss: 0.0100707\n",
      "[5502]\ttraining's binary_logloss: 0.0100685\n",
      "[5503]\ttraining's binary_logloss: 0.0100674\n",
      "[5504]\ttraining's binary_logloss: 0.0100665\n",
      "[5505]\ttraining's binary_logloss: 0.010066\n",
      "[5506]\ttraining's binary_logloss: 0.0100656\n",
      "[5507]\ttraining's binary_logloss: 0.0100651\n",
      "[5508]\ttraining's binary_logloss: 0.0100642\n",
      "[5509]\ttraining's binary_logloss: 0.0100633\n",
      "[5510]\ttraining's binary_logloss: 0.0100625\n",
      "[5511]\ttraining's binary_logloss: 0.010062\n",
      "[5512]\ttraining's binary_logloss: 0.0100616\n",
      "[5513]\ttraining's binary_logloss: 0.0100607\n",
      "[5514]\ttraining's binary_logloss: 0.0100597\n",
      "[5515]\ttraining's binary_logloss: 0.010059\n",
      "[5516]\ttraining's binary_logloss: 0.0100581\n",
      "[5517]\ttraining's binary_logloss: 0.0100573\n",
      "[5518]\ttraining's binary_logloss: 0.010056\n",
      "[5519]\ttraining's binary_logloss: 0.0100554\n",
      "[5520]\ttraining's binary_logloss: 0.0100543\n",
      "[5521]\ttraining's binary_logloss: 0.0100533\n",
      "[5522]\ttraining's binary_logloss: 0.0100523\n",
      "[5523]\ttraining's binary_logloss: 0.0100513\n",
      "[5524]\ttraining's binary_logloss: 0.01005\n",
      "[5525]\ttraining's binary_logloss: 0.0100485\n",
      "[5526]\ttraining's binary_logloss: 0.0100475\n",
      "[5527]\ttraining's binary_logloss: 0.0100466\n",
      "[5528]\ttraining's binary_logloss: 0.0100458\n",
      "[5529]\ttraining's binary_logloss: 0.0100449\n",
      "[5530]\ttraining's binary_logloss: 0.0100439\n",
      "[5531]\ttraining's binary_logloss: 0.0100428\n",
      "[5532]\ttraining's binary_logloss: 0.0100418\n",
      "[5533]\ttraining's binary_logloss: 0.0100403\n",
      "[5534]\ttraining's binary_logloss: 0.0100397\n",
      "[5535]\ttraining's binary_logloss: 0.0100392\n",
      "[5536]\ttraining's binary_logloss: 0.0100384\n",
      "[5537]\ttraining's binary_logloss: 0.0100373\n",
      "[5538]\ttraining's binary_logloss: 0.0100365\n",
      "[5539]\ttraining's binary_logloss: 0.0100357\n",
      "[5540]\ttraining's binary_logloss: 0.0100341\n",
      "[5541]\ttraining's binary_logloss: 0.0100337\n",
      "[5542]\ttraining's binary_logloss: 0.0100326\n",
      "[5543]\ttraining's binary_logloss: 0.0100319\n",
      "[5544]\ttraining's binary_logloss: 0.0100309\n",
      "[5545]\ttraining's binary_logloss: 0.01003\n",
      "[5546]\ttraining's binary_logloss: 0.0100293\n",
      "[5547]\ttraining's binary_logloss: 0.0100277\n",
      "[5548]\ttraining's binary_logloss: 0.0100265\n",
      "[5549]\ttraining's binary_logloss: 0.0100255\n",
      "[5550]\ttraining's binary_logloss: 0.0100246\n",
      "[5551]\ttraining's binary_logloss: 0.0100242\n",
      "[5552]\ttraining's binary_logloss: 0.0100237\n",
      "[5553]\ttraining's binary_logloss: 0.0100226\n",
      "[5554]\ttraining's binary_logloss: 0.0100217\n",
      "[5555]\ttraining's binary_logloss: 0.0100203\n",
      "[5556]\ttraining's binary_logloss: 0.0100194\n",
      "[5557]\ttraining's binary_logloss: 0.010019\n",
      "[5558]\ttraining's binary_logloss: 0.0100179\n",
      "[5559]\ttraining's binary_logloss: 0.0100166\n",
      "[5560]\ttraining's binary_logloss: 0.0100162\n",
      "[5561]\ttraining's binary_logloss: 0.0100152\n",
      "[5562]\ttraining's binary_logloss: 0.0100144\n",
      "[5563]\ttraining's binary_logloss: 0.0100134\n",
      "[5564]\ttraining's binary_logloss: 0.010012\n",
      "[5565]\ttraining's binary_logloss: 0.0100111\n",
      "[5566]\ttraining's binary_logloss: 0.0100107\n",
      "[5567]\ttraining's binary_logloss: 0.0100101\n",
      "[5568]\ttraining's binary_logloss: 0.0100091\n",
      "[5569]\ttraining's binary_logloss: 0.0100085\n",
      "[5570]\ttraining's binary_logloss: 0.0100076\n",
      "[5571]\ttraining's binary_logloss: 0.010007\n",
      "[5572]\ttraining's binary_logloss: 0.0100066\n",
      "[5573]\ttraining's binary_logloss: 0.0100061\n",
      "[5574]\ttraining's binary_logloss: 0.0100048\n",
      "[5575]\ttraining's binary_logloss: 0.0100044\n",
      "[5576]\ttraining's binary_logloss: 0.0100035\n",
      "[5577]\ttraining's binary_logloss: 0.0100021\n",
      "[5578]\ttraining's binary_logloss: 0.0100011\n",
      "[5579]\ttraining's binary_logloss: 0.00999936\n",
      "[5580]\ttraining's binary_logloss: 0.00999819\n",
      "[5581]\ttraining's binary_logloss: 0.0099972\n",
      "[5582]\ttraining's binary_logloss: 0.00999617\n",
      "[5583]\ttraining's binary_logloss: 0.00999526\n",
      "[5584]\ttraining's binary_logloss: 0.00999418\n",
      "[5585]\ttraining's binary_logloss: 0.00999326\n",
      "[5586]\ttraining's binary_logloss: 0.00999246\n",
      "[5587]\ttraining's binary_logloss: 0.00999161\n",
      "[5588]\ttraining's binary_logloss: 0.00999102\n",
      "[5589]\ttraining's binary_logloss: 0.00999052\n",
      "[5590]\ttraining's binary_logloss: 0.00998964\n",
      "[5591]\ttraining's binary_logloss: 0.00998904\n",
      "[5592]\ttraining's binary_logloss: 0.00998808\n",
      "[5593]\ttraining's binary_logloss: 0.00998725\n",
      "[5594]\ttraining's binary_logloss: 0.00998651\n",
      "[5595]\ttraining's binary_logloss: 0.00998561\n",
      "[5596]\ttraining's binary_logloss: 0.00998517\n",
      "[5597]\ttraining's binary_logloss: 0.00998405\n",
      "[5598]\ttraining's binary_logloss: 0.00998361\n",
      "[5599]\ttraining's binary_logloss: 0.0099828\n",
      "[5600]\ttraining's binary_logloss: 0.00998177\n",
      "[5601]\ttraining's binary_logloss: 0.00998099\n",
      "[5602]\ttraining's binary_logloss: 0.00998007\n",
      "[5603]\ttraining's binary_logloss: 0.00997925\n",
      "[5604]\ttraining's binary_logloss: 0.00997825\n",
      "[5605]\ttraining's binary_logloss: 0.00997732\n",
      "[5606]\ttraining's binary_logloss: 0.00997615\n",
      "[5607]\ttraining's binary_logloss: 0.00997537\n",
      "[5608]\ttraining's binary_logloss: 0.00997443\n",
      "[5609]\ttraining's binary_logloss: 0.00997395\n",
      "[5610]\ttraining's binary_logloss: 0.00997266\n",
      "[5611]\ttraining's binary_logloss: 0.00997152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5612]\ttraining's binary_logloss: 0.00997016\n",
      "[5613]\ttraining's binary_logloss: 0.0099693\n",
      "[5614]\ttraining's binary_logloss: 0.00996846\n",
      "[5615]\ttraining's binary_logloss: 0.00996712\n",
      "[5616]\ttraining's binary_logloss: 0.00996581\n",
      "[5617]\ttraining's binary_logloss: 0.00996499\n",
      "[5618]\ttraining's binary_logloss: 0.00996433\n",
      "[5619]\ttraining's binary_logloss: 0.00996384\n",
      "[5620]\ttraining's binary_logloss: 0.00996341\n",
      "[5621]\ttraining's binary_logloss: 0.00996297\n",
      "[5622]\ttraining's binary_logloss: 0.00996124\n",
      "[5623]\ttraining's binary_logloss: 0.00996004\n",
      "[5624]\ttraining's binary_logloss: 0.00995945\n",
      "[5625]\ttraining's binary_logloss: 0.00995859\n",
      "[5626]\ttraining's binary_logloss: 0.00995759\n",
      "[5627]\ttraining's binary_logloss: 0.00995716\n",
      "[5628]\ttraining's binary_logloss: 0.00995667\n",
      "[5629]\ttraining's binary_logloss: 0.00995596\n",
      "[5630]\ttraining's binary_logloss: 0.00995488\n",
      "[5631]\ttraining's binary_logloss: 0.00995406\n",
      "[5632]\ttraining's binary_logloss: 0.00995275\n",
      "[5633]\ttraining's binary_logloss: 0.00995132\n",
      "[5634]\ttraining's binary_logloss: 0.00994997\n",
      "[5635]\ttraining's binary_logloss: 0.00994913\n",
      "[5636]\ttraining's binary_logloss: 0.00994807\n",
      "[5637]\ttraining's binary_logloss: 0.00994682\n",
      "[5638]\ttraining's binary_logloss: 0.0099459\n",
      "[5639]\ttraining's binary_logloss: 0.0099448\n",
      "[5640]\ttraining's binary_logloss: 0.00994383\n",
      "[5641]\ttraining's binary_logloss: 0.00994305\n",
      "[5642]\ttraining's binary_logloss: 0.00994202\n",
      "[5643]\ttraining's binary_logloss: 0.00994069\n",
      "[5644]\ttraining's binary_logloss: 0.00993987\n",
      "[5645]\ttraining's binary_logloss: 0.00993917\n",
      "[5646]\ttraining's binary_logloss: 0.00993853\n",
      "[5647]\ttraining's binary_logloss: 0.00993767\n",
      "[5648]\ttraining's binary_logloss: 0.00993686\n",
      "[5649]\ttraining's binary_logloss: 0.00993605\n",
      "[5650]\ttraining's binary_logloss: 0.00993497\n",
      "[5651]\ttraining's binary_logloss: 0.00993399\n",
      "[5652]\ttraining's binary_logloss: 0.00993258\n",
      "[5653]\ttraining's binary_logloss: 0.00993209\n",
      "[5654]\ttraining's binary_logloss: 0.0099309\n",
      "[5655]\ttraining's binary_logloss: 0.00992983\n",
      "[5656]\ttraining's binary_logloss: 0.00992868\n",
      "[5657]\ttraining's binary_logloss: 0.00992786\n",
      "[5658]\ttraining's binary_logloss: 0.00992693\n",
      "[5659]\ttraining's binary_logloss: 0.0099259\n",
      "[5660]\ttraining's binary_logloss: 0.00992457\n",
      "[5661]\ttraining's binary_logloss: 0.0099234\n",
      "[5662]\ttraining's binary_logloss: 0.00992281\n",
      "[5663]\ttraining's binary_logloss: 0.00992237\n",
      "[5664]\ttraining's binary_logloss: 0.0099213\n",
      "[5665]\ttraining's binary_logloss: 0.0099203\n",
      "[5666]\ttraining's binary_logloss: 0.00991918\n",
      "[5667]\ttraining's binary_logloss: 0.00991797\n",
      "[5668]\ttraining's binary_logloss: 0.00991715\n",
      "[5669]\ttraining's binary_logloss: 0.00991623\n",
      "[5670]\ttraining's binary_logloss: 0.00991542\n",
      "[5671]\ttraining's binary_logloss: 0.00991402\n",
      "[5672]\ttraining's binary_logloss: 0.0099131\n",
      "[5673]\ttraining's binary_logloss: 0.0099122\n",
      "[5674]\ttraining's binary_logloss: 0.00991127\n",
      "[5675]\ttraining's binary_logloss: 0.00991012\n",
      "[5676]\ttraining's binary_logloss: 0.00990921\n",
      "[5677]\ttraining's binary_logloss: 0.00990771\n",
      "[5678]\ttraining's binary_logloss: 0.00990689\n",
      "[5679]\ttraining's binary_logloss: 0.00990486\n",
      "[5680]\ttraining's binary_logloss: 0.00990397\n",
      "[5681]\ttraining's binary_logloss: 0.00990274\n",
      "[5682]\ttraining's binary_logloss: 0.00990139\n",
      "[5683]\ttraining's binary_logloss: 0.00990011\n",
      "[5684]\ttraining's binary_logloss: 0.00989903\n",
      "[5685]\ttraining's binary_logloss: 0.0098986\n",
      "[5686]\ttraining's binary_logloss: 0.00989817\n",
      "[5687]\ttraining's binary_logloss: 0.00989728\n",
      "[5688]\ttraining's binary_logloss: 0.00989669\n",
      "[5689]\ttraining's binary_logloss: 0.00989586\n",
      "[5690]\ttraining's binary_logloss: 0.00989528\n",
      "[5691]\ttraining's binary_logloss: 0.0098948\n",
      "[5692]\ttraining's binary_logloss: 0.00989417\n",
      "[5693]\ttraining's binary_logloss: 0.00989318\n",
      "[5694]\ttraining's binary_logloss: 0.00989222\n",
      "[5695]\ttraining's binary_logloss: 0.00989178\n",
      "[5696]\ttraining's binary_logloss: 0.00989078\n",
      "[5697]\ttraining's binary_logloss: 0.00988982\n",
      "[5698]\ttraining's binary_logloss: 0.00988899\n",
      "[5699]\ttraining's binary_logloss: 0.00988858\n",
      "[5700]\ttraining's binary_logloss: 0.0098879\n",
      "[5701]\ttraining's binary_logloss: 0.00988732\n",
      "[5702]\ttraining's binary_logloss: 0.00988684\n",
      "[5703]\ttraining's binary_logloss: 0.00988596\n",
      "[5704]\ttraining's binary_logloss: 0.00988438\n",
      "[5705]\ttraining's binary_logloss: 0.00988327\n",
      "[5706]\ttraining's binary_logloss: 0.00988193\n",
      "[5707]\ttraining's binary_logloss: 0.0098815\n",
      "[5708]\ttraining's binary_logloss: 0.00988072\n",
      "[5709]\ttraining's binary_logloss: 0.00987981\n",
      "[5710]\ttraining's binary_logloss: 0.00987905\n",
      "[5711]\ttraining's binary_logloss: 0.00987742\n",
      "[5712]\ttraining's binary_logloss: 0.00987641\n",
      "[5713]\ttraining's binary_logloss: 0.00987559\n",
      "[5714]\ttraining's binary_logloss: 0.00987479\n",
      "[5715]\ttraining's binary_logloss: 0.00987371\n",
      "[5716]\ttraining's binary_logloss: 0.00987256\n",
      "[5717]\ttraining's binary_logloss: 0.00987157\n",
      "[5718]\ttraining's binary_logloss: 0.00987087\n",
      "[5719]\ttraining's binary_logloss: 0.00986992\n",
      "[5720]\ttraining's binary_logloss: 0.00986951\n",
      "[5721]\ttraining's binary_logloss: 0.00986837\n",
      "[5722]\ttraining's binary_logloss: 0.00986661\n",
      "[5723]\ttraining's binary_logloss: 0.00986564\n",
      "[5724]\ttraining's binary_logloss: 0.00986521\n",
      "[5725]\ttraining's binary_logloss: 0.00986363\n",
      "[5726]\ttraining's binary_logloss: 0.00986288\n",
      "[5727]\ttraining's binary_logloss: 0.0098623\n",
      "[5728]\ttraining's binary_logloss: 0.00986182\n",
      "[5729]\ttraining's binary_logloss: 0.00986141\n",
      "[5730]\ttraining's binary_logloss: 0.00986047\n",
      "[5731]\ttraining's binary_logloss: 0.00985969\n",
      "[5732]\ttraining's binary_logloss: 0.0098585\n",
      "[5733]\ttraining's binary_logloss: 0.00985764\n",
      "[5734]\ttraining's binary_logloss: 0.00985722\n",
      "[5735]\ttraining's binary_logloss: 0.00985631\n",
      "[5736]\ttraining's binary_logloss: 0.00985545\n",
      "[5737]\ttraining's binary_logloss: 0.00985464\n",
      "[5738]\ttraining's binary_logloss: 0.00985384\n",
      "[5739]\ttraining's binary_logloss: 0.00985254\n",
      "[5740]\ttraining's binary_logloss: 0.00985136\n",
      "[5741]\ttraining's binary_logloss: 0.00985046\n",
      "[5742]\ttraining's binary_logloss: 0.00985006\n",
      "[5743]\ttraining's binary_logloss: 0.00984899\n",
      "[5744]\ttraining's binary_logloss: 0.00984775\n",
      "[5745]\ttraining's binary_logloss: 0.00984714\n",
      "[5746]\ttraining's binary_logloss: 0.00984601\n",
      "[5747]\ttraining's binary_logloss: 0.00984508\n",
      "[5748]\ttraining's binary_logloss: 0.00984467\n",
      "[5749]\ttraining's binary_logloss: 0.00984388\n",
      "[5750]\ttraining's binary_logloss: 0.00984298\n",
      "[5751]\ttraining's binary_logloss: 0.00984192\n",
      "[5752]\ttraining's binary_logloss: 0.00984099\n",
      "[5753]\ttraining's binary_logloss: 0.00984005\n",
      "[5754]\ttraining's binary_logloss: 0.00983873\n",
      "[5755]\ttraining's binary_logloss: 0.00983779\n",
      "[5756]\ttraining's binary_logloss: 0.00983686\n",
      "[5757]\ttraining's binary_logloss: 0.00983577\n",
      "[5758]\ttraining's binary_logloss: 0.00983457\n",
      "[5759]\ttraining's binary_logloss: 0.00983364\n",
      "[5760]\ttraining's binary_logloss: 0.00983278\n",
      "[5761]\ttraining's binary_logloss: 0.009832\n",
      "[5762]\ttraining's binary_logloss: 0.00983142\n",
      "[5763]\ttraining's binary_logloss: 0.0098306\n",
      "[5764]\ttraining's binary_logloss: 0.00982984\n",
      "[5765]\ttraining's binary_logloss: 0.00982897\n",
      "[5766]\ttraining's binary_logloss: 0.00982807\n",
      "[5767]\ttraining's binary_logloss: 0.00982717\n",
      "[5768]\ttraining's binary_logloss: 0.00982629\n",
      "[5769]\ttraining's binary_logloss: 0.0098252\n",
      "[5770]\ttraining's binary_logloss: 0.00982481\n",
      "[5771]\ttraining's binary_logloss: 0.00982376\n",
      "[5772]\ttraining's binary_logloss: 0.00982282\n",
      "[5773]\ttraining's binary_logloss: 0.00982204\n",
      "[5774]\ttraining's binary_logloss: 0.00982118\n",
      "[5775]\ttraining's binary_logloss: 0.00982021\n",
      "[5776]\ttraining's binary_logloss: 0.00981979\n",
      "[5777]\ttraining's binary_logloss: 0.00981936\n",
      "[5778]\ttraining's binary_logloss: 0.00981804\n",
      "[5779]\ttraining's binary_logloss: 0.00981703\n",
      "[5780]\ttraining's binary_logloss: 0.00981664\n",
      "[5781]\ttraining's binary_logloss: 0.00981534\n",
      "[5782]\ttraining's binary_logloss: 0.00981436\n",
      "[5783]\ttraining's binary_logloss: 0.00981394\n",
      "[5784]\ttraining's binary_logloss: 0.00981346\n",
      "[5785]\ttraining's binary_logloss: 0.00981305\n",
      "[5786]\ttraining's binary_logloss: 0.00981257\n",
      "[5787]\ttraining's binary_logloss: 0.00981196\n",
      "[5788]\ttraining's binary_logloss: 0.0098115\n",
      "[5789]\ttraining's binary_logloss: 0.0098106\n",
      "[5790]\ttraining's binary_logloss: 0.00980954\n",
      "[5791]\ttraining's binary_logloss: 0.00980863\n",
      "[5792]\ttraining's binary_logloss: 0.00980785\n",
      "[5793]\ttraining's binary_logloss: 0.00980699\n",
      "[5794]\ttraining's binary_logloss: 0.00980639\n",
      "[5795]\ttraining's binary_logloss: 0.00980596\n",
      "[5796]\ttraining's binary_logloss: 0.00980512\n",
      "[5797]\ttraining's binary_logloss: 0.00980456\n",
      "[5798]\ttraining's binary_logloss: 0.00980365\n",
      "[5799]\ttraining's binary_logloss: 0.00980322\n",
      "[5800]\ttraining's binary_logloss: 0.0098023\n",
      "[5801]\ttraining's binary_logloss: 0.00980114\n",
      "[5802]\ttraining's binary_logloss: 0.00979989\n",
      "[5803]\ttraining's binary_logloss: 0.00979866\n",
      "[5804]\ttraining's binary_logloss: 0.00979811\n",
      "[5805]\ttraining's binary_logloss: 0.00979764\n",
      "[5806]\ttraining's binary_logloss: 0.00979593\n",
      "[5807]\ttraining's binary_logloss: 0.00979498\n",
      "[5808]\ttraining's binary_logloss: 0.00979458\n",
      "[5809]\ttraining's binary_logloss: 0.00979368\n",
      "[5810]\ttraining's binary_logloss: 0.0097929\n",
      "[5811]\ttraining's binary_logloss: 0.00979247\n",
      "[5812]\ttraining's binary_logloss: 0.00979206\n",
      "[5813]\ttraining's binary_logloss: 0.00979128\n",
      "[5814]\ttraining's binary_logloss: 0.00979084\n",
      "[5815]\ttraining's binary_logloss: 0.00979042\n",
      "[5816]\ttraining's binary_logloss: 0.00978953\n",
      "[5817]\ttraining's binary_logloss: 0.00978906\n",
      "[5818]\ttraining's binary_logloss: 0.00978769\n",
      "[5819]\ttraining's binary_logloss: 0.00978726\n",
      "[5820]\ttraining's binary_logloss: 0.00978644\n",
      "[5821]\ttraining's binary_logloss: 0.00978554\n",
      "[5822]\ttraining's binary_logloss: 0.00978455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5823]\ttraining's binary_logloss: 0.00978371\n",
      "[5824]\ttraining's binary_logloss: 0.00978329\n",
      "[5825]\ttraining's binary_logloss: 0.00978249\n",
      "[5826]\ttraining's binary_logloss: 0.00978154\n",
      "[5827]\ttraining's binary_logloss: 0.00978065\n",
      "[5828]\ttraining's binary_logloss: 0.0097791\n",
      "[5829]\ttraining's binary_logloss: 0.00977798\n",
      "[5830]\ttraining's binary_logloss: 0.00977694\n",
      "[5831]\ttraining's binary_logloss: 0.00977639\n",
      "[5832]\ttraining's binary_logloss: 0.00977593\n",
      "[5833]\ttraining's binary_logloss: 0.00977494\n",
      "[5834]\ttraining's binary_logloss: 0.00977445\n",
      "[5835]\ttraining's binary_logloss: 0.00977359\n",
      "[5836]\ttraining's binary_logloss: 0.00977262\n",
      "[5837]\ttraining's binary_logloss: 0.00977103\n",
      "[5838]\ttraining's binary_logloss: 0.00977062\n",
      "[5839]\ttraining's binary_logloss: 0.00976948\n",
      "[5840]\ttraining's binary_logloss: 0.0097679\n",
      "[5841]\ttraining's binary_logloss: 0.00976692\n",
      "[5842]\ttraining's binary_logloss: 0.00976585\n",
      "[5843]\ttraining's binary_logloss: 0.00976506\n",
      "[5844]\ttraining's binary_logloss: 0.00976466\n",
      "[5845]\ttraining's binary_logloss: 0.00976424\n",
      "[5846]\ttraining's binary_logloss: 0.00976369\n",
      "[5847]\ttraining's binary_logloss: 0.00976291\n",
      "[5848]\ttraining's binary_logloss: 0.00976237\n",
      "[5849]\ttraining's binary_logloss: 0.00976152\n",
      "[5850]\ttraining's binary_logloss: 0.00976109\n",
      "[5851]\ttraining's binary_logloss: 0.00976056\n",
      "[5852]\ttraining's binary_logloss: 0.00976014\n",
      "[5853]\ttraining's binary_logloss: 0.00975976\n",
      "[5854]\ttraining's binary_logloss: 0.00975877\n",
      "[5855]\ttraining's binary_logloss: 0.00975768\n",
      "[5856]\ttraining's binary_logloss: 0.00975721\n",
      "[5857]\ttraining's binary_logloss: 0.00975681\n",
      "[5858]\ttraining's binary_logloss: 0.00975546\n",
      "[5859]\ttraining's binary_logloss: 0.00975446\n",
      "[5860]\ttraining's binary_logloss: 0.00975329\n",
      "[5861]\ttraining's binary_logloss: 0.00975242\n",
      "[5862]\ttraining's binary_logloss: 0.00975155\n",
      "[5863]\ttraining's binary_logloss: 0.00975073\n",
      "[5864]\ttraining's binary_logloss: 0.00974968\n",
      "[5865]\ttraining's binary_logloss: 0.00974854\n",
      "[5866]\ttraining's binary_logloss: 0.00974759\n",
      "[5867]\ttraining's binary_logloss: 0.00974667\n",
      "[5868]\ttraining's binary_logloss: 0.00974574\n",
      "[5869]\ttraining's binary_logloss: 0.00974498\n",
      "[5870]\ttraining's binary_logloss: 0.00974452\n",
      "[5871]\ttraining's binary_logloss: 0.00974325\n",
      "[5872]\ttraining's binary_logloss: 0.00974224\n",
      "[5873]\ttraining's binary_logloss: 0.00974177\n",
      "[5874]\ttraining's binary_logloss: 0.00974077\n",
      "[5875]\ttraining's binary_logloss: 0.00973974\n",
      "[5876]\ttraining's binary_logloss: 0.00973824\n",
      "[5877]\ttraining's binary_logloss: 0.00973741\n",
      "[5878]\ttraining's binary_logloss: 0.00973612\n",
      "[5879]\ttraining's binary_logloss: 0.00973531\n",
      "[5880]\ttraining's binary_logloss: 0.00973423\n",
      "[5881]\ttraining's binary_logloss: 0.00973324\n",
      "[5882]\ttraining's binary_logloss: 0.00973221\n",
      "[5883]\ttraining's binary_logloss: 0.00973134\n",
      "[5884]\ttraining's binary_logloss: 0.00973031\n",
      "[5885]\ttraining's binary_logloss: 0.00972929\n",
      "[5886]\ttraining's binary_logloss: 0.00972849\n",
      "[5887]\ttraining's binary_logloss: 0.00972754\n",
      "[5888]\ttraining's binary_logloss: 0.00972713\n",
      "[5889]\ttraining's binary_logloss: 0.00972599\n",
      "[5890]\ttraining's binary_logloss: 0.00972512\n",
      "[5891]\ttraining's binary_logloss: 0.00972472\n",
      "[5892]\ttraining's binary_logloss: 0.00972377\n",
      "[5893]\ttraining's binary_logloss: 0.0097227\n",
      "[5894]\ttraining's binary_logloss: 0.00972159\n",
      "[5895]\ttraining's binary_logloss: 0.00972081\n",
      "[5896]\ttraining's binary_logloss: 0.00971991\n",
      "[5897]\ttraining's binary_logloss: 0.00971892\n",
      "[5898]\ttraining's binary_logloss: 0.00971804\n",
      "[5899]\ttraining's binary_logloss: 0.00971679\n",
      "[5900]\ttraining's binary_logloss: 0.00971637\n",
      "[5901]\ttraining's binary_logloss: 0.00971548\n",
      "[5902]\ttraining's binary_logloss: 0.00971508\n",
      "[5903]\ttraining's binary_logloss: 0.00971429\n",
      "[5904]\ttraining's binary_logloss: 0.00971325\n",
      "[5905]\ttraining's binary_logloss: 0.00971245\n",
      "[5906]\ttraining's binary_logloss: 0.00971149\n",
      "[5907]\ttraining's binary_logloss: 0.00971108\n",
      "[5908]\ttraining's binary_logloss: 0.00971013\n",
      "[5909]\ttraining's binary_logloss: 0.00970926\n",
      "[5910]\ttraining's binary_logloss: 0.0097084\n",
      "[5911]\ttraining's binary_logloss: 0.00970765\n",
      "[5912]\ttraining's binary_logloss: 0.00970689\n",
      "[5913]\ttraining's binary_logloss: 0.00970648\n",
      "[5914]\ttraining's binary_logloss: 0.00970577\n",
      "[5915]\ttraining's binary_logloss: 0.00970536\n",
      "[5916]\ttraining's binary_logloss: 0.00970494\n",
      "[5917]\ttraining's binary_logloss: 0.00970454\n",
      "[5918]\ttraining's binary_logloss: 0.00970412\n",
      "[5919]\ttraining's binary_logloss: 0.00970373\n",
      "[5920]\ttraining's binary_logloss: 0.00970327\n",
      "[5921]\ttraining's binary_logloss: 0.00970233\n",
      "[5922]\ttraining's binary_logloss: 0.00970149\n",
      "[5923]\ttraining's binary_logloss: 0.00970061\n",
      "[5924]\ttraining's binary_logloss: 0.0096993\n",
      "[5925]\ttraining's binary_logloss: 0.00969838\n",
      "[5926]\ttraining's binary_logloss: 0.00969797\n",
      "[5927]\ttraining's binary_logloss: 0.0096976\n",
      "[5928]\ttraining's binary_logloss: 0.0096972\n",
      "[5929]\ttraining's binary_logloss: 0.00969678\n",
      "[5930]\ttraining's binary_logloss: 0.00969638\n",
      "[5931]\ttraining's binary_logloss: 0.00969596\n",
      "[5932]\ttraining's binary_logloss: 0.0096953\n",
      "[5933]\ttraining's binary_logloss: 0.00969491\n",
      "[5934]\ttraining's binary_logloss: 0.0096941\n",
      "[5935]\ttraining's binary_logloss: 0.00969299\n",
      "[5936]\ttraining's binary_logloss: 0.00969197\n",
      "[5937]\ttraining's binary_logloss: 0.00969118\n",
      "[5938]\ttraining's binary_logloss: 0.00969019\n",
      "[5939]\ttraining's binary_logloss: 0.00968923\n",
      "[5940]\ttraining's binary_logloss: 0.00968832\n",
      "[5941]\ttraining's binary_logloss: 0.00968737\n",
      "[5942]\ttraining's binary_logloss: 0.00968609\n",
      "[5943]\ttraining's binary_logloss: 0.00968512\n",
      "[5944]\ttraining's binary_logloss: 0.00968415\n",
      "[5945]\ttraining's binary_logloss: 0.00968287\n",
      "[5946]\ttraining's binary_logloss: 0.0096816\n",
      "[5947]\ttraining's binary_logloss: 0.0096807\n",
      "[5948]\ttraining's binary_logloss: 0.00967985\n",
      "[5949]\ttraining's binary_logloss: 0.00967898\n",
      "[5950]\ttraining's binary_logloss: 0.00967827\n",
      "[5951]\ttraining's binary_logloss: 0.00967748\n",
      "[5952]\ttraining's binary_logloss: 0.00967643\n",
      "[5953]\ttraining's binary_logloss: 0.00967524\n",
      "[5954]\ttraining's binary_logloss: 0.00967432\n",
      "[5955]\ttraining's binary_logloss: 0.00967357\n",
      "[5956]\ttraining's binary_logloss: 0.00967311\n",
      "[5957]\ttraining's binary_logloss: 0.00967157\n",
      "[5958]\ttraining's binary_logloss: 0.00967063\n",
      "[5959]\ttraining's binary_logloss: 0.0096697\n",
      "[5960]\ttraining's binary_logloss: 0.00966933\n",
      "[5961]\ttraining's binary_logloss: 0.00966854\n",
      "[5962]\ttraining's binary_logloss: 0.00966808\n",
      "[5963]\ttraining's binary_logloss: 0.00966726\n",
      "[5964]\ttraining's binary_logloss: 0.00966634\n",
      "[5965]\ttraining's binary_logloss: 0.00966544\n",
      "[5966]\ttraining's binary_logloss: 0.00966462\n",
      "[5967]\ttraining's binary_logloss: 0.00966422\n",
      "[5968]\ttraining's binary_logloss: 0.00966358\n",
      "[5969]\ttraining's binary_logloss: 0.00966276\n",
      "[5970]\ttraining's binary_logloss: 0.00966161\n",
      "[5971]\ttraining's binary_logloss: 0.0096605\n",
      "[5972]\ttraining's binary_logloss: 0.00966004\n",
      "[5973]\ttraining's binary_logloss: 0.00965964\n",
      "[5974]\ttraining's binary_logloss: 0.00965923\n",
      "[5975]\ttraining's binary_logloss: 0.00965883\n",
      "[5976]\ttraining's binary_logloss: 0.00965842\n",
      "[5977]\ttraining's binary_logloss: 0.00965802\n",
      "[5978]\ttraining's binary_logloss: 0.00965757\n",
      "[5979]\ttraining's binary_logloss: 0.00965663\n",
      "[5980]\ttraining's binary_logloss: 0.00965588\n",
      "[5981]\ttraining's binary_logloss: 0.00965509\n",
      "[5982]\ttraining's binary_logloss: 0.00965399\n",
      "[5983]\ttraining's binary_logloss: 0.00965266\n",
      "[5984]\ttraining's binary_logloss: 0.00965226\n",
      "[5985]\ttraining's binary_logloss: 0.00965135\n",
      "[5986]\ttraining's binary_logloss: 0.0096506\n",
      "[5987]\ttraining's binary_logloss: 0.00964964\n",
      "[5988]\ttraining's binary_logloss: 0.00964879\n",
      "[5989]\ttraining's binary_logloss: 0.00964799\n",
      "[5990]\ttraining's binary_logloss: 0.00964676\n",
      "[5991]\ttraining's binary_logloss: 0.00964553\n",
      "[5992]\ttraining's binary_logloss: 0.00964429\n",
      "[5993]\ttraining's binary_logloss: 0.00964349\n",
      "[5994]\ttraining's binary_logloss: 0.00964264\n",
      "[5995]\ttraining's binary_logloss: 0.00964177\n",
      "[5996]\ttraining's binary_logloss: 0.00964092\n",
      "[5997]\ttraining's binary_logloss: 0.00964028\n",
      "[5998]\ttraining's binary_logloss: 0.00963989\n",
      "[5999]\ttraining's binary_logloss: 0.00963944\n",
      "[6000]\ttraining's binary_logloss: 0.00963776\n",
      "[6001]\ttraining's binary_logloss: 0.00963738\n",
      "[6002]\ttraining's binary_logloss: 0.00963659\n",
      "[6003]\ttraining's binary_logloss: 0.0096362\n",
      "[6004]\ttraining's binary_logloss: 0.00963545\n",
      "[6005]\ttraining's binary_logloss: 0.00963457\n",
      "[6006]\ttraining's binary_logloss: 0.00963348\n",
      "[6007]\ttraining's binary_logloss: 0.0096327\n",
      "[6008]\ttraining's binary_logloss: 0.00963155\n",
      "[6009]\ttraining's binary_logloss: 0.00963071\n",
      "[6010]\ttraining's binary_logloss: 0.00963025\n",
      "[6011]\ttraining's binary_logloss: 0.00962933\n",
      "[6012]\ttraining's binary_logloss: 0.0096278\n",
      "[6013]\ttraining's binary_logloss: 0.00962736\n",
      "[6014]\ttraining's binary_logloss: 0.00962662\n",
      "[6015]\ttraining's binary_logloss: 0.00962565\n",
      "[6016]\ttraining's binary_logloss: 0.00962526\n",
      "[6017]\ttraining's binary_logloss: 0.00962443\n",
      "[6018]\ttraining's binary_logloss: 0.00962381\n",
      "[6019]\ttraining's binary_logloss: 0.00962344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6020]\ttraining's binary_logloss: 0.00962224\n",
      "[6021]\ttraining's binary_logloss: 0.00962147\n",
      "[6022]\ttraining's binary_logloss: 0.0096203\n",
      "[6023]\ttraining's binary_logloss: 0.00961916\n",
      "[6024]\ttraining's binary_logloss: 0.00961878\n",
      "[6025]\ttraining's binary_logloss: 0.00961836\n",
      "[6026]\ttraining's binary_logloss: 0.00961798\n",
      "[6027]\ttraining's binary_logloss: 0.00961757\n",
      "[6028]\ttraining's binary_logloss: 0.00961593\n",
      "[6029]\ttraining's binary_logloss: 0.00961464\n",
      "[6030]\ttraining's binary_logloss: 0.00961369\n",
      "[6031]\ttraining's binary_logloss: 0.00961265\n",
      "[6032]\ttraining's binary_logloss: 0.00961162\n",
      "[6033]\ttraining's binary_logloss: 0.00961091\n",
      "[6034]\ttraining's binary_logloss: 0.0096105\n",
      "[6035]\ttraining's binary_logloss: 0.00961011\n",
      "[6036]\ttraining's binary_logloss: 0.00960935\n",
      "[6037]\ttraining's binary_logloss: 0.00960837\n",
      "[6038]\ttraining's binary_logloss: 0.00960726\n",
      "[6039]\ttraining's binary_logloss: 0.00960614\n",
      "[6040]\ttraining's binary_logloss: 0.00960519\n",
      "[6041]\ttraining's binary_logloss: 0.00960414\n",
      "[6042]\ttraining's binary_logloss: 0.00960376\n",
      "[6043]\ttraining's binary_logloss: 0.00960257\n",
      "[6044]\ttraining's binary_logloss: 0.0096018\n",
      "[6045]\ttraining's binary_logloss: 0.00960092\n",
      "[6046]\ttraining's binary_logloss: 0.00960006\n",
      "[6047]\ttraining's binary_logloss: 0.00959931\n",
      "[6048]\ttraining's binary_logloss: 0.00959825\n",
      "[6049]\ttraining's binary_logloss: 0.00959781\n",
      "[6050]\ttraining's binary_logloss: 0.00959742\n",
      "[6051]\ttraining's binary_logloss: 0.00959701\n",
      "[6052]\ttraining's binary_logloss: 0.00959603\n",
      "[6053]\ttraining's binary_logloss: 0.00959565\n",
      "[6054]\ttraining's binary_logloss: 0.0095946\n",
      "[6055]\ttraining's binary_logloss: 0.00959386\n",
      "[6056]\ttraining's binary_logloss: 0.00959302\n",
      "[6057]\ttraining's binary_logloss: 0.00959193\n",
      "[6058]\ttraining's binary_logloss: 0.00959093\n",
      "[6059]\ttraining's binary_logloss: 0.00959\n",
      "[6060]\ttraining's binary_logloss: 0.00958924\n",
      "[6061]\ttraining's binary_logloss: 0.00958798\n",
      "[6062]\ttraining's binary_logloss: 0.00958724\n",
      "[6063]\ttraining's binary_logloss: 0.00958598\n",
      "[6064]\ttraining's binary_logloss: 0.00958497\n",
      "[6065]\ttraining's binary_logloss: 0.00958422\n",
      "[6066]\ttraining's binary_logloss: 0.00958338\n",
      "[6067]\ttraining's binary_logloss: 0.00958257\n",
      "[6068]\ttraining's binary_logloss: 0.00958197\n",
      "[6069]\ttraining's binary_logloss: 0.00958076\n",
      "[6070]\ttraining's binary_logloss: 0.00957986\n",
      "[6071]\ttraining's binary_logloss: 0.00957864\n",
      "[6072]\ttraining's binary_logloss: 0.00957739\n",
      "[6073]\ttraining's binary_logloss: 0.0095764\n",
      "[6074]\ttraining's binary_logloss: 0.0095756\n",
      "[6075]\ttraining's binary_logloss: 0.00957479\n",
      "[6076]\ttraining's binary_logloss: 0.00957383\n",
      "[6077]\ttraining's binary_logloss: 0.00957298\n",
      "[6078]\ttraining's binary_logloss: 0.00957259\n",
      "[6079]\ttraining's binary_logloss: 0.00957154\n",
      "[6080]\ttraining's binary_logloss: 0.00957054\n",
      "[6081]\ttraining's binary_logloss: 0.00956987\n",
      "[6082]\ttraining's binary_logloss: 0.00956948\n",
      "[6083]\ttraining's binary_logloss: 0.00956843\n",
      "[6084]\ttraining's binary_logloss: 0.00956742\n",
      "[6085]\ttraining's binary_logloss: 0.00956644\n",
      "[6086]\ttraining's binary_logloss: 0.00956565\n",
      "[6087]\ttraining's binary_logloss: 0.00956471\n",
      "[6088]\ttraining's binary_logloss: 0.0095643\n",
      "[6089]\ttraining's binary_logloss: 0.00956391\n",
      "[6090]\ttraining's binary_logloss: 0.00956312\n",
      "[6091]\ttraining's binary_logloss: 0.00956216\n",
      "[6092]\ttraining's binary_logloss: 0.00956107\n",
      "[6093]\ttraining's binary_logloss: 0.00956066\n",
      "[6094]\ttraining's binary_logloss: 0.00956028\n",
      "[6095]\ttraining's binary_logloss: 0.00955984\n",
      "[6096]\ttraining's binary_logloss: 0.00955907\n",
      "[6097]\ttraining's binary_logloss: 0.00955815\n",
      "[6098]\ttraining's binary_logloss: 0.00955722\n",
      "[6099]\ttraining's binary_logloss: 0.00955642\n",
      "[6100]\ttraining's binary_logloss: 0.00955562\n",
      "[6101]\ttraining's binary_logloss: 0.00955477\n",
      "[6102]\ttraining's binary_logloss: 0.00955387\n",
      "[6103]\ttraining's binary_logloss: 0.00955349\n",
      "[6104]\ttraining's binary_logloss: 0.00955307\n",
      "[6105]\ttraining's binary_logloss: 0.00955208\n",
      "[6106]\ttraining's binary_logloss: 0.00955172\n",
      "[6107]\ttraining's binary_logloss: 0.00955134\n",
      "[6108]\ttraining's binary_logloss: 0.00955093\n",
      "[6109]\ttraining's binary_logloss: 0.00955055\n",
      "[6110]\ttraining's binary_logloss: 0.00955012\n",
      "[6111]\ttraining's binary_logloss: 0.00954974\n",
      "[6112]\ttraining's binary_logloss: 0.00954933\n",
      "[6113]\ttraining's binary_logloss: 0.00954817\n",
      "[6114]\ttraining's binary_logloss: 0.00954726\n",
      "[6115]\ttraining's binary_logloss: 0.00954633\n",
      "[6116]\ttraining's binary_logloss: 0.00954532\n",
      "[6117]\ttraining's binary_logloss: 0.00954434\n",
      "[6118]\ttraining's binary_logloss: 0.00954398\n",
      "[6119]\ttraining's binary_logloss: 0.0095436\n",
      "[6120]\ttraining's binary_logloss: 0.00954319\n",
      "[6121]\ttraining's binary_logloss: 0.00954221\n",
      "[6122]\ttraining's binary_logloss: 0.00954138\n",
      "[6123]\ttraining's binary_logloss: 0.00954052\n",
      "[6124]\ttraining's binary_logloss: 0.00954014\n",
      "[6125]\ttraining's binary_logloss: 0.00953917\n",
      "[6126]\ttraining's binary_logloss: 0.00953841\n",
      "[6127]\ttraining's binary_logloss: 0.00953798\n",
      "[6128]\ttraining's binary_logloss: 0.00953761\n",
      "[6129]\ttraining's binary_logloss: 0.0095372\n",
      "[6130]\ttraining's binary_logloss: 0.00953683\n",
      "[6131]\ttraining's binary_logloss: 0.00953617\n",
      "[6132]\ttraining's binary_logloss: 0.00953495\n",
      "[6133]\ttraining's binary_logloss: 0.00953402\n",
      "[6134]\ttraining's binary_logloss: 0.00953311\n",
      "[6135]\ttraining's binary_logloss: 0.00953233\n",
      "[6136]\ttraining's binary_logloss: 0.00953144\n",
      "[6137]\ttraining's binary_logloss: 0.00953072\n",
      "[6138]\ttraining's binary_logloss: 0.00952969\n",
      "[6139]\ttraining's binary_logloss: 0.00952894\n",
      "[6140]\ttraining's binary_logloss: 0.00952799\n",
      "[6141]\ttraining's binary_logloss: 0.00952762\n",
      "[6142]\ttraining's binary_logloss: 0.00952721\n",
      "[6143]\ttraining's binary_logloss: 0.00952645\n",
      "[6144]\ttraining's binary_logloss: 0.0095253\n",
      "[6145]\ttraining's binary_logloss: 0.00952453\n",
      "[6146]\ttraining's binary_logloss: 0.00952325\n",
      "[6147]\ttraining's binary_logloss: 0.00952221\n",
      "[6148]\ttraining's binary_logloss: 0.00952101\n",
      "[6149]\ttraining's binary_logloss: 0.00952013\n",
      "[6150]\ttraining's binary_logloss: 0.00951911\n",
      "[6151]\ttraining's binary_logloss: 0.00951851\n",
      "[6152]\ttraining's binary_logloss: 0.00951769\n",
      "[6153]\ttraining's binary_logloss: 0.00951687\n",
      "[6154]\ttraining's binary_logloss: 0.00951597\n",
      "[6155]\ttraining's binary_logloss: 0.009515\n",
      "[6156]\ttraining's binary_logloss: 0.0095138\n",
      "[6157]\ttraining's binary_logloss: 0.00951287\n",
      "[6158]\ttraining's binary_logloss: 0.00951148\n",
      "[6159]\ttraining's binary_logloss: 0.00951104\n",
      "[6160]\ttraining's binary_logloss: 0.00951025\n",
      "[6161]\ttraining's binary_logloss: 0.00950937\n",
      "[6162]\ttraining's binary_logloss: 0.00950853\n",
      "[6163]\ttraining's binary_logloss: 0.00950776\n",
      "[6164]\ttraining's binary_logloss: 0.00950704\n",
      "[6165]\ttraining's binary_logloss: 0.0095051\n",
      "[6166]\ttraining's binary_logloss: 0.00950435\n",
      "[6167]\ttraining's binary_logloss: 0.00950336\n",
      "[6168]\ttraining's binary_logloss: 0.00950273\n",
      "[6169]\ttraining's binary_logloss: 0.00950164\n",
      "[6170]\ttraining's binary_logloss: 0.00950126\n",
      "[6171]\ttraining's binary_logloss: 0.00950086\n",
      "[6172]\ttraining's binary_logloss: 0.00950008\n",
      "[6173]\ttraining's binary_logloss: 0.00949924\n",
      "[6174]\ttraining's binary_logloss: 0.00949832\n",
      "[6175]\ttraining's binary_logloss: 0.00949711\n",
      "[6176]\ttraining's binary_logloss: 0.00949608\n",
      "[6177]\ttraining's binary_logloss: 0.00949485\n",
      "[6178]\ttraining's binary_logloss: 0.00949399\n",
      "[6179]\ttraining's binary_logloss: 0.00949329\n",
      "[6180]\ttraining's binary_logloss: 0.00949289\n",
      "[6181]\ttraining's binary_logloss: 0.00949252\n",
      "[6182]\ttraining's binary_logloss: 0.00949148\n",
      "[6183]\ttraining's binary_logloss: 0.00949106\n",
      "[6184]\ttraining's binary_logloss: 0.00949047\n",
      "[6185]\ttraining's binary_logloss: 0.00949008\n",
      "[6186]\ttraining's binary_logloss: 0.0094897\n",
      "[6187]\ttraining's binary_logloss: 0.00948899\n",
      "[6188]\ttraining's binary_logloss: 0.00948797\n",
      "[6189]\ttraining's binary_logloss: 0.00948719\n",
      "[6190]\ttraining's binary_logloss: 0.00948684\n",
      "[6191]\ttraining's binary_logloss: 0.00948647\n",
      "[6192]\ttraining's binary_logloss: 0.0094855\n",
      "[6193]\ttraining's binary_logloss: 0.0094846\n",
      "[6194]\ttraining's binary_logloss: 0.00948421\n",
      "[6195]\ttraining's binary_logloss: 0.00948295\n",
      "[6196]\ttraining's binary_logloss: 0.00948218\n",
      "[6197]\ttraining's binary_logloss: 0.00948112\n",
      "[6198]\ttraining's binary_logloss: 0.00947977\n",
      "[6199]\ttraining's binary_logloss: 0.00947886\n",
      "[6200]\ttraining's binary_logloss: 0.0094777\n",
      "[6201]\ttraining's binary_logloss: 0.00947682\n",
      "[6202]\ttraining's binary_logloss: 0.00947585\n",
      "[6203]\ttraining's binary_logloss: 0.00947526\n",
      "[6204]\ttraining's binary_logloss: 0.00947487\n",
      "[6205]\ttraining's binary_logloss: 0.00947445\n",
      "[6206]\ttraining's binary_logloss: 0.00947403\n",
      "[6207]\ttraining's binary_logloss: 0.00947311\n",
      "[6208]\ttraining's binary_logloss: 0.00947226\n",
      "[6209]\ttraining's binary_logloss: 0.00947129\n",
      "[6210]\ttraining's binary_logloss: 0.00947091\n",
      "[6211]\ttraining's binary_logloss: 0.00947004\n",
      "[6212]\ttraining's binary_logloss: 0.00946908\n",
      "[6213]\ttraining's binary_logloss: 0.00946821\n",
      "[6214]\ttraining's binary_logloss: 0.00946747\n",
      "[6215]\ttraining's binary_logloss: 0.00946651\n",
      "[6216]\ttraining's binary_logloss: 0.00946571\n",
      "[6217]\ttraining's binary_logloss: 0.0094647\n",
      "[6218]\ttraining's binary_logloss: 0.0094636\n",
      "[6219]\ttraining's binary_logloss: 0.00946261\n",
      "[6220]\ttraining's binary_logloss: 0.00946193\n",
      "[6221]\ttraining's binary_logloss: 0.00946116\n",
      "[6222]\ttraining's binary_logloss: 0.00946015\n",
      "[6223]\ttraining's binary_logloss: 0.00945975\n",
      "[6224]\ttraining's binary_logloss: 0.00945871\n",
      "[6225]\ttraining's binary_logloss: 0.00945757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6226]\ttraining's binary_logloss: 0.00945681\n",
      "[6227]\ttraining's binary_logloss: 0.00945643\n",
      "[6228]\ttraining's binary_logloss: 0.00945604\n",
      "[6229]\ttraining's binary_logloss: 0.0094549\n",
      "[6230]\ttraining's binary_logloss: 0.00945404\n",
      "[6231]\ttraining's binary_logloss: 0.00945331\n",
      "[6232]\ttraining's binary_logloss: 0.00945294\n",
      "[6233]\ttraining's binary_logloss: 0.00945195\n",
      "[6234]\ttraining's binary_logloss: 0.00945098\n",
      "[6235]\ttraining's binary_logloss: 0.00945008\n",
      "[6236]\ttraining's binary_logloss: 0.0094493\n",
      "[6237]\ttraining's binary_logloss: 0.00944873\n",
      "[6238]\ttraining's binary_logloss: 0.009448\n",
      "[6239]\ttraining's binary_logloss: 0.00944764\n",
      "[6240]\ttraining's binary_logloss: 0.00944728\n",
      "[6241]\ttraining's binary_logloss: 0.00944649\n",
      "[6242]\ttraining's binary_logloss: 0.0094456\n",
      "[6243]\ttraining's binary_logloss: 0.00944488\n",
      "[6244]\ttraining's binary_logloss: 0.00944371\n",
      "[6245]\ttraining's binary_logloss: 0.00944276\n",
      "[6246]\ttraining's binary_logloss: 0.009442\n",
      "[6247]\ttraining's binary_logloss: 0.00944112\n",
      "[6248]\ttraining's binary_logloss: 0.00944018\n",
      "[6249]\ttraining's binary_logloss: 0.00943923\n",
      "[6250]\ttraining's binary_logloss: 0.00943887\n",
      "[6251]\ttraining's binary_logloss: 0.00943852\n",
      "[6252]\ttraining's binary_logloss: 0.00943756\n",
      "[6253]\ttraining's binary_logloss: 0.00943681\n",
      "[6254]\ttraining's binary_logloss: 0.00943607\n",
      "[6255]\ttraining's binary_logloss: 0.00943516\n",
      "[6256]\ttraining's binary_logloss: 0.00943478\n",
      "[6257]\ttraining's binary_logloss: 0.00943399\n",
      "[6258]\ttraining's binary_logloss: 0.00943318\n",
      "[6259]\ttraining's binary_logloss: 0.00943217\n",
      "[6260]\ttraining's binary_logloss: 0.00943147\n",
      "[6261]\ttraining's binary_logloss: 0.0094308\n",
      "[6262]\ttraining's binary_logloss: 0.00942962\n",
      "[6263]\ttraining's binary_logloss: 0.00942886\n",
      "[6264]\ttraining's binary_logloss: 0.00942785\n",
      "[6265]\ttraining's binary_logloss: 0.00942746\n",
      "[6266]\ttraining's binary_logloss: 0.00942659\n",
      "[6267]\ttraining's binary_logloss: 0.00942622\n",
      "[6268]\ttraining's binary_logloss: 0.0094256\n",
      "[6269]\ttraining's binary_logloss: 0.00942523\n",
      "[6270]\ttraining's binary_logloss: 0.00942483\n",
      "[6271]\ttraining's binary_logloss: 0.00942447\n",
      "[6272]\ttraining's binary_logloss: 0.00942407\n",
      "[6273]\ttraining's binary_logloss: 0.00942371\n",
      "[6274]\ttraining's binary_logloss: 0.0094233\n",
      "[6275]\ttraining's binary_logloss: 0.00942293\n",
      "[6276]\ttraining's binary_logloss: 0.00942254\n",
      "[6277]\ttraining's binary_logloss: 0.00942136\n",
      "[6278]\ttraining's binary_logloss: 0.00942023\n",
      "[6279]\ttraining's binary_logloss: 0.0094193\n",
      "[6280]\ttraining's binary_logloss: 0.0094184\n",
      "[6281]\ttraining's binary_logloss: 0.00941745\n",
      "[6282]\ttraining's binary_logloss: 0.00941674\n",
      "[6283]\ttraining's binary_logloss: 0.00941592\n",
      "[6284]\ttraining's binary_logloss: 0.00941478\n",
      "[6285]\ttraining's binary_logloss: 0.00941407\n",
      "[6286]\ttraining's binary_logloss: 0.00941337\n",
      "[6287]\ttraining's binary_logloss: 0.00941223\n",
      "[6288]\ttraining's binary_logloss: 0.00941126\n",
      "[6289]\ttraining's binary_logloss: 0.00941047\n",
      "[6290]\ttraining's binary_logloss: 0.00940972\n",
      "[6291]\ttraining's binary_logloss: 0.00940935\n",
      "[6292]\ttraining's binary_logloss: 0.00940827\n",
      "[6293]\ttraining's binary_logloss: 0.00940755\n",
      "[6294]\ttraining's binary_logloss: 0.00940719\n",
      "[6295]\ttraining's binary_logloss: 0.00940678\n",
      "[6296]\ttraining's binary_logloss: 0.00940641\n",
      "[6297]\ttraining's binary_logloss: 0.00940602\n",
      "[6298]\ttraining's binary_logloss: 0.00940566\n",
      "[6299]\ttraining's binary_logloss: 0.00940505\n",
      "[6300]\ttraining's binary_logloss: 0.00940382\n",
      "[6301]\ttraining's binary_logloss: 0.00940345\n",
      "[6302]\ttraining's binary_logloss: 0.00940247\n",
      "[6303]\ttraining's binary_logloss: 0.00940154\n",
      "[6304]\ttraining's binary_logloss: 0.00940076\n",
      "[6305]\ttraining's binary_logloss: 0.00939966\n",
      "[6306]\ttraining's binary_logloss: 0.0093991\n",
      "[6307]\ttraining's binary_logloss: 0.00939827\n",
      "[6308]\ttraining's binary_logloss: 0.00939741\n",
      "[6309]\ttraining's binary_logloss: 0.00939664\n",
      "[6310]\ttraining's binary_logloss: 0.00939628\n",
      "[6311]\ttraining's binary_logloss: 0.00939521\n",
      "[6312]\ttraining's binary_logloss: 0.00939398\n",
      "[6313]\ttraining's binary_logloss: 0.00939271\n",
      "[6314]\ttraining's binary_logloss: 0.00939225\n",
      "[6315]\ttraining's binary_logloss: 0.0093919\n",
      "[6316]\ttraining's binary_logloss: 0.00939112\n",
      "[6317]\ttraining's binary_logloss: 0.00939009\n",
      "[6318]\ttraining's binary_logloss: 0.00938926\n",
      "[6319]\ttraining's binary_logloss: 0.00938863\n",
      "[6320]\ttraining's binary_logloss: 0.00938771\n",
      "[6321]\ttraining's binary_logloss: 0.00938685\n",
      "[6322]\ttraining's binary_logloss: 0.00938612\n",
      "[6323]\ttraining's binary_logloss: 0.00938576\n",
      "[6324]\ttraining's binary_logloss: 0.00938481\n",
      "[6325]\ttraining's binary_logloss: 0.00938441\n",
      "[6326]\ttraining's binary_logloss: 0.00938357\n",
      "[6327]\ttraining's binary_logloss: 0.0093825\n",
      "[6328]\ttraining's binary_logloss: 0.00938095\n",
      "[6329]\ttraining's binary_logloss: 0.00937985\n",
      "[6330]\ttraining's binary_logloss: 0.00937916\n",
      "[6331]\ttraining's binary_logloss: 0.00937881\n",
      "[6332]\ttraining's binary_logloss: 0.0093776\n",
      "[6333]\ttraining's binary_logloss: 0.0093769\n",
      "[6334]\ttraining's binary_logloss: 0.00937605\n",
      "[6335]\ttraining's binary_logloss: 0.00937537\n",
      "[6336]\ttraining's binary_logloss: 0.00937432\n",
      "[6337]\ttraining's binary_logloss: 0.00937337\n",
      "[6338]\ttraining's binary_logloss: 0.0093726\n",
      "[6339]\ttraining's binary_logloss: 0.00937222\n",
      "[6340]\ttraining's binary_logloss: 0.00937131\n",
      "[6341]\ttraining's binary_logloss: 0.00937021\n",
      "[6342]\ttraining's binary_logloss: 0.00936918\n",
      "[6343]\ttraining's binary_logloss: 0.00936831\n",
      "[6344]\ttraining's binary_logloss: 0.00936742\n",
      "[6345]\ttraining's binary_logloss: 0.00936704\n",
      "[6346]\ttraining's binary_logloss: 0.00936667\n",
      "[6347]\ttraining's binary_logloss: 0.0093658\n",
      "[6348]\ttraining's binary_logloss: 0.00936513\n",
      "[6349]\ttraining's binary_logloss: 0.00936476\n",
      "[6350]\ttraining's binary_logloss: 0.00936374\n",
      "[6351]\ttraining's binary_logloss: 0.00936303\n",
      "[6352]\ttraining's binary_logloss: 0.00936218\n",
      "[6353]\ttraining's binary_logloss: 0.0093613\n",
      "[6354]\ttraining's binary_logloss: 0.00936057\n",
      "[6355]\ttraining's binary_logloss: 0.00936018\n",
      "[6356]\ttraining's binary_logloss: 0.00935911\n",
      "[6357]\ttraining's binary_logloss: 0.00935843\n",
      "[6358]\ttraining's binary_logloss: 0.00935759\n",
      "[6359]\ttraining's binary_logloss: 0.00935663\n",
      "[6360]\ttraining's binary_logloss: 0.00935562\n",
      "[6361]\ttraining's binary_logloss: 0.00935485\n",
      "[6362]\ttraining's binary_logloss: 0.00935413\n",
      "[6363]\ttraining's binary_logloss: 0.00935376\n",
      "[6364]\ttraining's binary_logloss: 0.00935302\n",
      "[6365]\ttraining's binary_logloss: 0.00935234\n",
      "[6366]\ttraining's binary_logloss: 0.00935124\n",
      "[6367]\ttraining's binary_logloss: 0.0093503\n",
      "[6368]\ttraining's binary_logloss: 0.00934884\n",
      "[6369]\ttraining's binary_logloss: 0.009348\n",
      "[6370]\ttraining's binary_logloss: 0.00934722\n",
      "[6371]\ttraining's binary_logloss: 0.00934631\n",
      "[6372]\ttraining's binary_logloss: 0.00934543\n",
      "[6373]\ttraining's binary_logloss: 0.00934456\n",
      "[6374]\ttraining's binary_logloss: 0.0093442\n",
      "[6375]\ttraining's binary_logloss: 0.00934337\n",
      "[6376]\ttraining's binary_logloss: 0.00934249\n",
      "[6377]\ttraining's binary_logloss: 0.00934209\n",
      "[6378]\ttraining's binary_logloss: 0.00934129\n",
      "[6379]\ttraining's binary_logloss: 0.00934023\n",
      "[6380]\ttraining's binary_logloss: 0.00933955\n",
      "[6381]\ttraining's binary_logloss: 0.00933918\n",
      "[6382]\ttraining's binary_logloss: 0.0093388\n",
      "[6383]\ttraining's binary_logloss: 0.00933805\n",
      "[6384]\ttraining's binary_logloss: 0.00933713\n",
      "[6385]\ttraining's binary_logloss: 0.00933594\n",
      "[6386]\ttraining's binary_logloss: 0.00933504\n",
      "[6387]\ttraining's binary_logloss: 0.00933469\n",
      "[6388]\ttraining's binary_logloss: 0.00933433\n",
      "[6389]\ttraining's binary_logloss: 0.00933365\n",
      "[6390]\ttraining's binary_logloss: 0.00933232\n",
      "[6391]\ttraining's binary_logloss: 0.00933136\n",
      "[6392]\ttraining's binary_logloss: 0.0093304\n",
      "[6393]\ttraining's binary_logloss: 0.0093295\n",
      "[6394]\ttraining's binary_logloss: 0.00932875\n",
      "[6395]\ttraining's binary_logloss: 0.00932831\n",
      "[6396]\ttraining's binary_logloss: 0.00932732\n",
      "[6397]\ttraining's binary_logloss: 0.0093266\n",
      "[6398]\ttraining's binary_logloss: 0.00932564\n",
      "[6399]\ttraining's binary_logloss: 0.00932472\n",
      "[6400]\ttraining's binary_logloss: 0.0093239\n",
      "[6401]\ttraining's binary_logloss: 0.00932275\n",
      "[6402]\ttraining's binary_logloss: 0.00932237\n",
      "[6403]\ttraining's binary_logloss: 0.009322\n",
      "[6404]\ttraining's binary_logloss: 0.0093216\n",
      "[6405]\ttraining's binary_logloss: 0.00932124\n",
      "[6406]\ttraining's binary_logloss: 0.00932086\n",
      "[6407]\ttraining's binary_logloss: 0.0093205\n",
      "[6408]\ttraining's binary_logloss: 0.00931992\n",
      "[6409]\ttraining's binary_logloss: 0.0093191\n",
      "[6410]\ttraining's binary_logloss: 0.00931824\n",
      "[6411]\ttraining's binary_logloss: 0.00931725\n",
      "[6412]\ttraining's binary_logloss: 0.00931633\n",
      "[6413]\ttraining's binary_logloss: 0.00931525\n",
      "[6414]\ttraining's binary_logloss: 0.00931436\n",
      "[6415]\ttraining's binary_logloss: 0.00931402\n",
      "[6416]\ttraining's binary_logloss: 0.00931341\n",
      "[6417]\ttraining's binary_logloss: 0.00931261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6418]\ttraining's binary_logloss: 0.00931174\n",
      "[6419]\ttraining's binary_logloss: 0.00931046\n",
      "[6420]\ttraining's binary_logloss: 0.00930973\n",
      "[6421]\ttraining's binary_logloss: 0.00930889\n",
      "[6422]\ttraining's binary_logloss: 0.00930799\n",
      "[6423]\ttraining's binary_logloss: 0.00930763\n",
      "[6424]\ttraining's binary_logloss: 0.00930725\n",
      "[6425]\ttraining's binary_logloss: 0.00930689\n",
      "[6426]\ttraining's binary_logloss: 0.00930651\n",
      "[6427]\ttraining's binary_logloss: 0.00930615\n",
      "[6428]\ttraining's binary_logloss: 0.00930502\n",
      "[6429]\ttraining's binary_logloss: 0.00930464\n",
      "[6430]\ttraining's binary_logloss: 0.00930364\n",
      "[6431]\ttraining's binary_logloss: 0.0093028\n",
      "[6432]\ttraining's binary_logloss: 0.00930197\n",
      "[6433]\ttraining's binary_logloss: 0.00930136\n",
      "[6434]\ttraining's binary_logloss: 0.00930046\n",
      "[6435]\ttraining's binary_logloss: 0.00930009\n",
      "[6436]\ttraining's binary_logloss: 0.00929922\n",
      "[6437]\ttraining's binary_logloss: 0.00929843\n",
      "[6438]\ttraining's binary_logloss: 0.00929767\n",
      "[6439]\ttraining's binary_logloss: 0.0092973\n",
      "[6440]\ttraining's binary_logloss: 0.00929633\n",
      "[6441]\ttraining's binary_logloss: 0.00929549\n",
      "[6442]\ttraining's binary_logloss: 0.00929455\n",
      "[6443]\ttraining's binary_logloss: 0.00929419\n",
      "[6444]\ttraining's binary_logloss: 0.00929292\n",
      "[6445]\ttraining's binary_logloss: 0.00929219\n",
      "[6446]\ttraining's binary_logloss: 0.00929137\n",
      "[6447]\ttraining's binary_logloss: 0.00929043\n",
      "[6448]\ttraining's binary_logloss: 0.00928967\n",
      "[6449]\ttraining's binary_logloss: 0.0092888\n",
      "[6450]\ttraining's binary_logloss: 0.00928802\n",
      "[6451]\ttraining's binary_logloss: 0.00928698\n",
      "[6452]\ttraining's binary_logloss: 0.00928581\n",
      "[6453]\ttraining's binary_logloss: 0.00928513\n",
      "[6454]\ttraining's binary_logloss: 0.00928402\n",
      "[6455]\ttraining's binary_logloss: 0.00928291\n",
      "[6456]\ttraining's binary_logloss: 0.00928212\n",
      "[6457]\ttraining's binary_logloss: 0.00928176\n",
      "[6458]\ttraining's binary_logloss: 0.00928091\n",
      "[6459]\ttraining's binary_logloss: 0.00927952\n",
      "[6460]\ttraining's binary_logloss: 0.00927918\n",
      "[6461]\ttraining's binary_logloss: 0.00927841\n",
      "[6462]\ttraining's binary_logloss: 0.00927761\n",
      "[6463]\ttraining's binary_logloss: 0.00927677\n",
      "[6464]\ttraining's binary_logloss: 0.00927591\n",
      "[6465]\ttraining's binary_logloss: 0.00927489\n",
      "[6466]\ttraining's binary_logloss: 0.00927409\n",
      "[6467]\ttraining's binary_logloss: 0.00927337\n",
      "[6468]\ttraining's binary_logloss: 0.00927236\n",
      "[6469]\ttraining's binary_logloss: 0.00927117\n",
      "[6470]\ttraining's binary_logloss: 0.00927014\n",
      "[6471]\ttraining's binary_logloss: 0.00926956\n",
      "[6472]\ttraining's binary_logloss: 0.00926845\n",
      "[6473]\ttraining's binary_logloss: 0.00926737\n",
      "[6474]\ttraining's binary_logloss: 0.00926649\n",
      "[6475]\ttraining's binary_logloss: 0.00926613\n",
      "[6476]\ttraining's binary_logloss: 0.00926575\n",
      "[6477]\ttraining's binary_logloss: 0.00926539\n",
      "[6478]\ttraining's binary_logloss: 0.00926497\n",
      "[6479]\ttraining's binary_logloss: 0.00926464\n",
      "[6480]\ttraining's binary_logloss: 0.00926428\n",
      "[6481]\ttraining's binary_logloss: 0.00926391\n",
      "[6482]\ttraining's binary_logloss: 0.00926297\n",
      "[6483]\ttraining's binary_logloss: 0.00926261\n",
      "[6484]\ttraining's binary_logloss: 0.00926178\n",
      "[6485]\ttraining's binary_logloss: 0.00926093\n",
      "[6486]\ttraining's binary_logloss: 0.00926021\n",
      "[6487]\ttraining's binary_logloss: 0.0092592\n",
      "[6488]\ttraining's binary_logloss: 0.00925893\n",
      "[6489]\ttraining's binary_logloss: 0.00925799\n",
      "[6490]\ttraining's binary_logloss: 0.00925704\n",
      "[6491]\ttraining's binary_logloss: 0.00925612\n",
      "[6492]\ttraining's binary_logloss: 0.00925576\n",
      "[6493]\ttraining's binary_logloss: 0.00925539\n",
      "[6494]\ttraining's binary_logloss: 0.00925457\n",
      "[6495]\ttraining's binary_logloss: 0.00925355\n",
      "[6496]\ttraining's binary_logloss: 0.00925287\n",
      "[6497]\ttraining's binary_logloss: 0.0092522\n",
      "[6498]\ttraining's binary_logloss: 0.00925127\n",
      "[6499]\ttraining's binary_logloss: 0.00925091\n",
      "[6500]\ttraining's binary_logloss: 0.00925054\n",
      "[6501]\ttraining's binary_logloss: 0.00924974\n",
      "[6502]\ttraining's binary_logloss: 0.00924861\n",
      "[6503]\ttraining's binary_logloss: 0.00924772\n",
      "[6504]\ttraining's binary_logloss: 0.00924681\n",
      "[6505]\ttraining's binary_logloss: 0.00924591\n",
      "[6506]\ttraining's binary_logloss: 0.00924518\n",
      "[6507]\ttraining's binary_logloss: 0.00924448\n",
      "[6508]\ttraining's binary_logloss: 0.00924329\n",
      "[6509]\ttraining's binary_logloss: 0.00924258\n",
      "[6510]\ttraining's binary_logloss: 0.00924222\n",
      "[6511]\ttraining's binary_logloss: 0.00924135\n",
      "[6512]\ttraining's binary_logloss: 0.00924108\n",
      "[6513]\ttraining's binary_logloss: 0.00924073\n",
      "[6514]\ttraining's binary_logloss: 0.00924036\n",
      "[6515]\ttraining's binary_logloss: 0.00923965\n",
      "[6516]\ttraining's binary_logloss: 0.00923868\n",
      "[6517]\ttraining's binary_logloss: 0.009238\n",
      "[6518]\ttraining's binary_logloss: 0.00923658\n",
      "[6519]\ttraining's binary_logloss: 0.00923567\n",
      "[6520]\ttraining's binary_logloss: 0.00923486\n",
      "[6521]\ttraining's binary_logloss: 0.00923452\n",
      "[6522]\ttraining's binary_logloss: 0.00923358\n",
      "[6523]\ttraining's binary_logloss: 0.00923322\n",
      "[6524]\ttraining's binary_logloss: 0.00923235\n",
      "[6525]\ttraining's binary_logloss: 0.00923149\n",
      "[6526]\ttraining's binary_logloss: 0.00923045\n",
      "[6527]\ttraining's binary_logloss: 0.00922959\n",
      "[6528]\ttraining's binary_logloss: 0.00922878\n",
      "[6529]\ttraining's binary_logloss: 0.00922803\n",
      "[6530]\ttraining's binary_logloss: 0.00922713\n",
      "[6531]\ttraining's binary_logloss: 0.00922614\n",
      "[6532]\ttraining's binary_logloss: 0.00922534\n",
      "[6533]\ttraining's binary_logloss: 0.00922433\n",
      "[6534]\ttraining's binary_logloss: 0.00922343\n",
      "[6535]\ttraining's binary_logloss: 0.00922267\n",
      "[6536]\ttraining's binary_logloss: 0.00922166\n",
      "[6537]\ttraining's binary_logloss: 0.00922098\n",
      "[6538]\ttraining's binary_logloss: 0.00921997\n",
      "[6539]\ttraining's binary_logloss: 0.00921928\n",
      "[6540]\ttraining's binary_logloss: 0.00921847\n",
      "[6541]\ttraining's binary_logloss: 0.00921753\n",
      "[6542]\ttraining's binary_logloss: 0.00921685\n",
      "[6543]\ttraining's binary_logloss: 0.00921649\n",
      "[6544]\ttraining's binary_logloss: 0.00921612\n",
      "[6545]\ttraining's binary_logloss: 0.00921524\n",
      "[6546]\ttraining's binary_logloss: 0.00921499\n",
      "[6547]\ttraining's binary_logloss: 0.00921462\n",
      "[6548]\ttraining's binary_logloss: 0.00921426\n",
      "[6549]\ttraining's binary_logloss: 0.00921391\n",
      "[6550]\ttraining's binary_logloss: 0.00921365\n",
      "[6551]\ttraining's binary_logloss: 0.00921293\n",
      "[6552]\ttraining's binary_logloss: 0.00921258\n",
      "[6553]\ttraining's binary_logloss: 0.0092119\n",
      "[6554]\ttraining's binary_logloss: 0.00921083\n",
      "[6555]\ttraining's binary_logloss: 0.00921001\n",
      "[6556]\ttraining's binary_logloss: 0.00920922\n",
      "[6557]\ttraining's binary_logloss: 0.00920842\n",
      "[6558]\ttraining's binary_logloss: 0.00920767\n",
      "[6559]\ttraining's binary_logloss: 0.00920676\n",
      "[6560]\ttraining's binary_logloss: 0.00920598\n",
      "[6561]\ttraining's binary_logloss: 0.00920493\n",
      "[6562]\ttraining's binary_logloss: 0.00920366\n",
      "[6563]\ttraining's binary_logloss: 0.00920284\n",
      "[6564]\ttraining's binary_logloss: 0.00920172\n",
      "[6565]\ttraining's binary_logloss: 0.00920076\n",
      "[6566]\ttraining's binary_logloss: 0.00920003\n",
      "[6567]\ttraining's binary_logloss: 0.00919922\n",
      "[6568]\ttraining's binary_logloss: 0.00919883\n",
      "[6569]\ttraining's binary_logloss: 0.00919782\n",
      "[6570]\ttraining's binary_logloss: 0.00919705\n",
      "[6571]\ttraining's binary_logloss: 0.00919613\n",
      "[6572]\ttraining's binary_logloss: 0.00919578\n",
      "[6573]\ttraining's binary_logloss: 0.009195\n",
      "[6574]\ttraining's binary_logloss: 0.00919409\n",
      "[6575]\ttraining's binary_logloss: 0.00919328\n",
      "[6576]\ttraining's binary_logloss: 0.00919235\n",
      "[6577]\ttraining's binary_logloss: 0.00919147\n",
      "[6578]\ttraining's binary_logloss: 0.00919049\n",
      "[6579]\ttraining's binary_logloss: 0.00918976\n",
      "[6580]\ttraining's binary_logloss: 0.00918903\n",
      "[6581]\ttraining's binary_logloss: 0.00918832\n",
      "[6582]\ttraining's binary_logloss: 0.00918731\n",
      "[6583]\ttraining's binary_logloss: 0.00918624\n",
      "[6584]\ttraining's binary_logloss: 0.00918598\n",
      "[6585]\ttraining's binary_logloss: 0.0091849\n",
      "[6586]\ttraining's binary_logloss: 0.00918403\n",
      "[6587]\ttraining's binary_logloss: 0.00918366\n",
      "[6588]\ttraining's binary_logloss: 0.00918277\n",
      "[6589]\ttraining's binary_logloss: 0.00918187\n",
      "[6590]\ttraining's binary_logloss: 0.00918103\n",
      "[6591]\ttraining's binary_logloss: 0.00918059\n",
      "[6592]\ttraining's binary_logloss: 0.00917989\n",
      "[6593]\ttraining's binary_logloss: 0.00917914\n",
      "[6594]\ttraining's binary_logloss: 0.00917827\n",
      "[6595]\ttraining's binary_logloss: 0.0091773\n",
      "[6596]\ttraining's binary_logloss: 0.00917656\n",
      "[6597]\ttraining's binary_logloss: 0.00917581\n",
      "[6598]\ttraining's binary_logloss: 0.00917556\n",
      "[6599]\ttraining's binary_logloss: 0.0091752\n",
      "[6600]\ttraining's binary_logloss: 0.00917484\n",
      "[6601]\ttraining's binary_logloss: 0.00917448\n",
      "[6602]\ttraining's binary_logloss: 0.00917422\n",
      "[6603]\ttraining's binary_logloss: 0.00917387\n",
      "[6604]\ttraining's binary_logloss: 0.00917351\n",
      "[6605]\ttraining's binary_logloss: 0.00917247\n",
      "[6606]\ttraining's binary_logloss: 0.00917146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6607]\ttraining's binary_logloss: 0.00917074\n",
      "[6608]\ttraining's binary_logloss: 0.00917017\n",
      "[6609]\ttraining's binary_logloss: 0.00916942\n",
      "[6610]\ttraining's binary_logloss: 0.00916871\n",
      "[6611]\ttraining's binary_logloss: 0.0091678\n",
      "[6612]\ttraining's binary_logloss: 0.00916711\n",
      "[6613]\ttraining's binary_logloss: 0.00916616\n",
      "[6614]\ttraining's binary_logloss: 0.00916552\n",
      "[6615]\ttraining's binary_logloss: 0.00916459\n",
      "[6616]\ttraining's binary_logloss: 0.00916361\n",
      "[6617]\ttraining's binary_logloss: 0.00916279\n",
      "[6618]\ttraining's binary_logloss: 0.00916244\n",
      "[6619]\ttraining's binary_logloss: 0.00916218\n",
      "[6620]\ttraining's binary_logloss: 0.00916146\n",
      "[6621]\ttraining's binary_logloss: 0.00916111\n",
      "[6622]\ttraining's binary_logloss: 0.00916074\n",
      "[6623]\ttraining's binary_logloss: 0.00916003\n",
      "[6624]\ttraining's binary_logloss: 0.00915967\n",
      "[6625]\ttraining's binary_logloss: 0.00915942\n",
      "[6626]\ttraining's binary_logloss: 0.00915906\n",
      "[6627]\ttraining's binary_logloss: 0.0091587\n",
      "[6628]\ttraining's binary_logloss: 0.00915792\n",
      "[6629]\ttraining's binary_logloss: 0.00915696\n",
      "[6630]\ttraining's binary_logloss: 0.0091564\n",
      "[6631]\ttraining's binary_logloss: 0.00915568\n",
      "[6632]\ttraining's binary_logloss: 0.00915483\n",
      "[6633]\ttraining's binary_logloss: 0.009154\n",
      "[6634]\ttraining's binary_logloss: 0.00915357\n",
      "[6635]\ttraining's binary_logloss: 0.00915322\n",
      "[6636]\ttraining's binary_logloss: 0.00915297\n",
      "[6637]\ttraining's binary_logloss: 0.00915265\n",
      "[6638]\ttraining's binary_logloss: 0.00915172\n",
      "[6639]\ttraining's binary_logloss: 0.00915137\n",
      "[6640]\ttraining's binary_logloss: 0.00915062\n",
      "[6641]\ttraining's binary_logloss: 0.00914969\n",
      "[6642]\ttraining's binary_logloss: 0.009149\n",
      "[6643]\ttraining's binary_logloss: 0.00914823\n",
      "[6644]\ttraining's binary_logloss: 0.00914743\n",
      "[6645]\ttraining's binary_logloss: 0.0091467\n",
      "[6646]\ttraining's binary_logloss: 0.00914634\n",
      "[6647]\ttraining's binary_logloss: 0.00914563\n",
      "[6648]\ttraining's binary_logloss: 0.00914528\n",
      "[6649]\ttraining's binary_logloss: 0.00914437\n",
      "[6650]\ttraining's binary_logloss: 0.00914359\n",
      "[6651]\ttraining's binary_logloss: 0.00914307\n",
      "[6652]\ttraining's binary_logloss: 0.00914272\n",
      "[6653]\ttraining's binary_logloss: 0.00914236\n",
      "[6654]\ttraining's binary_logloss: 0.00914202\n",
      "[6655]\ttraining's binary_logloss: 0.00914166\n",
      "[6656]\ttraining's binary_logloss: 0.00914131\n",
      "[6657]\ttraining's binary_logloss: 0.00914106\n",
      "[6658]\ttraining's binary_logloss: 0.00914071\n",
      "[6659]\ttraining's binary_logloss: 0.00914045\n",
      "[6660]\ttraining's binary_logloss: 0.00913926\n",
      "[6661]\ttraining's binary_logloss: 0.00913847\n",
      "[6662]\ttraining's binary_logloss: 0.00913764\n",
      "[6663]\ttraining's binary_logloss: 0.00913678\n",
      "[6664]\ttraining's binary_logloss: 0.00913644\n",
      "[6665]\ttraining's binary_logloss: 0.00913558\n",
      "[6666]\ttraining's binary_logloss: 0.00913482\n",
      "[6667]\ttraining's binary_logloss: 0.00913391\n",
      "[6668]\ttraining's binary_logloss: 0.00913264\n",
      "[6669]\ttraining's binary_logloss: 0.00913175\n",
      "[6670]\ttraining's binary_logloss: 0.00913095\n",
      "[6671]\ttraining's binary_logloss: 0.00913026\n",
      "[6672]\ttraining's binary_logloss: 0.00912989\n",
      "[6673]\ttraining's binary_logloss: 0.00912918\n",
      "[6674]\ttraining's binary_logloss: 0.00912853\n",
      "[6675]\ttraining's binary_logloss: 0.00912781\n",
      "[6676]\ttraining's binary_logloss: 0.00912746\n",
      "[6677]\ttraining's binary_logloss: 0.00912645\n",
      "[6678]\ttraining's binary_logloss: 0.00912563\n",
      "[6679]\ttraining's binary_logloss: 0.00912492\n",
      "[6680]\ttraining's binary_logloss: 0.0091241\n",
      "[6681]\ttraining's binary_logloss: 0.0091231\n",
      "[6682]\ttraining's binary_logloss: 0.00912274\n",
      "[6683]\ttraining's binary_logloss: 0.0091224\n",
      "[6684]\ttraining's binary_logloss: 0.00912214\n",
      "[6685]\ttraining's binary_logloss: 0.00912132\n",
      "[6686]\ttraining's binary_logloss: 0.00912038\n",
      "[6687]\ttraining's binary_logloss: 0.00911964\n",
      "[6688]\ttraining's binary_logloss: 0.00911873\n",
      "[6689]\ttraining's binary_logloss: 0.00911791\n",
      "[6690]\ttraining's binary_logloss: 0.00911707\n",
      "[6691]\ttraining's binary_logloss: 0.00911628\n",
      "[6692]\ttraining's binary_logloss: 0.00911552\n",
      "[6693]\ttraining's binary_logloss: 0.00911482\n",
      "[6694]\ttraining's binary_logloss: 0.00911394\n",
      "[6695]\ttraining's binary_logloss: 0.0091132\n",
      "[6696]\ttraining's binary_logloss: 0.00911275\n",
      "[6697]\ttraining's binary_logloss: 0.00911168\n",
      "[6698]\ttraining's binary_logloss: 0.0091107\n",
      "[6699]\ttraining's binary_logloss: 0.00910995\n",
      "[6700]\ttraining's binary_logloss: 0.00910961\n",
      "[6701]\ttraining's binary_logloss: 0.00910867\n",
      "[6702]\ttraining's binary_logloss: 0.00910781\n",
      "[6703]\ttraining's binary_logloss: 0.0091075\n",
      "[6704]\ttraining's binary_logloss: 0.00910681\n",
      "[6705]\ttraining's binary_logloss: 0.00910599\n",
      "[6706]\ttraining's binary_logloss: 0.00910525\n",
      "[6707]\ttraining's binary_logloss: 0.00910451\n",
      "[6708]\ttraining's binary_logloss: 0.00910365\n",
      "[6709]\ttraining's binary_logloss: 0.00910185\n",
      "[6710]\ttraining's binary_logloss: 0.00910106\n",
      "[6711]\ttraining's binary_logloss: 0.00910016\n",
      "[6712]\ttraining's binary_logloss: 0.00909937\n",
      "[6713]\ttraining's binary_logloss: 0.0090987\n",
      "[6714]\ttraining's binary_logloss: 0.00909773\n",
      "[6715]\ttraining's binary_logloss: 0.00909686\n",
      "[6716]\ttraining's binary_logloss: 0.00909569\n",
      "[6717]\ttraining's binary_logloss: 0.00909482\n",
      "[6718]\ttraining's binary_logloss: 0.00909402\n",
      "[6719]\ttraining's binary_logloss: 0.00909313\n",
      "[6720]\ttraining's binary_logloss: 0.00909282\n",
      "[6721]\ttraining's binary_logloss: 0.00909229\n",
      "[6722]\ttraining's binary_logloss: 0.0090915\n",
      "[6723]\ttraining's binary_logloss: 0.00909064\n",
      "[6724]\ttraining's binary_logloss: 0.00909033\n",
      "[6725]\ttraining's binary_logloss: 0.00908946\n",
      "[6726]\ttraining's binary_logloss: 0.00908906\n",
      "[6727]\ttraining's binary_logloss: 0.00908868\n",
      "[6728]\ttraining's binary_logloss: 0.00908843\n",
      "[6729]\ttraining's binary_logloss: 0.00908808\n",
      "[6730]\ttraining's binary_logloss: 0.00908731\n",
      "[6731]\ttraining's binary_logloss: 0.00908695\n",
      "[6732]\ttraining's binary_logloss: 0.00908661\n",
      "[6733]\ttraining's binary_logloss: 0.00908635\n",
      "[6734]\ttraining's binary_logloss: 0.00908601\n",
      "[6735]\ttraining's binary_logloss: 0.00908565\n",
      "[6736]\ttraining's binary_logloss: 0.00908485\n",
      "[6737]\ttraining's binary_logloss: 0.00908419\n",
      "[6738]\ttraining's binary_logloss: 0.00908331\n",
      "[6739]\ttraining's binary_logloss: 0.00908243\n",
      "[6740]\ttraining's binary_logloss: 0.00908209\n",
      "[6741]\ttraining's binary_logloss: 0.00908184\n",
      "[6742]\ttraining's binary_logloss: 0.0090815\n",
      "[6743]\ttraining's binary_logloss: 0.00908124\n",
      "[6744]\ttraining's binary_logloss: 0.0090809\n",
      "[6745]\ttraining's binary_logloss: 0.00908055\n",
      "[6746]\ttraining's binary_logloss: 0.00908021\n",
      "[6747]\ttraining's binary_logloss: 0.00907995\n",
      "[6748]\ttraining's binary_logloss: 0.00907917\n",
      "[6749]\ttraining's binary_logloss: 0.00907848\n",
      "[6750]\ttraining's binary_logloss: 0.00907814\n",
      "[6751]\ttraining's binary_logloss: 0.00907744\n",
      "[6752]\ttraining's binary_logloss: 0.00907683\n",
      "[6753]\ttraining's binary_logloss: 0.00907647\n",
      "[6754]\ttraining's binary_logloss: 0.0090758\n",
      "[6755]\ttraining's binary_logloss: 0.00907503\n",
      "[6756]\ttraining's binary_logloss: 0.00907469\n",
      "[6757]\ttraining's binary_logloss: 0.00907404\n",
      "[6758]\ttraining's binary_logloss: 0.00907291\n",
      "[6759]\ttraining's binary_logloss: 0.00907167\n",
      "[6760]\ttraining's binary_logloss: 0.00907071\n",
      "[6761]\ttraining's binary_logloss: 0.00906985\n",
      "[6762]\ttraining's binary_logloss: 0.00906959\n",
      "[6763]\ttraining's binary_logloss: 0.00906881\n",
      "[6764]\ttraining's binary_logloss: 0.00906775\n",
      "[6765]\ttraining's binary_logloss: 0.00906688\n",
      "[6766]\ttraining's binary_logloss: 0.00906608\n",
      "[6767]\ttraining's binary_logloss: 0.00906572\n",
      "[6768]\ttraining's binary_logloss: 0.00906498\n",
      "[6769]\ttraining's binary_logloss: 0.00906377\n",
      "[6770]\ttraining's binary_logloss: 0.00906268\n",
      "[6771]\ttraining's binary_logloss: 0.00906229\n",
      "[6772]\ttraining's binary_logloss: 0.00906159\n",
      "[6773]\ttraining's binary_logloss: 0.00906081\n",
      "[6774]\ttraining's binary_logloss: 0.00906\n",
      "[6775]\ttraining's binary_logloss: 0.00905928\n",
      "[6776]\ttraining's binary_logloss: 0.00905894\n",
      "[6777]\ttraining's binary_logloss: 0.00905809\n",
      "[6778]\ttraining's binary_logloss: 0.00905725\n",
      "[6779]\ttraining's binary_logloss: 0.0090569\n",
      "[6780]\ttraining's binary_logloss: 0.00905595\n",
      "[6781]\ttraining's binary_logloss: 0.0090556\n",
      "[6782]\ttraining's binary_logloss: 0.00905481\n",
      "[6783]\ttraining's binary_logloss: 0.00905415\n",
      "[6784]\ttraining's binary_logloss: 0.00905351\n",
      "[6785]\ttraining's binary_logloss: 0.00905254\n",
      "[6786]\ttraining's binary_logloss: 0.00905142\n",
      "[6787]\ttraining's binary_logloss: 0.00905055\n",
      "[6788]\ttraining's binary_logloss: 0.0090502\n",
      "[6789]\ttraining's binary_logloss: 0.00904986\n",
      "[6790]\ttraining's binary_logloss: 0.00904908\n",
      "[6791]\ttraining's binary_logloss: 0.00904814\n",
      "[6792]\ttraining's binary_logloss: 0.00904775\n",
      "[6793]\ttraining's binary_logloss: 0.00904705\n",
      "[6794]\ttraining's binary_logloss: 0.00904681\n",
      "[6795]\ttraining's binary_logloss: 0.00904646\n",
      "[6796]\ttraining's binary_logloss: 0.00904611\n",
      "[6797]\ttraining's binary_logloss: 0.00904577\n",
      "[6798]\ttraining's binary_logloss: 0.00904553\n",
      "[6799]\ttraining's binary_logloss: 0.00904519\n",
      "[6800]\ttraining's binary_logloss: 0.00904469\n",
      "[6801]\ttraining's binary_logloss: 0.00904436\n",
      "[6802]\ttraining's binary_logloss: 0.00904401\n",
      "[6803]\ttraining's binary_logloss: 0.00904323\n",
      "[6804]\ttraining's binary_logloss: 0.0090429\n",
      "[6805]\ttraining's binary_logloss: 0.00904255\n",
      "[6806]\ttraining's binary_logloss: 0.0090417\n",
      "[6807]\ttraining's binary_logloss: 0.009041\n",
      "[6808]\ttraining's binary_logloss: 0.00904066\n",
      "[6809]\ttraining's binary_logloss: 0.00903975\n",
      "[6810]\ttraining's binary_logloss: 0.00903882\n",
      "[6811]\ttraining's binary_logloss: 0.00903813\n",
      "[6812]\ttraining's binary_logloss: 0.00903751\n",
      "[6813]\ttraining's binary_logloss: 0.00903651\n",
      "[6814]\ttraining's binary_logloss: 0.00903618\n",
      "[6815]\ttraining's binary_logloss: 0.00903554\n",
      "[6816]\ttraining's binary_logloss: 0.00903455\n",
      "[6817]\ttraining's binary_logloss: 0.00903367\n",
      "[6818]\ttraining's binary_logloss: 0.00903246\n",
      "[6819]\ttraining's binary_logloss: 0.00903169\n",
      "[6820]\ttraining's binary_logloss: 0.00903099\n",
      "[6821]\ttraining's binary_logloss: 0.00903047\n",
      "[6822]\ttraining's binary_logloss: 0.00902957\n",
      "[6823]\ttraining's binary_logloss: 0.00902872\n",
      "[6824]\ttraining's binary_logloss: 0.00902787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6825]\ttraining's binary_logloss: 0.00902707\n",
      "[6826]\ttraining's binary_logloss: 0.00902641\n",
      "[6827]\ttraining's binary_logloss: 0.00902611\n",
      "[6828]\ttraining's binary_logloss: 0.00902508\n",
      "[6829]\ttraining's binary_logloss: 0.00902401\n",
      "[6830]\ttraining's binary_logloss: 0.00902307\n",
      "[6831]\ttraining's binary_logloss: 0.00902223\n",
      "[6832]\ttraining's binary_logloss: 0.00902144\n",
      "[6833]\ttraining's binary_logloss: 0.00902102\n",
      "[6834]\ttraining's binary_logloss: 0.00902024\n",
      "[6835]\ttraining's binary_logloss: 0.00901927\n",
      "[6836]\ttraining's binary_logloss: 0.00901887\n",
      "[6837]\ttraining's binary_logloss: 0.0090185\n",
      "[6838]\ttraining's binary_logloss: 0.00901816\n",
      "[6839]\ttraining's binary_logloss: 0.00901791\n",
      "[6840]\ttraining's binary_logloss: 0.00901752\n",
      "[6841]\ttraining's binary_logloss: 0.00901719\n",
      "[6842]\ttraining's binary_logloss: 0.00901694\n",
      "[6843]\ttraining's binary_logloss: 0.00901661\n",
      "[6844]\ttraining's binary_logloss: 0.00901636\n",
      "[6845]\ttraining's binary_logloss: 0.00901549\n",
      "[6846]\ttraining's binary_logloss: 0.00901474\n",
      "[6847]\ttraining's binary_logloss: 0.00901396\n",
      "[6848]\ttraining's binary_logloss: 0.00901332\n",
      "[6849]\ttraining's binary_logloss: 0.00901246\n",
      "[6850]\ttraining's binary_logloss: 0.00901144\n",
      "[6851]\ttraining's binary_logloss: 0.00901053\n",
      "[6852]\ttraining's binary_logloss: 0.00900977\n",
      "[6853]\ttraining's binary_logloss: 0.00900905\n",
      "[6854]\ttraining's binary_logloss: 0.00900813\n",
      "[6855]\ttraining's binary_logloss: 0.00900783\n",
      "[6856]\ttraining's binary_logloss: 0.00900705\n",
      "[6857]\ttraining's binary_logloss: 0.00900603\n",
      "[6858]\ttraining's binary_logloss: 0.00900522\n",
      "[6859]\ttraining's binary_logloss: 0.00900452\n",
      "[6860]\ttraining's binary_logloss: 0.0090038\n",
      "[6861]\ttraining's binary_logloss: 0.00900292\n",
      "[6862]\ttraining's binary_logloss: 0.00900207\n",
      "[6863]\ttraining's binary_logloss: 0.0090017\n",
      "[6864]\ttraining's binary_logloss: 0.00900067\n",
      "[6865]\ttraining's binary_logloss: 0.00899951\n",
      "[6866]\ttraining's binary_logloss: 0.00899879\n",
      "[6867]\ttraining's binary_logloss: 0.00899795\n",
      "[6868]\ttraining's binary_logloss: 0.00899708\n",
      "[6869]\ttraining's binary_logloss: 0.00899611\n",
      "[6870]\ttraining's binary_logloss: 0.00899544\n",
      "[6871]\ttraining's binary_logloss: 0.00899461\n",
      "[6872]\ttraining's binary_logloss: 0.00899397\n",
      "[6873]\ttraining's binary_logloss: 0.00899276\n",
      "[6874]\ttraining's binary_logloss: 0.00899172\n",
      "[6875]\ttraining's binary_logloss: 0.008991\n",
      "[6876]\ttraining's binary_logloss: 0.00899057\n",
      "[6877]\ttraining's binary_logloss: 0.00898959\n",
      "[6878]\ttraining's binary_logloss: 0.00898887\n",
      "[6879]\ttraining's binary_logloss: 0.00898815\n",
      "[6880]\ttraining's binary_logloss: 0.00898732\n",
      "[6881]\ttraining's binary_logloss: 0.00898655\n",
      "[6882]\ttraining's binary_logloss: 0.00898625\n",
      "[6883]\ttraining's binary_logloss: 0.00898556\n",
      "[6884]\ttraining's binary_logloss: 0.00898476\n",
      "[6885]\ttraining's binary_logloss: 0.00898439\n",
      "[6886]\ttraining's binary_logloss: 0.00898404\n",
      "[6887]\ttraining's binary_logloss: 0.00898371\n",
      "[6888]\ttraining's binary_logloss: 0.00898346\n",
      "[6889]\ttraining's binary_logloss: 0.00898313\n",
      "[6890]\ttraining's binary_logloss: 0.00898278\n",
      "[6891]\ttraining's binary_logloss: 0.00898196\n",
      "[6892]\ttraining's binary_logloss: 0.00898163\n",
      "[6893]\ttraining's binary_logloss: 0.00898138\n",
      "[6894]\ttraining's binary_logloss: 0.00898105\n",
      "[6895]\ttraining's binary_logloss: 0.00898081\n",
      "[6896]\ttraining's binary_logloss: 0.00898006\n",
      "[6897]\ttraining's binary_logloss: 0.00897973\n",
      "[6898]\ttraining's binary_logloss: 0.00897864\n",
      "[6899]\ttraining's binary_logloss: 0.00897829\n",
      "[6900]\ttraining's binary_logloss: 0.00897797\n",
      "[6901]\ttraining's binary_logloss: 0.00897716\n",
      "[6902]\ttraining's binary_logloss: 0.0089764\n",
      "[6903]\ttraining's binary_logloss: 0.00897596\n",
      "[6904]\ttraining's binary_logloss: 0.00897555\n",
      "[6905]\ttraining's binary_logloss: 0.00897472\n",
      "[6906]\ttraining's binary_logloss: 0.00897409\n",
      "[6907]\ttraining's binary_logloss: 0.00897309\n",
      "[6908]\ttraining's binary_logloss: 0.00897273\n",
      "[6909]\ttraining's binary_logloss: 0.00897099\n",
      "[6910]\ttraining's binary_logloss: 0.00897017\n",
      "[6911]\ttraining's binary_logloss: 0.00896939\n",
      "[6912]\ttraining's binary_logloss: 0.00896865\n",
      "[6913]\ttraining's binary_logloss: 0.00896825\n",
      "[6914]\ttraining's binary_logloss: 0.00896761\n",
      "[6915]\ttraining's binary_logloss: 0.00896687\n",
      "[6916]\ttraining's binary_logloss: 0.00896586\n",
      "[6917]\ttraining's binary_logloss: 0.00896518\n",
      "[6918]\ttraining's binary_logloss: 0.00896485\n",
      "[6919]\ttraining's binary_logloss: 0.0089646\n",
      "[6920]\ttraining's binary_logloss: 0.00896384\n",
      "[6921]\ttraining's binary_logloss: 0.00896285\n",
      "[6922]\ttraining's binary_logloss: 0.00896207\n",
      "[6923]\ttraining's binary_logloss: 0.00896101\n",
      "[6924]\ttraining's binary_logloss: 0.00896027\n",
      "[6925]\ttraining's binary_logloss: 0.00895944\n",
      "[6926]\ttraining's binary_logloss: 0.00895853\n",
      "[6927]\ttraining's binary_logloss: 0.00895817\n",
      "[6928]\ttraining's binary_logloss: 0.00895784\n",
      "[6929]\ttraining's binary_logloss: 0.00895759\n",
      "[6930]\ttraining's binary_logloss: 0.00895726\n",
      "[6931]\ttraining's binary_logloss: 0.00895701\n",
      "[6932]\ttraining's binary_logloss: 0.00895669\n",
      "[6933]\ttraining's binary_logloss: 0.00895634\n",
      "[6934]\ttraining's binary_logloss: 0.00895602\n",
      "[6935]\ttraining's binary_logloss: 0.00895577\n",
      "[6936]\ttraining's binary_logloss: 0.00895545\n",
      "[6937]\ttraining's binary_logloss: 0.0089551\n",
      "[6938]\ttraining's binary_logloss: 0.00895443\n",
      "[6939]\ttraining's binary_logloss: 0.00895374\n",
      "[6940]\ttraining's binary_logloss: 0.00895342\n",
      "[6941]\ttraining's binary_logloss: 0.00895307\n",
      "[6942]\ttraining's binary_logloss: 0.00895226\n",
      "[6943]\ttraining's binary_logloss: 0.00895144\n",
      "[6944]\ttraining's binary_logloss: 0.00895067\n",
      "[6945]\ttraining's binary_logloss: 0.0089497\n",
      "[6946]\ttraining's binary_logloss: 0.0089487\n",
      "[6947]\ttraining's binary_logloss: 0.00894832\n",
      "[6948]\ttraining's binary_logloss: 0.00894795\n",
      "[6949]\ttraining's binary_logloss: 0.00894722\n",
      "[6950]\ttraining's binary_logloss: 0.00894618\n",
      "[6951]\ttraining's binary_logloss: 0.00894512\n",
      "[6952]\ttraining's binary_logloss: 0.00894412\n",
      "[6953]\ttraining's binary_logloss: 0.00894339\n",
      "[6954]\ttraining's binary_logloss: 0.00894299\n",
      "[6955]\ttraining's binary_logloss: 0.00894264\n",
      "[6956]\ttraining's binary_logloss: 0.00894199\n",
      "[6957]\ttraining's binary_logloss: 0.00894126\n",
      "[6958]\ttraining's binary_logloss: 0.00894046\n",
      "[6959]\ttraining's binary_logloss: 0.00894016\n",
      "[6960]\ttraining's binary_logloss: 0.00893917\n",
      "[6961]\ttraining's binary_logloss: 0.00893845\n",
      "[6962]\ttraining's binary_logloss: 0.00893809\n",
      "[6963]\ttraining's binary_logloss: 0.00893743\n",
      "[6964]\ttraining's binary_logloss: 0.00893669\n",
      "[6965]\ttraining's binary_logloss: 0.0089356\n",
      "[6966]\ttraining's binary_logloss: 0.00893486\n",
      "[6967]\ttraining's binary_logloss: 0.00893409\n",
      "[6968]\ttraining's binary_logloss: 0.00893366\n",
      "[6969]\ttraining's binary_logloss: 0.0089327\n",
      "[6970]\ttraining's binary_logloss: 0.00893177\n",
      "[6971]\ttraining's binary_logloss: 0.00893103\n",
      "[6972]\ttraining's binary_logloss: 0.00893068\n",
      "[6973]\ttraining's binary_logloss: 0.00892991\n",
      "[6974]\ttraining's binary_logloss: 0.00892901\n",
      "[6975]\ttraining's binary_logloss: 0.00892805\n",
      "[6976]\ttraining's binary_logloss: 0.00892709\n",
      "[6977]\ttraining's binary_logloss: 0.00892644\n",
      "[6978]\ttraining's binary_logloss: 0.0089257\n",
      "[6979]\ttraining's binary_logloss: 0.00892537\n",
      "[6980]\ttraining's binary_logloss: 0.00892491\n",
      "[6981]\ttraining's binary_logloss: 0.00892398\n",
      "[6982]\ttraining's binary_logloss: 0.00892332\n",
      "[6983]\ttraining's binary_logloss: 0.00892257\n",
      "[6984]\ttraining's binary_logloss: 0.00892195\n",
      "[6985]\ttraining's binary_logloss: 0.00892122\n",
      "[6986]\ttraining's binary_logloss: 0.00892036\n",
      "[6987]\ttraining's binary_logloss: 0.00891972\n",
      "[6988]\ttraining's binary_logloss: 0.0089189\n",
      "[6989]\ttraining's binary_logloss: 0.00891828\n",
      "[6990]\ttraining's binary_logloss: 0.00891714\n",
      "[6991]\ttraining's binary_logloss: 0.00891681\n",
      "[6992]\ttraining's binary_logloss: 0.00891647\n",
      "[6993]\ttraining's binary_logloss: 0.00891614\n",
      "[6994]\ttraining's binary_logloss: 0.0089159\n",
      "[6995]\ttraining's binary_logloss: 0.0089152\n",
      "[6996]\ttraining's binary_logloss: 0.0089145\n",
      "[6997]\ttraining's binary_logloss: 0.00891344\n",
      "[6998]\ttraining's binary_logloss: 0.00891311\n",
      "[6999]\ttraining's binary_logloss: 0.00891287\n",
      "[7000]\ttraining's binary_logloss: 0.00891254\n",
      "[7001]\ttraining's binary_logloss: 0.00891174\n",
      "[7002]\ttraining's binary_logloss: 0.00891069\n",
      "[7003]\ttraining's binary_logloss: 0.0089103\n",
      "[7004]\ttraining's binary_logloss: 0.00890997\n",
      "[7005]\ttraining's binary_logloss: 0.00890917\n",
      "[7006]\ttraining's binary_logloss: 0.00890884\n",
      "[7007]\ttraining's binary_logloss: 0.0089086\n",
      "[7008]\ttraining's binary_logloss: 0.00890827\n",
      "[7009]\ttraining's binary_logloss: 0.00890794\n",
      "[7010]\ttraining's binary_logloss: 0.00890707\n",
      "[7011]\ttraining's binary_logloss: 0.00890675\n",
      "[7012]\ttraining's binary_logloss: 0.00890651\n",
      "[7013]\ttraining's binary_logloss: 0.00890609\n",
      "[7014]\ttraining's binary_logloss: 0.00890539\n",
      "[7015]\ttraining's binary_logloss: 0.00890448\n",
      "[7016]\ttraining's binary_logloss: 0.0089037\n",
      "[7017]\ttraining's binary_logloss: 0.00890297\n",
      "[7018]\ttraining's binary_logloss: 0.00890206\n",
      "[7019]\ttraining's binary_logloss: 0.0089014\n",
      "[7020]\ttraining's binary_logloss: 0.00890043\n",
      "[7021]\ttraining's binary_logloss: 0.00889949\n",
      "[7022]\ttraining's binary_logloss: 0.00889887\n",
      "[7023]\ttraining's binary_logloss: 0.00889785\n",
      "[7024]\ttraining's binary_logloss: 0.0088971\n",
      "[7025]\ttraining's binary_logloss: 0.00889678\n",
      "[7026]\ttraining's binary_logloss: 0.00889602\n",
      "[7027]\ttraining's binary_logloss: 0.00889527\n",
      "[7028]\ttraining's binary_logloss: 0.00889458\n",
      "[7029]\ttraining's binary_logloss: 0.00889422\n",
      "[7030]\ttraining's binary_logloss: 0.00889352\n",
      "[7031]\ttraining's binary_logloss: 0.00889278\n",
      "[7032]\ttraining's binary_logloss: 0.00889193\n",
      "[7033]\ttraining's binary_logloss: 0.00889153\n",
      "[7034]\ttraining's binary_logloss: 0.0088906\n",
      "[7035]\ttraining's binary_logloss: 0.00889027\n",
      "[7036]\ttraining's binary_logloss: 0.00888929\n",
      "[7037]\ttraining's binary_logloss: 0.00888858\n",
      "[7038]\ttraining's binary_logloss: 0.00888776\n",
      "[7039]\ttraining's binary_logloss: 0.00888709\n",
      "[7040]\ttraining's binary_logloss: 0.00888633\n",
      "[7041]\ttraining's binary_logloss: 0.00888536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7042]\ttraining's binary_logloss: 0.00888507\n",
      "[7043]\ttraining's binary_logloss: 0.00888432\n",
      "[7044]\ttraining's binary_logloss: 0.00888319\n",
      "[7045]\ttraining's binary_logloss: 0.00888245\n",
      "[7046]\ttraining's binary_logloss: 0.00888169\n",
      "[7047]\ttraining's binary_logloss: 0.00888098\n",
      "[7048]\ttraining's binary_logloss: 0.00888066\n",
      "[7049]\ttraining's binary_logloss: 0.00888033\n",
      "[7050]\ttraining's binary_logloss: 0.00888009\n",
      "[7051]\ttraining's binary_logloss: 0.00887928\n",
      "[7052]\ttraining's binary_logloss: 0.00887854\n",
      "[7053]\ttraining's binary_logloss: 0.00887816\n",
      "[7054]\ttraining's binary_logloss: 0.00887748\n",
      "[7055]\ttraining's binary_logloss: 0.00887671\n",
      "[7056]\ttraining's binary_logloss: 0.00887602\n",
      "[7057]\ttraining's binary_logloss: 0.00887527\n",
      "[7058]\ttraining's binary_logloss: 0.00887456\n",
      "[7059]\ttraining's binary_logloss: 0.00887387\n",
      "[7060]\ttraining's binary_logloss: 0.00887313\n",
      "[7061]\ttraining's binary_logloss: 0.00887217\n",
      "[7062]\ttraining's binary_logloss: 0.00887136\n",
      "[7063]\ttraining's binary_logloss: 0.00887059\n",
      "[7064]\ttraining's binary_logloss: 0.00887027\n",
      "[7065]\ttraining's binary_logloss: 0.00886993\n",
      "[7066]\ttraining's binary_logloss: 0.00886926\n",
      "[7067]\ttraining's binary_logloss: 0.00886894\n",
      "[7068]\ttraining's binary_logloss: 0.00886859\n",
      "[7069]\ttraining's binary_logloss: 0.00886788\n",
      "[7070]\ttraining's binary_logloss: 0.00886709\n",
      "[7071]\ttraining's binary_logloss: 0.00886675\n",
      "[7072]\ttraining's binary_logloss: 0.00886643\n",
      "[7073]\ttraining's binary_logloss: 0.00886619\n",
      "[7074]\ttraining's binary_logloss: 0.00886588\n",
      "[7075]\ttraining's binary_logloss: 0.00886516\n",
      "[7076]\ttraining's binary_logloss: 0.00886482\n",
      "[7077]\ttraining's binary_logloss: 0.00886387\n",
      "[7078]\ttraining's binary_logloss: 0.00886356\n",
      "[7079]\ttraining's binary_logloss: 0.0088628\n",
      "[7080]\ttraining's binary_logloss: 0.00886208\n",
      "[7081]\ttraining's binary_logloss: 0.00886132\n",
      "[7082]\ttraining's binary_logloss: 0.00886071\n",
      "[7083]\ttraining's binary_logloss: 0.00886021\n",
      "[7084]\ttraining's binary_logloss: 0.00885985\n",
      "[7085]\ttraining's binary_logloss: 0.00885817\n",
      "[7086]\ttraining's binary_logloss: 0.00885741\n",
      "[7087]\ttraining's binary_logloss: 0.0088571\n",
      "[7088]\ttraining's binary_logloss: 0.00885685\n",
      "[7089]\ttraining's binary_logloss: 0.00885647\n",
      "[7090]\ttraining's binary_logloss: 0.00885564\n",
      "[7091]\ttraining's binary_logloss: 0.00885533\n",
      "[7092]\ttraining's binary_logloss: 0.00885436\n",
      "[7093]\ttraining's binary_logloss: 0.00885357\n",
      "[7094]\ttraining's binary_logloss: 0.00885282\n",
      "[7095]\ttraining's binary_logloss: 0.00885248\n",
      "[7096]\ttraining's binary_logloss: 0.00885181\n",
      "[7097]\ttraining's binary_logloss: 0.0088511\n",
      "[7098]\ttraining's binary_logloss: 0.00885076\n",
      "[7099]\ttraining's binary_logloss: 0.00884972\n",
      "[7100]\ttraining's binary_logloss: 0.00884938\n",
      "[7101]\ttraining's binary_logloss: 0.00884905\n",
      "[7102]\ttraining's binary_logloss: 0.00884874\n",
      "[7103]\ttraining's binary_logloss: 0.00884783\n",
      "[7104]\ttraining's binary_logloss: 0.00884749\n",
      "[7105]\ttraining's binary_logloss: 0.00884657\n",
      "[7106]\ttraining's binary_logloss: 0.00884576\n",
      "[7107]\ttraining's binary_logloss: 0.00884545\n",
      "[7108]\ttraining's binary_logloss: 0.00884466\n",
      "[7109]\ttraining's binary_logloss: 0.00884442\n",
      "[7110]\ttraining's binary_logloss: 0.00884404\n",
      "[7111]\ttraining's binary_logloss: 0.00884363\n",
      "[7112]\ttraining's binary_logloss: 0.00884331\n",
      "[7113]\ttraining's binary_logloss: 0.00884298\n",
      "[7114]\ttraining's binary_logloss: 0.00884228\n",
      "[7115]\ttraining's binary_logloss: 0.00884162\n",
      "[7116]\ttraining's binary_logloss: 0.0088409\n",
      "[7117]\ttraining's binary_logloss: 0.00884011\n",
      "[7118]\ttraining's binary_logloss: 0.00883976\n",
      "[7119]\ttraining's binary_logloss: 0.00883945\n",
      "[7120]\ttraining's binary_logloss: 0.00883921\n",
      "[7121]\ttraining's binary_logloss: 0.00883828\n",
      "[7122]\ttraining's binary_logloss: 0.00883754\n",
      "[7123]\ttraining's binary_logloss: 0.00883723\n",
      "[7124]\ttraining's binary_logloss: 0.0088369\n",
      "[7125]\ttraining's binary_logloss: 0.00883623\n",
      "[7126]\ttraining's binary_logloss: 0.00883505\n",
      "[7127]\ttraining's binary_logloss: 0.00883474\n",
      "[7128]\ttraining's binary_logloss: 0.00883403\n",
      "[7129]\ttraining's binary_logloss: 0.00883336\n",
      "[7130]\ttraining's binary_logloss: 0.00883312\n",
      "[7131]\ttraining's binary_logloss: 0.00883281\n",
      "[7132]\ttraining's binary_logloss: 0.00883247\n",
      "[7133]\ttraining's binary_logloss: 0.0088317\n",
      "[7134]\ttraining's binary_logloss: 0.0088308\n",
      "[7135]\ttraining's binary_logloss: 0.00883042\n",
      "[7136]\ttraining's binary_logloss: 0.00883012\n",
      "[7137]\ttraining's binary_logloss: 0.00882988\n",
      "[7138]\ttraining's binary_logloss: 0.00882957\n",
      "[7139]\ttraining's binary_logloss: 0.00882924\n",
      "[7140]\ttraining's binary_logloss: 0.00882889\n",
      "[7141]\ttraining's binary_logloss: 0.00882851\n",
      "[7142]\ttraining's binary_logloss: 0.00882792\n",
      "[7143]\ttraining's binary_logloss: 0.00882729\n",
      "[7144]\ttraining's binary_logloss: 0.00882657\n",
      "[7145]\ttraining's binary_logloss: 0.00882564\n",
      "[7146]\ttraining's binary_logloss: 0.00882479\n",
      "[7147]\ttraining's binary_logloss: 0.00882391\n",
      "[7148]\ttraining's binary_logloss: 0.00882304\n",
      "[7149]\ttraining's binary_logloss: 0.00882224\n",
      "[7150]\ttraining's binary_logloss: 0.00882194\n",
      "[7151]\ttraining's binary_logloss: 0.00882118\n",
      "[7152]\ttraining's binary_logloss: 0.00882049\n",
      "[7153]\ttraining's binary_logloss: 0.00881979\n",
      "[7154]\ttraining's binary_logloss: 0.00881947\n",
      "[7155]\ttraining's binary_logloss: 0.00881912\n",
      "[7156]\ttraining's binary_logloss: 0.0088188\n",
      "[7157]\ttraining's binary_logloss: 0.00881792\n",
      "[7158]\ttraining's binary_logloss: 0.00881715\n",
      "[7159]\ttraining's binary_logloss: 0.00881641\n",
      "[7160]\ttraining's binary_logloss: 0.00881556\n",
      "[7161]\ttraining's binary_logloss: 0.00881491\n",
      "[7162]\ttraining's binary_logloss: 0.00881453\n",
      "[7163]\ttraining's binary_logloss: 0.00881419\n",
      "[7164]\ttraining's binary_logloss: 0.00881305\n",
      "[7165]\ttraining's binary_logloss: 0.00881225\n",
      "[7166]\ttraining's binary_logloss: 0.00881158\n",
      "[7167]\ttraining's binary_logloss: 0.00881087\n",
      "[7168]\ttraining's binary_logloss: 0.00881011\n",
      "[7169]\ttraining's binary_logloss: 0.00880917\n",
      "[7170]\ttraining's binary_logloss: 0.00880888\n",
      "[7171]\ttraining's binary_logloss: 0.00880855\n",
      "[7172]\ttraining's binary_logloss: 0.00880771\n",
      "[7173]\ttraining's binary_logloss: 0.0088074\n",
      "[7174]\ttraining's binary_logloss: 0.00880716\n",
      "[7175]\ttraining's binary_logloss: 0.00880623\n",
      "[7176]\ttraining's binary_logloss: 0.00880593\n",
      "[7177]\ttraining's binary_logloss: 0.00880569\n",
      "[7178]\ttraining's binary_logloss: 0.00880493\n",
      "[7179]\ttraining's binary_logloss: 0.00880401\n",
      "[7180]\ttraining's binary_logloss: 0.00880364\n",
      "[7181]\ttraining's binary_logloss: 0.00880299\n",
      "[7182]\ttraining's binary_logloss: 0.00880177\n",
      "[7183]\ttraining's binary_logloss: 0.00880138\n",
      "[7184]\ttraining's binary_logloss: 0.00880104\n",
      "[7185]\ttraining's binary_logloss: 0.00880034\n",
      "[7186]\ttraining's binary_logloss: 0.00879937\n",
      "[7187]\ttraining's binary_logloss: 0.00879907\n",
      "[7188]\ttraining's binary_logloss: 0.00879845\n",
      "[7189]\ttraining's binary_logloss: 0.00879813\n",
      "[7190]\ttraining's binary_logloss: 0.0087975\n",
      "[7191]\ttraining's binary_logloss: 0.00879669\n",
      "[7192]\ttraining's binary_logloss: 0.00879603\n",
      "[7193]\ttraining's binary_logloss: 0.0087957\n",
      "[7194]\ttraining's binary_logloss: 0.0087954\n",
      "[7195]\ttraining's binary_logloss: 0.0087947\n",
      "[7196]\ttraining's binary_logloss: 0.00879437\n",
      "[7197]\ttraining's binary_logloss: 0.00879406\n",
      "[7198]\ttraining's binary_logloss: 0.00879333\n",
      "[7199]\ttraining's binary_logloss: 0.0087925\n",
      "[7200]\ttraining's binary_logloss: 0.00879217\n",
      "[7201]\ttraining's binary_logloss: 0.00879133\n",
      "[7202]\ttraining's binary_logloss: 0.00879059\n",
      "[7203]\ttraining's binary_logloss: 0.00878968\n",
      "[7204]\ttraining's binary_logloss: 0.0087888\n",
      "[7205]\ttraining's binary_logloss: 0.00878843\n",
      "[7206]\ttraining's binary_logloss: 0.00878755\n",
      "[7207]\ttraining's binary_logloss: 0.00878658\n",
      "[7208]\ttraining's binary_logloss: 0.00878583\n",
      "[7209]\ttraining's binary_logloss: 0.0087851\n",
      "[7210]\ttraining's binary_logloss: 0.00878481\n",
      "[7211]\ttraining's binary_logloss: 0.00878442\n",
      "[7212]\ttraining's binary_logloss: 0.00878419\n",
      "[7213]\ttraining's binary_logloss: 0.00878388\n",
      "[7214]\ttraining's binary_logloss: 0.00878355\n",
      "[7215]\ttraining's binary_logloss: 0.00878325\n",
      "[7216]\ttraining's binary_logloss: 0.00878209\n",
      "[7217]\ttraining's binary_logloss: 0.00878141\n",
      "[7218]\ttraining's binary_logloss: 0.00878111\n",
      "[7219]\ttraining's binary_logloss: 0.00878087\n",
      "[7220]\ttraining's binary_logloss: 0.00877994\n",
      "[7221]\ttraining's binary_logloss: 0.00877923\n",
      "[7222]\ttraining's binary_logloss: 0.00877893\n",
      "[7223]\ttraining's binary_logloss: 0.00877869\n",
      "[7224]\ttraining's binary_logloss: 0.00877839\n",
      "[7225]\ttraining's binary_logloss: 0.00877806\n",
      "[7226]\ttraining's binary_logloss: 0.00877777\n",
      "[7227]\ttraining's binary_logloss: 0.00877753\n",
      "[7228]\ttraining's binary_logloss: 0.0087769\n",
      "[7229]\ttraining's binary_logloss: 0.00877616\n",
      "[7230]\ttraining's binary_logloss: 0.00877574\n",
      "[7231]\ttraining's binary_logloss: 0.00877464\n",
      "[7232]\ttraining's binary_logloss: 0.00877385\n",
      "[7233]\ttraining's binary_logloss: 0.00877311\n",
      "[7234]\ttraining's binary_logloss: 0.00877206\n",
      "[7235]\ttraining's binary_logloss: 0.00877171\n",
      "[7236]\ttraining's binary_logloss: 0.00877135\n",
      "[7237]\ttraining's binary_logloss: 0.00877044\n",
      "[7238]\ttraining's binary_logloss: 0.00876974\n",
      "[7239]\ttraining's binary_logloss: 0.00876946\n",
      "[7240]\ttraining's binary_logloss: 0.00876873\n",
      "[7241]\ttraining's binary_logloss: 0.00876841\n",
      "[7242]\ttraining's binary_logloss: 0.00876775\n",
      "[7243]\ttraining's binary_logloss: 0.00876745\n",
      "[7244]\ttraining's binary_logloss: 0.00876712\n",
      "[7245]\ttraining's binary_logloss: 0.00876644\n",
      "[7246]\ttraining's binary_logloss: 0.00876607\n",
      "[7247]\ttraining's binary_logloss: 0.00876536\n",
      "[7248]\ttraining's binary_logloss: 0.00876463\n",
      "[7249]\ttraining's binary_logloss: 0.00876402\n",
      "[7250]\ttraining's binary_logloss: 0.00876303\n",
      "[7251]\ttraining's binary_logloss: 0.00876215\n",
      "[7252]\ttraining's binary_logloss: 0.00876147\n",
      "[7253]\ttraining's binary_logloss: 0.00876076\n",
      "[7254]\ttraining's binary_logloss: 0.0087599\n",
      "[7255]\ttraining's binary_logloss: 0.00875957\n",
      "[7256]\ttraining's binary_logloss: 0.00875926\n",
      "[7257]\ttraining's binary_logloss: 0.00875896\n",
      "[7258]\ttraining's binary_logloss: 0.00875872\n",
      "[7259]\ttraining's binary_logloss: 0.00875811\n",
      "[7260]\ttraining's binary_logloss: 0.0087574\n",
      "[7261]\ttraining's binary_logloss: 0.00875704\n",
      "[7262]\ttraining's binary_logloss: 0.00875636\n",
      "[7263]\ttraining's binary_logloss: 0.00875528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7264]\ttraining's binary_logloss: 0.00875462\n",
      "[7265]\ttraining's binary_logloss: 0.00875392\n",
      "[7266]\ttraining's binary_logloss: 0.00875297\n",
      "[7267]\ttraining's binary_logloss: 0.00875201\n",
      "[7268]\ttraining's binary_logloss: 0.00875131\n",
      "[7269]\ttraining's binary_logloss: 0.00875104\n",
      "[7270]\ttraining's binary_logloss: 0.00875027\n",
      "[7271]\ttraining's binary_logloss: 0.00874997\n",
      "[7272]\ttraining's binary_logloss: 0.00874921\n",
      "[7273]\ttraining's binary_logloss: 0.00874843\n",
      "[7274]\ttraining's binary_logloss: 0.00874799\n",
      "[7275]\ttraining's binary_logloss: 0.00874766\n",
      "[7276]\ttraining's binary_logloss: 0.00874731\n",
      "[7277]\ttraining's binary_logloss: 0.00874702\n",
      "[7278]\ttraining's binary_logloss: 0.00874669\n",
      "[7279]\ttraining's binary_logloss: 0.0087464\n",
      "[7280]\ttraining's binary_logloss: 0.00874616\n",
      "[7281]\ttraining's binary_logloss: 0.00874584\n",
      "[7282]\ttraining's binary_logloss: 0.0087451\n",
      "[7283]\ttraining's binary_logloss: 0.00874456\n",
      "[7284]\ttraining's binary_logloss: 0.0087442\n",
      "[7285]\ttraining's binary_logloss: 0.00874353\n",
      "[7286]\ttraining's binary_logloss: 0.00874323\n",
      "[7287]\ttraining's binary_logloss: 0.0087429\n",
      "[7288]\ttraining's binary_logloss: 0.00874207\n",
      "[7289]\ttraining's binary_logloss: 0.00874177\n",
      "[7290]\ttraining's binary_logloss: 0.00874154\n",
      "[7291]\ttraining's binary_logloss: 0.00874061\n",
      "[7292]\ttraining's binary_logloss: 0.00873967\n",
      "[7293]\ttraining's binary_logloss: 0.00873894\n",
      "[7294]\ttraining's binary_logloss: 0.00873823\n",
      "[7295]\ttraining's binary_logloss: 0.00873793\n",
      "[7296]\ttraining's binary_logloss: 0.0087372\n",
      "[7297]\ttraining's binary_logloss: 0.00873659\n",
      "[7298]\ttraining's binary_logloss: 0.00873636\n",
      "[7299]\ttraining's binary_logloss: 0.00873607\n",
      "[7300]\ttraining's binary_logloss: 0.00873583\n",
      "[7301]\ttraining's binary_logloss: 0.00873554\n",
      "[7302]\ttraining's binary_logloss: 0.00873522\n",
      "[7303]\ttraining's binary_logloss: 0.00873463\n",
      "[7304]\ttraining's binary_logloss: 0.00873406\n",
      "[7305]\ttraining's binary_logloss: 0.00873318\n",
      "[7306]\ttraining's binary_logloss: 0.00873245\n",
      "[7307]\ttraining's binary_logloss: 0.00873215\n",
      "[7308]\ttraining's binary_logloss: 0.00873148\n",
      "[7309]\ttraining's binary_logloss: 0.00873116\n",
      "[7310]\ttraining's binary_logloss: 0.00873045\n",
      "[7311]\ttraining's binary_logloss: 0.00872979\n",
      "[7312]\ttraining's binary_logloss: 0.00872914\n",
      "[7313]\ttraining's binary_logloss: 0.00872882\n",
      "[7314]\ttraining's binary_logloss: 0.00872806\n",
      "[7315]\ttraining's binary_logloss: 0.00872718\n",
      "[7316]\ttraining's binary_logloss: 0.00872644\n",
      "[7317]\ttraining's binary_logloss: 0.00872612\n",
      "[7318]\ttraining's binary_logloss: 0.00872578\n",
      "[7319]\ttraining's binary_logloss: 0.00872517\n",
      "[7320]\ttraining's binary_logloss: 0.00872476\n",
      "[7321]\ttraining's binary_logloss: 0.00872447\n",
      "[7322]\ttraining's binary_logloss: 0.00872414\n",
      "[7323]\ttraining's binary_logloss: 0.00872354\n",
      "[7324]\ttraining's binary_logloss: 0.00872279\n",
      "[7325]\ttraining's binary_logloss: 0.00872211\n",
      "[7326]\ttraining's binary_logloss: 0.00872126\n",
      "[7327]\ttraining's binary_logloss: 0.00872098\n",
      "[7328]\ttraining's binary_logloss: 0.00872013\n",
      "[7329]\ttraining's binary_logloss: 0.00871913\n",
      "[7330]\ttraining's binary_logloss: 0.00871843\n",
      "[7331]\ttraining's binary_logloss: 0.00871725\n",
      "[7332]\ttraining's binary_logloss: 0.00871691\n",
      "[7333]\ttraining's binary_logloss: 0.00871648\n",
      "[7334]\ttraining's binary_logloss: 0.00871619\n",
      "[7335]\ttraining's binary_logloss: 0.00871527\n",
      "[7336]\ttraining's binary_logloss: 0.0087144\n",
      "[7337]\ttraining's binary_logloss: 0.00871401\n",
      "[7338]\ttraining's binary_logloss: 0.00871369\n",
      "[7339]\ttraining's binary_logloss: 0.00871339\n",
      "[7340]\ttraining's binary_logloss: 0.00871258\n",
      "[7341]\ttraining's binary_logloss: 0.00871187\n",
      "[7342]\ttraining's binary_logloss: 0.00871164\n",
      "[7343]\ttraining's binary_logloss: 0.00871135\n",
      "[7344]\ttraining's binary_logloss: 0.00871112\n",
      "[7345]\ttraining's binary_logloss: 0.00871022\n",
      "[7346]\ttraining's binary_logloss: 0.00870992\n",
      "[7347]\ttraining's binary_logloss: 0.0087096\n",
      "[7348]\ttraining's binary_logloss: 0.00870931\n",
      "[7349]\ttraining's binary_logloss: 0.00870909\n",
      "[7350]\ttraining's binary_logloss: 0.00870874\n",
      "[7351]\ttraining's binary_logloss: 0.00870809\n",
      "[7352]\ttraining's binary_logloss: 0.00870777\n",
      "[7353]\ttraining's binary_logloss: 0.00870687\n",
      "[7354]\ttraining's binary_logloss: 0.00870592\n",
      "[7355]\ttraining's binary_logloss: 0.00870512\n",
      "[7356]\ttraining's binary_logloss: 0.00870431\n",
      "[7357]\ttraining's binary_logloss: 0.00870344\n",
      "[7358]\ttraining's binary_logloss: 0.00870315\n",
      "[7359]\ttraining's binary_logloss: 0.00870292\n",
      "[7360]\ttraining's binary_logloss: 0.00870217\n",
      "[7361]\ttraining's binary_logloss: 0.00870141\n",
      "[7362]\ttraining's binary_logloss: 0.00870112\n",
      "[7363]\ttraining's binary_logloss: 0.00870048\n",
      "[7364]\ttraining's binary_logloss: 0.0086998\n",
      "[7365]\ttraining's binary_logloss: 0.00869913\n",
      "[7366]\ttraining's binary_logloss: 0.00869881\n",
      "[7367]\ttraining's binary_logloss: 0.00869852\n",
      "[7368]\ttraining's binary_logloss: 0.00869737\n",
      "[7369]\ttraining's binary_logloss: 0.00869672\n",
      "[7370]\ttraining's binary_logloss: 0.00869609\n",
      "[7371]\ttraining's binary_logloss: 0.00869573\n",
      "[7372]\ttraining's binary_logloss: 0.00869531\n",
      "[7373]\ttraining's binary_logloss: 0.00869502\n",
      "[7374]\ttraining's binary_logloss: 0.00869461\n",
      "[7375]\ttraining's binary_logloss: 0.00869373\n",
      "[7376]\ttraining's binary_logloss: 0.00869314\n",
      "[7377]\ttraining's binary_logloss: 0.00869279\n",
      "[7378]\ttraining's binary_logloss: 0.00869194\n",
      "[7379]\ttraining's binary_logloss: 0.00869105\n",
      "[7380]\ttraining's binary_logloss: 0.00869076\n",
      "[7381]\ttraining's binary_logloss: 0.00869053\n",
      "[7382]\ttraining's binary_logloss: 0.0086895\n",
      "[7383]\ttraining's binary_logloss: 0.00868883\n",
      "[7384]\ttraining's binary_logloss: 0.00868801\n",
      "[7385]\ttraining's binary_logloss: 0.00868731\n",
      "[7386]\ttraining's binary_logloss: 0.00868671\n",
      "[7387]\ttraining's binary_logloss: 0.00868642\n",
      "[7388]\ttraining's binary_logloss: 0.00868611\n",
      "[7389]\ttraining's binary_logloss: 0.00868576\n",
      "[7390]\ttraining's binary_logloss: 0.00868531\n",
      "[7391]\ttraining's binary_logloss: 0.00868502\n",
      "[7392]\ttraining's binary_logloss: 0.0086848\n",
      "[7393]\ttraining's binary_logloss: 0.00868408\n",
      "[7394]\ttraining's binary_logloss: 0.0086833\n",
      "[7395]\ttraining's binary_logloss: 0.00868238\n",
      "[7396]\ttraining's binary_logloss: 0.00868175\n",
      "[7397]\ttraining's binary_logloss: 0.00868146\n",
      "[7398]\ttraining's binary_logloss: 0.00868115\n",
      "[7399]\ttraining's binary_logloss: 0.00868031\n",
      "[7400]\ttraining's binary_logloss: 0.00867978\n",
      "[7401]\ttraining's binary_logloss: 0.00867904\n",
      "[7402]\ttraining's binary_logloss: 0.00867842\n",
      "[7403]\ttraining's binary_logloss: 0.00867814\n",
      "[7404]\ttraining's binary_logloss: 0.00867791\n",
      "[7405]\ttraining's binary_logloss: 0.00867762\n",
      "[7406]\ttraining's binary_logloss: 0.00867729\n",
      "[7407]\ttraining's binary_logloss: 0.00867671\n",
      "[7408]\ttraining's binary_logloss: 0.00867603\n",
      "[7409]\ttraining's binary_logloss: 0.00867568\n",
      "[7410]\ttraining's binary_logloss: 0.00867495\n",
      "[7411]\ttraining's binary_logloss: 0.00867447\n",
      "[7412]\ttraining's binary_logloss: 0.0086742\n",
      "[7413]\ttraining's binary_logloss: 0.00867389\n",
      "[7414]\ttraining's binary_logloss: 0.00867317\n",
      "[7415]\ttraining's binary_logloss: 0.00867252\n",
      "[7416]\ttraining's binary_logloss: 0.00867165\n",
      "[7417]\ttraining's binary_logloss: 0.00867126\n",
      "[7418]\ttraining's binary_logloss: 0.00867044\n",
      "[7419]\ttraining's binary_logloss: 0.00866943\n",
      "[7420]\ttraining's binary_logloss: 0.0086691\n",
      "[7421]\ttraining's binary_logloss: 0.0086684\n",
      "[7422]\ttraining's binary_logloss: 0.00866761\n",
      "[7423]\ttraining's binary_logloss: 0.0086673\n",
      "[7424]\ttraining's binary_logloss: 0.00866656\n",
      "[7425]\ttraining's binary_logloss: 0.0086659\n",
      "[7426]\ttraining's binary_logloss: 0.00866528\n",
      "[7427]\ttraining's binary_logloss: 0.00866452\n",
      "[7428]\ttraining's binary_logloss: 0.00866419\n",
      "[7429]\ttraining's binary_logloss: 0.00866376\n",
      "[7430]\ttraining's binary_logloss: 0.00866309\n",
      "[7431]\ttraining's binary_logloss: 0.00866237\n",
      "[7432]\ttraining's binary_logloss: 0.00866194\n",
      "[7433]\ttraining's binary_logloss: 0.00866136\n",
      "[7434]\ttraining's binary_logloss: 0.00866066\n",
      "[7435]\ttraining's binary_logloss: 0.00866038\n",
      "[7436]\ttraining's binary_logloss: 0.00865969\n",
      "[7437]\ttraining's binary_logloss: 0.00865911\n",
      "[7438]\ttraining's binary_logloss: 0.00865833\n",
      "[7439]\ttraining's binary_logloss: 0.0086581\n",
      "[7440]\ttraining's binary_logloss: 0.00865752\n",
      "[7441]\ttraining's binary_logloss: 0.00865653\n",
      "[7442]\ttraining's binary_logloss: 0.00865576\n",
      "[7443]\ttraining's binary_logloss: 0.0086548\n",
      "[7444]\ttraining's binary_logloss: 0.0086542\n",
      "[7445]\ttraining's binary_logloss: 0.0086535\n",
      "[7446]\ttraining's binary_logloss: 0.00865255\n",
      "[7447]\ttraining's binary_logloss: 0.00865179\n",
      "[7448]\ttraining's binary_logloss: 0.00865137\n",
      "[7449]\ttraining's binary_logloss: 0.00865028\n",
      "[7450]\ttraining's binary_logloss: 0.00864989\n",
      "[7451]\ttraining's binary_logloss: 0.00864904\n",
      "[7452]\ttraining's binary_logloss: 0.00864864\n",
      "[7453]\ttraining's binary_logloss: 0.0086483\n",
      "[7454]\ttraining's binary_logloss: 0.00864743\n",
      "[7455]\ttraining's binary_logloss: 0.00864674\n",
      "[7456]\ttraining's binary_logloss: 0.00864569\n",
      "[7457]\ttraining's binary_logloss: 0.00864533\n",
      "[7458]\ttraining's binary_logloss: 0.00864502\n",
      "[7459]\ttraining's binary_logloss: 0.00864429\n",
      "[7460]\ttraining's binary_logloss: 0.0086435\n",
      "[7461]\ttraining's binary_logloss: 0.00864264\n",
      "[7462]\ttraining's binary_logloss: 0.00864234\n",
      "[7463]\ttraining's binary_logloss: 0.00864202\n",
      "[7464]\ttraining's binary_logloss: 0.00864173\n",
      "[7465]\ttraining's binary_logloss: 0.00864142\n",
      "[7466]\ttraining's binary_logloss: 0.00864113\n",
      "[7467]\ttraining's binary_logloss: 0.00864044\n",
      "[7468]\ttraining's binary_logloss: 0.00863972\n",
      "[7469]\ttraining's binary_logloss: 0.00863914\n",
      "[7470]\ttraining's binary_logloss: 0.00863887\n",
      "[7471]\ttraining's binary_logloss: 0.00863803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7472]\ttraining's binary_logloss: 0.00863713\n",
      "[7473]\ttraining's binary_logloss: 0.00863679\n",
      "[7474]\ttraining's binary_logloss: 0.00863596\n",
      "[7475]\ttraining's binary_logloss: 0.00863526\n",
      "[7476]\ttraining's binary_logloss: 0.00863469\n",
      "[7477]\ttraining's binary_logloss: 0.00863383\n",
      "[7478]\ttraining's binary_logloss: 0.00863303\n",
      "[7479]\ttraining's binary_logloss: 0.00863237\n",
      "[7480]\ttraining's binary_logloss: 0.00863151\n",
      "[7481]\ttraining's binary_logloss: 0.00863077\n",
      "[7482]\ttraining's binary_logloss: 0.00862995\n",
      "[7483]\ttraining's binary_logloss: 0.00862926\n",
      "[7484]\ttraining's binary_logloss: 0.00862871\n",
      "[7485]\ttraining's binary_logloss: 0.00862802\n",
      "[7486]\ttraining's binary_logloss: 0.0086273\n",
      "[7487]\ttraining's binary_logloss: 0.00862658\n",
      "[7488]\ttraining's binary_logloss: 0.00862629\n",
      "[7489]\ttraining's binary_logloss: 0.00862598\n",
      "[7490]\ttraining's binary_logloss: 0.00862569\n",
      "[7491]\ttraining's binary_logloss: 0.00862547\n",
      "[7492]\ttraining's binary_logloss: 0.00862463\n",
      "[7493]\ttraining's binary_logloss: 0.00862395\n",
      "[7494]\ttraining's binary_logloss: 0.00862367\n",
      "[7495]\ttraining's binary_logloss: 0.00862269\n",
      "[7496]\ttraining's binary_logloss: 0.00862185\n",
      "[7497]\ttraining's binary_logloss: 0.00862158\n",
      "[7498]\ttraining's binary_logloss: 0.00862127\n",
      "[7499]\ttraining's binary_logloss: 0.00862042\n",
      "[7500]\ttraining's binary_logloss: 0.00861962\n",
      "[7501]\ttraining's binary_logloss: 0.00861891\n",
      "[7502]\ttraining's binary_logloss: 0.00861822\n",
      "[7503]\ttraining's binary_logloss: 0.00861787\n",
      "[7504]\ttraining's binary_logloss: 0.00861689\n",
      "[7505]\ttraining's binary_logloss: 0.00861606\n",
      "[7506]\ttraining's binary_logloss: 0.0086158\n",
      "[7507]\ttraining's binary_logloss: 0.00861536\n",
      "[7508]\ttraining's binary_logloss: 0.00861474\n",
      "[7509]\ttraining's binary_logloss: 0.00861446\n",
      "[7510]\ttraining's binary_logloss: 0.00861423\n",
      "[7511]\ttraining's binary_logloss: 0.00861395\n",
      "[7512]\ttraining's binary_logloss: 0.00861363\n",
      "[7513]\ttraining's binary_logloss: 0.00861335\n",
      "[7514]\ttraining's binary_logloss: 0.00861313\n",
      "[7515]\ttraining's binary_logloss: 0.0086122\n",
      "[7516]\ttraining's binary_logloss: 0.00861192\n",
      "[7517]\ttraining's binary_logloss: 0.00861161\n",
      "[7518]\ttraining's binary_logloss: 0.00861092\n",
      "[7519]\ttraining's binary_logloss: 0.0086102\n",
      "[7520]\ttraining's binary_logloss: 0.00860986\n",
      "[7521]\ttraining's binary_logloss: 0.00860914\n",
      "[7522]\ttraining's binary_logloss: 0.00860879\n",
      "[7523]\ttraining's binary_logloss: 0.00860846\n",
      "[7524]\ttraining's binary_logloss: 0.00860775\n",
      "[7525]\ttraining's binary_logloss: 0.00860694\n",
      "[7526]\ttraining's binary_logloss: 0.00860626\n",
      "[7527]\ttraining's binary_logloss: 0.00860542\n",
      "[7528]\ttraining's binary_logloss: 0.008605\n",
      "[7529]\ttraining's binary_logloss: 0.00860472\n",
      "[7530]\ttraining's binary_logloss: 0.00860441\n",
      "[7531]\ttraining's binary_logloss: 0.00860413\n",
      "[7532]\ttraining's binary_logloss: 0.00860391\n",
      "[7533]\ttraining's binary_logloss: 0.00860322\n",
      "[7534]\ttraining's binary_logloss: 0.00860264\n",
      "[7535]\ttraining's binary_logloss: 0.00860216\n",
      "[7536]\ttraining's binary_logloss: 0.00860182\n",
      "[7537]\ttraining's binary_logloss: 0.00860154\n",
      "[7538]\ttraining's binary_logloss: 0.00860132\n",
      "[7539]\ttraining's binary_logloss: 0.00860104\n",
      "[7540]\ttraining's binary_logloss: 0.00860073\n",
      "[7541]\ttraining's binary_logloss: 0.00860046\n",
      "[7542]\ttraining's binary_logloss: 0.00860023\n",
      "[7543]\ttraining's binary_logloss: 0.00859957\n",
      "[7544]\ttraining's binary_logloss: 0.00859929\n",
      "[7545]\ttraining's binary_logloss: 0.00859898\n",
      "[7546]\ttraining's binary_logloss: 0.00859871\n",
      "[7547]\ttraining's binary_logloss: 0.00859848\n",
      "[7548]\ttraining's binary_logloss: 0.00859765\n",
      "[7549]\ttraining's binary_logloss: 0.00859704\n",
      "[7550]\ttraining's binary_logloss: 0.00859665\n",
      "[7551]\ttraining's binary_logloss: 0.00859638\n",
      "[7552]\ttraining's binary_logloss: 0.00859615\n",
      "[7553]\ttraining's binary_logloss: 0.00859536\n",
      "[7554]\ttraining's binary_logloss: 0.00859509\n",
      "[7555]\ttraining's binary_logloss: 0.00859478\n",
      "[7556]\ttraining's binary_logloss: 0.00859395\n",
      "[7557]\ttraining's binary_logloss: 0.00859326\n",
      "[7558]\ttraining's binary_logloss: 0.00859234\n",
      "[7559]\ttraining's binary_logloss: 0.00859207\n",
      "[7560]\ttraining's binary_logloss: 0.00859151\n",
      "[7561]\ttraining's binary_logloss: 0.00859083\n",
      "[7562]\ttraining's binary_logloss: 0.00859052\n",
      "[7563]\ttraining's binary_logloss: 0.00858986\n",
      "[7564]\ttraining's binary_logloss: 0.00858925\n",
      "[7565]\ttraining's binary_logloss: 0.00858851\n",
      "[7566]\ttraining's binary_logloss: 0.00858817\n",
      "[7567]\ttraining's binary_logloss: 0.00858738\n",
      "[7568]\ttraining's binary_logloss: 0.00858683\n",
      "[7569]\ttraining's binary_logloss: 0.00858649\n",
      "[7570]\ttraining's binary_logloss: 0.00858609\n",
      "[7571]\ttraining's binary_logloss: 0.00858535\n",
      "[7572]\ttraining's binary_logloss: 0.00858508\n",
      "[7573]\ttraining's binary_logloss: 0.00858485\n",
      "[7574]\ttraining's binary_logloss: 0.00858458\n",
      "[7575]\ttraining's binary_logloss: 0.00858426\n",
      "[7576]\ttraining's binary_logloss: 0.00858399\n",
      "[7577]\ttraining's binary_logloss: 0.00858327\n",
      "[7578]\ttraining's binary_logloss: 0.00858295\n",
      "[7579]\ttraining's binary_logloss: 0.00858229\n",
      "[7580]\ttraining's binary_logloss: 0.00858123\n",
      "[7581]\ttraining's binary_logloss: 0.00858085\n",
      "[7582]\ttraining's binary_logloss: 0.00858058\n",
      "[7583]\ttraining's binary_logloss: 0.00857992\n",
      "[7584]\ttraining's binary_logloss: 0.00857969\n",
      "[7585]\ttraining's binary_logloss: 0.00857939\n",
      "[7586]\ttraining's binary_logloss: 0.00857866\n",
      "[7587]\ttraining's binary_logloss: 0.00857772\n",
      "[7588]\ttraining's binary_logloss: 0.00857729\n",
      "[7589]\ttraining's binary_logloss: 0.0085765\n",
      "[7590]\ttraining's binary_logloss: 0.00857579\n",
      "[7591]\ttraining's binary_logloss: 0.00857548\n",
      "[7592]\ttraining's binary_logloss: 0.00857481\n",
      "[7593]\ttraining's binary_logloss: 0.00857405\n",
      "[7594]\ttraining's binary_logloss: 0.00857334\n",
      "[7595]\ttraining's binary_logloss: 0.00857238\n",
      "[7596]\ttraining's binary_logloss: 0.0085717\n",
      "[7597]\ttraining's binary_logloss: 0.00857083\n",
      "[7598]\ttraining's binary_logloss: 0.0085705\n",
      "[7599]\ttraining's binary_logloss: 0.00856965\n",
      "[7600]\ttraining's binary_logloss: 0.00856923\n",
      "[7601]\ttraining's binary_logloss: 0.00856901\n",
      "[7602]\ttraining's binary_logloss: 0.00856867\n",
      "[7603]\ttraining's binary_logloss: 0.00856846\n",
      "[7604]\ttraining's binary_logloss: 0.00856824\n",
      "[7605]\ttraining's binary_logloss: 0.00856758\n",
      "[7606]\ttraining's binary_logloss: 0.00856728\n",
      "[7607]\ttraining's binary_logloss: 0.00856645\n",
      "[7608]\ttraining's binary_logloss: 0.00856576\n",
      "[7609]\ttraining's binary_logloss: 0.00856449\n",
      "[7610]\ttraining's binary_logloss: 0.00856374\n",
      "[7611]\ttraining's binary_logloss: 0.00856297\n",
      "[7612]\ttraining's binary_logloss: 0.00856262\n",
      "[7613]\ttraining's binary_logloss: 0.0085616\n",
      "[7614]\ttraining's binary_logloss: 0.00856092\n",
      "[7615]\ttraining's binary_logloss: 0.00856051\n",
      "[7616]\ttraining's binary_logloss: 0.00856018\n",
      "[7617]\ttraining's binary_logloss: 0.00855997\n",
      "[7618]\ttraining's binary_logloss: 0.00855964\n",
      "[7619]\ttraining's binary_logloss: 0.00855881\n",
      "[7620]\ttraining's binary_logloss: 0.00855794\n",
      "[7621]\ttraining's binary_logloss: 0.00855717\n",
      "[7622]\ttraining's binary_logloss: 0.00855695\n",
      "[7623]\ttraining's binary_logloss: 0.00855612\n",
      "[7624]\ttraining's binary_logloss: 0.00855545\n",
      "[7625]\ttraining's binary_logloss: 0.00855439\n",
      "[7626]\ttraining's binary_logloss: 0.00855352\n",
      "[7627]\ttraining's binary_logloss: 0.00855331\n",
      "[7628]\ttraining's binary_logloss: 0.00855257\n",
      "[7629]\ttraining's binary_logloss: 0.00855187\n",
      "[7630]\ttraining's binary_logloss: 0.00855124\n",
      "[7631]\ttraining's binary_logloss: 0.00855093\n",
      "[7632]\ttraining's binary_logloss: 0.00855061\n",
      "[7633]\ttraining's binary_logloss: 0.00855011\n",
      "[7634]\ttraining's binary_logloss: 0.00854941\n",
      "[7635]\ttraining's binary_logloss: 0.00854904\n",
      "[7636]\ttraining's binary_logloss: 0.00854883\n",
      "[7637]\ttraining's binary_logloss: 0.0085486\n",
      "[7638]\ttraining's binary_logloss: 0.0085484\n",
      "[7639]\ttraining's binary_logloss: 0.00854817\n",
      "[7640]\ttraining's binary_logloss: 0.00854715\n",
      "[7641]\ttraining's binary_logloss: 0.00854688\n",
      "[7642]\ttraining's binary_logloss: 0.00854619\n",
      "[7643]\ttraining's binary_logloss: 0.00854525\n",
      "[7644]\ttraining's binary_logloss: 0.00854453\n",
      "[7645]\ttraining's binary_logloss: 0.00854329\n",
      "[7646]\ttraining's binary_logloss: 0.00854263\n",
      "[7647]\ttraining's binary_logloss: 0.00854168\n",
      "[7648]\ttraining's binary_logloss: 0.00854083\n",
      "[7649]\ttraining's binary_logloss: 0.00854014\n",
      "[7650]\ttraining's binary_logloss: 0.00853993\n",
      "[7651]\ttraining's binary_logloss: 0.00853962\n",
      "[7652]\ttraining's binary_logloss: 0.00853902\n",
      "[7653]\ttraining's binary_logloss: 0.00853832\n",
      "[7654]\ttraining's binary_logloss: 0.00853766\n",
      "[7655]\ttraining's binary_logloss: 0.00853682\n",
      "[7656]\ttraining's binary_logloss: 0.00853614\n",
      "[7657]\ttraining's binary_logloss: 0.00853571\n",
      "[7658]\ttraining's binary_logloss: 0.00853538\n",
      "[7659]\ttraining's binary_logloss: 0.00853461\n",
      "[7660]\ttraining's binary_logloss: 0.00853422\n",
      "[7661]\ttraining's binary_logloss: 0.00853354\n",
      "[7662]\ttraining's binary_logloss: 0.00853333\n",
      "[7663]\ttraining's binary_logloss: 0.00853311\n",
      "[7664]\ttraining's binary_logloss: 0.0085329\n",
      "[7665]\ttraining's binary_logloss: 0.00853259\n",
      "[7666]\ttraining's binary_logloss: 0.00853239\n",
      "[7667]\ttraining's binary_logloss: 0.00853208\n",
      "[7668]\ttraining's binary_logloss: 0.00853106\n",
      "[7669]\ttraining's binary_logloss: 0.00853039\n",
      "[7670]\ttraining's binary_logloss: 0.00853018\n",
      "[7671]\ttraining's binary_logloss: 0.00852996\n",
      "[7672]\ttraining's binary_logloss: 0.00852937\n",
      "[7673]\ttraining's binary_logloss: 0.00852859\n",
      "[7674]\ttraining's binary_logloss: 0.00852766\n",
      "[7675]\ttraining's binary_logloss: 0.00852698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7676]\ttraining's binary_logloss: 0.00852632\n",
      "[7677]\ttraining's binary_logloss: 0.00852611\n",
      "[7678]\ttraining's binary_logloss: 0.00852526\n",
      "[7679]\ttraining's binary_logloss: 0.00852469\n",
      "[7680]\ttraining's binary_logloss: 0.00852386\n",
      "[7681]\ttraining's binary_logloss: 0.00852331\n",
      "[7682]\ttraining's binary_logloss: 0.00852301\n",
      "[7683]\ttraining's binary_logloss: 0.00852233\n",
      "[7684]\ttraining's binary_logloss: 0.00852118\n",
      "[7685]\ttraining's binary_logloss: 0.00852087\n",
      "[7686]\ttraining's binary_logloss: 0.00852065\n",
      "[7687]\ttraining's binary_logloss: 0.00852045\n",
      "[7688]\ttraining's binary_logloss: 0.00851973\n",
      "[7689]\ttraining's binary_logloss: 0.00851934\n",
      "[7690]\ttraining's binary_logloss: 0.00851868\n",
      "[7691]\ttraining's binary_logloss: 0.00851807\n",
      "[7692]\ttraining's binary_logloss: 0.00851777\n",
      "[7693]\ttraining's binary_logloss: 0.00851756\n",
      "[7694]\ttraining's binary_logloss: 0.00851734\n",
      "[7695]\ttraining's binary_logloss: 0.00851713\n",
      "[7696]\ttraining's binary_logloss: 0.00851682\n",
      "[7697]\ttraining's binary_logloss: 0.00851662\n",
      "[7698]\ttraining's binary_logloss: 0.00851631\n",
      "[7699]\ttraining's binary_logloss: 0.00851556\n",
      "[7700]\ttraining's binary_logloss: 0.0085149\n",
      "[7701]\ttraining's binary_logloss: 0.00851425\n",
      "[7702]\ttraining's binary_logloss: 0.00851404\n",
      "[7703]\ttraining's binary_logloss: 0.00851337\n",
      "[7704]\ttraining's binary_logloss: 0.00851296\n",
      "[7705]\ttraining's binary_logloss: 0.00851213\n",
      "[7706]\ttraining's binary_logloss: 0.00851157\n",
      "[7707]\ttraining's binary_logloss: 0.00851127\n",
      "[7708]\ttraining's binary_logloss: 0.00851077\n",
      "[7709]\ttraining's binary_logloss: 0.0085101\n",
      "[7710]\ttraining's binary_logloss: 0.00850921\n",
      "[7711]\ttraining's binary_logloss: 0.00850832\n",
      "[7712]\ttraining's binary_logloss: 0.00850749\n",
      "[7713]\ttraining's binary_logloss: 0.00850681\n",
      "[7714]\ttraining's binary_logloss: 0.00850604\n",
      "[7715]\ttraining's binary_logloss: 0.00850534\n",
      "[7716]\ttraining's binary_logloss: 0.00850469\n",
      "[7717]\ttraining's binary_logloss: 0.008504\n",
      "[7718]\ttraining's binary_logloss: 0.00850297\n",
      "[7719]\ttraining's binary_logloss: 0.00850257\n",
      "[7720]\ttraining's binary_logloss: 0.00850186\n",
      "[7721]\ttraining's binary_logloss: 0.00850114\n",
      "[7722]\ttraining's binary_logloss: 0.00850021\n",
      "[7723]\ttraining's binary_logloss: 0.0084995\n",
      "[7724]\ttraining's binary_logloss: 0.00849877\n",
      "[7725]\ttraining's binary_logloss: 0.00849796\n",
      "[7726]\ttraining's binary_logloss: 0.00849707\n",
      "[7727]\ttraining's binary_logloss: 0.00849642\n",
      "[7728]\ttraining's binary_logloss: 0.00849569\n",
      "[7729]\ttraining's binary_logloss: 0.00849465\n",
      "[7730]\ttraining's binary_logloss: 0.00849346\n",
      "[7731]\ttraining's binary_logloss: 0.00849279\n",
      "[7732]\ttraining's binary_logloss: 0.00849224\n",
      "[7733]\ttraining's binary_logloss: 0.0084913\n",
      "[7734]\ttraining's binary_logloss: 0.00849061\n",
      "[7735]\ttraining's binary_logloss: 0.00848987\n",
      "[7736]\ttraining's binary_logloss: 0.00848946\n",
      "[7737]\ttraining's binary_logloss: 0.00848873\n",
      "[7738]\ttraining's binary_logloss: 0.0084884\n",
      "[7739]\ttraining's binary_logloss: 0.00848767\n",
      "[7740]\ttraining's binary_logloss: 0.00848702\n",
      "[7741]\ttraining's binary_logloss: 0.00848669\n",
      "[7742]\ttraining's binary_logloss: 0.00848612\n",
      "[7743]\ttraining's binary_logloss: 0.00848543\n",
      "[7744]\ttraining's binary_logloss: 0.00848452\n",
      "[7745]\ttraining's binary_logloss: 0.00848383\n",
      "[7746]\ttraining's binary_logloss: 0.00848344\n",
      "[7747]\ttraining's binary_logloss: 0.00848273\n",
      "[7748]\ttraining's binary_logloss: 0.00848194\n",
      "[7749]\ttraining's binary_logloss: 0.00848085\n",
      "[7750]\ttraining's binary_logloss: 0.00847987\n",
      "[7751]\ttraining's binary_logloss: 0.00847956\n",
      "[7752]\ttraining's binary_logloss: 0.00847933\n",
      "[7753]\ttraining's binary_logloss: 0.00847912\n",
      "[7754]\ttraining's binary_logloss: 0.0084789\n",
      "[7755]\ttraining's binary_logloss: 0.00847869\n",
      "[7756]\ttraining's binary_logloss: 0.00847847\n",
      "[7757]\ttraining's binary_logloss: 0.00847759\n",
      "[7758]\ttraining's binary_logloss: 0.00847715\n",
      "[7759]\ttraining's binary_logloss: 0.00847644\n",
      "[7760]\ttraining's binary_logloss: 0.00847606\n",
      "[7761]\ttraining's binary_logloss: 0.00847525\n",
      "[7762]\ttraining's binary_logloss: 0.00847505\n",
      "[7763]\ttraining's binary_logloss: 0.00847441\n",
      "[7764]\ttraining's binary_logloss: 0.00847345\n",
      "[7765]\ttraining's binary_logloss: 0.00847315\n",
      "[7766]\ttraining's binary_logloss: 0.00847294\n",
      "[7767]\ttraining's binary_logloss: 0.00847238\n",
      "[7768]\ttraining's binary_logloss: 0.00847171\n",
      "[7769]\ttraining's binary_logloss: 0.00847149\n",
      "[7770]\ttraining's binary_logloss: 0.00847129\n",
      "[7771]\ttraining's binary_logloss: 0.00847098\n",
      "[7772]\ttraining's binary_logloss: 0.00847078\n",
      "[7773]\ttraining's binary_logloss: 0.00847056\n",
      "[7774]\ttraining's binary_logloss: 0.00847035\n",
      "[7775]\ttraining's binary_logloss: 0.00847005\n",
      "[7776]\ttraining's binary_logloss: 0.00846919\n",
      "[7777]\ttraining's binary_logloss: 0.00846899\n",
      "[7778]\ttraining's binary_logloss: 0.00846877\n",
      "[7779]\ttraining's binary_logloss: 0.00846856\n",
      "[7780]\ttraining's binary_logloss: 0.00846826\n",
      "[7781]\ttraining's binary_logloss: 0.0084676\n",
      "[7782]\ttraining's binary_logloss: 0.00846687\n",
      "[7783]\ttraining's binary_logloss: 0.00846623\n",
      "[7784]\ttraining's binary_logloss: 0.00846558\n",
      "[7785]\ttraining's binary_logloss: 0.00846525\n",
      "[7786]\ttraining's binary_logloss: 0.00846431\n",
      "[7787]\ttraining's binary_logloss: 0.00846389\n",
      "[7788]\ttraining's binary_logloss: 0.00846322\n",
      "[7789]\ttraining's binary_logloss: 0.0084629\n",
      "[7790]\ttraining's binary_logloss: 0.00846257\n",
      "[7791]\ttraining's binary_logloss: 0.00846237\n",
      "[7792]\ttraining's binary_logloss: 0.00846215\n",
      "[7793]\ttraining's binary_logloss: 0.00846194\n",
      "[7794]\ttraining's binary_logloss: 0.00846172\n",
      "[7795]\ttraining's binary_logloss: 0.00846152\n",
      "[7796]\ttraining's binary_logloss: 0.00846122\n",
      "[7797]\ttraining's binary_logloss: 0.00846026\n",
      "[7798]\ttraining's binary_logloss: 0.00845946\n",
      "[7799]\ttraining's binary_logloss: 0.00845874\n",
      "[7800]\ttraining's binary_logloss: 0.0084584\n",
      "[7801]\ttraining's binary_logloss: 0.00845782\n",
      "[7802]\ttraining's binary_logloss: 0.00845712\n",
      "[7803]\ttraining's binary_logloss: 0.00845633\n",
      "[7804]\ttraining's binary_logloss: 0.00845612\n",
      "[7805]\ttraining's binary_logloss: 0.00845549\n",
      "[7806]\ttraining's binary_logloss: 0.00845484\n",
      "[7807]\ttraining's binary_logloss: 0.00845383\n",
      "[7808]\ttraining's binary_logloss: 0.00845347\n",
      "[7809]\ttraining's binary_logloss: 0.0084526\n",
      "[7810]\ttraining's binary_logloss: 0.0084523\n",
      "[7811]\ttraining's binary_logloss: 0.00845149\n",
      "[7812]\ttraining's binary_logloss: 0.00845077\n",
      "[7813]\ttraining's binary_logloss: 0.00845045\n",
      "[7814]\ttraining's binary_logloss: 0.00844973\n",
      "[7815]\ttraining's binary_logloss: 0.00844891\n",
      "[7816]\ttraining's binary_logloss: 0.008448\n",
      "[7817]\ttraining's binary_logloss: 0.00844762\n",
      "[7818]\ttraining's binary_logloss: 0.00844686\n",
      "[7819]\ttraining's binary_logloss: 0.00844626\n",
      "[7820]\ttraining's binary_logloss: 0.00844564\n",
      "[7821]\ttraining's binary_logloss: 0.00844498\n",
      "[7822]\ttraining's binary_logloss: 0.00844414\n",
      "[7823]\ttraining's binary_logloss: 0.00844381\n",
      "[7824]\ttraining's binary_logloss: 0.00844359\n",
      "[7825]\ttraining's binary_logloss: 0.00844338\n",
      "[7826]\ttraining's binary_logloss: 0.00844308\n",
      "[7827]\ttraining's binary_logloss: 0.00844288\n",
      "[7828]\ttraining's binary_logloss: 0.00844266\n",
      "[7829]\ttraining's binary_logloss: 0.00844184\n",
      "[7830]\ttraining's binary_logloss: 0.00844147\n",
      "[7831]\ttraining's binary_logloss: 0.00844127\n",
      "[7832]\ttraining's binary_logloss: 0.00844057\n",
      "[7833]\ttraining's binary_logloss: 0.00843979\n",
      "[7834]\ttraining's binary_logloss: 0.00843912\n",
      "[7835]\ttraining's binary_logloss: 0.00843879\n",
      "[7836]\ttraining's binary_logloss: 0.00843822\n",
      "[7837]\ttraining's binary_logloss: 0.00843783\n",
      "[7838]\ttraining's binary_logloss: 0.00843717\n",
      "[7839]\ttraining's binary_logloss: 0.00843678\n",
      "[7840]\ttraining's binary_logloss: 0.00843648\n",
      "[7841]\ttraining's binary_logloss: 0.00843581\n",
      "[7842]\ttraining's binary_logloss: 0.00843551\n",
      "[7843]\ttraining's binary_logloss: 0.00843531\n",
      "[7844]\ttraining's binary_logloss: 0.00843426\n",
      "[7845]\ttraining's binary_logloss: 0.00843353\n",
      "[7846]\ttraining's binary_logloss: 0.00843256\n",
      "[7847]\ttraining's binary_logloss: 0.00843165\n",
      "[7848]\ttraining's binary_logloss: 0.00843143\n",
      "[7849]\ttraining's binary_logloss: 0.00843123\n",
      "[7850]\ttraining's binary_logloss: 0.00843059\n",
      "[7851]\ttraining's binary_logloss: 0.00842996\n",
      "[7852]\ttraining's binary_logloss: 0.00842967\n",
      "[7853]\ttraining's binary_logloss: 0.00842908\n",
      "[7854]\ttraining's binary_logloss: 0.00842875\n",
      "[7855]\ttraining's binary_logloss: 0.00842855\n",
      "[7856]\ttraining's binary_logloss: 0.00842826\n",
      "[7857]\ttraining's binary_logloss: 0.00842805\n",
      "[7858]\ttraining's binary_logloss: 0.00842783\n",
      "[7859]\ttraining's binary_logloss: 0.00842752\n",
      "[7860]\ttraining's binary_logloss: 0.00842709\n",
      "[7861]\ttraining's binary_logloss: 0.00842641\n",
      "[7862]\ttraining's binary_logloss: 0.00842563\n",
      "[7863]\ttraining's binary_logloss: 0.00842494\n",
      "[7864]\ttraining's binary_logloss: 0.00842462\n",
      "[7865]\ttraining's binary_logloss: 0.00842442\n",
      "[7866]\ttraining's binary_logloss: 0.00842361\n",
      "[7867]\ttraining's binary_logloss: 0.00842335\n",
      "[7868]\ttraining's binary_logloss: 0.00842296\n",
      "[7869]\ttraining's binary_logloss: 0.00842219\n",
      "[7870]\ttraining's binary_logloss: 0.00842159\n",
      "[7871]\ttraining's binary_logloss: 0.0084213\n",
      "[7872]\ttraining's binary_logloss: 0.00842059\n",
      "[7873]\ttraining's binary_logloss: 0.00841994\n",
      "[7874]\ttraining's binary_logloss: 0.0084195\n",
      "[7875]\ttraining's binary_logloss: 0.00841892\n",
      "[7876]\ttraining's binary_logloss: 0.00841815\n",
      "[7877]\ttraining's binary_logloss: 0.00841752\n",
      "[7878]\ttraining's binary_logloss: 0.00841684\n",
      "[7879]\ttraining's binary_logloss: 0.00841603\n",
      "[7880]\ttraining's binary_logloss: 0.00841525\n",
      "[7881]\ttraining's binary_logloss: 0.00841491\n",
      "[7882]\ttraining's binary_logloss: 0.00841425\n",
      "[7883]\ttraining's binary_logloss: 0.00841336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7884]\ttraining's binary_logloss: 0.00841299\n",
      "[7885]\ttraining's binary_logloss: 0.00841279\n",
      "[7886]\ttraining's binary_logloss: 0.0084125\n",
      "[7887]\ttraining's binary_logloss: 0.00841188\n",
      "[7888]\ttraining's binary_logloss: 0.00841131\n",
      "[7889]\ttraining's binary_logloss: 0.00841095\n",
      "[7890]\ttraining's binary_logloss: 0.00841075\n",
      "[7891]\ttraining's binary_logloss: 0.00841054\n",
      "[7892]\ttraining's binary_logloss: 0.00841034\n",
      "[7893]\ttraining's binary_logloss: 0.00841004\n",
      "[7894]\ttraining's binary_logloss: 0.00840919\n",
      "[7895]\ttraining's binary_logloss: 0.00840899\n",
      "[7896]\ttraining's binary_logloss: 0.00840877\n",
      "[7897]\ttraining's binary_logloss: 0.00840857\n",
      "[7898]\ttraining's binary_logloss: 0.00840835\n",
      "[7899]\ttraining's binary_logloss: 0.00840806\n",
      "[7900]\ttraining's binary_logloss: 0.00840739\n",
      "[7901]\ttraining's binary_logloss: 0.00840719\n",
      "[7902]\ttraining's binary_logloss: 0.00840675\n",
      "[7903]\ttraining's binary_logloss: 0.0084061\n",
      "[7904]\ttraining's binary_logloss: 0.00840555\n",
      "[7905]\ttraining's binary_logloss: 0.00840516\n",
      "[7906]\ttraining's binary_logloss: 0.00840458\n",
      "[7907]\ttraining's binary_logloss: 0.00840394\n",
      "[7908]\ttraining's binary_logloss: 0.00840346\n",
      "[7909]\ttraining's binary_logloss: 0.00840271\n",
      "[7910]\ttraining's binary_logloss: 0.00840209\n",
      "[7911]\ttraining's binary_logloss: 0.0084018\n",
      "[7912]\ttraining's binary_logloss: 0.0084016\n",
      "[7913]\ttraining's binary_logloss: 0.0084008\n",
      "[7914]\ttraining's binary_logloss: 0.00840047\n",
      "[7915]\ttraining's binary_logloss: 0.00840018\n",
      "[7916]\ttraining's binary_logloss: 0.0083995\n",
      "[7917]\ttraining's binary_logloss: 0.00839889\n",
      "[7918]\ttraining's binary_logloss: 0.00839818\n",
      "[7919]\ttraining's binary_logloss: 0.00839752\n",
      "[7920]\ttraining's binary_logloss: 0.0083968\n",
      "[7921]\ttraining's binary_logloss: 0.00839604\n",
      "[7922]\ttraining's binary_logloss: 0.00839574\n",
      "[7923]\ttraining's binary_logloss: 0.00839542\n",
      "[7924]\ttraining's binary_logloss: 0.00839473\n",
      "[7925]\ttraining's binary_logloss: 0.00839407\n",
      "[7926]\ttraining's binary_logloss: 0.00839341\n",
      "[7927]\ttraining's binary_logloss: 0.00839286\n",
      "[7928]\ttraining's binary_logloss: 0.00839248\n",
      "[7929]\ttraining's binary_logloss: 0.00839154\n",
      "[7930]\ttraining's binary_logloss: 0.00839076\n",
      "[7931]\ttraining's binary_logloss: 0.00839009\n",
      "[7932]\ttraining's binary_logloss: 0.00838948\n",
      "[7933]\ttraining's binary_logloss: 0.00838915\n",
      "[7934]\ttraining's binary_logloss: 0.00838875\n",
      "[7935]\ttraining's binary_logloss: 0.00838814\n",
      "[7936]\ttraining's binary_logloss: 0.00838719\n",
      "[7937]\ttraining's binary_logloss: 0.00838682\n",
      "[7938]\ttraining's binary_logloss: 0.00838633\n",
      "[7939]\ttraining's binary_logloss: 0.00838589\n",
      "[7940]\ttraining's binary_logloss: 0.00838527\n",
      "[7941]\ttraining's binary_logloss: 0.00838456\n",
      "[7942]\ttraining's binary_logloss: 0.00838383\n",
      "[7943]\ttraining's binary_logloss: 0.00838341\n",
      "[7944]\ttraining's binary_logloss: 0.00838247\n",
      "[7945]\ttraining's binary_logloss: 0.00838227\n",
      "[7946]\ttraining's binary_logloss: 0.00838136\n",
      "[7947]\ttraining's binary_logloss: 0.00838039\n",
      "[7948]\ttraining's binary_logloss: 0.00838004\n",
      "[7949]\ttraining's binary_logloss: 0.0083793\n",
      "[7950]\ttraining's binary_logloss: 0.00837842\n",
      "[7951]\ttraining's binary_logloss: 0.00837806\n",
      "[7952]\ttraining's binary_logloss: 0.00837769\n",
      "[7953]\ttraining's binary_logloss: 0.00837692\n",
      "[7954]\ttraining's binary_logloss: 0.00837562\n",
      "[7955]\ttraining's binary_logloss: 0.0083749\n",
      "[7956]\ttraining's binary_logloss: 0.00837446\n",
      "[7957]\ttraining's binary_logloss: 0.00837358\n",
      "[7958]\ttraining's binary_logloss: 0.00837292\n",
      "[7959]\ttraining's binary_logloss: 0.00837231\n",
      "[7960]\ttraining's binary_logloss: 0.00837167\n",
      "[7961]\ttraining's binary_logloss: 0.00837107\n",
      "[7962]\ttraining's binary_logloss: 0.00837078\n",
      "[7963]\ttraining's binary_logloss: 0.00837057\n",
      "[7964]\ttraining's binary_logloss: 0.00836991\n",
      "[7965]\ttraining's binary_logloss: 0.00836935\n",
      "[7966]\ttraining's binary_logloss: 0.00836906\n",
      "[7967]\ttraining's binary_logloss: 0.00836874\n",
      "[7968]\ttraining's binary_logloss: 0.00836855\n",
      "[7969]\ttraining's binary_logloss: 0.00836833\n",
      "[7970]\ttraining's binary_logloss: 0.00836772\n",
      "[7971]\ttraining's binary_logloss: 0.00836753\n",
      "[7972]\ttraining's binary_logloss: 0.00836723\n",
      "[7973]\ttraining's binary_logloss: 0.00836658\n",
      "[7974]\ttraining's binary_logloss: 0.00836638\n",
      "[7975]\ttraining's binary_logloss: 0.00836609\n",
      "[7976]\ttraining's binary_logloss: 0.00836589\n",
      "[7977]\ttraining's binary_logloss: 0.00836567\n",
      "[7978]\ttraining's binary_logloss: 0.00836499\n",
      "[7979]\ttraining's binary_logloss: 0.00836433\n",
      "[7980]\ttraining's binary_logloss: 0.00836413\n",
      "[7981]\ttraining's binary_logloss: 0.00836375\n",
      "[7982]\ttraining's binary_logloss: 0.00836354\n",
      "[7983]\ttraining's binary_logloss: 0.00836334\n",
      "[7984]\ttraining's binary_logloss: 0.00836305\n",
      "[7985]\ttraining's binary_logloss: 0.00836285\n",
      "[7986]\ttraining's binary_logloss: 0.00836264\n",
      "[7987]\ttraining's binary_logloss: 0.00836235\n",
      "[7988]\ttraining's binary_logloss: 0.00836215\n",
      "[7989]\ttraining's binary_logloss: 0.00836186\n",
      "[7990]\ttraining's binary_logloss: 0.00836167\n",
      "[7991]\ttraining's binary_logloss: 0.00836145\n",
      "[7992]\ttraining's binary_logloss: 0.00836125\n",
      "[7993]\ttraining's binary_logloss: 0.00836096\n",
      "[7994]\ttraining's binary_logloss: 0.00836041\n",
      "[7995]\ttraining's binary_logloss: 0.00835973\n",
      "[7996]\ttraining's binary_logloss: 0.00835912\n",
      "[7997]\ttraining's binary_logloss: 0.00835878\n",
      "[7998]\ttraining's binary_logloss: 0.00835775\n",
      "[7999]\ttraining's binary_logloss: 0.00835742\n",
      "[8000]\ttraining's binary_logloss: 0.00835677\n",
      "[8001]\ttraining's binary_logloss: 0.00835639\n",
      "[8002]\ttraining's binary_logloss: 0.00835604\n",
      "[8003]\ttraining's binary_logloss: 0.00835549\n",
      "[8004]\ttraining's binary_logloss: 0.00835461\n",
      "[8005]\ttraining's binary_logloss: 0.00835427\n",
      "[8006]\ttraining's binary_logloss: 0.0083534\n",
      "[8007]\ttraining's binary_logloss: 0.00835307\n",
      "[8008]\ttraining's binary_logloss: 0.00835288\n",
      "[8009]\ttraining's binary_logloss: 0.00835266\n",
      "[8010]\ttraining's binary_logloss: 0.00835203\n",
      "[8011]\ttraining's binary_logloss: 0.00835166\n",
      "[8012]\ttraining's binary_logloss: 0.00835146\n",
      "[8013]\ttraining's binary_logloss: 0.00835117\n",
      "[8014]\ttraining's binary_logloss: 0.0083506\n",
      "[8015]\ttraining's binary_logloss: 0.00835024\n",
      "[8016]\ttraining's binary_logloss: 0.00834963\n",
      "[8017]\ttraining's binary_logloss: 0.00834909\n",
      "[8018]\ttraining's binary_logloss: 0.0083482\n",
      "[8019]\ttraining's binary_logloss: 0.00834729\n",
      "[8020]\ttraining's binary_logloss: 0.00834697\n",
      "[8021]\ttraining's binary_logloss: 0.00834677\n",
      "[8022]\ttraining's binary_logloss: 0.00834606\n",
      "[8023]\ttraining's binary_logloss: 0.00834577\n",
      "[8024]\ttraining's binary_logloss: 0.00834516\n",
      "[8025]\ttraining's binary_logloss: 0.00834497\n",
      "[8026]\ttraining's binary_logloss: 0.00834476\n",
      "[8027]\ttraining's binary_logloss: 0.0083439\n",
      "[8028]\ttraining's binary_logloss: 0.00834353\n",
      "[8029]\ttraining's binary_logloss: 0.00834317\n",
      "[8030]\ttraining's binary_logloss: 0.00834298\n",
      "[8031]\ttraining's binary_logloss: 0.00834236\n",
      "[8032]\ttraining's binary_logloss: 0.00834172\n",
      "[8033]\ttraining's binary_logloss: 0.00834143\n",
      "[8034]\ttraining's binary_logloss: 0.00834107\n",
      "[8035]\ttraining's binary_logloss: 0.00834052\n",
      "[8036]\ttraining's binary_logloss: 0.00833964\n",
      "[8037]\ttraining's binary_logloss: 0.00833924\n",
      "[8038]\ttraining's binary_logloss: 0.00833859\n",
      "[8039]\ttraining's binary_logloss: 0.00833829\n",
      "[8040]\ttraining's binary_logloss: 0.00833795\n",
      "[8041]\ttraining's binary_logloss: 0.0083374\n",
      "[8042]\ttraining's binary_logloss: 0.00833669\n",
      "[8043]\ttraining's binary_logloss: 0.00833633\n",
      "[8044]\ttraining's binary_logloss: 0.00833553\n",
      "[8045]\ttraining's binary_logloss: 0.00833515\n",
      "[8046]\ttraining's binary_logloss: 0.00833415\n",
      "[8047]\ttraining's binary_logloss: 0.00833353\n",
      "[8048]\ttraining's binary_logloss: 0.00833293\n",
      "[8049]\ttraining's binary_logloss: 0.00833224\n",
      "[8050]\ttraining's binary_logloss: 0.0083317\n",
      "[8051]\ttraining's binary_logloss: 0.00833101\n",
      "[8052]\ttraining's binary_logloss: 0.00833039\n",
      "[8053]\ttraining's binary_logloss: 0.00832969\n",
      "[8054]\ttraining's binary_logloss: 0.00832933\n",
      "[8055]\ttraining's binary_logloss: 0.00832897\n",
      "[8056]\ttraining's binary_logloss: 0.00832876\n",
      "[8057]\ttraining's binary_logloss: 0.00832856\n",
      "[8058]\ttraining's binary_logloss: 0.0083278\n",
      "[8059]\ttraining's binary_logloss: 0.00832714\n",
      "[8060]\ttraining's binary_logloss: 0.00832682\n",
      "[8061]\ttraining's binary_logloss: 0.00832634\n",
      "[8062]\ttraining's binary_logloss: 0.00832605\n",
      "[8063]\ttraining's binary_logloss: 0.00832543\n",
      "[8064]\ttraining's binary_logloss: 0.0083248\n",
      "[8065]\ttraining's binary_logloss: 0.0083246\n",
      "[8066]\ttraining's binary_logloss: 0.00832439\n",
      "[8067]\ttraining's binary_logloss: 0.00832351\n",
      "[8068]\ttraining's binary_logloss: 0.00832288\n",
      "[8069]\ttraining's binary_logloss: 0.00832225\n",
      "[8070]\ttraining's binary_logloss: 0.00832197\n",
      "[8071]\ttraining's binary_logloss: 0.00832165\n",
      "[8072]\ttraining's binary_logloss: 0.00832146\n",
      "[8073]\ttraining's binary_logloss: 0.00832117\n",
      "[8074]\ttraining's binary_logloss: 0.00832097\n",
      "[8075]\ttraining's binary_logloss: 0.00832076\n",
      "[8076]\ttraining's binary_logloss: 0.00832056\n",
      "[8077]\ttraining's binary_logloss: 0.00832028\n",
      "[8078]\ttraining's binary_logloss: 0.00832008\n",
      "[8079]\ttraining's binary_logloss: 0.00831987\n",
      "[8080]\ttraining's binary_logloss: 0.00831949\n",
      "[8081]\ttraining's binary_logloss: 0.0083187\n",
      "[8082]\ttraining's binary_logloss: 0.00831777\n",
      "[8083]\ttraining's binary_logloss: 0.00831757\n",
      "[8084]\ttraining's binary_logloss: 0.00831728\n",
      "[8085]\ttraining's binary_logloss: 0.00831668\n",
      "[8086]\ttraining's binary_logloss: 0.008316\n",
      "[8087]\ttraining's binary_logloss: 0.00831502\n",
      "[8088]\ttraining's binary_logloss: 0.00831482\n",
      "[8089]\ttraining's binary_logloss: 0.00831403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8090]\ttraining's binary_logloss: 0.00831382\n",
      "[8091]\ttraining's binary_logloss: 0.00831363\n",
      "[8092]\ttraining's binary_logloss: 0.008313\n",
      "[8093]\ttraining's binary_logloss: 0.00831272\n",
      "[8094]\ttraining's binary_logloss: 0.00831251\n",
      "[8095]\ttraining's binary_logloss: 0.00831231\n",
      "[8096]\ttraining's binary_logloss: 0.00831185\n",
      "[8097]\ttraining's binary_logloss: 0.00831156\n",
      "[8098]\ttraining's binary_logloss: 0.00831137\n",
      "[8099]\ttraining's binary_logloss: 0.00831116\n",
      "[8100]\ttraining's binary_logloss: 0.00831096\n",
      "[8101]\ttraining's binary_logloss: 0.00831068\n",
      "[8102]\ttraining's binary_logloss: 0.00831015\n",
      "[8103]\ttraining's binary_logloss: 0.0083098\n",
      "[8104]\ttraining's binary_logloss: 0.0083096\n",
      "[8105]\ttraining's binary_logloss: 0.00830939\n",
      "[8106]\ttraining's binary_logloss: 0.0083092\n",
      "[8107]\ttraining's binary_logloss: 0.00830892\n",
      "[8108]\ttraining's binary_logloss: 0.00830872\n",
      "[8109]\ttraining's binary_logloss: 0.00830851\n",
      "[8110]\ttraining's binary_logloss: 0.00830782\n",
      "[8111]\ttraining's binary_logloss: 0.00830745\n",
      "[8112]\ttraining's binary_logloss: 0.00830667\n",
      "[8113]\ttraining's binary_logloss: 0.00830607\n",
      "[8114]\ttraining's binary_logloss: 0.00830576\n",
      "[8115]\ttraining's binary_logloss: 0.00830507\n",
      "[8116]\ttraining's binary_logloss: 0.00830475\n",
      "[8117]\ttraining's binary_logloss: 0.00830411\n",
      "[8118]\ttraining's binary_logloss: 0.00830378\n",
      "[8119]\ttraining's binary_logloss: 0.00830302\n",
      "[8120]\ttraining's binary_logloss: 0.00830266\n",
      "[8121]\ttraining's binary_logloss: 0.00830205\n",
      "[8122]\ttraining's binary_logloss: 0.00830173\n",
      "[8123]\ttraining's binary_logloss: 0.008301\n",
      "[8124]\ttraining's binary_logloss: 0.00830064\n",
      "[8125]\ttraining's binary_logloss: 0.00830033\n",
      "[8126]\ttraining's binary_logloss: 0.00829969\n",
      "[8127]\ttraining's binary_logloss: 0.00829933\n",
      "[8128]\ttraining's binary_logloss: 0.00829898\n",
      "[8129]\ttraining's binary_logloss: 0.00829863\n",
      "[8130]\ttraining's binary_logloss: 0.00829824\n",
      "[8131]\ttraining's binary_logloss: 0.00829728\n",
      "[8132]\ttraining's binary_logloss: 0.00829694\n",
      "[8133]\ttraining's binary_logloss: 0.00829632\n",
      "[8134]\ttraining's binary_logloss: 0.008296\n",
      "[8135]\ttraining's binary_logloss: 0.00829565\n",
      "[8136]\ttraining's binary_logloss: 0.00829498\n",
      "[8137]\ttraining's binary_logloss: 0.00829421\n",
      "[8138]\ttraining's binary_logloss: 0.00829402\n",
      "[8139]\ttraining's binary_logloss: 0.00829329\n",
      "[8140]\ttraining's binary_logloss: 0.008293\n",
      "[8141]\ttraining's binary_logloss: 0.00829281\n",
      "[8142]\ttraining's binary_logloss: 0.0082926\n",
      "[8143]\ttraining's binary_logloss: 0.00829228\n",
      "[8144]\ttraining's binary_logloss: 0.00829209\n",
      "[8145]\ttraining's binary_logloss: 0.00829173\n",
      "[8146]\ttraining's binary_logloss: 0.00829096\n",
      "[8147]\ttraining's binary_logloss: 0.00829027\n",
      "[8148]\ttraining's binary_logloss: 0.00828985\n",
      "[8149]\ttraining's binary_logloss: 0.0082893\n",
      "[8150]\ttraining's binary_logloss: 0.00828854\n",
      "[8151]\ttraining's binary_logloss: 0.00828819\n",
      "[8152]\ttraining's binary_logloss: 0.0082875\n",
      "[8153]\ttraining's binary_logloss: 0.00828669\n",
      "[8154]\ttraining's binary_logloss: 0.0082861\n",
      "[8155]\ttraining's binary_logloss: 0.0082854\n",
      "[8156]\ttraining's binary_logloss: 0.00828482\n",
      "[8157]\ttraining's binary_logloss: 0.0082845\n",
      "[8158]\ttraining's binary_logloss: 0.00828386\n",
      "[8159]\ttraining's binary_logloss: 0.00828312\n",
      "[8160]\ttraining's binary_logloss: 0.00828257\n",
      "[8161]\ttraining's binary_logloss: 0.00828227\n",
      "[8162]\ttraining's binary_logloss: 0.00828165\n",
      "[8163]\ttraining's binary_logloss: 0.00828134\n",
      "[8164]\ttraining's binary_logloss: 0.00828099\n",
      "[8165]\ttraining's binary_logloss: 0.00828066\n",
      "[8166]\ttraining's binary_logloss: 0.00828031\n",
      "[8167]\ttraining's binary_logloss: 0.00827965\n",
      "[8168]\ttraining's binary_logloss: 0.00827946\n",
      "[8169]\ttraining's binary_logloss: 0.00827917\n",
      "[8170]\ttraining's binary_logloss: 0.00827898\n",
      "[8171]\ttraining's binary_logloss: 0.00827877\n",
      "[8172]\ttraining's binary_logloss: 0.00827858\n",
      "[8173]\ttraining's binary_logloss: 0.0082783\n",
      "[8174]\ttraining's binary_logloss: 0.00827802\n",
      "[8175]\ttraining's binary_logloss: 0.00827716\n",
      "[8176]\ttraining's binary_logloss: 0.00827682\n",
      "[8177]\ttraining's binary_logloss: 0.00827627\n",
      "[8178]\ttraining's binary_logloss: 0.00827595\n",
      "[8179]\ttraining's binary_logloss: 0.00827516\n",
      "[8180]\ttraining's binary_logloss: 0.00827463\n",
      "[8181]\ttraining's binary_logloss: 0.00827433\n",
      "[8182]\ttraining's binary_logloss: 0.00827359\n",
      "[8183]\ttraining's binary_logloss: 0.00827318\n",
      "[8184]\ttraining's binary_logloss: 0.00827253\n",
      "[8185]\ttraining's binary_logloss: 0.00827181\n",
      "[8186]\ttraining's binary_logloss: 0.00827142\n",
      "[8187]\ttraining's binary_logloss: 0.00827123\n",
      "[8188]\ttraining's binary_logloss: 0.00827055\n",
      "[8189]\ttraining's binary_logloss: 0.00826985\n",
      "[8190]\ttraining's binary_logloss: 0.00826931\n",
      "[8191]\ttraining's binary_logloss: 0.00826876\n",
      "[8192]\ttraining's binary_logloss: 0.00826781\n",
      "[8193]\ttraining's binary_logloss: 0.00826746\n",
      "[8194]\ttraining's binary_logloss: 0.00826683\n",
      "[8195]\ttraining's binary_logloss: 0.0082663\n",
      "[8196]\ttraining's binary_logloss: 0.00826609\n",
      "[8197]\ttraining's binary_logloss: 0.00826571\n",
      "[8198]\ttraining's binary_logloss: 0.00826551\n",
      "[8199]\ttraining's binary_logloss: 0.00826489\n",
      "[8200]\ttraining's binary_logloss: 0.00826456\n",
      "[8201]\ttraining's binary_logloss: 0.00826427\n",
      "[8202]\ttraining's binary_logloss: 0.00826408\n",
      "[8203]\ttraining's binary_logloss: 0.00826348\n",
      "[8204]\ttraining's binary_logloss: 0.00826287\n",
      "[8205]\ttraining's binary_logloss: 0.00826265\n",
      "[8206]\ttraining's binary_logloss: 0.00826202\n",
      "[8207]\ttraining's binary_logloss: 0.00826132\n",
      "[8208]\ttraining's binary_logloss: 0.00826055\n",
      "[8209]\ttraining's binary_logloss: 0.00825994\n",
      "[8210]\ttraining's binary_logloss: 0.0082596\n",
      "[8211]\ttraining's binary_logloss: 0.00825941\n",
      "[8212]\ttraining's binary_logloss: 0.00825916\n",
      "[8213]\ttraining's binary_logloss: 0.00825884\n",
      "[8214]\ttraining's binary_logloss: 0.00825849\n",
      "[8215]\ttraining's binary_logloss: 0.00825817\n",
      "[8216]\ttraining's binary_logloss: 0.00825755\n",
      "[8217]\ttraining's binary_logloss: 0.00825695\n",
      "[8218]\ttraining's binary_logloss: 0.00825665\n",
      "[8219]\ttraining's binary_logloss: 0.00825637\n",
      "[8220]\ttraining's binary_logloss: 0.00825606\n",
      "[8221]\ttraining's binary_logloss: 0.00825524\n",
      "[8222]\ttraining's binary_logloss: 0.00825455\n",
      "[8223]\ttraining's binary_logloss: 0.00825435\n",
      "[8224]\ttraining's binary_logloss: 0.00825408\n",
      "[8225]\ttraining's binary_logloss: 0.00825389\n",
      "[8226]\ttraining's binary_logloss: 0.00825361\n",
      "[8227]\ttraining's binary_logloss: 0.00825328\n",
      "[8228]\ttraining's binary_logloss: 0.00825309\n",
      "[8229]\ttraining's binary_logloss: 0.00825288\n",
      "[8230]\ttraining's binary_logloss: 0.00825269\n",
      "[8231]\ttraining's binary_logloss: 0.00825241\n",
      "[8232]\ttraining's binary_logloss: 0.00825159\n",
      "[8233]\ttraining's binary_logloss: 0.00825126\n",
      "[8234]\ttraining's binary_logloss: 0.00825107\n",
      "[8235]\ttraining's binary_logloss: 0.00825087\n",
      "[8236]\ttraining's binary_logloss: 0.00825021\n",
      "[8237]\ttraining's binary_logloss: 0.00824957\n",
      "[8238]\ttraining's binary_logloss: 0.00824898\n",
      "[8239]\ttraining's binary_logloss: 0.00824844\n",
      "[8240]\ttraining's binary_logloss: 0.00824808\n",
      "[8241]\ttraining's binary_logloss: 0.00824767\n",
      "[8242]\ttraining's binary_logloss: 0.00824748\n",
      "[8243]\ttraining's binary_logloss: 0.00824661\n",
      "[8244]\ttraining's binary_logloss: 0.00824626\n",
      "[8245]\ttraining's binary_logloss: 0.00824517\n",
      "[8246]\ttraining's binary_logloss: 0.00824488\n",
      "[8247]\ttraining's binary_logloss: 0.00824459\n",
      "[8248]\ttraining's binary_logloss: 0.00824406\n",
      "[8249]\ttraining's binary_logloss: 0.00824327\n",
      "[8250]\ttraining's binary_logloss: 0.00824259\n",
      "[8251]\ttraining's binary_logloss: 0.00824232\n",
      "[8252]\ttraining's binary_logloss: 0.00824171\n",
      "[8253]\ttraining's binary_logloss: 0.00824138\n",
      "[8254]\ttraining's binary_logloss: 0.00824119\n",
      "[8255]\ttraining's binary_logloss: 0.00824092\n",
      "[8256]\ttraining's binary_logloss: 0.00824073\n",
      "[8257]\ttraining's binary_logloss: 0.00824052\n",
      "[8258]\ttraining's binary_logloss: 0.00824033\n",
      "[8259]\ttraining's binary_logloss: 0.00824013\n",
      "[8260]\ttraining's binary_logloss: 0.00823994\n",
      "[8261]\ttraining's binary_logloss: 0.00823966\n",
      "[8262]\ttraining's binary_logloss: 0.00823947\n",
      "[8263]\ttraining's binary_logloss: 0.00823927\n",
      "[8264]\ttraining's binary_logloss: 0.00823908\n",
      "[8265]\ttraining's binary_logloss: 0.00823887\n",
      "[8266]\ttraining's binary_logloss: 0.00823824\n",
      "[8267]\ttraining's binary_logloss: 0.00823793\n",
      "[8268]\ttraining's binary_logloss: 0.00823764\n",
      "[8269]\ttraining's binary_logloss: 0.00823745\n",
      "[8270]\ttraining's binary_logloss: 0.00823686\n",
      "[8271]\ttraining's binary_logloss: 0.00823643\n",
      "[8272]\ttraining's binary_logloss: 0.00823575\n",
      "[8273]\ttraining's binary_logloss: 0.00823523\n",
      "[8274]\ttraining's binary_logloss: 0.00823453\n",
      "[8275]\ttraining's binary_logloss: 0.00823418\n",
      "[8276]\ttraining's binary_logloss: 0.00823381\n",
      "[8277]\ttraining's binary_logloss: 0.00823319\n",
      "[8278]\ttraining's binary_logloss: 0.0082322\n",
      "[8279]\ttraining's binary_logloss: 0.00823188\n",
      "[8280]\ttraining's binary_logloss: 0.008231\n",
      "[8281]\ttraining's binary_logloss: 0.00823037\n",
      "[8282]\ttraining's binary_logloss: 0.00823008\n",
      "[8283]\ttraining's binary_logloss: 0.00822933\n",
      "[8284]\ttraining's binary_logloss: 0.00822865\n",
      "[8285]\ttraining's binary_logloss: 0.0082283\n",
      "[8286]\ttraining's binary_logloss: 0.00822753\n",
      "[8287]\ttraining's binary_logloss: 0.00822713\n",
      "[8288]\ttraining's binary_logloss: 0.00822639\n",
      "[8289]\ttraining's binary_logloss: 0.00822608\n",
      "[8290]\ttraining's binary_logloss: 0.00822574\n",
      "[8291]\ttraining's binary_logloss: 0.00822541\n",
      "[8292]\ttraining's binary_logloss: 0.00822475\n",
      "[8293]\ttraining's binary_logloss: 0.00822443\n",
      "[8294]\ttraining's binary_logloss: 0.00822414\n",
      "[8295]\ttraining's binary_logloss: 0.0082238\n",
      "[8296]\ttraining's binary_logloss: 0.00822349\n",
      "[8297]\ttraining's binary_logloss: 0.00822281\n",
      "[8298]\ttraining's binary_logloss: 0.00822222\n",
      "[8299]\ttraining's binary_logloss: 0.00822194\n",
      "[8300]\ttraining's binary_logloss: 0.00822163\n",
      "[8301]\ttraining's binary_logloss: 0.00822132\n",
      "[8302]\ttraining's binary_logloss: 0.00822048\n",
      "[8303]\ttraining's binary_logloss: 0.00821974\n",
      "[8304]\ttraining's binary_logloss: 0.00821922\n",
      "[8305]\ttraining's binary_logloss: 0.00821903\n",
      "[8306]\ttraining's binary_logloss: 0.00821875\n",
      "[8307]\ttraining's binary_logloss: 0.00821768\n",
      "[8308]\ttraining's binary_logloss: 0.0082174\n",
      "[8309]\ttraining's binary_logloss: 0.00821688\n",
      "[8310]\ttraining's binary_logloss: 0.00821653\n",
      "[8311]\ttraining's binary_logloss: 0.00821635\n",
      "[8312]\ttraining's binary_logloss: 0.0082161\n",
      "[8313]\ttraining's binary_logloss: 0.00821589\n",
      "[8314]\ttraining's binary_logloss: 0.0082157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8315]\ttraining's binary_logloss: 0.00821543\n",
      "[8316]\ttraining's binary_logloss: 0.00821524\n",
      "[8317]\ttraining's binary_logloss: 0.00821497\n",
      "[8318]\ttraining's binary_logloss: 0.00821457\n",
      "[8319]\ttraining's binary_logloss: 0.00821416\n",
      "[8320]\ttraining's binary_logloss: 0.00821376\n",
      "[8321]\ttraining's binary_logloss: 0.00821358\n",
      "[8322]\ttraining's binary_logloss: 0.00821337\n",
      "[8323]\ttraining's binary_logloss: 0.00821318\n",
      "[8324]\ttraining's binary_logloss: 0.00821291\n",
      "[8325]\ttraining's binary_logloss: 0.00821273\n",
      "[8326]\ttraining's binary_logloss: 0.0082122\n",
      "[8327]\ttraining's binary_logloss: 0.008212\n",
      "[8328]\ttraining's binary_logloss: 0.00821149\n",
      "[8329]\ttraining's binary_logloss: 0.00821115\n",
      "[8330]\ttraining's binary_logloss: 0.00821078\n",
      "[8331]\ttraining's binary_logloss: 0.00820981\n",
      "[8332]\ttraining's binary_logloss: 0.0082095\n",
      "[8333]\ttraining's binary_logloss: 0.0082087\n",
      "[8334]\ttraining's binary_logloss: 0.00820811\n",
      "[8335]\ttraining's binary_logloss: 0.00820743\n",
      "[8336]\ttraining's binary_logloss: 0.00820677\n",
      "[8337]\ttraining's binary_logloss: 0.00820618\n",
      "[8338]\ttraining's binary_logloss: 0.00820576\n",
      "[8339]\ttraining's binary_logloss: 0.00820558\n",
      "[8340]\ttraining's binary_logloss: 0.00820476\n",
      "[8341]\ttraining's binary_logloss: 0.00820442\n",
      "[8342]\ttraining's binary_logloss: 0.00820404\n",
      "[8343]\ttraining's binary_logloss: 0.00820345\n",
      "[8344]\ttraining's binary_logloss: 0.00820279\n",
      "[8345]\ttraining's binary_logloss: 0.00820189\n",
      "[8346]\ttraining's binary_logloss: 0.0082011\n",
      "[8347]\ttraining's binary_logloss: 0.00820077\n",
      "[8348]\ttraining's binary_logloss: 0.00820045\n",
      "[8349]\ttraining's binary_logloss: 0.00820014\n",
      "[8350]\ttraining's binary_logloss: 0.00819951\n",
      "[8351]\ttraining's binary_logloss: 0.00819872\n",
      "[8352]\ttraining's binary_logloss: 0.00819811\n",
      "[8353]\ttraining's binary_logloss: 0.00819792\n",
      "[8354]\ttraining's binary_logloss: 0.00819699\n",
      "[8355]\ttraining's binary_logloss: 0.00819678\n",
      "[8356]\ttraining's binary_logloss: 0.0081966\n",
      "[8357]\ttraining's binary_logloss: 0.00819639\n",
      "[8358]\ttraining's binary_logloss: 0.00819621\n",
      "[8359]\ttraining's binary_logloss: 0.00819593\n",
      "[8360]\ttraining's binary_logloss: 0.00819575\n",
      "[8361]\ttraining's binary_logloss: 0.00819502\n",
      "[8362]\ttraining's binary_logloss: 0.00819441\n",
      "[8363]\ttraining's binary_logloss: 0.00819405\n",
      "[8364]\ttraining's binary_logloss: 0.00819373\n",
      "[8365]\ttraining's binary_logloss: 0.00819347\n",
      "[8366]\ttraining's binary_logloss: 0.00819308\n",
      "[8367]\ttraining's binary_logloss: 0.00819267\n",
      "[8368]\ttraining's binary_logloss: 0.00819249\n",
      "[8369]\ttraining's binary_logloss: 0.00819172\n",
      "[8370]\ttraining's binary_logloss: 0.00819138\n",
      "[8371]\ttraining's binary_logloss: 0.0081908\n",
      "[8372]\ttraining's binary_logloss: 0.00819003\n",
      "[8373]\ttraining's binary_logloss: 0.00818983\n",
      "[8374]\ttraining's binary_logloss: 0.00818945\n",
      "[8375]\ttraining's binary_logloss: 0.00818926\n",
      "[8376]\ttraining's binary_logloss: 0.0081885\n",
      "[8377]\ttraining's binary_logloss: 0.00818815\n",
      "[8378]\ttraining's binary_logloss: 0.00818755\n",
      "[8379]\ttraining's binary_logloss: 0.00818723\n",
      "[8380]\ttraining's binary_logloss: 0.00818695\n",
      "[8381]\ttraining's binary_logloss: 0.00818666\n",
      "[8382]\ttraining's binary_logloss: 0.00818635\n",
      "[8383]\ttraining's binary_logloss: 0.00818594\n",
      "[8384]\ttraining's binary_logloss: 0.00818558\n",
      "[8385]\ttraining's binary_logloss: 0.0081853\n",
      "[8386]\ttraining's binary_logloss: 0.0081851\n",
      "[8387]\ttraining's binary_logloss: 0.00818478\n",
      "[8388]\ttraining's binary_logloss: 0.00818459\n",
      "[8389]\ttraining's binary_logloss: 0.00818433\n",
      "[8390]\ttraining's binary_logloss: 0.00818399\n",
      "[8391]\ttraining's binary_logloss: 0.0081838\n",
      "[8392]\ttraining's binary_logloss: 0.00818356\n",
      "[8393]\ttraining's binary_logloss: 0.00818262\n",
      "[8394]\ttraining's binary_logloss: 0.00818231\n",
      "[8395]\ttraining's binary_logloss: 0.0081819\n",
      "[8396]\ttraining's binary_logloss: 0.0081813\n",
      "[8397]\ttraining's binary_logloss: 0.00818099\n",
      "[8398]\ttraining's binary_logloss: 0.00818068\n",
      "[8399]\ttraining's binary_logloss: 0.0081797\n",
      "[8400]\ttraining's binary_logloss: 0.00817905\n",
      "[8401]\ttraining's binary_logloss: 0.00817872\n",
      "[8402]\ttraining's binary_logloss: 0.00817806\n",
      "[8403]\ttraining's binary_logloss: 0.00817787\n",
      "[8404]\ttraining's binary_logloss: 0.00817696\n",
      "[8405]\ttraining's binary_logloss: 0.00817676\n",
      "[8406]\ttraining's binary_logloss: 0.00817588\n",
      "[8407]\ttraining's binary_logloss: 0.00817527\n",
      "[8408]\ttraining's binary_logloss: 0.00817488\n",
      "[8409]\ttraining's binary_logloss: 0.00817456\n",
      "[8410]\ttraining's binary_logloss: 0.00817429\n",
      "[8411]\ttraining's binary_logloss: 0.00817354\n",
      "[8412]\ttraining's binary_logloss: 0.00817325\n",
      "[8413]\ttraining's binary_logloss: 0.00817294\n",
      "[8414]\ttraining's binary_logloss: 0.00817263\n",
      "[8415]\ttraining's binary_logloss: 0.00817204\n",
      "[8416]\ttraining's binary_logloss: 0.00817185\n",
      "[8417]\ttraining's binary_logloss: 0.00817154\n",
      "[8418]\ttraining's binary_logloss: 0.00817134\n",
      "[8419]\ttraining's binary_logloss: 0.00817115\n",
      "[8420]\ttraining's binary_logloss: 0.00817088\n",
      "[8421]\ttraining's binary_logloss: 0.0081707\n",
      "[8422]\ttraining's binary_logloss: 0.0081705\n",
      "[8423]\ttraining's binary_logloss: 0.00817031\n",
      "[8424]\ttraining's binary_logloss: 0.00817005\n",
      "[8425]\ttraining's binary_logloss: 0.00816974\n",
      "[8426]\ttraining's binary_logloss: 0.00816886\n",
      "[8427]\ttraining's binary_logloss: 0.00816855\n",
      "[8428]\ttraining's binary_logloss: 0.00816764\n",
      "[8429]\ttraining's binary_logloss: 0.00816733\n",
      "[8430]\ttraining's binary_logloss: 0.00816692\n",
      "[8431]\ttraining's binary_logloss: 0.00816674\n",
      "[8432]\ttraining's binary_logloss: 0.00816609\n",
      "[8433]\ttraining's binary_logloss: 0.00816574\n",
      "[8434]\ttraining's binary_logloss: 0.00816491\n",
      "[8435]\ttraining's binary_logloss: 0.00816456\n",
      "[8436]\ttraining's binary_logloss: 0.00816376\n",
      "[8437]\ttraining's binary_logloss: 0.00816341\n",
      "[8438]\ttraining's binary_logloss: 0.00816307\n",
      "[8439]\ttraining's binary_logloss: 0.00816273\n",
      "[8440]\ttraining's binary_logloss: 0.00816239\n",
      "[8441]\ttraining's binary_logloss: 0.00816183\n",
      "[8442]\ttraining's binary_logloss: 0.00816143\n",
      "[8443]\ttraining's binary_logloss: 0.00816112\n",
      "[8444]\ttraining's binary_logloss: 0.00816084\n",
      "[8445]\ttraining's binary_logloss: 0.00815993\n",
      "[8446]\ttraining's binary_logloss: 0.00815942\n",
      "[8447]\ttraining's binary_logloss: 0.00815865\n",
      "[8448]\ttraining's binary_logloss: 0.00815805\n",
      "[8449]\ttraining's binary_logloss: 0.00815753\n",
      "[8450]\ttraining's binary_logloss: 0.00815721\n",
      "[8451]\ttraining's binary_logloss: 0.00815693\n",
      "[8452]\ttraining's binary_logloss: 0.0081566\n",
      "[8453]\ttraining's binary_logloss: 0.00815573\n",
      "[8454]\ttraining's binary_logloss: 0.00815494\n",
      "[8455]\ttraining's binary_logloss: 0.00815424\n",
      "[8456]\ttraining's binary_logloss: 0.00815397\n",
      "[8457]\ttraining's binary_logloss: 0.00815327\n",
      "[8458]\ttraining's binary_logloss: 0.0081526\n",
      "[8459]\ttraining's binary_logloss: 0.00815224\n",
      "[8460]\ttraining's binary_logloss: 0.00815158\n",
      "[8461]\ttraining's binary_logloss: 0.00815124\n",
      "[8462]\ttraining's binary_logloss: 0.0081509\n",
      "[8463]\ttraining's binary_logloss: 0.00815002\n",
      "[8464]\ttraining's binary_logloss: 0.00814971\n",
      "[8465]\ttraining's binary_logloss: 0.00814932\n",
      "[8466]\ttraining's binary_logloss: 0.00814903\n",
      "[8467]\ttraining's binary_logloss: 0.00814872\n",
      "[8468]\ttraining's binary_logloss: 0.00814842\n",
      "[8469]\ttraining's binary_logloss: 0.00814784\n",
      "[8470]\ttraining's binary_logloss: 0.00814752\n",
      "[8471]\ttraining's binary_logloss: 0.00814699\n",
      "[8472]\ttraining's binary_logloss: 0.00814613\n",
      "[8473]\ttraining's binary_logloss: 0.00814537\n",
      "[8474]\ttraining's binary_logloss: 0.00814506\n",
      "[8475]\ttraining's binary_logloss: 0.00814471\n",
      "[8476]\ttraining's binary_logloss: 0.00814391\n",
      "[8477]\ttraining's binary_logloss: 0.00814318\n",
      "[8478]\ttraining's binary_logloss: 0.00814238\n",
      "[8479]\ttraining's binary_logloss: 0.00814209\n",
      "[8480]\ttraining's binary_logloss: 0.00814154\n",
      "[8481]\ttraining's binary_logloss: 0.00814123\n",
      "[8482]\ttraining's binary_logloss: 0.00814092\n",
      "[8483]\ttraining's binary_logloss: 0.00814059\n",
      "[8484]\ttraining's binary_logloss: 0.00813992\n",
      "[8485]\ttraining's binary_logloss: 0.00813973\n",
      "[8486]\ttraining's binary_logloss: 0.00813946\n",
      "[8487]\ttraining's binary_logloss: 0.00813915\n",
      "[8488]\ttraining's binary_logloss: 0.00813856\n",
      "[8489]\ttraining's binary_logloss: 0.00813791\n",
      "[8490]\ttraining's binary_logloss: 0.00813773\n",
      "[8491]\ttraining's binary_logloss: 0.00813692\n",
      "[8492]\ttraining's binary_logloss: 0.00813633\n",
      "[8493]\ttraining's binary_logloss: 0.00813603\n",
      "[8494]\ttraining's binary_logloss: 0.0081357\n",
      "[8495]\ttraining's binary_logloss: 0.00813543\n",
      "[8496]\ttraining's binary_logloss: 0.00813525\n",
      "[8497]\ttraining's binary_logloss: 0.00813496\n",
      "[8498]\ttraining's binary_logloss: 0.00813476\n",
      "[8499]\ttraining's binary_logloss: 0.00813404\n",
      "[8500]\ttraining's binary_logloss: 0.00813385\n",
      "[8501]\ttraining's binary_logloss: 0.00813335\n",
      "[8502]\ttraining's binary_logloss: 0.00813264\n",
      "[8503]\ttraining's binary_logloss: 0.00813233\n",
      "[8504]\ttraining's binary_logloss: 0.008132\n",
      "[8505]\ttraining's binary_logloss: 0.00813165\n",
      "[8506]\ttraining's binary_logloss: 0.00813134\n",
      "[8507]\ttraining's binary_logloss: 0.00813083\n",
      "[8508]\ttraining's binary_logloss: 0.00813063\n",
      "[8509]\ttraining's binary_logloss: 0.00813044\n",
      "[8510]\ttraining's binary_logloss: 0.00813018\n",
      "[8511]\ttraining's binary_logloss: 0.00813\n",
      "[8512]\ttraining's binary_logloss: 0.0081298\n",
      "[8513]\ttraining's binary_logloss: 0.00812947\n",
      "[8514]\ttraining's binary_logloss: 0.00812928\n",
      "[8515]\ttraining's binary_logloss: 0.00812888\n",
      "[8516]\ttraining's binary_logloss: 0.00812814\n",
      "[8517]\ttraining's binary_logloss: 0.00812735\n",
      "[8518]\ttraining's binary_logloss: 0.00812667\n",
      "[8519]\ttraining's binary_logloss: 0.00812634\n",
      "[8520]\ttraining's binary_logloss: 0.00812604\n",
      "[8521]\ttraining's binary_logloss: 0.00812577\n",
      "[8522]\ttraining's binary_logloss: 0.008125\n",
      "[8523]\ttraining's binary_logloss: 0.00812463\n",
      "[8524]\ttraining's binary_logloss: 0.00812387\n",
      "[8525]\ttraining's binary_logloss: 0.00812294\n",
      "[8526]\ttraining's binary_logloss: 0.00812263\n",
      "[8527]\ttraining's binary_logloss: 0.00812205\n",
      "[8528]\ttraining's binary_logloss: 0.0081214\n",
      "[8529]\ttraining's binary_logloss: 0.00812077\n",
      "[8530]\ttraining's binary_logloss: 0.00812009\n",
      "[8531]\ttraining's binary_logloss: 0.00811979\n",
      "[8532]\ttraining's binary_logloss: 0.00811948\n",
      "[8533]\ttraining's binary_logloss: 0.00811916\n",
      "[8534]\ttraining's binary_logloss: 0.00811849\n",
      "[8535]\ttraining's binary_logloss: 0.00811771\n",
      "[8536]\ttraining's binary_logloss: 0.00811686\n",
      "[8537]\ttraining's binary_logloss: 0.00811652\n",
      "[8538]\ttraining's binary_logloss: 0.00811624\n",
      "[8539]\ttraining's binary_logloss: 0.00811606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8540]\ttraining's binary_logloss: 0.00811586\n",
      "[8541]\ttraining's binary_logloss: 0.00811544\n",
      "[8542]\ttraining's binary_logloss: 0.00811508\n",
      "[8543]\ttraining's binary_logloss: 0.00811478\n",
      "[8544]\ttraining's binary_logloss: 0.00811406\n",
      "[8545]\ttraining's binary_logloss: 0.00811376\n",
      "[8546]\ttraining's binary_logloss: 0.0081132\n",
      "[8547]\ttraining's binary_logloss: 0.0081127\n",
      "[8548]\ttraining's binary_logloss: 0.00811242\n",
      "[8549]\ttraining's binary_logloss: 0.00811176\n",
      "[8550]\ttraining's binary_logloss: 0.00811157\n",
      "[8551]\ttraining's binary_logloss: 0.00811138\n",
      "[8552]\ttraining's binary_logloss: 0.00811108\n",
      "[8553]\ttraining's binary_logloss: 0.00811075\n",
      "[8554]\ttraining's binary_logloss: 0.00811001\n",
      "[8555]\ttraining's binary_logloss: 0.00810965\n",
      "[8556]\ttraining's binary_logloss: 0.00810946\n",
      "[8557]\ttraining's binary_logloss: 0.00810882\n",
      "[8558]\ttraining's binary_logloss: 0.00810797\n",
      "[8559]\ttraining's binary_logloss: 0.00810772\n",
      "[8560]\ttraining's binary_logloss: 0.00810742\n",
      "[8561]\ttraining's binary_logloss: 0.00810706\n",
      "[8562]\ttraining's binary_logloss: 0.00810636\n",
      "[8563]\ttraining's binary_logloss: 0.00810617\n",
      "[8564]\ttraining's binary_logloss: 0.00810552\n",
      "[8565]\ttraining's binary_logloss: 0.0081052\n",
      "[8566]\ttraining's binary_logloss: 0.00810501\n",
      "[8567]\ttraining's binary_logloss: 0.00810475\n",
      "[8568]\ttraining's binary_logloss: 0.00810457\n",
      "[8569]\ttraining's binary_logloss: 0.00810393\n",
      "[8570]\ttraining's binary_logloss: 0.00810312\n",
      "[8571]\ttraining's binary_logloss: 0.00810287\n",
      "[8572]\ttraining's binary_logloss: 0.00810268\n",
      "[8573]\ttraining's binary_logloss: 0.00810248\n",
      "[8574]\ttraining's binary_logloss: 0.0081023\n",
      "[8575]\ttraining's binary_logloss: 0.00810204\n",
      "[8576]\ttraining's binary_logloss: 0.00810186\n",
      "[8577]\ttraining's binary_logloss: 0.00810128\n",
      "[8578]\ttraining's binary_logloss: 0.00810102\n",
      "[8579]\ttraining's binary_logloss: 0.00810072\n",
      "[8580]\ttraining's binary_logloss: 0.00810039\n",
      "[8581]\ttraining's binary_logloss: 0.00810009\n",
      "[8582]\ttraining's binary_logloss: 0.00809951\n",
      "[8583]\ttraining's binary_logloss: 0.00809893\n",
      "[8584]\ttraining's binary_logloss: 0.00809864\n",
      "[8585]\ttraining's binary_logloss: 0.00809831\n",
      "[8586]\ttraining's binary_logloss: 0.00809769\n",
      "[8587]\ttraining's binary_logloss: 0.00809707\n",
      "[8588]\ttraining's binary_logloss: 0.00809652\n",
      "[8589]\ttraining's binary_logloss: 0.00809622\n",
      "[8590]\ttraining's binary_logloss: 0.00809592\n",
      "[8591]\ttraining's binary_logloss: 0.00809514\n",
      "[8592]\ttraining's binary_logloss: 0.0080946\n",
      "[8593]\ttraining's binary_logloss: 0.00809426\n",
      "[8594]\ttraining's binary_logloss: 0.00809361\n",
      "[8595]\ttraining's binary_logloss: 0.00809289\n",
      "[8596]\ttraining's binary_logloss: 0.0080926\n",
      "[8597]\ttraining's binary_logloss: 0.00809241\n",
      "[8598]\ttraining's binary_logloss: 0.00809182\n",
      "[8599]\ttraining's binary_logloss: 0.00809153\n",
      "[8600]\ttraining's binary_logloss: 0.00809127\n",
      "[8601]\ttraining's binary_logloss: 0.00809108\n",
      "[8602]\ttraining's binary_logloss: 0.00809081\n",
      "[8603]\ttraining's binary_logloss: 0.00809056\n",
      "[8604]\ttraining's binary_logloss: 0.00808974\n",
      "[8605]\ttraining's binary_logloss: 0.00808947\n",
      "[8606]\ttraining's binary_logloss: 0.00808909\n",
      "[8607]\ttraining's binary_logloss: 0.00808873\n",
      "[8608]\ttraining's binary_logloss: 0.00808841\n",
      "[8609]\ttraining's binary_logloss: 0.00808758\n",
      "[8610]\ttraining's binary_logloss: 0.008087\n",
      "[8611]\ttraining's binary_logloss: 0.00808668\n",
      "[8612]\ttraining's binary_logloss: 0.00808638\n",
      "[8613]\ttraining's binary_logloss: 0.00808606\n",
      "[8614]\ttraining's binary_logloss: 0.0080852\n",
      "[8615]\ttraining's binary_logloss: 0.00808483\n",
      "[8616]\ttraining's binary_logloss: 0.00808447\n",
      "[8617]\ttraining's binary_logloss: 0.00808364\n",
      "[8618]\ttraining's binary_logloss: 0.00808346\n",
      "[8619]\ttraining's binary_logloss: 0.00808326\n",
      "[8620]\ttraining's binary_logloss: 0.00808257\n",
      "[8621]\ttraining's binary_logloss: 0.00808198\n",
      "[8622]\ttraining's binary_logloss: 0.00808108\n",
      "[8623]\ttraining's binary_logloss: 0.00808034\n",
      "[8624]\ttraining's binary_logloss: 0.0080797\n",
      "[8625]\ttraining's binary_logloss: 0.00807929\n",
      "[8626]\ttraining's binary_logloss: 0.00807855\n",
      "[8627]\ttraining's binary_logloss: 0.00807783\n",
      "[8628]\ttraining's binary_logloss: 0.00807756\n",
      "[8629]\ttraining's binary_logloss: 0.00807683\n",
      "[8630]\ttraining's binary_logloss: 0.00807604\n",
      "[8631]\ttraining's binary_logloss: 0.00807585\n",
      "[8632]\ttraining's binary_logloss: 0.00807528\n",
      "[8633]\ttraining's binary_logloss: 0.00807456\n",
      "[8634]\ttraining's binary_logloss: 0.00807427\n",
      "[8635]\ttraining's binary_logloss: 0.00807388\n",
      "[8636]\ttraining's binary_logloss: 0.00807358\n",
      "[8637]\ttraining's binary_logloss: 0.00807338\n",
      "[8638]\ttraining's binary_logloss: 0.0080732\n",
      "[8639]\ttraining's binary_logloss: 0.0080729\n",
      "[8640]\ttraining's binary_logloss: 0.00807232\n",
      "[8641]\ttraining's binary_logloss: 0.00807202\n",
      "[8642]\ttraining's binary_logloss: 0.00807176\n",
      "[8643]\ttraining's binary_logloss: 0.00807149\n",
      "[8644]\ttraining's binary_logloss: 0.00807131\n",
      "[8645]\ttraining's binary_logloss: 0.00807111\n",
      "[8646]\ttraining's binary_logloss: 0.00807093\n",
      "[8647]\ttraining's binary_logloss: 0.00807073\n",
      "[8648]\ttraining's binary_logloss: 0.00807055\n",
      "[8649]\ttraining's binary_logloss: 0.0080703\n",
      "[8650]\ttraining's binary_logloss: 0.00807012\n",
      "[8651]\ttraining's binary_logloss: 0.00806992\n",
      "[8652]\ttraining's binary_logloss: 0.00806974\n",
      "[8653]\ttraining's binary_logloss: 0.00806949\n",
      "[8654]\ttraining's binary_logloss: 0.00806925\n",
      "[8655]\ttraining's binary_logloss: 0.00806868\n",
      "[8656]\ttraining's binary_logloss: 0.00806829\n",
      "[8657]\ttraining's binary_logloss: 0.00806755\n",
      "[8658]\ttraining's binary_logloss: 0.00806727\n",
      "[8659]\ttraining's binary_logloss: 0.00806708\n",
      "[8660]\ttraining's binary_logloss: 0.00806637\n",
      "[8661]\ttraining's binary_logloss: 0.00806593\n",
      "[8662]\ttraining's binary_logloss: 0.00806564\n",
      "[8663]\ttraining's binary_logloss: 0.00806531\n",
      "[8664]\ttraining's binary_logloss: 0.00806467\n",
      "[8665]\ttraining's binary_logloss: 0.00806396\n",
      "[8666]\ttraining's binary_logloss: 0.00806334\n",
      "[8667]\ttraining's binary_logloss: 0.00806249\n",
      "[8668]\ttraining's binary_logloss: 0.00806177\n",
      "[8669]\ttraining's binary_logloss: 0.00806084\n",
      "[8670]\ttraining's binary_logloss: 0.00806055\n",
      "[8671]\ttraining's binary_logloss: 0.00806025\n",
      "[8672]\ttraining's binary_logloss: 0.00806007\n",
      "[8673]\ttraining's binary_logloss: 0.00805939\n",
      "[8674]\ttraining's binary_logloss: 0.00805919\n",
      "[8675]\ttraining's binary_logloss: 0.00805886\n",
      "[8676]\ttraining's binary_logloss: 0.00805852\n",
      "[8677]\ttraining's binary_logloss: 0.0080582\n",
      "[8678]\ttraining's binary_logloss: 0.00805772\n",
      "[8679]\ttraining's binary_logloss: 0.00805714\n",
      "[8680]\ttraining's binary_logloss: 0.00805696\n",
      "[8681]\ttraining's binary_logloss: 0.00805649\n",
      "[8682]\ttraining's binary_logloss: 0.00805614\n",
      "[8683]\ttraining's binary_logloss: 0.00805543\n",
      "[8684]\ttraining's binary_logloss: 0.00805505\n",
      "[8685]\ttraining's binary_logloss: 0.00805435\n",
      "[8686]\ttraining's binary_logloss: 0.00805363\n",
      "[8687]\ttraining's binary_logloss: 0.00805329\n",
      "[8688]\ttraining's binary_logloss: 0.00805235\n",
      "[8689]\ttraining's binary_logloss: 0.00805151\n",
      "[8690]\ttraining's binary_logloss: 0.00805078\n",
      "[8691]\ttraining's binary_logloss: 0.00804988\n",
      "[8692]\ttraining's binary_logloss: 0.00804955\n",
      "[8693]\ttraining's binary_logloss: 0.0080493\n",
      "[8694]\ttraining's binary_logloss: 0.00804862\n",
      "[8695]\ttraining's binary_logloss: 0.00804801\n",
      "[8696]\ttraining's binary_logloss: 0.00804783\n",
      "[8697]\ttraining's binary_logloss: 0.00804758\n",
      "[8698]\ttraining's binary_logloss: 0.00804697\n",
      "[8699]\ttraining's binary_logloss: 0.00804665\n",
      "[8700]\ttraining's binary_logloss: 0.00804604\n",
      "[8701]\ttraining's binary_logloss: 0.00804573\n",
      "[8702]\ttraining's binary_logloss: 0.00804545\n",
      "[8703]\ttraining's binary_logloss: 0.00804527\n",
      "[8704]\ttraining's binary_logloss: 0.00804507\n",
      "[8705]\ttraining's binary_logloss: 0.00804489\n",
      "[8706]\ttraining's binary_logloss: 0.00804465\n",
      "[8707]\ttraining's binary_logloss: 0.00804412\n",
      "[8708]\ttraining's binary_logloss: 0.00804387\n",
      "[8709]\ttraining's binary_logloss: 0.00804339\n",
      "[8710]\ttraining's binary_logloss: 0.00804237\n",
      "[8711]\ttraining's binary_logloss: 0.00804209\n",
      "[8712]\ttraining's binary_logloss: 0.00804139\n",
      "[8713]\ttraining's binary_logloss: 0.00804047\n",
      "[8714]\ttraining's binary_logloss: 0.00803977\n",
      "[8715]\ttraining's binary_logloss: 0.0080395\n",
      "[8716]\ttraining's binary_logloss: 0.00803879\n",
      "[8717]\ttraining's binary_logloss: 0.00803796\n",
      "[8718]\ttraining's binary_logloss: 0.00803719\n",
      "[8719]\ttraining's binary_logloss: 0.00803687\n",
      "[8720]\ttraining's binary_logloss: 0.00803623\n",
      "[8721]\ttraining's binary_logloss: 0.00803554\n",
      "[8722]\ttraining's binary_logloss: 0.00803495\n",
      "[8723]\ttraining's binary_logloss: 0.00803415\n",
      "[8724]\ttraining's binary_logloss: 0.00803385\n",
      "[8725]\ttraining's binary_logloss: 0.00803327\n",
      "[8726]\ttraining's binary_logloss: 0.00803271\n",
      "[8727]\ttraining's binary_logloss: 0.00803236\n",
      "[8728]\ttraining's binary_logloss: 0.00803202\n",
      "[8729]\ttraining's binary_logloss: 0.00803184\n",
      "[8730]\ttraining's binary_logloss: 0.00803159\n",
      "[8731]\ttraining's binary_logloss: 0.00803087\n",
      "[8732]\ttraining's binary_logloss: 0.00803051\n",
      "[8733]\ttraining's binary_logloss: 0.00803033\n",
      "[8734]\ttraining's binary_logloss: 0.00803005\n",
      "[8735]\ttraining's binary_logloss: 0.00802976\n",
      "[8736]\ttraining's binary_logloss: 0.0080292\n",
      "[8737]\ttraining's binary_logloss: 0.00802892\n",
      "[8738]\ttraining's binary_logloss: 0.00802858\n",
      "[8739]\ttraining's binary_logloss: 0.00802795\n",
      "[8740]\ttraining's binary_logloss: 0.00802763\n",
      "[8741]\ttraining's binary_logloss: 0.00802729\n",
      "[8742]\ttraining's binary_logloss: 0.00802664\n",
      "[8743]\ttraining's binary_logloss: 0.00802612\n",
      "[8744]\ttraining's binary_logloss: 0.00802562\n",
      "[8745]\ttraining's binary_logloss: 0.00802532\n",
      "[8746]\ttraining's binary_logloss: 0.00802456\n",
      "[8747]\ttraining's binary_logloss: 0.00802424\n",
      "[8748]\ttraining's binary_logloss: 0.00802391\n",
      "[8749]\ttraining's binary_logloss: 0.0080236\n",
      "[8750]\ttraining's binary_logloss: 0.00802327\n",
      "[8751]\ttraining's binary_logloss: 0.00802289\n",
      "[8752]\ttraining's binary_logloss: 0.00802232\n",
      "[8753]\ttraining's binary_logloss: 0.00802175\n",
      "[8754]\ttraining's binary_logloss: 0.00802142\n",
      "[8755]\ttraining's binary_logloss: 0.00802115\n",
      "[8756]\ttraining's binary_logloss: 0.00802048\n",
      "[8757]\ttraining's binary_logloss: 0.0080203\n",
      "[8758]\ttraining's binary_logloss: 0.0080201\n",
      "[8759]\ttraining's binary_logloss: 0.00801984\n",
      "[8760]\ttraining's binary_logloss: 0.00801953\n",
      "[8761]\ttraining's binary_logloss: 0.00801935\n",
      "[8762]\ttraining's binary_logloss: 0.00801911\n",
      "[8763]\ttraining's binary_logloss: 0.00801887\n",
      "[8764]\ttraining's binary_logloss: 0.00801822\n",
      "[8765]\ttraining's binary_logloss: 0.00801765\n",
      "[8766]\ttraining's binary_logloss: 0.00801684\n",
      "[8767]\ttraining's binary_logloss: 0.0080165\n",
      "[8768]\ttraining's binary_logloss: 0.0080162\n",
      "[8769]\ttraining's binary_logloss: 0.0080156\n",
      "[8770]\ttraining's binary_logloss: 0.00801523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8771]\ttraining's binary_logloss: 0.00801454\n",
      "[8772]\ttraining's binary_logloss: 0.00801402\n",
      "[8773]\ttraining's binary_logloss: 0.00801383\n",
      "[8774]\ttraining's binary_logloss: 0.00801365\n",
      "[8775]\ttraining's binary_logloss: 0.00801293\n",
      "[8776]\ttraining's binary_logloss: 0.00801205\n",
      "[8777]\ttraining's binary_logloss: 0.00801176\n",
      "[8778]\ttraining's binary_logloss: 0.00801157\n",
      "[8779]\ttraining's binary_logloss: 0.00801139\n",
      "[8780]\ttraining's binary_logloss: 0.00801119\n",
      "[8781]\ttraining's binary_logloss: 0.00801101\n",
      "[8782]\ttraining's binary_logloss: 0.00801083\n",
      "[8783]\ttraining's binary_logloss: 0.00801064\n",
      "[8784]\ttraining's binary_logloss: 0.00801045\n",
      "[8785]\ttraining's binary_logloss: 0.00801027\n",
      "[8786]\ttraining's binary_logloss: 0.00801009\n",
      "[8787]\ttraining's binary_logloss: 0.0080099\n",
      "[8788]\ttraining's binary_logloss: 0.00800971\n",
      "[8789]\ttraining's binary_logloss: 0.00800953\n",
      "[8790]\ttraining's binary_logloss: 0.00800935\n",
      "[8791]\ttraining's binary_logloss: 0.00800916\n",
      "[8792]\ttraining's binary_logloss: 0.00800897\n",
      "[8793]\ttraining's binary_logloss: 0.00800838\n",
      "[8794]\ttraining's binary_logloss: 0.00800788\n",
      "[8795]\ttraining's binary_logloss: 0.00800738\n",
      "[8796]\ttraining's binary_logloss: 0.0080067\n",
      "[8797]\ttraining's binary_logloss: 0.00800652\n",
      "[8798]\ttraining's binary_logloss: 0.00800633\n",
      "[8799]\ttraining's binary_logloss: 0.00800604\n",
      "[8800]\ttraining's binary_logloss: 0.00800586\n",
      "[8801]\ttraining's binary_logloss: 0.00800552\n",
      "[8802]\ttraining's binary_logloss: 0.00800486\n",
      "[8803]\ttraining's binary_logloss: 0.00800457\n",
      "[8804]\ttraining's binary_logloss: 0.00800428\n",
      "[8805]\ttraining's binary_logloss: 0.0080038\n",
      "[8806]\ttraining's binary_logloss: 0.00800309\n",
      "[8807]\ttraining's binary_logloss: 0.00800284\n",
      "[8808]\ttraining's binary_logloss: 0.00800222\n",
      "[8809]\ttraining's binary_logloss: 0.00800165\n",
      "[8810]\ttraining's binary_logloss: 0.00800136\n",
      "[8811]\ttraining's binary_logloss: 0.00800106\n",
      "[8812]\ttraining's binary_logloss: 0.00800047\n",
      "[8813]\ttraining's binary_logloss: 0.00799967\n",
      "[8814]\ttraining's binary_logloss: 0.00799904\n",
      "[8815]\ttraining's binary_logloss: 0.00799824\n",
      "[8816]\ttraining's binary_logloss: 0.00799763\n",
      "[8817]\ttraining's binary_logloss: 0.00799737\n",
      "[8818]\ttraining's binary_logloss: 0.00799705\n",
      "[8819]\ttraining's binary_logloss: 0.00799605\n",
      "[8820]\ttraining's binary_logloss: 0.00799578\n",
      "[8821]\ttraining's binary_logloss: 0.00799509\n",
      "[8822]\ttraining's binary_logloss: 0.00799402\n",
      "[8823]\ttraining's binary_logloss: 0.00799335\n",
      "[8824]\ttraining's binary_logloss: 0.00799306\n",
      "[8825]\ttraining's binary_logloss: 0.00799287\n",
      "[8826]\ttraining's binary_logloss: 0.00799211\n",
      "[8827]\ttraining's binary_logloss: 0.00799155\n",
      "[8828]\ttraining's binary_logloss: 0.00799119\n",
      "[8829]\ttraining's binary_logloss: 0.00799042\n",
      "[8830]\ttraining's binary_logloss: 0.00798993\n",
      "[8831]\ttraining's binary_logloss: 0.00798914\n",
      "[8832]\ttraining's binary_logloss: 0.00798883\n",
      "[8833]\ttraining's binary_logloss: 0.00798815\n",
      "[8834]\ttraining's binary_logloss: 0.00798796\n",
      "[8835]\ttraining's binary_logloss: 0.00798758\n",
      "[8836]\ttraining's binary_logloss: 0.0079874\n",
      "[8837]\ttraining's binary_logloss: 0.00798721\n",
      "[8838]\ttraining's binary_logloss: 0.00798703\n",
      "[8839]\ttraining's binary_logloss: 0.00798667\n",
      "[8840]\ttraining's binary_logloss: 0.00798608\n",
      "[8841]\ttraining's binary_logloss: 0.00798589\n",
      "[8842]\ttraining's binary_logloss: 0.00798571\n",
      "[8843]\ttraining's binary_logloss: 0.00798553\n",
      "[8844]\ttraining's binary_logloss: 0.00798535\n",
      "[8845]\ttraining's binary_logloss: 0.00798516\n",
      "[8846]\ttraining's binary_logloss: 0.00798498\n",
      "[8847]\ttraining's binary_logloss: 0.0079848\n",
      "[8848]\ttraining's binary_logloss: 0.00798404\n",
      "[8849]\ttraining's binary_logloss: 0.00798325\n",
      "[8850]\ttraining's binary_logloss: 0.00798295\n",
      "[8851]\ttraining's binary_logloss: 0.0079826\n",
      "[8852]\ttraining's binary_logloss: 0.00798186\n",
      "[8853]\ttraining's binary_logloss: 0.00798154\n",
      "[8854]\ttraining's binary_logloss: 0.00798136\n",
      "[8855]\ttraining's binary_logloss: 0.00798065\n",
      "[8856]\ttraining's binary_logloss: 0.00798041\n",
      "[8857]\ttraining's binary_logloss: 0.00797969\n",
      "[8858]\ttraining's binary_logloss: 0.00797939\n",
      "[8859]\ttraining's binary_logloss: 0.00797878\n",
      "[8860]\ttraining's binary_logloss: 0.00797848\n",
      "[8861]\ttraining's binary_logloss: 0.00797816\n",
      "[8862]\ttraining's binary_logloss: 0.00797784\n",
      "[8863]\ttraining's binary_logloss: 0.00797715\n",
      "[8864]\ttraining's binary_logloss: 0.00797659\n",
      "[8865]\ttraining's binary_logloss: 0.00797602\n",
      "[8866]\ttraining's binary_logloss: 0.00797584\n",
      "[8867]\ttraining's binary_logloss: 0.00797554\n",
      "[8868]\ttraining's binary_logloss: 0.00797535\n",
      "[8869]\ttraining's binary_logloss: 0.00797517\n",
      "[8870]\ttraining's binary_logloss: 0.00797498\n",
      "[8871]\ttraining's binary_logloss: 0.0079748\n",
      "[8872]\ttraining's binary_logloss: 0.00797462\n",
      "[8873]\ttraining's binary_logloss: 0.00797444\n",
      "[8874]\ttraining's binary_logloss: 0.00797425\n",
      "[8875]\ttraining's binary_logloss: 0.00797357\n",
      "[8876]\ttraining's binary_logloss: 0.00797339\n",
      "[8877]\ttraining's binary_logloss: 0.00797312\n",
      "[8878]\ttraining's binary_logloss: 0.00797283\n",
      "[8879]\ttraining's binary_logloss: 0.00797226\n",
      "[8880]\ttraining's binary_logloss: 0.00797172\n",
      "[8881]\ttraining's binary_logloss: 0.00797142\n",
      "[8882]\ttraining's binary_logloss: 0.00797118\n",
      "[8883]\ttraining's binary_logloss: 0.00797038\n",
      "[8884]\ttraining's binary_logloss: 0.00796977\n",
      "[8885]\ttraining's binary_logloss: 0.00796897\n",
      "[8886]\ttraining's binary_logloss: 0.00796862\n",
      "[8887]\ttraining's binary_logloss: 0.00796833\n",
      "[8888]\ttraining's binary_logloss: 0.00796767\n",
      "[8889]\ttraining's binary_logloss: 0.00796689\n",
      "[8890]\ttraining's binary_logloss: 0.00796661\n",
      "[8891]\ttraining's binary_logloss: 0.00796632\n",
      "[8892]\ttraining's binary_logloss: 0.00796598\n",
      "[8893]\ttraining's binary_logloss: 0.00796549\n",
      "[8894]\ttraining's binary_logloss: 0.00796502\n",
      "[8895]\ttraining's binary_logloss: 0.00796483\n",
      "[8896]\ttraining's binary_logloss: 0.00796435\n",
      "[8897]\ttraining's binary_logloss: 0.00796407\n",
      "[8898]\ttraining's binary_logloss: 0.00796313\n",
      "[8899]\ttraining's binary_logloss: 0.00796223\n",
      "[8900]\ttraining's binary_logloss: 0.00796158\n",
      "[8901]\ttraining's binary_logloss: 0.0079613\n",
      "[8902]\ttraining's binary_logloss: 0.00796101\n",
      "[8903]\ttraining's binary_logloss: 0.00796037\n",
      "[8904]\ttraining's binary_logloss: 0.00795954\n",
      "[8905]\ttraining's binary_logloss: 0.00795924\n",
      "[8906]\ttraining's binary_logloss: 0.00795883\n",
      "[8907]\ttraining's binary_logloss: 0.00795828\n",
      "[8908]\ttraining's binary_logloss: 0.00795754\n",
      "[8909]\ttraining's binary_logloss: 0.00795722\n",
      "[8910]\ttraining's binary_logloss: 0.0079566\n",
      "[8911]\ttraining's binary_logloss: 0.0079559\n",
      "[8912]\ttraining's binary_logloss: 0.00795531\n",
      "[8913]\ttraining's binary_logloss: 0.00795513\n",
      "[8914]\ttraining's binary_logloss: 0.00795495\n",
      "[8915]\ttraining's binary_logloss: 0.00795405\n",
      "[8916]\ttraining's binary_logloss: 0.00795328\n",
      "[8917]\ttraining's binary_logloss: 0.00795298\n",
      "[8918]\ttraining's binary_logloss: 0.00795212\n",
      "[8919]\ttraining's binary_logloss: 0.00795166\n",
      "[8920]\ttraining's binary_logloss: 0.00795109\n",
      "[8921]\ttraining's binary_logloss: 0.00795072\n",
      "[8922]\ttraining's binary_logloss: 0.00795005\n",
      "[8923]\ttraining's binary_logloss: 0.00794937\n",
      "[8924]\ttraining's binary_logloss: 0.00794902\n",
      "[8925]\ttraining's binary_logloss: 0.00794819\n",
      "[8926]\ttraining's binary_logloss: 0.00794739\n",
      "[8927]\ttraining's binary_logloss: 0.0079471\n",
      "[8928]\ttraining's binary_logloss: 0.00794638\n",
      "[8929]\ttraining's binary_logloss: 0.00794576\n",
      "[8930]\ttraining's binary_logloss: 0.00794501\n",
      "[8931]\ttraining's binary_logloss: 0.00794421\n",
      "[8932]\ttraining's binary_logloss: 0.0079436\n",
      "[8933]\ttraining's binary_logloss: 0.00794293\n",
      "[8934]\ttraining's binary_logloss: 0.00794264\n",
      "[8935]\ttraining's binary_logloss: 0.0079419\n",
      "[8936]\ttraining's binary_logloss: 0.00794161\n",
      "[8937]\ttraining's binary_logloss: 0.00794102\n",
      "[8938]\ttraining's binary_logloss: 0.00794003\n",
      "[8939]\ttraining's binary_logloss: 0.00793985\n",
      "[8940]\ttraining's binary_logloss: 0.00793966\n",
      "[8941]\ttraining's binary_logloss: 0.00793932\n",
      "[8942]\ttraining's binary_logloss: 0.00793914\n",
      "[8943]\ttraining's binary_logloss: 0.00793852\n",
      "[8944]\ttraining's binary_logloss: 0.00793834\n",
      "[8945]\ttraining's binary_logloss: 0.00793787\n",
      "[8946]\ttraining's binary_logloss: 0.00793769\n",
      "[8947]\ttraining's binary_logloss: 0.00793708\n",
      "[8948]\ttraining's binary_logloss: 0.0079368\n",
      "[8949]\ttraining's binary_logloss: 0.00793651\n",
      "[8950]\ttraining's binary_logloss: 0.00793633\n",
      "[8951]\ttraining's binary_logloss: 0.00793603\n",
      "[8952]\ttraining's binary_logloss: 0.00793585\n",
      "[8953]\ttraining's binary_logloss: 0.00793566\n",
      "[8954]\ttraining's binary_logloss: 0.00793524\n",
      "[8955]\ttraining's binary_logloss: 0.00793485\n",
      "[8956]\ttraining's binary_logloss: 0.00793415\n",
      "[8957]\ttraining's binary_logloss: 0.00793354\n",
      "[8958]\ttraining's binary_logloss: 0.00793282\n",
      "[8959]\ttraining's binary_logloss: 0.00793235\n",
      "[8960]\ttraining's binary_logloss: 0.00793151\n",
      "[8961]\ttraining's binary_logloss: 0.00793081\n",
      "[8962]\ttraining's binary_logloss: 0.00793043\n",
      "[8963]\ttraining's binary_logloss: 0.00793014\n",
      "[8964]\ttraining's binary_logloss: 0.0079297\n",
      "[8965]\ttraining's binary_logloss: 0.00792892\n",
      "[8966]\ttraining's binary_logloss: 0.00792837\n",
      "[8967]\ttraining's binary_logloss: 0.00792819\n",
      "[8968]\ttraining's binary_logloss: 0.007928\n",
      "[8969]\ttraining's binary_logloss: 0.00792768\n",
      "[8970]\ttraining's binary_logloss: 0.0079275\n",
      "[8971]\ttraining's binary_logloss: 0.00792682\n",
      "[8972]\ttraining's binary_logloss: 0.00792648\n",
      "[8973]\ttraining's binary_logloss: 0.00792621\n",
      "[8974]\ttraining's binary_logloss: 0.00792591\n",
      "[8975]\ttraining's binary_logloss: 0.00792559\n",
      "[8976]\ttraining's binary_logloss: 0.007925\n",
      "[8977]\ttraining's binary_logloss: 0.00792468\n",
      "[8978]\ttraining's binary_logloss: 0.00792437\n",
      "[8979]\ttraining's binary_logloss: 0.00792411\n",
      "[8980]\ttraining's binary_logloss: 0.00792356\n",
      "[8981]\ttraining's binary_logloss: 0.0079231\n",
      "[8982]\ttraining's binary_logloss: 0.00792293\n",
      "[8983]\ttraining's binary_logloss: 0.00792248\n",
      "[8984]\ttraining's binary_logloss: 0.00792229\n",
      "[8985]\ttraining's binary_logloss: 0.00792172\n",
      "[8986]\ttraining's binary_logloss: 0.00792155\n",
      "[8987]\ttraining's binary_logloss: 0.00792136\n",
      "[8988]\ttraining's binary_logloss: 0.00792118\n",
      "[8989]\ttraining's binary_logloss: 0.007921\n",
      "[8990]\ttraining's binary_logloss: 0.00792082\n",
      "[8991]\ttraining's binary_logloss: 0.00792064\n",
      "[8992]\ttraining's binary_logloss: 0.00792008\n",
      "[8993]\ttraining's binary_logloss: 0.00791954\n",
      "[8994]\ttraining's binary_logloss: 0.00791892\n",
      "[8995]\ttraining's binary_logloss: 0.00791865\n",
      "[8996]\ttraining's binary_logloss: 0.00791848\n",
      "[8997]\ttraining's binary_logloss: 0.0079176\n",
      "[8998]\ttraining's binary_logloss: 0.00791732\n",
      "[8999]\ttraining's binary_logloss: 0.00791674\n",
      "[9000]\ttraining's binary_logloss: 0.00791625\n",
      "[9001]\ttraining's binary_logloss: 0.00791564\n",
      "[9002]\ttraining's binary_logloss: 0.00791494\n",
      "[9003]\ttraining's binary_logloss: 0.00791436\n",
      "[9004]\ttraining's binary_logloss: 0.00791401\n",
      "[9005]\ttraining's binary_logloss: 0.00791372\n",
      "[9006]\ttraining's binary_logloss: 0.00791342\n",
      "[9007]\ttraining's binary_logloss: 0.00791283\n",
      "[9008]\ttraining's binary_logloss: 0.00791225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9009]\ttraining's binary_logloss: 0.00791194\n",
      "[9010]\ttraining's binary_logloss: 0.00791161\n",
      "[9011]\ttraining's binary_logloss: 0.00791135\n",
      "[9012]\ttraining's binary_logloss: 0.00791103\n",
      "[9013]\ttraining's binary_logloss: 0.00791073\n",
      "[9014]\ttraining's binary_logloss: 0.00791017\n",
      "[9015]\ttraining's binary_logloss: 0.00790989\n",
      "[9016]\ttraining's binary_logloss: 0.0079094\n",
      "[9017]\ttraining's binary_logloss: 0.00790912\n",
      "[9018]\ttraining's binary_logloss: 0.00790859\n",
      "[9019]\ttraining's binary_logloss: 0.00790805\n",
      "[9020]\ttraining's binary_logloss: 0.00790767\n",
      "[9021]\ttraining's binary_logloss: 0.00790734\n",
      "[9022]\ttraining's binary_logloss: 0.00790704\n",
      "[9023]\ttraining's binary_logloss: 0.00790672\n",
      "[9024]\ttraining's binary_logloss: 0.00790653\n",
      "[9025]\ttraining's binary_logloss: 0.00790636\n",
      "[9026]\ttraining's binary_logloss: 0.0079057\n",
      "[9027]\ttraining's binary_logloss: 0.00790533\n",
      "[9028]\ttraining's binary_logloss: 0.00790486\n",
      "[9029]\ttraining's binary_logloss: 0.00790434\n",
      "[9030]\ttraining's binary_logloss: 0.0079038\n",
      "[9031]\ttraining's binary_logloss: 0.00790321\n",
      "[9032]\ttraining's binary_logloss: 0.00790255\n",
      "[9033]\ttraining's binary_logloss: 0.00790196\n",
      "[9034]\ttraining's binary_logloss: 0.0079017\n",
      "[9035]\ttraining's binary_logloss: 0.00790141\n",
      "[9036]\ttraining's binary_logloss: 0.00790088\n",
      "[9037]\ttraining's binary_logloss: 0.00790058\n",
      "[9038]\ttraining's binary_logloss: 0.00790029\n",
      "[9039]\ttraining's binary_logloss: 0.0079\n",
      "[9040]\ttraining's binary_logloss: 0.00789982\n",
      "[9041]\ttraining's binary_logloss: 0.00789963\n",
      "[9042]\ttraining's binary_logloss: 0.00789899\n",
      "[9043]\ttraining's binary_logloss: 0.00789798\n",
      "[9044]\ttraining's binary_logloss: 0.0078978\n",
      "[9045]\ttraining's binary_logloss: 0.00789762\n",
      "[9046]\ttraining's binary_logloss: 0.00789745\n",
      "[9047]\ttraining's binary_logloss: 0.00789727\n",
      "[9048]\ttraining's binary_logloss: 0.00789704\n",
      "[9049]\ttraining's binary_logloss: 0.00789666\n",
      "[9050]\ttraining's binary_logloss: 0.00789649\n",
      "[9051]\ttraining's binary_logloss: 0.0078963\n",
      "[9052]\ttraining's binary_logloss: 0.00789593\n",
      "[9053]\ttraining's binary_logloss: 0.00789576\n",
      "[9054]\ttraining's binary_logloss: 0.00789557\n",
      "[9055]\ttraining's binary_logloss: 0.00789539\n",
      "[9056]\ttraining's binary_logloss: 0.00789521\n",
      "[9057]\ttraining's binary_logloss: 0.00789504\n",
      "[9058]\ttraining's binary_logloss: 0.00789485\n",
      "[9059]\ttraining's binary_logloss: 0.00789408\n",
      "[9060]\ttraining's binary_logloss: 0.00789322\n",
      "[9061]\ttraining's binary_logloss: 0.00789244\n",
      "[9062]\ttraining's binary_logloss: 0.00789216\n",
      "[9063]\ttraining's binary_logloss: 0.00789189\n",
      "[9064]\ttraining's binary_logloss: 0.0078916\n",
      "[9065]\ttraining's binary_logloss: 0.00789087\n",
      "[9066]\ttraining's binary_logloss: 0.00789015\n",
      "[9067]\ttraining's binary_logloss: 0.00788998\n",
      "[9068]\ttraining's binary_logloss: 0.00788979\n",
      "[9069]\ttraining's binary_logloss: 0.00788962\n",
      "[9070]\ttraining's binary_logloss: 0.00788944\n",
      "[9071]\ttraining's binary_logloss: 0.00788927\n",
      "[9072]\ttraining's binary_logloss: 0.00788908\n",
      "[9073]\ttraining's binary_logloss: 0.00788891\n",
      "[9074]\ttraining's binary_logloss: 0.00788872\n",
      "[9075]\ttraining's binary_logloss: 0.00788812\n",
      "[9076]\ttraining's binary_logloss: 0.00788783\n",
      "[9077]\ttraining's binary_logloss: 0.00788706\n",
      "[9078]\ttraining's binary_logloss: 0.00788672\n",
      "[9079]\ttraining's binary_logloss: 0.00788643\n",
      "[9080]\ttraining's binary_logloss: 0.00788608\n",
      "[9081]\ttraining's binary_logloss: 0.00788579\n",
      "[9082]\ttraining's binary_logloss: 0.0078855\n",
      "[9083]\ttraining's binary_logloss: 0.00788505\n",
      "[9084]\ttraining's binary_logloss: 0.00788487\n",
      "[9085]\ttraining's binary_logloss: 0.00788469\n",
      "[9086]\ttraining's binary_logloss: 0.00788398\n",
      "[9087]\ttraining's binary_logloss: 0.0078837\n",
      "[9088]\ttraining's binary_logloss: 0.00788333\n",
      "[9089]\ttraining's binary_logloss: 0.00788286\n",
      "[9090]\ttraining's binary_logloss: 0.00788241\n",
      "[9091]\ttraining's binary_logloss: 0.00788187\n",
      "[9092]\ttraining's binary_logloss: 0.00788169\n",
      "[9093]\ttraining's binary_logloss: 0.00788152\n",
      "[9094]\ttraining's binary_logloss: 0.00788133\n",
      "[9095]\ttraining's binary_logloss: 0.00788116\n",
      "[9096]\ttraining's binary_logloss: 0.00788098\n",
      "[9097]\ttraining's binary_logloss: 0.0078808\n",
      "[9098]\ttraining's binary_logloss: 0.00788062\n",
      "[9099]\ttraining's binary_logloss: 0.00788032\n",
      "[9100]\ttraining's binary_logloss: 0.00788015\n",
      "[9101]\ttraining's binary_logloss: 0.00787956\n",
      "[9102]\ttraining's binary_logloss: 0.00787883\n",
      "[9103]\ttraining's binary_logloss: 0.00787822\n",
      "[9104]\ttraining's binary_logloss: 0.00787795\n",
      "[9105]\ttraining's binary_logloss: 0.00787734\n",
      "[9106]\ttraining's binary_logloss: 0.00787704\n",
      "[9107]\ttraining's binary_logloss: 0.00787634\n",
      "[9108]\ttraining's binary_logloss: 0.00787577\n",
      "[9109]\ttraining's binary_logloss: 0.0078755\n",
      "[9110]\ttraining's binary_logloss: 0.00787492\n",
      "[9111]\ttraining's binary_logloss: 0.00787463\n",
      "[9112]\ttraining's binary_logloss: 0.00787375\n",
      "[9113]\ttraining's binary_logloss: 0.00787313\n",
      "[9114]\ttraining's binary_logloss: 0.00787247\n",
      "[9115]\ttraining's binary_logloss: 0.00787216\n",
      "[9116]\ttraining's binary_logloss: 0.00787169\n",
      "[9117]\ttraining's binary_logloss: 0.00787083\n",
      "[9118]\ttraining's binary_logloss: 0.00787043\n",
      "[9119]\ttraining's binary_logloss: 0.0078697\n",
      "[9120]\ttraining's binary_logloss: 0.00786895\n",
      "[9121]\ttraining's binary_logloss: 0.00786842\n",
      "[9122]\ttraining's binary_logloss: 0.00786778\n",
      "[9123]\ttraining's binary_logloss: 0.00786721\n",
      "[9124]\ttraining's binary_logloss: 0.00786686\n",
      "[9125]\ttraining's binary_logloss: 0.00786651\n",
      "[9126]\ttraining's binary_logloss: 0.00786577\n",
      "[9127]\ttraining's binary_logloss: 0.00786514\n",
      "[9128]\ttraining's binary_logloss: 0.00786485\n",
      "[9129]\ttraining's binary_logloss: 0.00786459\n",
      "[9130]\ttraining's binary_logloss: 0.00786424\n",
      "[9131]\ttraining's binary_logloss: 0.00786394\n",
      "[9132]\ttraining's binary_logloss: 0.00786346\n",
      "[9133]\ttraining's binary_logloss: 0.00786309\n",
      "[9134]\ttraining's binary_logloss: 0.00786238\n",
      "[9135]\ttraining's binary_logloss: 0.0078621\n",
      "[9136]\ttraining's binary_logloss: 0.00786157\n",
      "[9137]\ttraining's binary_logloss: 0.007861\n",
      "[9138]\ttraining's binary_logloss: 0.00786034\n",
      "[9139]\ttraining's binary_logloss: 0.00786002\n",
      "[9140]\ttraining's binary_logloss: 0.00785976\n",
      "[9141]\ttraining's binary_logloss: 0.00785958\n",
      "[9142]\ttraining's binary_logloss: 0.00785932\n",
      "[9143]\ttraining's binary_logloss: 0.00785873\n",
      "[9144]\ttraining's binary_logloss: 0.00785855\n",
      "[9145]\ttraining's binary_logloss: 0.00785808\n",
      "[9146]\ttraining's binary_logloss: 0.00785778\n",
      "[9147]\ttraining's binary_logloss: 0.00785731\n",
      "[9148]\ttraining's binary_logloss: 0.00785658\n",
      "[9149]\ttraining's binary_logloss: 0.0078559\n",
      "[9150]\ttraining's binary_logloss: 0.00785566\n",
      "[9151]\ttraining's binary_logloss: 0.00785537\n",
      "[9152]\ttraining's binary_logloss: 0.00785514\n",
      "[9153]\ttraining's binary_logloss: 0.00785486\n",
      "[9154]\ttraining's binary_logloss: 0.00785457\n",
      "[9155]\ttraining's binary_logloss: 0.00785398\n",
      "[9156]\ttraining's binary_logloss: 0.00785338\n",
      "[9157]\ttraining's binary_logloss: 0.00785263\n",
      "[9158]\ttraining's binary_logloss: 0.00785207\n",
      "[9159]\ttraining's binary_logloss: 0.00785171\n",
      "[9160]\ttraining's binary_logloss: 0.00785137\n",
      "[9161]\ttraining's binary_logloss: 0.00785068\n",
      "[9162]\ttraining's binary_logloss: 0.00785018\n",
      "[9163]\ttraining's binary_logloss: 0.00784972\n",
      "[9164]\ttraining's binary_logloss: 0.00784944\n",
      "[9165]\ttraining's binary_logloss: 0.00784889\n",
      "[9166]\ttraining's binary_logloss: 0.00784853\n",
      "[9167]\ttraining's binary_logloss: 0.00784826\n",
      "[9168]\ttraining's binary_logloss: 0.0078474\n",
      "[9169]\ttraining's binary_logloss: 0.00784712\n",
      "[9170]\ttraining's binary_logloss: 0.00784695\n",
      "[9171]\ttraining's binary_logloss: 0.00784677\n",
      "[9172]\ttraining's binary_logloss: 0.00784644\n",
      "[9173]\ttraining's binary_logloss: 0.00784586\n",
      "[9174]\ttraining's binary_logloss: 0.00784546\n",
      "[9175]\ttraining's binary_logloss: 0.00784479\n",
      "[9176]\ttraining's binary_logloss: 0.0078445\n",
      "[9177]\ttraining's binary_logloss: 0.00784378\n",
      "[9178]\ttraining's binary_logloss: 0.00784327\n",
      "[9179]\ttraining's binary_logloss: 0.00784282\n",
      "[9180]\ttraining's binary_logloss: 0.00784237\n",
      "[9181]\ttraining's binary_logloss: 0.00784179\n",
      "[9182]\ttraining's binary_logloss: 0.00784162\n",
      "[9183]\ttraining's binary_logloss: 0.00784144\n",
      "[9184]\ttraining's binary_logloss: 0.00784127\n",
      "[9185]\ttraining's binary_logloss: 0.00784109\n",
      "[9186]\ttraining's binary_logloss: 0.0078408\n",
      "[9187]\ttraining's binary_logloss: 0.00784\n",
      "[9188]\ttraining's binary_logloss: 0.00783963\n",
      "[9189]\ttraining's binary_logloss: 0.00783946\n",
      "[9190]\ttraining's binary_logloss: 0.00783927\n",
      "[9191]\ttraining's binary_logloss: 0.0078391\n",
      "[9192]\ttraining's binary_logloss: 0.00783892\n",
      "[9193]\ttraining's binary_logloss: 0.00783846\n",
      "[9194]\ttraining's binary_logloss: 0.00783803\n",
      "[9195]\ttraining's binary_logloss: 0.00783775\n",
      "[9196]\ttraining's binary_logloss: 0.00783758\n",
      "[9197]\ttraining's binary_logloss: 0.00783725\n",
      "[9198]\ttraining's binary_logloss: 0.0078366\n",
      "[9199]\ttraining's binary_logloss: 0.00783608\n",
      "[9200]\ttraining's binary_logloss: 0.00783591\n",
      "[9201]\ttraining's binary_logloss: 0.00783573\n",
      "[9202]\ttraining's binary_logloss: 0.00783546\n",
      "[9203]\ttraining's binary_logloss: 0.00783516\n",
      "[9204]\ttraining's binary_logloss: 0.00783473\n",
      "[9205]\ttraining's binary_logloss: 0.00783423\n",
      "[9206]\ttraining's binary_logloss: 0.00783397\n",
      "[9207]\ttraining's binary_logloss: 0.00783325\n",
      "[9208]\ttraining's binary_logloss: 0.00783292\n",
      "[9209]\ttraining's binary_logloss: 0.00783217\n",
      "[9210]\ttraining's binary_logloss: 0.00783178\n",
      "[9211]\ttraining's binary_logloss: 0.00783119\n",
      "[9212]\ttraining's binary_logloss: 0.00783041\n",
      "[9213]\ttraining's binary_logloss: 0.00783005\n",
      "[9214]\ttraining's binary_logloss: 0.00782976\n",
      "[9215]\ttraining's binary_logloss: 0.0078291\n",
      "[9216]\ttraining's binary_logloss: 0.00782854\n",
      "[9217]\ttraining's binary_logloss: 0.00782809\n",
      "[9218]\ttraining's binary_logloss: 0.00782727\n",
      "[9219]\ttraining's binary_logloss: 0.00782689\n",
      "[9220]\ttraining's binary_logloss: 0.00782653\n",
      "[9221]\ttraining's binary_logloss: 0.00782591\n",
      "[9222]\ttraining's binary_logloss: 0.00782522\n",
      "[9223]\ttraining's binary_logloss: 0.00782475\n",
      "[9224]\ttraining's binary_logloss: 0.00782426\n",
      "[9225]\ttraining's binary_logloss: 0.00782394\n",
      "[9226]\ttraining's binary_logloss: 0.0078236\n",
      "[9227]\ttraining's binary_logloss: 0.00782289\n",
      "[9228]\ttraining's binary_logloss: 0.00782238\n",
      "[9229]\ttraining's binary_logloss: 0.00782186\n",
      "[9230]\ttraining's binary_logloss: 0.00782106\n",
      "[9231]\ttraining's binary_logloss: 0.00782041\n",
      "[9232]\ttraining's binary_logloss: 0.00782013\n",
      "[9233]\ttraining's binary_logloss: 0.00781949\n",
      "[9234]\ttraining's binary_logloss: 0.00781918\n",
      "[9235]\ttraining's binary_logloss: 0.00781888\n",
      "[9236]\ttraining's binary_logloss: 0.00781852\n",
      "[9237]\ttraining's binary_logloss: 0.00781822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9238]\ttraining's binary_logloss: 0.00781746\n",
      "[9239]\ttraining's binary_logloss: 0.00781715\n",
      "[9240]\ttraining's binary_logloss: 0.00781634\n",
      "[9241]\ttraining's binary_logloss: 0.00781589\n",
      "[9242]\ttraining's binary_logloss: 0.00781555\n",
      "[9243]\ttraining's binary_logloss: 0.00781521\n",
      "[9244]\ttraining's binary_logloss: 0.00781504\n",
      "[9245]\ttraining's binary_logloss: 0.00781486\n",
      "[9246]\ttraining's binary_logloss: 0.00781469\n",
      "[9247]\ttraining's binary_logloss: 0.00781412\n",
      "[9248]\ttraining's binary_logloss: 0.00781393\n",
      "[9249]\ttraining's binary_logloss: 0.00781376\n",
      "[9250]\ttraining's binary_logloss: 0.00781358\n",
      "[9251]\ttraining's binary_logloss: 0.00781341\n",
      "[9252]\ttraining's binary_logloss: 0.00781323\n",
      "[9253]\ttraining's binary_logloss: 0.00781263\n",
      "[9254]\ttraining's binary_logloss: 0.00781246\n",
      "[9255]\ttraining's binary_logloss: 0.00781227\n",
      "[9256]\ttraining's binary_logloss: 0.0078115\n",
      "[9257]\ttraining's binary_logloss: 0.00781121\n",
      "[9258]\ttraining's binary_logloss: 0.00781095\n",
      "[9259]\ttraining's binary_logloss: 0.00781058\n",
      "[9260]\ttraining's binary_logloss: 0.00780992\n",
      "[9261]\ttraining's binary_logloss: 0.00780975\n",
      "[9262]\ttraining's binary_logloss: 0.00780918\n",
      "[9263]\ttraining's binary_logloss: 0.00780847\n",
      "[9264]\ttraining's binary_logloss: 0.00780816\n",
      "[9265]\ttraining's binary_logloss: 0.00780763\n",
      "[9266]\ttraining's binary_logloss: 0.00780717\n",
      "[9267]\ttraining's binary_logloss: 0.0078069\n",
      "[9268]\ttraining's binary_logloss: 0.00780632\n",
      "[9269]\ttraining's binary_logloss: 0.00780583\n",
      "[9270]\ttraining's binary_logloss: 0.00780566\n",
      "[9271]\ttraining's binary_logloss: 0.00780548\n",
      "[9272]\ttraining's binary_logloss: 0.00780531\n",
      "[9273]\ttraining's binary_logloss: 0.00780513\n",
      "[9274]\ttraining's binary_logloss: 0.00780496\n",
      "[9275]\ttraining's binary_logloss: 0.00780478\n",
      "[9276]\ttraining's binary_logloss: 0.00780461\n",
      "[9277]\ttraining's binary_logloss: 0.00780444\n",
      "[9278]\ttraining's binary_logloss: 0.00780425\n",
      "[9279]\ttraining's binary_logloss: 0.00780408\n",
      "[9280]\ttraining's binary_logloss: 0.00780379\n",
      "[9281]\ttraining's binary_logloss: 0.00780361\n",
      "[9282]\ttraining's binary_logloss: 0.00780299\n",
      "[9283]\ttraining's binary_logloss: 0.00780237\n",
      "[9284]\ttraining's binary_logloss: 0.00780212\n",
      "[9285]\ttraining's binary_logloss: 0.00780186\n",
      "[9286]\ttraining's binary_logloss: 0.00780102\n",
      "[9287]\ttraining's binary_logloss: 0.0078005\n",
      "[9288]\ttraining's binary_logloss: 0.00779991\n",
      "[9289]\ttraining's binary_logloss: 0.00779974\n",
      "[9290]\ttraining's binary_logloss: 0.00779946\n",
      "[9291]\ttraining's binary_logloss: 0.00779927\n",
      "[9292]\ttraining's binary_logloss: 0.0077991\n",
      "[9293]\ttraining's binary_logloss: 0.00779893\n",
      "[9294]\ttraining's binary_logloss: 0.00779876\n",
      "[9295]\ttraining's binary_logloss: 0.00779858\n",
      "[9296]\ttraining's binary_logloss: 0.00779791\n",
      "[9297]\ttraining's binary_logloss: 0.00779774\n",
      "[9298]\ttraining's binary_logloss: 0.00779756\n",
      "[9299]\ttraining's binary_logloss: 0.00779739\n",
      "[9300]\ttraining's binary_logloss: 0.00779721\n",
      "[9301]\ttraining's binary_logloss: 0.00779655\n",
      "[9302]\ttraining's binary_logloss: 0.00779574\n",
      "[9303]\ttraining's binary_logloss: 0.00779546\n",
      "[9304]\ttraining's binary_logloss: 0.00779485\n",
      "[9305]\ttraining's binary_logloss: 0.00779421\n",
      "[9306]\ttraining's binary_logloss: 0.00779387\n",
      "[9307]\ttraining's binary_logloss: 0.00779357\n",
      "[9308]\ttraining's binary_logloss: 0.00779298\n",
      "[9309]\ttraining's binary_logloss: 0.0077922\n",
      "[9310]\ttraining's binary_logloss: 0.00779176\n",
      "[9311]\ttraining's binary_logloss: 0.00779093\n",
      "[9312]\ttraining's binary_logloss: 0.00779054\n",
      "[9313]\ttraining's binary_logloss: 0.00778983\n",
      "[9314]\ttraining's binary_logloss: 0.00778932\n",
      "[9315]\ttraining's binary_logloss: 0.00778897\n",
      "[9316]\ttraining's binary_logloss: 0.00778861\n",
      "[9317]\ttraining's binary_logloss: 0.00778832\n",
      "[9318]\ttraining's binary_logloss: 0.00778805\n",
      "[9319]\ttraining's binary_logloss: 0.00778744\n",
      "[9320]\ttraining's binary_logloss: 0.00778674\n",
      "[9321]\ttraining's binary_logloss: 0.00778614\n",
      "[9322]\ttraining's binary_logloss: 0.00778556\n",
      "[9323]\ttraining's binary_logloss: 0.00778526\n",
      "[9324]\ttraining's binary_logloss: 0.00778496\n",
      "[9325]\ttraining's binary_logloss: 0.0077848\n",
      "[9326]\ttraining's binary_logloss: 0.00778426\n",
      "[9327]\ttraining's binary_logloss: 0.00778359\n",
      "[9328]\ttraining's binary_logloss: 0.00778329\n",
      "[9329]\ttraining's binary_logloss: 0.00778253\n",
      "[9330]\ttraining's binary_logloss: 0.00778179\n",
      "[9331]\ttraining's binary_logloss: 0.00778115\n",
      "[9332]\ttraining's binary_logloss: 0.0077806\n",
      "[9333]\ttraining's binary_logloss: 0.00778024\n",
      "[9334]\ttraining's binary_logloss: 0.00778006\n",
      "[9335]\ttraining's binary_logloss: 0.00777958\n",
      "[9336]\ttraining's binary_logloss: 0.00777912\n",
      "[9337]\ttraining's binary_logloss: 0.00777882\n",
      "[9338]\ttraining's binary_logloss: 0.00777865\n",
      "[9339]\ttraining's binary_logloss: 0.00777848\n",
      "[9340]\ttraining's binary_logloss: 0.00777831\n",
      "[9341]\ttraining's binary_logloss: 0.00777813\n",
      "[9342]\ttraining's binary_logloss: 0.0077776\n",
      "[9343]\ttraining's binary_logloss: 0.00777724\n",
      "[9344]\ttraining's binary_logloss: 0.00777692\n",
      "[9345]\ttraining's binary_logloss: 0.0077766\n",
      "[9346]\ttraining's binary_logloss: 0.00777574\n",
      "[9347]\ttraining's binary_logloss: 0.00777517\n",
      "[9348]\ttraining's binary_logloss: 0.00777484\n",
      "[9349]\ttraining's binary_logloss: 0.00777428\n",
      "[9350]\ttraining's binary_logloss: 0.00777388\n",
      "[9351]\ttraining's binary_logloss: 0.00777362\n",
      "[9352]\ttraining's binary_logloss: 0.00777332\n",
      "[9353]\ttraining's binary_logloss: 0.00777293\n",
      "[9354]\ttraining's binary_logloss: 0.00777229\n",
      "[9355]\ttraining's binary_logloss: 0.007772\n",
      "[9356]\ttraining's binary_logloss: 0.00777172\n",
      "[9357]\ttraining's binary_logloss: 0.00777155\n",
      "[9358]\ttraining's binary_logloss: 0.00777087\n",
      "[9359]\ttraining's binary_logloss: 0.00777057\n",
      "[9360]\ttraining's binary_logloss: 0.00777005\n",
      "[9361]\ttraining's binary_logloss: 0.00776975\n",
      "[9362]\ttraining's binary_logloss: 0.00776895\n",
      "[9363]\ttraining's binary_logloss: 0.00776815\n",
      "[9364]\ttraining's binary_logloss: 0.00776783\n",
      "[9365]\ttraining's binary_logloss: 0.00776701\n",
      "[9366]\ttraining's binary_logloss: 0.00776641\n",
      "[9367]\ttraining's binary_logloss: 0.00776599\n",
      "[9368]\ttraining's binary_logloss: 0.00776544\n",
      "[9369]\ttraining's binary_logloss: 0.00776475\n",
      "[9370]\ttraining's binary_logloss: 0.00776448\n",
      "[9371]\ttraining's binary_logloss: 0.00776419\n",
      "[9372]\ttraining's binary_logloss: 0.00776389\n",
      "[9373]\ttraining's binary_logloss: 0.00776355\n",
      "[9374]\ttraining's binary_logloss: 0.00776325\n",
      "[9375]\ttraining's binary_logloss: 0.00776292\n",
      "[9376]\ttraining's binary_logloss: 0.00776264\n",
      "[9377]\ttraining's binary_logloss: 0.00776235\n",
      "[9378]\ttraining's binary_logloss: 0.00776218\n",
      "[9379]\ttraining's binary_logloss: 0.00776201\n",
      "[9380]\ttraining's binary_logloss: 0.00776135\n",
      "[9381]\ttraining's binary_logloss: 0.0077605\n",
      "[9382]\ttraining's binary_logloss: 0.00776032\n",
      "[9383]\ttraining's binary_logloss: 0.00776015\n",
      "[9384]\ttraining's binary_logloss: 0.00775998\n",
      "[9385]\ttraining's binary_logloss: 0.00775981\n",
      "[9386]\ttraining's binary_logloss: 0.00775963\n",
      "[9387]\ttraining's binary_logloss: 0.00775909\n",
      "[9388]\ttraining's binary_logloss: 0.00775892\n",
      "[9389]\ttraining's binary_logloss: 0.00775862\n",
      "[9390]\ttraining's binary_logloss: 0.00775833\n",
      "[9391]\ttraining's binary_logloss: 0.0077577\n",
      "[9392]\ttraining's binary_logloss: 0.00775714\n",
      "[9393]\ttraining's binary_logloss: 0.00775683\n",
      "[9394]\ttraining's binary_logloss: 0.0077562\n",
      "[9395]\ttraining's binary_logloss: 0.00775594\n",
      "[9396]\ttraining's binary_logloss: 0.00775512\n",
      "[9397]\ttraining's binary_logloss: 0.00775483\n",
      "[9398]\ttraining's binary_logloss: 0.00775404\n",
      "[9399]\ttraining's binary_logloss: 0.00775356\n",
      "[9400]\ttraining's binary_logloss: 0.00775339\n",
      "[9401]\ttraining's binary_logloss: 0.00775322\n",
      "[9402]\ttraining's binary_logloss: 0.00775304\n",
      "[9403]\ttraining's binary_logloss: 0.00775287\n",
      "[9404]\ttraining's binary_logloss: 0.00775223\n",
      "[9405]\ttraining's binary_logloss: 0.0077516\n",
      "[9406]\ttraining's binary_logloss: 0.00775133\n",
      "[9407]\ttraining's binary_logloss: 0.00775103\n",
      "[9408]\ttraining's binary_logloss: 0.00775076\n",
      "[9409]\ttraining's binary_logloss: 0.00775058\n",
      "[9410]\ttraining's binary_logloss: 0.0077503\n",
      "[9411]\ttraining's binary_logloss: 0.00775013\n",
      "[9412]\ttraining's binary_logloss: 0.00774995\n",
      "[9413]\ttraining's binary_logloss: 0.00774979\n",
      "[9414]\ttraining's binary_logloss: 0.00774914\n",
      "[9415]\ttraining's binary_logloss: 0.00774837\n",
      "[9416]\ttraining's binary_logloss: 0.00774802\n",
      "[9417]\ttraining's binary_logloss: 0.00774768\n",
      "[9418]\ttraining's binary_logloss: 0.00774696\n",
      "[9419]\ttraining's binary_logloss: 0.00774664\n",
      "[9420]\ttraining's binary_logloss: 0.00774621\n",
      "[9421]\ttraining's binary_logloss: 0.00774562\n",
      "[9422]\ttraining's binary_logloss: 0.00774526\n",
      "[9423]\ttraining's binary_logloss: 0.00774455\n",
      "[9424]\ttraining's binary_logloss: 0.007744\n",
      "[9425]\ttraining's binary_logloss: 0.00774349\n",
      "[9426]\ttraining's binary_logloss: 0.00774318\n",
      "[9427]\ttraining's binary_logloss: 0.00774256\n",
      "[9428]\ttraining's binary_logloss: 0.00774227\n",
      "[9429]\ttraining's binary_logloss: 0.00774209\n",
      "[9430]\ttraining's binary_logloss: 0.00774164\n",
      "[9431]\ttraining's binary_logloss: 0.00774122\n",
      "[9432]\ttraining's binary_logloss: 0.00774105\n",
      "[9433]\ttraining's binary_logloss: 0.00774067\n",
      "[9434]\ttraining's binary_logloss: 0.00774041\n",
      "[9435]\ttraining's binary_logloss: 0.00773994\n",
      "[9436]\ttraining's binary_logloss: 0.00773966\n",
      "[9437]\ttraining's binary_logloss: 0.00773949\n",
      "[9438]\ttraining's binary_logloss: 0.00773931\n",
      "[9439]\ttraining's binary_logloss: 0.00773896\n",
      "[9440]\ttraining's binary_logloss: 0.00773854\n",
      "[9441]\ttraining's binary_logloss: 0.00773796\n",
      "[9442]\ttraining's binary_logloss: 0.00773713\n",
      "[9443]\ttraining's binary_logloss: 0.00773651\n",
      "[9444]\ttraining's binary_logloss: 0.00773626\n",
      "[9445]\ttraining's binary_logloss: 0.00773555\n",
      "[9446]\ttraining's binary_logloss: 0.00773527\n",
      "[9447]\ttraining's binary_logloss: 0.00773448\n",
      "[9448]\ttraining's binary_logloss: 0.0077342\n",
      "[9449]\ttraining's binary_logloss: 0.00773388\n",
      "[9450]\ttraining's binary_logloss: 0.00773343\n",
      "[9451]\ttraining's binary_logloss: 0.00773311\n",
      "[9452]\ttraining's binary_logloss: 0.00773231\n",
      "[9453]\ttraining's binary_logloss: 0.00773196\n",
      "[9454]\ttraining's binary_logloss: 0.0077314\n",
      "[9455]\ttraining's binary_logloss: 0.00773077\n",
      "[9456]\ttraining's binary_logloss: 0.00773048\n",
      "[9457]\ttraining's binary_logloss: 0.00773018\n",
      "[9458]\ttraining's binary_logloss: 0.00773002\n",
      "[9459]\ttraining's binary_logloss: 0.00772984\n",
      "[9460]\ttraining's binary_logloss: 0.00772956\n",
      "[9461]\ttraining's binary_logloss: 0.00772923\n",
      "[9462]\ttraining's binary_logloss: 0.00772855\n",
      "[9463]\ttraining's binary_logloss: 0.00772806\n",
      "[9464]\ttraining's binary_logloss: 0.0077273\n",
      "[9465]\ttraining's binary_logloss: 0.00772685\n",
      "[9466]\ttraining's binary_logloss: 0.0077265\n",
      "[9467]\ttraining's binary_logloss: 0.00772621\n",
      "[9468]\ttraining's binary_logloss: 0.00772566\n",
      "[9469]\ttraining's binary_logloss: 0.0077249\n",
      "[9470]\ttraining's binary_logloss: 0.00772431\n",
      "[9471]\ttraining's binary_logloss: 0.00772414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9472]\ttraining's binary_logloss: 0.00772388\n",
      "[9473]\ttraining's binary_logloss: 0.00772336\n",
      "[9474]\ttraining's binary_logloss: 0.00772281\n",
      "[9475]\ttraining's binary_logloss: 0.00772254\n",
      "[9476]\ttraining's binary_logloss: 0.00772229\n",
      "[9477]\ttraining's binary_logloss: 0.00772133\n",
      "[9478]\ttraining's binary_logloss: 0.00772071\n",
      "[9479]\ttraining's binary_logloss: 0.00772041\n",
      "[9480]\ttraining's binary_logloss: 0.00771988\n",
      "[9481]\ttraining's binary_logloss: 0.00771958\n",
      "[9482]\ttraining's binary_logloss: 0.00771929\n",
      "[9483]\ttraining's binary_logloss: 0.00771912\n",
      "[9484]\ttraining's binary_logloss: 0.00771895\n",
      "[9485]\ttraining's binary_logloss: 0.00771877\n",
      "[9486]\ttraining's binary_logloss: 0.00771832\n",
      "[9487]\ttraining's binary_logloss: 0.00771816\n",
      "[9488]\ttraining's binary_logloss: 0.00771798\n",
      "[9489]\ttraining's binary_logloss: 0.00771782\n",
      "[9490]\ttraining's binary_logloss: 0.00771764\n",
      "[9491]\ttraining's binary_logloss: 0.00771698\n",
      "[9492]\ttraining's binary_logloss: 0.00771681\n",
      "[9493]\ttraining's binary_logloss: 0.00771663\n",
      "[9494]\ttraining's binary_logloss: 0.00771647\n",
      "[9495]\ttraining's binary_logloss: 0.00771629\n",
      "[9496]\ttraining's binary_logloss: 0.00771566\n",
      "[9497]\ttraining's binary_logloss: 0.0077155\n",
      "[9498]\ttraining's binary_logloss: 0.00771521\n",
      "[9499]\ttraining's binary_logloss: 0.0077148\n",
      "[9500]\ttraining's binary_logloss: 0.00771435\n",
      "[9501]\ttraining's binary_logloss: 0.00771419\n",
      "[9502]\ttraining's binary_logloss: 0.00771402\n",
      "[9503]\ttraining's binary_logloss: 0.00771362\n",
      "[9504]\ttraining's binary_logloss: 0.00771346\n",
      "[9505]\ttraining's binary_logloss: 0.00771251\n",
      "[9506]\ttraining's binary_logloss: 0.00771186\n",
      "[9507]\ttraining's binary_logloss: 0.00771157\n",
      "[9508]\ttraining's binary_logloss: 0.00771128\n",
      "[9509]\ttraining's binary_logloss: 0.00771076\n",
      "[9510]\ttraining's binary_logloss: 0.00771022\n",
      "[9511]\ttraining's binary_logloss: 0.00770975\n",
      "[9512]\ttraining's binary_logloss: 0.00770909\n",
      "[9513]\ttraining's binary_logloss: 0.00770884\n",
      "[9514]\ttraining's binary_logloss: 0.00770831\n",
      "[9515]\ttraining's binary_logloss: 0.00770806\n",
      "[9516]\ttraining's binary_logloss: 0.00770725\n",
      "[9517]\ttraining's binary_logloss: 0.0077067\n",
      "[9518]\ttraining's binary_logloss: 0.00770642\n",
      "[9519]\ttraining's binary_logloss: 0.00770571\n",
      "[9520]\ttraining's binary_logloss: 0.00770543\n",
      "[9521]\ttraining's binary_logloss: 0.00770503\n",
      "[9522]\ttraining's binary_logloss: 0.00770452\n",
      "[9523]\ttraining's binary_logloss: 0.00770423\n",
      "[9524]\ttraining's binary_logloss: 0.00770397\n",
      "[9525]\ttraining's binary_logloss: 0.00770323\n",
      "[9526]\ttraining's binary_logloss: 0.00770281\n",
      "[9527]\ttraining's binary_logloss: 0.00770247\n",
      "[9528]\ttraining's binary_logloss: 0.00770184\n",
      "[9529]\ttraining's binary_logloss: 0.00770159\n",
      "[9530]\ttraining's binary_logloss: 0.00770142\n",
      "[9531]\ttraining's binary_logloss: 0.00770125\n",
      "[9532]\ttraining's binary_logloss: 0.00770108\n",
      "[9533]\ttraining's binary_logloss: 0.00770091\n",
      "[9534]\ttraining's binary_logloss: 0.00770074\n",
      "[9535]\ttraining's binary_logloss: 0.00770057\n",
      "[9536]\ttraining's binary_logloss: 0.00770026\n",
      "[9537]\ttraining's binary_logloss: 0.00769998\n",
      "[9538]\ttraining's binary_logloss: 0.0076997\n",
      "[9539]\ttraining's binary_logloss: 0.00769931\n",
      "[9540]\ttraining's binary_logloss: 0.00769861\n",
      "[9541]\ttraining's binary_logloss: 0.00769833\n",
      "[9542]\ttraining's binary_logloss: 0.00769802\n",
      "[9543]\ttraining's binary_logloss: 0.00769762\n",
      "[9544]\ttraining's binary_logloss: 0.00769728\n",
      "[9545]\ttraining's binary_logloss: 0.007697\n",
      "[9546]\ttraining's binary_logloss: 0.00769647\n",
      "[9547]\ttraining's binary_logloss: 0.00769617\n",
      "[9548]\ttraining's binary_logloss: 0.00769588\n",
      "[9549]\ttraining's binary_logloss: 0.00769542\n",
      "[9550]\ttraining's binary_logloss: 0.00769498\n",
      "[9551]\ttraining's binary_logloss: 0.00769459\n",
      "[9552]\ttraining's binary_logloss: 0.00769442\n",
      "[9553]\ttraining's binary_logloss: 0.00769414\n",
      "[9554]\ttraining's binary_logloss: 0.0076939\n",
      "[9555]\ttraining's binary_logloss: 0.00769318\n",
      "[9556]\ttraining's binary_logloss: 0.00769288\n",
      "[9557]\ttraining's binary_logloss: 0.00769255\n",
      "[9558]\ttraining's binary_logloss: 0.00769227\n",
      "[9559]\ttraining's binary_logloss: 0.00769198\n",
      "[9560]\ttraining's binary_logloss: 0.00769142\n",
      "[9561]\ttraining's binary_logloss: 0.00769111\n",
      "[9562]\ttraining's binary_logloss: 0.0076908\n",
      "[9563]\ttraining's binary_logloss: 0.00769027\n",
      "[9564]\ttraining's binary_logloss: 0.00769\n",
      "[9565]\ttraining's binary_logloss: 0.00768983\n",
      "[9566]\ttraining's binary_logloss: 0.00768966\n",
      "[9567]\ttraining's binary_logloss: 0.00768893\n",
      "[9568]\ttraining's binary_logloss: 0.00768854\n",
      "[9569]\ttraining's binary_logloss: 0.00768825\n",
      "[9570]\ttraining's binary_logloss: 0.00768748\n",
      "[9571]\ttraining's binary_logloss: 0.00768686\n",
      "[9572]\ttraining's binary_logloss: 0.00768661\n",
      "[9573]\ttraining's binary_logloss: 0.00768633\n",
      "[9574]\ttraining's binary_logloss: 0.00768595\n",
      "[9575]\ttraining's binary_logloss: 0.00768578\n",
      "[9576]\ttraining's binary_logloss: 0.0076856\n",
      "[9577]\ttraining's binary_logloss: 0.00768544\n",
      "[9578]\ttraining's binary_logloss: 0.00768526\n",
      "[9579]\ttraining's binary_logloss: 0.0076851\n",
      "[9580]\ttraining's binary_logloss: 0.00768492\n",
      "[9581]\ttraining's binary_logloss: 0.00768476\n",
      "[9582]\ttraining's binary_logloss: 0.00768459\n",
      "[9583]\ttraining's binary_logloss: 0.00768443\n",
      "[9584]\ttraining's binary_logloss: 0.00768425\n",
      "[9585]\ttraining's binary_logloss: 0.00768363\n",
      "[9586]\ttraining's binary_logloss: 0.00768324\n",
      "[9587]\ttraining's binary_logloss: 0.00768261\n",
      "[9588]\ttraining's binary_logloss: 0.00768196\n",
      "[9589]\ttraining's binary_logloss: 0.00768128\n",
      "[9590]\ttraining's binary_logloss: 0.007681\n",
      "[9591]\ttraining's binary_logloss: 0.00768084\n",
      "[9592]\ttraining's binary_logloss: 0.00768045\n",
      "[9593]\ttraining's binary_logloss: 0.00768012\n",
      "[9594]\ttraining's binary_logloss: 0.0076798\n",
      "[9595]\ttraining's binary_logloss: 0.00767951\n",
      "[9596]\ttraining's binary_logloss: 0.00767913\n",
      "[9597]\ttraining's binary_logloss: 0.00767869\n",
      "[9598]\ttraining's binary_logloss: 0.00767833\n",
      "[9599]\ttraining's binary_logloss: 0.00767799\n",
      "[9600]\ttraining's binary_logloss: 0.00767775\n",
      "[9601]\ttraining's binary_logloss: 0.00767741\n",
      "[9602]\ttraining's binary_logloss: 0.00767709\n",
      "[9603]\ttraining's binary_logloss: 0.00767679\n",
      "[9604]\ttraining's binary_logloss: 0.00767635\n",
      "[9605]\ttraining's binary_logloss: 0.00767561\n",
      "[9606]\ttraining's binary_logloss: 0.00767491\n",
      "[9607]\ttraining's binary_logloss: 0.00767434\n",
      "[9608]\ttraining's binary_logloss: 0.00767373\n",
      "[9609]\ttraining's binary_logloss: 0.00767345\n",
      "[9610]\ttraining's binary_logloss: 0.00767302\n",
      "[9611]\ttraining's binary_logloss: 0.00767265\n",
      "[9612]\ttraining's binary_logloss: 0.00767215\n",
      "[9613]\ttraining's binary_logloss: 0.00767191\n",
      "[9614]\ttraining's binary_logloss: 0.00767175\n",
      "[9615]\ttraining's binary_logloss: 0.00767122\n",
      "[9616]\ttraining's binary_logloss: 0.00767079\n",
      "[9617]\ttraining's binary_logloss: 0.00767022\n",
      "[9618]\ttraining's binary_logloss: 0.00766959\n",
      "[9619]\ttraining's binary_logloss: 0.00766928\n",
      "[9620]\ttraining's binary_logloss: 0.0076685\n",
      "[9621]\ttraining's binary_logloss: 0.00766818\n",
      "[9622]\ttraining's binary_logloss: 0.00766756\n",
      "[9623]\ttraining's binary_logloss: 0.00766729\n",
      "[9624]\ttraining's binary_logloss: 0.00766701\n",
      "[9625]\ttraining's binary_logloss: 0.00766671\n",
      "[9626]\ttraining's binary_logloss: 0.00766608\n",
      "[9627]\ttraining's binary_logloss: 0.00766546\n",
      "[9628]\ttraining's binary_logloss: 0.00766454\n",
      "[9629]\ttraining's binary_logloss: 0.00766394\n",
      "[9630]\ttraining's binary_logloss: 0.00766363\n",
      "[9631]\ttraining's binary_logloss: 0.00766307\n",
      "[9632]\ttraining's binary_logloss: 0.0076628\n",
      "[9633]\ttraining's binary_logloss: 0.00766252\n",
      "[9634]\ttraining's binary_logloss: 0.00766223\n",
      "[9635]\ttraining's binary_logloss: 0.00766193\n",
      "[9636]\ttraining's binary_logloss: 0.00766138\n",
      "[9637]\ttraining's binary_logloss: 0.00766109\n",
      "[9638]\ttraining's binary_logloss: 0.0076608\n",
      "[9639]\ttraining's binary_logloss: 0.00766041\n",
      "[9640]\ttraining's binary_logloss: 0.00765981\n",
      "[9641]\ttraining's binary_logloss: 0.00765931\n",
      "[9642]\ttraining's binary_logloss: 0.00765913\n",
      "[9643]\ttraining's binary_logloss: 0.00765897\n",
      "[9644]\ttraining's binary_logloss: 0.00765868\n",
      "[9645]\ttraining's binary_logloss: 0.00765851\n",
      "[9646]\ttraining's binary_logloss: 0.007658\n",
      "[9647]\ttraining's binary_logloss: 0.0076577\n",
      "[9648]\ttraining's binary_logloss: 0.00765705\n",
      "[9649]\ttraining's binary_logloss: 0.0076567\n",
      "[9650]\ttraining's binary_logloss: 0.00765653\n",
      "[9651]\ttraining's binary_logloss: 0.00765579\n",
      "[9652]\ttraining's binary_logloss: 0.00765551\n",
      "[9653]\ttraining's binary_logloss: 0.00765508\n",
      "[9654]\ttraining's binary_logloss: 0.00765478\n",
      "[9655]\ttraining's binary_logloss: 0.00765405\n",
      "[9656]\ttraining's binary_logloss: 0.0076535\n",
      "[9657]\ttraining's binary_logloss: 0.00765281\n",
      "[9658]\ttraining's binary_logloss: 0.00765252\n",
      "[9659]\ttraining's binary_logloss: 0.00765206\n",
      "[9660]\ttraining's binary_logloss: 0.00765145\n",
      "[9661]\ttraining's binary_logloss: 0.00765116\n",
      "[9662]\ttraining's binary_logloss: 0.007651\n",
      "[9663]\ttraining's binary_logloss: 0.00765082\n",
      "[9664]\ttraining's binary_logloss: 0.00765066\n",
      "[9665]\ttraining's binary_logloss: 0.00765041\n",
      "[9666]\ttraining's binary_logloss: 0.00765024\n",
      "[9667]\ttraining's binary_logloss: 0.00765008\n",
      "[9668]\ttraining's binary_logloss: 0.0076499\n",
      "[9669]\ttraining's binary_logloss: 0.00764925\n",
      "[9670]\ttraining's binary_logloss: 0.00764871\n",
      "[9671]\ttraining's binary_logloss: 0.00764841\n",
      "[9672]\ttraining's binary_logloss: 0.00764813\n",
      "[9673]\ttraining's binary_logloss: 0.00764756\n",
      "[9674]\ttraining's binary_logloss: 0.00764721\n",
      "[9675]\ttraining's binary_logloss: 0.00764648\n",
      "[9676]\ttraining's binary_logloss: 0.00764619\n",
      "[9677]\ttraining's binary_logloss: 0.0076459\n",
      "[9678]\ttraining's binary_logloss: 0.00764547\n",
      "[9679]\ttraining's binary_logloss: 0.00764482\n",
      "[9680]\ttraining's binary_logloss: 0.00764454\n",
      "[9681]\ttraining's binary_logloss: 0.00764394\n",
      "[9682]\ttraining's binary_logloss: 0.00764366\n",
      "[9683]\ttraining's binary_logloss: 0.00764324\n",
      "[9684]\ttraining's binary_logloss: 0.00764266\n",
      "[9685]\ttraining's binary_logloss: 0.00764242\n",
      "[9686]\ttraining's binary_logloss: 0.00764195\n",
      "[9687]\ttraining's binary_logloss: 0.00764163\n",
      "[9688]\ttraining's binary_logloss: 0.00764128\n",
      "[9689]\ttraining's binary_logloss: 0.00764055\n",
      "[9690]\ttraining's binary_logloss: 0.00764028\n",
      "[9691]\ttraining's binary_logloss: 0.00764\n",
      "[9692]\ttraining's binary_logloss: 0.00763984\n",
      "[9693]\ttraining's binary_logloss: 0.00763966\n",
      "[9694]\ttraining's binary_logloss: 0.0076395\n",
      "[9695]\ttraining's binary_logloss: 0.00763933\n",
      "[9696]\ttraining's binary_logloss: 0.00763877\n",
      "[9697]\ttraining's binary_logloss: 0.00763826\n",
      "[9698]\ttraining's binary_logloss: 0.00763793\n",
      "[9699]\ttraining's binary_logloss: 0.00763765\n",
      "[9700]\ttraining's binary_logloss: 0.00763741\n",
      "[9701]\ttraining's binary_logloss: 0.00763705\n",
      "[9702]\ttraining's binary_logloss: 0.00763689\n",
      "[9703]\ttraining's binary_logloss: 0.00763672\n",
      "[9704]\ttraining's binary_logloss: 0.00763601\n",
      "[9705]\ttraining's binary_logloss: 0.00763575\n",
      "[9706]\ttraining's binary_logloss: 0.00763559\n",
      "[9707]\ttraining's binary_logloss: 0.00763541\n",
      "[9708]\ttraining's binary_logloss: 0.00763525\n",
      "[9709]\ttraining's binary_logloss: 0.00763508\n",
      "[9710]\ttraining's binary_logloss: 0.00763446\n",
      "[9711]\ttraining's binary_logloss: 0.00763417\n",
      "[9712]\ttraining's binary_logloss: 0.00763383\n",
      "[9713]\ttraining's binary_logloss: 0.00763359\n",
      "[9714]\ttraining's binary_logloss: 0.00763328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9715]\ttraining's binary_logloss: 0.00763234\n",
      "[9716]\ttraining's binary_logloss: 0.00763179\n",
      "[9717]\ttraining's binary_logloss: 0.00763123\n",
      "[9718]\ttraining's binary_logloss: 0.00763059\n",
      "[9719]\ttraining's binary_logloss: 0.00763026\n",
      "[9720]\ttraining's binary_logloss: 0.0076295\n",
      "[9721]\ttraining's binary_logloss: 0.00762918\n",
      "[9722]\ttraining's binary_logloss: 0.00762894\n",
      "[9723]\ttraining's binary_logloss: 0.00762833\n",
      "[9724]\ttraining's binary_logloss: 0.00762804\n",
      "[9725]\ttraining's binary_logloss: 0.00762773\n",
      "[9726]\ttraining's binary_logloss: 0.00762713\n",
      "[9727]\ttraining's binary_logloss: 0.00762685\n",
      "[9728]\ttraining's binary_logloss: 0.00762657\n",
      "[9729]\ttraining's binary_logloss: 0.00762626\n",
      "[9730]\ttraining's binary_logloss: 0.00762571\n",
      "[9731]\ttraining's binary_logloss: 0.00762519\n",
      "[9732]\ttraining's binary_logloss: 0.00762482\n",
      "[9733]\ttraining's binary_logloss: 0.00762449\n",
      "[9734]\ttraining's binary_logloss: 0.00762395\n",
      "[9735]\ttraining's binary_logloss: 0.0076233\n",
      "[9736]\ttraining's binary_logloss: 0.00762303\n",
      "[9737]\ttraining's binary_logloss: 0.00762259\n",
      "[9738]\ttraining's binary_logloss: 0.00762227\n",
      "[9739]\ttraining's binary_logloss: 0.00762168\n",
      "[9740]\ttraining's binary_logloss: 0.00762094\n",
      "[9741]\ttraining's binary_logloss: 0.00762063\n",
      "[9742]\ttraining's binary_logloss: 0.00761992\n",
      "[9743]\ttraining's binary_logloss: 0.00761965\n",
      "[9744]\ttraining's binary_logloss: 0.00761896\n",
      "[9745]\ttraining's binary_logloss: 0.00761859\n",
      "[9746]\ttraining's binary_logloss: 0.00761834\n",
      "[9747]\ttraining's binary_logloss: 0.00761817\n",
      "[9748]\ttraining's binary_logloss: 0.00761741\n",
      "[9749]\ttraining's binary_logloss: 0.00761689\n",
      "[9750]\ttraining's binary_logloss: 0.00761663\n",
      "[9751]\ttraining's binary_logloss: 0.00761646\n",
      "[9752]\ttraining's binary_logloss: 0.0076163\n",
      "[9753]\ttraining's binary_logloss: 0.00761613\n",
      "[9754]\ttraining's binary_logloss: 0.00761597\n",
      "[9755]\ttraining's binary_logloss: 0.00761579\n",
      "[9756]\ttraining's binary_logloss: 0.00761538\n",
      "[9757]\ttraining's binary_logloss: 0.00761522\n",
      "[9758]\ttraining's binary_logloss: 0.00761456\n",
      "[9759]\ttraining's binary_logloss: 0.00761386\n",
      "[9760]\ttraining's binary_logloss: 0.00761339\n",
      "[9761]\ttraining's binary_logloss: 0.00761311\n",
      "[9762]\ttraining's binary_logloss: 0.00761238\n",
      "[9763]\ttraining's binary_logloss: 0.0076122\n",
      "[9764]\ttraining's binary_logloss: 0.0076119\n",
      "[9765]\ttraining's binary_logloss: 0.00761131\n",
      "[9766]\ttraining's binary_logloss: 0.00761095\n",
      "[9767]\ttraining's binary_logloss: 0.00761071\n",
      "[9768]\ttraining's binary_logloss: 0.00761055\n",
      "[9769]\ttraining's binary_logloss: 0.00761029\n",
      "[9770]\ttraining's binary_logloss: 0.00760977\n",
      "[9771]\ttraining's binary_logloss: 0.00760949\n",
      "[9772]\ttraining's binary_logloss: 0.00760925\n",
      "[9773]\ttraining's binary_logloss: 0.00760897\n",
      "[9774]\ttraining's binary_logloss: 0.0076088\n",
      "[9775]\ttraining's binary_logloss: 0.00760864\n",
      "[9776]\ttraining's binary_logloss: 0.00760846\n",
      "[9777]\ttraining's binary_logloss: 0.00760783\n",
      "[9778]\ttraining's binary_logloss: 0.00760767\n",
      "[9779]\ttraining's binary_logloss: 0.0076075\n",
      "[9780]\ttraining's binary_logloss: 0.00760734\n",
      "[9781]\ttraining's binary_logloss: 0.00760717\n",
      "[9782]\ttraining's binary_logloss: 0.00760701\n",
      "[9783]\ttraining's binary_logloss: 0.00760684\n",
      "[9784]\ttraining's binary_logloss: 0.00760668\n",
      "[9785]\ttraining's binary_logloss: 0.00760651\n",
      "[9786]\ttraining's binary_logloss: 0.00760623\n",
      "[9787]\ttraining's binary_logloss: 0.00760607\n",
      "[9788]\ttraining's binary_logloss: 0.00760528\n",
      "[9789]\ttraining's binary_logloss: 0.00760484\n",
      "[9790]\ttraining's binary_logloss: 0.00760467\n",
      "[9791]\ttraining's binary_logloss: 0.00760388\n",
      "[9792]\ttraining's binary_logloss: 0.00760353\n",
      "[9793]\ttraining's binary_logloss: 0.00760329\n",
      "[9794]\ttraining's binary_logloss: 0.007603\n",
      "[9795]\ttraining's binary_logloss: 0.00760242\n",
      "[9796]\ttraining's binary_logloss: 0.00760212\n",
      "[9797]\ttraining's binary_logloss: 0.00760177\n",
      "[9798]\ttraining's binary_logloss: 0.00760161\n",
      "[9799]\ttraining's binary_logloss: 0.00760138\n",
      "[9800]\ttraining's binary_logloss: 0.00760049\n",
      "[9801]\ttraining's binary_logloss: 0.00760023\n",
      "[9802]\ttraining's binary_logloss: 0.00759962\n",
      "[9803]\ttraining's binary_logloss: 0.00759905\n",
      "[9804]\ttraining's binary_logloss: 0.00759833\n",
      "[9805]\ttraining's binary_logloss: 0.00759773\n",
      "[9806]\ttraining's binary_logloss: 0.00759743\n",
      "[9807]\ttraining's binary_logloss: 0.00759715\n",
      "[9808]\ttraining's binary_logloss: 0.00759687\n",
      "[9809]\ttraining's binary_logloss: 0.00759664\n",
      "[9810]\ttraining's binary_logloss: 0.00759616\n",
      "[9811]\ttraining's binary_logloss: 0.00759593\n",
      "[9812]\ttraining's binary_logloss: 0.00759537\n",
      "[9813]\ttraining's binary_logloss: 0.00759507\n",
      "[9814]\ttraining's binary_logloss: 0.00759483\n",
      "[9815]\ttraining's binary_logloss: 0.0075942\n",
      "[9816]\ttraining's binary_logloss: 0.00759395\n",
      "[9817]\ttraining's binary_logloss: 0.00759337\n",
      "[9818]\ttraining's binary_logloss: 0.0075932\n",
      "[9819]\ttraining's binary_logloss: 0.00759292\n",
      "[9820]\ttraining's binary_logloss: 0.0075924\n",
      "[9821]\ttraining's binary_logloss: 0.00759214\n",
      "[9822]\ttraining's binary_logloss: 0.00759183\n",
      "[9823]\ttraining's binary_logloss: 0.00759167\n",
      "[9824]\ttraining's binary_logloss: 0.00759151\n",
      "[9825]\ttraining's binary_logloss: 0.00759123\n",
      "[9826]\ttraining's binary_logloss: 0.00759091\n",
      "[9827]\ttraining's binary_logloss: 0.00759075\n",
      "[9828]\ttraining's binary_logloss: 0.00759058\n",
      "[9829]\ttraining's binary_logloss: 0.00759042\n",
      "[9830]\ttraining's binary_logloss: 0.00759026\n",
      "[9831]\ttraining's binary_logloss: 0.0075901\n",
      "[9832]\ttraining's binary_logloss: 0.00758993\n",
      "[9833]\ttraining's binary_logloss: 0.00758969\n",
      "[9834]\ttraining's binary_logloss: 0.00758953\n",
      "[9835]\ttraining's binary_logloss: 0.00758936\n",
      "[9836]\ttraining's binary_logloss: 0.00758909\n",
      "[9837]\ttraining's binary_logloss: 0.00758882\n",
      "[9838]\ttraining's binary_logloss: 0.00758856\n",
      "[9839]\ttraining's binary_logloss: 0.00758786\n",
      "[9840]\ttraining's binary_logloss: 0.00758769\n",
      "[9841]\ttraining's binary_logloss: 0.00758753\n",
      "[9842]\ttraining's binary_logloss: 0.00758726\n",
      "[9843]\ttraining's binary_logloss: 0.00758668\n",
      "[9844]\ttraining's binary_logloss: 0.00758645\n",
      "[9845]\ttraining's binary_logloss: 0.00758614\n",
      "[9846]\ttraining's binary_logloss: 0.00758589\n",
      "[9847]\ttraining's binary_logloss: 0.0075856\n",
      "[9848]\ttraining's binary_logloss: 0.00758467\n",
      "[9849]\ttraining's binary_logloss: 0.0075844\n",
      "[9850]\ttraining's binary_logloss: 0.00758413\n",
      "[9851]\ttraining's binary_logloss: 0.00758397\n",
      "[9852]\ttraining's binary_logloss: 0.0075838\n",
      "[9853]\ttraining's binary_logloss: 0.00758364\n",
      "[9854]\ttraining's binary_logloss: 0.00758347\n",
      "[9855]\ttraining's binary_logloss: 0.0075832\n",
      "[9856]\ttraining's binary_logloss: 0.00758292\n",
      "[9857]\ttraining's binary_logloss: 0.00758255\n",
      "[9858]\ttraining's binary_logloss: 0.00758231\n",
      "[9859]\ttraining's binary_logloss: 0.00758208\n",
      "[9860]\ttraining's binary_logloss: 0.00758184\n",
      "[9861]\ttraining's binary_logloss: 0.00758168\n",
      "[9862]\ttraining's binary_logloss: 0.00758127\n",
      "[9863]\ttraining's binary_logloss: 0.00758103\n",
      "[9864]\ttraining's binary_logloss: 0.0075807\n",
      "[9865]\ttraining's binary_logloss: 0.00758007\n",
      "[9866]\ttraining's binary_logloss: 0.0075798\n",
      "[9867]\ttraining's binary_logloss: 0.00757935\n",
      "[9868]\ttraining's binary_logloss: 0.00757879\n",
      "[9869]\ttraining's binary_logloss: 0.00757856\n",
      "[9870]\ttraining's binary_logloss: 0.00757828\n",
      "[9871]\ttraining's binary_logloss: 0.00757798\n",
      "[9872]\ttraining's binary_logloss: 0.0075777\n",
      "[9873]\ttraining's binary_logloss: 0.00757742\n",
      "[9874]\ttraining's binary_logloss: 0.00757705\n",
      "[9875]\ttraining's binary_logloss: 0.00757654\n",
      "[9876]\ttraining's binary_logloss: 0.00757631\n",
      "[9877]\ttraining's binary_logloss: 0.00757603\n",
      "[9878]\ttraining's binary_logloss: 0.00757571\n",
      "[9879]\ttraining's binary_logloss: 0.00757544\n",
      "[9880]\ttraining's binary_logloss: 0.00757517\n",
      "[9881]\ttraining's binary_logloss: 0.007575\n",
      "[9882]\ttraining's binary_logloss: 0.00757483\n",
      "[9883]\ttraining's binary_logloss: 0.00757432\n",
      "[9884]\ttraining's binary_logloss: 0.00757416\n",
      "[9885]\ttraining's binary_logloss: 0.007574\n",
      "[9886]\ttraining's binary_logloss: 0.00757349\n",
      "[9887]\ttraining's binary_logloss: 0.00757312\n",
      "[9888]\ttraining's binary_logloss: 0.00757251\n",
      "[9889]\ttraining's binary_logloss: 0.00757222\n",
      "[9890]\ttraining's binary_logloss: 0.00757165\n",
      "[9891]\ttraining's binary_logloss: 0.00757094\n",
      "[9892]\ttraining's binary_logloss: 0.0075704\n",
      "[9893]\ttraining's binary_logloss: 0.0075701\n",
      "[9894]\ttraining's binary_logloss: 0.00756969\n",
      "[9895]\ttraining's binary_logloss: 0.00756902\n",
      "[9896]\ttraining's binary_logloss: 0.00756848\n",
      "[9897]\ttraining's binary_logloss: 0.00756792\n",
      "[9898]\ttraining's binary_logloss: 0.00756776\n",
      "[9899]\ttraining's binary_logloss: 0.00756746\n",
      "[9900]\ttraining's binary_logloss: 0.00756677\n",
      "[9901]\ttraining's binary_logloss: 0.0075665\n",
      "[9902]\ttraining's binary_logloss: 0.00756623\n",
      "[9903]\ttraining's binary_logloss: 0.00756591\n",
      "[9904]\ttraining's binary_logloss: 0.00756575\n",
      "[9905]\ttraining's binary_logloss: 0.00756558\n",
      "[9906]\ttraining's binary_logloss: 0.00756496\n",
      "[9907]\ttraining's binary_logloss: 0.00756435\n",
      "[9908]\ttraining's binary_logloss: 0.00756402\n",
      "[9909]\ttraining's binary_logloss: 0.00756334\n",
      "[9910]\ttraining's binary_logloss: 0.00756307\n",
      "[9911]\ttraining's binary_logloss: 0.00756257\n",
      "[9912]\ttraining's binary_logloss: 0.00756231\n",
      "[9913]\ttraining's binary_logloss: 0.00756203\n",
      "[9914]\ttraining's binary_logloss: 0.00756176\n",
      "[9915]\ttraining's binary_logloss: 0.00756149\n",
      "[9916]\ttraining's binary_logloss: 0.00756132\n",
      "[9917]\ttraining's binary_logloss: 0.00756116\n",
      "[9918]\ttraining's binary_logloss: 0.00756061\n",
      "[9919]\ttraining's binary_logloss: 0.00755997\n",
      "[9920]\ttraining's binary_logloss: 0.00755937\n",
      "[9921]\ttraining's binary_logloss: 0.0075586\n",
      "[9922]\ttraining's binary_logloss: 0.00755844\n",
      "[9923]\ttraining's binary_logloss: 0.0075581\n",
      "[9924]\ttraining's binary_logloss: 0.00755786\n",
      "[9925]\ttraining's binary_logloss: 0.0075577\n",
      "[9926]\ttraining's binary_logloss: 0.00755746\n",
      "[9927]\ttraining's binary_logloss: 0.00755701\n",
      "[9928]\ttraining's binary_logloss: 0.00755632\n",
      "[9929]\ttraining's binary_logloss: 0.00755604\n",
      "[9930]\ttraining's binary_logloss: 0.00755587\n",
      "[9931]\ttraining's binary_logloss: 0.00755522\n",
      "[9932]\ttraining's binary_logloss: 0.00755506\n",
      "[9933]\ttraining's binary_logloss: 0.00755477\n",
      "[9934]\ttraining's binary_logloss: 0.00755448\n",
      "[9935]\ttraining's binary_logloss: 0.00755431\n",
      "[9936]\ttraining's binary_logloss: 0.00755415\n",
      "[9937]\ttraining's binary_logloss: 0.00755392\n",
      "[9938]\ttraining's binary_logloss: 0.00755365\n",
      "[9939]\ttraining's binary_logloss: 0.00755318\n",
      "[9940]\ttraining's binary_logloss: 0.00755266\n",
      "[9941]\ttraining's binary_logloss: 0.0075525\n",
      "[9942]\ttraining's binary_logloss: 0.00755234\n",
      "[9943]\ttraining's binary_logloss: 0.00755207\n",
      "[9944]\ttraining's binary_logloss: 0.00755184\n",
      "[9945]\ttraining's binary_logloss: 0.00755124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9946]\ttraining's binary_logloss: 0.00755097\n",
      "[9947]\ttraining's binary_logloss: 0.00755056\n",
      "[9948]\ttraining's binary_logloss: 0.00754981\n",
      "[9949]\ttraining's binary_logloss: 0.00754958\n",
      "[9950]\ttraining's binary_logloss: 0.00754929\n",
      "[9951]\ttraining's binary_logloss: 0.007549\n",
      "[9952]\ttraining's binary_logloss: 0.00754873\n",
      "[9953]\ttraining's binary_logloss: 0.00754821\n",
      "[9954]\ttraining's binary_logloss: 0.00754794\n",
      "[9955]\ttraining's binary_logloss: 0.00754732\n",
      "[9956]\ttraining's binary_logloss: 0.00754705\n",
      "[9957]\ttraining's binary_logloss: 0.00754677\n",
      "[9958]\ttraining's binary_logloss: 0.00754627\n",
      "[9959]\ttraining's binary_logloss: 0.00754598\n",
      "[9960]\ttraining's binary_logloss: 0.0075458\n",
      "[9961]\ttraining's binary_logloss: 0.00754564\n",
      "[9962]\ttraining's binary_logloss: 0.00754547\n",
      "[9963]\ttraining's binary_logloss: 0.00754498\n",
      "[9964]\ttraining's binary_logloss: 0.00754444\n",
      "[9965]\ttraining's binary_logloss: 0.00754428\n",
      "[9966]\ttraining's binary_logloss: 0.00754377\n",
      "[9967]\ttraining's binary_logloss: 0.00754354\n",
      "[9968]\ttraining's binary_logloss: 0.00754338\n",
      "[9969]\ttraining's binary_logloss: 0.00754306\n",
      "[9970]\ttraining's binary_logloss: 0.00754291\n",
      "[9971]\ttraining's binary_logloss: 0.00754228\n",
      "[9972]\ttraining's binary_logloss: 0.0075421\n",
      "[9973]\ttraining's binary_logloss: 0.00754194\n",
      "[9974]\ttraining's binary_logloss: 0.00754178\n",
      "[9975]\ttraining's binary_logloss: 0.00754129\n",
      "[9976]\ttraining's binary_logloss: 0.00754113\n",
      "[9977]\ttraining's binary_logloss: 0.00754097\n",
      "[9978]\ttraining's binary_logloss: 0.00754081\n",
      "[9979]\ttraining's binary_logloss: 0.00754065\n",
      "[9980]\ttraining's binary_logloss: 0.00754049\n",
      "[9981]\ttraining's binary_logloss: 0.00754032\n",
      "[9982]\ttraining's binary_logloss: 0.00754017\n",
      "[9983]\ttraining's binary_logloss: 0.00754\n",
      "[9984]\ttraining's binary_logloss: 0.00753977\n",
      "[9985]\ttraining's binary_logloss: 0.00753946\n",
      "[9986]\ttraining's binary_logloss: 0.00753919\n",
      "[9987]\ttraining's binary_logloss: 0.00753903\n",
      "[9988]\ttraining's binary_logloss: 0.0075388\n",
      "[9989]\ttraining's binary_logloss: 0.00753863\n",
      "[9990]\ttraining's binary_logloss: 0.00753848\n",
      "[9991]\ttraining's binary_logloss: 0.00753821\n",
      "[9992]\ttraining's binary_logloss: 0.00753791\n",
      "[9993]\ttraining's binary_logloss: 0.0075375\n",
      "[9994]\ttraining's binary_logloss: 0.00753691\n",
      "[9995]\ttraining's binary_logloss: 0.00753605\n",
      "[9996]\ttraining's binary_logloss: 0.00753528\n",
      "[9997]\ttraining's binary_logloss: 0.00753499\n",
      "[9998]\ttraining's binary_logloss: 0.00753442\n",
      "[9999]\ttraining's binary_logloss: 0.00753418\n",
      "[10000]\ttraining's binary_logloss: 0.0075339\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    nthread=4,\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=34,\n",
    "    colsample_bytree=0.9497036,\n",
    "    subsample=0.8715623,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.041545473,\n",
    "    reg_lambda=0.0735294,\n",
    "    min_split_gain=0.0222415,\n",
    "    min_child_weight=39.3259775,\n",
    "    silent=-1,)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric='f1')\n",
    "\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa545257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test: 0.9831235697940505\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"Score F1 sur l'ensemble de test: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f81b736c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[3396   80]\n",
      " [  38 3437]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66965094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Initialiser les listes pour stocker les résultats\n",
    "threshold_array = np.linspace(0, 1, 100)\n",
    "f1_list = []\n",
    "\n",
    "# Calculer le F1 pour différents seuils\n",
    "for threshold in threshold_array:\n",
    "    # Labels prédits pour un seuil donné\n",
    "    label_pred_threshold = (probas_pred > threshold).astype(int)\n",
    "    # Calcul du f1 pour un seuil donné\n",
    "    f1_threshold = f1_score(\n",
    "        y_true=y_test, y_pred=label_pred_threshold\n",
    "    )\n",
    "\n",
    "    f1_list.append(f1_threshold)\n",
    "\n",
    "# Trouver l'indice du maximum de la liste des scores F1\n",
    "best_threshold_index = np.argmax(f1_list)\n",
    "\n",
    "# Récupérer le seuil correspondant\n",
    "best_threshold = threshold_array[best_threshold_index]\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.plot(threshold_array, f1_list)\n",
    "plt.xlabel('Seuil')\n",
    "plt.ylabel('Score F1')\n",
    "plt.title('Score F1 en fonction du seuil')\n",
    "plt.scatter(best_threshold, f1_list[best_threshold_index], color='red', label=f'Max F1 at threshold {best_threshold:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Utiliser le seuil optimal pour les prédictions\n",
    "optimal_predictions = (probas_pred > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4844a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché avec le seuil optimal: 0.1516236572416348\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_with_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1] > best_threshold).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_with_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché avec le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88bb752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[ 1216 41186]\n",
      " [   40  3684]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_hide_test, predictions_with_optimal_threshold)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a68463f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché sans le seuil optimal: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_without_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1]).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_without_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché sans le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a8444",
   "metadata": {},
   "source": [
    "## Class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c8158b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2378562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 11.39}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "class_weights = get_class_weights(y_train)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0980e95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.691904\n",
      "[2]\ttraining's binary_logloss: 0.690916\n",
      "[3]\ttraining's binary_logloss: 0.690193\n",
      "[4]\ttraining's binary_logloss: 0.689736\n",
      "[5]\ttraining's binary_logloss: 0.689477\n",
      "[6]\ttraining's binary_logloss: 0.689437\n",
      "[7]\ttraining's binary_logloss: 0.689601\n",
      "[8]\ttraining's binary_logloss: 0.68994\n",
      "[9]\ttraining's binary_logloss: 0.690466\n",
      "[10]\ttraining's binary_logloss: 0.691171\n",
      "[11]\ttraining's binary_logloss: 0.692023\n",
      "[12]\ttraining's binary_logloss: 0.693\n",
      "[13]\ttraining's binary_logloss: 0.694323\n",
      "[14]\ttraining's binary_logloss: 0.695777\n",
      "[15]\ttraining's binary_logloss: 0.697182\n",
      "[16]\ttraining's binary_logloss: 0.698655\n",
      "[17]\ttraining's binary_logloss: 0.700239\n",
      "[18]\ttraining's binary_logloss: 0.701958\n",
      "[19]\ttraining's binary_logloss: 0.703756\n",
      "[20]\ttraining's binary_logloss: 0.705647\n",
      "[21]\ttraining's binary_logloss: 0.707762\n",
      "[22]\ttraining's binary_logloss: 0.709841\n",
      "[23]\ttraining's binary_logloss: 0.71201\n",
      "[24]\ttraining's binary_logloss: 0.714233\n",
      "[25]\ttraining's binary_logloss: 0.716535\n",
      "[26]\ttraining's binary_logloss: 0.719048\n",
      "[27]\ttraining's binary_logloss: 0.721494\n",
      "[28]\ttraining's binary_logloss: 0.723974\n",
      "[29]\ttraining's binary_logloss: 0.726512\n",
      "[30]\ttraining's binary_logloss: 0.729066\n",
      "[31]\ttraining's binary_logloss: 0.73168\n",
      "[32]\ttraining's binary_logloss: 0.734363\n",
      "[33]\ttraining's binary_logloss: 0.737225\n",
      "[34]\ttraining's binary_logloss: 0.740061\n",
      "[35]\ttraining's binary_logloss: 0.742815\n",
      "[36]\ttraining's binary_logloss: 0.745627\n",
      "[37]\ttraining's binary_logloss: 0.748494\n",
      "[38]\ttraining's binary_logloss: 0.75133\n",
      "[39]\ttraining's binary_logloss: 0.754366\n",
      "[40]\ttraining's binary_logloss: 0.75725\n",
      "[41]\ttraining's binary_logloss: 0.760203\n",
      "[42]\ttraining's binary_logloss: 0.763148\n",
      "[43]\ttraining's binary_logloss: 0.766083\n",
      "[44]\ttraining's binary_logloss: 0.769049\n",
      "[45]\ttraining's binary_logloss: 0.772015\n",
      "[46]\ttraining's binary_logloss: 0.774998\n",
      "[47]\ttraining's binary_logloss: 0.778032\n",
      "[48]\ttraining's binary_logloss: 0.781071\n",
      "[49]\ttraining's binary_logloss: 0.784088\n",
      "[50]\ttraining's binary_logloss: 0.787128\n",
      "[51]\ttraining's binary_logloss: 0.79017\n",
      "[52]\ttraining's binary_logloss: 0.793245\n",
      "[53]\ttraining's binary_logloss: 0.796248\n",
      "[54]\ttraining's binary_logloss: 0.799314\n",
      "[55]\ttraining's binary_logloss: 0.802369\n",
      "[56]\ttraining's binary_logloss: 0.805428\n",
      "[57]\ttraining's binary_logloss: 0.808573\n",
      "[58]\ttraining's binary_logloss: 0.811622\n",
      "[59]\ttraining's binary_logloss: 0.814628\n",
      "[60]\ttraining's binary_logloss: 0.817651\n",
      "[61]\ttraining's binary_logloss: 0.820654\n",
      "[62]\ttraining's binary_logloss: 0.823668\n",
      "[63]\ttraining's binary_logloss: 0.826726\n",
      "[64]\ttraining's binary_logloss: 0.829708\n",
      "[65]\ttraining's binary_logloss: 0.832685\n",
      "[66]\ttraining's binary_logloss: 0.835649\n",
      "[67]\ttraining's binary_logloss: 0.838618\n",
      "[68]\ttraining's binary_logloss: 0.841544\n",
      "[69]\ttraining's binary_logloss: 0.844477\n",
      "[70]\ttraining's binary_logloss: 0.847362\n",
      "[71]\ttraining's binary_logloss: 0.850272\n",
      "[72]\ttraining's binary_logloss: 0.853173\n",
      "[73]\ttraining's binary_logloss: 0.856024\n",
      "[74]\ttraining's binary_logloss: 0.858869\n",
      "[75]\ttraining's binary_logloss: 0.86171\n",
      "[76]\ttraining's binary_logloss: 0.864502\n",
      "[77]\ttraining's binary_logloss: 0.867268\n",
      "[78]\ttraining's binary_logloss: 0.869983\n",
      "[79]\ttraining's binary_logloss: 0.872671\n",
      "[80]\ttraining's binary_logloss: 0.875307\n",
      "[81]\ttraining's binary_logloss: 0.877953\n",
      "[82]\ttraining's binary_logloss: 0.880576\n",
      "[83]\ttraining's binary_logloss: 0.883156\n",
      "[84]\ttraining's binary_logloss: 0.885752\n",
      "[85]\ttraining's binary_logloss: 0.888322\n",
      "[86]\ttraining's binary_logloss: 0.890829\n",
      "[87]\ttraining's binary_logloss: 0.893386\n",
      "[88]\ttraining's binary_logloss: 0.895834\n",
      "[89]\ttraining's binary_logloss: 0.898313\n",
      "[90]\ttraining's binary_logloss: 0.900759\n",
      "[91]\ttraining's binary_logloss: 0.903227\n",
      "[92]\ttraining's binary_logloss: 0.905628\n",
      "[93]\ttraining's binary_logloss: 0.908024\n",
      "[94]\ttraining's binary_logloss: 0.910349\n",
      "[95]\ttraining's binary_logloss: 0.912663\n",
      "[96]\ttraining's binary_logloss: 0.914937\n",
      "[97]\ttraining's binary_logloss: 0.917192\n",
      "[98]\ttraining's binary_logloss: 0.919448\n",
      "[99]\ttraining's binary_logloss: 0.921716\n",
      "[100]\ttraining's binary_logloss: 0.923925\n",
      "[101]\ttraining's binary_logloss: 0.926063\n",
      "[102]\ttraining's binary_logloss: 0.928237\n",
      "[103]\ttraining's binary_logloss: 0.930331\n",
      "[104]\ttraining's binary_logloss: 0.932418\n",
      "[105]\ttraining's binary_logloss: 0.934491\n",
      "[106]\ttraining's binary_logloss: 0.936541\n",
      "[107]\ttraining's binary_logloss: 0.938571\n",
      "[108]\ttraining's binary_logloss: 0.940573\n",
      "[109]\ttraining's binary_logloss: 0.942528\n",
      "[110]\ttraining's binary_logloss: 0.944472\n",
      "[111]\ttraining's binary_logloss: 0.94633\n",
      "[112]\ttraining's binary_logloss: 0.948216\n",
      "[113]\ttraining's binary_logloss: 0.950062\n",
      "[114]\ttraining's binary_logloss: 0.951849\n",
      "[115]\ttraining's binary_logloss: 0.953551\n",
      "[116]\ttraining's binary_logloss: 0.955313\n",
      "[117]\ttraining's binary_logloss: 0.957041\n",
      "[118]\ttraining's binary_logloss: 0.958705\n",
      "[119]\ttraining's binary_logloss: 0.960373\n",
      "[120]\ttraining's binary_logloss: 0.961977\n",
      "[121]\ttraining's binary_logloss: 0.963499\n",
      "[122]\ttraining's binary_logloss: 0.965112\n",
      "[123]\ttraining's binary_logloss: 0.966679\n",
      "[124]\ttraining's binary_logloss: 0.96816\n",
      "[125]\ttraining's binary_logloss: 0.969668\n",
      "[126]\ttraining's binary_logloss: 0.971092\n",
      "[127]\ttraining's binary_logloss: 0.972507\n",
      "[128]\ttraining's binary_logloss: 0.973889\n",
      "[129]\ttraining's binary_logloss: 0.975315\n",
      "[130]\ttraining's binary_logloss: 0.976692\n",
      "[131]\ttraining's binary_logloss: 0.978062\n",
      "[132]\ttraining's binary_logloss: 0.979341\n",
      "[133]\ttraining's binary_logloss: 0.980609\n",
      "[134]\ttraining's binary_logloss: 0.981897\n",
      "[135]\ttraining's binary_logloss: 0.983077\n",
      "[136]\ttraining's binary_logloss: 0.984297\n",
      "[137]\ttraining's binary_logloss: 0.985562\n",
      "[138]\ttraining's binary_logloss: 0.986704\n",
      "[139]\ttraining's binary_logloss: 0.987842\n",
      "[140]\ttraining's binary_logloss: 0.988971\n",
      "[141]\ttraining's binary_logloss: 0.990087\n",
      "[142]\ttraining's binary_logloss: 0.991178\n",
      "[143]\ttraining's binary_logloss: 0.992249\n",
      "[144]\ttraining's binary_logloss: 0.99326\n",
      "[145]\ttraining's binary_logloss: 0.994277\n",
      "[146]\ttraining's binary_logloss: 0.995227\n",
      "[147]\ttraining's binary_logloss: 0.996196\n",
      "[148]\ttraining's binary_logloss: 0.997113\n",
      "[149]\ttraining's binary_logloss: 0.99808\n",
      "[150]\ttraining's binary_logloss: 0.998935\n",
      "[151]\ttraining's binary_logloss: 0.999796\n",
      "[152]\ttraining's binary_logloss: 1.00062\n",
      "[153]\ttraining's binary_logloss: 1.00143\n",
      "[154]\ttraining's binary_logloss: 1.0022\n",
      "[155]\ttraining's binary_logloss: 1.00301\n",
      "[156]\ttraining's binary_logloss: 1.00377\n",
      "[157]\ttraining's binary_logloss: 1.0045\n",
      "[158]\ttraining's binary_logloss: 1.0052\n",
      "[159]\ttraining's binary_logloss: 1.00591\n",
      "[160]\ttraining's binary_logloss: 1.00656\n",
      "[161]\ttraining's binary_logloss: 1.00718\n",
      "[162]\ttraining's binary_logloss: 1.0078\n",
      "[163]\ttraining's binary_logloss: 1.00841\n",
      "[164]\ttraining's binary_logloss: 1.00898\n",
      "[165]\ttraining's binary_logloss: 1.00956\n",
      "[166]\ttraining's binary_logloss: 1.01011\n",
      "[167]\ttraining's binary_logloss: 1.01062\n",
      "[168]\ttraining's binary_logloss: 1.01118\n",
      "[169]\ttraining's binary_logloss: 1.01169\n",
      "[170]\ttraining's binary_logloss: 1.01221\n",
      "[171]\ttraining's binary_logloss: 1.01266\n",
      "[172]\ttraining's binary_logloss: 1.01312\n",
      "[173]\ttraining's binary_logloss: 1.01353\n",
      "[174]\ttraining's binary_logloss: 1.01393\n",
      "[175]\ttraining's binary_logloss: 1.01432\n",
      "[176]\ttraining's binary_logloss: 1.01468\n",
      "[177]\ttraining's binary_logloss: 1.01505\n",
      "[178]\ttraining's binary_logloss: 1.01537\n",
      "[179]\ttraining's binary_logloss: 1.01572\n",
      "[180]\ttraining's binary_logloss: 1.01603\n",
      "[181]\ttraining's binary_logloss: 1.01638\n",
      "[182]\ttraining's binary_logloss: 1.01673\n",
      "[183]\ttraining's binary_logloss: 1.017\n",
      "[184]\ttraining's binary_logloss: 1.01726\n",
      "[185]\ttraining's binary_logloss: 1.01754\n",
      "[186]\ttraining's binary_logloss: 1.01782\n",
      "[187]\ttraining's binary_logloss: 1.01805\n",
      "[188]\ttraining's binary_logloss: 1.01826\n",
      "[189]\ttraining's binary_logloss: 1.01852\n",
      "[190]\ttraining's binary_logloss: 1.01869\n",
      "[191]\ttraining's binary_logloss: 1.01888\n",
      "[192]\ttraining's binary_logloss: 1.01902\n",
      "[193]\ttraining's binary_logloss: 1.01913\n",
      "[194]\ttraining's binary_logloss: 1.01919\n",
      "[195]\ttraining's binary_logloss: 1.01925\n",
      "[196]\ttraining's binary_logloss: 1.01938\n",
      "[197]\ttraining's binary_logloss: 1.01946\n",
      "[198]\ttraining's binary_logloss: 1.01956\n",
      "[199]\ttraining's binary_logloss: 1.01963\n",
      "[200]\ttraining's binary_logloss: 1.01976\n",
      "[201]\ttraining's binary_logloss: 1.01986\n",
      "[202]\ttraining's binary_logloss: 1.01994\n",
      "[203]\ttraining's binary_logloss: 1.01973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\ttraining's binary_logloss: 1.01983\n",
      "[205]\ttraining's binary_logloss: 1.01987\n",
      "[206]\ttraining's binary_logloss: 1.01992\n",
      "[207]\ttraining's binary_logloss: 1.01993\n",
      "[208]\ttraining's binary_logloss: 1.01991\n",
      "[209]\ttraining's binary_logloss: 1.0199\n",
      "[210]\ttraining's binary_logloss: 1.01997\n",
      "[211]\ttraining's binary_logloss: 1.01996\n",
      "[212]\ttraining's binary_logloss: 1.01996\n",
      "[213]\ttraining's binary_logloss: 1.01992\n",
      "[214]\ttraining's binary_logloss: 1.01992\n",
      "[215]\ttraining's binary_logloss: 1.01985\n",
      "[216]\ttraining's binary_logloss: 1.01975\n",
      "[217]\ttraining's binary_logloss: 1.01964\n",
      "[218]\ttraining's binary_logloss: 1.01959\n",
      "[219]\ttraining's binary_logloss: 1.01947\n",
      "[220]\ttraining's binary_logloss: 1.01935\n",
      "[221]\ttraining's binary_logloss: 1.01928\n",
      "[222]\ttraining's binary_logloss: 1.01926\n",
      "[223]\ttraining's binary_logloss: 1.01919\n",
      "[224]\ttraining's binary_logloss: 1.01909\n",
      "[225]\ttraining's binary_logloss: 1.01883\n",
      "[226]\ttraining's binary_logloss: 1.01866\n",
      "[227]\ttraining's binary_logloss: 1.01857\n",
      "[228]\ttraining's binary_logloss: 1.01839\n",
      "[229]\ttraining's binary_logloss: 1.01824\n",
      "[230]\ttraining's binary_logloss: 1.01816\n",
      "[231]\ttraining's binary_logloss: 1.018\n",
      "[232]\ttraining's binary_logloss: 1.01791\n",
      "[233]\ttraining's binary_logloss: 1.01774\n",
      "[234]\ttraining's binary_logloss: 1.01744\n",
      "[235]\ttraining's binary_logloss: 1.01728\n",
      "[236]\ttraining's binary_logloss: 1.01709\n",
      "[237]\ttraining's binary_logloss: 1.01688\n",
      "[238]\ttraining's binary_logloss: 1.01666\n",
      "[239]\ttraining's binary_logloss: 1.01644\n",
      "[240]\ttraining's binary_logloss: 1.01626\n",
      "[241]\ttraining's binary_logloss: 1.01603\n",
      "[242]\ttraining's binary_logloss: 1.01583\n",
      "[243]\ttraining's binary_logloss: 1.01552\n",
      "[244]\ttraining's binary_logloss: 1.01529\n",
      "[245]\ttraining's binary_logloss: 1.0151\n",
      "[246]\ttraining's binary_logloss: 1.01496\n",
      "[247]\ttraining's binary_logloss: 1.01473\n",
      "[248]\ttraining's binary_logloss: 1.01445\n",
      "[249]\ttraining's binary_logloss: 1.01423\n",
      "[250]\ttraining's binary_logloss: 1.01406\n",
      "[251]\ttraining's binary_logloss: 1.0138\n",
      "[252]\ttraining's binary_logloss: 1.01361\n",
      "[253]\ttraining's binary_logloss: 1.01338\n",
      "[254]\ttraining's binary_logloss: 1.01314\n",
      "[255]\ttraining's binary_logloss: 1.01283\n",
      "[256]\ttraining's binary_logloss: 1.01265\n",
      "[257]\ttraining's binary_logloss: 1.01247\n",
      "[258]\ttraining's binary_logloss: 1.01217\n",
      "[259]\ttraining's binary_logloss: 1.01197\n",
      "[260]\ttraining's binary_logloss: 1.01171\n",
      "[261]\ttraining's binary_logloss: 1.01142\n",
      "[262]\ttraining's binary_logloss: 1.01117\n",
      "[263]\ttraining's binary_logloss: 1.01094\n",
      "[264]\ttraining's binary_logloss: 1.01064\n",
      "[265]\ttraining's binary_logloss: 1.01034\n",
      "[266]\ttraining's binary_logloss: 1.01008\n",
      "[267]\ttraining's binary_logloss: 1.00974\n",
      "[268]\ttraining's binary_logloss: 1.00946\n",
      "[269]\ttraining's binary_logloss: 1.00919\n",
      "[270]\ttraining's binary_logloss: 1.00883\n",
      "[271]\ttraining's binary_logloss: 1.00856\n",
      "[272]\ttraining's binary_logloss: 1.00826\n",
      "[273]\ttraining's binary_logloss: 1.00801\n",
      "[274]\ttraining's binary_logloss: 1.00777\n",
      "[275]\ttraining's binary_logloss: 1.00752\n",
      "[276]\ttraining's binary_logloss: 1.00719\n",
      "[277]\ttraining's binary_logloss: 1.00683\n",
      "[278]\ttraining's binary_logloss: 1.00652\n",
      "[279]\ttraining's binary_logloss: 1.00615\n",
      "[280]\ttraining's binary_logloss: 1.00586\n",
      "[281]\ttraining's binary_logloss: 1.00552\n",
      "[282]\ttraining's binary_logloss: 1.00522\n",
      "[283]\ttraining's binary_logloss: 1.00487\n",
      "[284]\ttraining's binary_logloss: 1.00461\n",
      "[285]\ttraining's binary_logloss: 1.00427\n",
      "[286]\ttraining's binary_logloss: 1.00393\n",
      "[287]\ttraining's binary_logloss: 1.00364\n",
      "[288]\ttraining's binary_logloss: 1.00333\n",
      "[289]\ttraining's binary_logloss: 1.00302\n",
      "[290]\ttraining's binary_logloss: 1.00268\n",
      "[291]\ttraining's binary_logloss: 1.00239\n",
      "[292]\ttraining's binary_logloss: 1.00215\n",
      "[293]\ttraining's binary_logloss: 1.0018\n",
      "[294]\ttraining's binary_logloss: 1.00149\n",
      "[295]\ttraining's binary_logloss: 1.00119\n",
      "[296]\ttraining's binary_logloss: 1.00087\n",
      "[297]\ttraining's binary_logloss: 1.00052\n",
      "[298]\ttraining's binary_logloss: 1.00019\n",
      "[299]\ttraining's binary_logloss: 0.99982\n",
      "[300]\ttraining's binary_logloss: 0.999506\n",
      "[301]\ttraining's binary_logloss: 0.999137\n",
      "[302]\ttraining's binary_logloss: 0.998805\n",
      "[303]\ttraining's binary_logloss: 0.998443\n",
      "[304]\ttraining's binary_logloss: 0.998107\n",
      "[305]\ttraining's binary_logloss: 0.997812\n",
      "[306]\ttraining's binary_logloss: 0.997471\n",
      "[307]\ttraining's binary_logloss: 0.997155\n",
      "[308]\ttraining's binary_logloss: 0.996827\n",
      "[309]\ttraining's binary_logloss: 0.996419\n",
      "[310]\ttraining's binary_logloss: 0.996117\n",
      "[311]\ttraining's binary_logloss: 0.995802\n",
      "[312]\ttraining's binary_logloss: 0.995498\n",
      "[313]\ttraining's binary_logloss: 0.995182\n",
      "[314]\ttraining's binary_logloss: 0.994836\n",
      "[315]\ttraining's binary_logloss: 0.994506\n",
      "[316]\ttraining's binary_logloss: 0.994203\n",
      "[317]\ttraining's binary_logloss: 0.993891\n",
      "[318]\ttraining's binary_logloss: 0.99355\n",
      "[319]\ttraining's binary_logloss: 0.99323\n",
      "[320]\ttraining's binary_logloss: 0.99289\n",
      "[321]\ttraining's binary_logloss: 0.992547\n",
      "[322]\ttraining's binary_logloss: 0.992217\n",
      "[323]\ttraining's binary_logloss: 0.991823\n",
      "[324]\ttraining's binary_logloss: 0.991513\n",
      "[325]\ttraining's binary_logloss: 0.991174\n",
      "[326]\ttraining's binary_logloss: 0.99079\n",
      "[327]\ttraining's binary_logloss: 0.990481\n",
      "[328]\ttraining's binary_logloss: 0.990142\n",
      "[329]\ttraining's binary_logloss: 0.989825\n",
      "[330]\ttraining's binary_logloss: 0.989465\n",
      "[331]\ttraining's binary_logloss: 0.989129\n",
      "[332]\ttraining's binary_logloss: 0.988771\n",
      "[333]\ttraining's binary_logloss: 0.988423\n",
      "[334]\ttraining's binary_logloss: 0.98807\n",
      "[335]\ttraining's binary_logloss: 0.9878\n",
      "[336]\ttraining's binary_logloss: 0.987456\n",
      "[337]\ttraining's binary_logloss: 0.987152\n",
      "[338]\ttraining's binary_logloss: 0.986775\n",
      "[339]\ttraining's binary_logloss: 0.986463\n",
      "[340]\ttraining's binary_logloss: 0.986142\n",
      "[341]\ttraining's binary_logloss: 0.985888\n",
      "[342]\ttraining's binary_logloss: 0.985561\n",
      "[343]\ttraining's binary_logloss: 0.985162\n",
      "[344]\ttraining's binary_logloss: 0.984816\n",
      "[345]\ttraining's binary_logloss: 0.984412\n",
      "[346]\ttraining's binary_logloss: 0.98411\n",
      "[347]\ttraining's binary_logloss: 0.983797\n",
      "[348]\ttraining's binary_logloss: 0.983495\n",
      "[349]\ttraining's binary_logloss: 0.983172\n",
      "[350]\ttraining's binary_logloss: 0.982879\n",
      "[351]\ttraining's binary_logloss: 0.982538\n",
      "[352]\ttraining's binary_logloss: 0.982183\n",
      "[353]\ttraining's binary_logloss: 0.981777\n",
      "[354]\ttraining's binary_logloss: 0.981428\n",
      "[355]\ttraining's binary_logloss: 0.98111\n",
      "[356]\ttraining's binary_logloss: 0.980791\n",
      "[357]\ttraining's binary_logloss: 0.980476\n",
      "[358]\ttraining's binary_logloss: 0.980106\n",
      "[359]\ttraining's binary_logloss: 0.979621\n",
      "[360]\ttraining's binary_logloss: 0.979342\n",
      "[361]\ttraining's binary_logloss: 0.979046\n",
      "[362]\ttraining's binary_logloss: 0.978682\n",
      "[363]\ttraining's binary_logloss: 0.978304\n",
      "[364]\ttraining's binary_logloss: 0.978004\n",
      "[365]\ttraining's binary_logloss: 0.977596\n",
      "[366]\ttraining's binary_logloss: 0.977285\n",
      "[367]\ttraining's binary_logloss: 0.976916\n",
      "[368]\ttraining's binary_logloss: 0.976594\n",
      "[369]\ttraining's binary_logloss: 0.976238\n",
      "[370]\ttraining's binary_logloss: 0.97598\n",
      "[371]\ttraining's binary_logloss: 0.975653\n",
      "[372]\ttraining's binary_logloss: 0.975344\n",
      "[373]\ttraining's binary_logloss: 0.975016\n",
      "[374]\ttraining's binary_logloss: 0.974697\n",
      "[375]\ttraining's binary_logloss: 0.974427\n",
      "[376]\ttraining's binary_logloss: 0.974068\n",
      "[377]\ttraining's binary_logloss: 0.973754\n",
      "[378]\ttraining's binary_logloss: 0.973383\n",
      "[379]\ttraining's binary_logloss: 0.973085\n",
      "[380]\ttraining's binary_logloss: 0.972702\n",
      "[381]\ttraining's binary_logloss: 0.972371\n",
      "[382]\ttraining's binary_logloss: 0.971984\n",
      "[383]\ttraining's binary_logloss: 0.971688\n",
      "[384]\ttraining's binary_logloss: 0.971363\n",
      "[385]\ttraining's binary_logloss: 0.971029\n",
      "[386]\ttraining's binary_logloss: 0.970668\n",
      "[387]\ttraining's binary_logloss: 0.970357\n",
      "[388]\ttraining's binary_logloss: 0.970035\n",
      "[389]\ttraining's binary_logloss: 0.969731\n",
      "[390]\ttraining's binary_logloss: 0.96938\n",
      "[391]\ttraining's binary_logloss: 0.969088\n",
      "[392]\ttraining's binary_logloss: 0.968728\n",
      "[393]\ttraining's binary_logloss: 0.968355\n",
      "[394]\ttraining's binary_logloss: 0.968032\n",
      "[395]\ttraining's binary_logloss: 0.967641\n",
      "[396]\ttraining's binary_logloss: 0.967332\n",
      "[397]\ttraining's binary_logloss: 0.967054\n",
      "[398]\ttraining's binary_logloss: 0.966772\n",
      "[399]\ttraining's binary_logloss: 0.966478\n",
      "[400]\ttraining's binary_logloss: 0.966139\n",
      "[401]\ttraining's binary_logloss: 0.965865\n",
      "[402]\ttraining's binary_logloss: 0.965484\n",
      "[403]\ttraining's binary_logloss: 0.965192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404]\ttraining's binary_logloss: 0.964899\n",
      "[405]\ttraining's binary_logloss: 0.964593\n",
      "[406]\ttraining's binary_logloss: 0.964292\n",
      "[407]\ttraining's binary_logloss: 0.963928\n",
      "[408]\ttraining's binary_logloss: 0.963599\n",
      "[409]\ttraining's binary_logloss: 0.9633\n",
      "[410]\ttraining's binary_logloss: 0.962988\n",
      "[411]\ttraining's binary_logloss: 0.962715\n",
      "[412]\ttraining's binary_logloss: 0.962375\n",
      "[413]\ttraining's binary_logloss: 0.962096\n",
      "[414]\ttraining's binary_logloss: 0.961714\n",
      "[415]\ttraining's binary_logloss: 0.961235\n",
      "[416]\ttraining's binary_logloss: 0.960976\n",
      "[417]\ttraining's binary_logloss: 0.960632\n",
      "[418]\ttraining's binary_logloss: 0.960316\n",
      "[419]\ttraining's binary_logloss: 0.959993\n",
      "[420]\ttraining's binary_logloss: 0.959702\n",
      "[421]\ttraining's binary_logloss: 0.95927\n",
      "[422]\ttraining's binary_logloss: 0.958973\n",
      "[423]\ttraining's binary_logloss: 0.958674\n",
      "[424]\ttraining's binary_logloss: 0.958264\n",
      "[425]\ttraining's binary_logloss: 0.957974\n",
      "[426]\ttraining's binary_logloss: 0.957657\n",
      "[427]\ttraining's binary_logloss: 0.957332\n",
      "[428]\ttraining's binary_logloss: 0.957037\n",
      "[429]\ttraining's binary_logloss: 0.956673\n",
      "[430]\ttraining's binary_logloss: 0.956342\n",
      "[431]\ttraining's binary_logloss: 0.956074\n",
      "[432]\ttraining's binary_logloss: 0.955771\n",
      "[433]\ttraining's binary_logloss: 0.955335\n",
      "[434]\ttraining's binary_logloss: 0.955006\n",
      "[435]\ttraining's binary_logloss: 0.954725\n",
      "[436]\ttraining's binary_logloss: 0.954397\n",
      "[437]\ttraining's binary_logloss: 0.953929\n",
      "[438]\ttraining's binary_logloss: 0.953531\n",
      "[439]\ttraining's binary_logloss: 0.953231\n",
      "[440]\ttraining's binary_logloss: 0.952959\n",
      "[441]\ttraining's binary_logloss: 0.952621\n",
      "[442]\ttraining's binary_logloss: 0.952322\n",
      "[443]\ttraining's binary_logloss: 0.951987\n",
      "[444]\ttraining's binary_logloss: 0.951625\n",
      "[445]\ttraining's binary_logloss: 0.95132\n",
      "[446]\ttraining's binary_logloss: 0.950914\n",
      "[447]\ttraining's binary_logloss: 0.950636\n",
      "[448]\ttraining's binary_logloss: 0.950339\n",
      "[449]\ttraining's binary_logloss: 0.950072\n",
      "[450]\ttraining's binary_logloss: 0.949836\n",
      "[451]\ttraining's binary_logloss: 0.949449\n",
      "[452]\ttraining's binary_logloss: 0.949199\n",
      "[453]\ttraining's binary_logloss: 0.948952\n",
      "[454]\ttraining's binary_logloss: 0.948652\n",
      "[455]\ttraining's binary_logloss: 0.948256\n",
      "[456]\ttraining's binary_logloss: 0.947974\n",
      "[457]\ttraining's binary_logloss: 0.947676\n",
      "[458]\ttraining's binary_logloss: 0.947395\n",
      "[459]\ttraining's binary_logloss: 0.94712\n",
      "[460]\ttraining's binary_logloss: 0.946868\n",
      "[461]\ttraining's binary_logloss: 0.946584\n",
      "[462]\ttraining's binary_logloss: 0.946327\n",
      "[463]\ttraining's binary_logloss: 0.946039\n",
      "[464]\ttraining's binary_logloss: 0.945701\n",
      "[465]\ttraining's binary_logloss: 0.945416\n",
      "[466]\ttraining's binary_logloss: 0.945102\n",
      "[467]\ttraining's binary_logloss: 0.94485\n",
      "[468]\ttraining's binary_logloss: 0.944557\n",
      "[469]\ttraining's binary_logloss: 0.944256\n",
      "[470]\ttraining's binary_logloss: 0.943941\n",
      "[471]\ttraining's binary_logloss: 0.943693\n",
      "[472]\ttraining's binary_logloss: 0.943426\n",
      "[473]\ttraining's binary_logloss: 0.943091\n",
      "[474]\ttraining's binary_logloss: 0.942721\n",
      "[475]\ttraining's binary_logloss: 0.942458\n",
      "[476]\ttraining's binary_logloss: 0.942173\n",
      "[477]\ttraining's binary_logloss: 0.941933\n",
      "[478]\ttraining's binary_logloss: 0.941663\n",
      "[479]\ttraining's binary_logloss: 0.941402\n",
      "[480]\ttraining's binary_logloss: 0.9411\n",
      "[481]\ttraining's binary_logloss: 0.940791\n",
      "[482]\ttraining's binary_logloss: 0.940439\n",
      "[483]\ttraining's binary_logloss: 0.940194\n",
      "[484]\ttraining's binary_logloss: 0.939951\n",
      "[485]\ttraining's binary_logloss: 0.939678\n",
      "[486]\ttraining's binary_logloss: 0.939345\n",
      "[487]\ttraining's binary_logloss: 0.939046\n",
      "[488]\ttraining's binary_logloss: 0.938673\n",
      "[489]\ttraining's binary_logloss: 0.938299\n",
      "[490]\ttraining's binary_logloss: 0.938066\n",
      "[491]\ttraining's binary_logloss: 0.937794\n",
      "[492]\ttraining's binary_logloss: 0.937539\n",
      "[493]\ttraining's binary_logloss: 0.937192\n",
      "[494]\ttraining's binary_logloss: 0.93694\n",
      "[495]\ttraining's binary_logloss: 0.9366\n",
      "[496]\ttraining's binary_logloss: 0.936325\n",
      "[497]\ttraining's binary_logloss: 0.936089\n",
      "[498]\ttraining's binary_logloss: 0.935799\n",
      "[499]\ttraining's binary_logloss: 0.93546\n",
      "[500]\ttraining's binary_logloss: 0.935159\n",
      "[501]\ttraining's binary_logloss: 0.934858\n",
      "[502]\ttraining's binary_logloss: 0.934558\n",
      "[503]\ttraining's binary_logloss: 0.934188\n",
      "[504]\ttraining's binary_logloss: 0.93393\n",
      "[505]\ttraining's binary_logloss: 0.933665\n",
      "[506]\ttraining's binary_logloss: 0.933392\n",
      "[507]\ttraining's binary_logloss: 0.933084\n",
      "[508]\ttraining's binary_logloss: 0.932825\n",
      "[509]\ttraining's binary_logloss: 0.932521\n",
      "[510]\ttraining's binary_logloss: 0.932255\n",
      "[511]\ttraining's binary_logloss: 0.931976\n",
      "[512]\ttraining's binary_logloss: 0.931752\n",
      "[513]\ttraining's binary_logloss: 0.931514\n",
      "[514]\ttraining's binary_logloss: 0.93127\n",
      "[515]\ttraining's binary_logloss: 0.930938\n",
      "[516]\ttraining's binary_logloss: 0.930684\n",
      "[517]\ttraining's binary_logloss: 0.930449\n",
      "[518]\ttraining's binary_logloss: 0.930174\n",
      "[519]\ttraining's binary_logloss: 0.929888\n",
      "[520]\ttraining's binary_logloss: 0.929609\n",
      "[521]\ttraining's binary_logloss: 0.929301\n",
      "[522]\ttraining's binary_logloss: 0.929093\n",
      "[523]\ttraining's binary_logloss: 0.928797\n",
      "[524]\ttraining's binary_logloss: 0.928546\n",
      "[525]\ttraining's binary_logloss: 0.928319\n",
      "[526]\ttraining's binary_logloss: 0.928024\n",
      "[527]\ttraining's binary_logloss: 0.927765\n",
      "[528]\ttraining's binary_logloss: 0.9275\n",
      "[529]\ttraining's binary_logloss: 0.927254\n",
      "[530]\ttraining's binary_logloss: 0.926956\n",
      "[531]\ttraining's binary_logloss: 0.926673\n",
      "[532]\ttraining's binary_logloss: 0.926406\n",
      "[533]\ttraining's binary_logloss: 0.926184\n",
      "[534]\ttraining's binary_logloss: 0.925907\n",
      "[535]\ttraining's binary_logloss: 0.925665\n",
      "[536]\ttraining's binary_logloss: 0.925411\n",
      "[537]\ttraining's binary_logloss: 0.925155\n",
      "[538]\ttraining's binary_logloss: 0.924879\n",
      "[539]\ttraining's binary_logloss: 0.924629\n",
      "[540]\ttraining's binary_logloss: 0.924348\n",
      "[541]\ttraining's binary_logloss: 0.924101\n",
      "[542]\ttraining's binary_logloss: 0.923828\n",
      "[543]\ttraining's binary_logloss: 0.923577\n",
      "[544]\ttraining's binary_logloss: 0.923374\n",
      "[545]\ttraining's binary_logloss: 0.923122\n",
      "[546]\ttraining's binary_logloss: 0.92287\n",
      "[547]\ttraining's binary_logloss: 0.92263\n",
      "[548]\ttraining's binary_logloss: 0.922387\n",
      "[549]\ttraining's binary_logloss: 0.922109\n",
      "[550]\ttraining's binary_logloss: 0.921849\n",
      "[551]\ttraining's binary_logloss: 0.921656\n",
      "[552]\ttraining's binary_logloss: 0.921398\n",
      "[553]\ttraining's binary_logloss: 0.921113\n",
      "[554]\ttraining's binary_logloss: 0.920874\n",
      "[555]\ttraining's binary_logloss: 0.920635\n",
      "[556]\ttraining's binary_logloss: 0.920426\n",
      "[557]\ttraining's binary_logloss: 0.920207\n",
      "[558]\ttraining's binary_logloss: 0.919944\n",
      "[559]\ttraining's binary_logloss: 0.919704\n",
      "[560]\ttraining's binary_logloss: 0.919483\n",
      "[561]\ttraining's binary_logloss: 0.919203\n",
      "[562]\ttraining's binary_logloss: 0.918936\n",
      "[563]\ttraining's binary_logloss: 0.918675\n",
      "[564]\ttraining's binary_logloss: 0.918449\n",
      "[565]\ttraining's binary_logloss: 0.91817\n",
      "[566]\ttraining's binary_logloss: 0.917876\n",
      "[567]\ttraining's binary_logloss: 0.917659\n",
      "[568]\ttraining's binary_logloss: 0.91745\n",
      "[569]\ttraining's binary_logloss: 0.917157\n",
      "[570]\ttraining's binary_logloss: 0.916893\n",
      "[571]\ttraining's binary_logloss: 0.916628\n",
      "[572]\ttraining's binary_logloss: 0.916362\n",
      "[573]\ttraining's binary_logloss: 0.916116\n",
      "[574]\ttraining's binary_logloss: 0.915853\n",
      "[575]\ttraining's binary_logloss: 0.915597\n",
      "[576]\ttraining's binary_logloss: 0.915357\n",
      "[577]\ttraining's binary_logloss: 0.915122\n",
      "[578]\ttraining's binary_logloss: 0.914911\n",
      "[579]\ttraining's binary_logloss: 0.914623\n",
      "[580]\ttraining's binary_logloss: 0.914399\n",
      "[581]\ttraining's binary_logloss: 0.914115\n",
      "[582]\ttraining's binary_logloss: 0.9139\n",
      "[583]\ttraining's binary_logloss: 0.913662\n",
      "[584]\ttraining's binary_logloss: 0.913456\n",
      "[585]\ttraining's binary_logloss: 0.913171\n",
      "[586]\ttraining's binary_logloss: 0.91291\n",
      "[587]\ttraining's binary_logloss: 0.912685\n",
      "[588]\ttraining's binary_logloss: 0.912395\n",
      "[589]\ttraining's binary_logloss: 0.91218\n",
      "[590]\ttraining's binary_logloss: 0.911918\n",
      "[591]\ttraining's binary_logloss: 0.911654\n",
      "[592]\ttraining's binary_logloss: 0.911389\n",
      "[593]\ttraining's binary_logloss: 0.911139\n",
      "[594]\ttraining's binary_logloss: 0.910928\n",
      "[595]\ttraining's binary_logloss: 0.910652\n",
      "[596]\ttraining's binary_logloss: 0.910405\n",
      "[597]\ttraining's binary_logloss: 0.910173\n",
      "[598]\ttraining's binary_logloss: 0.909938\n",
      "[599]\ttraining's binary_logloss: 0.909694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's binary_logloss: 0.909501\n",
      "[601]\ttraining's binary_logloss: 0.909236\n",
      "[602]\ttraining's binary_logloss: 0.908893\n",
      "[603]\ttraining's binary_logloss: 0.908673\n",
      "[604]\ttraining's binary_logloss: 0.908457\n",
      "[605]\ttraining's binary_logloss: 0.908213\n",
      "[606]\ttraining's binary_logloss: 0.907955\n",
      "[607]\ttraining's binary_logloss: 0.907751\n",
      "[608]\ttraining's binary_logloss: 0.907554\n",
      "[609]\ttraining's binary_logloss: 0.907295\n",
      "[610]\ttraining's binary_logloss: 0.90708\n",
      "[611]\ttraining's binary_logloss: 0.906873\n",
      "[612]\ttraining's binary_logloss: 0.906664\n",
      "[613]\ttraining's binary_logloss: 0.906418\n",
      "[614]\ttraining's binary_logloss: 0.906179\n",
      "[615]\ttraining's binary_logloss: 0.905946\n",
      "[616]\ttraining's binary_logloss: 0.905724\n",
      "[617]\ttraining's binary_logloss: 0.905545\n",
      "[618]\ttraining's binary_logloss: 0.90532\n",
      "[619]\ttraining's binary_logloss: 0.905108\n",
      "[620]\ttraining's binary_logloss: 0.904889\n",
      "[621]\ttraining's binary_logloss: 0.904662\n",
      "[622]\ttraining's binary_logloss: 0.904395\n",
      "[623]\ttraining's binary_logloss: 0.904191\n",
      "[624]\ttraining's binary_logloss: 0.903966\n",
      "[625]\ttraining's binary_logloss: 0.903693\n",
      "[626]\ttraining's binary_logloss: 0.903461\n",
      "[627]\ttraining's binary_logloss: 0.903299\n",
      "[628]\ttraining's binary_logloss: 0.903074\n",
      "[629]\ttraining's binary_logloss: 0.902818\n",
      "[630]\ttraining's binary_logloss: 0.90261\n",
      "[631]\ttraining's binary_logloss: 0.902405\n",
      "[632]\ttraining's binary_logloss: 0.902137\n",
      "[633]\ttraining's binary_logloss: 0.901905\n",
      "[634]\ttraining's binary_logloss: 0.901644\n",
      "[635]\ttraining's binary_logloss: 0.901427\n",
      "[636]\ttraining's binary_logloss: 0.901218\n",
      "[637]\ttraining's binary_logloss: 0.901046\n",
      "[638]\ttraining's binary_logloss: 0.900844\n",
      "[639]\ttraining's binary_logloss: 0.900661\n",
      "[640]\ttraining's binary_logloss: 0.90043\n",
      "[641]\ttraining's binary_logloss: 0.90024\n",
      "[642]\ttraining's binary_logloss: 0.900028\n",
      "[643]\ttraining's binary_logloss: 0.899841\n",
      "[644]\ttraining's binary_logloss: 0.899625\n",
      "[645]\ttraining's binary_logloss: 0.899405\n",
      "[646]\ttraining's binary_logloss: 0.899174\n",
      "[647]\ttraining's binary_logloss: 0.898896\n",
      "[648]\ttraining's binary_logloss: 0.898675\n",
      "[649]\ttraining's binary_logloss: 0.898383\n",
      "[650]\ttraining's binary_logloss: 0.898132\n",
      "[651]\ttraining's binary_logloss: 0.897914\n",
      "[652]\ttraining's binary_logloss: 0.897708\n",
      "[653]\ttraining's binary_logloss: 0.897552\n",
      "[654]\ttraining's binary_logloss: 0.897324\n",
      "[655]\ttraining's binary_logloss: 0.897064\n",
      "[656]\ttraining's binary_logloss: 0.896805\n",
      "[657]\ttraining's binary_logloss: 0.896543\n",
      "[658]\ttraining's binary_logloss: 0.896342\n",
      "[659]\ttraining's binary_logloss: 0.896117\n",
      "[660]\ttraining's binary_logloss: 0.895887\n",
      "[661]\ttraining's binary_logloss: 0.895658\n",
      "[662]\ttraining's binary_logloss: 0.895393\n",
      "[663]\ttraining's binary_logloss: 0.895162\n",
      "[664]\ttraining's binary_logloss: 0.89496\n",
      "[665]\ttraining's binary_logloss: 0.894719\n",
      "[666]\ttraining's binary_logloss: 0.894566\n",
      "[667]\ttraining's binary_logloss: 0.894365\n",
      "[668]\ttraining's binary_logloss: 0.894183\n",
      "[669]\ttraining's binary_logloss: 0.893951\n",
      "[670]\ttraining's binary_logloss: 0.893704\n",
      "[671]\ttraining's binary_logloss: 0.893491\n",
      "[672]\ttraining's binary_logloss: 0.89321\n",
      "[673]\ttraining's binary_logloss: 0.892972\n",
      "[674]\ttraining's binary_logloss: 0.892723\n",
      "[675]\ttraining's binary_logloss: 0.892533\n",
      "[676]\ttraining's binary_logloss: 0.892333\n",
      "[677]\ttraining's binary_logloss: 0.892112\n",
      "[678]\ttraining's binary_logloss: 0.891917\n",
      "[679]\ttraining's binary_logloss: 0.891697\n",
      "[680]\ttraining's binary_logloss: 0.891524\n",
      "[681]\ttraining's binary_logloss: 0.891345\n",
      "[682]\ttraining's binary_logloss: 0.891164\n",
      "[683]\ttraining's binary_logloss: 0.890957\n",
      "[684]\ttraining's binary_logloss: 0.890756\n",
      "[685]\ttraining's binary_logloss: 0.890537\n",
      "[686]\ttraining's binary_logloss: 0.890373\n",
      "[687]\ttraining's binary_logloss: 0.890146\n",
      "[688]\ttraining's binary_logloss: 0.889892\n",
      "[689]\ttraining's binary_logloss: 0.889633\n",
      "[690]\ttraining's binary_logloss: 0.889402\n",
      "[691]\ttraining's binary_logloss: 0.88919\n",
      "[692]\ttraining's binary_logloss: 0.889009\n",
      "[693]\ttraining's binary_logloss: 0.888791\n",
      "[694]\ttraining's binary_logloss: 0.888559\n",
      "[695]\ttraining's binary_logloss: 0.888376\n",
      "[696]\ttraining's binary_logloss: 0.888154\n",
      "[697]\ttraining's binary_logloss: 0.887954\n",
      "[698]\ttraining's binary_logloss: 0.887718\n",
      "[699]\ttraining's binary_logloss: 0.88752\n",
      "[700]\ttraining's binary_logloss: 0.887317\n",
      "[701]\ttraining's binary_logloss: 0.887078\n",
      "[702]\ttraining's binary_logloss: 0.886875\n",
      "[703]\ttraining's binary_logloss: 0.886665\n",
      "[704]\ttraining's binary_logloss: 0.886444\n",
      "[705]\ttraining's binary_logloss: 0.886259\n",
      "[706]\ttraining's binary_logloss: 0.885978\n",
      "[707]\ttraining's binary_logloss: 0.885767\n",
      "[708]\ttraining's binary_logloss: 0.88555\n",
      "[709]\ttraining's binary_logloss: 0.88535\n",
      "[710]\ttraining's binary_logloss: 0.885152\n",
      "[711]\ttraining's binary_logloss: 0.884953\n",
      "[712]\ttraining's binary_logloss: 0.88475\n",
      "[713]\ttraining's binary_logloss: 0.88451\n",
      "[714]\ttraining's binary_logloss: 0.884291\n",
      "[715]\ttraining's binary_logloss: 0.884072\n",
      "[716]\ttraining's binary_logloss: 0.883851\n",
      "[717]\ttraining's binary_logloss: 0.883674\n",
      "[718]\ttraining's binary_logloss: 0.883511\n",
      "[719]\ttraining's binary_logloss: 0.88334\n",
      "[720]\ttraining's binary_logloss: 0.883134\n",
      "[721]\ttraining's binary_logloss: 0.88291\n",
      "[722]\ttraining's binary_logloss: 0.882711\n",
      "[723]\ttraining's binary_logloss: 0.882546\n",
      "[724]\ttraining's binary_logloss: 0.882376\n",
      "[725]\ttraining's binary_logloss: 0.8822\n",
      "[726]\ttraining's binary_logloss: 0.882004\n",
      "[727]\ttraining's binary_logloss: 0.881825\n",
      "[728]\ttraining's binary_logloss: 0.881566\n",
      "[729]\ttraining's binary_logloss: 0.881378\n",
      "[730]\ttraining's binary_logloss: 0.881185\n",
      "[731]\ttraining's binary_logloss: 0.88101\n",
      "[732]\ttraining's binary_logloss: 0.880818\n",
      "[733]\ttraining's binary_logloss: 0.880576\n",
      "[734]\ttraining's binary_logloss: 0.880366\n",
      "[735]\ttraining's binary_logloss: 0.880154\n",
      "[736]\ttraining's binary_logloss: 0.879971\n",
      "[737]\ttraining's binary_logloss: 0.879734\n",
      "[738]\ttraining's binary_logloss: 0.879532\n",
      "[739]\ttraining's binary_logloss: 0.879291\n",
      "[740]\ttraining's binary_logloss: 0.879067\n",
      "[741]\ttraining's binary_logloss: 0.878873\n",
      "[742]\ttraining's binary_logloss: 0.878682\n",
      "[743]\ttraining's binary_logloss: 0.878462\n",
      "[744]\ttraining's binary_logloss: 0.87828\n",
      "[745]\ttraining's binary_logloss: 0.878054\n",
      "[746]\ttraining's binary_logloss: 0.877903\n",
      "[747]\ttraining's binary_logloss: 0.877717\n",
      "[748]\ttraining's binary_logloss: 0.877542\n",
      "[749]\ttraining's binary_logloss: 0.877348\n",
      "[750]\ttraining's binary_logloss: 0.877122\n",
      "[751]\ttraining's binary_logloss: 0.876901\n",
      "[752]\ttraining's binary_logloss: 0.876748\n",
      "[753]\ttraining's binary_logloss: 0.876516\n",
      "[754]\ttraining's binary_logloss: 0.876352\n",
      "[755]\ttraining's binary_logloss: 0.876151\n",
      "[756]\ttraining's binary_logloss: 0.87591\n",
      "[757]\ttraining's binary_logloss: 0.875687\n",
      "[758]\ttraining's binary_logloss: 0.875491\n",
      "[759]\ttraining's binary_logloss: 0.875298\n",
      "[760]\ttraining's binary_logloss: 0.87507\n",
      "[761]\ttraining's binary_logloss: 0.874872\n",
      "[762]\ttraining's binary_logloss: 0.874689\n",
      "[763]\ttraining's binary_logloss: 0.87448\n",
      "[764]\ttraining's binary_logloss: 0.874272\n",
      "[765]\ttraining's binary_logloss: 0.874074\n",
      "[766]\ttraining's binary_logloss: 0.873855\n",
      "[767]\ttraining's binary_logloss: 0.873612\n",
      "[768]\ttraining's binary_logloss: 0.873375\n",
      "[769]\ttraining's binary_logloss: 0.873096\n",
      "[770]\ttraining's binary_logloss: 0.872899\n",
      "[771]\ttraining's binary_logloss: 0.872667\n",
      "[772]\ttraining's binary_logloss: 0.872467\n",
      "[773]\ttraining's binary_logloss: 0.872214\n",
      "[774]\ttraining's binary_logloss: 0.872002\n",
      "[775]\ttraining's binary_logloss: 0.871819\n",
      "[776]\ttraining's binary_logloss: 0.871629\n",
      "[777]\ttraining's binary_logloss: 0.871428\n",
      "[778]\ttraining's binary_logloss: 0.871178\n",
      "[779]\ttraining's binary_logloss: 0.871011\n",
      "[780]\ttraining's binary_logloss: 0.870857\n",
      "[781]\ttraining's binary_logloss: 0.870661\n",
      "[782]\ttraining's binary_logloss: 0.870447\n",
      "[783]\ttraining's binary_logloss: 0.870265\n",
      "[784]\ttraining's binary_logloss: 0.870099\n",
      "[785]\ttraining's binary_logloss: 0.869888\n",
      "[786]\ttraining's binary_logloss: 0.869721\n",
      "[787]\ttraining's binary_logloss: 0.869498\n",
      "[788]\ttraining's binary_logloss: 0.869317\n",
      "[789]\ttraining's binary_logloss: 0.869135\n",
      "[790]\ttraining's binary_logloss: 0.86896\n",
      "[791]\ttraining's binary_logloss: 0.868773\n",
      "[792]\ttraining's binary_logloss: 0.868592\n",
      "[793]\ttraining's binary_logloss: 0.868428\n",
      "[794]\ttraining's binary_logloss: 0.86822\n",
      "[795]\ttraining's binary_logloss: 0.868026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[796]\ttraining's binary_logloss: 0.867858\n",
      "[797]\ttraining's binary_logloss: 0.867668\n",
      "[798]\ttraining's binary_logloss: 0.867474\n",
      "[799]\ttraining's binary_logloss: 0.867232\n",
      "[800]\ttraining's binary_logloss: 0.867008\n",
      "[801]\ttraining's binary_logloss: 0.866761\n",
      "[802]\ttraining's binary_logloss: 0.866598\n",
      "[803]\ttraining's binary_logloss: 0.866458\n",
      "[804]\ttraining's binary_logloss: 0.86627\n",
      "[805]\ttraining's binary_logloss: 0.866091\n",
      "[806]\ttraining's binary_logloss: 0.86594\n",
      "[807]\ttraining's binary_logloss: 0.865765\n",
      "[808]\ttraining's binary_logloss: 0.865581\n",
      "[809]\ttraining's binary_logloss: 0.865414\n",
      "[810]\ttraining's binary_logloss: 0.865227\n",
      "[811]\ttraining's binary_logloss: 0.865057\n",
      "[812]\ttraining's binary_logloss: 0.864841\n",
      "[813]\ttraining's binary_logloss: 0.864637\n",
      "[814]\ttraining's binary_logloss: 0.86445\n",
      "[815]\ttraining's binary_logloss: 0.864238\n",
      "[816]\ttraining's binary_logloss: 0.864053\n",
      "[817]\ttraining's binary_logloss: 0.863859\n",
      "[818]\ttraining's binary_logloss: 0.863674\n",
      "[819]\ttraining's binary_logloss: 0.863556\n",
      "[820]\ttraining's binary_logloss: 0.863361\n",
      "[821]\ttraining's binary_logloss: 0.86319\n",
      "[822]\ttraining's binary_logloss: 0.86303\n",
      "[823]\ttraining's binary_logloss: 0.862866\n",
      "[824]\ttraining's binary_logloss: 0.862715\n",
      "[825]\ttraining's binary_logloss: 0.8625\n",
      "[826]\ttraining's binary_logloss: 0.862283\n",
      "[827]\ttraining's binary_logloss: 0.862068\n",
      "[828]\ttraining's binary_logloss: 0.861914\n",
      "[829]\ttraining's binary_logloss: 0.861677\n",
      "[830]\ttraining's binary_logloss: 0.861506\n",
      "[831]\ttraining's binary_logloss: 0.861365\n",
      "[832]\ttraining's binary_logloss: 0.861185\n",
      "[833]\ttraining's binary_logloss: 0.86097\n",
      "[834]\ttraining's binary_logloss: 0.860776\n",
      "[835]\ttraining's binary_logloss: 0.860633\n",
      "[836]\ttraining's binary_logloss: 0.860449\n",
      "[837]\ttraining's binary_logloss: 0.860302\n",
      "[838]\ttraining's binary_logloss: 0.860108\n",
      "[839]\ttraining's binary_logloss: 0.859917\n",
      "[840]\ttraining's binary_logloss: 0.85976\n",
      "[841]\ttraining's binary_logloss: 0.859573\n",
      "[842]\ttraining's binary_logloss: 0.859377\n",
      "[843]\ttraining's binary_logloss: 0.859171\n",
      "[844]\ttraining's binary_logloss: 0.859004\n",
      "[845]\ttraining's binary_logloss: 0.858802\n",
      "[846]\ttraining's binary_logloss: 0.858632\n",
      "[847]\ttraining's binary_logloss: 0.858415\n",
      "[848]\ttraining's binary_logloss: 0.858206\n",
      "[849]\ttraining's binary_logloss: 0.858025\n",
      "[850]\ttraining's binary_logloss: 0.857813\n",
      "[851]\ttraining's binary_logloss: 0.857659\n",
      "[852]\ttraining's binary_logloss: 0.857515\n",
      "[853]\ttraining's binary_logloss: 0.857362\n",
      "[854]\ttraining's binary_logloss: 0.85718\n",
      "[855]\ttraining's binary_logloss: 0.85701\n",
      "[856]\ttraining's binary_logloss: 0.856818\n",
      "[857]\ttraining's binary_logloss: 0.856642\n",
      "[858]\ttraining's binary_logloss: 0.856466\n",
      "[859]\ttraining's binary_logloss: 0.856248\n",
      "[860]\ttraining's binary_logloss: 0.856117\n",
      "[861]\ttraining's binary_logloss: 0.855943\n",
      "[862]\ttraining's binary_logloss: 0.855706\n",
      "[863]\ttraining's binary_logloss: 0.855506\n",
      "[864]\ttraining's binary_logloss: 0.855314\n",
      "[865]\ttraining's binary_logloss: 0.855169\n",
      "[866]\ttraining's binary_logloss: 0.854974\n",
      "[867]\ttraining's binary_logloss: 0.854792\n",
      "[868]\ttraining's binary_logloss: 0.854615\n",
      "[869]\ttraining's binary_logloss: 0.854472\n",
      "[870]\ttraining's binary_logloss: 0.854279\n",
      "[871]\ttraining's binary_logloss: 0.854141\n",
      "[872]\ttraining's binary_logloss: 0.853995\n",
      "[873]\ttraining's binary_logloss: 0.853804\n",
      "[874]\ttraining's binary_logloss: 0.853636\n",
      "[875]\ttraining's binary_logloss: 0.853448\n",
      "[876]\ttraining's binary_logloss: 0.853248\n",
      "[877]\ttraining's binary_logloss: 0.853051\n",
      "[878]\ttraining's binary_logloss: 0.852867\n",
      "[879]\ttraining's binary_logloss: 0.852717\n",
      "[880]\ttraining's binary_logloss: 0.852589\n",
      "[881]\ttraining's binary_logloss: 0.852411\n",
      "[882]\ttraining's binary_logloss: 0.852229\n",
      "[883]\ttraining's binary_logloss: 0.851994\n",
      "[884]\ttraining's binary_logloss: 0.851792\n",
      "[885]\ttraining's binary_logloss: 0.851591\n",
      "[886]\ttraining's binary_logloss: 0.851443\n",
      "[887]\ttraining's binary_logloss: 0.851258\n",
      "[888]\ttraining's binary_logloss: 0.85104\n",
      "[889]\ttraining's binary_logloss: 0.85084\n",
      "[890]\ttraining's binary_logloss: 0.850735\n",
      "[891]\ttraining's binary_logloss: 0.850568\n",
      "[892]\ttraining's binary_logloss: 0.850433\n",
      "[893]\ttraining's binary_logloss: 0.850273\n",
      "[894]\ttraining's binary_logloss: 0.850088\n",
      "[895]\ttraining's binary_logloss: 0.84996\n",
      "[896]\ttraining's binary_logloss: 0.849786\n",
      "[897]\ttraining's binary_logloss: 0.849572\n",
      "[898]\ttraining's binary_logloss: 0.849369\n",
      "[899]\ttraining's binary_logloss: 0.849222\n",
      "[900]\ttraining's binary_logloss: 0.849069\n",
      "[901]\ttraining's binary_logloss: 0.848861\n",
      "[902]\ttraining's binary_logloss: 0.848677\n",
      "[903]\ttraining's binary_logloss: 0.848501\n",
      "[904]\ttraining's binary_logloss: 0.848311\n",
      "[905]\ttraining's binary_logloss: 0.848074\n",
      "[906]\ttraining's binary_logloss: 0.847924\n",
      "[907]\ttraining's binary_logloss: 0.847712\n",
      "[908]\ttraining's binary_logloss: 0.847539\n",
      "[909]\ttraining's binary_logloss: 0.847367\n",
      "[910]\ttraining's binary_logloss: 0.847163\n",
      "[911]\ttraining's binary_logloss: 0.847033\n",
      "[912]\ttraining's binary_logloss: 0.846855\n",
      "[913]\ttraining's binary_logloss: 0.846683\n",
      "[914]\ttraining's binary_logloss: 0.846501\n",
      "[915]\ttraining's binary_logloss: 0.846324\n",
      "[916]\ttraining's binary_logloss: 0.846159\n",
      "[917]\ttraining's binary_logloss: 0.846028\n",
      "[918]\ttraining's binary_logloss: 0.845881\n",
      "[919]\ttraining's binary_logloss: 0.845633\n",
      "[920]\ttraining's binary_logloss: 0.845463\n",
      "[921]\ttraining's binary_logloss: 0.845231\n",
      "[922]\ttraining's binary_logloss: 0.845039\n",
      "[923]\ttraining's binary_logloss: 0.844833\n",
      "[924]\ttraining's binary_logloss: 0.84464\n",
      "[925]\ttraining's binary_logloss: 0.844504\n",
      "[926]\ttraining's binary_logloss: 0.844353\n",
      "[927]\ttraining's binary_logloss: 0.844199\n",
      "[928]\ttraining's binary_logloss: 0.84403\n",
      "[929]\ttraining's binary_logloss: 0.843877\n",
      "[930]\ttraining's binary_logloss: 0.843689\n",
      "[931]\ttraining's binary_logloss: 0.843495\n",
      "[932]\ttraining's binary_logloss: 0.843303\n",
      "[933]\ttraining's binary_logloss: 0.843111\n",
      "[934]\ttraining's binary_logloss: 0.842944\n",
      "[935]\ttraining's binary_logloss: 0.842753\n",
      "[936]\ttraining's binary_logloss: 0.842591\n",
      "[937]\ttraining's binary_logloss: 0.842431\n",
      "[938]\ttraining's binary_logloss: 0.842224\n",
      "[939]\ttraining's binary_logloss: 0.842089\n",
      "[940]\ttraining's binary_logloss: 0.841886\n",
      "[941]\ttraining's binary_logloss: 0.841701\n",
      "[942]\ttraining's binary_logloss: 0.841546\n",
      "[943]\ttraining's binary_logloss: 0.841301\n",
      "[944]\ttraining's binary_logloss: 0.841141\n",
      "[945]\ttraining's binary_logloss: 0.840995\n",
      "[946]\ttraining's binary_logloss: 0.840794\n",
      "[947]\ttraining's binary_logloss: 0.84055\n",
      "[948]\ttraining's binary_logloss: 0.840388\n",
      "[949]\ttraining's binary_logloss: 0.840248\n",
      "[950]\ttraining's binary_logloss: 0.84013\n",
      "[951]\ttraining's binary_logloss: 0.839954\n",
      "[952]\ttraining's binary_logloss: 0.839778\n",
      "[953]\ttraining's binary_logloss: 0.839558\n",
      "[954]\ttraining's binary_logloss: 0.839425\n",
      "[955]\ttraining's binary_logloss: 0.839294\n",
      "[956]\ttraining's binary_logloss: 0.839092\n",
      "[957]\ttraining's binary_logloss: 0.838897\n",
      "[958]\ttraining's binary_logloss: 0.838706\n",
      "[959]\ttraining's binary_logloss: 0.838567\n",
      "[960]\ttraining's binary_logloss: 0.838377\n",
      "[961]\ttraining's binary_logloss: 0.838213\n",
      "[962]\ttraining's binary_logloss: 0.838034\n",
      "[963]\ttraining's binary_logloss: 0.837915\n",
      "[964]\ttraining's binary_logloss: 0.837723\n",
      "[965]\ttraining's binary_logloss: 0.837515\n",
      "[966]\ttraining's binary_logloss: 0.837375\n",
      "[967]\ttraining's binary_logloss: 0.83723\n",
      "[968]\ttraining's binary_logloss: 0.837048\n",
      "[969]\ttraining's binary_logloss: 0.836901\n",
      "[970]\ttraining's binary_logloss: 0.836703\n",
      "[971]\ttraining's binary_logloss: 0.836513\n",
      "[972]\ttraining's binary_logloss: 0.83633\n",
      "[973]\ttraining's binary_logloss: 0.836167\n",
      "[974]\ttraining's binary_logloss: 0.836017\n",
      "[975]\ttraining's binary_logloss: 0.83578\n",
      "[976]\ttraining's binary_logloss: 0.835648\n",
      "[977]\ttraining's binary_logloss: 0.835492\n",
      "[978]\ttraining's binary_logloss: 0.835339\n",
      "[979]\ttraining's binary_logloss: 0.835123\n",
      "[980]\ttraining's binary_logloss: 0.834954\n",
      "[981]\ttraining's binary_logloss: 0.834785\n",
      "[982]\ttraining's binary_logloss: 0.834653\n",
      "[983]\ttraining's binary_logloss: 0.834419\n",
      "[984]\ttraining's binary_logloss: 0.834255\n",
      "[985]\ttraining's binary_logloss: 0.834064\n",
      "[986]\ttraining's binary_logloss: 0.833896\n",
      "[987]\ttraining's binary_logloss: 0.833733\n",
      "[988]\ttraining's binary_logloss: 0.833541\n",
      "[989]\ttraining's binary_logloss: 0.833406\n",
      "[990]\ttraining's binary_logloss: 0.833192\n",
      "[991]\ttraining's binary_logloss: 0.833042\n",
      "[992]\ttraining's binary_logloss: 0.832814\n",
      "[993]\ttraining's binary_logloss: 0.832654\n",
      "[994]\ttraining's binary_logloss: 0.832477\n",
      "[995]\ttraining's binary_logloss: 0.832335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[996]\ttraining's binary_logloss: 0.832157\n",
      "[997]\ttraining's binary_logloss: 0.832017\n",
      "[998]\ttraining's binary_logloss: 0.831811\n",
      "[999]\ttraining's binary_logloss: 0.831676\n",
      "[1000]\ttraining's binary_logloss: 0.831533\n",
      "[1001]\ttraining's binary_logloss: 0.831359\n",
      "[1002]\ttraining's binary_logloss: 0.831206\n",
      "[1003]\ttraining's binary_logloss: 0.831046\n",
      "[1004]\ttraining's binary_logloss: 0.830866\n",
      "[1005]\ttraining's binary_logloss: 0.830709\n",
      "[1006]\ttraining's binary_logloss: 0.830548\n",
      "[1007]\ttraining's binary_logloss: 0.830366\n",
      "[1008]\ttraining's binary_logloss: 0.830205\n",
      "[1009]\ttraining's binary_logloss: 0.83002\n",
      "[1010]\ttraining's binary_logloss: 0.829875\n",
      "[1011]\ttraining's binary_logloss: 0.829667\n",
      "[1012]\ttraining's binary_logloss: 0.829473\n",
      "[1013]\ttraining's binary_logloss: 0.829316\n",
      "[1014]\ttraining's binary_logloss: 0.829148\n",
      "[1015]\ttraining's binary_logloss: 0.829007\n",
      "[1016]\ttraining's binary_logloss: 0.828819\n",
      "[1017]\ttraining's binary_logloss: 0.828639\n",
      "[1018]\ttraining's binary_logloss: 0.828447\n",
      "[1019]\ttraining's binary_logloss: 0.828268\n",
      "[1020]\ttraining's binary_logloss: 0.828098\n",
      "[1021]\ttraining's binary_logloss: 0.827937\n",
      "[1022]\ttraining's binary_logloss: 0.827801\n",
      "[1023]\ttraining's binary_logloss: 0.827585\n",
      "[1024]\ttraining's binary_logloss: 0.827424\n",
      "[1025]\ttraining's binary_logloss: 0.827246\n",
      "[1026]\ttraining's binary_logloss: 0.827111\n",
      "[1027]\ttraining's binary_logloss: 0.826961\n",
      "[1028]\ttraining's binary_logloss: 0.82672\n",
      "[1029]\ttraining's binary_logloss: 0.826527\n",
      "[1030]\ttraining's binary_logloss: 0.826353\n",
      "[1031]\ttraining's binary_logloss: 0.826175\n",
      "[1032]\ttraining's binary_logloss: 0.825919\n",
      "[1033]\ttraining's binary_logloss: 0.825753\n",
      "[1034]\ttraining's binary_logloss: 0.825622\n",
      "[1035]\ttraining's binary_logloss: 0.825463\n",
      "[1036]\ttraining's binary_logloss: 0.8253\n",
      "[1037]\ttraining's binary_logloss: 0.82513\n",
      "[1038]\ttraining's binary_logloss: 0.824992\n",
      "[1039]\ttraining's binary_logloss: 0.824807\n",
      "[1040]\ttraining's binary_logloss: 0.824606\n",
      "[1041]\ttraining's binary_logloss: 0.824442\n",
      "[1042]\ttraining's binary_logloss: 0.824269\n",
      "[1043]\ttraining's binary_logloss: 0.824116\n",
      "[1044]\ttraining's binary_logloss: 0.823903\n",
      "[1045]\ttraining's binary_logloss: 0.823734\n",
      "[1046]\ttraining's binary_logloss: 0.823615\n",
      "[1047]\ttraining's binary_logloss: 0.823476\n",
      "[1048]\ttraining's binary_logloss: 0.823358\n",
      "[1049]\ttraining's binary_logloss: 0.823223\n",
      "[1050]\ttraining's binary_logloss: 0.823018\n",
      "[1051]\ttraining's binary_logloss: 0.822876\n",
      "[1052]\ttraining's binary_logloss: 0.822754\n",
      "[1053]\ttraining's binary_logloss: 0.822594\n",
      "[1054]\ttraining's binary_logloss: 0.822405\n",
      "[1055]\ttraining's binary_logloss: 0.822221\n",
      "[1056]\ttraining's binary_logloss: 0.82203\n",
      "[1057]\ttraining's binary_logloss: 0.82183\n",
      "[1058]\ttraining's binary_logloss: 0.821672\n",
      "[1059]\ttraining's binary_logloss: 0.821512\n",
      "[1060]\ttraining's binary_logloss: 0.821341\n",
      "[1061]\ttraining's binary_logloss: 0.821193\n",
      "[1062]\ttraining's binary_logloss: 0.821009\n",
      "[1063]\ttraining's binary_logloss: 0.820779\n",
      "[1064]\ttraining's binary_logloss: 0.820557\n",
      "[1065]\ttraining's binary_logloss: 0.820433\n",
      "[1066]\ttraining's binary_logloss: 0.820303\n",
      "[1067]\ttraining's binary_logloss: 0.820106\n",
      "[1068]\ttraining's binary_logloss: 0.819978\n",
      "[1069]\ttraining's binary_logloss: 0.819812\n",
      "[1070]\ttraining's binary_logloss: 0.819649\n",
      "[1071]\ttraining's binary_logloss: 0.819486\n",
      "[1072]\ttraining's binary_logloss: 0.819334\n",
      "[1073]\ttraining's binary_logloss: 0.819149\n",
      "[1074]\ttraining's binary_logloss: 0.818961\n",
      "[1075]\ttraining's binary_logloss: 0.81876\n",
      "[1076]\ttraining's binary_logloss: 0.81855\n",
      "[1077]\ttraining's binary_logloss: 0.81838\n",
      "[1078]\ttraining's binary_logloss: 0.818196\n",
      "[1079]\ttraining's binary_logloss: 0.818014\n",
      "[1080]\ttraining's binary_logloss: 0.817899\n",
      "[1081]\ttraining's binary_logloss: 0.817681\n",
      "[1082]\ttraining's binary_logloss: 0.817533\n",
      "[1083]\ttraining's binary_logloss: 0.817371\n",
      "[1084]\ttraining's binary_logloss: 0.817177\n",
      "[1085]\ttraining's binary_logloss: 0.817056\n",
      "[1086]\ttraining's binary_logloss: 0.816867\n",
      "[1087]\ttraining's binary_logloss: 0.816656\n",
      "[1088]\ttraining's binary_logloss: 0.816548\n",
      "[1089]\ttraining's binary_logloss: 0.816386\n",
      "[1090]\ttraining's binary_logloss: 0.816245\n",
      "[1091]\ttraining's binary_logloss: 0.816046\n",
      "[1092]\ttraining's binary_logloss: 0.815871\n",
      "[1093]\ttraining's binary_logloss: 0.815765\n",
      "[1094]\ttraining's binary_logloss: 0.815607\n",
      "[1095]\ttraining's binary_logloss: 0.815415\n",
      "[1096]\ttraining's binary_logloss: 0.81526\n",
      "[1097]\ttraining's binary_logloss: 0.815054\n",
      "[1098]\ttraining's binary_logloss: 0.814895\n",
      "[1099]\ttraining's binary_logloss: 0.814795\n",
      "[1100]\ttraining's binary_logloss: 0.814634\n",
      "[1101]\ttraining's binary_logloss: 0.814451\n",
      "[1102]\ttraining's binary_logloss: 0.814298\n",
      "[1103]\ttraining's binary_logloss: 0.814132\n",
      "[1104]\ttraining's binary_logloss: 0.813973\n",
      "[1105]\ttraining's binary_logloss: 0.813839\n",
      "[1106]\ttraining's binary_logloss: 0.813679\n",
      "[1107]\ttraining's binary_logloss: 0.813478\n",
      "[1108]\ttraining's binary_logloss: 0.813336\n",
      "[1109]\ttraining's binary_logloss: 0.813171\n",
      "[1110]\ttraining's binary_logloss: 0.813005\n",
      "[1111]\ttraining's binary_logloss: 0.812853\n",
      "[1112]\ttraining's binary_logloss: 0.812696\n",
      "[1113]\ttraining's binary_logloss: 0.812585\n",
      "[1114]\ttraining's binary_logloss: 0.812439\n",
      "[1115]\ttraining's binary_logloss: 0.812287\n",
      "[1116]\ttraining's binary_logloss: 0.81212\n",
      "[1117]\ttraining's binary_logloss: 0.811953\n",
      "[1118]\ttraining's binary_logloss: 0.811779\n",
      "[1119]\ttraining's binary_logloss: 0.811635\n",
      "[1120]\ttraining's binary_logloss: 0.811435\n",
      "[1121]\ttraining's binary_logloss: 0.811316\n",
      "[1122]\ttraining's binary_logloss: 0.811188\n",
      "[1123]\ttraining's binary_logloss: 0.811063\n",
      "[1124]\ttraining's binary_logloss: 0.810865\n",
      "[1125]\ttraining's binary_logloss: 0.81071\n",
      "[1126]\ttraining's binary_logloss: 0.810499\n",
      "[1127]\ttraining's binary_logloss: 0.810326\n",
      "[1128]\ttraining's binary_logloss: 0.810156\n",
      "[1129]\ttraining's binary_logloss: 0.810009\n",
      "[1130]\ttraining's binary_logloss: 0.809833\n",
      "[1131]\ttraining's binary_logloss: 0.809674\n",
      "[1132]\ttraining's binary_logloss: 0.809509\n",
      "[1133]\ttraining's binary_logloss: 0.809366\n",
      "[1134]\ttraining's binary_logloss: 0.809245\n",
      "[1135]\ttraining's binary_logloss: 0.809071\n",
      "[1136]\ttraining's binary_logloss: 0.808938\n",
      "[1137]\ttraining's binary_logloss: 0.808808\n",
      "[1138]\ttraining's binary_logloss: 0.808657\n",
      "[1139]\ttraining's binary_logloss: 0.80849\n",
      "[1140]\ttraining's binary_logloss: 0.808325\n",
      "[1141]\ttraining's binary_logloss: 0.808127\n",
      "[1142]\ttraining's binary_logloss: 0.807958\n",
      "[1143]\ttraining's binary_logloss: 0.807787\n",
      "[1144]\ttraining's binary_logloss: 0.807586\n",
      "[1145]\ttraining's binary_logloss: 0.807417\n",
      "[1146]\ttraining's binary_logloss: 0.807307\n",
      "[1147]\ttraining's binary_logloss: 0.807117\n",
      "[1148]\ttraining's binary_logloss: 0.806959\n",
      "[1149]\ttraining's binary_logloss: 0.806807\n",
      "[1150]\ttraining's binary_logloss: 0.806681\n",
      "[1151]\ttraining's binary_logloss: 0.806552\n",
      "[1152]\ttraining's binary_logloss: 0.806395\n",
      "[1153]\ttraining's binary_logloss: 0.806247\n",
      "[1154]\ttraining's binary_logloss: 0.806088\n",
      "[1155]\ttraining's binary_logloss: 0.8059\n",
      "[1156]\ttraining's binary_logloss: 0.805752\n",
      "[1157]\ttraining's binary_logloss: 0.805606\n",
      "[1158]\ttraining's binary_logloss: 0.805474\n",
      "[1159]\ttraining's binary_logloss: 0.805302\n",
      "[1160]\ttraining's binary_logloss: 0.805145\n",
      "[1161]\ttraining's binary_logloss: 0.805014\n",
      "[1162]\ttraining's binary_logloss: 0.804883\n",
      "[1163]\ttraining's binary_logloss: 0.80468\n",
      "[1164]\ttraining's binary_logloss: 0.804566\n",
      "[1165]\ttraining's binary_logloss: 0.804439\n",
      "[1166]\ttraining's binary_logloss: 0.804304\n",
      "[1167]\ttraining's binary_logloss: 0.804178\n",
      "[1168]\ttraining's binary_logloss: 0.804007\n",
      "[1169]\ttraining's binary_logloss: 0.803861\n",
      "[1170]\ttraining's binary_logloss: 0.803657\n",
      "[1171]\ttraining's binary_logloss: 0.803524\n",
      "[1172]\ttraining's binary_logloss: 0.8034\n",
      "[1173]\ttraining's binary_logloss: 0.803245\n",
      "[1174]\ttraining's binary_logloss: 0.803098\n",
      "[1175]\ttraining's binary_logloss: 0.802978\n",
      "[1176]\ttraining's binary_logloss: 0.802831\n",
      "[1177]\ttraining's binary_logloss: 0.802681\n",
      "[1178]\ttraining's binary_logloss: 0.802551\n",
      "[1179]\ttraining's binary_logloss: 0.802385\n",
      "[1180]\ttraining's binary_logloss: 0.802206\n",
      "[1181]\ttraining's binary_logloss: 0.802024\n",
      "[1182]\ttraining's binary_logloss: 0.801875\n",
      "[1183]\ttraining's binary_logloss: 0.801721\n",
      "[1184]\ttraining's binary_logloss: 0.801559\n",
      "[1185]\ttraining's binary_logloss: 0.801444\n",
      "[1186]\ttraining's binary_logloss: 0.801272\n",
      "[1187]\ttraining's binary_logloss: 0.801106\n",
      "[1188]\ttraining's binary_logloss: 0.800975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1189]\ttraining's binary_logloss: 0.800822\n",
      "[1190]\ttraining's binary_logloss: 0.800717\n",
      "[1191]\ttraining's binary_logloss: 0.800588\n",
      "[1192]\ttraining's binary_logloss: 0.800416\n",
      "[1193]\ttraining's binary_logloss: 0.80029\n",
      "[1194]\ttraining's binary_logloss: 0.800132\n",
      "[1195]\ttraining's binary_logloss: 0.799963\n",
      "[1196]\ttraining's binary_logloss: 0.799782\n",
      "[1197]\ttraining's binary_logloss: 0.799541\n",
      "[1198]\ttraining's binary_logloss: 0.799437\n",
      "[1199]\ttraining's binary_logloss: 0.79932\n",
      "[1200]\ttraining's binary_logloss: 0.799221\n",
      "[1201]\ttraining's binary_logloss: 0.799052\n",
      "[1202]\ttraining's binary_logloss: 0.798904\n",
      "[1203]\ttraining's binary_logloss: 0.798785\n",
      "[1204]\ttraining's binary_logloss: 0.798616\n",
      "[1205]\ttraining's binary_logloss: 0.798454\n",
      "[1206]\ttraining's binary_logloss: 0.798297\n",
      "[1207]\ttraining's binary_logloss: 0.798145\n",
      "[1208]\ttraining's binary_logloss: 0.79802\n",
      "[1209]\ttraining's binary_logloss: 0.797857\n",
      "[1210]\ttraining's binary_logloss: 0.79773\n",
      "[1211]\ttraining's binary_logloss: 0.797573\n",
      "[1212]\ttraining's binary_logloss: 0.797424\n",
      "[1213]\ttraining's binary_logloss: 0.7973\n",
      "[1214]\ttraining's binary_logloss: 0.797128\n",
      "[1215]\ttraining's binary_logloss: 0.796963\n",
      "[1216]\ttraining's binary_logloss: 0.796851\n",
      "[1217]\ttraining's binary_logloss: 0.796702\n",
      "[1218]\ttraining's binary_logloss: 0.796597\n",
      "[1219]\ttraining's binary_logloss: 0.796393\n",
      "[1220]\ttraining's binary_logloss: 0.796246\n",
      "[1221]\ttraining's binary_logloss: 0.796065\n",
      "[1222]\ttraining's binary_logloss: 0.795883\n",
      "[1223]\ttraining's binary_logloss: 0.795736\n",
      "[1224]\ttraining's binary_logloss: 0.795615\n",
      "[1225]\ttraining's binary_logloss: 0.795469\n",
      "[1226]\ttraining's binary_logloss: 0.795321\n",
      "[1227]\ttraining's binary_logloss: 0.795193\n",
      "[1228]\ttraining's binary_logloss: 0.795028\n",
      "[1229]\ttraining's binary_logloss: 0.794864\n",
      "[1230]\ttraining's binary_logloss: 0.794747\n",
      "[1231]\ttraining's binary_logloss: 0.794626\n",
      "[1232]\ttraining's binary_logloss: 0.794516\n",
      "[1233]\ttraining's binary_logloss: 0.794365\n",
      "[1234]\ttraining's binary_logloss: 0.794215\n",
      "[1235]\ttraining's binary_logloss: 0.794031\n",
      "[1236]\ttraining's binary_logloss: 0.793855\n",
      "[1237]\ttraining's binary_logloss: 0.793757\n",
      "[1238]\ttraining's binary_logloss: 0.793619\n",
      "[1239]\ttraining's binary_logloss: 0.793449\n",
      "[1240]\ttraining's binary_logloss: 0.793316\n",
      "[1241]\ttraining's binary_logloss: 0.793177\n",
      "[1242]\ttraining's binary_logloss: 0.793063\n",
      "[1243]\ttraining's binary_logloss: 0.792919\n",
      "[1244]\ttraining's binary_logloss: 0.792774\n",
      "[1245]\ttraining's binary_logloss: 0.792617\n",
      "[1246]\ttraining's binary_logloss: 0.792464\n",
      "[1247]\ttraining's binary_logloss: 0.792311\n",
      "[1248]\ttraining's binary_logloss: 0.792153\n",
      "[1249]\ttraining's binary_logloss: 0.792043\n",
      "[1250]\ttraining's binary_logloss: 0.791894\n",
      "[1251]\ttraining's binary_logloss: 0.791786\n",
      "[1252]\ttraining's binary_logloss: 0.791635\n",
      "[1253]\ttraining's binary_logloss: 0.791468\n",
      "[1254]\ttraining's binary_logloss: 0.791307\n",
      "[1255]\ttraining's binary_logloss: 0.791142\n",
      "[1256]\ttraining's binary_logloss: 0.790966\n",
      "[1257]\ttraining's binary_logloss: 0.790776\n",
      "[1258]\ttraining's binary_logloss: 0.790637\n",
      "[1259]\ttraining's binary_logloss: 0.790474\n",
      "[1260]\ttraining's binary_logloss: 0.790307\n",
      "[1261]\ttraining's binary_logloss: 0.790156\n",
      "[1262]\ttraining's binary_logloss: 0.789998\n",
      "[1263]\ttraining's binary_logloss: 0.789885\n",
      "[1264]\ttraining's binary_logloss: 0.78971\n",
      "[1265]\ttraining's binary_logloss: 0.789595\n",
      "[1266]\ttraining's binary_logloss: 0.789451\n",
      "[1267]\ttraining's binary_logloss: 0.789322\n",
      "[1268]\ttraining's binary_logloss: 0.789212\n",
      "[1269]\ttraining's binary_logloss: 0.789106\n",
      "[1270]\ttraining's binary_logloss: 0.788966\n",
      "[1271]\ttraining's binary_logloss: 0.788846\n",
      "[1272]\ttraining's binary_logloss: 0.788691\n",
      "[1273]\ttraining's binary_logloss: 0.788562\n",
      "[1274]\ttraining's binary_logloss: 0.788439\n",
      "[1275]\ttraining's binary_logloss: 0.788302\n",
      "[1276]\ttraining's binary_logloss: 0.78814\n",
      "[1277]\ttraining's binary_logloss: 0.787997\n",
      "[1278]\ttraining's binary_logloss: 0.787854\n",
      "[1279]\ttraining's binary_logloss: 0.78774\n",
      "[1280]\ttraining's binary_logloss: 0.787551\n",
      "[1281]\ttraining's binary_logloss: 0.787422\n",
      "[1282]\ttraining's binary_logloss: 0.787236\n",
      "[1283]\ttraining's binary_logloss: 0.787101\n",
      "[1284]\ttraining's binary_logloss: 0.786935\n",
      "[1285]\ttraining's binary_logloss: 0.7868\n",
      "[1286]\ttraining's binary_logloss: 0.786648\n",
      "[1287]\ttraining's binary_logloss: 0.786505\n",
      "[1288]\ttraining's binary_logloss: 0.786328\n",
      "[1289]\ttraining's binary_logloss: 0.78617\n",
      "[1290]\ttraining's binary_logloss: 0.786041\n",
      "[1291]\ttraining's binary_logloss: 0.7859\n",
      "[1292]\ttraining's binary_logloss: 0.78573\n",
      "[1293]\ttraining's binary_logloss: 0.785626\n",
      "[1294]\ttraining's binary_logloss: 0.78548\n",
      "[1295]\ttraining's binary_logloss: 0.78538\n",
      "[1296]\ttraining's binary_logloss: 0.785278\n",
      "[1297]\ttraining's binary_logloss: 0.785135\n",
      "[1298]\ttraining's binary_logloss: 0.784996\n",
      "[1299]\ttraining's binary_logloss: 0.78482\n",
      "[1300]\ttraining's binary_logloss: 0.784708\n",
      "[1301]\ttraining's binary_logloss: 0.784602\n",
      "[1302]\ttraining's binary_logloss: 0.784434\n",
      "[1303]\ttraining's binary_logloss: 0.784311\n",
      "[1304]\ttraining's binary_logloss: 0.784184\n",
      "[1305]\ttraining's binary_logloss: 0.784065\n",
      "[1306]\ttraining's binary_logloss: 0.783913\n",
      "[1307]\ttraining's binary_logloss: 0.783794\n",
      "[1308]\ttraining's binary_logloss: 0.783653\n",
      "[1309]\ttraining's binary_logloss: 0.783465\n",
      "[1310]\ttraining's binary_logloss: 0.783356\n",
      "[1311]\ttraining's binary_logloss: 0.783174\n",
      "[1312]\ttraining's binary_logloss: 0.782998\n",
      "[1313]\ttraining's binary_logloss: 0.782863\n",
      "[1314]\ttraining's binary_logloss: 0.78274\n",
      "[1315]\ttraining's binary_logloss: 0.782591\n",
      "[1316]\ttraining's binary_logloss: 0.782472\n",
      "[1317]\ttraining's binary_logloss: 0.782314\n",
      "[1318]\ttraining's binary_logloss: 0.782201\n",
      "[1319]\ttraining's binary_logloss: 0.78203\n",
      "[1320]\ttraining's binary_logloss: 0.781888\n",
      "[1321]\ttraining's binary_logloss: 0.781766\n",
      "[1322]\ttraining's binary_logloss: 0.781599\n",
      "[1323]\ttraining's binary_logloss: 0.781468\n",
      "[1324]\ttraining's binary_logloss: 0.781354\n",
      "[1325]\ttraining's binary_logloss: 0.781233\n",
      "[1326]\ttraining's binary_logloss: 0.781073\n",
      "[1327]\ttraining's binary_logloss: 0.780856\n",
      "[1328]\ttraining's binary_logloss: 0.780691\n",
      "[1329]\ttraining's binary_logloss: 0.780537\n",
      "[1330]\ttraining's binary_logloss: 0.78039\n",
      "[1331]\ttraining's binary_logloss: 0.780264\n",
      "[1332]\ttraining's binary_logloss: 0.780089\n",
      "[1333]\ttraining's binary_logloss: 0.779976\n",
      "[1334]\ttraining's binary_logloss: 0.779865\n",
      "[1335]\ttraining's binary_logloss: 0.779716\n",
      "[1336]\ttraining's binary_logloss: 0.779586\n",
      "[1337]\ttraining's binary_logloss: 0.779432\n",
      "[1338]\ttraining's binary_logloss: 0.779275\n",
      "[1339]\ttraining's binary_logloss: 0.779167\n",
      "[1340]\ttraining's binary_logloss: 0.779024\n",
      "[1341]\ttraining's binary_logloss: 0.77889\n",
      "[1342]\ttraining's binary_logloss: 0.778729\n",
      "[1343]\ttraining's binary_logloss: 0.778587\n",
      "[1344]\ttraining's binary_logloss: 0.778406\n",
      "[1345]\ttraining's binary_logloss: 0.778256\n",
      "[1346]\ttraining's binary_logloss: 0.778133\n",
      "[1347]\ttraining's binary_logloss: 0.778013\n",
      "[1348]\ttraining's binary_logloss: 0.777846\n",
      "[1349]\ttraining's binary_logloss: 0.777704\n",
      "[1350]\ttraining's binary_logloss: 0.777583\n",
      "[1351]\ttraining's binary_logloss: 0.777427\n",
      "[1352]\ttraining's binary_logloss: 0.777281\n",
      "[1353]\ttraining's binary_logloss: 0.777178\n",
      "[1354]\ttraining's binary_logloss: 0.777054\n",
      "[1355]\ttraining's binary_logloss: 0.776915\n",
      "[1356]\ttraining's binary_logloss: 0.776779\n",
      "[1357]\ttraining's binary_logloss: 0.77664\n",
      "[1358]\ttraining's binary_logloss: 0.776488\n",
      "[1359]\ttraining's binary_logloss: 0.776361\n",
      "[1360]\ttraining's binary_logloss: 0.776241\n",
      "[1361]\ttraining's binary_logloss: 0.776102\n",
      "[1362]\ttraining's binary_logloss: 0.775946\n",
      "[1363]\ttraining's binary_logloss: 0.775799\n",
      "[1364]\ttraining's binary_logloss: 0.775678\n",
      "[1365]\ttraining's binary_logloss: 0.775502\n",
      "[1366]\ttraining's binary_logloss: 0.7754\n",
      "[1367]\ttraining's binary_logloss: 0.775258\n",
      "[1368]\ttraining's binary_logloss: 0.775157\n",
      "[1369]\ttraining's binary_logloss: 0.775024\n",
      "[1370]\ttraining's binary_logloss: 0.774861\n",
      "[1371]\ttraining's binary_logloss: 0.774718\n",
      "[1372]\ttraining's binary_logloss: 0.774603\n",
      "[1373]\ttraining's binary_logloss: 0.774478\n",
      "[1374]\ttraining's binary_logloss: 0.774338\n",
      "[1375]\ttraining's binary_logloss: 0.774195\n",
      "[1376]\ttraining's binary_logloss: 0.774081\n",
      "[1377]\ttraining's binary_logloss: 0.773969\n",
      "[1378]\ttraining's binary_logloss: 0.773809\n",
      "[1379]\ttraining's binary_logloss: 0.773709\n",
      "[1380]\ttraining's binary_logloss: 0.773605\n",
      "[1381]\ttraining's binary_logloss: 0.773458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1382]\ttraining's binary_logloss: 0.773333\n",
      "[1383]\ttraining's binary_logloss: 0.773164\n",
      "[1384]\ttraining's binary_logloss: 0.773037\n",
      "[1385]\ttraining's binary_logloss: 0.77291\n",
      "[1386]\ttraining's binary_logloss: 0.772794\n",
      "[1387]\ttraining's binary_logloss: 0.772659\n",
      "[1388]\ttraining's binary_logloss: 0.772489\n",
      "[1389]\ttraining's binary_logloss: 0.772372\n",
      "[1390]\ttraining's binary_logloss: 0.772236\n",
      "[1391]\ttraining's binary_logloss: 0.772111\n",
      "[1392]\ttraining's binary_logloss: 0.771958\n",
      "[1393]\ttraining's binary_logloss: 0.771817\n",
      "[1394]\ttraining's binary_logloss: 0.771695\n",
      "[1395]\ttraining's binary_logloss: 0.771547\n",
      "[1396]\ttraining's binary_logloss: 0.771413\n",
      "[1397]\ttraining's binary_logloss: 0.771265\n",
      "[1398]\ttraining's binary_logloss: 0.771139\n",
      "[1399]\ttraining's binary_logloss: 0.770991\n",
      "[1400]\ttraining's binary_logloss: 0.770842\n",
      "[1401]\ttraining's binary_logloss: 0.770694\n",
      "[1402]\ttraining's binary_logloss: 0.770545\n",
      "[1403]\ttraining's binary_logloss: 0.770449\n",
      "[1404]\ttraining's binary_logloss: 0.770327\n",
      "[1405]\ttraining's binary_logloss: 0.770226\n",
      "[1406]\ttraining's binary_logloss: 0.770122\n",
      "[1407]\ttraining's binary_logloss: 0.770009\n",
      "[1408]\ttraining's binary_logloss: 0.769877\n",
      "[1409]\ttraining's binary_logloss: 0.769709\n",
      "[1410]\ttraining's binary_logloss: 0.769565\n",
      "[1411]\ttraining's binary_logloss: 0.769475\n",
      "[1412]\ttraining's binary_logloss: 0.76932\n",
      "[1413]\ttraining's binary_logloss: 0.769219\n",
      "[1414]\ttraining's binary_logloss: 0.769012\n",
      "[1415]\ttraining's binary_logloss: 0.76888\n",
      "[1416]\ttraining's binary_logloss: 0.768767\n",
      "[1417]\ttraining's binary_logloss: 0.768645\n",
      "[1418]\ttraining's binary_logloss: 0.768519\n",
      "[1419]\ttraining's binary_logloss: 0.7684\n",
      "[1420]\ttraining's binary_logloss: 0.768298\n",
      "[1421]\ttraining's binary_logloss: 0.76817\n",
      "[1422]\ttraining's binary_logloss: 0.768\n",
      "[1423]\ttraining's binary_logloss: 0.76787\n",
      "[1424]\ttraining's binary_logloss: 0.767702\n",
      "[1425]\ttraining's binary_logloss: 0.767572\n",
      "[1426]\ttraining's binary_logloss: 0.767455\n",
      "[1427]\ttraining's binary_logloss: 0.767296\n",
      "[1428]\ttraining's binary_logloss: 0.767149\n",
      "[1429]\ttraining's binary_logloss: 0.766992\n",
      "[1430]\ttraining's binary_logloss: 0.766863\n",
      "[1431]\ttraining's binary_logloss: 0.766748\n",
      "[1432]\ttraining's binary_logloss: 0.766567\n",
      "[1433]\ttraining's binary_logloss: 0.766407\n",
      "[1434]\ttraining's binary_logloss: 0.766276\n",
      "[1435]\ttraining's binary_logloss: 0.766115\n",
      "[1436]\ttraining's binary_logloss: 0.766009\n",
      "[1437]\ttraining's binary_logloss: 0.765888\n",
      "[1438]\ttraining's binary_logloss: 0.76573\n",
      "[1439]\ttraining's binary_logloss: 0.765565\n",
      "[1440]\ttraining's binary_logloss: 0.765427\n",
      "[1441]\ttraining's binary_logloss: 0.765328\n",
      "[1442]\ttraining's binary_logloss: 0.765232\n",
      "[1443]\ttraining's binary_logloss: 0.765118\n",
      "[1444]\ttraining's binary_logloss: 0.764982\n",
      "[1445]\ttraining's binary_logloss: 0.764837\n",
      "[1446]\ttraining's binary_logloss: 0.764678\n",
      "[1447]\ttraining's binary_logloss: 0.764561\n",
      "[1448]\ttraining's binary_logloss: 0.76444\n",
      "[1449]\ttraining's binary_logloss: 0.764288\n",
      "[1450]\ttraining's binary_logloss: 0.76415\n",
      "[1451]\ttraining's binary_logloss: 0.764021\n",
      "[1452]\ttraining's binary_logloss: 0.763928\n",
      "[1453]\ttraining's binary_logloss: 0.763785\n",
      "[1454]\ttraining's binary_logloss: 0.763683\n",
      "[1455]\ttraining's binary_logloss: 0.763583\n",
      "[1456]\ttraining's binary_logloss: 0.763427\n",
      "[1457]\ttraining's binary_logloss: 0.763316\n",
      "[1458]\ttraining's binary_logloss: 0.763181\n",
      "[1459]\ttraining's binary_logloss: 0.763017\n",
      "[1460]\ttraining's binary_logloss: 0.762875\n",
      "[1461]\ttraining's binary_logloss: 0.762755\n",
      "[1462]\ttraining's binary_logloss: 0.762641\n",
      "[1463]\ttraining's binary_logloss: 0.762501\n",
      "[1464]\ttraining's binary_logloss: 0.762368\n",
      "[1465]\ttraining's binary_logloss: 0.762251\n",
      "[1466]\ttraining's binary_logloss: 0.762119\n",
      "[1467]\ttraining's binary_logloss: 0.761986\n",
      "[1468]\ttraining's binary_logloss: 0.76189\n",
      "[1469]\ttraining's binary_logloss: 0.761767\n",
      "[1470]\ttraining's binary_logloss: 0.761641\n",
      "[1471]\ttraining's binary_logloss: 0.761448\n",
      "[1472]\ttraining's binary_logloss: 0.761294\n",
      "[1473]\ttraining's binary_logloss: 0.761141\n",
      "[1474]\ttraining's binary_logloss: 0.760984\n",
      "[1475]\ttraining's binary_logloss: 0.760884\n",
      "[1476]\ttraining's binary_logloss: 0.76079\n",
      "[1477]\ttraining's binary_logloss: 0.760672\n",
      "[1478]\ttraining's binary_logloss: 0.760573\n",
      "[1479]\ttraining's binary_logloss: 0.760451\n",
      "[1480]\ttraining's binary_logloss: 0.760347\n",
      "[1481]\ttraining's binary_logloss: 0.760227\n",
      "[1482]\ttraining's binary_logloss: 0.760066\n",
      "[1483]\ttraining's binary_logloss: 0.759929\n",
      "[1484]\ttraining's binary_logloss: 0.7598\n",
      "[1485]\ttraining's binary_logloss: 0.759704\n",
      "[1486]\ttraining's binary_logloss: 0.759553\n",
      "[1487]\ttraining's binary_logloss: 0.759398\n",
      "[1488]\ttraining's binary_logloss: 0.759277\n",
      "[1489]\ttraining's binary_logloss: 0.759175\n",
      "[1490]\ttraining's binary_logloss: 0.759035\n",
      "[1491]\ttraining's binary_logloss: 0.758924\n",
      "[1492]\ttraining's binary_logloss: 0.75878\n",
      "[1493]\ttraining's binary_logloss: 0.758623\n",
      "[1494]\ttraining's binary_logloss: 0.758453\n",
      "[1495]\ttraining's binary_logloss: 0.758355\n",
      "[1496]\ttraining's binary_logloss: 0.758223\n",
      "[1497]\ttraining's binary_logloss: 0.758113\n",
      "[1498]\ttraining's binary_logloss: 0.757938\n",
      "[1499]\ttraining's binary_logloss: 0.757846\n",
      "[1500]\ttraining's binary_logloss: 0.757713\n",
      "[1501]\ttraining's binary_logloss: 0.757609\n",
      "[1502]\ttraining's binary_logloss: 0.757519\n",
      "[1503]\ttraining's binary_logloss: 0.757378\n",
      "[1504]\ttraining's binary_logloss: 0.757209\n",
      "[1505]\ttraining's binary_logloss: 0.757057\n",
      "[1506]\ttraining's binary_logloss: 0.75695\n",
      "[1507]\ttraining's binary_logloss: 0.756846\n",
      "[1508]\ttraining's binary_logloss: 0.756719\n",
      "[1509]\ttraining's binary_logloss: 0.756555\n",
      "[1510]\ttraining's binary_logloss: 0.756411\n",
      "[1511]\ttraining's binary_logloss: 0.756277\n",
      "[1512]\ttraining's binary_logloss: 0.756142\n",
      "[1513]\ttraining's binary_logloss: 0.755998\n",
      "[1514]\ttraining's binary_logloss: 0.755856\n",
      "[1515]\ttraining's binary_logloss: 0.755694\n",
      "[1516]\ttraining's binary_logloss: 0.75551\n",
      "[1517]\ttraining's binary_logloss: 0.755394\n",
      "[1518]\ttraining's binary_logloss: 0.755252\n",
      "[1519]\ttraining's binary_logloss: 0.755107\n",
      "[1520]\ttraining's binary_logloss: 0.755022\n",
      "[1521]\ttraining's binary_logloss: 0.754909\n",
      "[1522]\ttraining's binary_logloss: 0.754748\n",
      "[1523]\ttraining's binary_logloss: 0.754646\n",
      "[1524]\ttraining's binary_logloss: 0.754515\n",
      "[1525]\ttraining's binary_logloss: 0.754385\n",
      "[1526]\ttraining's binary_logloss: 0.754225\n",
      "[1527]\ttraining's binary_logloss: 0.754109\n",
      "[1528]\ttraining's binary_logloss: 0.753995\n",
      "[1529]\ttraining's binary_logloss: 0.753904\n",
      "[1530]\ttraining's binary_logloss: 0.753785\n",
      "[1531]\ttraining's binary_logloss: 0.753652\n",
      "[1532]\ttraining's binary_logloss: 0.753517\n",
      "[1533]\ttraining's binary_logloss: 0.753412\n",
      "[1534]\ttraining's binary_logloss: 0.753322\n",
      "[1535]\ttraining's binary_logloss: 0.753173\n",
      "[1536]\ttraining's binary_logloss: 0.75304\n",
      "[1537]\ttraining's binary_logloss: 0.752935\n",
      "[1538]\ttraining's binary_logloss: 0.752812\n",
      "[1539]\ttraining's binary_logloss: 0.75266\n",
      "[1540]\ttraining's binary_logloss: 0.752556\n",
      "[1541]\ttraining's binary_logloss: 0.752412\n",
      "[1542]\ttraining's binary_logloss: 0.752309\n",
      "[1543]\ttraining's binary_logloss: 0.752161\n",
      "[1544]\ttraining's binary_logloss: 0.752045\n",
      "[1545]\ttraining's binary_logloss: 0.751873\n",
      "[1546]\ttraining's binary_logloss: 0.751727\n",
      "[1547]\ttraining's binary_logloss: 0.751633\n",
      "[1548]\ttraining's binary_logloss: 0.751474\n",
      "[1549]\ttraining's binary_logloss: 0.751353\n",
      "[1550]\ttraining's binary_logloss: 0.751216\n",
      "[1551]\ttraining's binary_logloss: 0.751107\n",
      "[1552]\ttraining's binary_logloss: 0.750981\n",
      "[1553]\ttraining's binary_logloss: 0.750861\n",
      "[1554]\ttraining's binary_logloss: 0.750766\n",
      "[1555]\ttraining's binary_logloss: 0.750642\n",
      "[1556]\ttraining's binary_logloss: 0.750544\n",
      "[1557]\ttraining's binary_logloss: 0.750395\n",
      "[1558]\ttraining's binary_logloss: 0.750199\n",
      "[1559]\ttraining's binary_logloss: 0.750086\n",
      "[1560]\ttraining's binary_logloss: 0.749964\n",
      "[1561]\ttraining's binary_logloss: 0.749841\n",
      "[1562]\ttraining's binary_logloss: 0.749724\n",
      "[1563]\ttraining's binary_logloss: 0.749609\n",
      "[1564]\ttraining's binary_logloss: 0.749456\n",
      "[1565]\ttraining's binary_logloss: 0.749327\n",
      "[1566]\ttraining's binary_logloss: 0.749201\n",
      "[1567]\ttraining's binary_logloss: 0.749071\n",
      "[1568]\ttraining's binary_logloss: 0.748967\n",
      "[1569]\ttraining's binary_logloss: 0.748866\n",
      "[1570]\ttraining's binary_logloss: 0.748736\n",
      "[1571]\ttraining's binary_logloss: 0.748652\n",
      "[1572]\ttraining's binary_logloss: 0.748498\n",
      "[1573]\ttraining's binary_logloss: 0.748374\n",
      "[1574]\ttraining's binary_logloss: 0.748278\n",
      "[1575]\ttraining's binary_logloss: 0.748135\n",
      "[1576]\ttraining's binary_logloss: 0.747978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1577]\ttraining's binary_logloss: 0.747871\n",
      "[1578]\ttraining's binary_logloss: 0.747778\n",
      "[1579]\ttraining's binary_logloss: 0.747665\n",
      "[1580]\ttraining's binary_logloss: 0.747554\n",
      "[1581]\ttraining's binary_logloss: 0.747447\n",
      "[1582]\ttraining's binary_logloss: 0.747325\n",
      "[1583]\ttraining's binary_logloss: 0.747228\n",
      "[1584]\ttraining's binary_logloss: 0.747109\n",
      "[1585]\ttraining's binary_logloss: 0.746962\n",
      "[1586]\ttraining's binary_logloss: 0.746847\n",
      "[1587]\ttraining's binary_logloss: 0.746688\n",
      "[1588]\ttraining's binary_logloss: 0.746571\n",
      "[1589]\ttraining's binary_logloss: 0.746467\n",
      "[1590]\ttraining's binary_logloss: 0.746326\n",
      "[1591]\ttraining's binary_logloss: 0.746145\n",
      "[1592]\ttraining's binary_logloss: 0.746008\n",
      "[1593]\ttraining's binary_logloss: 0.74589\n",
      "[1594]\ttraining's binary_logloss: 0.745802\n",
      "[1595]\ttraining's binary_logloss: 0.745658\n",
      "[1596]\ttraining's binary_logloss: 0.745482\n",
      "[1597]\ttraining's binary_logloss: 0.745391\n",
      "[1598]\ttraining's binary_logloss: 0.745246\n",
      "[1599]\ttraining's binary_logloss: 0.74514\n",
      "[1600]\ttraining's binary_logloss: 0.744985\n",
      "[1601]\ttraining's binary_logloss: 0.744885\n",
      "[1602]\ttraining's binary_logloss: 0.744763\n",
      "[1603]\ttraining's binary_logloss: 0.744657\n",
      "[1604]\ttraining's binary_logloss: 0.744547\n",
      "[1605]\ttraining's binary_logloss: 0.744429\n",
      "[1606]\ttraining's binary_logloss: 0.744262\n",
      "[1607]\ttraining's binary_logloss: 0.744152\n",
      "[1608]\ttraining's binary_logloss: 0.744013\n",
      "[1609]\ttraining's binary_logloss: 0.743886\n",
      "[1610]\ttraining's binary_logloss: 0.743749\n",
      "[1611]\ttraining's binary_logloss: 0.74367\n",
      "[1612]\ttraining's binary_logloss: 0.743555\n",
      "[1613]\ttraining's binary_logloss: 0.74345\n",
      "[1614]\ttraining's binary_logloss: 0.743337\n",
      "[1615]\ttraining's binary_logloss: 0.743238\n",
      "[1616]\ttraining's binary_logloss: 0.743094\n",
      "[1617]\ttraining's binary_logloss: 0.742931\n",
      "[1618]\ttraining's binary_logloss: 0.742784\n",
      "[1619]\ttraining's binary_logloss: 0.742655\n",
      "[1620]\ttraining's binary_logloss: 0.742527\n",
      "[1621]\ttraining's binary_logloss: 0.742411\n",
      "[1622]\ttraining's binary_logloss: 0.742303\n",
      "[1623]\ttraining's binary_logloss: 0.742147\n",
      "[1624]\ttraining's binary_logloss: 0.742017\n",
      "[1625]\ttraining's binary_logloss: 0.741908\n",
      "[1626]\ttraining's binary_logloss: 0.741764\n",
      "[1627]\ttraining's binary_logloss: 0.741668\n",
      "[1628]\ttraining's binary_logloss: 0.74154\n",
      "[1629]\ttraining's binary_logloss: 0.741441\n",
      "[1630]\ttraining's binary_logloss: 0.741295\n",
      "[1631]\ttraining's binary_logloss: 0.741181\n",
      "[1632]\ttraining's binary_logloss: 0.741043\n",
      "[1633]\ttraining's binary_logloss: 0.740916\n",
      "[1634]\ttraining's binary_logloss: 0.740789\n",
      "[1635]\ttraining's binary_logloss: 0.740687\n",
      "[1636]\ttraining's binary_logloss: 0.740552\n",
      "[1637]\ttraining's binary_logloss: 0.740443\n",
      "[1638]\ttraining's binary_logloss: 0.740287\n",
      "[1639]\ttraining's binary_logloss: 0.740168\n",
      "[1640]\ttraining's binary_logloss: 0.74007\n",
      "[1641]\ttraining's binary_logloss: 0.739984\n",
      "[1642]\ttraining's binary_logloss: 0.739851\n",
      "[1643]\ttraining's binary_logloss: 0.739707\n",
      "[1644]\ttraining's binary_logloss: 0.739588\n",
      "[1645]\ttraining's binary_logloss: 0.739468\n",
      "[1646]\ttraining's binary_logloss: 0.73935\n",
      "[1647]\ttraining's binary_logloss: 0.739215\n",
      "[1648]\ttraining's binary_logloss: 0.739135\n",
      "[1649]\ttraining's binary_logloss: 0.738991\n",
      "[1650]\ttraining's binary_logloss: 0.738831\n",
      "[1651]\ttraining's binary_logloss: 0.738713\n",
      "[1652]\ttraining's binary_logloss: 0.73862\n",
      "[1653]\ttraining's binary_logloss: 0.738468\n",
      "[1654]\ttraining's binary_logloss: 0.738313\n",
      "[1655]\ttraining's binary_logloss: 0.738198\n",
      "[1656]\ttraining's binary_logloss: 0.738078\n",
      "[1657]\ttraining's binary_logloss: 0.737936\n",
      "[1658]\ttraining's binary_logloss: 0.73783\n",
      "[1659]\ttraining's binary_logloss: 0.737721\n",
      "[1660]\ttraining's binary_logloss: 0.737597\n",
      "[1661]\ttraining's binary_logloss: 0.737459\n",
      "[1662]\ttraining's binary_logloss: 0.737347\n",
      "[1663]\ttraining's binary_logloss: 0.737217\n",
      "[1664]\ttraining's binary_logloss: 0.73714\n",
      "[1665]\ttraining's binary_logloss: 0.736997\n",
      "[1666]\ttraining's binary_logloss: 0.736865\n",
      "[1667]\ttraining's binary_logloss: 0.736746\n",
      "[1668]\ttraining's binary_logloss: 0.736626\n",
      "[1669]\ttraining's binary_logloss: 0.736516\n",
      "[1670]\ttraining's binary_logloss: 0.736397\n",
      "[1671]\ttraining's binary_logloss: 0.736258\n",
      "[1672]\ttraining's binary_logloss: 0.736071\n",
      "[1673]\ttraining's binary_logloss: 0.73592\n",
      "[1674]\ttraining's binary_logloss: 0.73581\n",
      "[1675]\ttraining's binary_logloss: 0.735689\n",
      "[1676]\ttraining's binary_logloss: 0.735551\n",
      "[1677]\ttraining's binary_logloss: 0.73546\n",
      "[1678]\ttraining's binary_logloss: 0.735354\n",
      "[1679]\ttraining's binary_logloss: 0.735255\n",
      "[1680]\ttraining's binary_logloss: 0.735102\n",
      "[1681]\ttraining's binary_logloss: 0.735011\n",
      "[1682]\ttraining's binary_logloss: 0.734916\n",
      "[1683]\ttraining's binary_logloss: 0.734777\n",
      "[1684]\ttraining's binary_logloss: 0.73467\n",
      "[1685]\ttraining's binary_logloss: 0.73457\n",
      "[1686]\ttraining's binary_logloss: 0.734473\n",
      "[1687]\ttraining's binary_logloss: 0.734351\n",
      "[1688]\ttraining's binary_logloss: 0.734239\n",
      "[1689]\ttraining's binary_logloss: 0.73406\n",
      "[1690]\ttraining's binary_logloss: 0.733938\n",
      "[1691]\ttraining's binary_logloss: 0.733854\n",
      "[1692]\ttraining's binary_logloss: 0.733665\n",
      "[1693]\ttraining's binary_logloss: 0.733522\n",
      "[1694]\ttraining's binary_logloss: 0.73339\n",
      "[1695]\ttraining's binary_logloss: 0.733306\n",
      "[1696]\ttraining's binary_logloss: 0.733169\n",
      "[1697]\ttraining's binary_logloss: 0.733061\n",
      "[1698]\ttraining's binary_logloss: 0.732943\n",
      "[1699]\ttraining's binary_logloss: 0.732761\n",
      "[1700]\ttraining's binary_logloss: 0.732638\n",
      "[1701]\ttraining's binary_logloss: 0.732523\n",
      "[1702]\ttraining's binary_logloss: 0.732431\n",
      "[1703]\ttraining's binary_logloss: 0.732252\n",
      "[1704]\ttraining's binary_logloss: 0.732071\n",
      "[1705]\ttraining's binary_logloss: 0.731959\n",
      "[1706]\ttraining's binary_logloss: 0.731831\n",
      "[1707]\ttraining's binary_logloss: 0.731705\n",
      "[1708]\ttraining's binary_logloss: 0.731565\n",
      "[1709]\ttraining's binary_logloss: 0.73144\n",
      "[1710]\ttraining's binary_logloss: 0.73129\n",
      "[1711]\ttraining's binary_logloss: 0.731214\n",
      "[1712]\ttraining's binary_logloss: 0.731113\n",
      "[1713]\ttraining's binary_logloss: 0.731013\n",
      "[1714]\ttraining's binary_logloss: 0.730883\n",
      "[1715]\ttraining's binary_logloss: 0.730756\n",
      "[1716]\ttraining's binary_logloss: 0.730572\n",
      "[1717]\ttraining's binary_logloss: 0.730453\n",
      "[1718]\ttraining's binary_logloss: 0.730331\n",
      "[1719]\ttraining's binary_logloss: 0.730198\n",
      "[1720]\ttraining's binary_logloss: 0.730108\n",
      "[1721]\ttraining's binary_logloss: 0.729972\n",
      "[1722]\ttraining's binary_logloss: 0.729838\n",
      "[1723]\ttraining's binary_logloss: 0.729743\n",
      "[1724]\ttraining's binary_logloss: 0.729652\n",
      "[1725]\ttraining's binary_logloss: 0.729561\n",
      "[1726]\ttraining's binary_logloss: 0.729413\n",
      "[1727]\ttraining's binary_logloss: 0.729327\n",
      "[1728]\ttraining's binary_logloss: 0.729191\n",
      "[1729]\ttraining's binary_logloss: 0.729081\n",
      "[1730]\ttraining's binary_logloss: 0.728966\n",
      "[1731]\ttraining's binary_logloss: 0.728878\n",
      "[1732]\ttraining's binary_logloss: 0.728748\n",
      "[1733]\ttraining's binary_logloss: 0.728619\n",
      "[1734]\ttraining's binary_logloss: 0.728496\n",
      "[1735]\ttraining's binary_logloss: 0.728369\n",
      "[1736]\ttraining's binary_logloss: 0.728265\n",
      "[1737]\ttraining's binary_logloss: 0.728142\n",
      "[1738]\ttraining's binary_logloss: 0.727995\n",
      "[1739]\ttraining's binary_logloss: 0.727876\n",
      "[1740]\ttraining's binary_logloss: 0.727769\n",
      "[1741]\ttraining's binary_logloss: 0.72766\n",
      "[1742]\ttraining's binary_logloss: 0.727526\n",
      "[1743]\ttraining's binary_logloss: 0.727425\n",
      "[1744]\ttraining's binary_logloss: 0.727337\n",
      "[1745]\ttraining's binary_logloss: 0.727215\n",
      "[1746]\ttraining's binary_logloss: 0.727108\n",
      "[1747]\ttraining's binary_logloss: 0.72701\n",
      "[1748]\ttraining's binary_logloss: 0.726931\n",
      "[1749]\ttraining's binary_logloss: 0.726803\n",
      "[1750]\ttraining's binary_logloss: 0.72669\n",
      "[1751]\ttraining's binary_logloss: 0.72657\n",
      "[1752]\ttraining's binary_logloss: 0.726447\n",
      "[1753]\ttraining's binary_logloss: 0.72636\n",
      "[1754]\ttraining's binary_logloss: 0.726276\n",
      "[1755]\ttraining's binary_logloss: 0.726132\n",
      "[1756]\ttraining's binary_logloss: 0.72603\n",
      "[1757]\ttraining's binary_logloss: 0.725884\n",
      "[1758]\ttraining's binary_logloss: 0.725767\n",
      "[1759]\ttraining's binary_logloss: 0.725651\n",
      "[1760]\ttraining's binary_logloss: 0.725542\n",
      "[1761]\ttraining's binary_logloss: 0.725423\n",
      "[1762]\ttraining's binary_logloss: 0.725304\n",
      "[1763]\ttraining's binary_logloss: 0.725215\n",
      "[1764]\ttraining's binary_logloss: 0.72512\n",
      "[1765]\ttraining's binary_logloss: 0.725005\n",
      "[1766]\ttraining's binary_logloss: 0.724889\n",
      "[1767]\ttraining's binary_logloss: 0.724779\n",
      "[1768]\ttraining's binary_logloss: 0.724654\n",
      "[1769]\ttraining's binary_logloss: 0.724553\n",
      "[1770]\ttraining's binary_logloss: 0.724414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1771]\ttraining's binary_logloss: 0.72428\n",
      "[1772]\ttraining's binary_logloss: 0.724153\n",
      "[1773]\ttraining's binary_logloss: 0.724041\n",
      "[1774]\ttraining's binary_logloss: 0.723915\n",
      "[1775]\ttraining's binary_logloss: 0.723814\n",
      "[1776]\ttraining's binary_logloss: 0.723684\n",
      "[1777]\ttraining's binary_logloss: 0.723573\n",
      "[1778]\ttraining's binary_logloss: 0.723442\n",
      "[1779]\ttraining's binary_logloss: 0.723333\n",
      "[1780]\ttraining's binary_logloss: 0.723248\n",
      "[1781]\ttraining's binary_logloss: 0.723156\n",
      "[1782]\ttraining's binary_logloss: 0.723055\n",
      "[1783]\ttraining's binary_logloss: 0.722937\n",
      "[1784]\ttraining's binary_logloss: 0.722818\n",
      "[1785]\ttraining's binary_logloss: 0.722706\n",
      "[1786]\ttraining's binary_logloss: 0.722602\n",
      "[1787]\ttraining's binary_logloss: 0.722466\n",
      "[1788]\ttraining's binary_logloss: 0.722351\n",
      "[1789]\ttraining's binary_logloss: 0.722196\n",
      "[1790]\ttraining's binary_logloss: 0.722108\n",
      "[1791]\ttraining's binary_logloss: 0.722006\n",
      "[1792]\ttraining's binary_logloss: 0.721887\n",
      "[1793]\ttraining's binary_logloss: 0.72175\n",
      "[1794]\ttraining's binary_logloss: 0.721663\n",
      "[1795]\ttraining's binary_logloss: 0.721527\n",
      "[1796]\ttraining's binary_logloss: 0.721429\n",
      "[1797]\ttraining's binary_logloss: 0.72126\n",
      "[1798]\ttraining's binary_logloss: 0.721148\n",
      "[1799]\ttraining's binary_logloss: 0.721065\n",
      "[1800]\ttraining's binary_logloss: 0.720966\n",
      "[1801]\ttraining's binary_logloss: 0.7208\n",
      "[1802]\ttraining's binary_logloss: 0.720685\n",
      "[1803]\ttraining's binary_logloss: 0.720605\n",
      "[1804]\ttraining's binary_logloss: 0.720514\n",
      "[1805]\ttraining's binary_logloss: 0.720401\n",
      "[1806]\ttraining's binary_logloss: 0.720275\n",
      "[1807]\ttraining's binary_logloss: 0.720154\n",
      "[1808]\ttraining's binary_logloss: 0.720032\n",
      "[1809]\ttraining's binary_logloss: 0.719891\n",
      "[1810]\ttraining's binary_logloss: 0.71979\n",
      "[1811]\ttraining's binary_logloss: 0.719674\n",
      "[1812]\ttraining's binary_logloss: 0.719584\n",
      "[1813]\ttraining's binary_logloss: 0.719443\n",
      "[1814]\ttraining's binary_logloss: 0.719314\n",
      "[1815]\ttraining's binary_logloss: 0.71921\n",
      "[1816]\ttraining's binary_logloss: 0.719081\n",
      "[1817]\ttraining's binary_logloss: 0.718951\n",
      "[1818]\ttraining's binary_logloss: 0.718849\n",
      "[1819]\ttraining's binary_logloss: 0.718709\n",
      "[1820]\ttraining's binary_logloss: 0.718593\n",
      "[1821]\ttraining's binary_logloss: 0.718512\n",
      "[1822]\ttraining's binary_logloss: 0.718387\n",
      "[1823]\ttraining's binary_logloss: 0.718282\n",
      "[1824]\ttraining's binary_logloss: 0.718132\n",
      "[1825]\ttraining's binary_logloss: 0.718018\n",
      "[1826]\ttraining's binary_logloss: 0.717885\n",
      "[1827]\ttraining's binary_logloss: 0.717795\n",
      "[1828]\ttraining's binary_logloss: 0.717712\n",
      "[1829]\ttraining's binary_logloss: 0.717619\n",
      "[1830]\ttraining's binary_logloss: 0.717524\n",
      "[1831]\ttraining's binary_logloss: 0.71741\n",
      "[1832]\ttraining's binary_logloss: 0.717293\n",
      "[1833]\ttraining's binary_logloss: 0.717154\n",
      "[1834]\ttraining's binary_logloss: 0.717028\n",
      "[1835]\ttraining's binary_logloss: 0.716927\n",
      "[1836]\ttraining's binary_logloss: 0.716811\n",
      "[1837]\ttraining's binary_logloss: 0.716719\n",
      "[1838]\ttraining's binary_logloss: 0.716595\n",
      "[1839]\ttraining's binary_logloss: 0.716463\n",
      "[1840]\ttraining's binary_logloss: 0.716321\n",
      "[1841]\ttraining's binary_logloss: 0.716225\n",
      "[1842]\ttraining's binary_logloss: 0.716148\n",
      "[1843]\ttraining's binary_logloss: 0.716062\n",
      "[1844]\ttraining's binary_logloss: 0.715948\n",
      "[1845]\ttraining's binary_logloss: 0.715836\n",
      "[1846]\ttraining's binary_logloss: 0.715762\n",
      "[1847]\ttraining's binary_logloss: 0.715683\n",
      "[1848]\ttraining's binary_logloss: 0.715566\n",
      "[1849]\ttraining's binary_logloss: 0.715467\n",
      "[1850]\ttraining's binary_logloss: 0.715342\n",
      "[1851]\ttraining's binary_logloss: 0.715226\n",
      "[1852]\ttraining's binary_logloss: 0.715102\n",
      "[1853]\ttraining's binary_logloss: 0.714999\n",
      "[1854]\ttraining's binary_logloss: 0.714879\n",
      "[1855]\ttraining's binary_logloss: 0.714718\n",
      "[1856]\ttraining's binary_logloss: 0.714618\n",
      "[1857]\ttraining's binary_logloss: 0.714459\n",
      "[1858]\ttraining's binary_logloss: 0.714366\n",
      "[1859]\ttraining's binary_logloss: 0.714276\n",
      "[1860]\ttraining's binary_logloss: 0.714162\n",
      "[1861]\ttraining's binary_logloss: 0.714057\n",
      "[1862]\ttraining's binary_logloss: 0.713953\n",
      "[1863]\ttraining's binary_logloss: 0.713827\n",
      "[1864]\ttraining's binary_logloss: 0.713698\n",
      "[1865]\ttraining's binary_logloss: 0.713566\n",
      "[1866]\ttraining's binary_logloss: 0.713453\n",
      "[1867]\ttraining's binary_logloss: 0.713316\n",
      "[1868]\ttraining's binary_logloss: 0.713222\n",
      "[1869]\ttraining's binary_logloss: 0.713089\n",
      "[1870]\ttraining's binary_logloss: 0.713004\n",
      "[1871]\ttraining's binary_logloss: 0.712915\n",
      "[1872]\ttraining's binary_logloss: 0.712812\n",
      "[1873]\ttraining's binary_logloss: 0.712673\n",
      "[1874]\ttraining's binary_logloss: 0.712597\n",
      "[1875]\ttraining's binary_logloss: 0.712484\n",
      "[1876]\ttraining's binary_logloss: 0.712371\n",
      "[1877]\ttraining's binary_logloss: 0.712264\n",
      "[1878]\ttraining's binary_logloss: 0.71218\n",
      "[1879]\ttraining's binary_logloss: 0.71207\n",
      "[1880]\ttraining's binary_logloss: 0.711959\n",
      "[1881]\ttraining's binary_logloss: 0.711862\n",
      "[1882]\ttraining's binary_logloss: 0.711763\n",
      "[1883]\ttraining's binary_logloss: 0.711677\n",
      "[1884]\ttraining's binary_logloss: 0.711563\n",
      "[1885]\ttraining's binary_logloss: 0.711444\n",
      "[1886]\ttraining's binary_logloss: 0.711325\n",
      "[1887]\ttraining's binary_logloss: 0.711218\n",
      "[1888]\ttraining's binary_logloss: 0.711136\n",
      "[1889]\ttraining's binary_logloss: 0.711027\n",
      "[1890]\ttraining's binary_logloss: 0.710917\n",
      "[1891]\ttraining's binary_logloss: 0.71083\n",
      "[1892]\ttraining's binary_logloss: 0.710739\n",
      "[1893]\ttraining's binary_logloss: 0.710621\n",
      "[1894]\ttraining's binary_logloss: 0.710541\n",
      "[1895]\ttraining's binary_logloss: 0.710411\n",
      "[1896]\ttraining's binary_logloss: 0.710304\n",
      "[1897]\ttraining's binary_logloss: 0.710222\n",
      "[1898]\ttraining's binary_logloss: 0.710093\n",
      "[1899]\ttraining's binary_logloss: 0.709969\n",
      "[1900]\ttraining's binary_logloss: 0.709811\n",
      "[1901]\ttraining's binary_logloss: 0.709722\n",
      "[1902]\ttraining's binary_logloss: 0.70962\n",
      "[1903]\ttraining's binary_logloss: 0.709514\n",
      "[1904]\ttraining's binary_logloss: 0.709382\n",
      "[1905]\ttraining's binary_logloss: 0.709298\n",
      "[1906]\ttraining's binary_logloss: 0.709217\n",
      "[1907]\ttraining's binary_logloss: 0.709083\n",
      "[1908]\ttraining's binary_logloss: 0.708964\n",
      "[1909]\ttraining's binary_logloss: 0.708865\n",
      "[1910]\ttraining's binary_logloss: 0.708767\n",
      "[1911]\ttraining's binary_logloss: 0.708681\n",
      "[1912]\ttraining's binary_logloss: 0.708522\n",
      "[1913]\ttraining's binary_logloss: 0.708444\n",
      "[1914]\ttraining's binary_logloss: 0.708325\n",
      "[1915]\ttraining's binary_logloss: 0.708213\n",
      "[1916]\ttraining's binary_logloss: 0.70813\n",
      "[1917]\ttraining's binary_logloss: 0.708007\n",
      "[1918]\ttraining's binary_logloss: 0.707896\n",
      "[1919]\ttraining's binary_logloss: 0.70779\n",
      "[1920]\ttraining's binary_logloss: 0.70767\n",
      "[1921]\ttraining's binary_logloss: 0.707567\n",
      "[1922]\ttraining's binary_logloss: 0.707473\n",
      "[1923]\ttraining's binary_logloss: 0.707371\n",
      "[1924]\ttraining's binary_logloss: 0.707282\n",
      "[1925]\ttraining's binary_logloss: 0.707166\n",
      "[1926]\ttraining's binary_logloss: 0.70709\n",
      "[1927]\ttraining's binary_logloss: 0.707003\n",
      "[1928]\ttraining's binary_logloss: 0.706863\n",
      "[1929]\ttraining's binary_logloss: 0.706749\n",
      "[1930]\ttraining's binary_logloss: 0.70663\n",
      "[1931]\ttraining's binary_logloss: 0.706499\n",
      "[1932]\ttraining's binary_logloss: 0.706392\n",
      "[1933]\ttraining's binary_logloss: 0.706341\n",
      "[1934]\ttraining's binary_logloss: 0.70622\n",
      "[1935]\ttraining's binary_logloss: 0.706108\n",
      "[1936]\ttraining's binary_logloss: 0.705985\n",
      "[1937]\ttraining's binary_logloss: 0.705882\n",
      "[1938]\ttraining's binary_logloss: 0.705788\n",
      "[1939]\ttraining's binary_logloss: 0.705672\n",
      "[1940]\ttraining's binary_logloss: 0.705585\n",
      "[1941]\ttraining's binary_logloss: 0.705491\n",
      "[1942]\ttraining's binary_logloss: 0.705375\n",
      "[1943]\ttraining's binary_logloss: 0.705278\n",
      "[1944]\ttraining's binary_logloss: 0.70517\n",
      "[1945]\ttraining's binary_logloss: 0.70505\n",
      "[1946]\ttraining's binary_logloss: 0.704956\n",
      "[1947]\ttraining's binary_logloss: 0.704869\n",
      "[1948]\ttraining's binary_logloss: 0.704747\n",
      "[1949]\ttraining's binary_logloss: 0.704659\n",
      "[1950]\ttraining's binary_logloss: 0.704566\n",
      "[1951]\ttraining's binary_logloss: 0.704409\n",
      "[1952]\ttraining's binary_logloss: 0.704291\n",
      "[1953]\ttraining's binary_logloss: 0.704186\n",
      "[1954]\ttraining's binary_logloss: 0.704073\n",
      "[1955]\ttraining's binary_logloss: 0.703972\n",
      "[1956]\ttraining's binary_logloss: 0.703871\n",
      "[1957]\ttraining's binary_logloss: 0.703793\n",
      "[1958]\ttraining's binary_logloss: 0.703697\n",
      "[1959]\ttraining's binary_logloss: 0.70359\n",
      "[1960]\ttraining's binary_logloss: 0.703493\n",
      "[1961]\ttraining's binary_logloss: 0.703375\n",
      "[1962]\ttraining's binary_logloss: 0.703268\n",
      "[1963]\ttraining's binary_logloss: 0.703122\n",
      "[1964]\ttraining's binary_logloss: 0.70298\n",
      "[1965]\ttraining's binary_logloss: 0.702894\n",
      "[1966]\ttraining's binary_logloss: 0.702784\n",
      "[1967]\ttraining's binary_logloss: 0.702645\n",
      "[1968]\ttraining's binary_logloss: 0.702533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1969]\ttraining's binary_logloss: 0.702417\n",
      "[1970]\ttraining's binary_logloss: 0.702333\n",
      "[1971]\ttraining's binary_logloss: 0.702204\n",
      "[1972]\ttraining's binary_logloss: 0.702119\n",
      "[1973]\ttraining's binary_logloss: 0.702005\n",
      "[1974]\ttraining's binary_logloss: 0.701914\n",
      "[1975]\ttraining's binary_logloss: 0.701803\n",
      "[1976]\ttraining's binary_logloss: 0.701719\n",
      "[1977]\ttraining's binary_logloss: 0.701564\n",
      "[1978]\ttraining's binary_logloss: 0.701488\n",
      "[1979]\ttraining's binary_logloss: 0.701396\n",
      "[1980]\ttraining's binary_logloss: 0.701278\n",
      "[1981]\ttraining's binary_logloss: 0.70118\n",
      "[1982]\ttraining's binary_logloss: 0.701049\n",
      "[1983]\ttraining's binary_logloss: 0.700936\n",
      "[1984]\ttraining's binary_logloss: 0.700812\n",
      "[1985]\ttraining's binary_logloss: 0.700731\n",
      "[1986]\ttraining's binary_logloss: 0.700624\n",
      "[1987]\ttraining's binary_logloss: 0.700504\n",
      "[1988]\ttraining's binary_logloss: 0.70041\n",
      "[1989]\ttraining's binary_logloss: 0.70033\n",
      "[1990]\ttraining's binary_logloss: 0.700251\n",
      "[1991]\ttraining's binary_logloss: 0.700131\n",
      "[1992]\ttraining's binary_logloss: 0.700019\n",
      "[1993]\ttraining's binary_logloss: 0.699875\n",
      "[1994]\ttraining's binary_logloss: 0.699763\n",
      "[1995]\ttraining's binary_logloss: 0.699665\n",
      "[1996]\ttraining's binary_logloss: 0.699548\n",
      "[1997]\ttraining's binary_logloss: 0.699471\n",
      "[1998]\ttraining's binary_logloss: 0.699367\n",
      "[1999]\ttraining's binary_logloss: 0.699241\n",
      "[2000]\ttraining's binary_logloss: 0.699125\n",
      "[2001]\ttraining's binary_logloss: 0.699016\n",
      "[2002]\ttraining's binary_logloss: 0.698901\n",
      "[2003]\ttraining's binary_logloss: 0.698788\n",
      "[2004]\ttraining's binary_logloss: 0.698705\n",
      "[2005]\ttraining's binary_logloss: 0.698588\n",
      "[2006]\ttraining's binary_logloss: 0.698475\n",
      "[2007]\ttraining's binary_logloss: 0.698367\n",
      "[2008]\ttraining's binary_logloss: 0.698261\n",
      "[2009]\ttraining's binary_logloss: 0.698186\n",
      "[2010]\ttraining's binary_logloss: 0.698103\n",
      "[2011]\ttraining's binary_logloss: 0.697981\n",
      "[2012]\ttraining's binary_logloss: 0.697888\n",
      "[2013]\ttraining's binary_logloss: 0.69775\n",
      "[2014]\ttraining's binary_logloss: 0.697641\n",
      "[2015]\ttraining's binary_logloss: 0.69754\n",
      "[2016]\ttraining's binary_logloss: 0.697452\n",
      "[2017]\ttraining's binary_logloss: 0.697355\n",
      "[2018]\ttraining's binary_logloss: 0.697253\n",
      "[2019]\ttraining's binary_logloss: 0.697145\n",
      "[2020]\ttraining's binary_logloss: 0.697047\n",
      "[2021]\ttraining's binary_logloss: 0.696915\n",
      "[2022]\ttraining's binary_logloss: 0.696839\n",
      "[2023]\ttraining's binary_logloss: 0.696717\n",
      "[2024]\ttraining's binary_logloss: 0.696616\n",
      "[2025]\ttraining's binary_logloss: 0.696509\n",
      "[2026]\ttraining's binary_logloss: 0.69642\n",
      "[2027]\ttraining's binary_logloss: 0.696301\n",
      "[2028]\ttraining's binary_logloss: 0.696188\n",
      "[2029]\ttraining's binary_logloss: 0.696095\n",
      "[2030]\ttraining's binary_logloss: 0.696021\n",
      "[2031]\ttraining's binary_logloss: 0.695934\n",
      "[2032]\ttraining's binary_logloss: 0.695854\n",
      "[2033]\ttraining's binary_logloss: 0.695766\n",
      "[2034]\ttraining's binary_logloss: 0.695672\n",
      "[2035]\ttraining's binary_logloss: 0.695575\n",
      "[2036]\ttraining's binary_logloss: 0.695454\n",
      "[2037]\ttraining's binary_logloss: 0.695386\n",
      "[2038]\ttraining's binary_logloss: 0.69524\n",
      "[2039]\ttraining's binary_logloss: 0.695147\n",
      "[2040]\ttraining's binary_logloss: 0.695071\n",
      "[2041]\ttraining's binary_logloss: 0.694959\n",
      "[2042]\ttraining's binary_logloss: 0.694843\n",
      "[2043]\ttraining's binary_logloss: 0.69472\n",
      "[2044]\ttraining's binary_logloss: 0.694581\n",
      "[2045]\ttraining's binary_logloss: 0.694444\n",
      "[2046]\ttraining's binary_logloss: 0.694346\n",
      "[2047]\ttraining's binary_logloss: 0.694208\n",
      "[2048]\ttraining's binary_logloss: 0.694116\n",
      "[2049]\ttraining's binary_logloss: 0.693986\n",
      "[2050]\ttraining's binary_logloss: 0.693864\n",
      "[2051]\ttraining's binary_logloss: 0.693786\n",
      "[2052]\ttraining's binary_logloss: 0.693669\n",
      "[2053]\ttraining's binary_logloss: 0.693543\n",
      "[2054]\ttraining's binary_logloss: 0.693449\n",
      "[2055]\ttraining's binary_logloss: 0.69335\n",
      "[2056]\ttraining's binary_logloss: 0.693259\n",
      "[2057]\ttraining's binary_logloss: 0.693162\n",
      "[2058]\ttraining's binary_logloss: 0.693088\n",
      "[2059]\ttraining's binary_logloss: 0.692973\n",
      "[2060]\ttraining's binary_logloss: 0.692859\n",
      "[2061]\ttraining's binary_logloss: 0.69277\n",
      "[2062]\ttraining's binary_logloss: 0.692662\n",
      "[2063]\ttraining's binary_logloss: 0.692556\n",
      "[2064]\ttraining's binary_logloss: 0.692462\n",
      "[2065]\ttraining's binary_logloss: 0.692362\n",
      "[2066]\ttraining's binary_logloss: 0.692265\n",
      "[2067]\ttraining's binary_logloss: 0.692148\n",
      "[2068]\ttraining's binary_logloss: 0.692061\n",
      "[2069]\ttraining's binary_logloss: 0.691979\n",
      "[2070]\ttraining's binary_logloss: 0.69186\n",
      "[2071]\ttraining's binary_logloss: 0.691734\n",
      "[2072]\ttraining's binary_logloss: 0.691614\n",
      "[2073]\ttraining's binary_logloss: 0.691538\n",
      "[2074]\ttraining's binary_logloss: 0.691408\n",
      "[2075]\ttraining's binary_logloss: 0.691327\n",
      "[2076]\ttraining's binary_logloss: 0.691209\n",
      "[2077]\ttraining's binary_logloss: 0.691068\n",
      "[2078]\ttraining's binary_logloss: 0.690973\n",
      "[2079]\ttraining's binary_logloss: 0.690837\n",
      "[2080]\ttraining's binary_logloss: 0.690731\n",
      "[2081]\ttraining's binary_logloss: 0.690656\n",
      "[2082]\ttraining's binary_logloss: 0.690576\n",
      "[2083]\ttraining's binary_logloss: 0.690472\n",
      "[2084]\ttraining's binary_logloss: 0.690382\n",
      "[2085]\ttraining's binary_logloss: 0.690311\n",
      "[2086]\ttraining's binary_logloss: 0.690188\n",
      "[2087]\ttraining's binary_logloss: 0.690084\n",
      "[2088]\ttraining's binary_logloss: 0.689999\n",
      "[2089]\ttraining's binary_logloss: 0.6899\n",
      "[2090]\ttraining's binary_logloss: 0.6898\n",
      "[2091]\ttraining's binary_logloss: 0.689707\n",
      "[2092]\ttraining's binary_logloss: 0.689611\n",
      "[2093]\ttraining's binary_logloss: 0.689522\n",
      "[2094]\ttraining's binary_logloss: 0.689374\n",
      "[2095]\ttraining's binary_logloss: 0.689276\n",
      "[2096]\ttraining's binary_logloss: 0.689168\n",
      "[2097]\ttraining's binary_logloss: 0.68904\n",
      "[2098]\ttraining's binary_logloss: 0.688937\n",
      "[2099]\ttraining's binary_logloss: 0.6888\n",
      "[2100]\ttraining's binary_logloss: 0.688714\n",
      "[2101]\ttraining's binary_logloss: 0.688601\n",
      "[2102]\ttraining's binary_logloss: 0.688498\n",
      "[2103]\ttraining's binary_logloss: 0.688382\n",
      "[2104]\ttraining's binary_logloss: 0.688265\n",
      "[2105]\ttraining's binary_logloss: 0.688179\n",
      "[2106]\ttraining's binary_logloss: 0.688078\n",
      "[2107]\ttraining's binary_logloss: 0.687981\n",
      "[2108]\ttraining's binary_logloss: 0.687874\n",
      "[2109]\ttraining's binary_logloss: 0.687775\n",
      "[2110]\ttraining's binary_logloss: 0.687696\n",
      "[2111]\ttraining's binary_logloss: 0.687578\n",
      "[2112]\ttraining's binary_logloss: 0.687481\n",
      "[2113]\ttraining's binary_logloss: 0.687394\n",
      "[2114]\ttraining's binary_logloss: 0.687301\n",
      "[2115]\ttraining's binary_logloss: 0.687178\n",
      "[2116]\ttraining's binary_logloss: 0.687058\n",
      "[2117]\ttraining's binary_logloss: 0.68693\n",
      "[2118]\ttraining's binary_logloss: 0.68682\n",
      "[2119]\ttraining's binary_logloss: 0.686725\n",
      "[2120]\ttraining's binary_logloss: 0.686623\n",
      "[2121]\ttraining's binary_logloss: 0.686539\n",
      "[2122]\ttraining's binary_logloss: 0.686439\n",
      "[2123]\ttraining's binary_logloss: 0.686353\n",
      "[2124]\ttraining's binary_logloss: 0.686256\n",
      "[2125]\ttraining's binary_logloss: 0.686154\n",
      "[2126]\ttraining's binary_logloss: 0.686046\n",
      "[2127]\ttraining's binary_logloss: 0.685923\n",
      "[2128]\ttraining's binary_logloss: 0.685811\n",
      "[2129]\ttraining's binary_logloss: 0.685685\n",
      "[2130]\ttraining's binary_logloss: 0.685578\n",
      "[2131]\ttraining's binary_logloss: 0.685502\n",
      "[2132]\ttraining's binary_logloss: 0.685387\n",
      "[2133]\ttraining's binary_logloss: 0.685305\n",
      "[2134]\ttraining's binary_logloss: 0.685189\n",
      "[2135]\ttraining's binary_logloss: 0.685102\n",
      "[2136]\ttraining's binary_logloss: 0.684972\n",
      "[2137]\ttraining's binary_logloss: 0.684871\n",
      "[2138]\ttraining's binary_logloss: 0.684801\n",
      "[2139]\ttraining's binary_logloss: 0.684718\n",
      "[2140]\ttraining's binary_logloss: 0.684603\n",
      "[2141]\ttraining's binary_logloss: 0.684476\n",
      "[2142]\ttraining's binary_logloss: 0.684362\n",
      "[2143]\ttraining's binary_logloss: 0.684279\n",
      "[2144]\ttraining's binary_logloss: 0.684178\n",
      "[2145]\ttraining's binary_logloss: 0.684059\n",
      "[2146]\ttraining's binary_logloss: 0.683972\n",
      "[2147]\ttraining's binary_logloss: 0.683869\n",
      "[2148]\ttraining's binary_logloss: 0.683776\n",
      "[2149]\ttraining's binary_logloss: 0.683671\n",
      "[2150]\ttraining's binary_logloss: 0.683571\n",
      "[2151]\ttraining's binary_logloss: 0.683497\n",
      "[2152]\ttraining's binary_logloss: 0.683355\n",
      "[2153]\ttraining's binary_logloss: 0.683269\n",
      "[2154]\ttraining's binary_logloss: 0.683149\n",
      "[2155]\ttraining's binary_logloss: 0.683062\n",
      "[2156]\ttraining's binary_logloss: 0.682978\n",
      "[2157]\ttraining's binary_logloss: 0.682909\n",
      "[2158]\ttraining's binary_logloss: 0.682794\n",
      "[2159]\ttraining's binary_logloss: 0.68269\n",
      "[2160]\ttraining's binary_logloss: 0.682575\n",
      "[2161]\ttraining's binary_logloss: 0.682499\n",
      "[2162]\ttraining's binary_logloss: 0.682411\n",
      "[2163]\ttraining's binary_logloss: 0.68233\n",
      "[2164]\ttraining's binary_logloss: 0.682233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2165]\ttraining's binary_logloss: 0.682117\n",
      "[2166]\ttraining's binary_logloss: 0.682026\n",
      "[2167]\ttraining's binary_logloss: 0.681939\n",
      "[2168]\ttraining's binary_logloss: 0.681848\n",
      "[2169]\ttraining's binary_logloss: 0.681755\n",
      "[2170]\ttraining's binary_logloss: 0.681671\n",
      "[2171]\ttraining's binary_logloss: 0.681577\n",
      "[2172]\ttraining's binary_logloss: 0.681458\n",
      "[2173]\ttraining's binary_logloss: 0.681355\n",
      "[2174]\ttraining's binary_logloss: 0.68126\n",
      "[2175]\ttraining's binary_logloss: 0.681175\n",
      "[2176]\ttraining's binary_logloss: 0.681069\n",
      "[2177]\ttraining's binary_logloss: 0.680985\n",
      "[2178]\ttraining's binary_logloss: 0.680868\n",
      "[2179]\ttraining's binary_logloss: 0.680773\n",
      "[2180]\ttraining's binary_logloss: 0.680695\n",
      "[2181]\ttraining's binary_logloss: 0.680583\n",
      "[2182]\ttraining's binary_logloss: 0.680482\n",
      "[2183]\ttraining's binary_logloss: 0.680418\n",
      "[2184]\ttraining's binary_logloss: 0.680314\n",
      "[2185]\ttraining's binary_logloss: 0.680232\n",
      "[2186]\ttraining's binary_logloss: 0.680062\n",
      "[2187]\ttraining's binary_logloss: 0.679967\n",
      "[2188]\ttraining's binary_logloss: 0.679871\n",
      "[2189]\ttraining's binary_logloss: 0.679786\n",
      "[2190]\ttraining's binary_logloss: 0.679705\n",
      "[2191]\ttraining's binary_logloss: 0.679616\n",
      "[2192]\ttraining's binary_logloss: 0.67952\n",
      "[2193]\ttraining's binary_logloss: 0.679406\n",
      "[2194]\ttraining's binary_logloss: 0.679303\n",
      "[2195]\ttraining's binary_logloss: 0.679211\n",
      "[2196]\ttraining's binary_logloss: 0.679053\n",
      "[2197]\ttraining's binary_logloss: 0.678938\n",
      "[2198]\ttraining's binary_logloss: 0.67882\n",
      "[2199]\ttraining's binary_logloss: 0.678674\n",
      "[2200]\ttraining's binary_logloss: 0.678545\n",
      "[2201]\ttraining's binary_logloss: 0.678481\n",
      "[2202]\ttraining's binary_logloss: 0.678386\n",
      "[2203]\ttraining's binary_logloss: 0.678315\n",
      "[2204]\ttraining's binary_logloss: 0.678245\n",
      "[2205]\ttraining's binary_logloss: 0.678153\n",
      "[2206]\ttraining's binary_logloss: 0.678028\n",
      "[2207]\ttraining's binary_logloss: 0.67796\n",
      "[2208]\ttraining's binary_logloss: 0.677837\n",
      "[2209]\ttraining's binary_logloss: 0.677736\n",
      "[2210]\ttraining's binary_logloss: 0.67761\n",
      "[2211]\ttraining's binary_logloss: 0.677513\n",
      "[2212]\ttraining's binary_logloss: 0.677445\n",
      "[2213]\ttraining's binary_logloss: 0.677358\n",
      "[2214]\ttraining's binary_logloss: 0.677274\n",
      "[2215]\ttraining's binary_logloss: 0.677129\n",
      "[2216]\ttraining's binary_logloss: 0.677009\n",
      "[2217]\ttraining's binary_logloss: 0.676915\n",
      "[2218]\ttraining's binary_logloss: 0.676839\n",
      "[2219]\ttraining's binary_logloss: 0.676726\n",
      "[2220]\ttraining's binary_logloss: 0.676636\n",
      "[2221]\ttraining's binary_logloss: 0.676533\n",
      "[2222]\ttraining's binary_logloss: 0.676395\n",
      "[2223]\ttraining's binary_logloss: 0.676304\n",
      "[2224]\ttraining's binary_logloss: 0.676182\n",
      "[2225]\ttraining's binary_logloss: 0.676108\n",
      "[2226]\ttraining's binary_logloss: 0.675988\n",
      "[2227]\ttraining's binary_logloss: 0.675864\n",
      "[2228]\ttraining's binary_logloss: 0.675724\n",
      "[2229]\ttraining's binary_logloss: 0.675644\n",
      "[2230]\ttraining's binary_logloss: 0.67553\n",
      "[2231]\ttraining's binary_logloss: 0.675442\n",
      "[2232]\ttraining's binary_logloss: 0.675331\n",
      "[2233]\ttraining's binary_logloss: 0.675233\n",
      "[2234]\ttraining's binary_logloss: 0.675119\n",
      "[2235]\ttraining's binary_logloss: 0.675036\n",
      "[2236]\ttraining's binary_logloss: 0.674972\n",
      "[2237]\ttraining's binary_logloss: 0.674864\n",
      "[2238]\ttraining's binary_logloss: 0.674738\n",
      "[2239]\ttraining's binary_logloss: 0.674705\n",
      "[2240]\ttraining's binary_logloss: 0.674608\n",
      "[2241]\ttraining's binary_logloss: 0.674496\n",
      "[2242]\ttraining's binary_logloss: 0.674365\n",
      "[2243]\ttraining's binary_logloss: 0.674232\n",
      "[2244]\ttraining's binary_logloss: 0.674152\n",
      "[2245]\ttraining's binary_logloss: 0.674007\n",
      "[2246]\ttraining's binary_logloss: 0.673915\n",
      "[2247]\ttraining's binary_logloss: 0.673827\n",
      "[2248]\ttraining's binary_logloss: 0.673739\n",
      "[2249]\ttraining's binary_logloss: 0.673633\n",
      "[2250]\ttraining's binary_logloss: 0.673529\n",
      "[2251]\ttraining's binary_logloss: 0.673465\n",
      "[2252]\ttraining's binary_logloss: 0.673391\n",
      "[2253]\ttraining's binary_logloss: 0.67329\n",
      "[2254]\ttraining's binary_logloss: 0.673173\n",
      "[2255]\ttraining's binary_logloss: 0.673099\n",
      "[2256]\ttraining's binary_logloss: 0.672997\n",
      "[2257]\ttraining's binary_logloss: 0.672918\n",
      "[2258]\ttraining's binary_logloss: 0.672769\n",
      "[2259]\ttraining's binary_logloss: 0.67268\n",
      "[2260]\ttraining's binary_logloss: 0.672588\n",
      "[2261]\ttraining's binary_logloss: 0.672484\n",
      "[2262]\ttraining's binary_logloss: 0.672389\n",
      "[2263]\ttraining's binary_logloss: 0.672285\n",
      "[2264]\ttraining's binary_logloss: 0.672174\n",
      "[2265]\ttraining's binary_logloss: 0.672052\n",
      "[2266]\ttraining's binary_logloss: 0.671968\n",
      "[2267]\ttraining's binary_logloss: 0.671825\n",
      "[2268]\ttraining's binary_logloss: 0.671739\n",
      "[2269]\ttraining's binary_logloss: 0.671633\n",
      "[2270]\ttraining's binary_logloss: 0.671533\n",
      "[2271]\ttraining's binary_logloss: 0.671437\n",
      "[2272]\ttraining's binary_logloss: 0.671355\n",
      "[2273]\ttraining's binary_logloss: 0.671252\n",
      "[2274]\ttraining's binary_logloss: 0.671178\n",
      "[2275]\ttraining's binary_logloss: 0.671074\n",
      "[2276]\ttraining's binary_logloss: 0.67098\n",
      "[2277]\ttraining's binary_logloss: 0.670885\n",
      "[2278]\ttraining's binary_logloss: 0.670797\n",
      "[2279]\ttraining's binary_logloss: 0.670702\n",
      "[2280]\ttraining's binary_logloss: 0.670614\n",
      "[2281]\ttraining's binary_logloss: 0.670527\n",
      "[2282]\ttraining's binary_logloss: 0.670433\n",
      "[2283]\ttraining's binary_logloss: 0.670348\n",
      "[2284]\ttraining's binary_logloss: 0.670272\n",
      "[2285]\ttraining's binary_logloss: 0.670194\n",
      "[2286]\ttraining's binary_logloss: 0.670077\n",
      "[2287]\ttraining's binary_logloss: 0.669971\n",
      "[2288]\ttraining's binary_logloss: 0.669864\n",
      "[2289]\ttraining's binary_logloss: 0.669759\n",
      "[2290]\ttraining's binary_logloss: 0.669651\n",
      "[2291]\ttraining's binary_logloss: 0.669586\n",
      "[2292]\ttraining's binary_logloss: 0.669486\n",
      "[2293]\ttraining's binary_logloss: 0.669393\n",
      "[2294]\ttraining's binary_logloss: 0.669299\n",
      "[2295]\ttraining's binary_logloss: 0.669223\n",
      "[2296]\ttraining's binary_logloss: 0.669087\n",
      "[2297]\ttraining's binary_logloss: 0.668971\n",
      "[2298]\ttraining's binary_logloss: 0.668873\n",
      "[2299]\ttraining's binary_logloss: 0.668811\n",
      "[2300]\ttraining's binary_logloss: 0.668705\n",
      "[2301]\ttraining's binary_logloss: 0.668629\n",
      "[2302]\ttraining's binary_logloss: 0.668516\n",
      "[2303]\ttraining's binary_logloss: 0.668434\n",
      "[2304]\ttraining's binary_logloss: 0.668349\n",
      "[2305]\ttraining's binary_logloss: 0.668231\n",
      "[2306]\ttraining's binary_logloss: 0.668105\n",
      "[2307]\ttraining's binary_logloss: 0.668034\n",
      "[2308]\ttraining's binary_logloss: 0.667953\n",
      "[2309]\ttraining's binary_logloss: 0.667845\n",
      "[2310]\ttraining's binary_logloss: 0.66775\n",
      "[2311]\ttraining's binary_logloss: 0.667714\n",
      "[2312]\ttraining's binary_logloss: 0.667608\n",
      "[2313]\ttraining's binary_logloss: 0.667533\n",
      "[2314]\ttraining's binary_logloss: 0.667464\n",
      "[2315]\ttraining's binary_logloss: 0.667362\n",
      "[2316]\ttraining's binary_logloss: 0.667275\n",
      "[2317]\ttraining's binary_logloss: 0.667162\n",
      "[2318]\ttraining's binary_logloss: 0.667062\n",
      "[2319]\ttraining's binary_logloss: 0.666989\n",
      "[2320]\ttraining's binary_logloss: 0.666907\n",
      "[2321]\ttraining's binary_logloss: 0.666812\n",
      "[2322]\ttraining's binary_logloss: 0.666714\n",
      "[2323]\ttraining's binary_logloss: 0.666635\n",
      "[2324]\ttraining's binary_logloss: 0.66654\n",
      "[2325]\ttraining's binary_logloss: 0.666447\n",
      "[2326]\ttraining's binary_logloss: 0.666339\n",
      "[2327]\ttraining's binary_logloss: 0.666216\n",
      "[2328]\ttraining's binary_logloss: 0.666107\n",
      "[2329]\ttraining's binary_logloss: 0.665996\n",
      "[2330]\ttraining's binary_logloss: 0.665904\n",
      "[2331]\ttraining's binary_logloss: 0.66579\n",
      "[2332]\ttraining's binary_logloss: 0.665685\n",
      "[2333]\ttraining's binary_logloss: 0.66556\n",
      "[2334]\ttraining's binary_logloss: 0.665424\n",
      "[2335]\ttraining's binary_logloss: 0.66536\n",
      "[2336]\ttraining's binary_logloss: 0.665282\n",
      "[2337]\ttraining's binary_logloss: 0.665209\n",
      "[2338]\ttraining's binary_logloss: 0.665111\n",
      "[2339]\ttraining's binary_logloss: 0.665012\n",
      "[2340]\ttraining's binary_logloss: 0.664878\n",
      "[2341]\ttraining's binary_logloss: 0.664752\n",
      "[2342]\ttraining's binary_logloss: 0.664639\n",
      "[2343]\ttraining's binary_logloss: 0.664518\n",
      "[2344]\ttraining's binary_logloss: 0.664416\n",
      "[2345]\ttraining's binary_logloss: 0.664297\n",
      "[2346]\ttraining's binary_logloss: 0.664208\n",
      "[2347]\ttraining's binary_logloss: 0.664133\n",
      "[2348]\ttraining's binary_logloss: 0.664007\n",
      "[2349]\ttraining's binary_logloss: 0.663919\n",
      "[2350]\ttraining's binary_logloss: 0.663839\n",
      "[2351]\ttraining's binary_logloss: 0.663748\n",
      "[2352]\ttraining's binary_logloss: 0.663629\n",
      "[2353]\ttraining's binary_logloss: 0.663534\n",
      "[2354]\ttraining's binary_logloss: 0.663423\n",
      "[2355]\ttraining's binary_logloss: 0.663318\n",
      "[2356]\ttraining's binary_logloss: 0.663244\n",
      "[2357]\ttraining's binary_logloss: 0.663162\n",
      "[2358]\ttraining's binary_logloss: 0.663063\n",
      "[2359]\ttraining's binary_logloss: 0.662931\n",
      "[2360]\ttraining's binary_logloss: 0.662844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2361]\ttraining's binary_logloss: 0.662703\n",
      "[2362]\ttraining's binary_logloss: 0.6626\n",
      "[2363]\ttraining's binary_logloss: 0.662496\n",
      "[2364]\ttraining's binary_logloss: 0.66241\n",
      "[2365]\ttraining's binary_logloss: 0.662307\n",
      "[2366]\ttraining's binary_logloss: 0.662142\n",
      "[2367]\ttraining's binary_logloss: 0.66205\n",
      "[2368]\ttraining's binary_logloss: 0.66197\n",
      "[2369]\ttraining's binary_logloss: 0.661865\n",
      "[2370]\ttraining's binary_logloss: 0.661735\n",
      "[2371]\ttraining's binary_logloss: 0.661643\n",
      "[2372]\ttraining's binary_logloss: 0.661569\n",
      "[2373]\ttraining's binary_logloss: 0.661475\n",
      "[2374]\ttraining's binary_logloss: 0.661367\n",
      "[2375]\ttraining's binary_logloss: 0.661287\n",
      "[2376]\ttraining's binary_logloss: 0.66122\n",
      "[2377]\ttraining's binary_logloss: 0.661138\n",
      "[2378]\ttraining's binary_logloss: 0.661033\n",
      "[2379]\ttraining's binary_logloss: 0.660936\n",
      "[2380]\ttraining's binary_logloss: 0.660852\n",
      "[2381]\ttraining's binary_logloss: 0.660777\n",
      "[2382]\ttraining's binary_logloss: 0.660652\n",
      "[2383]\ttraining's binary_logloss: 0.660547\n",
      "[2384]\ttraining's binary_logloss: 0.660393\n",
      "[2385]\ttraining's binary_logloss: 0.66026\n",
      "[2386]\ttraining's binary_logloss: 0.660178\n",
      "[2387]\ttraining's binary_logloss: 0.660098\n",
      "[2388]\ttraining's binary_logloss: 0.659992\n",
      "[2389]\ttraining's binary_logloss: 0.659891\n",
      "[2390]\ttraining's binary_logloss: 0.659787\n",
      "[2391]\ttraining's binary_logloss: 0.659678\n",
      "[2392]\ttraining's binary_logloss: 0.659592\n",
      "[2393]\ttraining's binary_logloss: 0.659489\n",
      "[2394]\ttraining's binary_logloss: 0.659385\n",
      "[2395]\ttraining's binary_logloss: 0.659254\n",
      "[2396]\ttraining's binary_logloss: 0.659145\n",
      "[2397]\ttraining's binary_logloss: 0.659063\n",
      "[2398]\ttraining's binary_logloss: 0.658988\n",
      "[2399]\ttraining's binary_logloss: 0.658913\n",
      "[2400]\ttraining's binary_logloss: 0.658827\n",
      "[2401]\ttraining's binary_logloss: 0.658722\n",
      "[2402]\ttraining's binary_logloss: 0.658609\n",
      "[2403]\ttraining's binary_logloss: 0.658515\n",
      "[2404]\ttraining's binary_logloss: 0.658404\n",
      "[2405]\ttraining's binary_logloss: 0.658327\n",
      "[2406]\ttraining's binary_logloss: 0.658251\n",
      "[2407]\ttraining's binary_logloss: 0.658186\n",
      "[2408]\ttraining's binary_logloss: 0.658113\n",
      "[2409]\ttraining's binary_logloss: 0.658039\n",
      "[2410]\ttraining's binary_logloss: 0.657952\n",
      "[2411]\ttraining's binary_logloss: 0.65787\n",
      "[2412]\ttraining's binary_logloss: 0.657775\n",
      "[2413]\ttraining's binary_logloss: 0.657682\n",
      "[2414]\ttraining's binary_logloss: 0.657623\n",
      "[2415]\ttraining's binary_logloss: 0.657528\n",
      "[2416]\ttraining's binary_logloss: 0.657378\n",
      "[2417]\ttraining's binary_logloss: 0.657262\n",
      "[2418]\ttraining's binary_logloss: 0.657159\n",
      "[2419]\ttraining's binary_logloss: 0.657076\n",
      "[2420]\ttraining's binary_logloss: 0.656994\n",
      "[2421]\ttraining's binary_logloss: 0.656916\n",
      "[2422]\ttraining's binary_logloss: 0.656847\n",
      "[2423]\ttraining's binary_logloss: 0.656757\n",
      "[2424]\ttraining's binary_logloss: 0.656654\n",
      "[2425]\ttraining's binary_logloss: 0.656541\n",
      "[2426]\ttraining's binary_logloss: 0.656426\n",
      "[2427]\ttraining's binary_logloss: 0.656323\n",
      "[2428]\ttraining's binary_logloss: 0.65625\n",
      "[2429]\ttraining's binary_logloss: 0.656167\n",
      "[2430]\ttraining's binary_logloss: 0.656063\n",
      "[2431]\ttraining's binary_logloss: 0.655985\n",
      "[2432]\ttraining's binary_logloss: 0.65588\n",
      "[2433]\ttraining's binary_logloss: 0.655783\n",
      "[2434]\ttraining's binary_logloss: 0.655717\n",
      "[2435]\ttraining's binary_logloss: 0.655615\n",
      "[2436]\ttraining's binary_logloss: 0.65552\n",
      "[2437]\ttraining's binary_logloss: 0.655424\n",
      "[2438]\ttraining's binary_logloss: 0.655328\n",
      "[2439]\ttraining's binary_logloss: 0.655243\n",
      "[2440]\ttraining's binary_logloss: 0.655117\n",
      "[2441]\ttraining's binary_logloss: 0.655026\n",
      "[2442]\ttraining's binary_logloss: 0.654896\n",
      "[2443]\ttraining's binary_logloss: 0.654825\n",
      "[2444]\ttraining's binary_logloss: 0.65476\n",
      "[2445]\ttraining's binary_logloss: 0.654665\n",
      "[2446]\ttraining's binary_logloss: 0.654558\n",
      "[2447]\ttraining's binary_logloss: 0.654409\n",
      "[2448]\ttraining's binary_logloss: 0.654312\n",
      "[2449]\ttraining's binary_logloss: 0.654252\n",
      "[2450]\ttraining's binary_logloss: 0.654187\n",
      "[2451]\ttraining's binary_logloss: 0.654081\n",
      "[2452]\ttraining's binary_logloss: 0.653969\n",
      "[2453]\ttraining's binary_logloss: 0.653891\n",
      "[2454]\ttraining's binary_logloss: 0.653803\n",
      "[2455]\ttraining's binary_logloss: 0.653707\n",
      "[2456]\ttraining's binary_logloss: 0.653618\n",
      "[2457]\ttraining's binary_logloss: 0.653518\n",
      "[2458]\ttraining's binary_logloss: 0.653454\n",
      "[2459]\ttraining's binary_logloss: 0.653359\n",
      "[2460]\ttraining's binary_logloss: 0.653281\n",
      "[2461]\ttraining's binary_logloss: 0.653206\n",
      "[2462]\ttraining's binary_logloss: 0.653117\n",
      "[2463]\ttraining's binary_logloss: 0.653049\n",
      "[2464]\ttraining's binary_logloss: 0.652969\n",
      "[2465]\ttraining's binary_logloss: 0.652885\n",
      "[2466]\ttraining's binary_logloss: 0.652789\n",
      "[2467]\ttraining's binary_logloss: 0.652684\n",
      "[2468]\ttraining's binary_logloss: 0.652584\n",
      "[2469]\ttraining's binary_logloss: 0.652481\n",
      "[2470]\ttraining's binary_logloss: 0.652382\n",
      "[2471]\ttraining's binary_logloss: 0.652299\n",
      "[2472]\ttraining's binary_logloss: 0.652191\n",
      "[2473]\ttraining's binary_logloss: 0.652106\n",
      "[2474]\ttraining's binary_logloss: 0.651995\n",
      "[2475]\ttraining's binary_logloss: 0.651868\n",
      "[2476]\ttraining's binary_logloss: 0.651797\n",
      "[2477]\ttraining's binary_logloss: 0.651674\n",
      "[2478]\ttraining's binary_logloss: 0.65157\n",
      "[2479]\ttraining's binary_logloss: 0.651464\n",
      "[2480]\ttraining's binary_logloss: 0.651367\n",
      "[2481]\ttraining's binary_logloss: 0.651286\n",
      "[2482]\ttraining's binary_logloss: 0.651183\n",
      "[2483]\ttraining's binary_logloss: 0.65109\n",
      "[2484]\ttraining's binary_logloss: 0.651008\n",
      "[2485]\ttraining's binary_logloss: 0.650904\n",
      "[2486]\ttraining's binary_logloss: 0.650833\n",
      "[2487]\ttraining's binary_logloss: 0.650761\n",
      "[2488]\ttraining's binary_logloss: 0.650661\n",
      "[2489]\ttraining's binary_logloss: 0.650587\n",
      "[2490]\ttraining's binary_logloss: 0.65046\n",
      "[2491]\ttraining's binary_logloss: 0.650364\n",
      "[2492]\ttraining's binary_logloss: 0.650254\n",
      "[2493]\ttraining's binary_logloss: 0.650145\n",
      "[2494]\ttraining's binary_logloss: 0.650039\n",
      "[2495]\ttraining's binary_logloss: 0.649939\n",
      "[2496]\ttraining's binary_logloss: 0.649871\n",
      "[2497]\ttraining's binary_logloss: 0.649763\n",
      "[2498]\ttraining's binary_logloss: 0.649677\n",
      "[2499]\ttraining's binary_logloss: 0.649576\n",
      "[2500]\ttraining's binary_logloss: 0.649478\n",
      "[2501]\ttraining's binary_logloss: 0.649369\n",
      "[2502]\ttraining's binary_logloss: 0.649268\n",
      "[2503]\ttraining's binary_logloss: 0.649161\n",
      "[2504]\ttraining's binary_logloss: 0.649063\n",
      "[2505]\ttraining's binary_logloss: 0.648955\n",
      "[2506]\ttraining's binary_logloss: 0.648849\n",
      "[2507]\ttraining's binary_logloss: 0.64876\n",
      "[2508]\ttraining's binary_logloss: 0.648649\n",
      "[2509]\ttraining's binary_logloss: 0.648544\n",
      "[2510]\ttraining's binary_logloss: 0.648473\n",
      "[2511]\ttraining's binary_logloss: 0.648394\n",
      "[2512]\ttraining's binary_logloss: 0.648275\n",
      "[2513]\ttraining's binary_logloss: 0.648187\n",
      "[2514]\ttraining's binary_logloss: 0.648078\n",
      "[2515]\ttraining's binary_logloss: 0.647999\n",
      "[2516]\ttraining's binary_logloss: 0.647937\n",
      "[2517]\ttraining's binary_logloss: 0.647854\n",
      "[2518]\ttraining's binary_logloss: 0.647739\n",
      "[2519]\ttraining's binary_logloss: 0.647651\n",
      "[2520]\ttraining's binary_logloss: 0.647569\n",
      "[2521]\ttraining's binary_logloss: 0.647459\n",
      "[2522]\ttraining's binary_logloss: 0.647369\n",
      "[2523]\ttraining's binary_logloss: 0.647256\n",
      "[2524]\ttraining's binary_logloss: 0.647169\n",
      "[2525]\ttraining's binary_logloss: 0.647038\n",
      "[2526]\ttraining's binary_logloss: 0.64694\n",
      "[2527]\ttraining's binary_logloss: 0.646868\n",
      "[2528]\ttraining's binary_logloss: 0.646781\n",
      "[2529]\ttraining's binary_logloss: 0.646721\n",
      "[2530]\ttraining's binary_logloss: 0.646619\n",
      "[2531]\ttraining's binary_logloss: 0.646514\n",
      "[2532]\ttraining's binary_logloss: 0.646434\n",
      "[2533]\ttraining's binary_logloss: 0.646337\n",
      "[2534]\ttraining's binary_logloss: 0.646248\n",
      "[2535]\ttraining's binary_logloss: 0.646162\n",
      "[2536]\ttraining's binary_logloss: 0.646052\n",
      "[2537]\ttraining's binary_logloss: 0.645984\n",
      "[2538]\ttraining's binary_logloss: 0.645865\n",
      "[2539]\ttraining's binary_logloss: 0.645729\n",
      "[2540]\ttraining's binary_logloss: 0.645628\n",
      "[2541]\ttraining's binary_logloss: 0.645489\n",
      "[2542]\ttraining's binary_logloss: 0.64541\n",
      "[2543]\ttraining's binary_logloss: 0.645282\n",
      "[2544]\ttraining's binary_logloss: 0.645196\n",
      "[2545]\ttraining's binary_logloss: 0.645093\n",
      "[2546]\ttraining's binary_logloss: 0.644967\n",
      "[2547]\ttraining's binary_logloss: 0.644874\n",
      "[2548]\ttraining's binary_logloss: 0.644771\n",
      "[2549]\ttraining's binary_logloss: 0.644712\n",
      "[2550]\ttraining's binary_logloss: 0.644633\n",
      "[2551]\ttraining's binary_logloss: 0.644544\n",
      "[2552]\ttraining's binary_logloss: 0.644467\n",
      "[2553]\ttraining's binary_logloss: 0.644357\n",
      "[2554]\ttraining's binary_logloss: 0.644245\n",
      "[2555]\ttraining's binary_logloss: 0.644169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2556]\ttraining's binary_logloss: 0.644086\n",
      "[2557]\ttraining's binary_logloss: 0.644015\n",
      "[2558]\ttraining's binary_logloss: 0.643892\n",
      "[2559]\ttraining's binary_logloss: 0.643822\n",
      "[2560]\ttraining's binary_logloss: 0.643727\n",
      "[2561]\ttraining's binary_logloss: 0.643641\n",
      "[2562]\ttraining's binary_logloss: 0.643572\n",
      "[2563]\ttraining's binary_logloss: 0.643451\n",
      "[2564]\ttraining's binary_logloss: 0.643344\n",
      "[2565]\ttraining's binary_logloss: 0.64323\n",
      "[2566]\ttraining's binary_logloss: 0.643148\n",
      "[2567]\ttraining's binary_logloss: 0.643078\n",
      "[2568]\ttraining's binary_logloss: 0.642978\n",
      "[2569]\ttraining's binary_logloss: 0.642894\n",
      "[2570]\ttraining's binary_logloss: 0.642809\n",
      "[2571]\ttraining's binary_logloss: 0.642722\n",
      "[2572]\ttraining's binary_logloss: 0.64261\n",
      "[2573]\ttraining's binary_logloss: 0.642527\n",
      "[2574]\ttraining's binary_logloss: 0.642447\n",
      "[2575]\ttraining's binary_logloss: 0.642387\n",
      "[2576]\ttraining's binary_logloss: 0.642296\n",
      "[2577]\ttraining's binary_logloss: 0.642191\n",
      "[2578]\ttraining's binary_logloss: 0.642098\n",
      "[2579]\ttraining's binary_logloss: 0.642023\n",
      "[2580]\ttraining's binary_logloss: 0.64196\n",
      "[2581]\ttraining's binary_logloss: 0.641886\n",
      "[2582]\ttraining's binary_logloss: 0.641782\n",
      "[2583]\ttraining's binary_logloss: 0.641673\n",
      "[2584]\ttraining's binary_logloss: 0.641588\n",
      "[2585]\ttraining's binary_logloss: 0.641512\n",
      "[2586]\ttraining's binary_logloss: 0.641425\n",
      "[2587]\ttraining's binary_logloss: 0.641336\n",
      "[2588]\ttraining's binary_logloss: 0.641232\n",
      "[2589]\ttraining's binary_logloss: 0.641124\n",
      "[2590]\ttraining's binary_logloss: 0.641043\n",
      "[2591]\ttraining's binary_logloss: 0.640958\n",
      "[2592]\ttraining's binary_logloss: 0.640874\n",
      "[2593]\ttraining's binary_logloss: 0.640818\n",
      "[2594]\ttraining's binary_logloss: 0.640721\n",
      "[2595]\ttraining's binary_logloss: 0.640625\n",
      "[2596]\ttraining's binary_logloss: 0.640532\n",
      "[2597]\ttraining's binary_logloss: 0.640446\n",
      "[2598]\ttraining's binary_logloss: 0.640344\n",
      "[2599]\ttraining's binary_logloss: 0.640255\n",
      "[2600]\ttraining's binary_logloss: 0.64016\n",
      "[2601]\ttraining's binary_logloss: 0.640094\n",
      "[2602]\ttraining's binary_logloss: 0.640012\n",
      "[2603]\ttraining's binary_logloss: 0.639917\n",
      "[2604]\ttraining's binary_logloss: 0.639858\n",
      "[2605]\ttraining's binary_logloss: 0.639747\n",
      "[2606]\ttraining's binary_logloss: 0.639627\n",
      "[2607]\ttraining's binary_logloss: 0.6395\n",
      "[2608]\ttraining's binary_logloss: 0.639407\n",
      "[2609]\ttraining's binary_logloss: 0.639338\n",
      "[2610]\ttraining's binary_logloss: 0.639244\n",
      "[2611]\ttraining's binary_logloss: 0.639122\n",
      "[2612]\ttraining's binary_logloss: 0.639032\n",
      "[2613]\ttraining's binary_logloss: 0.638907\n",
      "[2614]\ttraining's binary_logloss: 0.638845\n",
      "[2615]\ttraining's binary_logloss: 0.638752\n",
      "[2616]\ttraining's binary_logloss: 0.638676\n",
      "[2617]\ttraining's binary_logloss: 0.638567\n",
      "[2618]\ttraining's binary_logloss: 0.6385\n",
      "[2619]\ttraining's binary_logloss: 0.638408\n",
      "[2620]\ttraining's binary_logloss: 0.638337\n",
      "[2621]\ttraining's binary_logloss: 0.638245\n",
      "[2622]\ttraining's binary_logloss: 0.638152\n",
      "[2623]\ttraining's binary_logloss: 0.638055\n",
      "[2624]\ttraining's binary_logloss: 0.63797\n",
      "[2625]\ttraining's binary_logloss: 0.637901\n",
      "[2626]\ttraining's binary_logloss: 0.637817\n",
      "[2627]\ttraining's binary_logloss: 0.637702\n",
      "[2628]\ttraining's binary_logloss: 0.637627\n",
      "[2629]\ttraining's binary_logloss: 0.637528\n",
      "[2630]\ttraining's binary_logloss: 0.637431\n",
      "[2631]\ttraining's binary_logloss: 0.637365\n",
      "[2632]\ttraining's binary_logloss: 0.637273\n",
      "[2633]\ttraining's binary_logloss: 0.637193\n",
      "[2634]\ttraining's binary_logloss: 0.6371\n",
      "[2635]\ttraining's binary_logloss: 0.637032\n",
      "[2636]\ttraining's binary_logloss: 0.636918\n",
      "[2637]\ttraining's binary_logloss: 0.636837\n",
      "[2638]\ttraining's binary_logloss: 0.636712\n",
      "[2639]\ttraining's binary_logloss: 0.63663\n",
      "[2640]\ttraining's binary_logloss: 0.636506\n",
      "[2641]\ttraining's binary_logloss: 0.636378\n",
      "[2642]\ttraining's binary_logloss: 0.636283\n",
      "[2643]\ttraining's binary_logloss: 0.636194\n",
      "[2644]\ttraining's binary_logloss: 0.636136\n",
      "[2645]\ttraining's binary_logloss: 0.636058\n",
      "[2646]\ttraining's binary_logloss: 0.635951\n",
      "[2647]\ttraining's binary_logloss: 0.635823\n",
      "[2648]\ttraining's binary_logloss: 0.635732\n",
      "[2649]\ttraining's binary_logloss: 0.635631\n",
      "[2650]\ttraining's binary_logloss: 0.635532\n",
      "[2651]\ttraining's binary_logloss: 0.635431\n",
      "[2652]\ttraining's binary_logloss: 0.63535\n",
      "[2653]\ttraining's binary_logloss: 0.635231\n",
      "[2654]\ttraining's binary_logloss: 0.635133\n",
      "[2655]\ttraining's binary_logloss: 0.635038\n",
      "[2656]\ttraining's binary_logloss: 0.634936\n",
      "[2657]\ttraining's binary_logloss: 0.634839\n",
      "[2658]\ttraining's binary_logloss: 0.634746\n",
      "[2659]\ttraining's binary_logloss: 0.634666\n",
      "[2660]\ttraining's binary_logloss: 0.634576\n",
      "[2661]\ttraining's binary_logloss: 0.634485\n",
      "[2662]\ttraining's binary_logloss: 0.634398\n",
      "[2663]\ttraining's binary_logloss: 0.634303\n",
      "[2664]\ttraining's binary_logloss: 0.634166\n",
      "[2665]\ttraining's binary_logloss: 0.634071\n",
      "[2666]\ttraining's binary_logloss: 0.633951\n",
      "[2667]\ttraining's binary_logloss: 0.63383\n",
      "[2668]\ttraining's binary_logloss: 0.633753\n",
      "[2669]\ttraining's binary_logloss: 0.633671\n",
      "[2670]\ttraining's binary_logloss: 0.633592\n",
      "[2671]\ttraining's binary_logloss: 0.633507\n",
      "[2672]\ttraining's binary_logloss: 0.633408\n",
      "[2673]\ttraining's binary_logloss: 0.633323\n",
      "[2674]\ttraining's binary_logloss: 0.63325\n",
      "[2675]\ttraining's binary_logloss: 0.633182\n",
      "[2676]\ttraining's binary_logloss: 0.633089\n",
      "[2677]\ttraining's binary_logloss: 0.632992\n",
      "[2678]\ttraining's binary_logloss: 0.632897\n",
      "[2679]\ttraining's binary_logloss: 0.632786\n",
      "[2680]\ttraining's binary_logloss: 0.632708\n",
      "[2681]\ttraining's binary_logloss: 0.632638\n",
      "[2682]\ttraining's binary_logloss: 0.632581\n",
      "[2683]\ttraining's binary_logloss: 0.632487\n",
      "[2684]\ttraining's binary_logloss: 0.632374\n",
      "[2685]\ttraining's binary_logloss: 0.632291\n",
      "[2686]\ttraining's binary_logloss: 0.632179\n",
      "[2687]\ttraining's binary_logloss: 0.632086\n",
      "[2688]\ttraining's binary_logloss: 0.631983\n",
      "[2689]\ttraining's binary_logloss: 0.631902\n",
      "[2690]\ttraining's binary_logloss: 0.631818\n",
      "[2691]\ttraining's binary_logloss: 0.631724\n",
      "[2692]\ttraining's binary_logloss: 0.631619\n",
      "[2693]\ttraining's binary_logloss: 0.631511\n",
      "[2694]\ttraining's binary_logloss: 0.631403\n",
      "[2695]\ttraining's binary_logloss: 0.63129\n",
      "[2696]\ttraining's binary_logloss: 0.631215\n",
      "[2697]\ttraining's binary_logloss: 0.631114\n",
      "[2698]\ttraining's binary_logloss: 0.63105\n",
      "[2699]\ttraining's binary_logloss: 0.630951\n",
      "[2700]\ttraining's binary_logloss: 0.63085\n",
      "[2701]\ttraining's binary_logloss: 0.630776\n",
      "[2702]\ttraining's binary_logloss: 0.630696\n",
      "[2703]\ttraining's binary_logloss: 0.630642\n",
      "[2704]\ttraining's binary_logloss: 0.630555\n",
      "[2705]\ttraining's binary_logloss: 0.63048\n",
      "[2706]\ttraining's binary_logloss: 0.630409\n",
      "[2707]\ttraining's binary_logloss: 0.630276\n",
      "[2708]\ttraining's binary_logloss: 0.630205\n",
      "[2709]\ttraining's binary_logloss: 0.63012\n",
      "[2710]\ttraining's binary_logloss: 0.629983\n",
      "[2711]\ttraining's binary_logloss: 0.629905\n",
      "[2712]\ttraining's binary_logloss: 0.629823\n",
      "[2713]\ttraining's binary_logloss: 0.629734\n",
      "[2714]\ttraining's binary_logloss: 0.629673\n",
      "[2715]\ttraining's binary_logloss: 0.62961\n",
      "[2716]\ttraining's binary_logloss: 0.629529\n",
      "[2717]\ttraining's binary_logloss: 0.629423\n",
      "[2718]\ttraining's binary_logloss: 0.629334\n",
      "[2719]\ttraining's binary_logloss: 0.629251\n",
      "[2720]\ttraining's binary_logloss: 0.629155\n",
      "[2721]\ttraining's binary_logloss: 0.629096\n",
      "[2722]\ttraining's binary_logloss: 0.628972\n",
      "[2723]\ttraining's binary_logloss: 0.628862\n",
      "[2724]\ttraining's binary_logloss: 0.628794\n",
      "[2725]\ttraining's binary_logloss: 0.628674\n",
      "[2726]\ttraining's binary_logloss: 0.628591\n",
      "[2727]\ttraining's binary_logloss: 0.628505\n",
      "[2728]\ttraining's binary_logloss: 0.628441\n",
      "[2729]\ttraining's binary_logloss: 0.628386\n",
      "[2730]\ttraining's binary_logloss: 0.628276\n",
      "[2731]\ttraining's binary_logloss: 0.628199\n",
      "[2732]\ttraining's binary_logloss: 0.628113\n",
      "[2733]\ttraining's binary_logloss: 0.628004\n",
      "[2734]\ttraining's binary_logloss: 0.627924\n",
      "[2735]\ttraining's binary_logloss: 0.62786\n",
      "[2736]\ttraining's binary_logloss: 0.62777\n",
      "[2737]\ttraining's binary_logloss: 0.627662\n",
      "[2738]\ttraining's binary_logloss: 0.627593\n",
      "[2739]\ttraining's binary_logloss: 0.627501\n",
      "[2740]\ttraining's binary_logloss: 0.627411\n",
      "[2741]\ttraining's binary_logloss: 0.627332\n",
      "[2742]\ttraining's binary_logloss: 0.627223\n",
      "[2743]\ttraining's binary_logloss: 0.627121\n",
      "[2744]\ttraining's binary_logloss: 0.627017\n",
      "[2745]\ttraining's binary_logloss: 0.626952\n",
      "[2746]\ttraining's binary_logloss: 0.626889\n",
      "[2747]\ttraining's binary_logloss: 0.626817\n",
      "[2748]\ttraining's binary_logloss: 0.626734\n",
      "[2749]\ttraining's binary_logloss: 0.62664\n",
      "[2750]\ttraining's binary_logloss: 0.626552\n",
      "[2751]\ttraining's binary_logloss: 0.626452\n",
      "[2752]\ttraining's binary_logloss: 0.626383\n",
      "[2753]\ttraining's binary_logloss: 0.626309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2754]\ttraining's binary_logloss: 0.62617\n",
      "[2755]\ttraining's binary_logloss: 0.626079\n",
      "[2756]\ttraining's binary_logloss: 0.626024\n",
      "[2757]\ttraining's binary_logloss: 0.625963\n",
      "[2758]\ttraining's binary_logloss: 0.625869\n",
      "[2759]\ttraining's binary_logloss: 0.625775\n",
      "[2760]\ttraining's binary_logloss: 0.625677\n",
      "[2761]\ttraining's binary_logloss: 0.625592\n",
      "[2762]\ttraining's binary_logloss: 0.625504\n",
      "[2763]\ttraining's binary_logloss: 0.625421\n",
      "[2764]\ttraining's binary_logloss: 0.625355\n",
      "[2765]\ttraining's binary_logloss: 0.625237\n",
      "[2766]\ttraining's binary_logloss: 0.625166\n",
      "[2767]\ttraining's binary_logloss: 0.625089\n",
      "[2768]\ttraining's binary_logloss: 0.624972\n",
      "[2769]\ttraining's binary_logloss: 0.624874\n",
      "[2770]\ttraining's binary_logloss: 0.624781\n",
      "[2771]\ttraining's binary_logloss: 0.624711\n",
      "[2772]\ttraining's binary_logloss: 0.624648\n",
      "[2773]\ttraining's binary_logloss: 0.62456\n",
      "[2774]\ttraining's binary_logloss: 0.624483\n",
      "[2775]\ttraining's binary_logloss: 0.624388\n",
      "[2776]\ttraining's binary_logloss: 0.62427\n",
      "[2777]\ttraining's binary_logloss: 0.624204\n",
      "[2778]\ttraining's binary_logloss: 0.624123\n",
      "[2779]\ttraining's binary_logloss: 0.624014\n",
      "[2780]\ttraining's binary_logloss: 0.623955\n",
      "[2781]\ttraining's binary_logloss: 0.62383\n",
      "[2782]\ttraining's binary_logloss: 0.623743\n",
      "[2783]\ttraining's binary_logloss: 0.623648\n",
      "[2784]\ttraining's binary_logloss: 0.623566\n",
      "[2785]\ttraining's binary_logloss: 0.623453\n",
      "[2786]\ttraining's binary_logloss: 0.623353\n",
      "[2787]\ttraining's binary_logloss: 0.623247\n",
      "[2788]\ttraining's binary_logloss: 0.623177\n",
      "[2789]\ttraining's binary_logloss: 0.623099\n",
      "[2790]\ttraining's binary_logloss: 0.623037\n",
      "[2791]\ttraining's binary_logloss: 0.622952\n",
      "[2792]\ttraining's binary_logloss: 0.622824\n",
      "[2793]\ttraining's binary_logloss: 0.622738\n",
      "[2794]\ttraining's binary_logloss: 0.622659\n",
      "[2795]\ttraining's binary_logloss: 0.622587\n",
      "[2796]\ttraining's binary_logloss: 0.622491\n",
      "[2797]\ttraining's binary_logloss: 0.622407\n",
      "[2798]\ttraining's binary_logloss: 0.622332\n",
      "[2799]\ttraining's binary_logloss: 0.622253\n",
      "[2800]\ttraining's binary_logloss: 0.622117\n",
      "[2801]\ttraining's binary_logloss: 0.62202\n",
      "[2802]\ttraining's binary_logloss: 0.621946\n",
      "[2803]\ttraining's binary_logloss: 0.621875\n",
      "[2804]\ttraining's binary_logloss: 0.621778\n",
      "[2805]\ttraining's binary_logloss: 0.621691\n",
      "[2806]\ttraining's binary_logloss: 0.621581\n",
      "[2807]\ttraining's binary_logloss: 0.621492\n",
      "[2808]\ttraining's binary_logloss: 0.621409\n",
      "[2809]\ttraining's binary_logloss: 0.621331\n",
      "[2810]\ttraining's binary_logloss: 0.621271\n",
      "[2811]\ttraining's binary_logloss: 0.621159\n",
      "[2812]\ttraining's binary_logloss: 0.621062\n",
      "[2813]\ttraining's binary_logloss: 0.620944\n",
      "[2814]\ttraining's binary_logloss: 0.62086\n",
      "[2815]\ttraining's binary_logloss: 0.620771\n",
      "[2816]\ttraining's binary_logloss: 0.620684\n",
      "[2817]\ttraining's binary_logloss: 0.62062\n",
      "[2818]\ttraining's binary_logloss: 0.620543\n",
      "[2819]\ttraining's binary_logloss: 0.620454\n",
      "[2820]\ttraining's binary_logloss: 0.620385\n",
      "[2821]\ttraining's binary_logloss: 0.62032\n",
      "[2822]\ttraining's binary_logloss: 0.620249\n",
      "[2823]\ttraining's binary_logloss: 0.620168\n",
      "[2824]\ttraining's binary_logloss: 0.620095\n",
      "[2825]\ttraining's binary_logloss: 0.620002\n",
      "[2826]\ttraining's binary_logloss: 0.619917\n",
      "[2827]\ttraining's binary_logloss: 0.619851\n",
      "[2828]\ttraining's binary_logloss: 0.619749\n",
      "[2829]\ttraining's binary_logloss: 0.61969\n",
      "[2830]\ttraining's binary_logloss: 0.619623\n",
      "[2831]\ttraining's binary_logloss: 0.619536\n",
      "[2832]\ttraining's binary_logloss: 0.619472\n",
      "[2833]\ttraining's binary_logloss: 0.619365\n",
      "[2834]\ttraining's binary_logloss: 0.619273\n",
      "[2835]\ttraining's binary_logloss: 0.619211\n",
      "[2836]\ttraining's binary_logloss: 0.619104\n",
      "[2837]\ttraining's binary_logloss: 0.619008\n",
      "[2838]\ttraining's binary_logloss: 0.618878\n",
      "[2839]\ttraining's binary_logloss: 0.618811\n",
      "[2840]\ttraining's binary_logloss: 0.618744\n",
      "[2841]\ttraining's binary_logloss: 0.61868\n",
      "[2842]\ttraining's binary_logloss: 0.618556\n",
      "[2843]\ttraining's binary_logloss: 0.618481\n",
      "[2844]\ttraining's binary_logloss: 0.618391\n",
      "[2845]\ttraining's binary_logloss: 0.618313\n",
      "[2846]\ttraining's binary_logloss: 0.618232\n",
      "[2847]\ttraining's binary_logloss: 0.618148\n",
      "[2848]\ttraining's binary_logloss: 0.618069\n",
      "[2849]\ttraining's binary_logloss: 0.617948\n",
      "[2850]\ttraining's binary_logloss: 0.617847\n",
      "[2851]\ttraining's binary_logloss: 0.617749\n",
      "[2852]\ttraining's binary_logloss: 0.617658\n",
      "[2853]\ttraining's binary_logloss: 0.617581\n",
      "[2854]\ttraining's binary_logloss: 0.617513\n",
      "[2855]\ttraining's binary_logloss: 0.617428\n",
      "[2856]\ttraining's binary_logloss: 0.617307\n",
      "[2857]\ttraining's binary_logloss: 0.61722\n",
      "[2858]\ttraining's binary_logloss: 0.617155\n",
      "[2859]\ttraining's binary_logloss: 0.617083\n",
      "[2860]\ttraining's binary_logloss: 0.617003\n",
      "[2861]\ttraining's binary_logloss: 0.616911\n",
      "[2862]\ttraining's binary_logloss: 0.616838\n",
      "[2863]\ttraining's binary_logloss: 0.616738\n",
      "[2864]\ttraining's binary_logloss: 0.616667\n",
      "[2865]\ttraining's binary_logloss: 0.616596\n",
      "[2866]\ttraining's binary_logloss: 0.616538\n",
      "[2867]\ttraining's binary_logloss: 0.616466\n",
      "[2868]\ttraining's binary_logloss: 0.616373\n",
      "[2869]\ttraining's binary_logloss: 0.616288\n",
      "[2870]\ttraining's binary_logloss: 0.616213\n",
      "[2871]\ttraining's binary_logloss: 0.616115\n",
      "[2872]\ttraining's binary_logloss: 0.616049\n",
      "[2873]\ttraining's binary_logloss: 0.615977\n",
      "[2874]\ttraining's binary_logloss: 0.615876\n",
      "[2875]\ttraining's binary_logloss: 0.615806\n",
      "[2876]\ttraining's binary_logloss: 0.615742\n",
      "[2877]\ttraining's binary_logloss: 0.615666\n",
      "[2878]\ttraining's binary_logloss: 0.615589\n",
      "[2879]\ttraining's binary_logloss: 0.615503\n",
      "[2880]\ttraining's binary_logloss: 0.615422\n",
      "[2881]\ttraining's binary_logloss: 0.615324\n",
      "[2882]\ttraining's binary_logloss: 0.615249\n",
      "[2883]\ttraining's binary_logloss: 0.615142\n",
      "[2884]\ttraining's binary_logloss: 0.615081\n",
      "[2885]\ttraining's binary_logloss: 0.615025\n",
      "[2886]\ttraining's binary_logloss: 0.614949\n",
      "[2887]\ttraining's binary_logloss: 0.614878\n",
      "[2888]\ttraining's binary_logloss: 0.614794\n",
      "[2889]\ttraining's binary_logloss: 0.614695\n",
      "[2890]\ttraining's binary_logloss: 0.614615\n",
      "[2891]\ttraining's binary_logloss: 0.614566\n",
      "[2892]\ttraining's binary_logloss: 0.614457\n",
      "[2893]\ttraining's binary_logloss: 0.614381\n",
      "[2894]\ttraining's binary_logloss: 0.614296\n",
      "[2895]\ttraining's binary_logloss: 0.614193\n",
      "[2896]\ttraining's binary_logloss: 0.614105\n",
      "[2897]\ttraining's binary_logloss: 0.614\n",
      "[2898]\ttraining's binary_logloss: 0.613938\n",
      "[2899]\ttraining's binary_logloss: 0.613825\n",
      "[2900]\ttraining's binary_logloss: 0.613745\n",
      "[2901]\ttraining's binary_logloss: 0.61364\n",
      "[2902]\ttraining's binary_logloss: 0.613584\n",
      "[2903]\ttraining's binary_logloss: 0.613492\n",
      "[2904]\ttraining's binary_logloss: 0.613419\n",
      "[2905]\ttraining's binary_logloss: 0.613315\n",
      "[2906]\ttraining's binary_logloss: 0.613232\n",
      "[2907]\ttraining's binary_logloss: 0.613161\n",
      "[2908]\ttraining's binary_logloss: 0.613073\n",
      "[2909]\ttraining's binary_logloss: 0.612991\n",
      "[2910]\ttraining's binary_logloss: 0.612918\n",
      "[2911]\ttraining's binary_logloss: 0.612851\n",
      "[2912]\ttraining's binary_logloss: 0.61278\n",
      "[2913]\ttraining's binary_logloss: 0.612696\n",
      "[2914]\ttraining's binary_logloss: 0.612612\n",
      "[2915]\ttraining's binary_logloss: 0.612541\n",
      "[2916]\ttraining's binary_logloss: 0.612476\n",
      "[2917]\ttraining's binary_logloss: 0.612387\n",
      "[2918]\ttraining's binary_logloss: 0.612289\n",
      "[2919]\ttraining's binary_logloss: 0.612206\n",
      "[2920]\ttraining's binary_logloss: 0.612119\n",
      "[2921]\ttraining's binary_logloss: 0.612043\n",
      "[2922]\ttraining's binary_logloss: 0.611974\n",
      "[2923]\ttraining's binary_logloss: 0.611894\n",
      "[2924]\ttraining's binary_logloss: 0.611811\n",
      "[2925]\ttraining's binary_logloss: 0.611758\n",
      "[2926]\ttraining's binary_logloss: 0.611648\n",
      "[2927]\ttraining's binary_logloss: 0.611559\n",
      "[2928]\ttraining's binary_logloss: 0.611498\n",
      "[2929]\ttraining's binary_logloss: 0.611403\n",
      "[2930]\ttraining's binary_logloss: 0.611316\n",
      "[2931]\ttraining's binary_logloss: 0.611208\n",
      "[2932]\ttraining's binary_logloss: 0.611101\n",
      "[2933]\ttraining's binary_logloss: 0.610996\n",
      "[2934]\ttraining's binary_logloss: 0.610901\n",
      "[2935]\ttraining's binary_logloss: 0.610813\n",
      "[2936]\ttraining's binary_logloss: 0.610714\n",
      "[2937]\ttraining's binary_logloss: 0.61065\n",
      "[2938]\ttraining's binary_logloss: 0.61054\n",
      "[2939]\ttraining's binary_logloss: 0.610461\n",
      "[2940]\ttraining's binary_logloss: 0.610389\n",
      "[2941]\ttraining's binary_logloss: 0.610299\n",
      "[2942]\ttraining's binary_logloss: 0.610233\n",
      "[2943]\ttraining's binary_logloss: 0.610132\n",
      "[2944]\ttraining's binary_logloss: 0.610065\n",
      "[2945]\ttraining's binary_logloss: 0.609996\n",
      "[2946]\ttraining's binary_logloss: 0.60991\n",
      "[2947]\ttraining's binary_logloss: 0.609824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2948]\ttraining's binary_logloss: 0.609718\n",
      "[2949]\ttraining's binary_logloss: 0.609616\n",
      "[2950]\ttraining's binary_logloss: 0.609493\n",
      "[2951]\ttraining's binary_logloss: 0.609393\n",
      "[2952]\ttraining's binary_logloss: 0.609334\n",
      "[2953]\ttraining's binary_logloss: 0.609251\n",
      "[2954]\ttraining's binary_logloss: 0.60914\n",
      "[2955]\ttraining's binary_logloss: 0.609078\n",
      "[2956]\ttraining's binary_logloss: 0.608992\n",
      "[2957]\ttraining's binary_logloss: 0.608914\n",
      "[2958]\ttraining's binary_logloss: 0.608821\n",
      "[2959]\ttraining's binary_logloss: 0.608755\n",
      "[2960]\ttraining's binary_logloss: 0.608694\n",
      "[2961]\ttraining's binary_logloss: 0.608605\n",
      "[2962]\ttraining's binary_logloss: 0.608535\n",
      "[2963]\ttraining's binary_logloss: 0.608467\n",
      "[2964]\ttraining's binary_logloss: 0.6084\n",
      "[2965]\ttraining's binary_logloss: 0.608315\n",
      "[2966]\ttraining's binary_logloss: 0.608248\n",
      "[2967]\ttraining's binary_logloss: 0.608154\n",
      "[2968]\ttraining's binary_logloss: 0.608046\n",
      "[2969]\ttraining's binary_logloss: 0.607957\n",
      "[2970]\ttraining's binary_logloss: 0.607874\n",
      "[2971]\ttraining's binary_logloss: 0.607817\n",
      "[2972]\ttraining's binary_logloss: 0.607713\n",
      "[2973]\ttraining's binary_logloss: 0.607598\n",
      "[2974]\ttraining's binary_logloss: 0.607523\n",
      "[2975]\ttraining's binary_logloss: 0.607443\n",
      "[2976]\ttraining's binary_logloss: 0.607355\n",
      "[2977]\ttraining's binary_logloss: 0.607258\n",
      "[2978]\ttraining's binary_logloss: 0.607175\n",
      "[2979]\ttraining's binary_logloss: 0.607097\n",
      "[2980]\ttraining's binary_logloss: 0.607033\n",
      "[2981]\ttraining's binary_logloss: 0.606921\n",
      "[2982]\ttraining's binary_logloss: 0.60681\n",
      "[2983]\ttraining's binary_logloss: 0.606749\n",
      "[2984]\ttraining's binary_logloss: 0.60666\n",
      "[2985]\ttraining's binary_logloss: 0.606583\n",
      "[2986]\ttraining's binary_logloss: 0.606478\n",
      "[2987]\ttraining's binary_logloss: 0.606394\n",
      "[2988]\ttraining's binary_logloss: 0.606327\n",
      "[2989]\ttraining's binary_logloss: 0.606246\n",
      "[2990]\ttraining's binary_logloss: 0.606164\n",
      "[2991]\ttraining's binary_logloss: 0.606063\n",
      "[2992]\ttraining's binary_logloss: 0.605972\n",
      "[2993]\ttraining's binary_logloss: 0.605887\n",
      "[2994]\ttraining's binary_logloss: 0.605766\n",
      "[2995]\ttraining's binary_logloss: 0.605692\n",
      "[2996]\ttraining's binary_logloss: 0.605621\n",
      "[2997]\ttraining's binary_logloss: 0.605517\n",
      "[2998]\ttraining's binary_logloss: 0.605452\n",
      "[2999]\ttraining's binary_logloss: 0.605398\n",
      "[3000]\ttraining's binary_logloss: 0.605304\n",
      "[3001]\ttraining's binary_logloss: 0.605248\n",
      "[3002]\ttraining's binary_logloss: 0.605144\n",
      "[3003]\ttraining's binary_logloss: 0.605052\n",
      "[3004]\ttraining's binary_logloss: 0.604979\n",
      "[3005]\ttraining's binary_logloss: 0.604894\n",
      "[3006]\ttraining's binary_logloss: 0.604826\n",
      "[3007]\ttraining's binary_logloss: 0.604742\n",
      "[3008]\ttraining's binary_logloss: 0.604644\n",
      "[3009]\ttraining's binary_logloss: 0.604551\n",
      "[3010]\ttraining's binary_logloss: 0.604484\n",
      "[3011]\ttraining's binary_logloss: 0.604382\n",
      "[3012]\ttraining's binary_logloss: 0.604305\n",
      "[3013]\ttraining's binary_logloss: 0.604228\n",
      "[3014]\ttraining's binary_logloss: 0.604152\n",
      "[3015]\ttraining's binary_logloss: 0.604044\n",
      "[3016]\ttraining's binary_logloss: 0.603913\n",
      "[3017]\ttraining's binary_logloss: 0.603866\n",
      "[3018]\ttraining's binary_logloss: 0.603788\n",
      "[3019]\ttraining's binary_logloss: 0.603717\n",
      "[3020]\ttraining's binary_logloss: 0.603643\n",
      "[3021]\ttraining's binary_logloss: 0.603569\n",
      "[3022]\ttraining's binary_logloss: 0.603476\n",
      "[3023]\ttraining's binary_logloss: 0.603382\n",
      "[3024]\ttraining's binary_logloss: 0.603312\n",
      "[3025]\ttraining's binary_logloss: 0.603245\n",
      "[3026]\ttraining's binary_logloss: 0.603127\n",
      "[3027]\ttraining's binary_logloss: 0.603029\n",
      "[3028]\ttraining's binary_logloss: 0.602959\n",
      "[3029]\ttraining's binary_logloss: 0.602894\n",
      "[3030]\ttraining's binary_logloss: 0.602832\n",
      "[3031]\ttraining's binary_logloss: 0.602745\n",
      "[3032]\ttraining's binary_logloss: 0.602645\n",
      "[3033]\ttraining's binary_logloss: 0.602542\n",
      "[3034]\ttraining's binary_logloss: 0.60247\n",
      "[3035]\ttraining's binary_logloss: 0.602389\n",
      "[3036]\ttraining's binary_logloss: 0.602297\n",
      "[3037]\ttraining's binary_logloss: 0.60221\n",
      "[3038]\ttraining's binary_logloss: 0.602133\n",
      "[3039]\ttraining's binary_logloss: 0.60204\n",
      "[3040]\ttraining's binary_logloss: 0.601925\n",
      "[3041]\ttraining's binary_logloss: 0.601856\n",
      "[3042]\ttraining's binary_logloss: 0.601781\n",
      "[3043]\ttraining's binary_logloss: 0.601705\n",
      "[3044]\ttraining's binary_logloss: 0.601634\n",
      "[3045]\ttraining's binary_logloss: 0.601533\n",
      "[3046]\ttraining's binary_logloss: 0.601459\n",
      "[3047]\ttraining's binary_logloss: 0.601402\n",
      "[3048]\ttraining's binary_logloss: 0.601316\n",
      "[3049]\ttraining's binary_logloss: 0.601236\n",
      "[3050]\ttraining's binary_logloss: 0.601171\n",
      "[3051]\ttraining's binary_logloss: 0.601075\n",
      "[3052]\ttraining's binary_logloss: 0.601013\n",
      "[3053]\ttraining's binary_logloss: 0.600947\n",
      "[3054]\ttraining's binary_logloss: 0.600895\n",
      "[3055]\ttraining's binary_logloss: 0.600821\n",
      "[3056]\ttraining's binary_logloss: 0.600734\n",
      "[3057]\ttraining's binary_logloss: 0.600643\n",
      "[3058]\ttraining's binary_logloss: 0.600548\n",
      "[3059]\ttraining's binary_logloss: 0.600477\n",
      "[3060]\ttraining's binary_logloss: 0.600385\n",
      "[3061]\ttraining's binary_logloss: 0.600281\n",
      "[3062]\ttraining's binary_logloss: 0.600195\n",
      "[3063]\ttraining's binary_logloss: 0.600127\n",
      "[3064]\ttraining's binary_logloss: 0.600065\n",
      "[3065]\ttraining's binary_logloss: 0.599989\n",
      "[3066]\ttraining's binary_logloss: 0.599923\n",
      "[3067]\ttraining's binary_logloss: 0.599844\n",
      "[3068]\ttraining's binary_logloss: 0.599794\n",
      "[3069]\ttraining's binary_logloss: 0.599698\n",
      "[3070]\ttraining's binary_logloss: 0.599613\n",
      "[3071]\ttraining's binary_logloss: 0.599555\n",
      "[3072]\ttraining's binary_logloss: 0.599492\n",
      "[3073]\ttraining's binary_logloss: 0.599416\n",
      "[3074]\ttraining's binary_logloss: 0.599322\n",
      "[3075]\ttraining's binary_logloss: 0.599219\n",
      "[3076]\ttraining's binary_logloss: 0.599122\n",
      "[3077]\ttraining's binary_logloss: 0.599034\n",
      "[3078]\ttraining's binary_logloss: 0.598951\n",
      "[3079]\ttraining's binary_logloss: 0.598896\n",
      "[3080]\ttraining's binary_logloss: 0.598779\n",
      "[3081]\ttraining's binary_logloss: 0.598658\n",
      "[3082]\ttraining's binary_logloss: 0.598529\n",
      "[3083]\ttraining's binary_logloss: 0.598443\n",
      "[3084]\ttraining's binary_logloss: 0.598368\n",
      "[3085]\ttraining's binary_logloss: 0.598294\n",
      "[3086]\ttraining's binary_logloss: 0.59822\n",
      "[3087]\ttraining's binary_logloss: 0.598129\n",
      "[3088]\ttraining's binary_logloss: 0.598028\n",
      "[3089]\ttraining's binary_logloss: 0.597953\n",
      "[3090]\ttraining's binary_logloss: 0.597865\n",
      "[3091]\ttraining's binary_logloss: 0.597796\n",
      "[3092]\ttraining's binary_logloss: 0.59772\n",
      "[3093]\ttraining's binary_logloss: 0.59765\n",
      "[3094]\ttraining's binary_logloss: 0.597541\n",
      "[3095]\ttraining's binary_logloss: 0.597481\n",
      "[3096]\ttraining's binary_logloss: 0.5974\n",
      "[3097]\ttraining's binary_logloss: 0.597321\n",
      "[3098]\ttraining's binary_logloss: 0.597266\n",
      "[3099]\ttraining's binary_logloss: 0.597179\n",
      "[3100]\ttraining's binary_logloss: 0.597132\n",
      "[3101]\ttraining's binary_logloss: 0.597055\n",
      "[3102]\ttraining's binary_logloss: 0.596982\n",
      "[3103]\ttraining's binary_logloss: 0.596898\n",
      "[3104]\ttraining's binary_logloss: 0.596803\n",
      "[3105]\ttraining's binary_logloss: 0.596738\n",
      "[3106]\ttraining's binary_logloss: 0.596661\n",
      "[3107]\ttraining's binary_logloss: 0.596567\n",
      "[3108]\ttraining's binary_logloss: 0.596485\n",
      "[3109]\ttraining's binary_logloss: 0.596416\n",
      "[3110]\ttraining's binary_logloss: 0.596334\n",
      "[3111]\ttraining's binary_logloss: 0.596256\n",
      "[3112]\ttraining's binary_logloss: 0.596199\n",
      "[3113]\ttraining's binary_logloss: 0.596129\n",
      "[3114]\ttraining's binary_logloss: 0.596025\n",
      "[3115]\ttraining's binary_logloss: 0.595925\n",
      "[3116]\ttraining's binary_logloss: 0.595858\n",
      "[3117]\ttraining's binary_logloss: 0.595785\n",
      "[3118]\ttraining's binary_logloss: 0.595719\n",
      "[3119]\ttraining's binary_logloss: 0.595659\n",
      "[3120]\ttraining's binary_logloss: 0.595564\n",
      "[3121]\ttraining's binary_logloss: 0.595488\n",
      "[3122]\ttraining's binary_logloss: 0.595425\n",
      "[3123]\ttraining's binary_logloss: 0.595338\n",
      "[3124]\ttraining's binary_logloss: 0.595275\n",
      "[3125]\ttraining's binary_logloss: 0.595197\n",
      "[3126]\ttraining's binary_logloss: 0.595123\n",
      "[3127]\ttraining's binary_logloss: 0.595024\n",
      "[3128]\ttraining's binary_logloss: 0.594956\n",
      "[3129]\ttraining's binary_logloss: 0.594882\n",
      "[3130]\ttraining's binary_logloss: 0.594795\n",
      "[3131]\ttraining's binary_logloss: 0.594723\n",
      "[3132]\ttraining's binary_logloss: 0.594651\n",
      "[3133]\ttraining's binary_logloss: 0.594548\n",
      "[3134]\ttraining's binary_logloss: 0.59447\n",
      "[3135]\ttraining's binary_logloss: 0.594395\n",
      "[3136]\ttraining's binary_logloss: 0.594284\n",
      "[3137]\ttraining's binary_logloss: 0.594213\n",
      "[3138]\ttraining's binary_logloss: 0.594156\n",
      "[3139]\ttraining's binary_logloss: 0.594096\n",
      "[3140]\ttraining's binary_logloss: 0.594016\n",
      "[3141]\ttraining's binary_logloss: 0.593919\n",
      "[3142]\ttraining's binary_logloss: 0.593838\n",
      "[3143]\ttraining's binary_logloss: 0.593776\n",
      "[3144]\ttraining's binary_logloss: 0.593681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3145]\ttraining's binary_logloss: 0.593596\n",
      "[3146]\ttraining's binary_logloss: 0.593533\n",
      "[3147]\ttraining's binary_logloss: 0.593437\n",
      "[3148]\ttraining's binary_logloss: 0.59334\n",
      "[3149]\ttraining's binary_logloss: 0.593258\n",
      "[3150]\ttraining's binary_logloss: 0.593185\n",
      "[3151]\ttraining's binary_logloss: 0.593114\n",
      "[3152]\ttraining's binary_logloss: 0.593066\n",
      "[3153]\ttraining's binary_logloss: 0.592999\n",
      "[3154]\ttraining's binary_logloss: 0.59292\n",
      "[3155]\ttraining's binary_logloss: 0.592839\n",
      "[3156]\ttraining's binary_logloss: 0.59278\n",
      "[3157]\ttraining's binary_logloss: 0.592706\n",
      "[3158]\ttraining's binary_logloss: 0.592618\n",
      "[3159]\ttraining's binary_logloss: 0.592567\n",
      "[3160]\ttraining's binary_logloss: 0.592497\n",
      "[3161]\ttraining's binary_logloss: 0.592412\n",
      "[3162]\ttraining's binary_logloss: 0.592346\n",
      "[3163]\ttraining's binary_logloss: 0.592269\n",
      "[3164]\ttraining's binary_logloss: 0.592202\n",
      "[3165]\ttraining's binary_logloss: 0.592144\n",
      "[3166]\ttraining's binary_logloss: 0.592069\n",
      "[3167]\ttraining's binary_logloss: 0.591977\n",
      "[3168]\ttraining's binary_logloss: 0.591894\n",
      "[3169]\ttraining's binary_logloss: 0.591804\n",
      "[3170]\ttraining's binary_logloss: 0.591731\n",
      "[3171]\ttraining's binary_logloss: 0.591669\n",
      "[3172]\ttraining's binary_logloss: 0.591578\n",
      "[3173]\ttraining's binary_logloss: 0.591517\n",
      "[3174]\ttraining's binary_logloss: 0.591444\n",
      "[3175]\ttraining's binary_logloss: 0.591371\n",
      "[3176]\ttraining's binary_logloss: 0.591308\n",
      "[3177]\ttraining's binary_logloss: 0.591236\n",
      "[3178]\ttraining's binary_logloss: 0.591163\n",
      "[3179]\ttraining's binary_logloss: 0.591074\n",
      "[3180]\ttraining's binary_logloss: 0.590989\n",
      "[3181]\ttraining's binary_logloss: 0.590936\n",
      "[3182]\ttraining's binary_logloss: 0.590866\n",
      "[3183]\ttraining's binary_logloss: 0.590774\n",
      "[3184]\ttraining's binary_logloss: 0.590714\n",
      "[3185]\ttraining's binary_logloss: 0.59064\n",
      "[3186]\ttraining's binary_logloss: 0.590559\n",
      "[3187]\ttraining's binary_logloss: 0.590465\n",
      "[3188]\ttraining's binary_logloss: 0.590394\n",
      "[3189]\ttraining's binary_logloss: 0.590315\n",
      "[3190]\ttraining's binary_logloss: 0.590242\n",
      "[3191]\ttraining's binary_logloss: 0.590147\n",
      "[3192]\ttraining's binary_logloss: 0.590078\n",
      "[3193]\ttraining's binary_logloss: 0.590013\n",
      "[3194]\ttraining's binary_logloss: 0.589912\n",
      "[3195]\ttraining's binary_logloss: 0.58985\n",
      "[3196]\ttraining's binary_logloss: 0.589763\n",
      "[3197]\ttraining's binary_logloss: 0.5897\n",
      "[3198]\ttraining's binary_logloss: 0.589608\n",
      "[3199]\ttraining's binary_logloss: 0.589546\n",
      "[3200]\ttraining's binary_logloss: 0.589444\n",
      "[3201]\ttraining's binary_logloss: 0.589387\n",
      "[3202]\ttraining's binary_logloss: 0.589338\n",
      "[3203]\ttraining's binary_logloss: 0.58927\n",
      "[3204]\ttraining's binary_logloss: 0.589185\n",
      "[3205]\ttraining's binary_logloss: 0.58912\n",
      "[3206]\ttraining's binary_logloss: 0.589051\n",
      "[3207]\ttraining's binary_logloss: 0.588985\n",
      "[3208]\ttraining's binary_logloss: 0.588921\n",
      "[3209]\ttraining's binary_logloss: 0.588834\n",
      "[3210]\ttraining's binary_logloss: 0.588766\n",
      "[3211]\ttraining's binary_logloss: 0.588699\n",
      "[3212]\ttraining's binary_logloss: 0.588639\n",
      "[3213]\ttraining's binary_logloss: 0.588568\n",
      "[3214]\ttraining's binary_logloss: 0.588504\n",
      "[3215]\ttraining's binary_logloss: 0.588437\n",
      "[3216]\ttraining's binary_logloss: 0.588339\n",
      "[3217]\ttraining's binary_logloss: 0.588278\n",
      "[3218]\ttraining's binary_logloss: 0.588212\n",
      "[3219]\ttraining's binary_logloss: 0.588124\n",
      "[3220]\ttraining's binary_logloss: 0.588009\n",
      "[3221]\ttraining's binary_logloss: 0.587928\n",
      "[3222]\ttraining's binary_logloss: 0.587855\n",
      "[3223]\ttraining's binary_logloss: 0.587798\n",
      "[3224]\ttraining's binary_logloss: 0.587717\n",
      "[3225]\ttraining's binary_logloss: 0.587661\n",
      "[3226]\ttraining's binary_logloss: 0.587584\n",
      "[3227]\ttraining's binary_logloss: 0.587488\n",
      "[3228]\ttraining's binary_logloss: 0.587416\n",
      "[3229]\ttraining's binary_logloss: 0.587333\n",
      "[3230]\ttraining's binary_logloss: 0.587269\n",
      "[3231]\ttraining's binary_logloss: 0.587185\n",
      "[3232]\ttraining's binary_logloss: 0.587093\n",
      "[3233]\ttraining's binary_logloss: 0.587\n",
      "[3234]\ttraining's binary_logloss: 0.586935\n",
      "[3235]\ttraining's binary_logloss: 0.586822\n",
      "[3236]\ttraining's binary_logloss: 0.586728\n",
      "[3237]\ttraining's binary_logloss: 0.586645\n",
      "[3238]\ttraining's binary_logloss: 0.586565\n",
      "[3239]\ttraining's binary_logloss: 0.586513\n",
      "[3240]\ttraining's binary_logloss: 0.586454\n",
      "[3241]\ttraining's binary_logloss: 0.586372\n",
      "[3242]\ttraining's binary_logloss: 0.586253\n",
      "[3243]\ttraining's binary_logloss: 0.58617\n",
      "[3244]\ttraining's binary_logloss: 0.586097\n",
      "[3245]\ttraining's binary_logloss: 0.586021\n",
      "[3246]\ttraining's binary_logloss: 0.585936\n",
      "[3247]\ttraining's binary_logloss: 0.585849\n",
      "[3248]\ttraining's binary_logloss: 0.585755\n",
      "[3249]\ttraining's binary_logloss: 0.585671\n",
      "[3250]\ttraining's binary_logloss: 0.585594\n",
      "[3251]\ttraining's binary_logloss: 0.585554\n",
      "[3252]\ttraining's binary_logloss: 0.585493\n",
      "[3253]\ttraining's binary_logloss: 0.585425\n",
      "[3254]\ttraining's binary_logloss: 0.585361\n",
      "[3255]\ttraining's binary_logloss: 0.585282\n",
      "[3256]\ttraining's binary_logloss: 0.585215\n",
      "[3257]\ttraining's binary_logloss: 0.585119\n",
      "[3258]\ttraining's binary_logloss: 0.585038\n",
      "[3259]\ttraining's binary_logloss: 0.584935\n",
      "[3260]\ttraining's binary_logloss: 0.584874\n",
      "[3261]\ttraining's binary_logloss: 0.584785\n",
      "[3262]\ttraining's binary_logloss: 0.584699\n",
      "[3263]\ttraining's binary_logloss: 0.584631\n",
      "[3264]\ttraining's binary_logloss: 0.584569\n",
      "[3265]\ttraining's binary_logloss: 0.584493\n",
      "[3266]\ttraining's binary_logloss: 0.584427\n",
      "[3267]\ttraining's binary_logloss: 0.584361\n",
      "[3268]\ttraining's binary_logloss: 0.584308\n",
      "[3269]\ttraining's binary_logloss: 0.584212\n",
      "[3270]\ttraining's binary_logloss: 0.584134\n",
      "[3271]\ttraining's binary_logloss: 0.584077\n",
      "[3272]\ttraining's binary_logloss: 0.584023\n",
      "[3273]\ttraining's binary_logloss: 0.583929\n",
      "[3274]\ttraining's binary_logloss: 0.583844\n",
      "[3275]\ttraining's binary_logloss: 0.583775\n",
      "[3276]\ttraining's binary_logloss: 0.583693\n",
      "[3277]\ttraining's binary_logloss: 0.583639\n",
      "[3278]\ttraining's binary_logloss: 0.583585\n",
      "[3279]\ttraining's binary_logloss: 0.583508\n",
      "[3280]\ttraining's binary_logloss: 0.583415\n",
      "[3281]\ttraining's binary_logloss: 0.583337\n",
      "[3282]\ttraining's binary_logloss: 0.583261\n",
      "[3283]\ttraining's binary_logloss: 0.583186\n",
      "[3284]\ttraining's binary_logloss: 0.583092\n",
      "[3285]\ttraining's binary_logloss: 0.582981\n",
      "[3286]\ttraining's binary_logloss: 0.582896\n",
      "[3287]\ttraining's binary_logloss: 0.582814\n",
      "[3288]\ttraining's binary_logloss: 0.582741\n",
      "[3289]\ttraining's binary_logloss: 0.582655\n",
      "[3290]\ttraining's binary_logloss: 0.582567\n",
      "[3291]\ttraining's binary_logloss: 0.582476\n",
      "[3292]\ttraining's binary_logloss: 0.582416\n",
      "[3293]\ttraining's binary_logloss: 0.582339\n",
      "[3294]\ttraining's binary_logloss: 0.582269\n",
      "[3295]\ttraining's binary_logloss: 0.582195\n",
      "[3296]\ttraining's binary_logloss: 0.582121\n",
      "[3297]\ttraining's binary_logloss: 0.582033\n",
      "[3298]\ttraining's binary_logloss: 0.581962\n",
      "[3299]\ttraining's binary_logloss: 0.581888\n",
      "[3300]\ttraining's binary_logloss: 0.581817\n",
      "[3301]\ttraining's binary_logloss: 0.581742\n",
      "[3302]\ttraining's binary_logloss: 0.581642\n",
      "[3303]\ttraining's binary_logloss: 0.58158\n",
      "[3304]\ttraining's binary_logloss: 0.581503\n",
      "[3305]\ttraining's binary_logloss: 0.581421\n",
      "[3306]\ttraining's binary_logloss: 0.581361\n",
      "[3307]\ttraining's binary_logloss: 0.581272\n",
      "[3308]\ttraining's binary_logloss: 0.581175\n",
      "[3309]\ttraining's binary_logloss: 0.581113\n",
      "[3310]\ttraining's binary_logloss: 0.581041\n",
      "[3311]\ttraining's binary_logloss: 0.580989\n",
      "[3312]\ttraining's binary_logloss: 0.580891\n",
      "[3313]\ttraining's binary_logloss: 0.580819\n",
      "[3314]\ttraining's binary_logloss: 0.580768\n",
      "[3315]\ttraining's binary_logloss: 0.580697\n",
      "[3316]\ttraining's binary_logloss: 0.58061\n",
      "[3317]\ttraining's binary_logloss: 0.580528\n",
      "[3318]\ttraining's binary_logloss: 0.580473\n",
      "[3319]\ttraining's binary_logloss: 0.580402\n",
      "[3320]\ttraining's binary_logloss: 0.580325\n",
      "[3321]\ttraining's binary_logloss: 0.580249\n",
      "[3322]\ttraining's binary_logloss: 0.580152\n",
      "[3323]\ttraining's binary_logloss: 0.580078\n",
      "[3324]\ttraining's binary_logloss: 0.579999\n",
      "[3325]\ttraining's binary_logloss: 0.579918\n",
      "[3326]\ttraining's binary_logloss: 0.579844\n",
      "[3327]\ttraining's binary_logloss: 0.579783\n",
      "[3328]\ttraining's binary_logloss: 0.579714\n",
      "[3329]\ttraining's binary_logloss: 0.579631\n",
      "[3330]\ttraining's binary_logloss: 0.579566\n",
      "[3331]\ttraining's binary_logloss: 0.579499\n",
      "[3332]\ttraining's binary_logloss: 0.57941\n",
      "[3333]\ttraining's binary_logloss: 0.579351\n",
      "[3334]\ttraining's binary_logloss: 0.579288\n",
      "[3335]\ttraining's binary_logloss: 0.579226\n",
      "[3336]\ttraining's binary_logloss: 0.579132\n",
      "[3337]\ttraining's binary_logloss: 0.579044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3338]\ttraining's binary_logloss: 0.578972\n",
      "[3339]\ttraining's binary_logloss: 0.578922\n",
      "[3340]\ttraining's binary_logloss: 0.578855\n",
      "[3341]\ttraining's binary_logloss: 0.578778\n",
      "[3342]\ttraining's binary_logloss: 0.578671\n",
      "[3343]\ttraining's binary_logloss: 0.578593\n",
      "[3344]\ttraining's binary_logloss: 0.578501\n",
      "[3345]\ttraining's binary_logloss: 0.578419\n",
      "[3346]\ttraining's binary_logloss: 0.578333\n",
      "[3347]\ttraining's binary_logloss: 0.578228\n",
      "[3348]\ttraining's binary_logloss: 0.578166\n",
      "[3349]\ttraining's binary_logloss: 0.578084\n",
      "[3350]\ttraining's binary_logloss: 0.578021\n",
      "[3351]\ttraining's binary_logloss: 0.577941\n",
      "[3352]\ttraining's binary_logloss: 0.577868\n",
      "[3353]\ttraining's binary_logloss: 0.577816\n",
      "[3354]\ttraining's binary_logloss: 0.577749\n",
      "[3355]\ttraining's binary_logloss: 0.577673\n",
      "[3356]\ttraining's binary_logloss: 0.57761\n",
      "[3357]\ttraining's binary_logloss: 0.57753\n",
      "[3358]\ttraining's binary_logloss: 0.577456\n",
      "[3359]\ttraining's binary_logloss: 0.577376\n",
      "[3360]\ttraining's binary_logloss: 0.577294\n",
      "[3361]\ttraining's binary_logloss: 0.577245\n",
      "[3362]\ttraining's binary_logloss: 0.577156\n",
      "[3363]\ttraining's binary_logloss: 0.57707\n",
      "[3364]\ttraining's binary_logloss: 0.576994\n",
      "[3365]\ttraining's binary_logloss: 0.57689\n",
      "[3366]\ttraining's binary_logloss: 0.576833\n",
      "[3367]\ttraining's binary_logloss: 0.576778\n",
      "[3368]\ttraining's binary_logloss: 0.576724\n",
      "[3369]\ttraining's binary_logloss: 0.576647\n",
      "[3370]\ttraining's binary_logloss: 0.576585\n",
      "[3371]\ttraining's binary_logloss: 0.576496\n",
      "[3372]\ttraining's binary_logloss: 0.57639\n",
      "[3373]\ttraining's binary_logloss: 0.576329\n",
      "[3374]\ttraining's binary_logloss: 0.576273\n",
      "[3375]\ttraining's binary_logloss: 0.576201\n",
      "[3376]\ttraining's binary_logloss: 0.576127\n",
      "[3377]\ttraining's binary_logloss: 0.576064\n",
      "[3378]\ttraining's binary_logloss: 0.576022\n",
      "[3379]\ttraining's binary_logloss: 0.575969\n",
      "[3380]\ttraining's binary_logloss: 0.575859\n",
      "[3381]\ttraining's binary_logloss: 0.57579\n",
      "[3382]\ttraining's binary_logloss: 0.575704\n",
      "[3383]\ttraining's binary_logloss: 0.575603\n",
      "[3384]\ttraining's binary_logloss: 0.575542\n",
      "[3385]\ttraining's binary_logloss: 0.575469\n",
      "[3386]\ttraining's binary_logloss: 0.575398\n",
      "[3387]\ttraining's binary_logloss: 0.57531\n",
      "[3388]\ttraining's binary_logloss: 0.575252\n",
      "[3389]\ttraining's binary_logloss: 0.575174\n",
      "[3390]\ttraining's binary_logloss: 0.575097\n",
      "[3391]\ttraining's binary_logloss: 0.575025\n",
      "[3392]\ttraining's binary_logloss: 0.57495\n",
      "[3393]\ttraining's binary_logloss: 0.574844\n",
      "[3394]\ttraining's binary_logloss: 0.574776\n",
      "[3395]\ttraining's binary_logloss: 0.574704\n",
      "[3396]\ttraining's binary_logloss: 0.574625\n",
      "[3397]\ttraining's binary_logloss: 0.574573\n",
      "[3398]\ttraining's binary_logloss: 0.574502\n",
      "[3399]\ttraining's binary_logloss: 0.574442\n",
      "[3400]\ttraining's binary_logloss: 0.574382\n",
      "[3401]\ttraining's binary_logloss: 0.574317\n",
      "[3402]\ttraining's binary_logloss: 0.574262\n",
      "[3403]\ttraining's binary_logloss: 0.574195\n",
      "[3404]\ttraining's binary_logloss: 0.574121\n",
      "[3405]\ttraining's binary_logloss: 0.57406\n",
      "[3406]\ttraining's binary_logloss: 0.573992\n",
      "[3407]\ttraining's binary_logloss: 0.57389\n",
      "[3408]\ttraining's binary_logloss: 0.573825\n",
      "[3409]\ttraining's binary_logloss: 0.573724\n",
      "[3410]\ttraining's binary_logloss: 0.573645\n",
      "[3411]\ttraining's binary_logloss: 0.573584\n",
      "[3412]\ttraining's binary_logloss: 0.573502\n",
      "[3413]\ttraining's binary_logloss: 0.573428\n",
      "[3414]\ttraining's binary_logloss: 0.573369\n",
      "[3415]\ttraining's binary_logloss: 0.573301\n",
      "[3416]\ttraining's binary_logloss: 0.573205\n",
      "[3417]\ttraining's binary_logloss: 0.573133\n",
      "[3418]\ttraining's binary_logloss: 0.573065\n",
      "[3419]\ttraining's binary_logloss: 0.572987\n",
      "[3420]\ttraining's binary_logloss: 0.572895\n",
      "[3421]\ttraining's binary_logloss: 0.572844\n",
      "[3422]\ttraining's binary_logloss: 0.572781\n",
      "[3423]\ttraining's binary_logloss: 0.572702\n",
      "[3424]\ttraining's binary_logloss: 0.572599\n",
      "[3425]\ttraining's binary_logloss: 0.572529\n",
      "[3426]\ttraining's binary_logloss: 0.572432\n",
      "[3427]\ttraining's binary_logloss: 0.572362\n",
      "[3428]\ttraining's binary_logloss: 0.5723\n",
      "[3429]\ttraining's binary_logloss: 0.57223\n",
      "[3430]\ttraining's binary_logloss: 0.572172\n",
      "[3431]\ttraining's binary_logloss: 0.5721\n",
      "[3432]\ttraining's binary_logloss: 0.572026\n",
      "[3433]\ttraining's binary_logloss: 0.571951\n",
      "[3434]\ttraining's binary_logloss: 0.571874\n",
      "[3435]\ttraining's binary_logloss: 0.571814\n",
      "[3436]\ttraining's binary_logloss: 0.571748\n",
      "[3437]\ttraining's binary_logloss: 0.571656\n",
      "[3438]\ttraining's binary_logloss: 0.571571\n",
      "[3439]\ttraining's binary_logloss: 0.571506\n",
      "[3440]\ttraining's binary_logloss: 0.571443\n",
      "[3441]\ttraining's binary_logloss: 0.571371\n",
      "[3442]\ttraining's binary_logloss: 0.571314\n",
      "[3443]\ttraining's binary_logloss: 0.571251\n",
      "[3444]\ttraining's binary_logloss: 0.571153\n",
      "[3445]\ttraining's binary_logloss: 0.571099\n",
      "[3446]\ttraining's binary_logloss: 0.571025\n",
      "[3447]\ttraining's binary_logloss: 0.570965\n",
      "[3448]\ttraining's binary_logloss: 0.570891\n",
      "[3449]\ttraining's binary_logloss: 0.57082\n",
      "[3450]\ttraining's binary_logloss: 0.570729\n",
      "[3451]\ttraining's binary_logloss: 0.570633\n",
      "[3452]\ttraining's binary_logloss: 0.570561\n",
      "[3453]\ttraining's binary_logloss: 0.570474\n",
      "[3454]\ttraining's binary_logloss: 0.570403\n",
      "[3455]\ttraining's binary_logloss: 0.570307\n",
      "[3456]\ttraining's binary_logloss: 0.570234\n",
      "[3457]\ttraining's binary_logloss: 0.570181\n",
      "[3458]\ttraining's binary_logloss: 0.570108\n",
      "[3459]\ttraining's binary_logloss: 0.570057\n",
      "[3460]\ttraining's binary_logloss: 0.569985\n",
      "[3461]\ttraining's binary_logloss: 0.569924\n",
      "[3462]\ttraining's binary_logloss: 0.569832\n",
      "[3463]\ttraining's binary_logloss: 0.569751\n",
      "[3464]\ttraining's binary_logloss: 0.569666\n",
      "[3465]\ttraining's binary_logloss: 0.56962\n",
      "[3466]\ttraining's binary_logloss: 0.56953\n",
      "[3467]\ttraining's binary_logloss: 0.569451\n",
      "[3468]\ttraining's binary_logloss: 0.569386\n",
      "[3469]\ttraining's binary_logloss: 0.569312\n",
      "[3470]\ttraining's binary_logloss: 0.569253\n",
      "[3471]\ttraining's binary_logloss: 0.569193\n",
      "[3472]\ttraining's binary_logloss: 0.569123\n",
      "[3473]\ttraining's binary_logloss: 0.569054\n",
      "[3474]\ttraining's binary_logloss: 0.568978\n",
      "[3475]\ttraining's binary_logloss: 0.568895\n",
      "[3476]\ttraining's binary_logloss: 0.568829\n",
      "[3477]\ttraining's binary_logloss: 0.568776\n",
      "[3478]\ttraining's binary_logloss: 0.56871\n",
      "[3479]\ttraining's binary_logloss: 0.568649\n",
      "[3480]\ttraining's binary_logloss: 0.568603\n",
      "[3481]\ttraining's binary_logloss: 0.568529\n",
      "[3482]\ttraining's binary_logloss: 0.568474\n",
      "[3483]\ttraining's binary_logloss: 0.568419\n",
      "[3484]\ttraining's binary_logloss: 0.568344\n",
      "[3485]\ttraining's binary_logloss: 0.568261\n",
      "[3486]\ttraining's binary_logloss: 0.568202\n",
      "[3487]\ttraining's binary_logloss: 0.568115\n",
      "[3488]\ttraining's binary_logloss: 0.568056\n",
      "[3489]\ttraining's binary_logloss: 0.567962\n",
      "[3490]\ttraining's binary_logloss: 0.567898\n",
      "[3491]\ttraining's binary_logloss: 0.567836\n",
      "[3492]\ttraining's binary_logloss: 0.567764\n",
      "[3493]\ttraining's binary_logloss: 0.567677\n",
      "[3494]\ttraining's binary_logloss: 0.567619\n",
      "[3495]\ttraining's binary_logloss: 0.567526\n",
      "[3496]\ttraining's binary_logloss: 0.567452\n",
      "[3497]\ttraining's binary_logloss: 0.567391\n",
      "[3498]\ttraining's binary_logloss: 0.567338\n",
      "[3499]\ttraining's binary_logloss: 0.567289\n",
      "[3500]\ttraining's binary_logloss: 0.567224\n",
      "[3501]\ttraining's binary_logloss: 0.567155\n",
      "[3502]\ttraining's binary_logloss: 0.567088\n",
      "[3503]\ttraining's binary_logloss: 0.566998\n",
      "[3504]\ttraining's binary_logloss: 0.566933\n",
      "[3505]\ttraining's binary_logloss: 0.566862\n",
      "[3506]\ttraining's binary_logloss: 0.566813\n",
      "[3507]\ttraining's binary_logloss: 0.566713\n",
      "[3508]\ttraining's binary_logloss: 0.566637\n",
      "[3509]\ttraining's binary_logloss: 0.566583\n",
      "[3510]\ttraining's binary_logloss: 0.5665\n",
      "[3511]\ttraining's binary_logloss: 0.566436\n",
      "[3512]\ttraining's binary_logloss: 0.566351\n",
      "[3513]\ttraining's binary_logloss: 0.566288\n",
      "[3514]\ttraining's binary_logloss: 0.566219\n",
      "[3515]\ttraining's binary_logloss: 0.566152\n",
      "[3516]\ttraining's binary_logloss: 0.566092\n",
      "[3517]\ttraining's binary_logloss: 0.566024\n",
      "[3518]\ttraining's binary_logloss: 0.565964\n",
      "[3519]\ttraining's binary_logloss: 0.565895\n",
      "[3520]\ttraining's binary_logloss: 0.565823\n",
      "[3521]\ttraining's binary_logloss: 0.565775\n",
      "[3522]\ttraining's binary_logloss: 0.565708\n",
      "[3523]\ttraining's binary_logloss: 0.565617\n",
      "[3524]\ttraining's binary_logloss: 0.565549\n",
      "[3525]\ttraining's binary_logloss: 0.56546\n",
      "[3526]\ttraining's binary_logloss: 0.56538\n",
      "[3527]\ttraining's binary_logloss: 0.565314\n",
      "[3528]\ttraining's binary_logloss: 0.565248\n",
      "[3529]\ttraining's binary_logloss: 0.565168\n",
      "[3530]\ttraining's binary_logloss: 0.565097\n",
      "[3531]\ttraining's binary_logloss: 0.565024\n",
      "[3532]\ttraining's binary_logloss: 0.564968\n",
      "[3533]\ttraining's binary_logloss: 0.564926\n",
      "[3534]\ttraining's binary_logloss: 0.56484\n",
      "[3535]\ttraining's binary_logloss: 0.564767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3536]\ttraining's binary_logloss: 0.564667\n",
      "[3537]\ttraining's binary_logloss: 0.564595\n",
      "[3538]\ttraining's binary_logloss: 0.564537\n",
      "[3539]\ttraining's binary_logloss: 0.564434\n",
      "[3540]\ttraining's binary_logloss: 0.564385\n",
      "[3541]\ttraining's binary_logloss: 0.564337\n",
      "[3542]\ttraining's binary_logloss: 0.564278\n",
      "[3543]\ttraining's binary_logloss: 0.56422\n",
      "[3544]\ttraining's binary_logloss: 0.56416\n",
      "[3545]\ttraining's binary_logloss: 0.564068\n",
      "[3546]\ttraining's binary_logloss: 0.563996\n",
      "[3547]\ttraining's binary_logloss: 0.563927\n",
      "[3548]\ttraining's binary_logloss: 0.563848\n",
      "[3549]\ttraining's binary_logloss: 0.563798\n",
      "[3550]\ttraining's binary_logloss: 0.563726\n",
      "[3551]\ttraining's binary_logloss: 0.563641\n",
      "[3552]\ttraining's binary_logloss: 0.563573\n",
      "[3553]\ttraining's binary_logloss: 0.56348\n",
      "[3554]\ttraining's binary_logloss: 0.563411\n",
      "[3555]\ttraining's binary_logloss: 0.563307\n",
      "[3556]\ttraining's binary_logloss: 0.563231\n",
      "[3557]\ttraining's binary_logloss: 0.563182\n",
      "[3558]\ttraining's binary_logloss: 0.563113\n",
      "[3559]\ttraining's binary_logloss: 0.563022\n",
      "[3560]\ttraining's binary_logloss: 0.562935\n",
      "[3561]\ttraining's binary_logloss: 0.562879\n",
      "[3562]\ttraining's binary_logloss: 0.562808\n",
      "[3563]\ttraining's binary_logloss: 0.562759\n",
      "[3564]\ttraining's binary_logloss: 0.562697\n",
      "[3565]\ttraining's binary_logloss: 0.562612\n",
      "[3566]\ttraining's binary_logloss: 0.562553\n",
      "[3567]\ttraining's binary_logloss: 0.562466\n",
      "[3568]\ttraining's binary_logloss: 0.562394\n",
      "[3569]\ttraining's binary_logloss: 0.562324\n",
      "[3570]\ttraining's binary_logloss: 0.562253\n",
      "[3571]\ttraining's binary_logloss: 0.562185\n",
      "[3572]\ttraining's binary_logloss: 0.562101\n",
      "[3573]\ttraining's binary_logloss: 0.562008\n",
      "[3574]\ttraining's binary_logloss: 0.561932\n",
      "[3575]\ttraining's binary_logloss: 0.561836\n",
      "[3576]\ttraining's binary_logloss: 0.561781\n",
      "[3577]\ttraining's binary_logloss: 0.561724\n",
      "[3578]\ttraining's binary_logloss: 0.561655\n",
      "[3579]\ttraining's binary_logloss: 0.561585\n",
      "[3580]\ttraining's binary_logloss: 0.561525\n",
      "[3581]\ttraining's binary_logloss: 0.561458\n",
      "[3582]\ttraining's binary_logloss: 0.561396\n",
      "[3583]\ttraining's binary_logloss: 0.561293\n",
      "[3584]\ttraining's binary_logloss: 0.561219\n",
      "[3585]\ttraining's binary_logloss: 0.561145\n",
      "[3586]\ttraining's binary_logloss: 0.561048\n",
      "[3587]\ttraining's binary_logloss: 0.560986\n",
      "[3588]\ttraining's binary_logloss: 0.5609\n",
      "[3589]\ttraining's binary_logloss: 0.56084\n",
      "[3590]\ttraining's binary_logloss: 0.560746\n",
      "[3591]\ttraining's binary_logloss: 0.560645\n",
      "[3592]\ttraining's binary_logloss: 0.560577\n",
      "[3593]\ttraining's binary_logloss: 0.560501\n",
      "[3594]\ttraining's binary_logloss: 0.560448\n",
      "[3595]\ttraining's binary_logloss: 0.560369\n",
      "[3596]\ttraining's binary_logloss: 0.560322\n",
      "[3597]\ttraining's binary_logloss: 0.560246\n",
      "[3598]\ttraining's binary_logloss: 0.560175\n",
      "[3599]\ttraining's binary_logloss: 0.560111\n",
      "[3600]\ttraining's binary_logloss: 0.560021\n",
      "[3601]\ttraining's binary_logloss: 0.559955\n",
      "[3602]\ttraining's binary_logloss: 0.559898\n",
      "[3603]\ttraining's binary_logloss: 0.559828\n",
      "[3604]\ttraining's binary_logloss: 0.559741\n",
      "[3605]\ttraining's binary_logloss: 0.559685\n",
      "[3606]\ttraining's binary_logloss: 0.559616\n",
      "[3607]\ttraining's binary_logloss: 0.559539\n",
      "[3608]\ttraining's binary_logloss: 0.55948\n",
      "[3609]\ttraining's binary_logloss: 0.559434\n",
      "[3610]\ttraining's binary_logloss: 0.559359\n",
      "[3611]\ttraining's binary_logloss: 0.559298\n",
      "[3612]\ttraining's binary_logloss: 0.559225\n",
      "[3613]\ttraining's binary_logloss: 0.559168\n",
      "[3614]\ttraining's binary_logloss: 0.559091\n",
      "[3615]\ttraining's binary_logloss: 0.559041\n",
      "[3616]\ttraining's binary_logloss: 0.558967\n",
      "[3617]\ttraining's binary_logloss: 0.558904\n",
      "[3618]\ttraining's binary_logloss: 0.558826\n",
      "[3619]\ttraining's binary_logloss: 0.558766\n",
      "[3620]\ttraining's binary_logloss: 0.55869\n",
      "[3621]\ttraining's binary_logloss: 0.558607\n",
      "[3622]\ttraining's binary_logloss: 0.558533\n",
      "[3623]\ttraining's binary_logloss: 0.558476\n",
      "[3624]\ttraining's binary_logloss: 0.558392\n",
      "[3625]\ttraining's binary_logloss: 0.558343\n",
      "[3626]\ttraining's binary_logloss: 0.558258\n",
      "[3627]\ttraining's binary_logloss: 0.558198\n",
      "[3628]\ttraining's binary_logloss: 0.558133\n",
      "[3629]\ttraining's binary_logloss: 0.558054\n",
      "[3630]\ttraining's binary_logloss: 0.557988\n",
      "[3631]\ttraining's binary_logloss: 0.557913\n",
      "[3632]\ttraining's binary_logloss: 0.557864\n",
      "[3633]\ttraining's binary_logloss: 0.557802\n",
      "[3634]\ttraining's binary_logloss: 0.557727\n",
      "[3635]\ttraining's binary_logloss: 0.557671\n",
      "[3636]\ttraining's binary_logloss: 0.557612\n",
      "[3637]\ttraining's binary_logloss: 0.557559\n",
      "[3638]\ttraining's binary_logloss: 0.557498\n",
      "[3639]\ttraining's binary_logloss: 0.557417\n",
      "[3640]\ttraining's binary_logloss: 0.557316\n",
      "[3641]\ttraining's binary_logloss: 0.557266\n",
      "[3642]\ttraining's binary_logloss: 0.55718\n",
      "[3643]\ttraining's binary_logloss: 0.557138\n",
      "[3644]\ttraining's binary_logloss: 0.557093\n",
      "[3645]\ttraining's binary_logloss: 0.557016\n",
      "[3646]\ttraining's binary_logloss: 0.556955\n",
      "[3647]\ttraining's binary_logloss: 0.55689\n",
      "[3648]\ttraining's binary_logloss: 0.55682\n",
      "[3649]\ttraining's binary_logloss: 0.556729\n",
      "[3650]\ttraining's binary_logloss: 0.556662\n",
      "[3651]\ttraining's binary_logloss: 0.556592\n",
      "[3652]\ttraining's binary_logloss: 0.556509\n",
      "[3653]\ttraining's binary_logloss: 0.556439\n",
      "[3654]\ttraining's binary_logloss: 0.556358\n",
      "[3655]\ttraining's binary_logloss: 0.556282\n",
      "[3656]\ttraining's binary_logloss: 0.556235\n",
      "[3657]\ttraining's binary_logloss: 0.556168\n",
      "[3658]\ttraining's binary_logloss: 0.556084\n",
      "[3659]\ttraining's binary_logloss: 0.55603\n",
      "[3660]\ttraining's binary_logloss: 0.555951\n",
      "[3661]\ttraining's binary_logloss: 0.555899\n",
      "[3662]\ttraining's binary_logloss: 0.555811\n",
      "[3663]\ttraining's binary_logloss: 0.555745\n",
      "[3664]\ttraining's binary_logloss: 0.555685\n",
      "[3665]\ttraining's binary_logloss: 0.555615\n",
      "[3666]\ttraining's binary_logloss: 0.555553\n",
      "[3667]\ttraining's binary_logloss: 0.555501\n",
      "[3668]\ttraining's binary_logloss: 0.555421\n",
      "[3669]\ttraining's binary_logloss: 0.555336\n",
      "[3670]\ttraining's binary_logloss: 0.555258\n",
      "[3671]\ttraining's binary_logloss: 0.555205\n",
      "[3672]\ttraining's binary_logloss: 0.555137\n",
      "[3673]\ttraining's binary_logloss: 0.555056\n",
      "[3674]\ttraining's binary_logloss: 0.554974\n",
      "[3675]\ttraining's binary_logloss: 0.554938\n",
      "[3676]\ttraining's binary_logloss: 0.554877\n",
      "[3677]\ttraining's binary_logloss: 0.554794\n",
      "[3678]\ttraining's binary_logloss: 0.554736\n",
      "[3679]\ttraining's binary_logloss: 0.554663\n",
      "[3680]\ttraining's binary_logloss: 0.55459\n",
      "[3681]\ttraining's binary_logloss: 0.554513\n",
      "[3682]\ttraining's binary_logloss: 0.554456\n",
      "[3683]\ttraining's binary_logloss: 0.554407\n",
      "[3684]\ttraining's binary_logloss: 0.554347\n",
      "[3685]\ttraining's binary_logloss: 0.554254\n",
      "[3686]\ttraining's binary_logloss: 0.554193\n",
      "[3687]\ttraining's binary_logloss: 0.554107\n",
      "[3688]\ttraining's binary_logloss: 0.554011\n",
      "[3689]\ttraining's binary_logloss: 0.553936\n",
      "[3690]\ttraining's binary_logloss: 0.553866\n",
      "[3691]\ttraining's binary_logloss: 0.553772\n",
      "[3692]\ttraining's binary_logloss: 0.553707\n",
      "[3693]\ttraining's binary_logloss: 0.553643\n",
      "[3694]\ttraining's binary_logloss: 0.553566\n",
      "[3695]\ttraining's binary_logloss: 0.553491\n",
      "[3696]\ttraining's binary_logloss: 0.553386\n",
      "[3697]\ttraining's binary_logloss: 0.553294\n",
      "[3698]\ttraining's binary_logloss: 0.553206\n",
      "[3699]\ttraining's binary_logloss: 0.553119\n",
      "[3700]\ttraining's binary_logloss: 0.553059\n",
      "[3701]\ttraining's binary_logloss: 0.552968\n",
      "[3702]\ttraining's binary_logloss: 0.552898\n",
      "[3703]\ttraining's binary_logloss: 0.552838\n",
      "[3704]\ttraining's binary_logloss: 0.552758\n",
      "[3705]\ttraining's binary_logloss: 0.552693\n",
      "[3706]\ttraining's binary_logloss: 0.552618\n",
      "[3707]\ttraining's binary_logloss: 0.552536\n",
      "[3708]\ttraining's binary_logloss: 0.552461\n",
      "[3709]\ttraining's binary_logloss: 0.55241\n",
      "[3710]\ttraining's binary_logloss: 0.552335\n",
      "[3711]\ttraining's binary_logloss: 0.552269\n",
      "[3712]\ttraining's binary_logloss: 0.552226\n",
      "[3713]\ttraining's binary_logloss: 0.552177\n",
      "[3714]\ttraining's binary_logloss: 0.552096\n",
      "[3715]\ttraining's binary_logloss: 0.552042\n",
      "[3716]\ttraining's binary_logloss: 0.551986\n",
      "[3717]\ttraining's binary_logloss: 0.551929\n",
      "[3718]\ttraining's binary_logloss: 0.551855\n",
      "[3719]\ttraining's binary_logloss: 0.551785\n",
      "[3720]\ttraining's binary_logloss: 0.551711\n",
      "[3721]\ttraining's binary_logloss: 0.551631\n",
      "[3722]\ttraining's binary_logloss: 0.55156\n",
      "[3723]\ttraining's binary_logloss: 0.551494\n",
      "[3724]\ttraining's binary_logloss: 0.551428\n",
      "[3725]\ttraining's binary_logloss: 0.551361\n",
      "[3726]\ttraining's binary_logloss: 0.551279\n",
      "[3727]\ttraining's binary_logloss: 0.551214\n",
      "[3728]\ttraining's binary_logloss: 0.551166\n",
      "[3729]\ttraining's binary_logloss: 0.551071\n",
      "[3730]\ttraining's binary_logloss: 0.550979\n",
      "[3731]\ttraining's binary_logloss: 0.550922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3732]\ttraining's binary_logloss: 0.550865\n",
      "[3733]\ttraining's binary_logloss: 0.550821\n",
      "[3734]\ttraining's binary_logloss: 0.55077\n",
      "[3735]\ttraining's binary_logloss: 0.550714\n",
      "[3736]\ttraining's binary_logloss: 0.550629\n",
      "[3737]\ttraining's binary_logloss: 0.550558\n",
      "[3738]\ttraining's binary_logloss: 0.550468\n",
      "[3739]\ttraining's binary_logloss: 0.550402\n",
      "[3740]\ttraining's binary_logloss: 0.550339\n",
      "[3741]\ttraining's binary_logloss: 0.550256\n",
      "[3742]\ttraining's binary_logloss: 0.550179\n",
      "[3743]\ttraining's binary_logloss: 0.550111\n",
      "[3744]\ttraining's binary_logloss: 0.550039\n",
      "[3745]\ttraining's binary_logloss: 0.549999\n",
      "[3746]\ttraining's binary_logloss: 0.54993\n",
      "[3747]\ttraining's binary_logloss: 0.549874\n",
      "[3748]\ttraining's binary_logloss: 0.549798\n",
      "[3749]\ttraining's binary_logloss: 0.549752\n",
      "[3750]\ttraining's binary_logloss: 0.549672\n",
      "[3751]\ttraining's binary_logloss: 0.549577\n",
      "[3752]\ttraining's binary_logloss: 0.549515\n",
      "[3753]\ttraining's binary_logloss: 0.549455\n",
      "[3754]\ttraining's binary_logloss: 0.549397\n",
      "[3755]\ttraining's binary_logloss: 0.549326\n",
      "[3756]\ttraining's binary_logloss: 0.54925\n",
      "[3757]\ttraining's binary_logloss: 0.549196\n",
      "[3758]\ttraining's binary_logloss: 0.549117\n",
      "[3759]\ttraining's binary_logloss: 0.54903\n",
      "[3760]\ttraining's binary_logloss: 0.548984\n",
      "[3761]\ttraining's binary_logloss: 0.548898\n",
      "[3762]\ttraining's binary_logloss: 0.548806\n",
      "[3763]\ttraining's binary_logloss: 0.548752\n",
      "[3764]\ttraining's binary_logloss: 0.548692\n",
      "[3765]\ttraining's binary_logloss: 0.548593\n",
      "[3766]\ttraining's binary_logloss: 0.548506\n",
      "[3767]\ttraining's binary_logloss: 0.548447\n",
      "[3768]\ttraining's binary_logloss: 0.548381\n",
      "[3769]\ttraining's binary_logloss: 0.548305\n",
      "[3770]\ttraining's binary_logloss: 0.54826\n",
      "[3771]\ttraining's binary_logloss: 0.548195\n",
      "[3772]\ttraining's binary_logloss: 0.548117\n",
      "[3773]\ttraining's binary_logloss: 0.548073\n",
      "[3774]\ttraining's binary_logloss: 0.548019\n",
      "[3775]\ttraining's binary_logloss: 0.547931\n",
      "[3776]\ttraining's binary_logloss: 0.547858\n",
      "[3777]\ttraining's binary_logloss: 0.547794\n",
      "[3778]\ttraining's binary_logloss: 0.547718\n",
      "[3779]\ttraining's binary_logloss: 0.547655\n",
      "[3780]\ttraining's binary_logloss: 0.547596\n",
      "[3781]\ttraining's binary_logloss: 0.547531\n",
      "[3782]\ttraining's binary_logloss: 0.547451\n",
      "[3783]\ttraining's binary_logloss: 0.547375\n",
      "[3784]\ttraining's binary_logloss: 0.547299\n",
      "[3785]\ttraining's binary_logloss: 0.54725\n",
      "[3786]\ttraining's binary_logloss: 0.547193\n",
      "[3787]\ttraining's binary_logloss: 0.547152\n",
      "[3788]\ttraining's binary_logloss: 0.547079\n",
      "[3789]\ttraining's binary_logloss: 0.547014\n",
      "[3790]\ttraining's binary_logloss: 0.546946\n",
      "[3791]\ttraining's binary_logloss: 0.546893\n",
      "[3792]\ttraining's binary_logloss: 0.546825\n",
      "[3793]\ttraining's binary_logloss: 0.546744\n",
      "[3794]\ttraining's binary_logloss: 0.546691\n",
      "[3795]\ttraining's binary_logloss: 0.546638\n",
      "[3796]\ttraining's binary_logloss: 0.54659\n",
      "[3797]\ttraining's binary_logloss: 0.54653\n",
      "[3798]\ttraining's binary_logloss: 0.546443\n",
      "[3799]\ttraining's binary_logloss: 0.546367\n",
      "[3800]\ttraining's binary_logloss: 0.546324\n",
      "[3801]\ttraining's binary_logloss: 0.546271\n",
      "[3802]\ttraining's binary_logloss: 0.54622\n",
      "[3803]\ttraining's binary_logloss: 0.546148\n",
      "[3804]\ttraining's binary_logloss: 0.546096\n",
      "[3805]\ttraining's binary_logloss: 0.546046\n",
      "[3806]\ttraining's binary_logloss: 0.545989\n",
      "[3807]\ttraining's binary_logloss: 0.545932\n",
      "[3808]\ttraining's binary_logloss: 0.545854\n",
      "[3809]\ttraining's binary_logloss: 0.54576\n",
      "[3810]\ttraining's binary_logloss: 0.545672\n",
      "[3811]\ttraining's binary_logloss: 0.545622\n",
      "[3812]\ttraining's binary_logloss: 0.545554\n",
      "[3813]\ttraining's binary_logloss: 0.545498\n",
      "[3814]\ttraining's binary_logloss: 0.54544\n",
      "[3815]\ttraining's binary_logloss: 0.545394\n",
      "[3816]\ttraining's binary_logloss: 0.545341\n",
      "[3817]\ttraining's binary_logloss: 0.545266\n",
      "[3818]\ttraining's binary_logloss: 0.545188\n",
      "[3819]\ttraining's binary_logloss: 0.545108\n",
      "[3820]\ttraining's binary_logloss: 0.545021\n",
      "[3821]\ttraining's binary_logloss: 0.544942\n",
      "[3822]\ttraining's binary_logloss: 0.544861\n",
      "[3823]\ttraining's binary_logloss: 0.544775\n",
      "[3824]\ttraining's binary_logloss: 0.544695\n",
      "[3825]\ttraining's binary_logloss: 0.544647\n",
      "[3826]\ttraining's binary_logloss: 0.544584\n",
      "[3827]\ttraining's binary_logloss: 0.544537\n",
      "[3828]\ttraining's binary_logloss: 0.544475\n",
      "[3829]\ttraining's binary_logloss: 0.544419\n",
      "[3830]\ttraining's binary_logloss: 0.544378\n",
      "[3831]\ttraining's binary_logloss: 0.544314\n",
      "[3832]\ttraining's binary_logloss: 0.544253\n",
      "[3833]\ttraining's binary_logloss: 0.544204\n",
      "[3834]\ttraining's binary_logloss: 0.544128\n",
      "[3835]\ttraining's binary_logloss: 0.544061\n",
      "[3836]\ttraining's binary_logloss: 0.543992\n",
      "[3837]\ttraining's binary_logloss: 0.543935\n",
      "[3838]\ttraining's binary_logloss: 0.543869\n",
      "[3839]\ttraining's binary_logloss: 0.543809\n",
      "[3840]\ttraining's binary_logloss: 0.543736\n",
      "[3841]\ttraining's binary_logloss: 0.543664\n",
      "[3842]\ttraining's binary_logloss: 0.543606\n",
      "[3843]\ttraining's binary_logloss: 0.543519\n",
      "[3844]\ttraining's binary_logloss: 0.543462\n",
      "[3845]\ttraining's binary_logloss: 0.543412\n",
      "[3846]\ttraining's binary_logloss: 0.543356\n",
      "[3847]\ttraining's binary_logloss: 0.543308\n",
      "[3848]\ttraining's binary_logloss: 0.543211\n",
      "[3849]\ttraining's binary_logloss: 0.543135\n",
      "[3850]\ttraining's binary_logloss: 0.543065\n",
      "[3851]\ttraining's binary_logloss: 0.543002\n",
      "[3852]\ttraining's binary_logloss: 0.542954\n",
      "[3853]\ttraining's binary_logloss: 0.542864\n",
      "[3854]\ttraining's binary_logloss: 0.542801\n",
      "[3855]\ttraining's binary_logloss: 0.542746\n",
      "[3856]\ttraining's binary_logloss: 0.542669\n",
      "[3857]\ttraining's binary_logloss: 0.542609\n",
      "[3858]\ttraining's binary_logloss: 0.542505\n",
      "[3859]\ttraining's binary_logloss: 0.54244\n",
      "[3860]\ttraining's binary_logloss: 0.542376\n",
      "[3861]\ttraining's binary_logloss: 0.54232\n",
      "[3862]\ttraining's binary_logloss: 0.542243\n",
      "[3863]\ttraining's binary_logloss: 0.542185\n",
      "[3864]\ttraining's binary_logloss: 0.542115\n",
      "[3865]\ttraining's binary_logloss: 0.54205\n",
      "[3866]\ttraining's binary_logloss: 0.541981\n",
      "[3867]\ttraining's binary_logloss: 0.541904\n",
      "[3868]\ttraining's binary_logloss: 0.541842\n",
      "[3869]\ttraining's binary_logloss: 0.541768\n",
      "[3870]\ttraining's binary_logloss: 0.541698\n",
      "[3871]\ttraining's binary_logloss: 0.541615\n",
      "[3872]\ttraining's binary_logloss: 0.541538\n",
      "[3873]\ttraining's binary_logloss: 0.541473\n",
      "[3874]\ttraining's binary_logloss: 0.541394\n",
      "[3875]\ttraining's binary_logloss: 0.541337\n",
      "[3876]\ttraining's binary_logloss: 0.54128\n",
      "[3877]\ttraining's binary_logloss: 0.541215\n",
      "[3878]\ttraining's binary_logloss: 0.54115\n",
      "[3879]\ttraining's binary_logloss: 0.541078\n",
      "[3880]\ttraining's binary_logloss: 0.541006\n",
      "[3881]\ttraining's binary_logloss: 0.540964\n",
      "[3882]\ttraining's binary_logloss: 0.540904\n",
      "[3883]\ttraining's binary_logloss: 0.540831\n",
      "[3884]\ttraining's binary_logloss: 0.540769\n",
      "[3885]\ttraining's binary_logloss: 0.540711\n",
      "[3886]\ttraining's binary_logloss: 0.540666\n",
      "[3887]\ttraining's binary_logloss: 0.540574\n",
      "[3888]\ttraining's binary_logloss: 0.540504\n",
      "[3889]\ttraining's binary_logloss: 0.540442\n",
      "[3890]\ttraining's binary_logloss: 0.540391\n",
      "[3891]\ttraining's binary_logloss: 0.540337\n",
      "[3892]\ttraining's binary_logloss: 0.540277\n",
      "[3893]\ttraining's binary_logloss: 0.54019\n",
      "[3894]\ttraining's binary_logloss: 0.540116\n",
      "[3895]\ttraining's binary_logloss: 0.540057\n",
      "[3896]\ttraining's binary_logloss: 0.539999\n",
      "[3897]\ttraining's binary_logloss: 0.539931\n",
      "[3898]\ttraining's binary_logloss: 0.539861\n",
      "[3899]\ttraining's binary_logloss: 0.539806\n",
      "[3900]\ttraining's binary_logloss: 0.539718\n",
      "[3901]\ttraining's binary_logloss: 0.539656\n",
      "[3902]\ttraining's binary_logloss: 0.539605\n",
      "[3903]\ttraining's binary_logloss: 0.539536\n",
      "[3904]\ttraining's binary_logloss: 0.539474\n",
      "[3905]\ttraining's binary_logloss: 0.539411\n",
      "[3906]\ttraining's binary_logloss: 0.539344\n",
      "[3907]\ttraining's binary_logloss: 0.539255\n",
      "[3908]\ttraining's binary_logloss: 0.539204\n",
      "[3909]\ttraining's binary_logloss: 0.539111\n",
      "[3910]\ttraining's binary_logloss: 0.539044\n",
      "[3911]\ttraining's binary_logloss: 0.538945\n",
      "[3912]\ttraining's binary_logloss: 0.538894\n",
      "[3913]\ttraining's binary_logloss: 0.538807\n",
      "[3914]\ttraining's binary_logloss: 0.538752\n",
      "[3915]\ttraining's binary_logloss: 0.538672\n",
      "[3916]\ttraining's binary_logloss: 0.53859\n",
      "[3917]\ttraining's binary_logloss: 0.538522\n",
      "[3918]\ttraining's binary_logloss: 0.538428\n",
      "[3919]\ttraining's binary_logloss: 0.538351\n",
      "[3920]\ttraining's binary_logloss: 0.538311\n",
      "[3921]\ttraining's binary_logloss: 0.538258\n",
      "[3922]\ttraining's binary_logloss: 0.538182\n",
      "[3923]\ttraining's binary_logloss: 0.538121\n",
      "[3924]\ttraining's binary_logloss: 0.538079\n",
      "[3925]\ttraining's binary_logloss: 0.537997\n",
      "[3926]\ttraining's binary_logloss: 0.537936\n",
      "[3927]\ttraining's binary_logloss: 0.537866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3928]\ttraining's binary_logloss: 0.537775\n",
      "[3929]\ttraining's binary_logloss: 0.537695\n",
      "[3930]\ttraining's binary_logloss: 0.537635\n",
      "[3931]\ttraining's binary_logloss: 0.537586\n",
      "[3932]\ttraining's binary_logloss: 0.537525\n",
      "[3933]\ttraining's binary_logloss: 0.537447\n",
      "[3934]\ttraining's binary_logloss: 0.537406\n",
      "[3935]\ttraining's binary_logloss: 0.537339\n",
      "[3936]\ttraining's binary_logloss: 0.537274\n",
      "[3937]\ttraining's binary_logloss: 0.537193\n",
      "[3938]\ttraining's binary_logloss: 0.537132\n",
      "[3939]\ttraining's binary_logloss: 0.537081\n",
      "[3940]\ttraining's binary_logloss: 0.53701\n",
      "[3941]\ttraining's binary_logloss: 0.53694\n",
      "[3942]\ttraining's binary_logloss: 0.536881\n",
      "[3943]\ttraining's binary_logloss: 0.536831\n",
      "[3944]\ttraining's binary_logloss: 0.536777\n",
      "[3945]\ttraining's binary_logloss: 0.536734\n",
      "[3946]\ttraining's binary_logloss: 0.536691\n",
      "[3947]\ttraining's binary_logloss: 0.536626\n",
      "[3948]\ttraining's binary_logloss: 0.536543\n",
      "[3949]\ttraining's binary_logloss: 0.536475\n",
      "[3950]\ttraining's binary_logloss: 0.536415\n",
      "[3951]\ttraining's binary_logloss: 0.536358\n",
      "[3952]\ttraining's binary_logloss: 0.536272\n",
      "[3953]\ttraining's binary_logloss: 0.536213\n",
      "[3954]\ttraining's binary_logloss: 0.536105\n",
      "[3955]\ttraining's binary_logloss: 0.536032\n",
      "[3956]\ttraining's binary_logloss: 0.535976\n",
      "[3957]\ttraining's binary_logloss: 0.535904\n",
      "[3958]\ttraining's binary_logloss: 0.535869\n",
      "[3959]\ttraining's binary_logloss: 0.535803\n",
      "[3960]\ttraining's binary_logloss: 0.53576\n",
      "[3961]\ttraining's binary_logloss: 0.535671\n",
      "[3962]\ttraining's binary_logloss: 0.535607\n",
      "[3963]\ttraining's binary_logloss: 0.535535\n",
      "[3964]\ttraining's binary_logloss: 0.535485\n",
      "[3965]\ttraining's binary_logloss: 0.535406\n",
      "[3966]\ttraining's binary_logloss: 0.535357\n",
      "[3967]\ttraining's binary_logloss: 0.5353\n",
      "[3968]\ttraining's binary_logloss: 0.535209\n",
      "[3969]\ttraining's binary_logloss: 0.535129\n",
      "[3970]\ttraining's binary_logloss: 0.535078\n",
      "[3971]\ttraining's binary_logloss: 0.535016\n",
      "[3972]\ttraining's binary_logloss: 0.534978\n",
      "[3973]\ttraining's binary_logloss: 0.534908\n",
      "[3974]\ttraining's binary_logloss: 0.534824\n",
      "[3975]\ttraining's binary_logloss: 0.534761\n",
      "[3976]\ttraining's binary_logloss: 0.53471\n",
      "[3977]\ttraining's binary_logloss: 0.534651\n",
      "[3978]\ttraining's binary_logloss: 0.534564\n",
      "[3979]\ttraining's binary_logloss: 0.534502\n",
      "[3980]\ttraining's binary_logloss: 0.534442\n",
      "[3981]\ttraining's binary_logloss: 0.534357\n",
      "[3982]\ttraining's binary_logloss: 0.534309\n",
      "[3983]\ttraining's binary_logloss: 0.534264\n",
      "[3984]\ttraining's binary_logloss: 0.534205\n",
      "[3985]\ttraining's binary_logloss: 0.534145\n",
      "[3986]\ttraining's binary_logloss: 0.534067\n",
      "[3987]\ttraining's binary_logloss: 0.534009\n",
      "[3988]\ttraining's binary_logloss: 0.533943\n",
      "[3989]\ttraining's binary_logloss: 0.533848\n",
      "[3990]\ttraining's binary_logloss: 0.533791\n",
      "[3991]\ttraining's binary_logloss: 0.533745\n",
      "[3992]\ttraining's binary_logloss: 0.533686\n",
      "[3993]\ttraining's binary_logloss: 0.533623\n",
      "[3994]\ttraining's binary_logloss: 0.53352\n",
      "[3995]\ttraining's binary_logloss: 0.533467\n",
      "[3996]\ttraining's binary_logloss: 0.533402\n",
      "[3997]\ttraining's binary_logloss: 0.533355\n",
      "[3998]\ttraining's binary_logloss: 0.533283\n",
      "[3999]\ttraining's binary_logloss: 0.533215\n",
      "[4000]\ttraining's binary_logloss: 0.533145\n",
      "[4001]\ttraining's binary_logloss: 0.533093\n",
      "[4002]\ttraining's binary_logloss: 0.533038\n",
      "[4003]\ttraining's binary_logloss: 0.532972\n",
      "[4004]\ttraining's binary_logloss: 0.532896\n",
      "[4005]\ttraining's binary_logloss: 0.532835\n",
      "[4006]\ttraining's binary_logloss: 0.532782\n",
      "[4007]\ttraining's binary_logloss: 0.532722\n",
      "[4008]\ttraining's binary_logloss: 0.53264\n",
      "[4009]\ttraining's binary_logloss: 0.532575\n",
      "[4010]\ttraining's binary_logloss: 0.532509\n",
      "[4011]\ttraining's binary_logloss: 0.532456\n",
      "[4012]\ttraining's binary_logloss: 0.532374\n",
      "[4013]\ttraining's binary_logloss: 0.532328\n",
      "[4014]\ttraining's binary_logloss: 0.532257\n",
      "[4015]\ttraining's binary_logloss: 0.5322\n",
      "[4016]\ttraining's binary_logloss: 0.532127\n",
      "[4017]\ttraining's binary_logloss: 0.532087\n",
      "[4018]\ttraining's binary_logloss: 0.53203\n",
      "[4019]\ttraining's binary_logloss: 0.531953\n",
      "[4020]\ttraining's binary_logloss: 0.531878\n",
      "[4021]\ttraining's binary_logloss: 0.531818\n",
      "[4022]\ttraining's binary_logloss: 0.531748\n",
      "[4023]\ttraining's binary_logloss: 0.531664\n",
      "[4024]\ttraining's binary_logloss: 0.531575\n",
      "[4025]\ttraining's binary_logloss: 0.531479\n",
      "[4026]\ttraining's binary_logloss: 0.531435\n",
      "[4027]\ttraining's binary_logloss: 0.531368\n",
      "[4028]\ttraining's binary_logloss: 0.531309\n",
      "[4029]\ttraining's binary_logloss: 0.531236\n",
      "[4030]\ttraining's binary_logloss: 0.531149\n",
      "[4031]\ttraining's binary_logloss: 0.531088\n",
      "[4032]\ttraining's binary_logloss: 0.531023\n",
      "[4033]\ttraining's binary_logloss: 0.530942\n",
      "[4034]\ttraining's binary_logloss: 0.530863\n",
      "[4035]\ttraining's binary_logloss: 0.530803\n",
      "[4036]\ttraining's binary_logloss: 0.530743\n",
      "[4037]\ttraining's binary_logloss: 0.530659\n",
      "[4038]\ttraining's binary_logloss: 0.530578\n",
      "[4039]\ttraining's binary_logloss: 0.530524\n",
      "[4040]\ttraining's binary_logloss: 0.530462\n",
      "[4041]\ttraining's binary_logloss: 0.530397\n",
      "[4042]\ttraining's binary_logloss: 0.530343\n",
      "[4043]\ttraining's binary_logloss: 0.530277\n",
      "[4044]\ttraining's binary_logloss: 0.530246\n",
      "[4045]\ttraining's binary_logloss: 0.530206\n",
      "[4046]\ttraining's binary_logloss: 0.530142\n",
      "[4047]\ttraining's binary_logloss: 0.530069\n",
      "[4048]\ttraining's binary_logloss: 0.53001\n",
      "[4049]\ttraining's binary_logloss: 0.529935\n",
      "[4050]\ttraining's binary_logloss: 0.529874\n",
      "[4051]\ttraining's binary_logloss: 0.529799\n",
      "[4052]\ttraining's binary_logloss: 0.529714\n",
      "[4053]\ttraining's binary_logloss: 0.529637\n",
      "[4054]\ttraining's binary_logloss: 0.52958\n",
      "[4055]\ttraining's binary_logloss: 0.529549\n",
      "[4056]\ttraining's binary_logloss: 0.529493\n",
      "[4057]\ttraining's binary_logloss: 0.529441\n",
      "[4058]\ttraining's binary_logloss: 0.529387\n",
      "[4059]\ttraining's binary_logloss: 0.529292\n",
      "[4060]\ttraining's binary_logloss: 0.529217\n",
      "[4061]\ttraining's binary_logloss: 0.529165\n",
      "[4062]\ttraining's binary_logloss: 0.529112\n",
      "[4063]\ttraining's binary_logloss: 0.529051\n",
      "[4064]\ttraining's binary_logloss: 0.528969\n",
      "[4065]\ttraining's binary_logloss: 0.528916\n",
      "[4066]\ttraining's binary_logloss: 0.528837\n",
      "[4067]\ttraining's binary_logloss: 0.528794\n",
      "[4068]\ttraining's binary_logloss: 0.528747\n",
      "[4069]\ttraining's binary_logloss: 0.52868\n",
      "[4070]\ttraining's binary_logloss: 0.528614\n",
      "[4071]\ttraining's binary_logloss: 0.528552\n",
      "[4072]\ttraining's binary_logloss: 0.528475\n",
      "[4073]\ttraining's binary_logloss: 0.528397\n",
      "[4074]\ttraining's binary_logloss: 0.528343\n",
      "[4075]\ttraining's binary_logloss: 0.528298\n",
      "[4076]\ttraining's binary_logloss: 0.52825\n",
      "[4077]\ttraining's binary_logloss: 0.528164\n",
      "[4078]\ttraining's binary_logloss: 0.528082\n",
      "[4079]\ttraining's binary_logloss: 0.528009\n",
      "[4080]\ttraining's binary_logloss: 0.527946\n",
      "[4081]\ttraining's binary_logloss: 0.527873\n",
      "[4082]\ttraining's binary_logloss: 0.527786\n",
      "[4083]\ttraining's binary_logloss: 0.527713\n",
      "[4084]\ttraining's binary_logloss: 0.527617\n",
      "[4085]\ttraining's binary_logloss: 0.527546\n",
      "[4086]\ttraining's binary_logloss: 0.527497\n",
      "[4087]\ttraining's binary_logloss: 0.527419\n",
      "[4088]\ttraining's binary_logloss: 0.527362\n",
      "[4089]\ttraining's binary_logloss: 0.527311\n",
      "[4090]\ttraining's binary_logloss: 0.527265\n",
      "[4091]\ttraining's binary_logloss: 0.527183\n",
      "[4092]\ttraining's binary_logloss: 0.527126\n",
      "[4093]\ttraining's binary_logloss: 0.52703\n",
      "[4094]\ttraining's binary_logloss: 0.526966\n",
      "[4095]\ttraining's binary_logloss: 0.526906\n",
      "[4096]\ttraining's binary_logloss: 0.52684\n",
      "[4097]\ttraining's binary_logloss: 0.526793\n",
      "[4098]\ttraining's binary_logloss: 0.526726\n",
      "[4099]\ttraining's binary_logloss: 0.526659\n",
      "[4100]\ttraining's binary_logloss: 0.526587\n",
      "[4101]\ttraining's binary_logloss: 0.526511\n",
      "[4102]\ttraining's binary_logloss: 0.52645\n",
      "[4103]\ttraining's binary_logloss: 0.526372\n",
      "[4104]\ttraining's binary_logloss: 0.526329\n",
      "[4105]\ttraining's binary_logloss: 0.52627\n",
      "[4106]\ttraining's binary_logloss: 0.526207\n",
      "[4107]\ttraining's binary_logloss: 0.52615\n",
      "[4108]\ttraining's binary_logloss: 0.526094\n",
      "[4109]\ttraining's binary_logloss: 0.526016\n",
      "[4110]\ttraining's binary_logloss: 0.525947\n",
      "[4111]\ttraining's binary_logloss: 0.525882\n",
      "[4112]\ttraining's binary_logloss: 0.525817\n",
      "[4113]\ttraining's binary_logloss: 0.525757\n",
      "[4114]\ttraining's binary_logloss: 0.525696\n",
      "[4115]\ttraining's binary_logloss: 0.525636\n",
      "[4116]\ttraining's binary_logloss: 0.525547\n",
      "[4117]\ttraining's binary_logloss: 0.5255\n",
      "[4118]\ttraining's binary_logloss: 0.525447\n",
      "[4119]\ttraining's binary_logloss: 0.525393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4120]\ttraining's binary_logloss: 0.525341\n",
      "[4121]\ttraining's binary_logloss: 0.525269\n",
      "[4122]\ttraining's binary_logloss: 0.525211\n",
      "[4123]\ttraining's binary_logloss: 0.525151\n",
      "[4124]\ttraining's binary_logloss: 0.525053\n",
      "[4125]\ttraining's binary_logloss: 0.524989\n",
      "[4126]\ttraining's binary_logloss: 0.524937\n",
      "[4127]\ttraining's binary_logloss: 0.524875\n",
      "[4128]\ttraining's binary_logloss: 0.524835\n",
      "[4129]\ttraining's binary_logloss: 0.524771\n",
      "[4130]\ttraining's binary_logloss: 0.524674\n",
      "[4131]\ttraining's binary_logloss: 0.524618\n",
      "[4132]\ttraining's binary_logloss: 0.524567\n",
      "[4133]\ttraining's binary_logloss: 0.524494\n",
      "[4134]\ttraining's binary_logloss: 0.524423\n",
      "[4135]\ttraining's binary_logloss: 0.52435\n",
      "[4136]\ttraining's binary_logloss: 0.524286\n",
      "[4137]\ttraining's binary_logloss: 0.524227\n",
      "[4138]\ttraining's binary_logloss: 0.524146\n",
      "[4139]\ttraining's binary_logloss: 0.524034\n",
      "[4140]\ttraining's binary_logloss: 0.523976\n",
      "[4141]\ttraining's binary_logloss: 0.523908\n",
      "[4142]\ttraining's binary_logloss: 0.523846\n",
      "[4143]\ttraining's binary_logloss: 0.523788\n",
      "[4144]\ttraining's binary_logloss: 0.523735\n",
      "[4145]\ttraining's binary_logloss: 0.52368\n",
      "[4146]\ttraining's binary_logloss: 0.523639\n",
      "[4147]\ttraining's binary_logloss: 0.523571\n",
      "[4148]\ttraining's binary_logloss: 0.523501\n",
      "[4149]\ttraining's binary_logloss: 0.523438\n",
      "[4150]\ttraining's binary_logloss: 0.523386\n",
      "[4151]\ttraining's binary_logloss: 0.523305\n",
      "[4152]\ttraining's binary_logloss: 0.523258\n",
      "[4153]\ttraining's binary_logloss: 0.523171\n",
      "[4154]\ttraining's binary_logloss: 0.523107\n",
      "[4155]\ttraining's binary_logloss: 0.523033\n",
      "[4156]\ttraining's binary_logloss: 0.522947\n",
      "[4157]\ttraining's binary_logloss: 0.522876\n",
      "[4158]\ttraining's binary_logloss: 0.522811\n",
      "[4159]\ttraining's binary_logloss: 0.522756\n",
      "[4160]\ttraining's binary_logloss: 0.522694\n",
      "[4161]\ttraining's binary_logloss: 0.522641\n",
      "[4162]\ttraining's binary_logloss: 0.522566\n",
      "[4163]\ttraining's binary_logloss: 0.522496\n",
      "[4164]\ttraining's binary_logloss: 0.522428\n",
      "[4165]\ttraining's binary_logloss: 0.522357\n",
      "[4166]\ttraining's binary_logloss: 0.522303\n",
      "[4167]\ttraining's binary_logloss: 0.522256\n",
      "[4168]\ttraining's binary_logloss: 0.522211\n",
      "[4169]\ttraining's binary_logloss: 0.522143\n",
      "[4170]\ttraining's binary_logloss: 0.522086\n",
      "[4171]\ttraining's binary_logloss: 0.522027\n",
      "[4172]\ttraining's binary_logloss: 0.521977\n",
      "[4173]\ttraining's binary_logloss: 0.521899\n",
      "[4174]\ttraining's binary_logloss: 0.521822\n",
      "[4175]\ttraining's binary_logloss: 0.521755\n",
      "[4176]\ttraining's binary_logloss: 0.521705\n",
      "[4177]\ttraining's binary_logloss: 0.521625\n",
      "[4178]\ttraining's binary_logloss: 0.521565\n",
      "[4179]\ttraining's binary_logloss: 0.521484\n",
      "[4180]\ttraining's binary_logloss: 0.521404\n",
      "[4181]\ttraining's binary_logloss: 0.521333\n",
      "[4182]\ttraining's binary_logloss: 0.521276\n",
      "[4183]\ttraining's binary_logloss: 0.52123\n",
      "[4184]\ttraining's binary_logloss: 0.521159\n",
      "[4185]\ttraining's binary_logloss: 0.521101\n",
      "[4186]\ttraining's binary_logloss: 0.521056\n",
      "[4187]\ttraining's binary_logloss: 0.520998\n",
      "[4188]\ttraining's binary_logloss: 0.520931\n",
      "[4189]\ttraining's binary_logloss: 0.520882\n",
      "[4190]\ttraining's binary_logloss: 0.520804\n",
      "[4191]\ttraining's binary_logloss: 0.520743\n",
      "[4192]\ttraining's binary_logloss: 0.520676\n",
      "[4193]\ttraining's binary_logloss: 0.52063\n",
      "[4194]\ttraining's binary_logloss: 0.520553\n",
      "[4195]\ttraining's binary_logloss: 0.520486\n",
      "[4196]\ttraining's binary_logloss: 0.520438\n",
      "[4197]\ttraining's binary_logloss: 0.520372\n",
      "[4198]\ttraining's binary_logloss: 0.52032\n",
      "[4199]\ttraining's binary_logloss: 0.52024\n",
      "[4200]\ttraining's binary_logloss: 0.520177\n",
      "[4201]\ttraining's binary_logloss: 0.520114\n",
      "[4202]\ttraining's binary_logloss: 0.520063\n",
      "[4203]\ttraining's binary_logloss: 0.519996\n",
      "[4204]\ttraining's binary_logloss: 0.519947\n",
      "[4205]\ttraining's binary_logloss: 0.519896\n",
      "[4206]\ttraining's binary_logloss: 0.519833\n",
      "[4207]\ttraining's binary_logloss: 0.519766\n",
      "[4208]\ttraining's binary_logloss: 0.519716\n",
      "[4209]\ttraining's binary_logloss: 0.519665\n",
      "[4210]\ttraining's binary_logloss: 0.519614\n",
      "[4211]\ttraining's binary_logloss: 0.519556\n",
      "[4212]\ttraining's binary_logloss: 0.519501\n",
      "[4213]\ttraining's binary_logloss: 0.519433\n",
      "[4214]\ttraining's binary_logloss: 0.519385\n",
      "[4215]\ttraining's binary_logloss: 0.519343\n",
      "[4216]\ttraining's binary_logloss: 0.519284\n",
      "[4217]\ttraining's binary_logloss: 0.51921\n",
      "[4218]\ttraining's binary_logloss: 0.519149\n",
      "[4219]\ttraining's binary_logloss: 0.519095\n",
      "[4220]\ttraining's binary_logloss: 0.519036\n",
      "[4221]\ttraining's binary_logloss: 0.518972\n",
      "[4222]\ttraining's binary_logloss: 0.518897\n",
      "[4223]\ttraining's binary_logloss: 0.51883\n",
      "[4224]\ttraining's binary_logloss: 0.518772\n",
      "[4225]\ttraining's binary_logloss: 0.518712\n",
      "[4226]\ttraining's binary_logloss: 0.518655\n",
      "[4227]\ttraining's binary_logloss: 0.518587\n",
      "[4228]\ttraining's binary_logloss: 0.518524\n",
      "[4229]\ttraining's binary_logloss: 0.518448\n",
      "[4230]\ttraining's binary_logloss: 0.518396\n",
      "[4231]\ttraining's binary_logloss: 0.518343\n",
      "[4232]\ttraining's binary_logloss: 0.518266\n",
      "[4233]\ttraining's binary_logloss: 0.51821\n",
      "[4234]\ttraining's binary_logloss: 0.518138\n",
      "[4235]\ttraining's binary_logloss: 0.518082\n",
      "[4236]\ttraining's binary_logloss: 0.518037\n",
      "[4237]\ttraining's binary_logloss: 0.517995\n",
      "[4238]\ttraining's binary_logloss: 0.517926\n",
      "[4239]\ttraining's binary_logloss: 0.517869\n",
      "[4240]\ttraining's binary_logloss: 0.517802\n",
      "[4241]\ttraining's binary_logloss: 0.517735\n",
      "[4242]\ttraining's binary_logloss: 0.517668\n",
      "[4243]\ttraining's binary_logloss: 0.517596\n",
      "[4244]\ttraining's binary_logloss: 0.517535\n",
      "[4245]\ttraining's binary_logloss: 0.517467\n",
      "[4246]\ttraining's binary_logloss: 0.517391\n",
      "[4247]\ttraining's binary_logloss: 0.51733\n",
      "[4248]\ttraining's binary_logloss: 0.517285\n",
      "[4249]\ttraining's binary_logloss: 0.517234\n",
      "[4250]\ttraining's binary_logloss: 0.517181\n",
      "[4251]\ttraining's binary_logloss: 0.517116\n",
      "[4252]\ttraining's binary_logloss: 0.517064\n",
      "[4253]\ttraining's binary_logloss: 0.516988\n",
      "[4254]\ttraining's binary_logloss: 0.516944\n",
      "[4255]\ttraining's binary_logloss: 0.516891\n",
      "[4256]\ttraining's binary_logloss: 0.516816\n",
      "[4257]\ttraining's binary_logloss: 0.516744\n",
      "[4258]\ttraining's binary_logloss: 0.516702\n",
      "[4259]\ttraining's binary_logloss: 0.516615\n",
      "[4260]\ttraining's binary_logloss: 0.516565\n",
      "[4261]\ttraining's binary_logloss: 0.516504\n",
      "[4262]\ttraining's binary_logloss: 0.516451\n",
      "[4263]\ttraining's binary_logloss: 0.516385\n",
      "[4264]\ttraining's binary_logloss: 0.516309\n",
      "[4265]\ttraining's binary_logloss: 0.516266\n",
      "[4266]\ttraining's binary_logloss: 0.516182\n",
      "[4267]\ttraining's binary_logloss: 0.516143\n",
      "[4268]\ttraining's binary_logloss: 0.516046\n",
      "[4269]\ttraining's binary_logloss: 0.51599\n",
      "[4270]\ttraining's binary_logloss: 0.515929\n",
      "[4271]\ttraining's binary_logloss: 0.515887\n",
      "[4272]\ttraining's binary_logloss: 0.515818\n",
      "[4273]\ttraining's binary_logloss: 0.515737\n",
      "[4274]\ttraining's binary_logloss: 0.515686\n",
      "[4275]\ttraining's binary_logloss: 0.51562\n",
      "[4276]\ttraining's binary_logloss: 0.515525\n",
      "[4277]\ttraining's binary_logloss: 0.515471\n",
      "[4278]\ttraining's binary_logloss: 0.515415\n",
      "[4279]\ttraining's binary_logloss: 0.515345\n",
      "[4280]\ttraining's binary_logloss: 0.515279\n",
      "[4281]\ttraining's binary_logloss: 0.515191\n",
      "[4282]\ttraining's binary_logloss: 0.515148\n",
      "[4283]\ttraining's binary_logloss: 0.515086\n",
      "[4284]\ttraining's binary_logloss: 0.514986\n",
      "[4285]\ttraining's binary_logloss: 0.514939\n",
      "[4286]\ttraining's binary_logloss: 0.514896\n",
      "[4287]\ttraining's binary_logloss: 0.514816\n",
      "[4288]\ttraining's binary_logloss: 0.51474\n",
      "[4289]\ttraining's binary_logloss: 0.51468\n",
      "[4290]\ttraining's binary_logloss: 0.514623\n",
      "[4291]\ttraining's binary_logloss: 0.514521\n",
      "[4292]\ttraining's binary_logloss: 0.514447\n",
      "[4293]\ttraining's binary_logloss: 0.514389\n",
      "[4294]\ttraining's binary_logloss: 0.514332\n",
      "[4295]\ttraining's binary_logloss: 0.514244\n",
      "[4296]\ttraining's binary_logloss: 0.514168\n",
      "[4297]\ttraining's binary_logloss: 0.514106\n",
      "[4298]\ttraining's binary_logloss: 0.514025\n",
      "[4299]\ttraining's binary_logloss: 0.513966\n",
      "[4300]\ttraining's binary_logloss: 0.513919\n",
      "[4301]\ttraining's binary_logloss: 0.513865\n",
      "[4302]\ttraining's binary_logloss: 0.513818\n",
      "[4303]\ttraining's binary_logloss: 0.513766\n",
      "[4304]\ttraining's binary_logloss: 0.513724\n",
      "[4305]\ttraining's binary_logloss: 0.513676\n",
      "[4306]\ttraining's binary_logloss: 0.513615\n",
      "[4307]\ttraining's binary_logloss: 0.513556\n",
      "[4308]\ttraining's binary_logloss: 0.51351\n",
      "[4309]\ttraining's binary_logloss: 0.513445\n",
      "[4310]\ttraining's binary_logloss: 0.513356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4311]\ttraining's binary_logloss: 0.513296\n",
      "[4312]\ttraining's binary_logloss: 0.513245\n",
      "[4313]\ttraining's binary_logloss: 0.513171\n",
      "[4314]\ttraining's binary_logloss: 0.513127\n",
      "[4315]\ttraining's binary_logloss: 0.513061\n",
      "[4316]\ttraining's binary_logloss: 0.513016\n",
      "[4317]\ttraining's binary_logloss: 0.512971\n",
      "[4318]\ttraining's binary_logloss: 0.512886\n",
      "[4319]\ttraining's binary_logloss: 0.512827\n",
      "[4320]\ttraining's binary_logloss: 0.512765\n",
      "[4321]\ttraining's binary_logloss: 0.512714\n",
      "[4322]\ttraining's binary_logloss: 0.512648\n",
      "[4323]\ttraining's binary_logloss: 0.512589\n",
      "[4324]\ttraining's binary_logloss: 0.512532\n",
      "[4325]\ttraining's binary_logloss: 0.512458\n",
      "[4326]\ttraining's binary_logloss: 0.512411\n",
      "[4327]\ttraining's binary_logloss: 0.512361\n",
      "[4328]\ttraining's binary_logloss: 0.51229\n",
      "[4329]\ttraining's binary_logloss: 0.512244\n",
      "[4330]\ttraining's binary_logloss: 0.512192\n",
      "[4331]\ttraining's binary_logloss: 0.512128\n",
      "[4332]\ttraining's binary_logloss: 0.512072\n",
      "[4333]\ttraining's binary_logloss: 0.512027\n",
      "[4334]\ttraining's binary_logloss: 0.511974\n",
      "[4335]\ttraining's binary_logloss: 0.511899\n",
      "[4336]\ttraining's binary_logloss: 0.511828\n",
      "[4337]\ttraining's binary_logloss: 0.511765\n",
      "[4338]\ttraining's binary_logloss: 0.511697\n",
      "[4339]\ttraining's binary_logloss: 0.511623\n",
      "[4340]\ttraining's binary_logloss: 0.511567\n",
      "[4341]\ttraining's binary_logloss: 0.511527\n",
      "[4342]\ttraining's binary_logloss: 0.511466\n",
      "[4343]\ttraining's binary_logloss: 0.511381\n",
      "[4344]\ttraining's binary_logloss: 0.511312\n",
      "[4345]\ttraining's binary_logloss: 0.511267\n",
      "[4346]\ttraining's binary_logloss: 0.511214\n",
      "[4347]\ttraining's binary_logloss: 0.511171\n",
      "[4348]\ttraining's binary_logloss: 0.511127\n",
      "[4349]\ttraining's binary_logloss: 0.511068\n",
      "[4350]\ttraining's binary_logloss: 0.510997\n",
      "[4351]\ttraining's binary_logloss: 0.510925\n",
      "[4352]\ttraining's binary_logloss: 0.510882\n",
      "[4353]\ttraining's binary_logloss: 0.510824\n",
      "[4354]\ttraining's binary_logloss: 0.510726\n",
      "[4355]\ttraining's binary_logloss: 0.51067\n",
      "[4356]\ttraining's binary_logloss: 0.510615\n",
      "[4357]\ttraining's binary_logloss: 0.510562\n",
      "[4358]\ttraining's binary_logloss: 0.510502\n",
      "[4359]\ttraining's binary_logloss: 0.510426\n",
      "[4360]\ttraining's binary_logloss: 0.510351\n",
      "[4361]\ttraining's binary_logloss: 0.510281\n",
      "[4362]\ttraining's binary_logloss: 0.510234\n",
      "[4363]\ttraining's binary_logloss: 0.510163\n",
      "[4364]\ttraining's binary_logloss: 0.510115\n",
      "[4365]\ttraining's binary_logloss: 0.510053\n",
      "[4366]\ttraining's binary_logloss: 0.509991\n",
      "[4367]\ttraining's binary_logloss: 0.509929\n",
      "[4368]\ttraining's binary_logloss: 0.509857\n",
      "[4369]\ttraining's binary_logloss: 0.509773\n",
      "[4370]\ttraining's binary_logloss: 0.509697\n",
      "[4371]\ttraining's binary_logloss: 0.509643\n",
      "[4372]\ttraining's binary_logloss: 0.509576\n",
      "[4373]\ttraining's binary_logloss: 0.509526\n",
      "[4374]\ttraining's binary_logloss: 0.509481\n",
      "[4375]\ttraining's binary_logloss: 0.509431\n",
      "[4376]\ttraining's binary_logloss: 0.509387\n",
      "[4377]\ttraining's binary_logloss: 0.509336\n",
      "[4378]\ttraining's binary_logloss: 0.509269\n",
      "[4379]\ttraining's binary_logloss: 0.509222\n",
      "[4380]\ttraining's binary_logloss: 0.509164\n",
      "[4381]\ttraining's binary_logloss: 0.509116\n",
      "[4382]\ttraining's binary_logloss: 0.509048\n",
      "[4383]\ttraining's binary_logloss: 0.508973\n",
      "[4384]\ttraining's binary_logloss: 0.508894\n",
      "[4385]\ttraining's binary_logloss: 0.508854\n",
      "[4386]\ttraining's binary_logloss: 0.508768\n",
      "[4387]\ttraining's binary_logloss: 0.508709\n",
      "[4388]\ttraining's binary_logloss: 0.508642\n",
      "[4389]\ttraining's binary_logloss: 0.50857\n",
      "[4390]\ttraining's binary_logloss: 0.508501\n",
      "[4391]\ttraining's binary_logloss: 0.508431\n",
      "[4392]\ttraining's binary_logloss: 0.508384\n",
      "[4393]\ttraining's binary_logloss: 0.508349\n",
      "[4394]\ttraining's binary_logloss: 0.508292\n",
      "[4395]\ttraining's binary_logloss: 0.508226\n",
      "[4396]\ttraining's binary_logloss: 0.508153\n",
      "[4397]\ttraining's binary_logloss: 0.508085\n",
      "[4398]\ttraining's binary_logloss: 0.508035\n",
      "[4399]\ttraining's binary_logloss: 0.507974\n",
      "[4400]\ttraining's binary_logloss: 0.507928\n",
      "[4401]\ttraining's binary_logloss: 0.50788\n",
      "[4402]\ttraining's binary_logloss: 0.507816\n",
      "[4403]\ttraining's binary_logloss: 0.507768\n",
      "[4404]\ttraining's binary_logloss: 0.507705\n",
      "[4405]\ttraining's binary_logloss: 0.507638\n",
      "[4406]\ttraining's binary_logloss: 0.507597\n",
      "[4407]\ttraining's binary_logloss: 0.507522\n",
      "[4408]\ttraining's binary_logloss: 0.507465\n",
      "[4409]\ttraining's binary_logloss: 0.507401\n",
      "[4410]\ttraining's binary_logloss: 0.507339\n",
      "[4411]\ttraining's binary_logloss: 0.507287\n",
      "[4412]\ttraining's binary_logloss: 0.507218\n",
      "[4413]\ttraining's binary_logloss: 0.507173\n",
      "[4414]\ttraining's binary_logloss: 0.507124\n",
      "[4415]\ttraining's binary_logloss: 0.50707\n",
      "[4416]\ttraining's binary_logloss: 0.507008\n",
      "[4417]\ttraining's binary_logloss: 0.506942\n",
      "[4418]\ttraining's binary_logloss: 0.506889\n",
      "[4419]\ttraining's binary_logloss: 0.506838\n",
      "[4420]\ttraining's binary_logloss: 0.50675\n",
      "[4421]\ttraining's binary_logloss: 0.506692\n",
      "[4422]\ttraining's binary_logloss: 0.506627\n",
      "[4423]\ttraining's binary_logloss: 0.506565\n",
      "[4424]\ttraining's binary_logloss: 0.50649\n",
      "[4425]\ttraining's binary_logloss: 0.506443\n",
      "[4426]\ttraining's binary_logloss: 0.5064\n",
      "[4427]\ttraining's binary_logloss: 0.506336\n",
      "[4428]\ttraining's binary_logloss: 0.506293\n",
      "[4429]\ttraining's binary_logloss: 0.506241\n",
      "[4430]\ttraining's binary_logloss: 0.506172\n",
      "[4431]\ttraining's binary_logloss: 0.506093\n",
      "[4432]\ttraining's binary_logloss: 0.506036\n",
      "[4433]\ttraining's binary_logloss: 0.505973\n",
      "[4434]\ttraining's binary_logloss: 0.505936\n",
      "[4435]\ttraining's binary_logloss: 0.50589\n",
      "[4436]\ttraining's binary_logloss: 0.505821\n",
      "[4437]\ttraining's binary_logloss: 0.505757\n",
      "[4438]\ttraining's binary_logloss: 0.505696\n",
      "[4439]\ttraining's binary_logloss: 0.50564\n",
      "[4440]\ttraining's binary_logloss: 0.505596\n",
      "[4441]\ttraining's binary_logloss: 0.505531\n",
      "[4442]\ttraining's binary_logloss: 0.505454\n",
      "[4443]\ttraining's binary_logloss: 0.505375\n",
      "[4444]\ttraining's binary_logloss: 0.505319\n",
      "[4445]\ttraining's binary_logloss: 0.505275\n",
      "[4446]\ttraining's binary_logloss: 0.505192\n",
      "[4447]\ttraining's binary_logloss: 0.505129\n",
      "[4448]\ttraining's binary_logloss: 0.505091\n",
      "[4449]\ttraining's binary_logloss: 0.505027\n",
      "[4450]\ttraining's binary_logloss: 0.504957\n",
      "[4451]\ttraining's binary_logloss: 0.504866\n",
      "[4452]\ttraining's binary_logloss: 0.5048\n",
      "[4453]\ttraining's binary_logloss: 0.504743\n",
      "[4454]\ttraining's binary_logloss: 0.504688\n",
      "[4455]\ttraining's binary_logloss: 0.504634\n",
      "[4456]\ttraining's binary_logloss: 0.504576\n",
      "[4457]\ttraining's binary_logloss: 0.504505\n",
      "[4458]\ttraining's binary_logloss: 0.504444\n",
      "[4459]\ttraining's binary_logloss: 0.504356\n",
      "[4460]\ttraining's binary_logloss: 0.504304\n",
      "[4461]\ttraining's binary_logloss: 0.504241\n",
      "[4462]\ttraining's binary_logloss: 0.504194\n",
      "[4463]\ttraining's binary_logloss: 0.504154\n",
      "[4464]\ttraining's binary_logloss: 0.504093\n",
      "[4465]\ttraining's binary_logloss: 0.504049\n",
      "[4466]\ttraining's binary_logloss: 0.503976\n",
      "[4467]\ttraining's binary_logloss: 0.503937\n",
      "[4468]\ttraining's binary_logloss: 0.503868\n",
      "[4469]\ttraining's binary_logloss: 0.503805\n",
      "[4470]\ttraining's binary_logloss: 0.503733\n",
      "[4471]\ttraining's binary_logloss: 0.503669\n",
      "[4472]\ttraining's binary_logloss: 0.5036\n",
      "[4473]\ttraining's binary_logloss: 0.503507\n",
      "[4474]\ttraining's binary_logloss: 0.503444\n",
      "[4475]\ttraining's binary_logloss: 0.503391\n",
      "[4476]\ttraining's binary_logloss: 0.503327\n",
      "[4477]\ttraining's binary_logloss: 0.503252\n",
      "[4478]\ttraining's binary_logloss: 0.503168\n",
      "[4479]\ttraining's binary_logloss: 0.50312\n",
      "[4480]\ttraining's binary_logloss: 0.503038\n",
      "[4481]\ttraining's binary_logloss: 0.502998\n",
      "[4482]\ttraining's binary_logloss: 0.502954\n",
      "[4483]\ttraining's binary_logloss: 0.502899\n",
      "[4484]\ttraining's binary_logloss: 0.502838\n",
      "[4485]\ttraining's binary_logloss: 0.502807\n",
      "[4486]\ttraining's binary_logloss: 0.502747\n",
      "[4487]\ttraining's binary_logloss: 0.502697\n",
      "[4488]\ttraining's binary_logloss: 0.502623\n",
      "[4489]\ttraining's binary_logloss: 0.502579\n",
      "[4490]\ttraining's binary_logloss: 0.502517\n",
      "[4491]\ttraining's binary_logloss: 0.502449\n",
      "[4492]\ttraining's binary_logloss: 0.502388\n",
      "[4493]\ttraining's binary_logloss: 0.502339\n",
      "[4494]\ttraining's binary_logloss: 0.50229\n",
      "[4495]\ttraining's binary_logloss: 0.502236\n",
      "[4496]\ttraining's binary_logloss: 0.502192\n",
      "[4497]\ttraining's binary_logloss: 0.502144\n",
      "[4498]\ttraining's binary_logloss: 0.502079\n",
      "[4499]\ttraining's binary_logloss: 0.502008\n",
      "[4500]\ttraining's binary_logloss: 0.501953\n",
      "[4501]\ttraining's binary_logloss: 0.501891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4502]\ttraining's binary_logloss: 0.501848\n",
      "[4503]\ttraining's binary_logloss: 0.50176\n",
      "[4504]\ttraining's binary_logloss: 0.50171\n",
      "[4505]\ttraining's binary_logloss: 0.501665\n",
      "[4506]\ttraining's binary_logloss: 0.501576\n",
      "[4507]\ttraining's binary_logloss: 0.501506\n",
      "[4508]\ttraining's binary_logloss: 0.501453\n",
      "[4509]\ttraining's binary_logloss: 0.501387\n",
      "[4510]\ttraining's binary_logloss: 0.501309\n",
      "[4511]\ttraining's binary_logloss: 0.501259\n",
      "[4512]\ttraining's binary_logloss: 0.501217\n",
      "[4513]\ttraining's binary_logloss: 0.501162\n",
      "[4514]\ttraining's binary_logloss: 0.501115\n",
      "[4515]\ttraining's binary_logloss: 0.501057\n",
      "[4516]\ttraining's binary_logloss: 0.500967\n",
      "[4517]\ttraining's binary_logloss: 0.500922\n",
      "[4518]\ttraining's binary_logloss: 0.50084\n",
      "[4519]\ttraining's binary_logloss: 0.500778\n",
      "[4520]\ttraining's binary_logloss: 0.50073\n",
      "[4521]\ttraining's binary_logloss: 0.500673\n",
      "[4522]\ttraining's binary_logloss: 0.500619\n",
      "[4523]\ttraining's binary_logloss: 0.500578\n",
      "[4524]\ttraining's binary_logloss: 0.500523\n",
      "[4525]\ttraining's binary_logloss: 0.50046\n",
      "[4526]\ttraining's binary_logloss: 0.500408\n",
      "[4527]\ttraining's binary_logloss: 0.500349\n",
      "[4528]\ttraining's binary_logloss: 0.500286\n",
      "[4529]\ttraining's binary_logloss: 0.500218\n",
      "[4530]\ttraining's binary_logloss: 0.500151\n",
      "[4531]\ttraining's binary_logloss: 0.500106\n",
      "[4532]\ttraining's binary_logloss: 0.500042\n",
      "[4533]\ttraining's binary_logloss: 0.499993\n",
      "[4534]\ttraining's binary_logloss: 0.49994\n",
      "[4535]\ttraining's binary_logloss: 0.499872\n",
      "[4536]\ttraining's binary_logloss: 0.499817\n",
      "[4537]\ttraining's binary_logloss: 0.499761\n",
      "[4538]\ttraining's binary_logloss: 0.4997\n",
      "[4539]\ttraining's binary_logloss: 0.49964\n",
      "[4540]\ttraining's binary_logloss: 0.499578\n",
      "[4541]\ttraining's binary_logloss: 0.499523\n",
      "[4542]\ttraining's binary_logloss: 0.49947\n",
      "[4543]\ttraining's binary_logloss: 0.499423\n",
      "[4544]\ttraining's binary_logloss: 0.499373\n",
      "[4545]\ttraining's binary_logloss: 0.499307\n",
      "[4546]\ttraining's binary_logloss: 0.499254\n",
      "[4547]\ttraining's binary_logloss: 0.499194\n",
      "[4548]\ttraining's binary_logloss: 0.499158\n",
      "[4549]\ttraining's binary_logloss: 0.499116\n",
      "[4550]\ttraining's binary_logloss: 0.499081\n",
      "[4551]\ttraining's binary_logloss: 0.499024\n",
      "[4552]\ttraining's binary_logloss: 0.498968\n",
      "[4553]\ttraining's binary_logloss: 0.498917\n",
      "[4554]\ttraining's binary_logloss: 0.498856\n",
      "[4555]\ttraining's binary_logloss: 0.49881\n",
      "[4556]\ttraining's binary_logloss: 0.498759\n",
      "[4557]\ttraining's binary_logloss: 0.498697\n",
      "[4558]\ttraining's binary_logloss: 0.498652\n",
      "[4559]\ttraining's binary_logloss: 0.498592\n",
      "[4560]\ttraining's binary_logloss: 0.498514\n",
      "[4561]\ttraining's binary_logloss: 0.498479\n",
      "[4562]\ttraining's binary_logloss: 0.498411\n",
      "[4563]\ttraining's binary_logloss: 0.498359\n",
      "[4564]\ttraining's binary_logloss: 0.498302\n",
      "[4565]\ttraining's binary_logloss: 0.498231\n",
      "[4566]\ttraining's binary_logloss: 0.498151\n",
      "[4567]\ttraining's binary_logloss: 0.498081\n",
      "[4568]\ttraining's binary_logloss: 0.49803\n",
      "[4569]\ttraining's binary_logloss: 0.497973\n",
      "[4570]\ttraining's binary_logloss: 0.497937\n",
      "[4571]\ttraining's binary_logloss: 0.497879\n",
      "[4572]\ttraining's binary_logloss: 0.497819\n",
      "[4573]\ttraining's binary_logloss: 0.497763\n",
      "[4574]\ttraining's binary_logloss: 0.497718\n",
      "[4575]\ttraining's binary_logloss: 0.497657\n",
      "[4576]\ttraining's binary_logloss: 0.497605\n",
      "[4577]\ttraining's binary_logloss: 0.49754\n",
      "[4578]\ttraining's binary_logloss: 0.497489\n",
      "[4579]\ttraining's binary_logloss: 0.497428\n",
      "[4580]\ttraining's binary_logloss: 0.497363\n",
      "[4581]\ttraining's binary_logloss: 0.497313\n",
      "[4582]\ttraining's binary_logloss: 0.497259\n",
      "[4583]\ttraining's binary_logloss: 0.497209\n",
      "[4584]\ttraining's binary_logloss: 0.497138\n",
      "[4585]\ttraining's binary_logloss: 0.497096\n",
      "[4586]\ttraining's binary_logloss: 0.497039\n",
      "[4587]\ttraining's binary_logloss: 0.496982\n",
      "[4588]\ttraining's binary_logloss: 0.496905\n",
      "[4589]\ttraining's binary_logloss: 0.496827\n",
      "[4590]\ttraining's binary_logloss: 0.496761\n",
      "[4591]\ttraining's binary_logloss: 0.496704\n",
      "[4592]\ttraining's binary_logloss: 0.496653\n",
      "[4593]\ttraining's binary_logloss: 0.496588\n",
      "[4594]\ttraining's binary_logloss: 0.496549\n",
      "[4595]\ttraining's binary_logloss: 0.496507\n",
      "[4596]\ttraining's binary_logloss: 0.496452\n",
      "[4597]\ttraining's binary_logloss: 0.496409\n",
      "[4598]\ttraining's binary_logloss: 0.496351\n",
      "[4599]\ttraining's binary_logloss: 0.496264\n",
      "[4600]\ttraining's binary_logloss: 0.496192\n",
      "[4601]\ttraining's binary_logloss: 0.496152\n",
      "[4602]\ttraining's binary_logloss: 0.496111\n",
      "[4603]\ttraining's binary_logloss: 0.496055\n",
      "[4604]\ttraining's binary_logloss: 0.496003\n",
      "[4605]\ttraining's binary_logloss: 0.495946\n",
      "[4606]\ttraining's binary_logloss: 0.495919\n",
      "[4607]\ttraining's binary_logloss: 0.495866\n",
      "[4608]\ttraining's binary_logloss: 0.495812\n",
      "[4609]\ttraining's binary_logloss: 0.495758\n",
      "[4610]\ttraining's binary_logloss: 0.49571\n",
      "[4611]\ttraining's binary_logloss: 0.495647\n",
      "[4612]\ttraining's binary_logloss: 0.495601\n",
      "[4613]\ttraining's binary_logloss: 0.495553\n",
      "[4614]\ttraining's binary_logloss: 0.495507\n",
      "[4615]\ttraining's binary_logloss: 0.495458\n",
      "[4616]\ttraining's binary_logloss: 0.495399\n",
      "[4617]\ttraining's binary_logloss: 0.49533\n",
      "[4618]\ttraining's binary_logloss: 0.495286\n",
      "[4619]\ttraining's binary_logloss: 0.495219\n",
      "[4620]\ttraining's binary_logloss: 0.495168\n",
      "[4621]\ttraining's binary_logloss: 0.495108\n",
      "[4622]\ttraining's binary_logloss: 0.495051\n",
      "[4623]\ttraining's binary_logloss: 0.494986\n",
      "[4624]\ttraining's binary_logloss: 0.494931\n",
      "[4625]\ttraining's binary_logloss: 0.494865\n",
      "[4626]\ttraining's binary_logloss: 0.494815\n",
      "[4627]\ttraining's binary_logloss: 0.494763\n",
      "[4628]\ttraining's binary_logloss: 0.494703\n",
      "[4629]\ttraining's binary_logloss: 0.494671\n",
      "[4630]\ttraining's binary_logloss: 0.494602\n",
      "[4631]\ttraining's binary_logloss: 0.494561\n",
      "[4632]\ttraining's binary_logloss: 0.49451\n",
      "[4633]\ttraining's binary_logloss: 0.494446\n",
      "[4634]\ttraining's binary_logloss: 0.494403\n",
      "[4635]\ttraining's binary_logloss: 0.494349\n",
      "[4636]\ttraining's binary_logloss: 0.494267\n",
      "[4637]\ttraining's binary_logloss: 0.494196\n",
      "[4638]\ttraining's binary_logloss: 0.494149\n",
      "[4639]\ttraining's binary_logloss: 0.494085\n",
      "[4640]\ttraining's binary_logloss: 0.494028\n",
      "[4641]\ttraining's binary_logloss: 0.493969\n",
      "[4642]\ttraining's binary_logloss: 0.49391\n",
      "[4643]\ttraining's binary_logloss: 0.493841\n",
      "[4644]\ttraining's binary_logloss: 0.49379\n",
      "[4645]\ttraining's binary_logloss: 0.493744\n",
      "[4646]\ttraining's binary_logloss: 0.493695\n",
      "[4647]\ttraining's binary_logloss: 0.493629\n",
      "[4648]\ttraining's binary_logloss: 0.493574\n",
      "[4649]\ttraining's binary_logloss: 0.493514\n",
      "[4650]\ttraining's binary_logloss: 0.49346\n",
      "[4651]\ttraining's binary_logloss: 0.493382\n",
      "[4652]\ttraining's binary_logloss: 0.493326\n",
      "[4653]\ttraining's binary_logloss: 0.493268\n",
      "[4654]\ttraining's binary_logloss: 0.493212\n",
      "[4655]\ttraining's binary_logloss: 0.493144\n",
      "[4656]\ttraining's binary_logloss: 0.493079\n",
      "[4657]\ttraining's binary_logloss: 0.49302\n",
      "[4658]\ttraining's binary_logloss: 0.492963\n",
      "[4659]\ttraining's binary_logloss: 0.492928\n",
      "[4660]\ttraining's binary_logloss: 0.492883\n",
      "[4661]\ttraining's binary_logloss: 0.492834\n",
      "[4662]\ttraining's binary_logloss: 0.492767\n",
      "[4663]\ttraining's binary_logloss: 0.492716\n",
      "[4664]\ttraining's binary_logloss: 0.49265\n",
      "[4665]\ttraining's binary_logloss: 0.492603\n",
      "[4666]\ttraining's binary_logloss: 0.492547\n",
      "[4667]\ttraining's binary_logloss: 0.492502\n",
      "[4668]\ttraining's binary_logloss: 0.49245\n",
      "[4669]\ttraining's binary_logloss: 0.492374\n",
      "[4670]\ttraining's binary_logloss: 0.492316\n",
      "[4671]\ttraining's binary_logloss: 0.49225\n",
      "[4672]\ttraining's binary_logloss: 0.492204\n",
      "[4673]\ttraining's binary_logloss: 0.492137\n",
      "[4674]\ttraining's binary_logloss: 0.492065\n",
      "[4675]\ttraining's binary_logloss: 0.492009\n",
      "[4676]\ttraining's binary_logloss: 0.491964\n",
      "[4677]\ttraining's binary_logloss: 0.491914\n",
      "[4678]\ttraining's binary_logloss: 0.491855\n",
      "[4679]\ttraining's binary_logloss: 0.491807\n",
      "[4680]\ttraining's binary_logloss: 0.491761\n",
      "[4681]\ttraining's binary_logloss: 0.491712\n",
      "[4682]\ttraining's binary_logloss: 0.49168\n",
      "[4683]\ttraining's binary_logloss: 0.491622\n",
      "[4684]\ttraining's binary_logloss: 0.491585\n",
      "[4685]\ttraining's binary_logloss: 0.491517\n",
      "[4686]\ttraining's binary_logloss: 0.491454\n",
      "[4687]\ttraining's binary_logloss: 0.491391\n",
      "[4688]\ttraining's binary_logloss: 0.491356\n",
      "[4689]\ttraining's binary_logloss: 0.491297\n",
      "[4690]\ttraining's binary_logloss: 0.491233\n",
      "[4691]\ttraining's binary_logloss: 0.491162\n",
      "[4692]\ttraining's binary_logloss: 0.491101\n",
      "[4693]\ttraining's binary_logloss: 0.491043\n",
      "[4694]\ttraining's binary_logloss: 0.490963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4695]\ttraining's binary_logloss: 0.490914\n",
      "[4696]\ttraining's binary_logloss: 0.490873\n",
      "[4697]\ttraining's binary_logloss: 0.490816\n",
      "[4698]\ttraining's binary_logloss: 0.49076\n",
      "[4699]\ttraining's binary_logloss: 0.490711\n",
      "[4700]\ttraining's binary_logloss: 0.49063\n",
      "[4701]\ttraining's binary_logloss: 0.490588\n",
      "[4702]\ttraining's binary_logloss: 0.490537\n",
      "[4703]\ttraining's binary_logloss: 0.490498\n",
      "[4704]\ttraining's binary_logloss: 0.490453\n",
      "[4705]\ttraining's binary_logloss: 0.490394\n",
      "[4706]\ttraining's binary_logloss: 0.490334\n",
      "[4707]\ttraining's binary_logloss: 0.490299\n",
      "[4708]\ttraining's binary_logloss: 0.490257\n",
      "[4709]\ttraining's binary_logloss: 0.490185\n",
      "[4710]\ttraining's binary_logloss: 0.490116\n",
      "[4711]\ttraining's binary_logloss: 0.490033\n",
      "[4712]\ttraining's binary_logloss: 0.489966\n",
      "[4713]\ttraining's binary_logloss: 0.489909\n",
      "[4714]\ttraining's binary_logloss: 0.489823\n",
      "[4715]\ttraining's binary_logloss: 0.489782\n",
      "[4716]\ttraining's binary_logloss: 0.489727\n",
      "[4717]\ttraining's binary_logloss: 0.489657\n",
      "[4718]\ttraining's binary_logloss: 0.489601\n",
      "[4719]\ttraining's binary_logloss: 0.489532\n",
      "[4720]\ttraining's binary_logloss: 0.489491\n",
      "[4721]\ttraining's binary_logloss: 0.489418\n",
      "[4722]\ttraining's binary_logloss: 0.489367\n",
      "[4723]\ttraining's binary_logloss: 0.489303\n",
      "[4724]\ttraining's binary_logloss: 0.489221\n",
      "[4725]\ttraining's binary_logloss: 0.489175\n",
      "[4726]\ttraining's binary_logloss: 0.489122\n",
      "[4727]\ttraining's binary_logloss: 0.489065\n",
      "[4728]\ttraining's binary_logloss: 0.488994\n",
      "[4729]\ttraining's binary_logloss: 0.488941\n",
      "[4730]\ttraining's binary_logloss: 0.488873\n",
      "[4731]\ttraining's binary_logloss: 0.488825\n",
      "[4732]\ttraining's binary_logloss: 0.48878\n",
      "[4733]\ttraining's binary_logloss: 0.488726\n",
      "[4734]\ttraining's binary_logloss: 0.488654\n",
      "[4735]\ttraining's binary_logloss: 0.488587\n",
      "[4736]\ttraining's binary_logloss: 0.488532\n",
      "[4737]\ttraining's binary_logloss: 0.488452\n",
      "[4738]\ttraining's binary_logloss: 0.488399\n",
      "[4739]\ttraining's binary_logloss: 0.488352\n",
      "[4740]\ttraining's binary_logloss: 0.488304\n",
      "[4741]\ttraining's binary_logloss: 0.488266\n",
      "[4742]\ttraining's binary_logloss: 0.488216\n",
      "[4743]\ttraining's binary_logloss: 0.488156\n",
      "[4744]\ttraining's binary_logloss: 0.488106\n",
      "[4745]\ttraining's binary_logloss: 0.488048\n",
      "[4746]\ttraining's binary_logloss: 0.487992\n",
      "[4747]\ttraining's binary_logloss: 0.487945\n",
      "[4748]\ttraining's binary_logloss: 0.487865\n",
      "[4749]\ttraining's binary_logloss: 0.48781\n",
      "[4750]\ttraining's binary_logloss: 0.487761\n",
      "[4751]\ttraining's binary_logloss: 0.487713\n",
      "[4752]\ttraining's binary_logloss: 0.487652\n",
      "[4753]\ttraining's binary_logloss: 0.487576\n",
      "[4754]\ttraining's binary_logloss: 0.487522\n",
      "[4755]\ttraining's binary_logloss: 0.487468\n",
      "[4756]\ttraining's binary_logloss: 0.487402\n",
      "[4757]\ttraining's binary_logloss: 0.487348\n",
      "[4758]\ttraining's binary_logloss: 0.487312\n",
      "[4759]\ttraining's binary_logloss: 0.487267\n",
      "[4760]\ttraining's binary_logloss: 0.487205\n",
      "[4761]\ttraining's binary_logloss: 0.48715\n",
      "[4762]\ttraining's binary_logloss: 0.4871\n",
      "[4763]\ttraining's binary_logloss: 0.487055\n",
      "[4764]\ttraining's binary_logloss: 0.487012\n",
      "[4765]\ttraining's binary_logloss: 0.486954\n",
      "[4766]\ttraining's binary_logloss: 0.486887\n",
      "[4767]\ttraining's binary_logloss: 0.486814\n",
      "[4768]\ttraining's binary_logloss: 0.486772\n",
      "[4769]\ttraining's binary_logloss: 0.486714\n",
      "[4770]\ttraining's binary_logloss: 0.48668\n",
      "[4771]\ttraining's binary_logloss: 0.486631\n",
      "[4772]\ttraining's binary_logloss: 0.48658\n",
      "[4773]\ttraining's binary_logloss: 0.486518\n",
      "[4774]\ttraining's binary_logloss: 0.486478\n",
      "[4775]\ttraining's binary_logloss: 0.486434\n",
      "[4776]\ttraining's binary_logloss: 0.486368\n",
      "[4777]\ttraining's binary_logloss: 0.486305\n",
      "[4778]\ttraining's binary_logloss: 0.486245\n",
      "[4779]\ttraining's binary_logloss: 0.486199\n",
      "[4780]\ttraining's binary_logloss: 0.486152\n",
      "[4781]\ttraining's binary_logloss: 0.486116\n",
      "[4782]\ttraining's binary_logloss: 0.486068\n",
      "[4783]\ttraining's binary_logloss: 0.486023\n",
      "[4784]\ttraining's binary_logloss: 0.485959\n",
      "[4785]\ttraining's binary_logloss: 0.48589\n",
      "[4786]\ttraining's binary_logloss: 0.485846\n",
      "[4787]\ttraining's binary_logloss: 0.485778\n",
      "[4788]\ttraining's binary_logloss: 0.485702\n",
      "[4789]\ttraining's binary_logloss: 0.485647\n",
      "[4790]\ttraining's binary_logloss: 0.48561\n",
      "[4791]\ttraining's binary_logloss: 0.485555\n",
      "[4792]\ttraining's binary_logloss: 0.485508\n",
      "[4793]\ttraining's binary_logloss: 0.485452\n",
      "[4794]\ttraining's binary_logloss: 0.485382\n",
      "[4795]\ttraining's binary_logloss: 0.485348\n",
      "[4796]\ttraining's binary_logloss: 0.48525\n",
      "[4797]\ttraining's binary_logloss: 0.485191\n",
      "[4798]\ttraining's binary_logloss: 0.485146\n",
      "[4799]\ttraining's binary_logloss: 0.485101\n",
      "[4800]\ttraining's binary_logloss: 0.485037\n",
      "[4801]\ttraining's binary_logloss: 0.48497\n",
      "[4802]\ttraining's binary_logloss: 0.484893\n",
      "[4803]\ttraining's binary_logloss: 0.48484\n",
      "[4804]\ttraining's binary_logloss: 0.484762\n",
      "[4805]\ttraining's binary_logloss: 0.484721\n",
      "[4806]\ttraining's binary_logloss: 0.48468\n",
      "[4807]\ttraining's binary_logloss: 0.484621\n",
      "[4808]\ttraining's binary_logloss: 0.484573\n",
      "[4809]\ttraining's binary_logloss: 0.48452\n",
      "[4810]\ttraining's binary_logloss: 0.484477\n",
      "[4811]\ttraining's binary_logloss: 0.484438\n",
      "[4812]\ttraining's binary_logloss: 0.48438\n",
      "[4813]\ttraining's binary_logloss: 0.484339\n",
      "[4814]\ttraining's binary_logloss: 0.484286\n",
      "[4815]\ttraining's binary_logloss: 0.484237\n",
      "[4816]\ttraining's binary_logloss: 0.484178\n",
      "[4817]\ttraining's binary_logloss: 0.48412\n",
      "[4818]\ttraining's binary_logloss: 0.484052\n",
      "[4819]\ttraining's binary_logloss: 0.483993\n",
      "[4820]\ttraining's binary_logloss: 0.483954\n",
      "[4821]\ttraining's binary_logloss: 0.48391\n",
      "[4822]\ttraining's binary_logloss: 0.483862\n",
      "[4823]\ttraining's binary_logloss: 0.483815\n",
      "[4824]\ttraining's binary_logloss: 0.48375\n",
      "[4825]\ttraining's binary_logloss: 0.483708\n",
      "[4826]\ttraining's binary_logloss: 0.483663\n",
      "[4827]\ttraining's binary_logloss: 0.483621\n",
      "[4828]\ttraining's binary_logloss: 0.48357\n",
      "[4829]\ttraining's binary_logloss: 0.483506\n",
      "[4830]\ttraining's binary_logloss: 0.48344\n",
      "[4831]\ttraining's binary_logloss: 0.483377\n",
      "[4832]\ttraining's binary_logloss: 0.483312\n",
      "[4833]\ttraining's binary_logloss: 0.483265\n",
      "[4834]\ttraining's binary_logloss: 0.483219\n",
      "[4835]\ttraining's binary_logloss: 0.483152\n",
      "[4836]\ttraining's binary_logloss: 0.483076\n",
      "[4837]\ttraining's binary_logloss: 0.483015\n",
      "[4838]\ttraining's binary_logloss: 0.48296\n",
      "[4839]\ttraining's binary_logloss: 0.482883\n",
      "[4840]\ttraining's binary_logloss: 0.482815\n",
      "[4841]\ttraining's binary_logloss: 0.482774\n",
      "[4842]\ttraining's binary_logloss: 0.482704\n",
      "[4843]\ttraining's binary_logloss: 0.482657\n",
      "[4844]\ttraining's binary_logloss: 0.482598\n",
      "[4845]\ttraining's binary_logloss: 0.482551\n",
      "[4846]\ttraining's binary_logloss: 0.482478\n",
      "[4847]\ttraining's binary_logloss: 0.482423\n",
      "[4848]\ttraining's binary_logloss: 0.48237\n",
      "[4849]\ttraining's binary_logloss: 0.482304\n",
      "[4850]\ttraining's binary_logloss: 0.482252\n",
      "[4851]\ttraining's binary_logloss: 0.482196\n",
      "[4852]\ttraining's binary_logloss: 0.482152\n",
      "[4853]\ttraining's binary_logloss: 0.482112\n",
      "[4854]\ttraining's binary_logloss: 0.482041\n",
      "[4855]\ttraining's binary_logloss: 0.481972\n",
      "[4856]\ttraining's binary_logloss: 0.481938\n",
      "[4857]\ttraining's binary_logloss: 0.481845\n",
      "[4858]\ttraining's binary_logloss: 0.481793\n",
      "[4859]\ttraining's binary_logloss: 0.481746\n",
      "[4860]\ttraining's binary_logloss: 0.481698\n",
      "[4861]\ttraining's binary_logloss: 0.481636\n",
      "[4862]\ttraining's binary_logloss: 0.481596\n",
      "[4863]\ttraining's binary_logloss: 0.481545\n",
      "[4864]\ttraining's binary_logloss: 0.4815\n",
      "[4865]\ttraining's binary_logloss: 0.481447\n",
      "[4866]\ttraining's binary_logloss: 0.481375\n",
      "[4867]\ttraining's binary_logloss: 0.481333\n",
      "[4868]\ttraining's binary_logloss: 0.481293\n",
      "[4869]\ttraining's binary_logloss: 0.481251\n",
      "[4870]\ttraining's binary_logloss: 0.481206\n",
      "[4871]\ttraining's binary_logloss: 0.481154\n",
      "[4872]\ttraining's binary_logloss: 0.481095\n",
      "[4873]\ttraining's binary_logloss: 0.481032\n",
      "[4874]\ttraining's binary_logloss: 0.480971\n",
      "[4875]\ttraining's binary_logloss: 0.480906\n",
      "[4876]\ttraining's binary_logloss: 0.480829\n",
      "[4877]\ttraining's binary_logloss: 0.480789\n",
      "[4878]\ttraining's binary_logloss: 0.480744\n",
      "[4879]\ttraining's binary_logloss: 0.48069\n",
      "[4880]\ttraining's binary_logloss: 0.480641\n",
      "[4881]\ttraining's binary_logloss: 0.4806\n",
      "[4882]\ttraining's binary_logloss: 0.480553\n",
      "[4883]\ttraining's binary_logloss: 0.480519\n",
      "[4884]\ttraining's binary_logloss: 0.48045\n",
      "[4885]\ttraining's binary_logloss: 0.480408\n",
      "[4886]\ttraining's binary_logloss: 0.48036\n",
      "[4887]\ttraining's binary_logloss: 0.480329\n",
      "[4888]\ttraining's binary_logloss: 0.480275\n",
      "[4889]\ttraining's binary_logloss: 0.480236\n",
      "[4890]\ttraining's binary_logloss: 0.480197\n",
      "[4891]\ttraining's binary_logloss: 0.480149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4892]\ttraining's binary_logloss: 0.480073\n",
      "[4893]\ttraining's binary_logloss: 0.480028\n",
      "[4894]\ttraining's binary_logloss: 0.479982\n",
      "[4895]\ttraining's binary_logloss: 0.479925\n",
      "[4896]\ttraining's binary_logloss: 0.479875\n",
      "[4897]\ttraining's binary_logloss: 0.479813\n",
      "[4898]\ttraining's binary_logloss: 0.479764\n",
      "[4899]\ttraining's binary_logloss: 0.479727\n",
      "[4900]\ttraining's binary_logloss: 0.479685\n",
      "[4901]\ttraining's binary_logloss: 0.479633\n",
      "[4902]\ttraining's binary_logloss: 0.479577\n",
      "[4903]\ttraining's binary_logloss: 0.479535\n",
      "[4904]\ttraining's binary_logloss: 0.479473\n",
      "[4905]\ttraining's binary_logloss: 0.479408\n",
      "[4906]\ttraining's binary_logloss: 0.479359\n",
      "[4907]\ttraining's binary_logloss: 0.479312\n",
      "[4908]\ttraining's binary_logloss: 0.479261\n",
      "[4909]\ttraining's binary_logloss: 0.479209\n",
      "[4910]\ttraining's binary_logloss: 0.479189\n",
      "[4911]\ttraining's binary_logloss: 0.479125\n",
      "[4912]\ttraining's binary_logloss: 0.479066\n",
      "[4913]\ttraining's binary_logloss: 0.478995\n",
      "[4914]\ttraining's binary_logloss: 0.478916\n",
      "[4915]\ttraining's binary_logloss: 0.478865\n",
      "[4916]\ttraining's binary_logloss: 0.478808\n",
      "[4917]\ttraining's binary_logloss: 0.478758\n",
      "[4918]\ttraining's binary_logloss: 0.47871\n",
      "[4919]\ttraining's binary_logloss: 0.478668\n",
      "[4920]\ttraining's binary_logloss: 0.478624\n",
      "[4921]\ttraining's binary_logloss: 0.478564\n",
      "[4922]\ttraining's binary_logloss: 0.478511\n",
      "[4923]\ttraining's binary_logloss: 0.478457\n",
      "[4924]\ttraining's binary_logloss: 0.478405\n",
      "[4925]\ttraining's binary_logloss: 0.47834\n",
      "[4926]\ttraining's binary_logloss: 0.478272\n",
      "[4927]\ttraining's binary_logloss: 0.478226\n",
      "[4928]\ttraining's binary_logloss: 0.47818\n",
      "[4929]\ttraining's binary_logloss: 0.478115\n",
      "[4930]\ttraining's binary_logloss: 0.478047\n",
      "[4931]\ttraining's binary_logloss: 0.477978\n",
      "[4932]\ttraining's binary_logloss: 0.477906\n",
      "[4933]\ttraining's binary_logloss: 0.477854\n",
      "[4934]\ttraining's binary_logloss: 0.477794\n",
      "[4935]\ttraining's binary_logloss: 0.477697\n",
      "[4936]\ttraining's binary_logloss: 0.477632\n",
      "[4937]\ttraining's binary_logloss: 0.477586\n",
      "[4938]\ttraining's binary_logloss: 0.477527\n",
      "[4939]\ttraining's binary_logloss: 0.477477\n",
      "[4940]\ttraining's binary_logloss: 0.477443\n",
      "[4941]\ttraining's binary_logloss: 0.477367\n",
      "[4942]\ttraining's binary_logloss: 0.477321\n",
      "[4943]\ttraining's binary_logloss: 0.477252\n",
      "[4944]\ttraining's binary_logloss: 0.477201\n",
      "[4945]\ttraining's binary_logloss: 0.477159\n",
      "[4946]\ttraining's binary_logloss: 0.47711\n",
      "[4947]\ttraining's binary_logloss: 0.477068\n",
      "[4948]\ttraining's binary_logloss: 0.477033\n",
      "[4949]\ttraining's binary_logloss: 0.476989\n",
      "[4950]\ttraining's binary_logloss: 0.476945\n",
      "[4951]\ttraining's binary_logloss: 0.476898\n",
      "[4952]\ttraining's binary_logloss: 0.476841\n",
      "[4953]\ttraining's binary_logloss: 0.476797\n",
      "[4954]\ttraining's binary_logloss: 0.476745\n",
      "[4955]\ttraining's binary_logloss: 0.476694\n",
      "[4956]\ttraining's binary_logloss: 0.476648\n",
      "[4957]\ttraining's binary_logloss: 0.476605\n",
      "[4958]\ttraining's binary_logloss: 0.476561\n",
      "[4959]\ttraining's binary_logloss: 0.476502\n",
      "[4960]\ttraining's binary_logloss: 0.476428\n",
      "[4961]\ttraining's binary_logloss: 0.476361\n",
      "[4962]\ttraining's binary_logloss: 0.4763\n",
      "[4963]\ttraining's binary_logloss: 0.476257\n",
      "[4964]\ttraining's binary_logloss: 0.476209\n",
      "[4965]\ttraining's binary_logloss: 0.476132\n",
      "[4966]\ttraining's binary_logloss: 0.47609\n",
      "[4967]\ttraining's binary_logloss: 0.476027\n",
      "[4968]\ttraining's binary_logloss: 0.475973\n",
      "[4969]\ttraining's binary_logloss: 0.47591\n",
      "[4970]\ttraining's binary_logloss: 0.475862\n",
      "[4971]\ttraining's binary_logloss: 0.475811\n",
      "[4972]\ttraining's binary_logloss: 0.475759\n",
      "[4973]\ttraining's binary_logloss: 0.475703\n",
      "[4974]\ttraining's binary_logloss: 0.475652\n",
      "[4975]\ttraining's binary_logloss: 0.475605\n",
      "[4976]\ttraining's binary_logloss: 0.475517\n",
      "[4977]\ttraining's binary_logloss: 0.475444\n",
      "[4978]\ttraining's binary_logloss: 0.475408\n",
      "[4979]\ttraining's binary_logloss: 0.47535\n",
      "[4980]\ttraining's binary_logloss: 0.475281\n",
      "[4981]\ttraining's binary_logloss: 0.475222\n",
      "[4982]\ttraining's binary_logloss: 0.475179\n",
      "[4983]\ttraining's binary_logloss: 0.475132\n",
      "[4984]\ttraining's binary_logloss: 0.475091\n",
      "[4985]\ttraining's binary_logloss: 0.475052\n",
      "[4986]\ttraining's binary_logloss: 0.474991\n",
      "[4987]\ttraining's binary_logloss: 0.474947\n",
      "[4988]\ttraining's binary_logloss: 0.474889\n",
      "[4989]\ttraining's binary_logloss: 0.474825\n",
      "[4990]\ttraining's binary_logloss: 0.474757\n",
      "[4991]\ttraining's binary_logloss: 0.474711\n",
      "[4992]\ttraining's binary_logloss: 0.474651\n",
      "[4993]\ttraining's binary_logloss: 0.474607\n",
      "[4994]\ttraining's binary_logloss: 0.474552\n",
      "[4995]\ttraining's binary_logloss: 0.474507\n",
      "[4996]\ttraining's binary_logloss: 0.474444\n",
      "[4997]\ttraining's binary_logloss: 0.474391\n",
      "[4998]\ttraining's binary_logloss: 0.474327\n",
      "[4999]\ttraining's binary_logloss: 0.474287\n",
      "[5000]\ttraining's binary_logloss: 0.474225\n",
      "[5001]\ttraining's binary_logloss: 0.474158\n",
      "[5002]\ttraining's binary_logloss: 0.474095\n",
      "[5003]\ttraining's binary_logloss: 0.474045\n",
      "[5004]\ttraining's binary_logloss: 0.473998\n",
      "[5005]\ttraining's binary_logloss: 0.47394\n",
      "[5006]\ttraining's binary_logloss: 0.473876\n",
      "[5007]\ttraining's binary_logloss: 0.473833\n",
      "[5008]\ttraining's binary_logloss: 0.473788\n",
      "[5009]\ttraining's binary_logloss: 0.473748\n",
      "[5010]\ttraining's binary_logloss: 0.473687\n",
      "[5011]\ttraining's binary_logloss: 0.473643\n",
      "[5012]\ttraining's binary_logloss: 0.473585\n",
      "[5013]\ttraining's binary_logloss: 0.473533\n",
      "[5014]\ttraining's binary_logloss: 0.473494\n",
      "[5015]\ttraining's binary_logloss: 0.473448\n",
      "[5016]\ttraining's binary_logloss: 0.473388\n",
      "[5017]\ttraining's binary_logloss: 0.473344\n",
      "[5018]\ttraining's binary_logloss: 0.473298\n",
      "[5019]\ttraining's binary_logloss: 0.473251\n",
      "[5020]\ttraining's binary_logloss: 0.473189\n",
      "[5021]\ttraining's binary_logloss: 0.473124\n",
      "[5022]\ttraining's binary_logloss: 0.47307\n",
      "[5023]\ttraining's binary_logloss: 0.473009\n",
      "[5024]\ttraining's binary_logloss: 0.472968\n",
      "[5025]\ttraining's binary_logloss: 0.472921\n",
      "[5026]\ttraining's binary_logloss: 0.472859\n",
      "[5027]\ttraining's binary_logloss: 0.472813\n",
      "[5028]\ttraining's binary_logloss: 0.472762\n",
      "[5029]\ttraining's binary_logloss: 0.472708\n",
      "[5030]\ttraining's binary_logloss: 0.472659\n",
      "[5031]\ttraining's binary_logloss: 0.472604\n",
      "[5032]\ttraining's binary_logloss: 0.472552\n",
      "[5033]\ttraining's binary_logloss: 0.472502\n",
      "[5034]\ttraining's binary_logloss: 0.472458\n",
      "[5035]\ttraining's binary_logloss: 0.472401\n",
      "[5036]\ttraining's binary_logloss: 0.472364\n",
      "[5037]\ttraining's binary_logloss: 0.472317\n",
      "[5038]\ttraining's binary_logloss: 0.472254\n",
      "[5039]\ttraining's binary_logloss: 0.472209\n",
      "[5040]\ttraining's binary_logloss: 0.472161\n",
      "[5041]\ttraining's binary_logloss: 0.472102\n",
      "[5042]\ttraining's binary_logloss: 0.472049\n",
      "[5043]\ttraining's binary_logloss: 0.471994\n",
      "[5044]\ttraining's binary_logloss: 0.471942\n",
      "[5045]\ttraining's binary_logloss: 0.471892\n",
      "[5046]\ttraining's binary_logloss: 0.471862\n",
      "[5047]\ttraining's binary_logloss: 0.471799\n",
      "[5048]\ttraining's binary_logloss: 0.471753\n",
      "[5049]\ttraining's binary_logloss: 0.471698\n",
      "[5050]\ttraining's binary_logloss: 0.471643\n",
      "[5051]\ttraining's binary_logloss: 0.471599\n",
      "[5052]\ttraining's binary_logloss: 0.471561\n",
      "[5053]\ttraining's binary_logloss: 0.471497\n",
      "[5054]\ttraining's binary_logloss: 0.471448\n",
      "[5055]\ttraining's binary_logloss: 0.471394\n",
      "[5056]\ttraining's binary_logloss: 0.471344\n",
      "[5057]\ttraining's binary_logloss: 0.471301\n",
      "[5058]\ttraining's binary_logloss: 0.47124\n",
      "[5059]\ttraining's binary_logloss: 0.471183\n",
      "[5060]\ttraining's binary_logloss: 0.471134\n",
      "[5061]\ttraining's binary_logloss: 0.471092\n",
      "[5062]\ttraining's binary_logloss: 0.471037\n",
      "[5063]\ttraining's binary_logloss: 0.47097\n",
      "[5064]\ttraining's binary_logloss: 0.470914\n",
      "[5065]\ttraining's binary_logloss: 0.470873\n",
      "[5066]\ttraining's binary_logloss: 0.47083\n",
      "[5067]\ttraining's binary_logloss: 0.470786\n",
      "[5068]\ttraining's binary_logloss: 0.470729\n",
      "[5069]\ttraining's binary_logloss: 0.470674\n",
      "[5070]\ttraining's binary_logloss: 0.470633\n",
      "[5071]\ttraining's binary_logloss: 0.470575\n",
      "[5072]\ttraining's binary_logloss: 0.470542\n",
      "[5073]\ttraining's binary_logloss: 0.470484\n",
      "[5074]\ttraining's binary_logloss: 0.470433\n",
      "[5075]\ttraining's binary_logloss: 0.470389\n",
      "[5076]\ttraining's binary_logloss: 0.470349\n",
      "[5077]\ttraining's binary_logloss: 0.470287\n",
      "[5078]\ttraining's binary_logloss: 0.470238\n",
      "[5079]\ttraining's binary_logloss: 0.470192\n",
      "[5080]\ttraining's binary_logloss: 0.470146\n",
      "[5081]\ttraining's binary_logloss: 0.470084\n",
      "[5082]\ttraining's binary_logloss: 0.470032\n",
      "[5083]\ttraining's binary_logloss: 0.46999\n",
      "[5084]\ttraining's binary_logloss: 0.469935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5085]\ttraining's binary_logloss: 0.46989\n",
      "[5086]\ttraining's binary_logloss: 0.469858\n",
      "[5087]\ttraining's binary_logloss: 0.469808\n",
      "[5088]\ttraining's binary_logloss: 0.469751\n",
      "[5089]\ttraining's binary_logloss: 0.469697\n",
      "[5090]\ttraining's binary_logloss: 0.469631\n",
      "[5091]\ttraining's binary_logloss: 0.469578\n",
      "[5092]\ttraining's binary_logloss: 0.469543\n",
      "[5093]\ttraining's binary_logloss: 0.469477\n",
      "[5094]\ttraining's binary_logloss: 0.469413\n",
      "[5095]\ttraining's binary_logloss: 0.469342\n",
      "[5096]\ttraining's binary_logloss: 0.469292\n",
      "[5097]\ttraining's binary_logloss: 0.469247\n",
      "[5098]\ttraining's binary_logloss: 0.469205\n",
      "[5099]\ttraining's binary_logloss: 0.46916\n",
      "[5100]\ttraining's binary_logloss: 0.469101\n",
      "[5101]\ttraining's binary_logloss: 0.469028\n",
      "[5102]\ttraining's binary_logloss: 0.468973\n",
      "[5103]\ttraining's binary_logloss: 0.468922\n",
      "[5104]\ttraining's binary_logloss: 0.468852\n",
      "[5105]\ttraining's binary_logloss: 0.468813\n",
      "[5106]\ttraining's binary_logloss: 0.468758\n",
      "[5107]\ttraining's binary_logloss: 0.468714\n",
      "[5108]\ttraining's binary_logloss: 0.468632\n",
      "[5109]\ttraining's binary_logloss: 0.46858\n",
      "[5110]\ttraining's binary_logloss: 0.468525\n",
      "[5111]\ttraining's binary_logloss: 0.468483\n",
      "[5112]\ttraining's binary_logloss: 0.468419\n",
      "[5113]\ttraining's binary_logloss: 0.468381\n",
      "[5114]\ttraining's binary_logloss: 0.468327\n",
      "[5115]\ttraining's binary_logloss: 0.46828\n",
      "[5116]\ttraining's binary_logloss: 0.46821\n",
      "[5117]\ttraining's binary_logloss: 0.468152\n",
      "[5118]\ttraining's binary_logloss: 0.468104\n",
      "[5119]\ttraining's binary_logloss: 0.468047\n",
      "[5120]\ttraining's binary_logloss: 0.468011\n",
      "[5121]\ttraining's binary_logloss: 0.467973\n",
      "[5122]\ttraining's binary_logloss: 0.467909\n",
      "[5123]\ttraining's binary_logloss: 0.467855\n",
      "[5124]\ttraining's binary_logloss: 0.467813\n",
      "[5125]\ttraining's binary_logloss: 0.467754\n",
      "[5126]\ttraining's binary_logloss: 0.467712\n",
      "[5127]\ttraining's binary_logloss: 0.467667\n",
      "[5128]\ttraining's binary_logloss: 0.467617\n",
      "[5129]\ttraining's binary_logloss: 0.467567\n",
      "[5130]\ttraining's binary_logloss: 0.467525\n",
      "[5131]\ttraining's binary_logloss: 0.467457\n",
      "[5132]\ttraining's binary_logloss: 0.467404\n",
      "[5133]\ttraining's binary_logloss: 0.467353\n",
      "[5134]\ttraining's binary_logloss: 0.467282\n",
      "[5135]\ttraining's binary_logloss: 0.467245\n",
      "[5136]\ttraining's binary_logloss: 0.467186\n",
      "[5137]\ttraining's binary_logloss: 0.467135\n",
      "[5138]\ttraining's binary_logloss: 0.467082\n",
      "[5139]\ttraining's binary_logloss: 0.46704\n",
      "[5140]\ttraining's binary_logloss: 0.466996\n",
      "[5141]\ttraining's binary_logloss: 0.466955\n",
      "[5142]\ttraining's binary_logloss: 0.466904\n",
      "[5143]\ttraining's binary_logloss: 0.466861\n",
      "[5144]\ttraining's binary_logloss: 0.466831\n",
      "[5145]\ttraining's binary_logloss: 0.466786\n",
      "[5146]\ttraining's binary_logloss: 0.466751\n",
      "[5147]\ttraining's binary_logloss: 0.466714\n",
      "[5148]\ttraining's binary_logloss: 0.466651\n",
      "[5149]\ttraining's binary_logloss: 0.466612\n",
      "[5150]\ttraining's binary_logloss: 0.46656\n",
      "[5151]\ttraining's binary_logloss: 0.466504\n",
      "[5152]\ttraining's binary_logloss: 0.466436\n",
      "[5153]\ttraining's binary_logloss: 0.466374\n",
      "[5154]\ttraining's binary_logloss: 0.466321\n",
      "[5155]\ttraining's binary_logloss: 0.466236\n",
      "[5156]\ttraining's binary_logloss: 0.466185\n",
      "[5157]\ttraining's binary_logloss: 0.466137\n",
      "[5158]\ttraining's binary_logloss: 0.466071\n",
      "[5159]\ttraining's binary_logloss: 0.46603\n",
      "[5160]\ttraining's binary_logloss: 0.46599\n",
      "[5161]\ttraining's binary_logloss: 0.465924\n",
      "[5162]\ttraining's binary_logloss: 0.465885\n",
      "[5163]\ttraining's binary_logloss: 0.465815\n",
      "[5164]\ttraining's binary_logloss: 0.465756\n",
      "[5165]\ttraining's binary_logloss: 0.465701\n",
      "[5166]\ttraining's binary_logloss: 0.465642\n",
      "[5167]\ttraining's binary_logloss: 0.465607\n",
      "[5168]\ttraining's binary_logloss: 0.465567\n",
      "[5169]\ttraining's binary_logloss: 0.465501\n",
      "[5170]\ttraining's binary_logloss: 0.465419\n",
      "[5171]\ttraining's binary_logloss: 0.46537\n",
      "[5172]\ttraining's binary_logloss: 0.465333\n",
      "[5173]\ttraining's binary_logloss: 0.465275\n",
      "[5174]\ttraining's binary_logloss: 0.465235\n",
      "[5175]\ttraining's binary_logloss: 0.465186\n",
      "[5176]\ttraining's binary_logloss: 0.465138\n",
      "[5177]\ttraining's binary_logloss: 0.465096\n",
      "[5178]\ttraining's binary_logloss: 0.465043\n",
      "[5179]\ttraining's binary_logloss: 0.464977\n",
      "[5180]\ttraining's binary_logloss: 0.464931\n",
      "[5181]\ttraining's binary_logloss: 0.464881\n",
      "[5182]\ttraining's binary_logloss: 0.464824\n",
      "[5183]\ttraining's binary_logloss: 0.464775\n",
      "[5184]\ttraining's binary_logloss: 0.464704\n",
      "[5185]\ttraining's binary_logloss: 0.464639\n",
      "[5186]\ttraining's binary_logloss: 0.464586\n",
      "[5187]\ttraining's binary_logloss: 0.464519\n",
      "[5188]\ttraining's binary_logloss: 0.464451\n",
      "[5189]\ttraining's binary_logloss: 0.464392\n",
      "[5190]\ttraining's binary_logloss: 0.464343\n",
      "[5191]\ttraining's binary_logloss: 0.464297\n",
      "[5192]\ttraining's binary_logloss: 0.464242\n",
      "[5193]\ttraining's binary_logloss: 0.464201\n",
      "[5194]\ttraining's binary_logloss: 0.464129\n",
      "[5195]\ttraining's binary_logloss: 0.464059\n",
      "[5196]\ttraining's binary_logloss: 0.464001\n",
      "[5197]\ttraining's binary_logloss: 0.463955\n",
      "[5198]\ttraining's binary_logloss: 0.463894\n",
      "[5199]\ttraining's binary_logloss: 0.463812\n",
      "[5200]\ttraining's binary_logloss: 0.463768\n",
      "[5201]\ttraining's binary_logloss: 0.463732\n",
      "[5202]\ttraining's binary_logloss: 0.463688\n",
      "[5203]\ttraining's binary_logloss: 0.463636\n",
      "[5204]\ttraining's binary_logloss: 0.463599\n",
      "[5205]\ttraining's binary_logloss: 0.463543\n",
      "[5206]\ttraining's binary_logloss: 0.463496\n",
      "[5207]\ttraining's binary_logloss: 0.46345\n",
      "[5208]\ttraining's binary_logloss: 0.463411\n",
      "[5209]\ttraining's binary_logloss: 0.463369\n",
      "[5210]\ttraining's binary_logloss: 0.463329\n",
      "[5211]\ttraining's binary_logloss: 0.463274\n",
      "[5212]\ttraining's binary_logloss: 0.463219\n",
      "[5213]\ttraining's binary_logloss: 0.463175\n",
      "[5214]\ttraining's binary_logloss: 0.463129\n",
      "[5215]\ttraining's binary_logloss: 0.463076\n",
      "[5216]\ttraining's binary_logloss: 0.463034\n",
      "[5217]\ttraining's binary_logloss: 0.462969\n",
      "[5218]\ttraining's binary_logloss: 0.462926\n",
      "[5219]\ttraining's binary_logloss: 0.462876\n",
      "[5220]\ttraining's binary_logloss: 0.462836\n",
      "[5221]\ttraining's binary_logloss: 0.462787\n",
      "[5222]\ttraining's binary_logloss: 0.462746\n",
      "[5223]\ttraining's binary_logloss: 0.462699\n",
      "[5224]\ttraining's binary_logloss: 0.462663\n",
      "[5225]\ttraining's binary_logloss: 0.462618\n",
      "[5226]\ttraining's binary_logloss: 0.462567\n",
      "[5227]\ttraining's binary_logloss: 0.4625\n",
      "[5228]\ttraining's binary_logloss: 0.462447\n",
      "[5229]\ttraining's binary_logloss: 0.4624\n",
      "[5230]\ttraining's binary_logloss: 0.462353\n",
      "[5231]\ttraining's binary_logloss: 0.462307\n",
      "[5232]\ttraining's binary_logloss: 0.462221\n",
      "[5233]\ttraining's binary_logloss: 0.462159\n",
      "[5234]\ttraining's binary_logloss: 0.462109\n",
      "[5235]\ttraining's binary_logloss: 0.462045\n",
      "[5236]\ttraining's binary_logloss: 0.461997\n",
      "[5237]\ttraining's binary_logloss: 0.461932\n",
      "[5238]\ttraining's binary_logloss: 0.461866\n",
      "[5239]\ttraining's binary_logloss: 0.461804\n",
      "[5240]\ttraining's binary_logloss: 0.461736\n",
      "[5241]\ttraining's binary_logloss: 0.461688\n",
      "[5242]\ttraining's binary_logloss: 0.461644\n",
      "[5243]\ttraining's binary_logloss: 0.461599\n",
      "[5244]\ttraining's binary_logloss: 0.461557\n",
      "[5245]\ttraining's binary_logloss: 0.461498\n",
      "[5246]\ttraining's binary_logloss: 0.461464\n",
      "[5247]\ttraining's binary_logloss: 0.461419\n",
      "[5248]\ttraining's binary_logloss: 0.461353\n",
      "[5249]\ttraining's binary_logloss: 0.461285\n",
      "[5250]\ttraining's binary_logloss: 0.461224\n",
      "[5251]\ttraining's binary_logloss: 0.461173\n",
      "[5252]\ttraining's binary_logloss: 0.461111\n",
      "[5253]\ttraining's binary_logloss: 0.461057\n",
      "[5254]\ttraining's binary_logloss: 0.461004\n",
      "[5255]\ttraining's binary_logloss: 0.46094\n",
      "[5256]\ttraining's binary_logloss: 0.460898\n",
      "[5257]\ttraining's binary_logloss: 0.460844\n",
      "[5258]\ttraining's binary_logloss: 0.460809\n",
      "[5259]\ttraining's binary_logloss: 0.460763\n",
      "[5260]\ttraining's binary_logloss: 0.460705\n",
      "[5261]\ttraining's binary_logloss: 0.460668\n",
      "[5262]\ttraining's binary_logloss: 0.460607\n",
      "[5263]\ttraining's binary_logloss: 0.46055\n",
      "[5264]\ttraining's binary_logloss: 0.460509\n",
      "[5265]\ttraining's binary_logloss: 0.460463\n",
      "[5266]\ttraining's binary_logloss: 0.460416\n",
      "[5267]\ttraining's binary_logloss: 0.460384\n",
      "[5268]\ttraining's binary_logloss: 0.460322\n",
      "[5269]\ttraining's binary_logloss: 0.460285\n",
      "[5270]\ttraining's binary_logloss: 0.46024\n",
      "[5271]\ttraining's binary_logloss: 0.460178\n",
      "[5272]\ttraining's binary_logloss: 0.460106\n",
      "[5273]\ttraining's binary_logloss: 0.460045\n",
      "[5274]\ttraining's binary_logloss: 0.459997\n",
      "[5275]\ttraining's binary_logloss: 0.459952\n",
      "[5276]\ttraining's binary_logloss: 0.459896\n",
      "[5277]\ttraining's binary_logloss: 0.459854\n",
      "[5278]\ttraining's binary_logloss: 0.459762\n",
      "[5279]\ttraining's binary_logloss: 0.459716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5280]\ttraining's binary_logloss: 0.45966\n",
      "[5281]\ttraining's binary_logloss: 0.459625\n",
      "[5282]\ttraining's binary_logloss: 0.459586\n",
      "[5283]\ttraining's binary_logloss: 0.459509\n",
      "[5284]\ttraining's binary_logloss: 0.459469\n",
      "[5285]\ttraining's binary_logloss: 0.459435\n",
      "[5286]\ttraining's binary_logloss: 0.459375\n",
      "[5287]\ttraining's binary_logloss: 0.459334\n",
      "[5288]\ttraining's binary_logloss: 0.459261\n",
      "[5289]\ttraining's binary_logloss: 0.459212\n",
      "[5290]\ttraining's binary_logloss: 0.459171\n",
      "[5291]\ttraining's binary_logloss: 0.459122\n",
      "[5292]\ttraining's binary_logloss: 0.459053\n",
      "[5293]\ttraining's binary_logloss: 0.458996\n",
      "[5294]\ttraining's binary_logloss: 0.458951\n",
      "[5295]\ttraining's binary_logloss: 0.458909\n",
      "[5296]\ttraining's binary_logloss: 0.458852\n",
      "[5297]\ttraining's binary_logloss: 0.458808\n",
      "[5298]\ttraining's binary_logloss: 0.458773\n",
      "[5299]\ttraining's binary_logloss: 0.458728\n",
      "[5300]\ttraining's binary_logloss: 0.458678\n",
      "[5301]\ttraining's binary_logloss: 0.458623\n",
      "[5302]\ttraining's binary_logloss: 0.458557\n",
      "[5303]\ttraining's binary_logloss: 0.458514\n",
      "[5304]\ttraining's binary_logloss: 0.458474\n",
      "[5305]\ttraining's binary_logloss: 0.458425\n",
      "[5306]\ttraining's binary_logloss: 0.458375\n",
      "[5307]\ttraining's binary_logloss: 0.458341\n",
      "[5308]\ttraining's binary_logloss: 0.458281\n",
      "[5309]\ttraining's binary_logloss: 0.4582\n",
      "[5310]\ttraining's binary_logloss: 0.458149\n",
      "[5311]\ttraining's binary_logloss: 0.458092\n",
      "[5312]\ttraining's binary_logloss: 0.458056\n",
      "[5313]\ttraining's binary_logloss: 0.458019\n",
      "[5314]\ttraining's binary_logloss: 0.457972\n",
      "[5315]\ttraining's binary_logloss: 0.457921\n",
      "[5316]\ttraining's binary_logloss: 0.457902\n",
      "[5317]\ttraining's binary_logloss: 0.457857\n",
      "[5318]\ttraining's binary_logloss: 0.457789\n",
      "[5319]\ttraining's binary_logloss: 0.457726\n",
      "[5320]\ttraining's binary_logloss: 0.457668\n",
      "[5321]\ttraining's binary_logloss: 0.457631\n",
      "[5322]\ttraining's binary_logloss: 0.457582\n",
      "[5323]\ttraining's binary_logloss: 0.457506\n",
      "[5324]\ttraining's binary_logloss: 0.457443\n",
      "[5325]\ttraining's binary_logloss: 0.457381\n",
      "[5326]\ttraining's binary_logloss: 0.457334\n",
      "[5327]\ttraining's binary_logloss: 0.457295\n",
      "[5328]\ttraining's binary_logloss: 0.457231\n",
      "[5329]\ttraining's binary_logloss: 0.457195\n",
      "[5330]\ttraining's binary_logloss: 0.45713\n",
      "[5331]\ttraining's binary_logloss: 0.457073\n",
      "[5332]\ttraining's binary_logloss: 0.457004\n",
      "[5333]\ttraining's binary_logloss: 0.456961\n",
      "[5334]\ttraining's binary_logloss: 0.456906\n",
      "[5335]\ttraining's binary_logloss: 0.456864\n",
      "[5336]\ttraining's binary_logloss: 0.456822\n",
      "[5337]\ttraining's binary_logloss: 0.456784\n",
      "[5338]\ttraining's binary_logloss: 0.456738\n",
      "[5339]\ttraining's binary_logloss: 0.456698\n",
      "[5340]\ttraining's binary_logloss: 0.456642\n",
      "[5341]\ttraining's binary_logloss: 0.456594\n",
      "[5342]\ttraining's binary_logloss: 0.45655\n",
      "[5343]\ttraining's binary_logloss: 0.456493\n",
      "[5344]\ttraining's binary_logloss: 0.45644\n",
      "[5345]\ttraining's binary_logloss: 0.456391\n",
      "[5346]\ttraining's binary_logloss: 0.456357\n",
      "[5347]\ttraining's binary_logloss: 0.45632\n",
      "[5348]\ttraining's binary_logloss: 0.456273\n",
      "[5349]\ttraining's binary_logloss: 0.456208\n",
      "[5350]\ttraining's binary_logloss: 0.456165\n",
      "[5351]\ttraining's binary_logloss: 0.456123\n",
      "[5352]\ttraining's binary_logloss: 0.456087\n",
      "[5353]\ttraining's binary_logloss: 0.456026\n",
      "[5354]\ttraining's binary_logloss: 0.455973\n",
      "[5355]\ttraining's binary_logloss: 0.455937\n",
      "[5356]\ttraining's binary_logloss: 0.455891\n",
      "[5357]\ttraining's binary_logloss: 0.455853\n",
      "[5358]\ttraining's binary_logloss: 0.455778\n",
      "[5359]\ttraining's binary_logloss: 0.455707\n",
      "[5360]\ttraining's binary_logloss: 0.455661\n",
      "[5361]\ttraining's binary_logloss: 0.455605\n",
      "[5362]\ttraining's binary_logloss: 0.455563\n",
      "[5363]\ttraining's binary_logloss: 0.455523\n",
      "[5364]\ttraining's binary_logloss: 0.455475\n",
      "[5365]\ttraining's binary_logloss: 0.455416\n",
      "[5366]\ttraining's binary_logloss: 0.455354\n",
      "[5367]\ttraining's binary_logloss: 0.455288\n",
      "[5368]\ttraining's binary_logloss: 0.455232\n",
      "[5369]\ttraining's binary_logloss: 0.455179\n",
      "[5370]\ttraining's binary_logloss: 0.455117\n",
      "[5371]\ttraining's binary_logloss: 0.45508\n",
      "[5372]\ttraining's binary_logloss: 0.455034\n",
      "[5373]\ttraining's binary_logloss: 0.454984\n",
      "[5374]\ttraining's binary_logloss: 0.454945\n",
      "[5375]\ttraining's binary_logloss: 0.454896\n",
      "[5376]\ttraining's binary_logloss: 0.454823\n",
      "[5377]\ttraining's binary_logloss: 0.454787\n",
      "[5378]\ttraining's binary_logloss: 0.454759\n",
      "[5379]\ttraining's binary_logloss: 0.454706\n",
      "[5380]\ttraining's binary_logloss: 0.454653\n",
      "[5381]\ttraining's binary_logloss: 0.454602\n",
      "[5382]\ttraining's binary_logloss: 0.454564\n",
      "[5383]\ttraining's binary_logloss: 0.454518\n",
      "[5384]\ttraining's binary_logloss: 0.454452\n",
      "[5385]\ttraining's binary_logloss: 0.454403\n",
      "[5386]\ttraining's binary_logloss: 0.454346\n",
      "[5387]\ttraining's binary_logloss: 0.454304\n",
      "[5388]\ttraining's binary_logloss: 0.454251\n",
      "[5389]\ttraining's binary_logloss: 0.454209\n",
      "[5390]\ttraining's binary_logloss: 0.454144\n",
      "[5391]\ttraining's binary_logloss: 0.454094\n",
      "[5392]\ttraining's binary_logloss: 0.454043\n",
      "[5393]\ttraining's binary_logloss: 0.45399\n",
      "[5394]\ttraining's binary_logloss: 0.453945\n",
      "[5395]\ttraining's binary_logloss: 0.453881\n",
      "[5396]\ttraining's binary_logloss: 0.453847\n",
      "[5397]\ttraining's binary_logloss: 0.4538\n",
      "[5398]\ttraining's binary_logloss: 0.453731\n",
      "[5399]\ttraining's binary_logloss: 0.453657\n",
      "[5400]\ttraining's binary_logloss: 0.453611\n",
      "[5401]\ttraining's binary_logloss: 0.453563\n",
      "[5402]\ttraining's binary_logloss: 0.453523\n",
      "[5403]\ttraining's binary_logloss: 0.453476\n",
      "[5404]\ttraining's binary_logloss: 0.453437\n",
      "[5405]\ttraining's binary_logloss: 0.453397\n",
      "[5406]\ttraining's binary_logloss: 0.453353\n",
      "[5407]\ttraining's binary_logloss: 0.453324\n",
      "[5408]\ttraining's binary_logloss: 0.453279\n",
      "[5409]\ttraining's binary_logloss: 0.453235\n",
      "[5410]\ttraining's binary_logloss: 0.453198\n",
      "[5411]\ttraining's binary_logloss: 0.453118\n",
      "[5412]\ttraining's binary_logloss: 0.453063\n",
      "[5413]\ttraining's binary_logloss: 0.453024\n",
      "[5414]\ttraining's binary_logloss: 0.452981\n",
      "[5415]\ttraining's binary_logloss: 0.452941\n",
      "[5416]\ttraining's binary_logloss: 0.45289\n",
      "[5417]\ttraining's binary_logloss: 0.452799\n",
      "[5418]\ttraining's binary_logloss: 0.452747\n",
      "[5419]\ttraining's binary_logloss: 0.452705\n",
      "[5420]\ttraining's binary_logloss: 0.452622\n",
      "[5421]\ttraining's binary_logloss: 0.452563\n",
      "[5422]\ttraining's binary_logloss: 0.452508\n",
      "[5423]\ttraining's binary_logloss: 0.452459\n",
      "[5424]\ttraining's binary_logloss: 0.452412\n",
      "[5425]\ttraining's binary_logloss: 0.452359\n",
      "[5426]\ttraining's binary_logloss: 0.452329\n",
      "[5427]\ttraining's binary_logloss: 0.452288\n",
      "[5428]\ttraining's binary_logloss: 0.452244\n",
      "[5429]\ttraining's binary_logloss: 0.45218\n",
      "[5430]\ttraining's binary_logloss: 0.45214\n",
      "[5431]\ttraining's binary_logloss: 0.452111\n",
      "[5432]\ttraining's binary_logloss: 0.452074\n",
      "[5433]\ttraining's binary_logloss: 0.452027\n",
      "[5434]\ttraining's binary_logloss: 0.451978\n",
      "[5435]\ttraining's binary_logloss: 0.451915\n",
      "[5436]\ttraining's binary_logloss: 0.451862\n",
      "[5437]\ttraining's binary_logloss: 0.451817\n",
      "[5438]\ttraining's binary_logloss: 0.451767\n",
      "[5439]\ttraining's binary_logloss: 0.451724\n",
      "[5440]\ttraining's binary_logloss: 0.451673\n",
      "[5441]\ttraining's binary_logloss: 0.451629\n",
      "[5442]\ttraining's binary_logloss: 0.451575\n",
      "[5443]\ttraining's binary_logloss: 0.451525\n",
      "[5444]\ttraining's binary_logloss: 0.45148\n",
      "[5445]\ttraining's binary_logloss: 0.451431\n",
      "[5446]\ttraining's binary_logloss: 0.451365\n",
      "[5447]\ttraining's binary_logloss: 0.451307\n",
      "[5448]\ttraining's binary_logloss: 0.451266\n",
      "[5449]\ttraining's binary_logloss: 0.451217\n",
      "[5450]\ttraining's binary_logloss: 0.451185\n",
      "[5451]\ttraining's binary_logloss: 0.451146\n",
      "[5452]\ttraining's binary_logloss: 0.451098\n",
      "[5453]\ttraining's binary_logloss: 0.451053\n",
      "[5454]\ttraining's binary_logloss: 0.451015\n",
      "[5455]\ttraining's binary_logloss: 0.450959\n",
      "[5456]\ttraining's binary_logloss: 0.450914\n",
      "[5457]\ttraining's binary_logloss: 0.450869\n",
      "[5458]\ttraining's binary_logloss: 0.450837\n",
      "[5459]\ttraining's binary_logloss: 0.450793\n",
      "[5460]\ttraining's binary_logloss: 0.450734\n",
      "[5461]\ttraining's binary_logloss: 0.450686\n",
      "[5462]\ttraining's binary_logloss: 0.450633\n",
      "[5463]\ttraining's binary_logloss: 0.450574\n",
      "[5464]\ttraining's binary_logloss: 0.450537\n",
      "[5465]\ttraining's binary_logloss: 0.450485\n",
      "[5466]\ttraining's binary_logloss: 0.450427\n",
      "[5467]\ttraining's binary_logloss: 0.450385\n",
      "[5468]\ttraining's binary_logloss: 0.450319\n",
      "[5469]\ttraining's binary_logloss: 0.450265\n",
      "[5470]\ttraining's binary_logloss: 0.45023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5471]\ttraining's binary_logloss: 0.450193\n",
      "[5472]\ttraining's binary_logloss: 0.450132\n",
      "[5473]\ttraining's binary_logloss: 0.450082\n",
      "[5474]\ttraining's binary_logloss: 0.450034\n",
      "[5475]\ttraining's binary_logloss: 0.450001\n",
      "[5476]\ttraining's binary_logloss: 0.449957\n",
      "[5477]\ttraining's binary_logloss: 0.449919\n",
      "[5478]\ttraining's binary_logloss: 0.449871\n",
      "[5479]\ttraining's binary_logloss: 0.449823\n",
      "[5480]\ttraining's binary_logloss: 0.449778\n",
      "[5481]\ttraining's binary_logloss: 0.449734\n",
      "[5482]\ttraining's binary_logloss: 0.449681\n",
      "[5483]\ttraining's binary_logloss: 0.449615\n",
      "[5484]\ttraining's binary_logloss: 0.449573\n",
      "[5485]\ttraining's binary_logloss: 0.449532\n",
      "[5486]\ttraining's binary_logloss: 0.449472\n",
      "[5487]\ttraining's binary_logloss: 0.449407\n",
      "[5488]\ttraining's binary_logloss: 0.449361\n",
      "[5489]\ttraining's binary_logloss: 0.449319\n",
      "[5490]\ttraining's binary_logloss: 0.449279\n",
      "[5491]\ttraining's binary_logloss: 0.449227\n",
      "[5492]\ttraining's binary_logloss: 0.449174\n",
      "[5493]\ttraining's binary_logloss: 0.449135\n",
      "[5494]\ttraining's binary_logloss: 0.449092\n",
      "[5495]\ttraining's binary_logloss: 0.449029\n",
      "[5496]\ttraining's binary_logloss: 0.448985\n",
      "[5497]\ttraining's binary_logloss: 0.448945\n",
      "[5498]\ttraining's binary_logloss: 0.448886\n",
      "[5499]\ttraining's binary_logloss: 0.448831\n",
      "[5500]\ttraining's binary_logloss: 0.448766\n",
      "[5501]\ttraining's binary_logloss: 0.448726\n",
      "[5502]\ttraining's binary_logloss: 0.448665\n",
      "[5503]\ttraining's binary_logloss: 0.448624\n",
      "[5504]\ttraining's binary_logloss: 0.448572\n",
      "[5505]\ttraining's binary_logloss: 0.448524\n",
      "[5506]\ttraining's binary_logloss: 0.448481\n",
      "[5507]\ttraining's binary_logloss: 0.448422\n",
      "[5508]\ttraining's binary_logloss: 0.448385\n",
      "[5509]\ttraining's binary_logloss: 0.448313\n",
      "[5510]\ttraining's binary_logloss: 0.448265\n",
      "[5511]\ttraining's binary_logloss: 0.448223\n",
      "[5512]\ttraining's binary_logloss: 0.448166\n",
      "[5513]\ttraining's binary_logloss: 0.448131\n",
      "[5514]\ttraining's binary_logloss: 0.448052\n",
      "[5515]\ttraining's binary_logloss: 0.448011\n",
      "[5516]\ttraining's binary_logloss: 0.447972\n",
      "[5517]\ttraining's binary_logloss: 0.447929\n",
      "[5518]\ttraining's binary_logloss: 0.447871\n",
      "[5519]\ttraining's binary_logloss: 0.447808\n",
      "[5520]\ttraining's binary_logloss: 0.447739\n",
      "[5521]\ttraining's binary_logloss: 0.447682\n",
      "[5522]\ttraining's binary_logloss: 0.447633\n",
      "[5523]\ttraining's binary_logloss: 0.447549\n",
      "[5524]\ttraining's binary_logloss: 0.447504\n",
      "[5525]\ttraining's binary_logloss: 0.447451\n",
      "[5526]\ttraining's binary_logloss: 0.44741\n",
      "[5527]\ttraining's binary_logloss: 0.447349\n",
      "[5528]\ttraining's binary_logloss: 0.4473\n",
      "[5529]\ttraining's binary_logloss: 0.447255\n",
      "[5530]\ttraining's binary_logloss: 0.447208\n",
      "[5531]\ttraining's binary_logloss: 0.447165\n",
      "[5532]\ttraining's binary_logloss: 0.447103\n",
      "[5533]\ttraining's binary_logloss: 0.447062\n",
      "[5534]\ttraining's binary_logloss: 0.447032\n",
      "[5535]\ttraining's binary_logloss: 0.446992\n",
      "[5536]\ttraining's binary_logloss: 0.446942\n",
      "[5537]\ttraining's binary_logloss: 0.446905\n",
      "[5538]\ttraining's binary_logloss: 0.446867\n",
      "[5539]\ttraining's binary_logloss: 0.446826\n",
      "[5540]\ttraining's binary_logloss: 0.446765\n",
      "[5541]\ttraining's binary_logloss: 0.446717\n",
      "[5542]\ttraining's binary_logloss: 0.446678\n",
      "[5543]\ttraining's binary_logloss: 0.446627\n",
      "[5544]\ttraining's binary_logloss: 0.446579\n",
      "[5545]\ttraining's binary_logloss: 0.446542\n",
      "[5546]\ttraining's binary_logloss: 0.4465\n",
      "[5547]\ttraining's binary_logloss: 0.446459\n",
      "[5548]\ttraining's binary_logloss: 0.446399\n",
      "[5549]\ttraining's binary_logloss: 0.446358\n",
      "[5550]\ttraining's binary_logloss: 0.44632\n",
      "[5551]\ttraining's binary_logloss: 0.446287\n",
      "[5552]\ttraining's binary_logloss: 0.446233\n",
      "[5553]\ttraining's binary_logloss: 0.446175\n",
      "[5554]\ttraining's binary_logloss: 0.446134\n",
      "[5555]\ttraining's binary_logloss: 0.446097\n",
      "[5556]\ttraining's binary_logloss: 0.446054\n",
      "[5557]\ttraining's binary_logloss: 0.446002\n",
      "[5558]\ttraining's binary_logloss: 0.445938\n",
      "[5559]\ttraining's binary_logloss: 0.445884\n",
      "[5560]\ttraining's binary_logloss: 0.445834\n",
      "[5561]\ttraining's binary_logloss: 0.445793\n",
      "[5562]\ttraining's binary_logloss: 0.44575\n",
      "[5563]\ttraining's binary_logloss: 0.4457\n",
      "[5564]\ttraining's binary_logloss: 0.445647\n",
      "[5565]\ttraining's binary_logloss: 0.445605\n",
      "[5566]\ttraining's binary_logloss: 0.445553\n",
      "[5567]\ttraining's binary_logloss: 0.44552\n",
      "[5568]\ttraining's binary_logloss: 0.445459\n",
      "[5569]\ttraining's binary_logloss: 0.445422\n",
      "[5570]\ttraining's binary_logloss: 0.445366\n",
      "[5571]\ttraining's binary_logloss: 0.445321\n",
      "[5572]\ttraining's binary_logloss: 0.445276\n",
      "[5573]\ttraining's binary_logloss: 0.445188\n",
      "[5574]\ttraining's binary_logloss: 0.445129\n",
      "[5575]\ttraining's binary_logloss: 0.445069\n",
      "[5576]\ttraining's binary_logloss: 0.445024\n",
      "[5577]\ttraining's binary_logloss: 0.444989\n",
      "[5578]\ttraining's binary_logloss: 0.444927\n",
      "[5579]\ttraining's binary_logloss: 0.444885\n",
      "[5580]\ttraining's binary_logloss: 0.444838\n",
      "[5581]\ttraining's binary_logloss: 0.444785\n",
      "[5582]\ttraining's binary_logloss: 0.444742\n",
      "[5583]\ttraining's binary_logloss: 0.444705\n",
      "[5584]\ttraining's binary_logloss: 0.44466\n",
      "[5585]\ttraining's binary_logloss: 0.444617\n",
      "[5586]\ttraining's binary_logloss: 0.444561\n",
      "[5587]\ttraining's binary_logloss: 0.444523\n",
      "[5588]\ttraining's binary_logloss: 0.444469\n",
      "[5589]\ttraining's binary_logloss: 0.444406\n",
      "[5590]\ttraining's binary_logloss: 0.444376\n",
      "[5591]\ttraining's binary_logloss: 0.444323\n",
      "[5592]\ttraining's binary_logloss: 0.444273\n",
      "[5593]\ttraining's binary_logloss: 0.444223\n",
      "[5594]\ttraining's binary_logloss: 0.444158\n",
      "[5595]\ttraining's binary_logloss: 0.444108\n",
      "[5596]\ttraining's binary_logloss: 0.444065\n",
      "[5597]\ttraining's binary_logloss: 0.444024\n",
      "[5598]\ttraining's binary_logloss: 0.443982\n",
      "[5599]\ttraining's binary_logloss: 0.443931\n",
      "[5600]\ttraining's binary_logloss: 0.443898\n",
      "[5601]\ttraining's binary_logloss: 0.443822\n",
      "[5602]\ttraining's binary_logloss: 0.44378\n",
      "[5603]\ttraining's binary_logloss: 0.443723\n",
      "[5604]\ttraining's binary_logloss: 0.443667\n",
      "[5605]\ttraining's binary_logloss: 0.443624\n",
      "[5606]\ttraining's binary_logloss: 0.443577\n",
      "[5607]\ttraining's binary_logloss: 0.44353\n",
      "[5608]\ttraining's binary_logloss: 0.443468\n",
      "[5609]\ttraining's binary_logloss: 0.443432\n",
      "[5610]\ttraining's binary_logloss: 0.443391\n",
      "[5611]\ttraining's binary_logloss: 0.443358\n",
      "[5612]\ttraining's binary_logloss: 0.443319\n",
      "[5613]\ttraining's binary_logloss: 0.44326\n",
      "[5614]\ttraining's binary_logloss: 0.443219\n",
      "[5615]\ttraining's binary_logloss: 0.443175\n",
      "[5616]\ttraining's binary_logloss: 0.443128\n",
      "[5617]\ttraining's binary_logloss: 0.443077\n",
      "[5618]\ttraining's binary_logloss: 0.443039\n",
      "[5619]\ttraining's binary_logloss: 0.44297\n",
      "[5620]\ttraining's binary_logloss: 0.442906\n",
      "[5621]\ttraining's binary_logloss: 0.442828\n",
      "[5622]\ttraining's binary_logloss: 0.442766\n",
      "[5623]\ttraining's binary_logloss: 0.44272\n",
      "[5624]\ttraining's binary_logloss: 0.44266\n",
      "[5625]\ttraining's binary_logloss: 0.442601\n",
      "[5626]\ttraining's binary_logloss: 0.442552\n",
      "[5627]\ttraining's binary_logloss: 0.442498\n",
      "[5628]\ttraining's binary_logloss: 0.442451\n",
      "[5629]\ttraining's binary_logloss: 0.44242\n",
      "[5630]\ttraining's binary_logloss: 0.442367\n",
      "[5631]\ttraining's binary_logloss: 0.442306\n",
      "[5632]\ttraining's binary_logloss: 0.442256\n",
      "[5633]\ttraining's binary_logloss: 0.442188\n",
      "[5634]\ttraining's binary_logloss: 0.44213\n",
      "[5635]\ttraining's binary_logloss: 0.442089\n",
      "[5636]\ttraining's binary_logloss: 0.442039\n",
      "[5637]\ttraining's binary_logloss: 0.442002\n",
      "[5638]\ttraining's binary_logloss: 0.441968\n",
      "[5639]\ttraining's binary_logloss: 0.441922\n",
      "[5640]\ttraining's binary_logloss: 0.441882\n",
      "[5641]\ttraining's binary_logloss: 0.441841\n",
      "[5642]\ttraining's binary_logloss: 0.441769\n",
      "[5643]\ttraining's binary_logloss: 0.441711\n",
      "[5644]\ttraining's binary_logloss: 0.441648\n",
      "[5645]\ttraining's binary_logloss: 0.44161\n",
      "[5646]\ttraining's binary_logloss: 0.441553\n",
      "[5647]\ttraining's binary_logloss: 0.441472\n",
      "[5648]\ttraining's binary_logloss: 0.441434\n",
      "[5649]\ttraining's binary_logloss: 0.441392\n",
      "[5650]\ttraining's binary_logloss: 0.441339\n",
      "[5651]\ttraining's binary_logloss: 0.44129\n",
      "[5652]\ttraining's binary_logloss: 0.441253\n",
      "[5653]\ttraining's binary_logloss: 0.441208\n",
      "[5654]\ttraining's binary_logloss: 0.441165\n",
      "[5655]\ttraining's binary_logloss: 0.441117\n",
      "[5656]\ttraining's binary_logloss: 0.441077\n",
      "[5657]\ttraining's binary_logloss: 0.441024\n",
      "[5658]\ttraining's binary_logloss: 0.440985\n",
      "[5659]\ttraining's binary_logloss: 0.440936\n",
      "[5660]\ttraining's binary_logloss: 0.440894\n",
      "[5661]\ttraining's binary_logloss: 0.440849\n",
      "[5662]\ttraining's binary_logloss: 0.440815\n",
      "[5663]\ttraining's binary_logloss: 0.440775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5664]\ttraining's binary_logloss: 0.440712\n",
      "[5665]\ttraining's binary_logloss: 0.440651\n",
      "[5666]\ttraining's binary_logloss: 0.440622\n",
      "[5667]\ttraining's binary_logloss: 0.440564\n",
      "[5668]\ttraining's binary_logloss: 0.440518\n",
      "[5669]\ttraining's binary_logloss: 0.44048\n",
      "[5670]\ttraining's binary_logloss: 0.440415\n",
      "[5671]\ttraining's binary_logloss: 0.440368\n",
      "[5672]\ttraining's binary_logloss: 0.440331\n",
      "[5673]\ttraining's binary_logloss: 0.440293\n",
      "[5674]\ttraining's binary_logloss: 0.44025\n",
      "[5675]\ttraining's binary_logloss: 0.440202\n",
      "[5676]\ttraining's binary_logloss: 0.440147\n",
      "[5677]\ttraining's binary_logloss: 0.440085\n",
      "[5678]\ttraining's binary_logloss: 0.440033\n",
      "[5679]\ttraining's binary_logloss: 0.439992\n",
      "[5680]\ttraining's binary_logloss: 0.439942\n",
      "[5681]\ttraining's binary_logloss: 0.439891\n",
      "[5682]\ttraining's binary_logloss: 0.439851\n",
      "[5683]\ttraining's binary_logloss: 0.439788\n",
      "[5684]\ttraining's binary_logloss: 0.439743\n",
      "[5685]\ttraining's binary_logloss: 0.439698\n",
      "[5686]\ttraining's binary_logloss: 0.439657\n",
      "[5687]\ttraining's binary_logloss: 0.439619\n",
      "[5688]\ttraining's binary_logloss: 0.439573\n",
      "[5689]\ttraining's binary_logloss: 0.439499\n",
      "[5690]\ttraining's binary_logloss: 0.439438\n",
      "[5691]\ttraining's binary_logloss: 0.439406\n",
      "[5692]\ttraining's binary_logloss: 0.439361\n",
      "[5693]\ttraining's binary_logloss: 0.439323\n",
      "[5694]\ttraining's binary_logloss: 0.439247\n",
      "[5695]\ttraining's binary_logloss: 0.439198\n",
      "[5696]\ttraining's binary_logloss: 0.439134\n",
      "[5697]\ttraining's binary_logloss: 0.439092\n",
      "[5698]\ttraining's binary_logloss: 0.439043\n",
      "[5699]\ttraining's binary_logloss: 0.438994\n",
      "[5700]\ttraining's binary_logloss: 0.438949\n",
      "[5701]\ttraining's binary_logloss: 0.438867\n",
      "[5702]\ttraining's binary_logloss: 0.438809\n",
      "[5703]\ttraining's binary_logloss: 0.438748\n",
      "[5704]\ttraining's binary_logloss: 0.438707\n",
      "[5705]\ttraining's binary_logloss: 0.438657\n",
      "[5706]\ttraining's binary_logloss: 0.438611\n",
      "[5707]\ttraining's binary_logloss: 0.438575\n",
      "[5708]\ttraining's binary_logloss: 0.438549\n",
      "[5709]\ttraining's binary_logloss: 0.438509\n",
      "[5710]\ttraining's binary_logloss: 0.438463\n",
      "[5711]\ttraining's binary_logloss: 0.438418\n",
      "[5712]\ttraining's binary_logloss: 0.43837\n",
      "[5713]\ttraining's binary_logloss: 0.438334\n",
      "[5714]\ttraining's binary_logloss: 0.438294\n",
      "[5715]\ttraining's binary_logloss: 0.438253\n",
      "[5716]\ttraining's binary_logloss: 0.438196\n",
      "[5717]\ttraining's binary_logloss: 0.438116\n",
      "[5718]\ttraining's binary_logloss: 0.438061\n",
      "[5719]\ttraining's binary_logloss: 0.43801\n",
      "[5720]\ttraining's binary_logloss: 0.437964\n",
      "[5721]\ttraining's binary_logloss: 0.437906\n",
      "[5722]\ttraining's binary_logloss: 0.437866\n",
      "[5723]\ttraining's binary_logloss: 0.43783\n",
      "[5724]\ttraining's binary_logloss: 0.437787\n",
      "[5725]\ttraining's binary_logloss: 0.43773\n",
      "[5726]\ttraining's binary_logloss: 0.43769\n",
      "[5727]\ttraining's binary_logloss: 0.437656\n",
      "[5728]\ttraining's binary_logloss: 0.437578\n",
      "[5729]\ttraining's binary_logloss: 0.437531\n",
      "[5730]\ttraining's binary_logloss: 0.437484\n",
      "[5731]\ttraining's binary_logloss: 0.437446\n",
      "[5732]\ttraining's binary_logloss: 0.43738\n",
      "[5733]\ttraining's binary_logloss: 0.437318\n",
      "[5734]\ttraining's binary_logloss: 0.437275\n",
      "[5735]\ttraining's binary_logloss: 0.43723\n",
      "[5736]\ttraining's binary_logloss: 0.437186\n",
      "[5737]\ttraining's binary_logloss: 0.437136\n",
      "[5738]\ttraining's binary_logloss: 0.437092\n",
      "[5739]\ttraining's binary_logloss: 0.437056\n",
      "[5740]\ttraining's binary_logloss: 0.436999\n",
      "[5741]\ttraining's binary_logloss: 0.436959\n",
      "[5742]\ttraining's binary_logloss: 0.436922\n",
      "[5743]\ttraining's binary_logloss: 0.436871\n",
      "[5744]\ttraining's binary_logloss: 0.436814\n",
      "[5745]\ttraining's binary_logloss: 0.436758\n",
      "[5746]\ttraining's binary_logloss: 0.436717\n",
      "[5747]\ttraining's binary_logloss: 0.436646\n",
      "[5748]\ttraining's binary_logloss: 0.436605\n",
      "[5749]\ttraining's binary_logloss: 0.436554\n",
      "[5750]\ttraining's binary_logloss: 0.436503\n",
      "[5751]\ttraining's binary_logloss: 0.43647\n",
      "[5752]\ttraining's binary_logloss: 0.43643\n",
      "[5753]\ttraining's binary_logloss: 0.436382\n",
      "[5754]\ttraining's binary_logloss: 0.436331\n",
      "[5755]\ttraining's binary_logloss: 0.436291\n",
      "[5756]\ttraining's binary_logloss: 0.436231\n",
      "[5757]\ttraining's binary_logloss: 0.436174\n",
      "[5758]\ttraining's binary_logloss: 0.436126\n",
      "[5759]\ttraining's binary_logloss: 0.43607\n",
      "[5760]\ttraining's binary_logloss: 0.436017\n",
      "[5761]\ttraining's binary_logloss: 0.435985\n",
      "[5762]\ttraining's binary_logloss: 0.43593\n",
      "[5763]\ttraining's binary_logloss: 0.435879\n",
      "[5764]\ttraining's binary_logloss: 0.435841\n",
      "[5765]\ttraining's binary_logloss: 0.435806\n",
      "[5766]\ttraining's binary_logloss: 0.435761\n",
      "[5767]\ttraining's binary_logloss: 0.435719\n",
      "[5768]\ttraining's binary_logloss: 0.43566\n",
      "[5769]\ttraining's binary_logloss: 0.435597\n",
      "[5770]\ttraining's binary_logloss: 0.435553\n",
      "[5771]\ttraining's binary_logloss: 0.435514\n",
      "[5772]\ttraining's binary_logloss: 0.435478\n",
      "[5773]\ttraining's binary_logloss: 0.43542\n",
      "[5774]\ttraining's binary_logloss: 0.43536\n",
      "[5775]\ttraining's binary_logloss: 0.435322\n",
      "[5776]\ttraining's binary_logloss: 0.435265\n",
      "[5777]\ttraining's binary_logloss: 0.435237\n",
      "[5778]\ttraining's binary_logloss: 0.435173\n",
      "[5779]\ttraining's binary_logloss: 0.435114\n",
      "[5780]\ttraining's binary_logloss: 0.435065\n",
      "[5781]\ttraining's binary_logloss: 0.435009\n",
      "[5782]\ttraining's binary_logloss: 0.434961\n",
      "[5783]\ttraining's binary_logloss: 0.434922\n",
      "[5784]\ttraining's binary_logloss: 0.434865\n",
      "[5785]\ttraining's binary_logloss: 0.434785\n",
      "[5786]\ttraining's binary_logloss: 0.43473\n",
      "[5787]\ttraining's binary_logloss: 0.434686\n",
      "[5788]\ttraining's binary_logloss: 0.434646\n",
      "[5789]\ttraining's binary_logloss: 0.4346\n",
      "[5790]\ttraining's binary_logloss: 0.434567\n",
      "[5791]\ttraining's binary_logloss: 0.434521\n",
      "[5792]\ttraining's binary_logloss: 0.43445\n",
      "[5793]\ttraining's binary_logloss: 0.434401\n",
      "[5794]\ttraining's binary_logloss: 0.434353\n",
      "[5795]\ttraining's binary_logloss: 0.434307\n",
      "[5796]\ttraining's binary_logloss: 0.434259\n",
      "[5797]\ttraining's binary_logloss: 0.434222\n",
      "[5798]\ttraining's binary_logloss: 0.434178\n",
      "[5799]\ttraining's binary_logloss: 0.434145\n",
      "[5800]\ttraining's binary_logloss: 0.434108\n",
      "[5801]\ttraining's binary_logloss: 0.434049\n",
      "[5802]\ttraining's binary_logloss: 0.433991\n",
      "[5803]\ttraining's binary_logloss: 0.433947\n",
      "[5804]\ttraining's binary_logloss: 0.433905\n",
      "[5805]\ttraining's binary_logloss: 0.433846\n",
      "[5806]\ttraining's binary_logloss: 0.433808\n",
      "[5807]\ttraining's binary_logloss: 0.433773\n",
      "[5808]\ttraining's binary_logloss: 0.433741\n",
      "[5809]\ttraining's binary_logloss: 0.433688\n",
      "[5810]\ttraining's binary_logloss: 0.433653\n",
      "[5811]\ttraining's binary_logloss: 0.43361\n",
      "[5812]\ttraining's binary_logloss: 0.433568\n",
      "[5813]\ttraining's binary_logloss: 0.433518\n",
      "[5814]\ttraining's binary_logloss: 0.433457\n",
      "[5815]\ttraining's binary_logloss: 0.433421\n",
      "[5816]\ttraining's binary_logloss: 0.43339\n",
      "[5817]\ttraining's binary_logloss: 0.433343\n",
      "[5818]\ttraining's binary_logloss: 0.433289\n",
      "[5819]\ttraining's binary_logloss: 0.433247\n",
      "[5820]\ttraining's binary_logloss: 0.433207\n",
      "[5821]\ttraining's binary_logloss: 0.433152\n",
      "[5822]\ttraining's binary_logloss: 0.433112\n",
      "[5823]\ttraining's binary_logloss: 0.433062\n",
      "[5824]\ttraining's binary_logloss: 0.433027\n",
      "[5825]\ttraining's binary_logloss: 0.432971\n",
      "[5826]\ttraining's binary_logloss: 0.432923\n",
      "[5827]\ttraining's binary_logloss: 0.432872\n",
      "[5828]\ttraining's binary_logloss: 0.432814\n",
      "[5829]\ttraining's binary_logloss: 0.432769\n",
      "[5830]\ttraining's binary_logloss: 0.432717\n",
      "[5831]\ttraining's binary_logloss: 0.43266\n",
      "[5832]\ttraining's binary_logloss: 0.432608\n",
      "[5833]\ttraining's binary_logloss: 0.432561\n",
      "[5834]\ttraining's binary_logloss: 0.432511\n",
      "[5835]\ttraining's binary_logloss: 0.432452\n",
      "[5836]\ttraining's binary_logloss: 0.432422\n",
      "[5837]\ttraining's binary_logloss: 0.432381\n",
      "[5838]\ttraining's binary_logloss: 0.432329\n",
      "[5839]\ttraining's binary_logloss: 0.432279\n",
      "[5840]\ttraining's binary_logloss: 0.432218\n",
      "[5841]\ttraining's binary_logloss: 0.432184\n",
      "[5842]\ttraining's binary_logloss: 0.432148\n",
      "[5843]\ttraining's binary_logloss: 0.432101\n",
      "[5844]\ttraining's binary_logloss: 0.432059\n",
      "[5845]\ttraining's binary_logloss: 0.432022\n",
      "[5846]\ttraining's binary_logloss: 0.431972\n",
      "[5847]\ttraining's binary_logloss: 0.431924\n",
      "[5848]\ttraining's binary_logloss: 0.43189\n",
      "[5849]\ttraining's binary_logloss: 0.431849\n",
      "[5850]\ttraining's binary_logloss: 0.431805\n",
      "[5851]\ttraining's binary_logloss: 0.431738\n",
      "[5852]\ttraining's binary_logloss: 0.431676\n",
      "[5853]\ttraining's binary_logloss: 0.431617\n",
      "[5854]\ttraining's binary_logloss: 0.431577\n",
      "[5855]\ttraining's binary_logloss: 0.431542\n",
      "[5856]\ttraining's binary_logloss: 0.431507\n",
      "[5857]\ttraining's binary_logloss: 0.431462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5858]\ttraining's binary_logloss: 0.431395\n",
      "[5859]\ttraining's binary_logloss: 0.431348\n",
      "[5860]\ttraining's binary_logloss: 0.431303\n",
      "[5861]\ttraining's binary_logloss: 0.431268\n",
      "[5862]\ttraining's binary_logloss: 0.431205\n",
      "[5863]\ttraining's binary_logloss: 0.431176\n",
      "[5864]\ttraining's binary_logloss: 0.431132\n",
      "[5865]\ttraining's binary_logloss: 0.43108\n",
      "[5866]\ttraining's binary_logloss: 0.43104\n",
      "[5867]\ttraining's binary_logloss: 0.430978\n",
      "[5868]\ttraining's binary_logloss: 0.430931\n",
      "[5869]\ttraining's binary_logloss: 0.430869\n",
      "[5870]\ttraining's binary_logloss: 0.430822\n",
      "[5871]\ttraining's binary_logloss: 0.430789\n",
      "[5872]\ttraining's binary_logloss: 0.43074\n",
      "[5873]\ttraining's binary_logloss: 0.430707\n",
      "[5874]\ttraining's binary_logloss: 0.430671\n",
      "[5875]\ttraining's binary_logloss: 0.430616\n",
      "[5876]\ttraining's binary_logloss: 0.43056\n",
      "[5877]\ttraining's binary_logloss: 0.430511\n",
      "[5878]\ttraining's binary_logloss: 0.430423\n",
      "[5879]\ttraining's binary_logloss: 0.430385\n",
      "[5880]\ttraining's binary_logloss: 0.430345\n",
      "[5881]\ttraining's binary_logloss: 0.430295\n",
      "[5882]\ttraining's binary_logloss: 0.430242\n",
      "[5883]\ttraining's binary_logloss: 0.430174\n",
      "[5884]\ttraining's binary_logloss: 0.43012\n",
      "[5885]\ttraining's binary_logloss: 0.430067\n",
      "[5886]\ttraining's binary_logloss: 0.430025\n",
      "[5887]\ttraining's binary_logloss: 0.429985\n",
      "[5888]\ttraining's binary_logloss: 0.429937\n",
      "[5889]\ttraining's binary_logloss: 0.429883\n",
      "[5890]\ttraining's binary_logloss: 0.429845\n",
      "[5891]\ttraining's binary_logloss: 0.429807\n",
      "[5892]\ttraining's binary_logloss: 0.429766\n",
      "[5893]\ttraining's binary_logloss: 0.429726\n",
      "[5894]\ttraining's binary_logloss: 0.429685\n",
      "[5895]\ttraining's binary_logloss: 0.429628\n",
      "[5896]\ttraining's binary_logloss: 0.429604\n",
      "[5897]\ttraining's binary_logloss: 0.42955\n",
      "[5898]\ttraining's binary_logloss: 0.429497\n",
      "[5899]\ttraining's binary_logloss: 0.429449\n",
      "[5900]\ttraining's binary_logloss: 0.4294\n",
      "[5901]\ttraining's binary_logloss: 0.429364\n",
      "[5902]\ttraining's binary_logloss: 0.429328\n",
      "[5903]\ttraining's binary_logloss: 0.429291\n",
      "[5904]\ttraining's binary_logloss: 0.429263\n",
      "[5905]\ttraining's binary_logloss: 0.429213\n",
      "[5906]\ttraining's binary_logloss: 0.42917\n",
      "[5907]\ttraining's binary_logloss: 0.429125\n",
      "[5908]\ttraining's binary_logloss: 0.429091\n",
      "[5909]\ttraining's binary_logloss: 0.429034\n",
      "[5910]\ttraining's binary_logloss: 0.428992\n",
      "[5911]\ttraining's binary_logloss: 0.428937\n",
      "[5912]\ttraining's binary_logloss: 0.428897\n",
      "[5913]\ttraining's binary_logloss: 0.42884\n",
      "[5914]\ttraining's binary_logloss: 0.428777\n",
      "[5915]\ttraining's binary_logloss: 0.428733\n",
      "[5916]\ttraining's binary_logloss: 0.428677\n",
      "[5917]\ttraining's binary_logloss: 0.428647\n",
      "[5918]\ttraining's binary_logloss: 0.428582\n",
      "[5919]\ttraining's binary_logloss: 0.428516\n",
      "[5920]\ttraining's binary_logloss: 0.42848\n",
      "[5921]\ttraining's binary_logloss: 0.428444\n",
      "[5922]\ttraining's binary_logloss: 0.4284\n",
      "[5923]\ttraining's binary_logloss: 0.428343\n",
      "[5924]\ttraining's binary_logloss: 0.428298\n",
      "[5925]\ttraining's binary_logloss: 0.428238\n",
      "[5926]\ttraining's binary_logloss: 0.428195\n",
      "[5927]\ttraining's binary_logloss: 0.428153\n",
      "[5928]\ttraining's binary_logloss: 0.428116\n",
      "[5929]\ttraining's binary_logloss: 0.42807\n",
      "[5930]\ttraining's binary_logloss: 0.428018\n",
      "[5931]\ttraining's binary_logloss: 0.427974\n",
      "[5932]\ttraining's binary_logloss: 0.427932\n",
      "[5933]\ttraining's binary_logloss: 0.427871\n",
      "[5934]\ttraining's binary_logloss: 0.427821\n",
      "[5935]\ttraining's binary_logloss: 0.427768\n",
      "[5936]\ttraining's binary_logloss: 0.427715\n",
      "[5937]\ttraining's binary_logloss: 0.42766\n",
      "[5938]\ttraining's binary_logloss: 0.427614\n",
      "[5939]\ttraining's binary_logloss: 0.427559\n",
      "[5940]\ttraining's binary_logloss: 0.427506\n",
      "[5941]\ttraining's binary_logloss: 0.427442\n",
      "[5942]\ttraining's binary_logloss: 0.427413\n",
      "[5943]\ttraining's binary_logloss: 0.427358\n",
      "[5944]\ttraining's binary_logloss: 0.427315\n",
      "[5945]\ttraining's binary_logloss: 0.427263\n",
      "[5946]\ttraining's binary_logloss: 0.427207\n",
      "[5947]\ttraining's binary_logloss: 0.427177\n",
      "[5948]\ttraining's binary_logloss: 0.427123\n",
      "[5949]\ttraining's binary_logloss: 0.427094\n",
      "[5950]\ttraining's binary_logloss: 0.427023\n",
      "[5951]\ttraining's binary_logloss: 0.426987\n",
      "[5952]\ttraining's binary_logloss: 0.426934\n",
      "[5953]\ttraining's binary_logloss: 0.426881\n",
      "[5954]\ttraining's binary_logloss: 0.426838\n",
      "[5955]\ttraining's binary_logloss: 0.426784\n",
      "[5956]\ttraining's binary_logloss: 0.426751\n",
      "[5957]\ttraining's binary_logloss: 0.426703\n",
      "[5958]\ttraining's binary_logloss: 0.426666\n",
      "[5959]\ttraining's binary_logloss: 0.426605\n",
      "[5960]\ttraining's binary_logloss: 0.426567\n",
      "[5961]\ttraining's binary_logloss: 0.426536\n",
      "[5962]\ttraining's binary_logloss: 0.426498\n",
      "[5963]\ttraining's binary_logloss: 0.426461\n",
      "[5964]\ttraining's binary_logloss: 0.42641\n",
      "[5965]\ttraining's binary_logloss: 0.426375\n",
      "[5966]\ttraining's binary_logloss: 0.426327\n",
      "[5967]\ttraining's binary_logloss: 0.42627\n",
      "[5968]\ttraining's binary_logloss: 0.426215\n",
      "[5969]\ttraining's binary_logloss: 0.426183\n",
      "[5970]\ttraining's binary_logloss: 0.426126\n",
      "[5971]\ttraining's binary_logloss: 0.426075\n",
      "[5972]\ttraining's binary_logloss: 0.426031\n",
      "[5973]\ttraining's binary_logloss: 0.425975\n",
      "[5974]\ttraining's binary_logloss: 0.425933\n",
      "[5975]\ttraining's binary_logloss: 0.425899\n",
      "[5976]\ttraining's binary_logloss: 0.425863\n",
      "[5977]\ttraining's binary_logloss: 0.425814\n",
      "[5978]\ttraining's binary_logloss: 0.425765\n",
      "[5979]\ttraining's binary_logloss: 0.425713\n",
      "[5980]\ttraining's binary_logloss: 0.42567\n",
      "[5981]\ttraining's binary_logloss: 0.425616\n",
      "[5982]\ttraining's binary_logloss: 0.425564\n",
      "[5983]\ttraining's binary_logloss: 0.425509\n",
      "[5984]\ttraining's binary_logloss: 0.425461\n",
      "[5985]\ttraining's binary_logloss: 0.425412\n",
      "[5986]\ttraining's binary_logloss: 0.425354\n",
      "[5987]\ttraining's binary_logloss: 0.425298\n",
      "[5988]\ttraining's binary_logloss: 0.425262\n",
      "[5989]\ttraining's binary_logloss: 0.42522\n",
      "[5990]\ttraining's binary_logloss: 0.425183\n",
      "[5991]\ttraining's binary_logloss: 0.425154\n",
      "[5992]\ttraining's binary_logloss: 0.425126\n",
      "[5993]\ttraining's binary_logloss: 0.425078\n",
      "[5994]\ttraining's binary_logloss: 0.425011\n",
      "[5995]\ttraining's binary_logloss: 0.424962\n",
      "[5996]\ttraining's binary_logloss: 0.424919\n",
      "[5997]\ttraining's binary_logloss: 0.424867\n",
      "[5998]\ttraining's binary_logloss: 0.424835\n",
      "[5999]\ttraining's binary_logloss: 0.424802\n",
      "[6000]\ttraining's binary_logloss: 0.424756\n",
      "[6001]\ttraining's binary_logloss: 0.424723\n",
      "[6002]\ttraining's binary_logloss: 0.424684\n",
      "[6003]\ttraining's binary_logloss: 0.42463\n",
      "[6004]\ttraining's binary_logloss: 0.424582\n",
      "[6005]\ttraining's binary_logloss: 0.42453\n",
      "[6006]\ttraining's binary_logloss: 0.424492\n",
      "[6007]\ttraining's binary_logloss: 0.424446\n",
      "[6008]\ttraining's binary_logloss: 0.424414\n",
      "[6009]\ttraining's binary_logloss: 0.424372\n",
      "[6010]\ttraining's binary_logloss: 0.424316\n",
      "[6011]\ttraining's binary_logloss: 0.424285\n",
      "[6012]\ttraining's binary_logloss: 0.42425\n",
      "[6013]\ttraining's binary_logloss: 0.424196\n",
      "[6014]\ttraining's binary_logloss: 0.424135\n",
      "[6015]\ttraining's binary_logloss: 0.424095\n",
      "[6016]\ttraining's binary_logloss: 0.424034\n",
      "[6017]\ttraining's binary_logloss: 0.423964\n",
      "[6018]\ttraining's binary_logloss: 0.423908\n",
      "[6019]\ttraining's binary_logloss: 0.423863\n",
      "[6020]\ttraining's binary_logloss: 0.423818\n",
      "[6021]\ttraining's binary_logloss: 0.423787\n",
      "[6022]\ttraining's binary_logloss: 0.423729\n",
      "[6023]\ttraining's binary_logloss: 0.42369\n",
      "[6024]\ttraining's binary_logloss: 0.423646\n",
      "[6025]\ttraining's binary_logloss: 0.423607\n",
      "[6026]\ttraining's binary_logloss: 0.423573\n",
      "[6027]\ttraining's binary_logloss: 0.423538\n",
      "[6028]\ttraining's binary_logloss: 0.423472\n",
      "[6029]\ttraining's binary_logloss: 0.423425\n",
      "[6030]\ttraining's binary_logloss: 0.423384\n",
      "[6031]\ttraining's binary_logloss: 0.423325\n",
      "[6032]\ttraining's binary_logloss: 0.42329\n",
      "[6033]\ttraining's binary_logloss: 0.423233\n",
      "[6034]\ttraining's binary_logloss: 0.423186\n",
      "[6035]\ttraining's binary_logloss: 0.423139\n",
      "[6036]\ttraining's binary_logloss: 0.42307\n",
      "[6037]\ttraining's binary_logloss: 0.423015\n",
      "[6038]\ttraining's binary_logloss: 0.422972\n",
      "[6039]\ttraining's binary_logloss: 0.422941\n",
      "[6040]\ttraining's binary_logloss: 0.422897\n",
      "[6041]\ttraining's binary_logloss: 0.42286\n",
      "[6042]\ttraining's binary_logloss: 0.422818\n",
      "[6043]\ttraining's binary_logloss: 0.422777\n",
      "[6044]\ttraining's binary_logloss: 0.422733\n",
      "[6045]\ttraining's binary_logloss: 0.422696\n",
      "[6046]\ttraining's binary_logloss: 0.42265\n",
      "[6047]\ttraining's binary_logloss: 0.42261\n",
      "[6048]\ttraining's binary_logloss: 0.422554\n",
      "[6049]\ttraining's binary_logloss: 0.422502\n",
      "[6050]\ttraining's binary_logloss: 0.422467\n",
      "[6051]\ttraining's binary_logloss: 0.422411\n",
      "[6052]\ttraining's binary_logloss: 0.422364\n",
      "[6053]\ttraining's binary_logloss: 0.422323\n",
      "[6054]\ttraining's binary_logloss: 0.422288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6055]\ttraining's binary_logloss: 0.422237\n",
      "[6056]\ttraining's binary_logloss: 0.422182\n",
      "[6057]\ttraining's binary_logloss: 0.422152\n",
      "[6058]\ttraining's binary_logloss: 0.422103\n",
      "[6059]\ttraining's binary_logloss: 0.422055\n",
      "[6060]\ttraining's binary_logloss: 0.422018\n",
      "[6061]\ttraining's binary_logloss: 0.421979\n",
      "[6062]\ttraining's binary_logloss: 0.421941\n",
      "[6063]\ttraining's binary_logloss: 0.421895\n",
      "[6064]\ttraining's binary_logloss: 0.421856\n",
      "[6065]\ttraining's binary_logloss: 0.421822\n",
      "[6066]\ttraining's binary_logloss: 0.421744\n",
      "[6067]\ttraining's binary_logloss: 0.421693\n",
      "[6068]\ttraining's binary_logloss: 0.421651\n",
      "[6069]\ttraining's binary_logloss: 0.421614\n",
      "[6070]\ttraining's binary_logloss: 0.421578\n",
      "[6071]\ttraining's binary_logloss: 0.421526\n",
      "[6072]\ttraining's binary_logloss: 0.42147\n",
      "[6073]\ttraining's binary_logloss: 0.421439\n",
      "[6074]\ttraining's binary_logloss: 0.421403\n",
      "[6075]\ttraining's binary_logloss: 0.421371\n",
      "[6076]\ttraining's binary_logloss: 0.421324\n",
      "[6077]\ttraining's binary_logloss: 0.421275\n",
      "[6078]\ttraining's binary_logloss: 0.421242\n",
      "[6079]\ttraining's binary_logloss: 0.421208\n",
      "[6080]\ttraining's binary_logloss: 0.42116\n",
      "[6081]\ttraining's binary_logloss: 0.421122\n",
      "[6082]\ttraining's binary_logloss: 0.42107\n",
      "[6083]\ttraining's binary_logloss: 0.421016\n",
      "[6084]\ttraining's binary_logloss: 0.420972\n",
      "[6085]\ttraining's binary_logloss: 0.420933\n",
      "[6086]\ttraining's binary_logloss: 0.420899\n",
      "[6087]\ttraining's binary_logloss: 0.420875\n",
      "[6088]\ttraining's binary_logloss: 0.42083\n",
      "[6089]\ttraining's binary_logloss: 0.420786\n",
      "[6090]\ttraining's binary_logloss: 0.420743\n",
      "[6091]\ttraining's binary_logloss: 0.420707\n",
      "[6092]\ttraining's binary_logloss: 0.420655\n",
      "[6093]\ttraining's binary_logloss: 0.42062\n",
      "[6094]\ttraining's binary_logloss: 0.420578\n",
      "[6095]\ttraining's binary_logloss: 0.42055\n",
      "[6096]\ttraining's binary_logloss: 0.420498\n",
      "[6097]\ttraining's binary_logloss: 0.420447\n",
      "[6098]\ttraining's binary_logloss: 0.420391\n",
      "[6099]\ttraining's binary_logloss: 0.420347\n",
      "[6100]\ttraining's binary_logloss: 0.420315\n",
      "[6101]\ttraining's binary_logloss: 0.420275\n",
      "[6102]\ttraining's binary_logloss: 0.420225\n",
      "[6103]\ttraining's binary_logloss: 0.420178\n",
      "[6104]\ttraining's binary_logloss: 0.420112\n",
      "[6105]\ttraining's binary_logloss: 0.420059\n",
      "[6106]\ttraining's binary_logloss: 0.420007\n",
      "[6107]\ttraining's binary_logloss: 0.41996\n",
      "[6108]\ttraining's binary_logloss: 0.419912\n",
      "[6109]\ttraining's binary_logloss: 0.419861\n",
      "[6110]\ttraining's binary_logloss: 0.419822\n",
      "[6111]\ttraining's binary_logloss: 0.419783\n",
      "[6112]\ttraining's binary_logloss: 0.41974\n",
      "[6113]\ttraining's binary_logloss: 0.4197\n",
      "[6114]\ttraining's binary_logloss: 0.419658\n",
      "[6115]\ttraining's binary_logloss: 0.419614\n",
      "[6116]\ttraining's binary_logloss: 0.41957\n",
      "[6117]\ttraining's binary_logloss: 0.419522\n",
      "[6118]\ttraining's binary_logloss: 0.41947\n",
      "[6119]\ttraining's binary_logloss: 0.419432\n",
      "[6120]\ttraining's binary_logloss: 0.419385\n",
      "[6121]\ttraining's binary_logloss: 0.419347\n",
      "[6122]\ttraining's binary_logloss: 0.419306\n",
      "[6123]\ttraining's binary_logloss: 0.41926\n",
      "[6124]\ttraining's binary_logloss: 0.419215\n",
      "[6125]\ttraining's binary_logloss: 0.419174\n",
      "[6126]\ttraining's binary_logloss: 0.419118\n",
      "[6127]\ttraining's binary_logloss: 0.41908\n",
      "[6128]\ttraining's binary_logloss: 0.419026\n",
      "[6129]\ttraining's binary_logloss: 0.418983\n",
      "[6130]\ttraining's binary_logloss: 0.418935\n",
      "[6131]\ttraining's binary_logloss: 0.418901\n",
      "[6132]\ttraining's binary_logloss: 0.418866\n",
      "[6133]\ttraining's binary_logloss: 0.418838\n",
      "[6134]\ttraining's binary_logloss: 0.418796\n",
      "[6135]\ttraining's binary_logloss: 0.418741\n",
      "[6136]\ttraining's binary_logloss: 0.418705\n",
      "[6137]\ttraining's binary_logloss: 0.418667\n",
      "[6138]\ttraining's binary_logloss: 0.418623\n",
      "[6139]\ttraining's binary_logloss: 0.418573\n",
      "[6140]\ttraining's binary_logloss: 0.418516\n",
      "[6141]\ttraining's binary_logloss: 0.418466\n",
      "[6142]\ttraining's binary_logloss: 0.418423\n",
      "[6143]\ttraining's binary_logloss: 0.418378\n",
      "[6144]\ttraining's binary_logloss: 0.418342\n",
      "[6145]\ttraining's binary_logloss: 0.418305\n",
      "[6146]\ttraining's binary_logloss: 0.418262\n",
      "[6147]\ttraining's binary_logloss: 0.418217\n",
      "[6148]\ttraining's binary_logloss: 0.418175\n",
      "[6149]\ttraining's binary_logloss: 0.418134\n",
      "[6150]\ttraining's binary_logloss: 0.418089\n",
      "[6151]\ttraining's binary_logloss: 0.418053\n",
      "[6152]\ttraining's binary_logloss: 0.418015\n",
      "[6153]\ttraining's binary_logloss: 0.417962\n",
      "[6154]\ttraining's binary_logloss: 0.417918\n",
      "[6155]\ttraining's binary_logloss: 0.417887\n",
      "[6156]\ttraining's binary_logloss: 0.417841\n",
      "[6157]\ttraining's binary_logloss: 0.417796\n",
      "[6158]\ttraining's binary_logloss: 0.41775\n",
      "[6159]\ttraining's binary_logloss: 0.417718\n",
      "[6160]\ttraining's binary_logloss: 0.417678\n",
      "[6161]\ttraining's binary_logloss: 0.417638\n",
      "[6162]\ttraining's binary_logloss: 0.417586\n",
      "[6163]\ttraining's binary_logloss: 0.417544\n",
      "[6164]\ttraining's binary_logloss: 0.417501\n",
      "[6165]\ttraining's binary_logloss: 0.417453\n",
      "[6166]\ttraining's binary_logloss: 0.417409\n",
      "[6167]\ttraining's binary_logloss: 0.417362\n",
      "[6168]\ttraining's binary_logloss: 0.417326\n",
      "[6169]\ttraining's binary_logloss: 0.417289\n",
      "[6170]\ttraining's binary_logloss: 0.417243\n",
      "[6171]\ttraining's binary_logloss: 0.417193\n",
      "[6172]\ttraining's binary_logloss: 0.417139\n",
      "[6173]\ttraining's binary_logloss: 0.417099\n",
      "[6174]\ttraining's binary_logloss: 0.417052\n",
      "[6175]\ttraining's binary_logloss: 0.416996\n",
      "[6176]\ttraining's binary_logloss: 0.416959\n",
      "[6177]\ttraining's binary_logloss: 0.416916\n",
      "[6178]\ttraining's binary_logloss: 0.416877\n",
      "[6179]\ttraining's binary_logloss: 0.416827\n",
      "[6180]\ttraining's binary_logloss: 0.416793\n",
      "[6181]\ttraining's binary_logloss: 0.416742\n",
      "[6182]\ttraining's binary_logloss: 0.416697\n",
      "[6183]\ttraining's binary_logloss: 0.416672\n",
      "[6184]\ttraining's binary_logloss: 0.416621\n",
      "[6185]\ttraining's binary_logloss: 0.416572\n",
      "[6186]\ttraining's binary_logloss: 0.416531\n",
      "[6187]\ttraining's binary_logloss: 0.416491\n",
      "[6188]\ttraining's binary_logloss: 0.416444\n",
      "[6189]\ttraining's binary_logloss: 0.416401\n",
      "[6190]\ttraining's binary_logloss: 0.416345\n",
      "[6191]\ttraining's binary_logloss: 0.416306\n",
      "[6192]\ttraining's binary_logloss: 0.416259\n",
      "[6193]\ttraining's binary_logloss: 0.416222\n",
      "[6194]\ttraining's binary_logloss: 0.416178\n",
      "[6195]\ttraining's binary_logloss: 0.416135\n",
      "[6196]\ttraining's binary_logloss: 0.416093\n",
      "[6197]\ttraining's binary_logloss: 0.416033\n",
      "[6198]\ttraining's binary_logloss: 0.415995\n",
      "[6199]\ttraining's binary_logloss: 0.415959\n",
      "[6200]\ttraining's binary_logloss: 0.415898\n",
      "[6201]\ttraining's binary_logloss: 0.415871\n",
      "[6202]\ttraining's binary_logloss: 0.415819\n",
      "[6203]\ttraining's binary_logloss: 0.415782\n",
      "[6204]\ttraining's binary_logloss: 0.41575\n",
      "[6205]\ttraining's binary_logloss: 0.4157\n",
      "[6206]\ttraining's binary_logloss: 0.415661\n",
      "[6207]\ttraining's binary_logloss: 0.415627\n",
      "[6208]\ttraining's binary_logloss: 0.415567\n",
      "[6209]\ttraining's binary_logloss: 0.415523\n",
      "[6210]\ttraining's binary_logloss: 0.415494\n",
      "[6211]\ttraining's binary_logloss: 0.415435\n",
      "[6212]\ttraining's binary_logloss: 0.415391\n",
      "[6213]\ttraining's binary_logloss: 0.41536\n",
      "[6214]\ttraining's binary_logloss: 0.415307\n",
      "[6215]\ttraining's binary_logloss: 0.41526\n",
      "[6216]\ttraining's binary_logloss: 0.415217\n",
      "[6217]\ttraining's binary_logloss: 0.415174\n",
      "[6218]\ttraining's binary_logloss: 0.415143\n",
      "[6219]\ttraining's binary_logloss: 0.415097\n",
      "[6220]\ttraining's binary_logloss: 0.415068\n",
      "[6221]\ttraining's binary_logloss: 0.415033\n",
      "[6222]\ttraining's binary_logloss: 0.414976\n",
      "[6223]\ttraining's binary_logloss: 0.414928\n",
      "[6224]\ttraining's binary_logloss: 0.414888\n",
      "[6225]\ttraining's binary_logloss: 0.414837\n",
      "[6226]\ttraining's binary_logloss: 0.41479\n",
      "[6227]\ttraining's binary_logloss: 0.414749\n",
      "[6228]\ttraining's binary_logloss: 0.414691\n",
      "[6229]\ttraining's binary_logloss: 0.414634\n",
      "[6230]\ttraining's binary_logloss: 0.414596\n",
      "[6231]\ttraining's binary_logloss: 0.41455\n",
      "[6232]\ttraining's binary_logloss: 0.414516\n",
      "[6233]\ttraining's binary_logloss: 0.414459\n",
      "[6234]\ttraining's binary_logloss: 0.414402\n",
      "[6235]\ttraining's binary_logloss: 0.41437\n",
      "[6236]\ttraining's binary_logloss: 0.414321\n",
      "[6237]\ttraining's binary_logloss: 0.41428\n",
      "[6238]\ttraining's binary_logloss: 0.414242\n",
      "[6239]\ttraining's binary_logloss: 0.414198\n",
      "[6240]\ttraining's binary_logloss: 0.414168\n",
      "[6241]\ttraining's binary_logloss: 0.414113\n",
      "[6242]\ttraining's binary_logloss: 0.414068\n",
      "[6243]\ttraining's binary_logloss: 0.414027\n",
      "[6244]\ttraining's binary_logloss: 0.413974\n",
      "[6245]\ttraining's binary_logloss: 0.413922\n",
      "[6246]\ttraining's binary_logloss: 0.413867\n",
      "[6247]\ttraining's binary_logloss: 0.413827\n",
      "[6248]\ttraining's binary_logloss: 0.413775\n",
      "[6249]\ttraining's binary_logloss: 0.413732\n",
      "[6250]\ttraining's binary_logloss: 0.413681\n",
      "[6251]\ttraining's binary_logloss: 0.413643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6252]\ttraining's binary_logloss: 0.413592\n",
      "[6253]\ttraining's binary_logloss: 0.413552\n",
      "[6254]\ttraining's binary_logloss: 0.413496\n",
      "[6255]\ttraining's binary_logloss: 0.413451\n",
      "[6256]\ttraining's binary_logloss: 0.413396\n",
      "[6257]\ttraining's binary_logloss: 0.413362\n",
      "[6258]\ttraining's binary_logloss: 0.413327\n",
      "[6259]\ttraining's binary_logloss: 0.413285\n",
      "[6260]\ttraining's binary_logloss: 0.41324\n",
      "[6261]\ttraining's binary_logloss: 0.413191\n",
      "[6262]\ttraining's binary_logloss: 0.413162\n",
      "[6263]\ttraining's binary_logloss: 0.413119\n",
      "[6264]\ttraining's binary_logloss: 0.413052\n",
      "[6265]\ttraining's binary_logloss: 0.413001\n",
      "[6266]\ttraining's binary_logloss: 0.412964\n",
      "[6267]\ttraining's binary_logloss: 0.412918\n",
      "[6268]\ttraining's binary_logloss: 0.412881\n",
      "[6269]\ttraining's binary_logloss: 0.412828\n",
      "[6270]\ttraining's binary_logloss: 0.412771\n",
      "[6271]\ttraining's binary_logloss: 0.412739\n",
      "[6272]\ttraining's binary_logloss: 0.412682\n",
      "[6273]\ttraining's binary_logloss: 0.412633\n",
      "[6274]\ttraining's binary_logloss: 0.412596\n",
      "[6275]\ttraining's binary_logloss: 0.412558\n",
      "[6276]\ttraining's binary_logloss: 0.412511\n",
      "[6277]\ttraining's binary_logloss: 0.412465\n",
      "[6278]\ttraining's binary_logloss: 0.412404\n",
      "[6279]\ttraining's binary_logloss: 0.412359\n",
      "[6280]\ttraining's binary_logloss: 0.412313\n",
      "[6281]\ttraining's binary_logloss: 0.412271\n",
      "[6282]\ttraining's binary_logloss: 0.412233\n",
      "[6283]\ttraining's binary_logloss: 0.412192\n",
      "[6284]\ttraining's binary_logloss: 0.412149\n",
      "[6285]\ttraining's binary_logloss: 0.412106\n",
      "[6286]\ttraining's binary_logloss: 0.412067\n",
      "[6287]\ttraining's binary_logloss: 0.412032\n",
      "[6288]\ttraining's binary_logloss: 0.411972\n",
      "[6289]\ttraining's binary_logloss: 0.411928\n",
      "[6290]\ttraining's binary_logloss: 0.411886\n",
      "[6291]\ttraining's binary_logloss: 0.411845\n",
      "[6292]\ttraining's binary_logloss: 0.411798\n",
      "[6293]\ttraining's binary_logloss: 0.411755\n",
      "[6294]\ttraining's binary_logloss: 0.411705\n",
      "[6295]\ttraining's binary_logloss: 0.411661\n",
      "[6296]\ttraining's binary_logloss: 0.411624\n",
      "[6297]\ttraining's binary_logloss: 0.411579\n",
      "[6298]\ttraining's binary_logloss: 0.411532\n",
      "[6299]\ttraining's binary_logloss: 0.411485\n",
      "[6300]\ttraining's binary_logloss: 0.411446\n",
      "[6301]\ttraining's binary_logloss: 0.411421\n",
      "[6302]\ttraining's binary_logloss: 0.411387\n",
      "[6303]\ttraining's binary_logloss: 0.41133\n",
      "[6304]\ttraining's binary_logloss: 0.411297\n",
      "[6305]\ttraining's binary_logloss: 0.411267\n",
      "[6306]\ttraining's binary_logloss: 0.411228\n",
      "[6307]\ttraining's binary_logloss: 0.411183\n",
      "[6308]\ttraining's binary_logloss: 0.411141\n",
      "[6309]\ttraining's binary_logloss: 0.411095\n",
      "[6310]\ttraining's binary_logloss: 0.411051\n",
      "[6311]\ttraining's binary_logloss: 0.411009\n",
      "[6312]\ttraining's binary_logloss: 0.410979\n",
      "[6313]\ttraining's binary_logloss: 0.410935\n",
      "[6314]\ttraining's binary_logloss: 0.410896\n",
      "[6315]\ttraining's binary_logloss: 0.410855\n",
      "[6316]\ttraining's binary_logloss: 0.410826\n",
      "[6317]\ttraining's binary_logloss: 0.410786\n",
      "[6318]\ttraining's binary_logloss: 0.410739\n",
      "[6319]\ttraining's binary_logloss: 0.410678\n",
      "[6320]\ttraining's binary_logloss: 0.410629\n",
      "[6321]\ttraining's binary_logloss: 0.410584\n",
      "[6322]\ttraining's binary_logloss: 0.410544\n",
      "[6323]\ttraining's binary_logloss: 0.410511\n",
      "[6324]\ttraining's binary_logloss: 0.410457\n",
      "[6325]\ttraining's binary_logloss: 0.410415\n",
      "[6326]\ttraining's binary_logloss: 0.410375\n",
      "[6327]\ttraining's binary_logloss: 0.410336\n",
      "[6328]\ttraining's binary_logloss: 0.410302\n",
      "[6329]\ttraining's binary_logloss: 0.410255\n",
      "[6330]\ttraining's binary_logloss: 0.410212\n",
      "[6331]\ttraining's binary_logloss: 0.410157\n",
      "[6332]\ttraining's binary_logloss: 0.410111\n",
      "[6333]\ttraining's binary_logloss: 0.410071\n",
      "[6334]\ttraining's binary_logloss: 0.410031\n",
      "[6335]\ttraining's binary_logloss: 0.409993\n",
      "[6336]\ttraining's binary_logloss: 0.409962\n",
      "[6337]\ttraining's binary_logloss: 0.409929\n",
      "[6338]\ttraining's binary_logloss: 0.40987\n",
      "[6339]\ttraining's binary_logloss: 0.409821\n",
      "[6340]\ttraining's binary_logloss: 0.409783\n",
      "[6341]\ttraining's binary_logloss: 0.409754\n",
      "[6342]\ttraining's binary_logloss: 0.409689\n",
      "[6343]\ttraining's binary_logloss: 0.409642\n",
      "[6344]\ttraining's binary_logloss: 0.409589\n",
      "[6345]\ttraining's binary_logloss: 0.409555\n",
      "[6346]\ttraining's binary_logloss: 0.409516\n",
      "[6347]\ttraining's binary_logloss: 0.409477\n",
      "[6348]\ttraining's binary_logloss: 0.409427\n",
      "[6349]\ttraining's binary_logloss: 0.409367\n",
      "[6350]\ttraining's binary_logloss: 0.409328\n",
      "[6351]\ttraining's binary_logloss: 0.409278\n",
      "[6352]\ttraining's binary_logloss: 0.409237\n",
      "[6353]\ttraining's binary_logloss: 0.409176\n",
      "[6354]\ttraining's binary_logloss: 0.40911\n",
      "[6355]\ttraining's binary_logloss: 0.409061\n",
      "[6356]\ttraining's binary_logloss: 0.40902\n",
      "[6357]\ttraining's binary_logloss: 0.408987\n",
      "[6358]\ttraining's binary_logloss: 0.408955\n",
      "[6359]\ttraining's binary_logloss: 0.408925\n",
      "[6360]\ttraining's binary_logloss: 0.408888\n",
      "[6361]\ttraining's binary_logloss: 0.408851\n",
      "[6362]\ttraining's binary_logloss: 0.40881\n",
      "[6363]\ttraining's binary_logloss: 0.408785\n",
      "[6364]\ttraining's binary_logloss: 0.408743\n",
      "[6365]\ttraining's binary_logloss: 0.40869\n",
      "[6366]\ttraining's binary_logloss: 0.408653\n",
      "[6367]\ttraining's binary_logloss: 0.408595\n",
      "[6368]\ttraining's binary_logloss: 0.408548\n",
      "[6369]\ttraining's binary_logloss: 0.408506\n",
      "[6370]\ttraining's binary_logloss: 0.408465\n",
      "[6371]\ttraining's binary_logloss: 0.408436\n",
      "[6372]\ttraining's binary_logloss: 0.4084\n",
      "[6373]\ttraining's binary_logloss: 0.408345\n",
      "[6374]\ttraining's binary_logloss: 0.408301\n",
      "[6375]\ttraining's binary_logloss: 0.408262\n",
      "[6376]\ttraining's binary_logloss: 0.408216\n",
      "[6377]\ttraining's binary_logloss: 0.408173\n",
      "[6378]\ttraining's binary_logloss: 0.408134\n",
      "[6379]\ttraining's binary_logloss: 0.408104\n",
      "[6380]\ttraining's binary_logloss: 0.408039\n",
      "[6381]\ttraining's binary_logloss: 0.408008\n",
      "[6382]\ttraining's binary_logloss: 0.407968\n",
      "[6383]\ttraining's binary_logloss: 0.407928\n",
      "[6384]\ttraining's binary_logloss: 0.407891\n",
      "[6385]\ttraining's binary_logloss: 0.407849\n",
      "[6386]\ttraining's binary_logloss: 0.407818\n",
      "[6387]\ttraining's binary_logloss: 0.407767\n",
      "[6388]\ttraining's binary_logloss: 0.407719\n",
      "[6389]\ttraining's binary_logloss: 0.407662\n",
      "[6390]\ttraining's binary_logloss: 0.407628\n",
      "[6391]\ttraining's binary_logloss: 0.407568\n",
      "[6392]\ttraining's binary_logloss: 0.407527\n",
      "[6393]\ttraining's binary_logloss: 0.407489\n",
      "[6394]\ttraining's binary_logloss: 0.40745\n",
      "[6395]\ttraining's binary_logloss: 0.407405\n",
      "[6396]\ttraining's binary_logloss: 0.407357\n",
      "[6397]\ttraining's binary_logloss: 0.407317\n",
      "[6398]\ttraining's binary_logloss: 0.40728\n",
      "[6399]\ttraining's binary_logloss: 0.407239\n",
      "[6400]\ttraining's binary_logloss: 0.407192\n",
      "[6401]\ttraining's binary_logloss: 0.407159\n",
      "[6402]\ttraining's binary_logloss: 0.407107\n",
      "[6403]\ttraining's binary_logloss: 0.407066\n",
      "[6404]\ttraining's binary_logloss: 0.407029\n",
      "[6405]\ttraining's binary_logloss: 0.406985\n",
      "[6406]\ttraining's binary_logloss: 0.406936\n",
      "[6407]\ttraining's binary_logloss: 0.406877\n",
      "[6408]\ttraining's binary_logloss: 0.406827\n",
      "[6409]\ttraining's binary_logloss: 0.406794\n",
      "[6410]\ttraining's binary_logloss: 0.406767\n",
      "[6411]\ttraining's binary_logloss: 0.406728\n",
      "[6412]\ttraining's binary_logloss: 0.406672\n",
      "[6413]\ttraining's binary_logloss: 0.406636\n",
      "[6414]\ttraining's binary_logloss: 0.406597\n",
      "[6415]\ttraining's binary_logloss: 0.40656\n",
      "[6416]\ttraining's binary_logloss: 0.406512\n",
      "[6417]\ttraining's binary_logloss: 0.406461\n",
      "[6418]\ttraining's binary_logloss: 0.406411\n",
      "[6419]\ttraining's binary_logloss: 0.406365\n",
      "[6420]\ttraining's binary_logloss: 0.406325\n",
      "[6421]\ttraining's binary_logloss: 0.406277\n",
      "[6422]\ttraining's binary_logloss: 0.406245\n",
      "[6423]\ttraining's binary_logloss: 0.406203\n",
      "[6424]\ttraining's binary_logloss: 0.406139\n",
      "[6425]\ttraining's binary_logloss: 0.406104\n",
      "[6426]\ttraining's binary_logloss: 0.40605\n",
      "[6427]\ttraining's binary_logloss: 0.406006\n",
      "[6428]\ttraining's binary_logloss: 0.405956\n",
      "[6429]\ttraining's binary_logloss: 0.405899\n",
      "[6430]\ttraining's binary_logloss: 0.405871\n",
      "[6431]\ttraining's binary_logloss: 0.405821\n",
      "[6432]\ttraining's binary_logloss: 0.405789\n",
      "[6433]\ttraining's binary_logloss: 0.405755\n",
      "[6434]\ttraining's binary_logloss: 0.405707\n",
      "[6435]\ttraining's binary_logloss: 0.405671\n",
      "[6436]\ttraining's binary_logloss: 0.405633\n",
      "[6437]\ttraining's binary_logloss: 0.40557\n",
      "[6438]\ttraining's binary_logloss: 0.405532\n",
      "[6439]\ttraining's binary_logloss: 0.405474\n",
      "[6440]\ttraining's binary_logloss: 0.405434\n",
      "[6441]\ttraining's binary_logloss: 0.405394\n",
      "[6442]\ttraining's binary_logloss: 0.405331\n",
      "[6443]\ttraining's binary_logloss: 0.405296\n",
      "[6444]\ttraining's binary_logloss: 0.405253\n",
      "[6445]\ttraining's binary_logloss: 0.405202\n",
      "[6446]\ttraining's binary_logloss: 0.405153\n",
      "[6447]\ttraining's binary_logloss: 0.405116\n",
      "[6448]\ttraining's binary_logloss: 0.405076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6449]\ttraining's binary_logloss: 0.405027\n",
      "[6450]\ttraining's binary_logloss: 0.404997\n",
      "[6451]\ttraining's binary_logloss: 0.404964\n",
      "[6452]\ttraining's binary_logloss: 0.404925\n",
      "[6453]\ttraining's binary_logloss: 0.404884\n",
      "[6454]\ttraining's binary_logloss: 0.404855\n",
      "[6455]\ttraining's binary_logloss: 0.404809\n",
      "[6456]\ttraining's binary_logloss: 0.404764\n",
      "[6457]\ttraining's binary_logloss: 0.404725\n",
      "[6458]\ttraining's binary_logloss: 0.404676\n",
      "[6459]\ttraining's binary_logloss: 0.404625\n",
      "[6460]\ttraining's binary_logloss: 0.404589\n",
      "[6461]\ttraining's binary_logloss: 0.404542\n",
      "[6462]\ttraining's binary_logloss: 0.404487\n",
      "[6463]\ttraining's binary_logloss: 0.404442\n",
      "[6464]\ttraining's binary_logloss: 0.404413\n",
      "[6465]\ttraining's binary_logloss: 0.404371\n",
      "[6466]\ttraining's binary_logloss: 0.404337\n",
      "[6467]\ttraining's binary_logloss: 0.404287\n",
      "[6468]\ttraining's binary_logloss: 0.404254\n",
      "[6469]\ttraining's binary_logloss: 0.404214\n",
      "[6470]\ttraining's binary_logloss: 0.404187\n",
      "[6471]\ttraining's binary_logloss: 0.404138\n",
      "[6472]\ttraining's binary_logloss: 0.404079\n",
      "[6473]\ttraining's binary_logloss: 0.404033\n",
      "[6474]\ttraining's binary_logloss: 0.404004\n",
      "[6475]\ttraining's binary_logloss: 0.40397\n",
      "[6476]\ttraining's binary_logloss: 0.403916\n",
      "[6477]\ttraining's binary_logloss: 0.403871\n",
      "[6478]\ttraining's binary_logloss: 0.403828\n",
      "[6479]\ttraining's binary_logloss: 0.403789\n",
      "[6480]\ttraining's binary_logloss: 0.40374\n",
      "[6481]\ttraining's binary_logloss: 0.403705\n",
      "[6482]\ttraining's binary_logloss: 0.403659\n",
      "[6483]\ttraining's binary_logloss: 0.40362\n",
      "[6484]\ttraining's binary_logloss: 0.403576\n",
      "[6485]\ttraining's binary_logloss: 0.403528\n",
      "[6486]\ttraining's binary_logloss: 0.403466\n",
      "[6487]\ttraining's binary_logloss: 0.403438\n",
      "[6488]\ttraining's binary_logloss: 0.403398\n",
      "[6489]\ttraining's binary_logloss: 0.403345\n",
      "[6490]\ttraining's binary_logloss: 0.403308\n",
      "[6491]\ttraining's binary_logloss: 0.403258\n",
      "[6492]\ttraining's binary_logloss: 0.403192\n",
      "[6493]\ttraining's binary_logloss: 0.403154\n",
      "[6494]\ttraining's binary_logloss: 0.403118\n",
      "[6495]\ttraining's binary_logloss: 0.403076\n",
      "[6496]\ttraining's binary_logloss: 0.403047\n",
      "[6497]\ttraining's binary_logloss: 0.403002\n",
      "[6498]\ttraining's binary_logloss: 0.402973\n",
      "[6499]\ttraining's binary_logloss: 0.402935\n",
      "[6500]\ttraining's binary_logloss: 0.402906\n",
      "[6501]\ttraining's binary_logloss: 0.402865\n",
      "[6502]\ttraining's binary_logloss: 0.402831\n",
      "[6503]\ttraining's binary_logloss: 0.402785\n",
      "[6504]\ttraining's binary_logloss: 0.402739\n",
      "[6505]\ttraining's binary_logloss: 0.402694\n",
      "[6506]\ttraining's binary_logloss: 0.402655\n",
      "[6507]\ttraining's binary_logloss: 0.402603\n",
      "[6508]\ttraining's binary_logloss: 0.402551\n",
      "[6509]\ttraining's binary_logloss: 0.402492\n",
      "[6510]\ttraining's binary_logloss: 0.402447\n",
      "[6511]\ttraining's binary_logloss: 0.402384\n",
      "[6512]\ttraining's binary_logloss: 0.402344\n",
      "[6513]\ttraining's binary_logloss: 0.402291\n",
      "[6514]\ttraining's binary_logloss: 0.402244\n",
      "[6515]\ttraining's binary_logloss: 0.402197\n",
      "[6516]\ttraining's binary_logloss: 0.402152\n",
      "[6517]\ttraining's binary_logloss: 0.402117\n",
      "[6518]\ttraining's binary_logloss: 0.402083\n",
      "[6519]\ttraining's binary_logloss: 0.402054\n",
      "[6520]\ttraining's binary_logloss: 0.402028\n",
      "[6521]\ttraining's binary_logloss: 0.401982\n",
      "[6522]\ttraining's binary_logloss: 0.401927\n",
      "[6523]\ttraining's binary_logloss: 0.401888\n",
      "[6524]\ttraining's binary_logloss: 0.401844\n",
      "[6525]\ttraining's binary_logloss: 0.401797\n",
      "[6526]\ttraining's binary_logloss: 0.401744\n",
      "[6527]\ttraining's binary_logloss: 0.401707\n",
      "[6528]\ttraining's binary_logloss: 0.401663\n",
      "[6529]\ttraining's binary_logloss: 0.40163\n",
      "[6530]\ttraining's binary_logloss: 0.4016\n",
      "[6531]\ttraining's binary_logloss: 0.401563\n",
      "[6532]\ttraining's binary_logloss: 0.40152\n",
      "[6533]\ttraining's binary_logloss: 0.401482\n",
      "[6534]\ttraining's binary_logloss: 0.401447\n",
      "[6535]\ttraining's binary_logloss: 0.401405\n",
      "[6536]\ttraining's binary_logloss: 0.401357\n",
      "[6537]\ttraining's binary_logloss: 0.401318\n",
      "[6538]\ttraining's binary_logloss: 0.401269\n",
      "[6539]\ttraining's binary_logloss: 0.401238\n",
      "[6540]\ttraining's binary_logloss: 0.401205\n",
      "[6541]\ttraining's binary_logloss: 0.401149\n",
      "[6542]\ttraining's binary_logloss: 0.401106\n",
      "[6543]\ttraining's binary_logloss: 0.40106\n",
      "[6544]\ttraining's binary_logloss: 0.40102\n",
      "[6545]\ttraining's binary_logloss: 0.400966\n",
      "[6546]\ttraining's binary_logloss: 0.400935\n",
      "[6547]\ttraining's binary_logloss: 0.400874\n",
      "[6548]\ttraining's binary_logloss: 0.400822\n",
      "[6549]\ttraining's binary_logloss: 0.400774\n",
      "[6550]\ttraining's binary_logloss: 0.400734\n",
      "[6551]\ttraining's binary_logloss: 0.400702\n",
      "[6552]\ttraining's binary_logloss: 0.400652\n",
      "[6553]\ttraining's binary_logloss: 0.40061\n",
      "[6554]\ttraining's binary_logloss: 0.40057\n",
      "[6555]\ttraining's binary_logloss: 0.400541\n",
      "[6556]\ttraining's binary_logloss: 0.4005\n",
      "[6557]\ttraining's binary_logloss: 0.400449\n",
      "[6558]\ttraining's binary_logloss: 0.400392\n",
      "[6559]\ttraining's binary_logloss: 0.400344\n",
      "[6560]\ttraining's binary_logloss: 0.400301\n",
      "[6561]\ttraining's binary_logloss: 0.400264\n",
      "[6562]\ttraining's binary_logloss: 0.400195\n",
      "[6563]\ttraining's binary_logloss: 0.400182\n",
      "[6564]\ttraining's binary_logloss: 0.400137\n",
      "[6565]\ttraining's binary_logloss: 0.400106\n",
      "[6566]\ttraining's binary_logloss: 0.400059\n",
      "[6567]\ttraining's binary_logloss: 0.400026\n",
      "[6568]\ttraining's binary_logloss: 0.399992\n",
      "[6569]\ttraining's binary_logloss: 0.39994\n",
      "[6570]\ttraining's binary_logloss: 0.399887\n",
      "[6571]\ttraining's binary_logloss: 0.399826\n",
      "[6572]\ttraining's binary_logloss: 0.399786\n",
      "[6573]\ttraining's binary_logloss: 0.39974\n",
      "[6574]\ttraining's binary_logloss: 0.399695\n",
      "[6575]\ttraining's binary_logloss: 0.39966\n",
      "[6576]\ttraining's binary_logloss: 0.399596\n",
      "[6577]\ttraining's binary_logloss: 0.399553\n",
      "[6578]\ttraining's binary_logloss: 0.399507\n",
      "[6579]\ttraining's binary_logloss: 0.39947\n",
      "[6580]\ttraining's binary_logloss: 0.399438\n",
      "[6581]\ttraining's binary_logloss: 0.399395\n",
      "[6582]\ttraining's binary_logloss: 0.39937\n",
      "[6583]\ttraining's binary_logloss: 0.399323\n",
      "[6584]\ttraining's binary_logloss: 0.39928\n",
      "[6585]\ttraining's binary_logloss: 0.399243\n",
      "[6586]\ttraining's binary_logloss: 0.399211\n",
      "[6587]\ttraining's binary_logloss: 0.399166\n",
      "[6588]\ttraining's binary_logloss: 0.399125\n",
      "[6589]\ttraining's binary_logloss: 0.399088\n",
      "[6590]\ttraining's binary_logloss: 0.39904\n",
      "[6591]\ttraining's binary_logloss: 0.399004\n",
      "[6592]\ttraining's binary_logloss: 0.398969\n",
      "[6593]\ttraining's binary_logloss: 0.398907\n",
      "[6594]\ttraining's binary_logloss: 0.398856\n",
      "[6595]\ttraining's binary_logloss: 0.398823\n",
      "[6596]\ttraining's binary_logloss: 0.398787\n",
      "[6597]\ttraining's binary_logloss: 0.398753\n",
      "[6598]\ttraining's binary_logloss: 0.398709\n",
      "[6599]\ttraining's binary_logloss: 0.398675\n",
      "[6600]\ttraining's binary_logloss: 0.398638\n",
      "[6601]\ttraining's binary_logloss: 0.398585\n",
      "[6602]\ttraining's binary_logloss: 0.398531\n",
      "[6603]\ttraining's binary_logloss: 0.398508\n",
      "[6604]\ttraining's binary_logloss: 0.398472\n",
      "[6605]\ttraining's binary_logloss: 0.39843\n",
      "[6606]\ttraining's binary_logloss: 0.398384\n",
      "[6607]\ttraining's binary_logloss: 0.398351\n",
      "[6608]\ttraining's binary_logloss: 0.398306\n",
      "[6609]\ttraining's binary_logloss: 0.398268\n",
      "[6610]\ttraining's binary_logloss: 0.398239\n",
      "[6611]\ttraining's binary_logloss: 0.398208\n",
      "[6612]\ttraining's binary_logloss: 0.39816\n",
      "[6613]\ttraining's binary_logloss: 0.398111\n",
      "[6614]\ttraining's binary_logloss: 0.398065\n",
      "[6615]\ttraining's binary_logloss: 0.398014\n",
      "[6616]\ttraining's binary_logloss: 0.39798\n",
      "[6617]\ttraining's binary_logloss: 0.397931\n",
      "[6618]\ttraining's binary_logloss: 0.397888\n",
      "[6619]\ttraining's binary_logloss: 0.397852\n",
      "[6620]\ttraining's binary_logloss: 0.397814\n",
      "[6621]\ttraining's binary_logloss: 0.397785\n",
      "[6622]\ttraining's binary_logloss: 0.397748\n",
      "[6623]\ttraining's binary_logloss: 0.397712\n",
      "[6624]\ttraining's binary_logloss: 0.397678\n",
      "[6625]\ttraining's binary_logloss: 0.397648\n",
      "[6626]\ttraining's binary_logloss: 0.397595\n",
      "[6627]\ttraining's binary_logloss: 0.397552\n",
      "[6628]\ttraining's binary_logloss: 0.397504\n",
      "[6629]\ttraining's binary_logloss: 0.397462\n",
      "[6630]\ttraining's binary_logloss: 0.397393\n",
      "[6631]\ttraining's binary_logloss: 0.397352\n",
      "[6632]\ttraining's binary_logloss: 0.397317\n",
      "[6633]\ttraining's binary_logloss: 0.397278\n",
      "[6634]\ttraining's binary_logloss: 0.397229\n",
      "[6635]\ttraining's binary_logloss: 0.397196\n",
      "[6636]\ttraining's binary_logloss: 0.397163\n",
      "[6637]\ttraining's binary_logloss: 0.39713\n",
      "[6638]\ttraining's binary_logloss: 0.397088\n",
      "[6639]\ttraining's binary_logloss: 0.397045\n",
      "[6640]\ttraining's binary_logloss: 0.397018\n",
      "[6641]\ttraining's binary_logloss: 0.396972\n",
      "[6642]\ttraining's binary_logloss: 0.396922\n",
      "[6643]\ttraining's binary_logloss: 0.396866\n",
      "[6644]\ttraining's binary_logloss: 0.39683\n",
      "[6645]\ttraining's binary_logloss: 0.396789\n",
      "[6646]\ttraining's binary_logloss: 0.396752\n",
      "[6647]\ttraining's binary_logloss: 0.396689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6648]\ttraining's binary_logloss: 0.396652\n",
      "[6649]\ttraining's binary_logloss: 0.396587\n",
      "[6650]\ttraining's binary_logloss: 0.396558\n",
      "[6651]\ttraining's binary_logloss: 0.396504\n",
      "[6652]\ttraining's binary_logloss: 0.396464\n",
      "[6653]\ttraining's binary_logloss: 0.39642\n",
      "[6654]\ttraining's binary_logloss: 0.396381\n",
      "[6655]\ttraining's binary_logloss: 0.396319\n",
      "[6656]\ttraining's binary_logloss: 0.396279\n",
      "[6657]\ttraining's binary_logloss: 0.396227\n",
      "[6658]\ttraining's binary_logloss: 0.396189\n",
      "[6659]\ttraining's binary_logloss: 0.39615\n",
      "[6660]\ttraining's binary_logloss: 0.396109\n",
      "[6661]\ttraining's binary_logloss: 0.396067\n",
      "[6662]\ttraining's binary_logloss: 0.396022\n",
      "[6663]\ttraining's binary_logloss: 0.395984\n",
      "[6664]\ttraining's binary_logloss: 0.395937\n",
      "[6665]\ttraining's binary_logloss: 0.395906\n",
      "[6666]\ttraining's binary_logloss: 0.395858\n",
      "[6667]\ttraining's binary_logloss: 0.395825\n",
      "[6668]\ttraining's binary_logloss: 0.395796\n",
      "[6669]\ttraining's binary_logloss: 0.395769\n",
      "[6670]\ttraining's binary_logloss: 0.395735\n",
      "[6671]\ttraining's binary_logloss: 0.395684\n",
      "[6672]\ttraining's binary_logloss: 0.395643\n",
      "[6673]\ttraining's binary_logloss: 0.395603\n",
      "[6674]\ttraining's binary_logloss: 0.395579\n",
      "[6675]\ttraining's binary_logloss: 0.395547\n",
      "[6676]\ttraining's binary_logloss: 0.395513\n",
      "[6677]\ttraining's binary_logloss: 0.395468\n",
      "[6678]\ttraining's binary_logloss: 0.39543\n",
      "[6679]\ttraining's binary_logloss: 0.395377\n",
      "[6680]\ttraining's binary_logloss: 0.395318\n",
      "[6681]\ttraining's binary_logloss: 0.395271\n",
      "[6682]\ttraining's binary_logloss: 0.39523\n",
      "[6683]\ttraining's binary_logloss: 0.395186\n",
      "[6684]\ttraining's binary_logloss: 0.395155\n",
      "[6685]\ttraining's binary_logloss: 0.395125\n",
      "[6686]\ttraining's binary_logloss: 0.395084\n",
      "[6687]\ttraining's binary_logloss: 0.395051\n",
      "[6688]\ttraining's binary_logloss: 0.395003\n",
      "[6689]\ttraining's binary_logloss: 0.394968\n",
      "[6690]\ttraining's binary_logloss: 0.394929\n",
      "[6691]\ttraining's binary_logloss: 0.39489\n",
      "[6692]\ttraining's binary_logloss: 0.394829\n",
      "[6693]\ttraining's binary_logloss: 0.394793\n",
      "[6694]\ttraining's binary_logloss: 0.394764\n",
      "[6695]\ttraining's binary_logloss: 0.394722\n",
      "[6696]\ttraining's binary_logloss: 0.394676\n",
      "[6697]\ttraining's binary_logloss: 0.394618\n",
      "[6698]\ttraining's binary_logloss: 0.394581\n",
      "[6699]\ttraining's binary_logloss: 0.394552\n",
      "[6700]\ttraining's binary_logloss: 0.394515\n",
      "[6701]\ttraining's binary_logloss: 0.39447\n",
      "[6702]\ttraining's binary_logloss: 0.394428\n",
      "[6703]\ttraining's binary_logloss: 0.394399\n",
      "[6704]\ttraining's binary_logloss: 0.39435\n",
      "[6705]\ttraining's binary_logloss: 0.394317\n",
      "[6706]\ttraining's binary_logloss: 0.394289\n",
      "[6707]\ttraining's binary_logloss: 0.394259\n",
      "[6708]\ttraining's binary_logloss: 0.394214\n",
      "[6709]\ttraining's binary_logloss: 0.394178\n",
      "[6710]\ttraining's binary_logloss: 0.394126\n",
      "[6711]\ttraining's binary_logloss: 0.394088\n",
      "[6712]\ttraining's binary_logloss: 0.394054\n",
      "[6713]\ttraining's binary_logloss: 0.39401\n",
      "[6714]\ttraining's binary_logloss: 0.39396\n",
      "[6715]\ttraining's binary_logloss: 0.393922\n",
      "[6716]\ttraining's binary_logloss: 0.393883\n",
      "[6717]\ttraining's binary_logloss: 0.393841\n",
      "[6718]\ttraining's binary_logloss: 0.393794\n",
      "[6719]\ttraining's binary_logloss: 0.393757\n",
      "[6720]\ttraining's binary_logloss: 0.393726\n",
      "[6721]\ttraining's binary_logloss: 0.393681\n",
      "[6722]\ttraining's binary_logloss: 0.393637\n",
      "[6723]\ttraining's binary_logloss: 0.393585\n",
      "[6724]\ttraining's binary_logloss: 0.393539\n",
      "[6725]\ttraining's binary_logloss: 0.393498\n",
      "[6726]\ttraining's binary_logloss: 0.393441\n",
      "[6727]\ttraining's binary_logloss: 0.393398\n",
      "[6728]\ttraining's binary_logloss: 0.393338\n",
      "[6729]\ttraining's binary_logloss: 0.393306\n",
      "[6730]\ttraining's binary_logloss: 0.393264\n",
      "[6731]\ttraining's binary_logloss: 0.39324\n",
      "[6732]\ttraining's binary_logloss: 0.393204\n",
      "[6733]\ttraining's binary_logloss: 0.393159\n",
      "[6734]\ttraining's binary_logloss: 0.39312\n",
      "[6735]\ttraining's binary_logloss: 0.39308\n",
      "[6736]\ttraining's binary_logloss: 0.393045\n",
      "[6737]\ttraining's binary_logloss: 0.392995\n",
      "[6738]\ttraining's binary_logloss: 0.392952\n",
      "[6739]\ttraining's binary_logloss: 0.392907\n",
      "[6740]\ttraining's binary_logloss: 0.392865\n",
      "[6741]\ttraining's binary_logloss: 0.392804\n",
      "[6742]\ttraining's binary_logloss: 0.392768\n",
      "[6743]\ttraining's binary_logloss: 0.39274\n",
      "[6744]\ttraining's binary_logloss: 0.392708\n",
      "[6745]\ttraining's binary_logloss: 0.392656\n",
      "[6746]\ttraining's binary_logloss: 0.392625\n",
      "[6747]\ttraining's binary_logloss: 0.392575\n",
      "[6748]\ttraining's binary_logloss: 0.392516\n",
      "[6749]\ttraining's binary_logloss: 0.392473\n",
      "[6750]\ttraining's binary_logloss: 0.39243\n",
      "[6751]\ttraining's binary_logloss: 0.392397\n",
      "[6752]\ttraining's binary_logloss: 0.392372\n",
      "[6753]\ttraining's binary_logloss: 0.392344\n",
      "[6754]\ttraining's binary_logloss: 0.392286\n",
      "[6755]\ttraining's binary_logloss: 0.392238\n",
      "[6756]\ttraining's binary_logloss: 0.392182\n",
      "[6757]\ttraining's binary_logloss: 0.392145\n",
      "[6758]\ttraining's binary_logloss: 0.392108\n",
      "[6759]\ttraining's binary_logloss: 0.392071\n",
      "[6760]\ttraining's binary_logloss: 0.39203\n",
      "[6761]\ttraining's binary_logloss: 0.391995\n",
      "[6762]\ttraining's binary_logloss: 0.39194\n",
      "[6763]\ttraining's binary_logloss: 0.391902\n",
      "[6764]\ttraining's binary_logloss: 0.391867\n",
      "[6765]\ttraining's binary_logloss: 0.39183\n",
      "[6766]\ttraining's binary_logloss: 0.391798\n",
      "[6767]\ttraining's binary_logloss: 0.391764\n",
      "[6768]\ttraining's binary_logloss: 0.391712\n",
      "[6769]\ttraining's binary_logloss: 0.391639\n",
      "[6770]\ttraining's binary_logloss: 0.391603\n",
      "[6771]\ttraining's binary_logloss: 0.391553\n",
      "[6772]\ttraining's binary_logloss: 0.391518\n",
      "[6773]\ttraining's binary_logloss: 0.391476\n",
      "[6774]\ttraining's binary_logloss: 0.391433\n",
      "[6775]\ttraining's binary_logloss: 0.391377\n",
      "[6776]\ttraining's binary_logloss: 0.39133\n",
      "[6777]\ttraining's binary_logloss: 0.391292\n",
      "[6778]\ttraining's binary_logloss: 0.391259\n",
      "[6779]\ttraining's binary_logloss: 0.391219\n",
      "[6780]\ttraining's binary_logloss: 0.391183\n",
      "[6781]\ttraining's binary_logloss: 0.391142\n",
      "[6782]\ttraining's binary_logloss: 0.3911\n",
      "[6783]\ttraining's binary_logloss: 0.391075\n",
      "[6784]\ttraining's binary_logloss: 0.391027\n",
      "[6785]\ttraining's binary_logloss: 0.390992\n",
      "[6786]\ttraining's binary_logloss: 0.390962\n",
      "[6787]\ttraining's binary_logloss: 0.390927\n",
      "[6788]\ttraining's binary_logloss: 0.390874\n",
      "[6789]\ttraining's binary_logloss: 0.390838\n",
      "[6790]\ttraining's binary_logloss: 0.390799\n",
      "[6791]\ttraining's binary_logloss: 0.390761\n",
      "[6792]\ttraining's binary_logloss: 0.390706\n",
      "[6793]\ttraining's binary_logloss: 0.390674\n",
      "[6794]\ttraining's binary_logloss: 0.390629\n",
      "[6795]\ttraining's binary_logloss: 0.390564\n",
      "[6796]\ttraining's binary_logloss: 0.390515\n",
      "[6797]\ttraining's binary_logloss: 0.390464\n",
      "[6798]\ttraining's binary_logloss: 0.390424\n",
      "[6799]\ttraining's binary_logloss: 0.390394\n",
      "[6800]\ttraining's binary_logloss: 0.390331\n",
      "[6801]\ttraining's binary_logloss: 0.390288\n",
      "[6802]\ttraining's binary_logloss: 0.390262\n",
      "[6803]\ttraining's binary_logloss: 0.390227\n",
      "[6804]\ttraining's binary_logloss: 0.390192\n",
      "[6805]\ttraining's binary_logloss: 0.390142\n",
      "[6806]\ttraining's binary_logloss: 0.390108\n",
      "[6807]\ttraining's binary_logloss: 0.390079\n",
      "[6808]\ttraining's binary_logloss: 0.390042\n",
      "[6809]\ttraining's binary_logloss: 0.389993\n",
      "[6810]\ttraining's binary_logloss: 0.389946\n",
      "[6811]\ttraining's binary_logloss: 0.389914\n",
      "[6812]\ttraining's binary_logloss: 0.389879\n",
      "[6813]\ttraining's binary_logloss: 0.389831\n",
      "[6814]\ttraining's binary_logloss: 0.389795\n",
      "[6815]\ttraining's binary_logloss: 0.389762\n",
      "[6816]\ttraining's binary_logloss: 0.389734\n",
      "[6817]\ttraining's binary_logloss: 0.389682\n",
      "[6818]\ttraining's binary_logloss: 0.389623\n",
      "[6819]\ttraining's binary_logloss: 0.389581\n",
      "[6820]\ttraining's binary_logloss: 0.389536\n",
      "[6821]\ttraining's binary_logloss: 0.389496\n",
      "[6822]\ttraining's binary_logloss: 0.389465\n",
      "[6823]\ttraining's binary_logloss: 0.389428\n",
      "[6824]\ttraining's binary_logloss: 0.389389\n",
      "[6825]\ttraining's binary_logloss: 0.389354\n",
      "[6826]\ttraining's binary_logloss: 0.389325\n",
      "[6827]\ttraining's binary_logloss: 0.389285\n",
      "[6828]\ttraining's binary_logloss: 0.389242\n",
      "[6829]\ttraining's binary_logloss: 0.389193\n",
      "[6830]\ttraining's binary_logloss: 0.389162\n",
      "[6831]\ttraining's binary_logloss: 0.389117\n",
      "[6832]\ttraining's binary_logloss: 0.389062\n",
      "[6833]\ttraining's binary_logloss: 0.389039\n",
      "[6834]\ttraining's binary_logloss: 0.389005\n",
      "[6835]\ttraining's binary_logloss: 0.388973\n",
      "[6836]\ttraining's binary_logloss: 0.388935\n",
      "[6837]\ttraining's binary_logloss: 0.388892\n",
      "[6838]\ttraining's binary_logloss: 0.388853\n",
      "[6839]\ttraining's binary_logloss: 0.388802\n",
      "[6840]\ttraining's binary_logloss: 0.388762\n",
      "[6841]\ttraining's binary_logloss: 0.388717\n",
      "[6842]\ttraining's binary_logloss: 0.388679\n",
      "[6843]\ttraining's binary_logloss: 0.388644\n",
      "[6844]\ttraining's binary_logloss: 0.388615\n",
      "[6845]\ttraining's binary_logloss: 0.388578\n",
      "[6846]\ttraining's binary_logloss: 0.388536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6847]\ttraining's binary_logloss: 0.388498\n",
      "[6848]\ttraining's binary_logloss: 0.388459\n",
      "[6849]\ttraining's binary_logloss: 0.388421\n",
      "[6850]\ttraining's binary_logloss: 0.388385\n",
      "[6851]\ttraining's binary_logloss: 0.388342\n",
      "[6852]\ttraining's binary_logloss: 0.38831\n",
      "[6853]\ttraining's binary_logloss: 0.388279\n",
      "[6854]\ttraining's binary_logloss: 0.388244\n",
      "[6855]\ttraining's binary_logloss: 0.388204\n",
      "[6856]\ttraining's binary_logloss: 0.38816\n",
      "[6857]\ttraining's binary_logloss: 0.388106\n",
      "[6858]\ttraining's binary_logloss: 0.38806\n",
      "[6859]\ttraining's binary_logloss: 0.388009\n",
      "[6860]\ttraining's binary_logloss: 0.387965\n",
      "[6861]\ttraining's binary_logloss: 0.387915\n",
      "[6862]\ttraining's binary_logloss: 0.38787\n",
      "[6863]\ttraining's binary_logloss: 0.387831\n",
      "[6864]\ttraining's binary_logloss: 0.387802\n",
      "[6865]\ttraining's binary_logloss: 0.38777\n",
      "[6866]\ttraining's binary_logloss: 0.387735\n",
      "[6867]\ttraining's binary_logloss: 0.387693\n",
      "[6868]\ttraining's binary_logloss: 0.387644\n",
      "[6869]\ttraining's binary_logloss: 0.387608\n",
      "[6870]\ttraining's binary_logloss: 0.387573\n",
      "[6871]\ttraining's binary_logloss: 0.387529\n",
      "[6872]\ttraining's binary_logloss: 0.387475\n",
      "[6873]\ttraining's binary_logloss: 0.387441\n",
      "[6874]\ttraining's binary_logloss: 0.387397\n",
      "[6875]\ttraining's binary_logloss: 0.387351\n",
      "[6876]\ttraining's binary_logloss: 0.387324\n",
      "[6877]\ttraining's binary_logloss: 0.387281\n",
      "[6878]\ttraining's binary_logloss: 0.38725\n",
      "[6879]\ttraining's binary_logloss: 0.38719\n",
      "[6880]\ttraining's binary_logloss: 0.387158\n",
      "[6881]\ttraining's binary_logloss: 0.387112\n",
      "[6882]\ttraining's binary_logloss: 0.387068\n",
      "[6883]\ttraining's binary_logloss: 0.387017\n",
      "[6884]\ttraining's binary_logloss: 0.386978\n",
      "[6885]\ttraining's binary_logloss: 0.386936\n",
      "[6886]\ttraining's binary_logloss: 0.386904\n",
      "[6887]\ttraining's binary_logloss: 0.386873\n",
      "[6888]\ttraining's binary_logloss: 0.386821\n",
      "[6889]\ttraining's binary_logloss: 0.386777\n",
      "[6890]\ttraining's binary_logloss: 0.386743\n",
      "[6891]\ttraining's binary_logloss: 0.386703\n",
      "[6892]\ttraining's binary_logloss: 0.386667\n",
      "[6893]\ttraining's binary_logloss: 0.386612\n",
      "[6894]\ttraining's binary_logloss: 0.38658\n",
      "[6895]\ttraining's binary_logloss: 0.386549\n",
      "[6896]\ttraining's binary_logloss: 0.38651\n",
      "[6897]\ttraining's binary_logloss: 0.386459\n",
      "[6898]\ttraining's binary_logloss: 0.386395\n",
      "[6899]\ttraining's binary_logloss: 0.386359\n",
      "[6900]\ttraining's binary_logloss: 0.386316\n",
      "[6901]\ttraining's binary_logloss: 0.386267\n",
      "[6902]\ttraining's binary_logloss: 0.38624\n",
      "[6903]\ttraining's binary_logloss: 0.38621\n",
      "[6904]\ttraining's binary_logloss: 0.386171\n",
      "[6905]\ttraining's binary_logloss: 0.386129\n",
      "[6906]\ttraining's binary_logloss: 0.386088\n",
      "[6907]\ttraining's binary_logloss: 0.386052\n",
      "[6908]\ttraining's binary_logloss: 0.386003\n",
      "[6909]\ttraining's binary_logloss: 0.385963\n",
      "[6910]\ttraining's binary_logloss: 0.385932\n",
      "[6911]\ttraining's binary_logloss: 0.385897\n",
      "[6912]\ttraining's binary_logloss: 0.385857\n",
      "[6913]\ttraining's binary_logloss: 0.38582\n",
      "[6914]\ttraining's binary_logloss: 0.385782\n",
      "[6915]\ttraining's binary_logloss: 0.385744\n",
      "[6916]\ttraining's binary_logloss: 0.385705\n",
      "[6917]\ttraining's binary_logloss: 0.385664\n",
      "[6918]\ttraining's binary_logloss: 0.385636\n",
      "[6919]\ttraining's binary_logloss: 0.385608\n",
      "[6920]\ttraining's binary_logloss: 0.385572\n",
      "[6921]\ttraining's binary_logloss: 0.385537\n",
      "[6922]\ttraining's binary_logloss: 0.385496\n",
      "[6923]\ttraining's binary_logloss: 0.385461\n",
      "[6924]\ttraining's binary_logloss: 0.38541\n",
      "[6925]\ttraining's binary_logloss: 0.385354\n",
      "[6926]\ttraining's binary_logloss: 0.3853\n",
      "[6927]\ttraining's binary_logloss: 0.385266\n",
      "[6928]\ttraining's binary_logloss: 0.385234\n",
      "[6929]\ttraining's binary_logloss: 0.385189\n",
      "[6930]\ttraining's binary_logloss: 0.385147\n",
      "[6931]\ttraining's binary_logloss: 0.385109\n",
      "[6932]\ttraining's binary_logloss: 0.38507\n",
      "[6933]\ttraining's binary_logloss: 0.38504\n",
      "[6934]\ttraining's binary_logloss: 0.385012\n",
      "[6935]\ttraining's binary_logloss: 0.384954\n",
      "[6936]\ttraining's binary_logloss: 0.384904\n",
      "[6937]\ttraining's binary_logloss: 0.384849\n",
      "[6938]\ttraining's binary_logloss: 0.384812\n",
      "[6939]\ttraining's binary_logloss: 0.384765\n",
      "[6940]\ttraining's binary_logloss: 0.384725\n",
      "[6941]\ttraining's binary_logloss: 0.384691\n",
      "[6942]\ttraining's binary_logloss: 0.384658\n",
      "[6943]\ttraining's binary_logloss: 0.384626\n",
      "[6944]\ttraining's binary_logloss: 0.384576\n",
      "[6945]\ttraining's binary_logloss: 0.384548\n",
      "[6946]\ttraining's binary_logloss: 0.384495\n",
      "[6947]\ttraining's binary_logloss: 0.384457\n",
      "[6948]\ttraining's binary_logloss: 0.384422\n",
      "[6949]\ttraining's binary_logloss: 0.384376\n",
      "[6950]\ttraining's binary_logloss: 0.384347\n",
      "[6951]\ttraining's binary_logloss: 0.38431\n",
      "[6952]\ttraining's binary_logloss: 0.384277\n",
      "[6953]\ttraining's binary_logloss: 0.384244\n",
      "[6954]\ttraining's binary_logloss: 0.384196\n",
      "[6955]\ttraining's binary_logloss: 0.384152\n",
      "[6956]\ttraining's binary_logloss: 0.384102\n",
      "[6957]\ttraining's binary_logloss: 0.384063\n",
      "[6958]\ttraining's binary_logloss: 0.384015\n",
      "[6959]\ttraining's binary_logloss: 0.383968\n",
      "[6960]\ttraining's binary_logloss: 0.383917\n",
      "[6961]\ttraining's binary_logloss: 0.383888\n",
      "[6962]\ttraining's binary_logloss: 0.383856\n",
      "[6963]\ttraining's binary_logloss: 0.383816\n",
      "[6964]\ttraining's binary_logloss: 0.383778\n",
      "[6965]\ttraining's binary_logloss: 0.383713\n",
      "[6966]\ttraining's binary_logloss: 0.383677\n",
      "[6967]\ttraining's binary_logloss: 0.383634\n",
      "[6968]\ttraining's binary_logloss: 0.3836\n",
      "[6969]\ttraining's binary_logloss: 0.383539\n",
      "[6970]\ttraining's binary_logloss: 0.383494\n",
      "[6971]\ttraining's binary_logloss: 0.383457\n",
      "[6972]\ttraining's binary_logloss: 0.383428\n",
      "[6973]\ttraining's binary_logloss: 0.383383\n",
      "[6974]\ttraining's binary_logloss: 0.383326\n",
      "[6975]\ttraining's binary_logloss: 0.383296\n",
      "[6976]\ttraining's binary_logloss: 0.383262\n",
      "[6977]\ttraining's binary_logloss: 0.383219\n",
      "[6978]\ttraining's binary_logloss: 0.38318\n",
      "[6979]\ttraining's binary_logloss: 0.383169\n",
      "[6980]\ttraining's binary_logloss: 0.383106\n",
      "[6981]\ttraining's binary_logloss: 0.383045\n",
      "[6982]\ttraining's binary_logloss: 0.383005\n",
      "[6983]\ttraining's binary_logloss: 0.382967\n",
      "[6984]\ttraining's binary_logloss: 0.382925\n",
      "[6985]\ttraining's binary_logloss: 0.382876\n",
      "[6986]\ttraining's binary_logloss: 0.382848\n",
      "[6987]\ttraining's binary_logloss: 0.382811\n",
      "[6988]\ttraining's binary_logloss: 0.38277\n",
      "[6989]\ttraining's binary_logloss: 0.382726\n",
      "[6990]\ttraining's binary_logloss: 0.382697\n",
      "[6991]\ttraining's binary_logloss: 0.38266\n",
      "[6992]\ttraining's binary_logloss: 0.382609\n",
      "[6993]\ttraining's binary_logloss: 0.382569\n",
      "[6994]\ttraining's binary_logloss: 0.382536\n",
      "[6995]\ttraining's binary_logloss: 0.382499\n",
      "[6996]\ttraining's binary_logloss: 0.382463\n",
      "[6997]\ttraining's binary_logloss: 0.382426\n",
      "[6998]\ttraining's binary_logloss: 0.382392\n",
      "[6999]\ttraining's binary_logloss: 0.382359\n",
      "[7000]\ttraining's binary_logloss: 0.382327\n",
      "[7001]\ttraining's binary_logloss: 0.382285\n",
      "[7002]\ttraining's binary_logloss: 0.382263\n",
      "[7003]\ttraining's binary_logloss: 0.38222\n",
      "[7004]\ttraining's binary_logloss: 0.382193\n",
      "[7005]\ttraining's binary_logloss: 0.382162\n",
      "[7006]\ttraining's binary_logloss: 0.382136\n",
      "[7007]\ttraining's binary_logloss: 0.382086\n",
      "[7008]\ttraining's binary_logloss: 0.382043\n",
      "[7009]\ttraining's binary_logloss: 0.382011\n",
      "[7010]\ttraining's binary_logloss: 0.381978\n",
      "[7011]\ttraining's binary_logloss: 0.381932\n",
      "[7012]\ttraining's binary_logloss: 0.381901\n",
      "[7013]\ttraining's binary_logloss: 0.381869\n",
      "[7014]\ttraining's binary_logloss: 0.381841\n",
      "[7015]\ttraining's binary_logloss: 0.381801\n",
      "[7016]\ttraining's binary_logloss: 0.381743\n",
      "[7017]\ttraining's binary_logloss: 0.381693\n",
      "[7018]\ttraining's binary_logloss: 0.38165\n",
      "[7019]\ttraining's binary_logloss: 0.381619\n",
      "[7020]\ttraining's binary_logloss: 0.381568\n",
      "[7021]\ttraining's binary_logloss: 0.38154\n",
      "[7022]\ttraining's binary_logloss: 0.381495\n",
      "[7023]\ttraining's binary_logloss: 0.381465\n",
      "[7024]\ttraining's binary_logloss: 0.381417\n",
      "[7025]\ttraining's binary_logloss: 0.381392\n",
      "[7026]\ttraining's binary_logloss: 0.381356\n",
      "[7027]\ttraining's binary_logloss: 0.381308\n",
      "[7028]\ttraining's binary_logloss: 0.381269\n",
      "[7029]\ttraining's binary_logloss: 0.381228\n",
      "[7030]\ttraining's binary_logloss: 0.381182\n",
      "[7031]\ttraining's binary_logloss: 0.381128\n",
      "[7032]\ttraining's binary_logloss: 0.381086\n",
      "[7033]\ttraining's binary_logloss: 0.381054\n",
      "[7034]\ttraining's binary_logloss: 0.381013\n",
      "[7035]\ttraining's binary_logloss: 0.380967\n",
      "[7036]\ttraining's binary_logloss: 0.380935\n",
      "[7037]\ttraining's binary_logloss: 0.380892\n",
      "[7038]\ttraining's binary_logloss: 0.380839\n",
      "[7039]\ttraining's binary_logloss: 0.380804\n",
      "[7040]\ttraining's binary_logloss: 0.380757\n",
      "[7041]\ttraining's binary_logloss: 0.380717\n",
      "[7042]\ttraining's binary_logloss: 0.380677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7043]\ttraining's binary_logloss: 0.380637\n",
      "[7044]\ttraining's binary_logloss: 0.380609\n",
      "[7045]\ttraining's binary_logloss: 0.380576\n",
      "[7046]\ttraining's binary_logloss: 0.380538\n",
      "[7047]\ttraining's binary_logloss: 0.380487\n",
      "[7048]\ttraining's binary_logloss: 0.380437\n",
      "[7049]\ttraining's binary_logloss: 0.380406\n",
      "[7050]\ttraining's binary_logloss: 0.380365\n",
      "[7051]\ttraining's binary_logloss: 0.380337\n",
      "[7052]\ttraining's binary_logloss: 0.380289\n",
      "[7053]\ttraining's binary_logloss: 0.380244\n",
      "[7054]\ttraining's binary_logloss: 0.380202\n",
      "[7055]\ttraining's binary_logloss: 0.380172\n",
      "[7056]\ttraining's binary_logloss: 0.380127\n",
      "[7057]\ttraining's binary_logloss: 0.380069\n",
      "[7058]\ttraining's binary_logloss: 0.380027\n",
      "[7059]\ttraining's binary_logloss: 0.379973\n",
      "[7060]\ttraining's binary_logloss: 0.379931\n",
      "[7061]\ttraining's binary_logloss: 0.379897\n",
      "[7062]\ttraining's binary_logloss: 0.379826\n",
      "[7063]\ttraining's binary_logloss: 0.379789\n",
      "[7064]\ttraining's binary_logloss: 0.37975\n",
      "[7065]\ttraining's binary_logloss: 0.379687\n",
      "[7066]\ttraining's binary_logloss: 0.379655\n",
      "[7067]\ttraining's binary_logloss: 0.379623\n",
      "[7068]\ttraining's binary_logloss: 0.379588\n",
      "[7069]\ttraining's binary_logloss: 0.379557\n",
      "[7070]\ttraining's binary_logloss: 0.379517\n",
      "[7071]\ttraining's binary_logloss: 0.379485\n",
      "[7072]\ttraining's binary_logloss: 0.379434\n",
      "[7073]\ttraining's binary_logloss: 0.379407\n",
      "[7074]\ttraining's binary_logloss: 0.379375\n",
      "[7075]\ttraining's binary_logloss: 0.379345\n",
      "[7076]\ttraining's binary_logloss: 0.37931\n",
      "[7077]\ttraining's binary_logloss: 0.379262\n",
      "[7078]\ttraining's binary_logloss: 0.379202\n",
      "[7079]\ttraining's binary_logloss: 0.379174\n",
      "[7080]\ttraining's binary_logloss: 0.379106\n",
      "[7081]\ttraining's binary_logloss: 0.379076\n",
      "[7082]\ttraining's binary_logloss: 0.379028\n",
      "[7083]\ttraining's binary_logloss: 0.378985\n",
      "[7084]\ttraining's binary_logloss: 0.378943\n",
      "[7085]\ttraining's binary_logloss: 0.378914\n",
      "[7086]\ttraining's binary_logloss: 0.378878\n",
      "[7087]\ttraining's binary_logloss: 0.378854\n",
      "[7088]\ttraining's binary_logloss: 0.378807\n",
      "[7089]\ttraining's binary_logloss: 0.378733\n",
      "[7090]\ttraining's binary_logloss: 0.378684\n",
      "[7091]\ttraining's binary_logloss: 0.378659\n",
      "[7092]\ttraining's binary_logloss: 0.378632\n",
      "[7093]\ttraining's binary_logloss: 0.378593\n",
      "[7094]\ttraining's binary_logloss: 0.378572\n",
      "[7095]\ttraining's binary_logloss: 0.378513\n",
      "[7096]\ttraining's binary_logloss: 0.378479\n",
      "[7097]\ttraining's binary_logloss: 0.378434\n",
      "[7098]\ttraining's binary_logloss: 0.378408\n",
      "[7099]\ttraining's binary_logloss: 0.378365\n",
      "[7100]\ttraining's binary_logloss: 0.378323\n",
      "[7101]\ttraining's binary_logloss: 0.378288\n",
      "[7102]\ttraining's binary_logloss: 0.378261\n",
      "[7103]\ttraining's binary_logloss: 0.378212\n",
      "[7104]\ttraining's binary_logloss: 0.378185\n",
      "[7105]\ttraining's binary_logloss: 0.378148\n",
      "[7106]\ttraining's binary_logloss: 0.378116\n",
      "[7107]\ttraining's binary_logloss: 0.378077\n",
      "[7108]\ttraining's binary_logloss: 0.37804\n",
      "[7109]\ttraining's binary_logloss: 0.377998\n",
      "[7110]\ttraining's binary_logloss: 0.377972\n",
      "[7111]\ttraining's binary_logloss: 0.377937\n",
      "[7112]\ttraining's binary_logloss: 0.377887\n",
      "[7113]\ttraining's binary_logloss: 0.377858\n",
      "[7114]\ttraining's binary_logloss: 0.37783\n",
      "[7115]\ttraining's binary_logloss: 0.377787\n",
      "[7116]\ttraining's binary_logloss: 0.377753\n",
      "[7117]\ttraining's binary_logloss: 0.377704\n",
      "[7118]\ttraining's binary_logloss: 0.377666\n",
      "[7119]\ttraining's binary_logloss: 0.377632\n",
      "[7120]\ttraining's binary_logloss: 0.377602\n",
      "[7121]\ttraining's binary_logloss: 0.377578\n",
      "[7122]\ttraining's binary_logloss: 0.377544\n",
      "[7123]\ttraining's binary_logloss: 0.377505\n",
      "[7124]\ttraining's binary_logloss: 0.377477\n",
      "[7125]\ttraining's binary_logloss: 0.37743\n",
      "[7126]\ttraining's binary_logloss: 0.377396\n",
      "[7127]\ttraining's binary_logloss: 0.377348\n",
      "[7128]\ttraining's binary_logloss: 0.377303\n",
      "[7129]\ttraining's binary_logloss: 0.37727\n",
      "[7130]\ttraining's binary_logloss: 0.377229\n",
      "[7131]\ttraining's binary_logloss: 0.377186\n",
      "[7132]\ttraining's binary_logloss: 0.377138\n",
      "[7133]\ttraining's binary_logloss: 0.377107\n",
      "[7134]\ttraining's binary_logloss: 0.377067\n",
      "[7135]\ttraining's binary_logloss: 0.377026\n",
      "[7136]\ttraining's binary_logloss: 0.376995\n",
      "[7137]\ttraining's binary_logloss: 0.376965\n",
      "[7138]\ttraining's binary_logloss: 0.376904\n",
      "[7139]\ttraining's binary_logloss: 0.376887\n",
      "[7140]\ttraining's binary_logloss: 0.376852\n",
      "[7141]\ttraining's binary_logloss: 0.376816\n",
      "[7142]\ttraining's binary_logloss: 0.376787\n",
      "[7143]\ttraining's binary_logloss: 0.376748\n",
      "[7144]\ttraining's binary_logloss: 0.376703\n",
      "[7145]\ttraining's binary_logloss: 0.376674\n",
      "[7146]\ttraining's binary_logloss: 0.376645\n",
      "[7147]\ttraining's binary_logloss: 0.376609\n",
      "[7148]\ttraining's binary_logloss: 0.376561\n",
      "[7149]\ttraining's binary_logloss: 0.376533\n",
      "[7150]\ttraining's binary_logloss: 0.376477\n",
      "[7151]\ttraining's binary_logloss: 0.376435\n",
      "[7152]\ttraining's binary_logloss: 0.376395\n",
      "[7153]\ttraining's binary_logloss: 0.376361\n",
      "[7154]\ttraining's binary_logloss: 0.376321\n",
      "[7155]\ttraining's binary_logloss: 0.376269\n",
      "[7156]\ttraining's binary_logloss: 0.37623\n",
      "[7157]\ttraining's binary_logloss: 0.376191\n",
      "[7158]\ttraining's binary_logloss: 0.376152\n",
      "[7159]\ttraining's binary_logloss: 0.37612\n",
      "[7160]\ttraining's binary_logloss: 0.376071\n",
      "[7161]\ttraining's binary_logloss: 0.376013\n",
      "[7162]\ttraining's binary_logloss: 0.375977\n",
      "[7163]\ttraining's binary_logloss: 0.375938\n",
      "[7164]\ttraining's binary_logloss: 0.375892\n",
      "[7165]\ttraining's binary_logloss: 0.375862\n",
      "[7166]\ttraining's binary_logloss: 0.375822\n",
      "[7167]\ttraining's binary_logloss: 0.37579\n",
      "[7168]\ttraining's binary_logloss: 0.375757\n",
      "[7169]\ttraining's binary_logloss: 0.375707\n",
      "[7170]\ttraining's binary_logloss: 0.375678\n",
      "[7171]\ttraining's binary_logloss: 0.375645\n",
      "[7172]\ttraining's binary_logloss: 0.3756\n",
      "[7173]\ttraining's binary_logloss: 0.375553\n",
      "[7174]\ttraining's binary_logloss: 0.375514\n",
      "[7175]\ttraining's binary_logloss: 0.375485\n",
      "[7176]\ttraining's binary_logloss: 0.375441\n",
      "[7177]\ttraining's binary_logloss: 0.375405\n",
      "[7178]\ttraining's binary_logloss: 0.375354\n",
      "[7179]\ttraining's binary_logloss: 0.375299\n",
      "[7180]\ttraining's binary_logloss: 0.37526\n",
      "[7181]\ttraining's binary_logloss: 0.375219\n",
      "[7182]\ttraining's binary_logloss: 0.375175\n",
      "[7183]\ttraining's binary_logloss: 0.375124\n",
      "[7184]\ttraining's binary_logloss: 0.375076\n",
      "[7185]\ttraining's binary_logloss: 0.37503\n",
      "[7186]\ttraining's binary_logloss: 0.374985\n",
      "[7187]\ttraining's binary_logloss: 0.374933\n",
      "[7188]\ttraining's binary_logloss: 0.374879\n",
      "[7189]\ttraining's binary_logloss: 0.374832\n",
      "[7190]\ttraining's binary_logloss: 0.374806\n",
      "[7191]\ttraining's binary_logloss: 0.374765\n",
      "[7192]\ttraining's binary_logloss: 0.374738\n",
      "[7193]\ttraining's binary_logloss: 0.374699\n",
      "[7194]\ttraining's binary_logloss: 0.374672\n",
      "[7195]\ttraining's binary_logloss: 0.374644\n",
      "[7196]\ttraining's binary_logloss: 0.374599\n",
      "[7197]\ttraining's binary_logloss: 0.374568\n",
      "[7198]\ttraining's binary_logloss: 0.374545\n",
      "[7199]\ttraining's binary_logloss: 0.374511\n",
      "[7200]\ttraining's binary_logloss: 0.374471\n",
      "[7201]\ttraining's binary_logloss: 0.374436\n",
      "[7202]\ttraining's binary_logloss: 0.374402\n",
      "[7203]\ttraining's binary_logloss: 0.374349\n",
      "[7204]\ttraining's binary_logloss: 0.374328\n",
      "[7205]\ttraining's binary_logloss: 0.374292\n",
      "[7206]\ttraining's binary_logloss: 0.374217\n",
      "[7207]\ttraining's binary_logloss: 0.374179\n",
      "[7208]\ttraining's binary_logloss: 0.374153\n",
      "[7209]\ttraining's binary_logloss: 0.374115\n",
      "[7210]\ttraining's binary_logloss: 0.374082\n",
      "[7211]\ttraining's binary_logloss: 0.374025\n",
      "[7212]\ttraining's binary_logloss: 0.37398\n",
      "[7213]\ttraining's binary_logloss: 0.373949\n",
      "[7214]\ttraining's binary_logloss: 0.373906\n",
      "[7215]\ttraining's binary_logloss: 0.373878\n",
      "[7216]\ttraining's binary_logloss: 0.373828\n",
      "[7217]\ttraining's binary_logloss: 0.373801\n",
      "[7218]\ttraining's binary_logloss: 0.373774\n",
      "[7219]\ttraining's binary_logloss: 0.373749\n",
      "[7220]\ttraining's binary_logloss: 0.373725\n",
      "[7221]\ttraining's binary_logloss: 0.373652\n",
      "[7222]\ttraining's binary_logloss: 0.373609\n",
      "[7223]\ttraining's binary_logloss: 0.373571\n",
      "[7224]\ttraining's binary_logloss: 0.373543\n",
      "[7225]\ttraining's binary_logloss: 0.373491\n",
      "[7226]\ttraining's binary_logloss: 0.373461\n",
      "[7227]\ttraining's binary_logloss: 0.373434\n",
      "[7228]\ttraining's binary_logloss: 0.373399\n",
      "[7229]\ttraining's binary_logloss: 0.373366\n",
      "[7230]\ttraining's binary_logloss: 0.373326\n",
      "[7231]\ttraining's binary_logloss: 0.373291\n",
      "[7232]\ttraining's binary_logloss: 0.373257\n",
      "[7233]\ttraining's binary_logloss: 0.373226\n",
      "[7234]\ttraining's binary_logloss: 0.373199\n",
      "[7235]\ttraining's binary_logloss: 0.37317\n",
      "[7236]\ttraining's binary_logloss: 0.373138\n",
      "[7237]\ttraining's binary_logloss: 0.373093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7238]\ttraining's binary_logloss: 0.373049\n",
      "[7239]\ttraining's binary_logloss: 0.373012\n",
      "[7240]\ttraining's binary_logloss: 0.372981\n",
      "[7241]\ttraining's binary_logloss: 0.372931\n",
      "[7242]\ttraining's binary_logloss: 0.372894\n",
      "[7243]\ttraining's binary_logloss: 0.372848\n",
      "[7244]\ttraining's binary_logloss: 0.372801\n",
      "[7245]\ttraining's binary_logloss: 0.372751\n",
      "[7246]\ttraining's binary_logloss: 0.372709\n",
      "[7247]\ttraining's binary_logloss: 0.372668\n",
      "[7248]\ttraining's binary_logloss: 0.372635\n",
      "[7249]\ttraining's binary_logloss: 0.372601\n",
      "[7250]\ttraining's binary_logloss: 0.372577\n",
      "[7251]\ttraining's binary_logloss: 0.372545\n",
      "[7252]\ttraining's binary_logloss: 0.372514\n",
      "[7253]\ttraining's binary_logloss: 0.372483\n",
      "[7254]\ttraining's binary_logloss: 0.372442\n",
      "[7255]\ttraining's binary_logloss: 0.372415\n",
      "[7256]\ttraining's binary_logloss: 0.372371\n",
      "[7257]\ttraining's binary_logloss: 0.372336\n",
      "[7258]\ttraining's binary_logloss: 0.372288\n",
      "[7259]\ttraining's binary_logloss: 0.372247\n",
      "[7260]\ttraining's binary_logloss: 0.372208\n",
      "[7261]\ttraining's binary_logloss: 0.372165\n",
      "[7262]\ttraining's binary_logloss: 0.372136\n",
      "[7263]\ttraining's binary_logloss: 0.372102\n",
      "[7264]\ttraining's binary_logloss: 0.372068\n",
      "[7265]\ttraining's binary_logloss: 0.371999\n",
      "[7266]\ttraining's binary_logloss: 0.37194\n",
      "[7267]\ttraining's binary_logloss: 0.371892\n",
      "[7268]\ttraining's binary_logloss: 0.371852\n",
      "[7269]\ttraining's binary_logloss: 0.371826\n",
      "[7270]\ttraining's binary_logloss: 0.371768\n",
      "[7271]\ttraining's binary_logloss: 0.371741\n",
      "[7272]\ttraining's binary_logloss: 0.371689\n",
      "[7273]\ttraining's binary_logloss: 0.37166\n",
      "[7274]\ttraining's binary_logloss: 0.37162\n",
      "[7275]\ttraining's binary_logloss: 0.371563\n",
      "[7276]\ttraining's binary_logloss: 0.371532\n",
      "[7277]\ttraining's binary_logloss: 0.371505\n",
      "[7278]\ttraining's binary_logloss: 0.371459\n",
      "[7279]\ttraining's binary_logloss: 0.371418\n",
      "[7280]\ttraining's binary_logloss: 0.371381\n",
      "[7281]\ttraining's binary_logloss: 0.371322\n",
      "[7282]\ttraining's binary_logloss: 0.371274\n",
      "[7283]\ttraining's binary_logloss: 0.371244\n",
      "[7284]\ttraining's binary_logloss: 0.371205\n",
      "[7285]\ttraining's binary_logloss: 0.371175\n",
      "[7286]\ttraining's binary_logloss: 0.371152\n",
      "[7287]\ttraining's binary_logloss: 0.37112\n",
      "[7288]\ttraining's binary_logloss: 0.371072\n",
      "[7289]\ttraining's binary_logloss: 0.371025\n",
      "[7290]\ttraining's binary_logloss: 0.370998\n",
      "[7291]\ttraining's binary_logloss: 0.370956\n",
      "[7292]\ttraining's binary_logloss: 0.37092\n",
      "[7293]\ttraining's binary_logloss: 0.370895\n",
      "[7294]\ttraining's binary_logloss: 0.370861\n",
      "[7295]\ttraining's binary_logloss: 0.370831\n",
      "[7296]\ttraining's binary_logloss: 0.370798\n",
      "[7297]\ttraining's binary_logloss: 0.370746\n",
      "[7298]\ttraining's binary_logloss: 0.370703\n",
      "[7299]\ttraining's binary_logloss: 0.370677\n",
      "[7300]\ttraining's binary_logloss: 0.370637\n",
      "[7301]\ttraining's binary_logloss: 0.370594\n",
      "[7302]\ttraining's binary_logloss: 0.370534\n",
      "[7303]\ttraining's binary_logloss: 0.370496\n",
      "[7304]\ttraining's binary_logloss: 0.370467\n",
      "[7305]\ttraining's binary_logloss: 0.370431\n",
      "[7306]\ttraining's binary_logloss: 0.370391\n",
      "[7307]\ttraining's binary_logloss: 0.370349\n",
      "[7308]\ttraining's binary_logloss: 0.370304\n",
      "[7309]\ttraining's binary_logloss: 0.370261\n",
      "[7310]\ttraining's binary_logloss: 0.370235\n",
      "[7311]\ttraining's binary_logloss: 0.3702\n",
      "[7312]\ttraining's binary_logloss: 0.370158\n",
      "[7313]\ttraining's binary_logloss: 0.370122\n",
      "[7314]\ttraining's binary_logloss: 0.370072\n",
      "[7315]\ttraining's binary_logloss: 0.370026\n",
      "[7316]\ttraining's binary_logloss: 0.369998\n",
      "[7317]\ttraining's binary_logloss: 0.369958\n",
      "[7318]\ttraining's binary_logloss: 0.369927\n",
      "[7319]\ttraining's binary_logloss: 0.36989\n",
      "[7320]\ttraining's binary_logloss: 0.369854\n",
      "[7321]\ttraining's binary_logloss: 0.36981\n",
      "[7322]\ttraining's binary_logloss: 0.369765\n",
      "[7323]\ttraining's binary_logloss: 0.36973\n",
      "[7324]\ttraining's binary_logloss: 0.369702\n",
      "[7325]\ttraining's binary_logloss: 0.369673\n",
      "[7326]\ttraining's binary_logloss: 0.369633\n",
      "[7327]\ttraining's binary_logloss: 0.369604\n",
      "[7328]\ttraining's binary_logloss: 0.369557\n",
      "[7329]\ttraining's binary_logloss: 0.369514\n",
      "[7330]\ttraining's binary_logloss: 0.369482\n",
      "[7331]\ttraining's binary_logloss: 0.369451\n",
      "[7332]\ttraining's binary_logloss: 0.369413\n",
      "[7333]\ttraining's binary_logloss: 0.369356\n",
      "[7334]\ttraining's binary_logloss: 0.369301\n",
      "[7335]\ttraining's binary_logloss: 0.369256\n",
      "[7336]\ttraining's binary_logloss: 0.369222\n",
      "[7337]\ttraining's binary_logloss: 0.36919\n",
      "[7338]\ttraining's binary_logloss: 0.369153\n",
      "[7339]\ttraining's binary_logloss: 0.369126\n",
      "[7340]\ttraining's binary_logloss: 0.369097\n",
      "[7341]\ttraining's binary_logloss: 0.369057\n",
      "[7342]\ttraining's binary_logloss: 0.369033\n",
      "[7343]\ttraining's binary_logloss: 0.368992\n",
      "[7344]\ttraining's binary_logloss: 0.368965\n",
      "[7345]\ttraining's binary_logloss: 0.368937\n",
      "[7346]\ttraining's binary_logloss: 0.368897\n",
      "[7347]\ttraining's binary_logloss: 0.368872\n",
      "[7348]\ttraining's binary_logloss: 0.368824\n",
      "[7349]\ttraining's binary_logloss: 0.368794\n",
      "[7350]\ttraining's binary_logloss: 0.368754\n",
      "[7351]\ttraining's binary_logloss: 0.368722\n",
      "[7352]\ttraining's binary_logloss: 0.368682\n",
      "[7353]\ttraining's binary_logloss: 0.368657\n",
      "[7354]\ttraining's binary_logloss: 0.368627\n",
      "[7355]\ttraining's binary_logloss: 0.36859\n",
      "[7356]\ttraining's binary_logloss: 0.368541\n",
      "[7357]\ttraining's binary_logloss: 0.368512\n",
      "[7358]\ttraining's binary_logloss: 0.368485\n",
      "[7359]\ttraining's binary_logloss: 0.368446\n",
      "[7360]\ttraining's binary_logloss: 0.368407\n",
      "[7361]\ttraining's binary_logloss: 0.368359\n",
      "[7362]\ttraining's binary_logloss: 0.368331\n",
      "[7363]\ttraining's binary_logloss: 0.368292\n",
      "[7364]\ttraining's binary_logloss: 0.368261\n",
      "[7365]\ttraining's binary_logloss: 0.368223\n",
      "[7366]\ttraining's binary_logloss: 0.368189\n",
      "[7367]\ttraining's binary_logloss: 0.368142\n",
      "[7368]\ttraining's binary_logloss: 0.368105\n",
      "[7369]\ttraining's binary_logloss: 0.368049\n",
      "[7370]\ttraining's binary_logloss: 0.368015\n",
      "[7371]\ttraining's binary_logloss: 0.367984\n",
      "[7372]\ttraining's binary_logloss: 0.367943\n",
      "[7373]\ttraining's binary_logloss: 0.367895\n",
      "[7374]\ttraining's binary_logloss: 0.367863\n",
      "[7375]\ttraining's binary_logloss: 0.367833\n",
      "[7376]\ttraining's binary_logloss: 0.367791\n",
      "[7377]\ttraining's binary_logloss: 0.367748\n",
      "[7378]\ttraining's binary_logloss: 0.367718\n",
      "[7379]\ttraining's binary_logloss: 0.367687\n",
      "[7380]\ttraining's binary_logloss: 0.367626\n",
      "[7381]\ttraining's binary_logloss: 0.367588\n",
      "[7382]\ttraining's binary_logloss: 0.367539\n",
      "[7383]\ttraining's binary_logloss: 0.367497\n",
      "[7384]\ttraining's binary_logloss: 0.367462\n",
      "[7385]\ttraining's binary_logloss: 0.367413\n",
      "[7386]\ttraining's binary_logloss: 0.367384\n",
      "[7387]\ttraining's binary_logloss: 0.367353\n",
      "[7388]\ttraining's binary_logloss: 0.367305\n",
      "[7389]\ttraining's binary_logloss: 0.367273\n",
      "[7390]\ttraining's binary_logloss: 0.367228\n",
      "[7391]\ttraining's binary_logloss: 0.367191\n",
      "[7392]\ttraining's binary_logloss: 0.367147\n",
      "[7393]\ttraining's binary_logloss: 0.367116\n",
      "[7394]\ttraining's binary_logloss: 0.367084\n",
      "[7395]\ttraining's binary_logloss: 0.367054\n",
      "[7396]\ttraining's binary_logloss: 0.367018\n",
      "[7397]\ttraining's binary_logloss: 0.366975\n",
      "[7398]\ttraining's binary_logloss: 0.366944\n",
      "[7399]\ttraining's binary_logloss: 0.366931\n",
      "[7400]\ttraining's binary_logloss: 0.366897\n",
      "[7401]\ttraining's binary_logloss: 0.366857\n",
      "[7402]\ttraining's binary_logloss: 0.366813\n",
      "[7403]\ttraining's binary_logloss: 0.366771\n",
      "[7404]\ttraining's binary_logloss: 0.366733\n",
      "[7405]\ttraining's binary_logloss: 0.36669\n",
      "[7406]\ttraining's binary_logloss: 0.366665\n",
      "[7407]\ttraining's binary_logloss: 0.366641\n",
      "[7408]\ttraining's binary_logloss: 0.366605\n",
      "[7409]\ttraining's binary_logloss: 0.36657\n",
      "[7410]\ttraining's binary_logloss: 0.366542\n",
      "[7411]\ttraining's binary_logloss: 0.366511\n",
      "[7412]\ttraining's binary_logloss: 0.366473\n",
      "[7413]\ttraining's binary_logloss: 0.366427\n",
      "[7414]\ttraining's binary_logloss: 0.366396\n",
      "[7415]\ttraining's binary_logloss: 0.366363\n",
      "[7416]\ttraining's binary_logloss: 0.366327\n",
      "[7417]\ttraining's binary_logloss: 0.366286\n",
      "[7418]\ttraining's binary_logloss: 0.366254\n",
      "[7419]\ttraining's binary_logloss: 0.366226\n",
      "[7420]\ttraining's binary_logloss: 0.366199\n",
      "[7421]\ttraining's binary_logloss: 0.366166\n",
      "[7422]\ttraining's binary_logloss: 0.366109\n",
      "[7423]\ttraining's binary_logloss: 0.366073\n",
      "[7424]\ttraining's binary_logloss: 0.366039\n",
      "[7425]\ttraining's binary_logloss: 0.366005\n",
      "[7426]\ttraining's binary_logloss: 0.365976\n",
      "[7427]\ttraining's binary_logloss: 0.365939\n",
      "[7428]\ttraining's binary_logloss: 0.365892\n",
      "[7429]\ttraining's binary_logloss: 0.36586\n",
      "[7430]\ttraining's binary_logloss: 0.365801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7431]\ttraining's binary_logloss: 0.365768\n",
      "[7432]\ttraining's binary_logloss: 0.365739\n",
      "[7433]\ttraining's binary_logloss: 0.365707\n",
      "[7434]\ttraining's binary_logloss: 0.365674\n",
      "[7435]\ttraining's binary_logloss: 0.365651\n",
      "[7436]\ttraining's binary_logloss: 0.365606\n",
      "[7437]\ttraining's binary_logloss: 0.365561\n",
      "[7438]\ttraining's binary_logloss: 0.365527\n",
      "[7439]\ttraining's binary_logloss: 0.365499\n",
      "[7440]\ttraining's binary_logloss: 0.365455\n",
      "[7441]\ttraining's binary_logloss: 0.365427\n",
      "[7442]\ttraining's binary_logloss: 0.365382\n",
      "[7443]\ttraining's binary_logloss: 0.365341\n",
      "[7444]\ttraining's binary_logloss: 0.365318\n",
      "[7445]\ttraining's binary_logloss: 0.365274\n",
      "[7446]\ttraining's binary_logloss: 0.365215\n",
      "[7447]\ttraining's binary_logloss: 0.365181\n",
      "[7448]\ttraining's binary_logloss: 0.365141\n",
      "[7449]\ttraining's binary_logloss: 0.36511\n",
      "[7450]\ttraining's binary_logloss: 0.365078\n",
      "[7451]\ttraining's binary_logloss: 0.365044\n",
      "[7452]\ttraining's binary_logloss: 0.365005\n",
      "[7453]\ttraining's binary_logloss: 0.36496\n",
      "[7454]\ttraining's binary_logloss: 0.364925\n",
      "[7455]\ttraining's binary_logloss: 0.364894\n",
      "[7456]\ttraining's binary_logloss: 0.36485\n",
      "[7457]\ttraining's binary_logloss: 0.364809\n",
      "[7458]\ttraining's binary_logloss: 0.36477\n",
      "[7459]\ttraining's binary_logloss: 0.364739\n",
      "[7460]\ttraining's binary_logloss: 0.364703\n",
      "[7461]\ttraining's binary_logloss: 0.364673\n",
      "[7462]\ttraining's binary_logloss: 0.36464\n",
      "[7463]\ttraining's binary_logloss: 0.364607\n",
      "[7464]\ttraining's binary_logloss: 0.36457\n",
      "[7465]\ttraining's binary_logloss: 0.364533\n",
      "[7466]\ttraining's binary_logloss: 0.364481\n",
      "[7467]\ttraining's binary_logloss: 0.364453\n",
      "[7468]\ttraining's binary_logloss: 0.364415\n",
      "[7469]\ttraining's binary_logloss: 0.364379\n",
      "[7470]\ttraining's binary_logloss: 0.364336\n",
      "[7471]\ttraining's binary_logloss: 0.364283\n",
      "[7472]\ttraining's binary_logloss: 0.364251\n",
      "[7473]\ttraining's binary_logloss: 0.364227\n",
      "[7474]\ttraining's binary_logloss: 0.364194\n",
      "[7475]\ttraining's binary_logloss: 0.364165\n",
      "[7476]\ttraining's binary_logloss: 0.364122\n",
      "[7477]\ttraining's binary_logloss: 0.364083\n",
      "[7478]\ttraining's binary_logloss: 0.364052\n",
      "[7479]\ttraining's binary_logloss: 0.364009\n",
      "[7480]\ttraining's binary_logloss: 0.363963\n",
      "[7481]\ttraining's binary_logloss: 0.363931\n",
      "[7482]\ttraining's binary_logloss: 0.363883\n",
      "[7483]\ttraining's binary_logloss: 0.363836\n",
      "[7484]\ttraining's binary_logloss: 0.363796\n",
      "[7485]\ttraining's binary_logloss: 0.363765\n",
      "[7486]\ttraining's binary_logloss: 0.363734\n",
      "[7487]\ttraining's binary_logloss: 0.363686\n",
      "[7488]\ttraining's binary_logloss: 0.363651\n",
      "[7489]\ttraining's binary_logloss: 0.363615\n",
      "[7490]\ttraining's binary_logloss: 0.363588\n",
      "[7491]\ttraining's binary_logloss: 0.363536\n",
      "[7492]\ttraining's binary_logloss: 0.363502\n",
      "[7493]\ttraining's binary_logloss: 0.363472\n",
      "[7494]\ttraining's binary_logloss: 0.363425\n",
      "[7495]\ttraining's binary_logloss: 0.363398\n",
      "[7496]\ttraining's binary_logloss: 0.363364\n",
      "[7497]\ttraining's binary_logloss: 0.363323\n",
      "[7498]\ttraining's binary_logloss: 0.363286\n",
      "[7499]\ttraining's binary_logloss: 0.36321\n",
      "[7500]\ttraining's binary_logloss: 0.363153\n",
      "[7501]\ttraining's binary_logloss: 0.363103\n",
      "[7502]\ttraining's binary_logloss: 0.363059\n",
      "[7503]\ttraining's binary_logloss: 0.363023\n",
      "[7504]\ttraining's binary_logloss: 0.362989\n",
      "[7505]\ttraining's binary_logloss: 0.362945\n",
      "[7506]\ttraining's binary_logloss: 0.362898\n",
      "[7507]\ttraining's binary_logloss: 0.362873\n",
      "[7508]\ttraining's binary_logloss: 0.362843\n",
      "[7509]\ttraining's binary_logloss: 0.362813\n",
      "[7510]\ttraining's binary_logloss: 0.362783\n",
      "[7511]\ttraining's binary_logloss: 0.362743\n",
      "[7512]\ttraining's binary_logloss: 0.362704\n",
      "[7513]\ttraining's binary_logloss: 0.362654\n",
      "[7514]\ttraining's binary_logloss: 0.362626\n",
      "[7515]\ttraining's binary_logloss: 0.362593\n",
      "[7516]\ttraining's binary_logloss: 0.36256\n",
      "[7517]\ttraining's binary_logloss: 0.362521\n",
      "[7518]\ttraining's binary_logloss: 0.362486\n",
      "[7519]\ttraining's binary_logloss: 0.362462\n",
      "[7520]\ttraining's binary_logloss: 0.362433\n",
      "[7521]\ttraining's binary_logloss: 0.362393\n",
      "[7522]\ttraining's binary_logloss: 0.362347\n",
      "[7523]\ttraining's binary_logloss: 0.362307\n",
      "[7524]\ttraining's binary_logloss: 0.362274\n",
      "[7525]\ttraining's binary_logloss: 0.362234\n",
      "[7526]\ttraining's binary_logloss: 0.362205\n",
      "[7527]\ttraining's binary_logloss: 0.362177\n",
      "[7528]\ttraining's binary_logloss: 0.362125\n",
      "[7529]\ttraining's binary_logloss: 0.362077\n",
      "[7530]\ttraining's binary_logloss: 0.362039\n",
      "[7531]\ttraining's binary_logloss: 0.36201\n",
      "[7532]\ttraining's binary_logloss: 0.361968\n",
      "[7533]\ttraining's binary_logloss: 0.361932\n",
      "[7534]\ttraining's binary_logloss: 0.361894\n",
      "[7535]\ttraining's binary_logloss: 0.361865\n",
      "[7536]\ttraining's binary_logloss: 0.36183\n",
      "[7537]\ttraining's binary_logloss: 0.361797\n",
      "[7538]\ttraining's binary_logloss: 0.361771\n",
      "[7539]\ttraining's binary_logloss: 0.36173\n",
      "[7540]\ttraining's binary_logloss: 0.361697\n",
      "[7541]\ttraining's binary_logloss: 0.36166\n",
      "[7542]\ttraining's binary_logloss: 0.361623\n",
      "[7543]\ttraining's binary_logloss: 0.361591\n",
      "[7544]\ttraining's binary_logloss: 0.361555\n",
      "[7545]\ttraining's binary_logloss: 0.361524\n",
      "[7546]\ttraining's binary_logloss: 0.361494\n",
      "[7547]\ttraining's binary_logloss: 0.361463\n",
      "[7548]\ttraining's binary_logloss: 0.361434\n",
      "[7549]\ttraining's binary_logloss: 0.361405\n",
      "[7550]\ttraining's binary_logloss: 0.361373\n",
      "[7551]\ttraining's binary_logloss: 0.361341\n",
      "[7552]\ttraining's binary_logloss: 0.361306\n",
      "[7553]\ttraining's binary_logloss: 0.361252\n",
      "[7554]\ttraining's binary_logloss: 0.361225\n",
      "[7555]\ttraining's binary_logloss: 0.361192\n",
      "[7556]\ttraining's binary_logloss: 0.361152\n",
      "[7557]\ttraining's binary_logloss: 0.361104\n",
      "[7558]\ttraining's binary_logloss: 0.361066\n",
      "[7559]\ttraining's binary_logloss: 0.361037\n",
      "[7560]\ttraining's binary_logloss: 0.361002\n",
      "[7561]\ttraining's binary_logloss: 0.360965\n",
      "[7562]\ttraining's binary_logloss: 0.360936\n",
      "[7563]\ttraining's binary_logloss: 0.360874\n",
      "[7564]\ttraining's binary_logloss: 0.36085\n",
      "[7565]\ttraining's binary_logloss: 0.360806\n",
      "[7566]\ttraining's binary_logloss: 0.360738\n",
      "[7567]\ttraining's binary_logloss: 0.360714\n",
      "[7568]\ttraining's binary_logloss: 0.360676\n",
      "[7569]\ttraining's binary_logloss: 0.360639\n",
      "[7570]\ttraining's binary_logloss: 0.360602\n",
      "[7571]\ttraining's binary_logloss: 0.360566\n",
      "[7572]\ttraining's binary_logloss: 0.360523\n",
      "[7573]\ttraining's binary_logloss: 0.36048\n",
      "[7574]\ttraining's binary_logloss: 0.360426\n",
      "[7575]\ttraining's binary_logloss: 0.360377\n",
      "[7576]\ttraining's binary_logloss: 0.360347\n",
      "[7577]\ttraining's binary_logloss: 0.360317\n",
      "[7578]\ttraining's binary_logloss: 0.360289\n",
      "[7579]\ttraining's binary_logloss: 0.360261\n",
      "[7580]\ttraining's binary_logloss: 0.360233\n",
      "[7581]\ttraining's binary_logloss: 0.3602\n",
      "[7582]\ttraining's binary_logloss: 0.360155\n",
      "[7583]\ttraining's binary_logloss: 0.36012\n",
      "[7584]\ttraining's binary_logloss: 0.360068\n",
      "[7585]\ttraining's binary_logloss: 0.360024\n",
      "[7586]\ttraining's binary_logloss: 0.359985\n",
      "[7587]\ttraining's binary_logloss: 0.35995\n",
      "[7588]\ttraining's binary_logloss: 0.359906\n",
      "[7589]\ttraining's binary_logloss: 0.359861\n",
      "[7590]\ttraining's binary_logloss: 0.359833\n",
      "[7591]\ttraining's binary_logloss: 0.359801\n",
      "[7592]\ttraining's binary_logloss: 0.359774\n",
      "[7593]\ttraining's binary_logloss: 0.359753\n",
      "[7594]\ttraining's binary_logloss: 0.359708\n",
      "[7595]\ttraining's binary_logloss: 0.359676\n",
      "[7596]\ttraining's binary_logloss: 0.359649\n",
      "[7597]\ttraining's binary_logloss: 0.359626\n",
      "[7598]\ttraining's binary_logloss: 0.359599\n",
      "[7599]\ttraining's binary_logloss: 0.359568\n",
      "[7600]\ttraining's binary_logloss: 0.359529\n",
      "[7601]\ttraining's binary_logloss: 0.359499\n",
      "[7602]\ttraining's binary_logloss: 0.359456\n",
      "[7603]\ttraining's binary_logloss: 0.359433\n",
      "[7604]\ttraining's binary_logloss: 0.359405\n",
      "[7605]\ttraining's binary_logloss: 0.359364\n",
      "[7606]\ttraining's binary_logloss: 0.359332\n",
      "[7607]\ttraining's binary_logloss: 0.359301\n",
      "[7608]\ttraining's binary_logloss: 0.359263\n",
      "[7609]\ttraining's binary_logloss: 0.35923\n",
      "[7610]\ttraining's binary_logloss: 0.35917\n",
      "[7611]\ttraining's binary_logloss: 0.359128\n",
      "[7612]\ttraining's binary_logloss: 0.359088\n",
      "[7613]\ttraining's binary_logloss: 0.359061\n",
      "[7614]\ttraining's binary_logloss: 0.359021\n",
      "[7615]\ttraining's binary_logloss: 0.358987\n",
      "[7616]\ttraining's binary_logloss: 0.358964\n",
      "[7617]\ttraining's binary_logloss: 0.358931\n",
      "[7618]\ttraining's binary_logloss: 0.358895\n",
      "[7619]\ttraining's binary_logloss: 0.35886\n",
      "[7620]\ttraining's binary_logloss: 0.358825\n",
      "[7621]\ttraining's binary_logloss: 0.358784\n",
      "[7622]\ttraining's binary_logloss: 0.358757\n",
      "[7623]\ttraining's binary_logloss: 0.358715\n",
      "[7624]\ttraining's binary_logloss: 0.358682\n",
      "[7625]\ttraining's binary_logloss: 0.358655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7626]\ttraining's binary_logloss: 0.358617\n",
      "[7627]\ttraining's binary_logloss: 0.358588\n",
      "[7628]\ttraining's binary_logloss: 0.358559\n",
      "[7629]\ttraining's binary_logloss: 0.35853\n",
      "[7630]\ttraining's binary_logloss: 0.358494\n",
      "[7631]\ttraining's binary_logloss: 0.358448\n",
      "[7632]\ttraining's binary_logloss: 0.358393\n",
      "[7633]\ttraining's binary_logloss: 0.358363\n",
      "[7634]\ttraining's binary_logloss: 0.358314\n",
      "[7635]\ttraining's binary_logloss: 0.358263\n",
      "[7636]\ttraining's binary_logloss: 0.358238\n",
      "[7637]\ttraining's binary_logloss: 0.358195\n",
      "[7638]\ttraining's binary_logloss: 0.358171\n",
      "[7639]\ttraining's binary_logloss: 0.358126\n",
      "[7640]\ttraining's binary_logloss: 0.358082\n",
      "[7641]\ttraining's binary_logloss: 0.358034\n",
      "[7642]\ttraining's binary_logloss: 0.358021\n",
      "[7643]\ttraining's binary_logloss: 0.357992\n",
      "[7644]\ttraining's binary_logloss: 0.35794\n",
      "[7645]\ttraining's binary_logloss: 0.35791\n",
      "[7646]\ttraining's binary_logloss: 0.357865\n",
      "[7647]\ttraining's binary_logloss: 0.357833\n",
      "[7648]\ttraining's binary_logloss: 0.357802\n",
      "[7649]\ttraining's binary_logloss: 0.357769\n",
      "[7650]\ttraining's binary_logloss: 0.357737\n",
      "[7651]\ttraining's binary_logloss: 0.357694\n",
      "[7652]\ttraining's binary_logloss: 0.357655\n",
      "[7653]\ttraining's binary_logloss: 0.35763\n",
      "[7654]\ttraining's binary_logloss: 0.357597\n",
      "[7655]\ttraining's binary_logloss: 0.357564\n",
      "[7656]\ttraining's binary_logloss: 0.357522\n",
      "[7657]\ttraining's binary_logloss: 0.357484\n",
      "[7658]\ttraining's binary_logloss: 0.35746\n",
      "[7659]\ttraining's binary_logloss: 0.357421\n",
      "[7660]\ttraining's binary_logloss: 0.357389\n",
      "[7661]\ttraining's binary_logloss: 0.357353\n",
      "[7662]\ttraining's binary_logloss: 0.35732\n",
      "[7663]\ttraining's binary_logloss: 0.357284\n",
      "[7664]\ttraining's binary_logloss: 0.357246\n",
      "[7665]\ttraining's binary_logloss: 0.357219\n",
      "[7666]\ttraining's binary_logloss: 0.357189\n",
      "[7667]\ttraining's binary_logloss: 0.357161\n",
      "[7668]\ttraining's binary_logloss: 0.357124\n",
      "[7669]\ttraining's binary_logloss: 0.357101\n",
      "[7670]\ttraining's binary_logloss: 0.35706\n",
      "[7671]\ttraining's binary_logloss: 0.357027\n",
      "[7672]\ttraining's binary_logloss: 0.356997\n",
      "[7673]\ttraining's binary_logloss: 0.356959\n",
      "[7674]\ttraining's binary_logloss: 0.356913\n",
      "[7675]\ttraining's binary_logloss: 0.356881\n",
      "[7676]\ttraining's binary_logloss: 0.356839\n",
      "[7677]\ttraining's binary_logloss: 0.356814\n",
      "[7678]\ttraining's binary_logloss: 0.356767\n",
      "[7679]\ttraining's binary_logloss: 0.356741\n",
      "[7680]\ttraining's binary_logloss: 0.356692\n",
      "[7681]\ttraining's binary_logloss: 0.35666\n",
      "[7682]\ttraining's binary_logloss: 0.356629\n",
      "[7683]\ttraining's binary_logloss: 0.356573\n",
      "[7684]\ttraining's binary_logloss: 0.356532\n",
      "[7685]\ttraining's binary_logloss: 0.356485\n",
      "[7686]\ttraining's binary_logloss: 0.356453\n",
      "[7687]\ttraining's binary_logloss: 0.356417\n",
      "[7688]\ttraining's binary_logloss: 0.356389\n",
      "[7689]\ttraining's binary_logloss: 0.356346\n",
      "[7690]\ttraining's binary_logloss: 0.356313\n",
      "[7691]\ttraining's binary_logloss: 0.356271\n",
      "[7692]\ttraining's binary_logloss: 0.35623\n",
      "[7693]\ttraining's binary_logloss: 0.356204\n",
      "[7694]\ttraining's binary_logloss: 0.35616\n",
      "[7695]\ttraining's binary_logloss: 0.356132\n",
      "[7696]\ttraining's binary_logloss: 0.356106\n",
      "[7697]\ttraining's binary_logloss: 0.356081\n",
      "[7698]\ttraining's binary_logloss: 0.356048\n",
      "[7699]\ttraining's binary_logloss: 0.355991\n",
      "[7700]\ttraining's binary_logloss: 0.355961\n",
      "[7701]\ttraining's binary_logloss: 0.355941\n",
      "[7702]\ttraining's binary_logloss: 0.355918\n",
      "[7703]\ttraining's binary_logloss: 0.355887\n",
      "[7704]\ttraining's binary_logloss: 0.355839\n",
      "[7705]\ttraining's binary_logloss: 0.355794\n",
      "[7706]\ttraining's binary_logloss: 0.355766\n",
      "[7707]\ttraining's binary_logloss: 0.355741\n",
      "[7708]\ttraining's binary_logloss: 0.355713\n",
      "[7709]\ttraining's binary_logloss: 0.355676\n",
      "[7710]\ttraining's binary_logloss: 0.355639\n",
      "[7711]\ttraining's binary_logloss: 0.355601\n",
      "[7712]\ttraining's binary_logloss: 0.355558\n",
      "[7713]\ttraining's binary_logloss: 0.355529\n",
      "[7714]\ttraining's binary_logloss: 0.355499\n",
      "[7715]\ttraining's binary_logloss: 0.355471\n",
      "[7716]\ttraining's binary_logloss: 0.355435\n",
      "[7717]\ttraining's binary_logloss: 0.35539\n",
      "[7718]\ttraining's binary_logloss: 0.355351\n",
      "[7719]\ttraining's binary_logloss: 0.35531\n",
      "[7720]\ttraining's binary_logloss: 0.355258\n",
      "[7721]\ttraining's binary_logloss: 0.35522\n",
      "[7722]\ttraining's binary_logloss: 0.355194\n",
      "[7723]\ttraining's binary_logloss: 0.355164\n",
      "[7724]\ttraining's binary_logloss: 0.35513\n",
      "[7725]\ttraining's binary_logloss: 0.355104\n",
      "[7726]\ttraining's binary_logloss: 0.355065\n",
      "[7727]\ttraining's binary_logloss: 0.35504\n",
      "[7728]\ttraining's binary_logloss: 0.355009\n",
      "[7729]\ttraining's binary_logloss: 0.354985\n",
      "[7730]\ttraining's binary_logloss: 0.354954\n",
      "[7731]\ttraining's binary_logloss: 0.354912\n",
      "[7732]\ttraining's binary_logloss: 0.354883\n",
      "[7733]\ttraining's binary_logloss: 0.354839\n",
      "[7734]\ttraining's binary_logloss: 0.3548\n",
      "[7735]\ttraining's binary_logloss: 0.354768\n",
      "[7736]\ttraining's binary_logloss: 0.35473\n",
      "[7737]\ttraining's binary_logloss: 0.354679\n",
      "[7738]\ttraining's binary_logloss: 0.354654\n",
      "[7739]\ttraining's binary_logloss: 0.35462\n",
      "[7740]\ttraining's binary_logloss: 0.354571\n",
      "[7741]\ttraining's binary_logloss: 0.354535\n",
      "[7742]\ttraining's binary_logloss: 0.354508\n",
      "[7743]\ttraining's binary_logloss: 0.354464\n",
      "[7744]\ttraining's binary_logloss: 0.35443\n",
      "[7745]\ttraining's binary_logloss: 0.354396\n",
      "[7746]\ttraining's binary_logloss: 0.354342\n",
      "[7747]\ttraining's binary_logloss: 0.354316\n",
      "[7748]\ttraining's binary_logloss: 0.354273\n",
      "[7749]\ttraining's binary_logloss: 0.354233\n",
      "[7750]\ttraining's binary_logloss: 0.354199\n",
      "[7751]\ttraining's binary_logloss: 0.354171\n",
      "[7752]\ttraining's binary_logloss: 0.354138\n",
      "[7753]\ttraining's binary_logloss: 0.354092\n",
      "[7754]\ttraining's binary_logloss: 0.35405\n",
      "[7755]\ttraining's binary_logloss: 0.35402\n",
      "[7756]\ttraining's binary_logloss: 0.353977\n",
      "[7757]\ttraining's binary_logloss: 0.353954\n",
      "[7758]\ttraining's binary_logloss: 0.353917\n",
      "[7759]\ttraining's binary_logloss: 0.353886\n",
      "[7760]\ttraining's binary_logloss: 0.353865\n",
      "[7761]\ttraining's binary_logloss: 0.353837\n",
      "[7762]\ttraining's binary_logloss: 0.353804\n",
      "[7763]\ttraining's binary_logloss: 0.353769\n",
      "[7764]\ttraining's binary_logloss: 0.353737\n",
      "[7765]\ttraining's binary_logloss: 0.353691\n",
      "[7766]\ttraining's binary_logloss: 0.35364\n",
      "[7767]\ttraining's binary_logloss: 0.353594\n",
      "[7768]\ttraining's binary_logloss: 0.353559\n",
      "[7769]\ttraining's binary_logloss: 0.35353\n",
      "[7770]\ttraining's binary_logloss: 0.353504\n",
      "[7771]\ttraining's binary_logloss: 0.353477\n",
      "[7772]\ttraining's binary_logloss: 0.353447\n",
      "[7773]\ttraining's binary_logloss: 0.353397\n",
      "[7774]\ttraining's binary_logloss: 0.353363\n",
      "[7775]\ttraining's binary_logloss: 0.353331\n",
      "[7776]\ttraining's binary_logloss: 0.353292\n",
      "[7777]\ttraining's binary_logloss: 0.353247\n",
      "[7778]\ttraining's binary_logloss: 0.353219\n",
      "[7779]\ttraining's binary_logloss: 0.353196\n",
      "[7780]\ttraining's binary_logloss: 0.353158\n",
      "[7781]\ttraining's binary_logloss: 0.353126\n",
      "[7782]\ttraining's binary_logloss: 0.35309\n",
      "[7783]\ttraining's binary_logloss: 0.353048\n",
      "[7784]\ttraining's binary_logloss: 0.35301\n",
      "[7785]\ttraining's binary_logloss: 0.352959\n",
      "[7786]\ttraining's binary_logloss: 0.352916\n",
      "[7787]\ttraining's binary_logloss: 0.352888\n",
      "[7788]\ttraining's binary_logloss: 0.352855\n",
      "[7789]\ttraining's binary_logloss: 0.352834\n",
      "[7790]\ttraining's binary_logloss: 0.352809\n",
      "[7791]\ttraining's binary_logloss: 0.352763\n",
      "[7792]\ttraining's binary_logloss: 0.352731\n",
      "[7793]\ttraining's binary_logloss: 0.3527\n",
      "[7794]\ttraining's binary_logloss: 0.352672\n",
      "[7795]\ttraining's binary_logloss: 0.352648\n",
      "[7796]\ttraining's binary_logloss: 0.352611\n",
      "[7797]\ttraining's binary_logloss: 0.352581\n",
      "[7798]\ttraining's binary_logloss: 0.352541\n",
      "[7799]\ttraining's binary_logloss: 0.352499\n",
      "[7800]\ttraining's binary_logloss: 0.35247\n",
      "[7801]\ttraining's binary_logloss: 0.352423\n",
      "[7802]\ttraining's binary_logloss: 0.352392\n",
      "[7803]\ttraining's binary_logloss: 0.35236\n",
      "[7804]\ttraining's binary_logloss: 0.352321\n",
      "[7805]\ttraining's binary_logloss: 0.35228\n",
      "[7806]\ttraining's binary_logloss: 0.35224\n",
      "[7807]\ttraining's binary_logloss: 0.352205\n",
      "[7808]\ttraining's binary_logloss: 0.352152\n",
      "[7809]\ttraining's binary_logloss: 0.352126\n",
      "[7810]\ttraining's binary_logloss: 0.352084\n",
      "[7811]\ttraining's binary_logloss: 0.352062\n",
      "[7812]\ttraining's binary_logloss: 0.352029\n",
      "[7813]\ttraining's binary_logloss: 0.352005\n",
      "[7814]\ttraining's binary_logloss: 0.351971\n",
      "[7815]\ttraining's binary_logloss: 0.351928\n",
      "[7816]\ttraining's binary_logloss: 0.351894\n",
      "[7817]\ttraining's binary_logloss: 0.351851\n",
      "[7818]\ttraining's binary_logloss: 0.351814\n",
      "[7819]\ttraining's binary_logloss: 0.351787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7820]\ttraining's binary_logloss: 0.35176\n",
      "[7821]\ttraining's binary_logloss: 0.351722\n",
      "[7822]\ttraining's binary_logloss: 0.351678\n",
      "[7823]\ttraining's binary_logloss: 0.35164\n",
      "[7824]\ttraining's binary_logloss: 0.351587\n",
      "[7825]\ttraining's binary_logloss: 0.351551\n",
      "[7826]\ttraining's binary_logloss: 0.351513\n",
      "[7827]\ttraining's binary_logloss: 0.351484\n",
      "[7828]\ttraining's binary_logloss: 0.351446\n",
      "[7829]\ttraining's binary_logloss: 0.351416\n",
      "[7830]\ttraining's binary_logloss: 0.351386\n",
      "[7831]\ttraining's binary_logloss: 0.351349\n",
      "[7832]\ttraining's binary_logloss: 0.35132\n",
      "[7833]\ttraining's binary_logloss: 0.351279\n",
      "[7834]\ttraining's binary_logloss: 0.351254\n",
      "[7835]\ttraining's binary_logloss: 0.351219\n",
      "[7836]\ttraining's binary_logloss: 0.351184\n",
      "[7837]\ttraining's binary_logloss: 0.351161\n",
      "[7838]\ttraining's binary_logloss: 0.351139\n",
      "[7839]\ttraining's binary_logloss: 0.351117\n",
      "[7840]\ttraining's binary_logloss: 0.351062\n",
      "[7841]\ttraining's binary_logloss: 0.351021\n",
      "[7842]\ttraining's binary_logloss: 0.350991\n",
      "[7843]\ttraining's binary_logloss: 0.350965\n",
      "[7844]\ttraining's binary_logloss: 0.350927\n",
      "[7845]\ttraining's binary_logloss: 0.350889\n",
      "[7846]\ttraining's binary_logloss: 0.350859\n",
      "[7847]\ttraining's binary_logloss: 0.350831\n",
      "[7848]\ttraining's binary_logloss: 0.35079\n",
      "[7849]\ttraining's binary_logloss: 0.350757\n",
      "[7850]\ttraining's binary_logloss: 0.35073\n",
      "[7851]\ttraining's binary_logloss: 0.350699\n",
      "[7852]\ttraining's binary_logloss: 0.35067\n",
      "[7853]\ttraining's binary_logloss: 0.350625\n",
      "[7854]\ttraining's binary_logloss: 0.350589\n",
      "[7855]\ttraining's binary_logloss: 0.350538\n",
      "[7856]\ttraining's binary_logloss: 0.350493\n",
      "[7857]\ttraining's binary_logloss: 0.350448\n",
      "[7858]\ttraining's binary_logloss: 0.350415\n",
      "[7859]\ttraining's binary_logloss: 0.350388\n",
      "[7860]\ttraining's binary_logloss: 0.350354\n",
      "[7861]\ttraining's binary_logloss: 0.350315\n",
      "[7862]\ttraining's binary_logloss: 0.350289\n",
      "[7863]\ttraining's binary_logloss: 0.350254\n",
      "[7864]\ttraining's binary_logloss: 0.350204\n",
      "[7865]\ttraining's binary_logloss: 0.35018\n",
      "[7866]\ttraining's binary_logloss: 0.350149\n",
      "[7867]\ttraining's binary_logloss: 0.350119\n",
      "[7868]\ttraining's binary_logloss: 0.350098\n",
      "[7869]\ttraining's binary_logloss: 0.350067\n",
      "[7870]\ttraining's binary_logloss: 0.350038\n",
      "[7871]\ttraining's binary_logloss: 0.350002\n",
      "[7872]\ttraining's binary_logloss: 0.349982\n",
      "[7873]\ttraining's binary_logloss: 0.349954\n",
      "[7874]\ttraining's binary_logloss: 0.349911\n",
      "[7875]\ttraining's binary_logloss: 0.349851\n",
      "[7876]\ttraining's binary_logloss: 0.349825\n",
      "[7877]\ttraining's binary_logloss: 0.349787\n",
      "[7878]\ttraining's binary_logloss: 0.349754\n",
      "[7879]\ttraining's binary_logloss: 0.34972\n",
      "[7880]\ttraining's binary_logloss: 0.349694\n",
      "[7881]\ttraining's binary_logloss: 0.349651\n",
      "[7882]\ttraining's binary_logloss: 0.349626\n",
      "[7883]\ttraining's binary_logloss: 0.349596\n",
      "[7884]\ttraining's binary_logloss: 0.349561\n",
      "[7885]\ttraining's binary_logloss: 0.349517\n",
      "[7886]\ttraining's binary_logloss: 0.349487\n",
      "[7887]\ttraining's binary_logloss: 0.349463\n",
      "[7888]\ttraining's binary_logloss: 0.349425\n",
      "[7889]\ttraining's binary_logloss: 0.349397\n",
      "[7890]\ttraining's binary_logloss: 0.349366\n",
      "[7891]\ttraining's binary_logloss: 0.349336\n",
      "[7892]\ttraining's binary_logloss: 0.3493\n",
      "[7893]\ttraining's binary_logloss: 0.349246\n",
      "[7894]\ttraining's binary_logloss: 0.349213\n",
      "[7895]\ttraining's binary_logloss: 0.34918\n",
      "[7896]\ttraining's binary_logloss: 0.349149\n",
      "[7897]\ttraining's binary_logloss: 0.349114\n",
      "[7898]\ttraining's binary_logloss: 0.349065\n",
      "[7899]\ttraining's binary_logloss: 0.349041\n",
      "[7900]\ttraining's binary_logloss: 0.349016\n",
      "[7901]\ttraining's binary_logloss: 0.348987\n",
      "[7902]\ttraining's binary_logloss: 0.348948\n",
      "[7903]\ttraining's binary_logloss: 0.348906\n",
      "[7904]\ttraining's binary_logloss: 0.348871\n",
      "[7905]\ttraining's binary_logloss: 0.348831\n",
      "[7906]\ttraining's binary_logloss: 0.348787\n",
      "[7907]\ttraining's binary_logloss: 0.348763\n",
      "[7908]\ttraining's binary_logloss: 0.348719\n",
      "[7909]\ttraining's binary_logloss: 0.348698\n",
      "[7910]\ttraining's binary_logloss: 0.348667\n",
      "[7911]\ttraining's binary_logloss: 0.348626\n",
      "[7912]\ttraining's binary_logloss: 0.348594\n",
      "[7913]\ttraining's binary_logloss: 0.348556\n",
      "[7914]\ttraining's binary_logloss: 0.348521\n",
      "[7915]\ttraining's binary_logloss: 0.348473\n",
      "[7916]\ttraining's binary_logloss: 0.34844\n",
      "[7917]\ttraining's binary_logloss: 0.348396\n",
      "[7918]\ttraining's binary_logloss: 0.348364\n",
      "[7919]\ttraining's binary_logloss: 0.348333\n",
      "[7920]\ttraining's binary_logloss: 0.34829\n",
      "[7921]\ttraining's binary_logloss: 0.348262\n",
      "[7922]\ttraining's binary_logloss: 0.34823\n",
      "[7923]\ttraining's binary_logloss: 0.348195\n",
      "[7924]\ttraining's binary_logloss: 0.34816\n",
      "[7925]\ttraining's binary_logloss: 0.348119\n",
      "[7926]\ttraining's binary_logloss: 0.348091\n",
      "[7927]\ttraining's binary_logloss: 0.348052\n",
      "[7928]\ttraining's binary_logloss: 0.348021\n",
      "[7929]\ttraining's binary_logloss: 0.347995\n",
      "[7930]\ttraining's binary_logloss: 0.34795\n",
      "[7931]\ttraining's binary_logloss: 0.34791\n",
      "[7932]\ttraining's binary_logloss: 0.347874\n",
      "[7933]\ttraining's binary_logloss: 0.347837\n",
      "[7934]\ttraining's binary_logloss: 0.347776\n",
      "[7935]\ttraining's binary_logloss: 0.347742\n",
      "[7936]\ttraining's binary_logloss: 0.34772\n",
      "[7937]\ttraining's binary_logloss: 0.347691\n",
      "[7938]\ttraining's binary_logloss: 0.347664\n",
      "[7939]\ttraining's binary_logloss: 0.347637\n",
      "[7940]\ttraining's binary_logloss: 0.347602\n",
      "[7941]\ttraining's binary_logloss: 0.347564\n",
      "[7942]\ttraining's binary_logloss: 0.347526\n",
      "[7943]\ttraining's binary_logloss: 0.347493\n",
      "[7944]\ttraining's binary_logloss: 0.347466\n",
      "[7945]\ttraining's binary_logloss: 0.347427\n",
      "[7946]\ttraining's binary_logloss: 0.347402\n",
      "[7947]\ttraining's binary_logloss: 0.34737\n",
      "[7948]\ttraining's binary_logloss: 0.347347\n",
      "[7949]\ttraining's binary_logloss: 0.347313\n",
      "[7950]\ttraining's binary_logloss: 0.347271\n",
      "[7951]\ttraining's binary_logloss: 0.347241\n",
      "[7952]\ttraining's binary_logloss: 0.347207\n",
      "[7953]\ttraining's binary_logloss: 0.347181\n",
      "[7954]\ttraining's binary_logloss: 0.347148\n",
      "[7955]\ttraining's binary_logloss: 0.347121\n",
      "[7956]\ttraining's binary_logloss: 0.347086\n",
      "[7957]\ttraining's binary_logloss: 0.34706\n",
      "[7958]\ttraining's binary_logloss: 0.347026\n",
      "[7959]\ttraining's binary_logloss: 0.346977\n",
      "[7960]\ttraining's binary_logloss: 0.346923\n",
      "[7961]\ttraining's binary_logloss: 0.346886\n",
      "[7962]\ttraining's binary_logloss: 0.346856\n",
      "[7963]\ttraining's binary_logloss: 0.346809\n",
      "[7964]\ttraining's binary_logloss: 0.346778\n",
      "[7965]\ttraining's binary_logloss: 0.346742\n",
      "[7966]\ttraining's binary_logloss: 0.346705\n",
      "[7967]\ttraining's binary_logloss: 0.346669\n",
      "[7968]\ttraining's binary_logloss: 0.346628\n",
      "[7969]\ttraining's binary_logloss: 0.346591\n",
      "[7970]\ttraining's binary_logloss: 0.346559\n",
      "[7971]\ttraining's binary_logloss: 0.346523\n",
      "[7972]\ttraining's binary_logloss: 0.346483\n",
      "[7973]\ttraining's binary_logloss: 0.346457\n",
      "[7974]\ttraining's binary_logloss: 0.346423\n",
      "[7975]\ttraining's binary_logloss: 0.346389\n",
      "[7976]\ttraining's binary_logloss: 0.34636\n",
      "[7977]\ttraining's binary_logloss: 0.346327\n",
      "[7978]\ttraining's binary_logloss: 0.346297\n",
      "[7979]\ttraining's binary_logloss: 0.346258\n",
      "[7980]\ttraining's binary_logloss: 0.346221\n",
      "[7981]\ttraining's binary_logloss: 0.346183\n",
      "[7982]\ttraining's binary_logloss: 0.346149\n",
      "[7983]\ttraining's binary_logloss: 0.346124\n",
      "[7984]\ttraining's binary_logloss: 0.3461\n",
      "[7985]\ttraining's binary_logloss: 0.346062\n",
      "[7986]\ttraining's binary_logloss: 0.346036\n",
      "[7987]\ttraining's binary_logloss: 0.346001\n",
      "[7988]\ttraining's binary_logloss: 0.345964\n",
      "[7989]\ttraining's binary_logloss: 0.345933\n",
      "[7990]\ttraining's binary_logloss: 0.345891\n",
      "[7991]\ttraining's binary_logloss: 0.345849\n",
      "[7992]\ttraining's binary_logloss: 0.345805\n",
      "[7993]\ttraining's binary_logloss: 0.345764\n",
      "[7994]\ttraining's binary_logloss: 0.34573\n",
      "[7995]\ttraining's binary_logloss: 0.345709\n",
      "[7996]\ttraining's binary_logloss: 0.345683\n",
      "[7997]\ttraining's binary_logloss: 0.345636\n",
      "[7998]\ttraining's binary_logloss: 0.345605\n",
      "[7999]\ttraining's binary_logloss: 0.345563\n",
      "[8000]\ttraining's binary_logloss: 0.345521\n",
      "[8001]\ttraining's binary_logloss: 0.345494\n",
      "[8002]\ttraining's binary_logloss: 0.345446\n",
      "[8003]\ttraining's binary_logloss: 0.34542\n",
      "[8004]\ttraining's binary_logloss: 0.345386\n",
      "[8005]\ttraining's binary_logloss: 0.345346\n",
      "[8006]\ttraining's binary_logloss: 0.345322\n",
      "[8007]\ttraining's binary_logloss: 0.345287\n",
      "[8008]\ttraining's binary_logloss: 0.345266\n",
      "[8009]\ttraining's binary_logloss: 0.345231\n",
      "[8010]\ttraining's binary_logloss: 0.345209\n",
      "[8011]\ttraining's binary_logloss: 0.345171\n",
      "[8012]\ttraining's binary_logloss: 0.345127\n",
      "[8013]\ttraining's binary_logloss: 0.345073\n",
      "[8014]\ttraining's binary_logloss: 0.345015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8015]\ttraining's binary_logloss: 0.344978\n",
      "[8016]\ttraining's binary_logloss: 0.344939\n",
      "[8017]\ttraining's binary_logloss: 0.3449\n",
      "[8018]\ttraining's binary_logloss: 0.34487\n",
      "[8019]\ttraining's binary_logloss: 0.344831\n",
      "[8020]\ttraining's binary_logloss: 0.344803\n",
      "[8021]\ttraining's binary_logloss: 0.34478\n",
      "[8022]\ttraining's binary_logloss: 0.344737\n",
      "[8023]\ttraining's binary_logloss: 0.344711\n",
      "[8024]\ttraining's binary_logloss: 0.344686\n",
      "[8025]\ttraining's binary_logloss: 0.344653\n",
      "[8026]\ttraining's binary_logloss: 0.344631\n",
      "[8027]\ttraining's binary_logloss: 0.344584\n",
      "[8028]\ttraining's binary_logloss: 0.34456\n",
      "[8029]\ttraining's binary_logloss: 0.344527\n",
      "[8030]\ttraining's binary_logloss: 0.344491\n",
      "[8031]\ttraining's binary_logloss: 0.344459\n",
      "[8032]\ttraining's binary_logloss: 0.344416\n",
      "[8033]\ttraining's binary_logloss: 0.34439\n",
      "[8034]\ttraining's binary_logloss: 0.344346\n",
      "[8035]\ttraining's binary_logloss: 0.344308\n",
      "[8036]\ttraining's binary_logloss: 0.34427\n",
      "[8037]\ttraining's binary_logloss: 0.344241\n",
      "[8038]\ttraining's binary_logloss: 0.3442\n",
      "[8039]\ttraining's binary_logloss: 0.344165\n",
      "[8040]\ttraining's binary_logloss: 0.34412\n",
      "[8041]\ttraining's binary_logloss: 0.344093\n",
      "[8042]\ttraining's binary_logloss: 0.344065\n",
      "[8043]\ttraining's binary_logloss: 0.344028\n",
      "[8044]\ttraining's binary_logloss: 0.343981\n",
      "[8045]\ttraining's binary_logloss: 0.343948\n",
      "[8046]\ttraining's binary_logloss: 0.343918\n",
      "[8047]\ttraining's binary_logloss: 0.343885\n",
      "[8048]\ttraining's binary_logloss: 0.343855\n",
      "[8049]\ttraining's binary_logloss: 0.343831\n",
      "[8050]\ttraining's binary_logloss: 0.343808\n",
      "[8051]\ttraining's binary_logloss: 0.343756\n",
      "[8052]\ttraining's binary_logloss: 0.343724\n",
      "[8053]\ttraining's binary_logloss: 0.343694\n",
      "[8054]\ttraining's binary_logloss: 0.343668\n",
      "[8055]\ttraining's binary_logloss: 0.343638\n",
      "[8056]\ttraining's binary_logloss: 0.343601\n",
      "[8057]\ttraining's binary_logloss: 0.343575\n",
      "[8058]\ttraining's binary_logloss: 0.343547\n",
      "[8059]\ttraining's binary_logloss: 0.343517\n",
      "[8060]\ttraining's binary_logloss: 0.343482\n",
      "[8061]\ttraining's binary_logloss: 0.343445\n",
      "[8062]\ttraining's binary_logloss: 0.343414\n",
      "[8063]\ttraining's binary_logloss: 0.343377\n",
      "[8064]\ttraining's binary_logloss: 0.343347\n",
      "[8065]\ttraining's binary_logloss: 0.34332\n",
      "[8066]\ttraining's binary_logloss: 0.343288\n",
      "[8067]\ttraining's binary_logloss: 0.343255\n",
      "[8068]\ttraining's binary_logloss: 0.343209\n",
      "[8069]\ttraining's binary_logloss: 0.343167\n",
      "[8070]\ttraining's binary_logloss: 0.343138\n",
      "[8071]\ttraining's binary_logloss: 0.343115\n",
      "[8072]\ttraining's binary_logloss: 0.34308\n",
      "[8073]\ttraining's binary_logloss: 0.343043\n",
      "[8074]\ttraining's binary_logloss: 0.343004\n",
      "[8075]\ttraining's binary_logloss: 0.342956\n",
      "[8076]\ttraining's binary_logloss: 0.342927\n",
      "[8077]\ttraining's binary_logloss: 0.342903\n",
      "[8078]\ttraining's binary_logloss: 0.342869\n",
      "[8079]\ttraining's binary_logloss: 0.342839\n",
      "[8080]\ttraining's binary_logloss: 0.342804\n",
      "[8081]\ttraining's binary_logloss: 0.342774\n",
      "[8082]\ttraining's binary_logloss: 0.342747\n",
      "[8083]\ttraining's binary_logloss: 0.342719\n",
      "[8084]\ttraining's binary_logloss: 0.342684\n",
      "[8085]\ttraining's binary_logloss: 0.34266\n",
      "[8086]\ttraining's binary_logloss: 0.342611\n",
      "[8087]\ttraining's binary_logloss: 0.342575\n",
      "[8088]\ttraining's binary_logloss: 0.342551\n",
      "[8089]\ttraining's binary_logloss: 0.342517\n",
      "[8090]\ttraining's binary_logloss: 0.342471\n",
      "[8091]\ttraining's binary_logloss: 0.342442\n",
      "[8092]\ttraining's binary_logloss: 0.342405\n",
      "[8093]\ttraining's binary_logloss: 0.34237\n",
      "[8094]\ttraining's binary_logloss: 0.342341\n",
      "[8095]\ttraining's binary_logloss: 0.342317\n",
      "[8096]\ttraining's binary_logloss: 0.342296\n",
      "[8097]\ttraining's binary_logloss: 0.342269\n",
      "[8098]\ttraining's binary_logloss: 0.342229\n",
      "[8099]\ttraining's binary_logloss: 0.342203\n",
      "[8100]\ttraining's binary_logloss: 0.342171\n",
      "[8101]\ttraining's binary_logloss: 0.342132\n",
      "[8102]\ttraining's binary_logloss: 0.342092\n",
      "[8103]\ttraining's binary_logloss: 0.342042\n",
      "[8104]\ttraining's binary_logloss: 0.342007\n",
      "[8105]\ttraining's binary_logloss: 0.341966\n",
      "[8106]\ttraining's binary_logloss: 0.341932\n",
      "[8107]\ttraining's binary_logloss: 0.341905\n",
      "[8108]\ttraining's binary_logloss: 0.341884\n",
      "[8109]\ttraining's binary_logloss: 0.341859\n",
      "[8110]\ttraining's binary_logloss: 0.34183\n",
      "[8111]\ttraining's binary_logloss: 0.341779\n",
      "[8112]\ttraining's binary_logloss: 0.341745\n",
      "[8113]\ttraining's binary_logloss: 0.341697\n",
      "[8114]\ttraining's binary_logloss: 0.341654\n",
      "[8115]\ttraining's binary_logloss: 0.341625\n",
      "[8116]\ttraining's binary_logloss: 0.3416\n",
      "[8117]\ttraining's binary_logloss: 0.341571\n",
      "[8118]\ttraining's binary_logloss: 0.341536\n",
      "[8119]\ttraining's binary_logloss: 0.341501\n",
      "[8120]\ttraining's binary_logloss: 0.341464\n",
      "[8121]\ttraining's binary_logloss: 0.341437\n",
      "[8122]\ttraining's binary_logloss: 0.341399\n",
      "[8123]\ttraining's binary_logloss: 0.34136\n",
      "[8124]\ttraining's binary_logloss: 0.341327\n",
      "[8125]\ttraining's binary_logloss: 0.34128\n",
      "[8126]\ttraining's binary_logloss: 0.341245\n",
      "[8127]\ttraining's binary_logloss: 0.341217\n",
      "[8128]\ttraining's binary_logloss: 0.341178\n",
      "[8129]\ttraining's binary_logloss: 0.341141\n",
      "[8130]\ttraining's binary_logloss: 0.341118\n",
      "[8131]\ttraining's binary_logloss: 0.341072\n",
      "[8132]\ttraining's binary_logloss: 0.341048\n",
      "[8133]\ttraining's binary_logloss: 0.340995\n",
      "[8134]\ttraining's binary_logloss: 0.340942\n",
      "[8135]\ttraining's binary_logloss: 0.340902\n",
      "[8136]\ttraining's binary_logloss: 0.340881\n",
      "[8137]\ttraining's binary_logloss: 0.340853\n",
      "[8138]\ttraining's binary_logloss: 0.340825\n",
      "[8139]\ttraining's binary_logloss: 0.340792\n",
      "[8140]\ttraining's binary_logloss: 0.340763\n",
      "[8141]\ttraining's binary_logloss: 0.340733\n",
      "[8142]\ttraining's binary_logloss: 0.340705\n",
      "[8143]\ttraining's binary_logloss: 0.340678\n",
      "[8144]\ttraining's binary_logloss: 0.34063\n",
      "[8145]\ttraining's binary_logloss: 0.340595\n",
      "[8146]\ttraining's binary_logloss: 0.340574\n",
      "[8147]\ttraining's binary_logloss: 0.34054\n",
      "[8148]\ttraining's binary_logloss: 0.340497\n",
      "[8149]\ttraining's binary_logloss: 0.340454\n",
      "[8150]\ttraining's binary_logloss: 0.34042\n",
      "[8151]\ttraining's binary_logloss: 0.340391\n",
      "[8152]\ttraining's binary_logloss: 0.340358\n",
      "[8153]\ttraining's binary_logloss: 0.340334\n",
      "[8154]\ttraining's binary_logloss: 0.340304\n",
      "[8155]\ttraining's binary_logloss: 0.340274\n",
      "[8156]\ttraining's binary_logloss: 0.340231\n",
      "[8157]\ttraining's binary_logloss: 0.340206\n",
      "[8158]\ttraining's binary_logloss: 0.340178\n",
      "[8159]\ttraining's binary_logloss: 0.340146\n",
      "[8160]\ttraining's binary_logloss: 0.340091\n",
      "[8161]\ttraining's binary_logloss: 0.340067\n",
      "[8162]\ttraining's binary_logloss: 0.340039\n",
      "[8163]\ttraining's binary_logloss: 0.339997\n",
      "[8164]\ttraining's binary_logloss: 0.339974\n",
      "[8165]\ttraining's binary_logloss: 0.339936\n",
      "[8166]\ttraining's binary_logloss: 0.339904\n",
      "[8167]\ttraining's binary_logloss: 0.339872\n",
      "[8168]\ttraining's binary_logloss: 0.339841\n",
      "[8169]\ttraining's binary_logloss: 0.339804\n",
      "[8170]\ttraining's binary_logloss: 0.339781\n",
      "[8171]\ttraining's binary_logloss: 0.33975\n",
      "[8172]\ttraining's binary_logloss: 0.339724\n",
      "[8173]\ttraining's binary_logloss: 0.339689\n",
      "[8174]\ttraining's binary_logloss: 0.339663\n",
      "[8175]\ttraining's binary_logloss: 0.339635\n",
      "[8176]\ttraining's binary_logloss: 0.339585\n",
      "[8177]\ttraining's binary_logloss: 0.339558\n",
      "[8178]\ttraining's binary_logloss: 0.33952\n",
      "[8179]\ttraining's binary_logloss: 0.339465\n",
      "[8180]\ttraining's binary_logloss: 0.339415\n",
      "[8181]\ttraining's binary_logloss: 0.339374\n",
      "[8182]\ttraining's binary_logloss: 0.339343\n",
      "[8183]\ttraining's binary_logloss: 0.339299\n",
      "[8184]\ttraining's binary_logloss: 0.339269\n",
      "[8185]\ttraining's binary_logloss: 0.339234\n",
      "[8186]\ttraining's binary_logloss: 0.339186\n",
      "[8187]\ttraining's binary_logloss: 0.339152\n",
      "[8188]\ttraining's binary_logloss: 0.339117\n",
      "[8189]\ttraining's binary_logloss: 0.339082\n",
      "[8190]\ttraining's binary_logloss: 0.339038\n",
      "[8191]\ttraining's binary_logloss: 0.338995\n",
      "[8192]\ttraining's binary_logloss: 0.338952\n",
      "[8193]\ttraining's binary_logloss: 0.338911\n",
      "[8194]\ttraining's binary_logloss: 0.338863\n",
      "[8195]\ttraining's binary_logloss: 0.338832\n",
      "[8196]\ttraining's binary_logloss: 0.338795\n",
      "[8197]\ttraining's binary_logloss: 0.338771\n",
      "[8198]\ttraining's binary_logloss: 0.338743\n",
      "[8199]\ttraining's binary_logloss: 0.338703\n",
      "[8200]\ttraining's binary_logloss: 0.338674\n",
      "[8201]\ttraining's binary_logloss: 0.338628\n",
      "[8202]\ttraining's binary_logloss: 0.338598\n",
      "[8203]\ttraining's binary_logloss: 0.33856\n",
      "[8204]\ttraining's binary_logloss: 0.338535\n",
      "[8205]\ttraining's binary_logloss: 0.338512\n",
      "[8206]\ttraining's binary_logloss: 0.338474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8207]\ttraining's binary_logloss: 0.338433\n",
      "[8208]\ttraining's binary_logloss: 0.338402\n",
      "[8209]\ttraining's binary_logloss: 0.338375\n",
      "[8210]\ttraining's binary_logloss: 0.338334\n",
      "[8211]\ttraining's binary_logloss: 0.338284\n",
      "[8212]\ttraining's binary_logloss: 0.338259\n",
      "[8213]\ttraining's binary_logloss: 0.338227\n",
      "[8214]\ttraining's binary_logloss: 0.338201\n",
      "[8215]\ttraining's binary_logloss: 0.338149\n",
      "[8216]\ttraining's binary_logloss: 0.338125\n",
      "[8217]\ttraining's binary_logloss: 0.338079\n",
      "[8218]\ttraining's binary_logloss: 0.338049\n",
      "[8219]\ttraining's binary_logloss: 0.338022\n",
      "[8220]\ttraining's binary_logloss: 0.337972\n",
      "[8221]\ttraining's binary_logloss: 0.337931\n",
      "[8222]\ttraining's binary_logloss: 0.337893\n",
      "[8223]\ttraining's binary_logloss: 0.337852\n",
      "[8224]\ttraining's binary_logloss: 0.337821\n",
      "[8225]\ttraining's binary_logloss: 0.337794\n",
      "[8226]\ttraining's binary_logloss: 0.337767\n",
      "[8227]\ttraining's binary_logloss: 0.337735\n",
      "[8228]\ttraining's binary_logloss: 0.337708\n",
      "[8229]\ttraining's binary_logloss: 0.337674\n",
      "[8230]\ttraining's binary_logloss: 0.337646\n",
      "[8231]\ttraining's binary_logloss: 0.337623\n",
      "[8232]\ttraining's binary_logloss: 0.337592\n",
      "[8233]\ttraining's binary_logloss: 0.337557\n",
      "[8234]\ttraining's binary_logloss: 0.337528\n",
      "[8235]\ttraining's binary_logloss: 0.337472\n",
      "[8236]\ttraining's binary_logloss: 0.337437\n",
      "[8237]\ttraining's binary_logloss: 0.337397\n",
      "[8238]\ttraining's binary_logloss: 0.337361\n",
      "[8239]\ttraining's binary_logloss: 0.337329\n",
      "[8240]\ttraining's binary_logloss: 0.337293\n",
      "[8241]\ttraining's binary_logloss: 0.337258\n",
      "[8242]\ttraining's binary_logloss: 0.33723\n",
      "[8243]\ttraining's binary_logloss: 0.337209\n",
      "[8244]\ttraining's binary_logloss: 0.337178\n",
      "[8245]\ttraining's binary_logloss: 0.337147\n",
      "[8246]\ttraining's binary_logloss: 0.337106\n",
      "[8247]\ttraining's binary_logloss: 0.337055\n",
      "[8248]\ttraining's binary_logloss: 0.337004\n",
      "[8249]\ttraining's binary_logloss: 0.33697\n",
      "[8250]\ttraining's binary_logloss: 0.336938\n",
      "[8251]\ttraining's binary_logloss: 0.33691\n",
      "[8252]\ttraining's binary_logloss: 0.336876\n",
      "[8253]\ttraining's binary_logloss: 0.336848\n",
      "[8254]\ttraining's binary_logloss: 0.336811\n",
      "[8255]\ttraining's binary_logloss: 0.336783\n",
      "[8256]\ttraining's binary_logloss: 0.33674\n",
      "[8257]\ttraining's binary_logloss: 0.3367\n",
      "[8258]\ttraining's binary_logloss: 0.336673\n",
      "[8259]\ttraining's binary_logloss: 0.336627\n",
      "[8260]\ttraining's binary_logloss: 0.336593\n",
      "[8261]\ttraining's binary_logloss: 0.336561\n",
      "[8262]\ttraining's binary_logloss: 0.336531\n",
      "[8263]\ttraining's binary_logloss: 0.3365\n",
      "[8264]\ttraining's binary_logloss: 0.336464\n",
      "[8265]\ttraining's binary_logloss: 0.336432\n",
      "[8266]\ttraining's binary_logloss: 0.336393\n",
      "[8267]\ttraining's binary_logloss: 0.336374\n",
      "[8268]\ttraining's binary_logloss: 0.336332\n",
      "[8269]\ttraining's binary_logloss: 0.336305\n",
      "[8270]\ttraining's binary_logloss: 0.336283\n",
      "[8271]\ttraining's binary_logloss: 0.336249\n",
      "[8272]\ttraining's binary_logloss: 0.336201\n",
      "[8273]\ttraining's binary_logloss: 0.336173\n",
      "[8274]\ttraining's binary_logloss: 0.336124\n",
      "[8275]\ttraining's binary_logloss: 0.336095\n",
      "[8276]\ttraining's binary_logloss: 0.336053\n",
      "[8277]\ttraining's binary_logloss: 0.336022\n",
      "[8278]\ttraining's binary_logloss: 0.335982\n",
      "[8279]\ttraining's binary_logloss: 0.335952\n",
      "[8280]\ttraining's binary_logloss: 0.335916\n",
      "[8281]\ttraining's binary_logloss: 0.335871\n",
      "[8282]\ttraining's binary_logloss: 0.335848\n",
      "[8283]\ttraining's binary_logloss: 0.335819\n",
      "[8284]\ttraining's binary_logloss: 0.33579\n",
      "[8285]\ttraining's binary_logloss: 0.335762\n",
      "[8286]\ttraining's binary_logloss: 0.335701\n",
      "[8287]\ttraining's binary_logloss: 0.335664\n",
      "[8288]\ttraining's binary_logloss: 0.33562\n",
      "[8289]\ttraining's binary_logloss: 0.335591\n",
      "[8290]\ttraining's binary_logloss: 0.335552\n",
      "[8291]\ttraining's binary_logloss: 0.335524\n",
      "[8292]\ttraining's binary_logloss: 0.335487\n",
      "[8293]\ttraining's binary_logloss: 0.335449\n",
      "[8294]\ttraining's binary_logloss: 0.335411\n",
      "[8295]\ttraining's binary_logloss: 0.335389\n",
      "[8296]\ttraining's binary_logloss: 0.335363\n",
      "[8297]\ttraining's binary_logloss: 0.335343\n",
      "[8298]\ttraining's binary_logloss: 0.335318\n",
      "[8299]\ttraining's binary_logloss: 0.335286\n",
      "[8300]\ttraining's binary_logloss: 0.335239\n",
      "[8301]\ttraining's binary_logloss: 0.335212\n",
      "[8302]\ttraining's binary_logloss: 0.335182\n",
      "[8303]\ttraining's binary_logloss: 0.335159\n",
      "[8304]\ttraining's binary_logloss: 0.335131\n",
      "[8305]\ttraining's binary_logloss: 0.335097\n",
      "[8306]\ttraining's binary_logloss: 0.335065\n",
      "[8307]\ttraining's binary_logloss: 0.335014\n",
      "[8308]\ttraining's binary_logloss: 0.334989\n",
      "[8309]\ttraining's binary_logloss: 0.334944\n",
      "[8310]\ttraining's binary_logloss: 0.334892\n",
      "[8311]\ttraining's binary_logloss: 0.334864\n",
      "[8312]\ttraining's binary_logloss: 0.334829\n",
      "[8313]\ttraining's binary_logloss: 0.334806\n",
      "[8314]\ttraining's binary_logloss: 0.334784\n",
      "[8315]\ttraining's binary_logloss: 0.334746\n",
      "[8316]\ttraining's binary_logloss: 0.334692\n",
      "[8317]\ttraining's binary_logloss: 0.334641\n",
      "[8318]\ttraining's binary_logloss: 0.334588\n",
      "[8319]\ttraining's binary_logloss: 0.334562\n",
      "[8320]\ttraining's binary_logloss: 0.334527\n",
      "[8321]\ttraining's binary_logloss: 0.334506\n",
      "[8322]\ttraining's binary_logloss: 0.334466\n",
      "[8323]\ttraining's binary_logloss: 0.334437\n",
      "[8324]\ttraining's binary_logloss: 0.334401\n",
      "[8325]\ttraining's binary_logloss: 0.33436\n",
      "[8326]\ttraining's binary_logloss: 0.334316\n",
      "[8327]\ttraining's binary_logloss: 0.334273\n",
      "[8328]\ttraining's binary_logloss: 0.334246\n",
      "[8329]\ttraining's binary_logloss: 0.334221\n",
      "[8330]\ttraining's binary_logloss: 0.334178\n",
      "[8331]\ttraining's binary_logloss: 0.33415\n",
      "[8332]\ttraining's binary_logloss: 0.334119\n",
      "[8333]\ttraining's binary_logloss: 0.334089\n",
      "[8334]\ttraining's binary_logloss: 0.334058\n",
      "[8335]\ttraining's binary_logloss: 0.334017\n",
      "[8336]\ttraining's binary_logloss: 0.33397\n",
      "[8337]\ttraining's binary_logloss: 0.333938\n",
      "[8338]\ttraining's binary_logloss: 0.333909\n",
      "[8339]\ttraining's binary_logloss: 0.333885\n",
      "[8340]\ttraining's binary_logloss: 0.333841\n",
      "[8341]\ttraining's binary_logloss: 0.333793\n",
      "[8342]\ttraining's binary_logloss: 0.333758\n",
      "[8343]\ttraining's binary_logloss: 0.333724\n",
      "[8344]\ttraining's binary_logloss: 0.333688\n",
      "[8345]\ttraining's binary_logloss: 0.333661\n",
      "[8346]\ttraining's binary_logloss: 0.333621\n",
      "[8347]\ttraining's binary_logloss: 0.333583\n",
      "[8348]\ttraining's binary_logloss: 0.333546\n",
      "[8349]\ttraining's binary_logloss: 0.333504\n",
      "[8350]\ttraining's binary_logloss: 0.333465\n",
      "[8351]\ttraining's binary_logloss: 0.333428\n",
      "[8352]\ttraining's binary_logloss: 0.333405\n",
      "[8353]\ttraining's binary_logloss: 0.333376\n",
      "[8354]\ttraining's binary_logloss: 0.333347\n",
      "[8355]\ttraining's binary_logloss: 0.33331\n",
      "[8356]\ttraining's binary_logloss: 0.333284\n",
      "[8357]\ttraining's binary_logloss: 0.333259\n",
      "[8358]\ttraining's binary_logloss: 0.33323\n",
      "[8359]\ttraining's binary_logloss: 0.333198\n",
      "[8360]\ttraining's binary_logloss: 0.333168\n",
      "[8361]\ttraining's binary_logloss: 0.333144\n",
      "[8362]\ttraining's binary_logloss: 0.333116\n",
      "[8363]\ttraining's binary_logloss: 0.333074\n",
      "[8364]\ttraining's binary_logloss: 0.333038\n",
      "[8365]\ttraining's binary_logloss: 0.333013\n",
      "[8366]\ttraining's binary_logloss: 0.332985\n",
      "[8367]\ttraining's binary_logloss: 0.332954\n",
      "[8368]\ttraining's binary_logloss: 0.332929\n",
      "[8369]\ttraining's binary_logloss: 0.332896\n",
      "[8370]\ttraining's binary_logloss: 0.332869\n",
      "[8371]\ttraining's binary_logloss: 0.332835\n",
      "[8372]\ttraining's binary_logloss: 0.332807\n",
      "[8373]\ttraining's binary_logloss: 0.332769\n",
      "[8374]\ttraining's binary_logloss: 0.332743\n",
      "[8375]\ttraining's binary_logloss: 0.332721\n",
      "[8376]\ttraining's binary_logloss: 0.33269\n",
      "[8377]\ttraining's binary_logloss: 0.332647\n",
      "[8378]\ttraining's binary_logloss: 0.33261\n",
      "[8379]\ttraining's binary_logloss: 0.332577\n",
      "[8380]\ttraining's binary_logloss: 0.332532\n",
      "[8381]\ttraining's binary_logloss: 0.33251\n",
      "[8382]\ttraining's binary_logloss: 0.332475\n",
      "[8383]\ttraining's binary_logloss: 0.332444\n",
      "[8384]\ttraining's binary_logloss: 0.332413\n",
      "[8385]\ttraining's binary_logloss: 0.332375\n",
      "[8386]\ttraining's binary_logloss: 0.332341\n",
      "[8387]\ttraining's binary_logloss: 0.332313\n",
      "[8388]\ttraining's binary_logloss: 0.332284\n",
      "[8389]\ttraining's binary_logloss: 0.332245\n",
      "[8390]\ttraining's binary_logloss: 0.332216\n",
      "[8391]\ttraining's binary_logloss: 0.33218\n",
      "[8392]\ttraining's binary_logloss: 0.332142\n",
      "[8393]\ttraining's binary_logloss: 0.332101\n",
      "[8394]\ttraining's binary_logloss: 0.332071\n",
      "[8395]\ttraining's binary_logloss: 0.332046\n",
      "[8396]\ttraining's binary_logloss: 0.332005\n",
      "[8397]\ttraining's binary_logloss: 0.331975\n",
      "[8398]\ttraining's binary_logloss: 0.331928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8399]\ttraining's binary_logloss: 0.331881\n",
      "[8400]\ttraining's binary_logloss: 0.331851\n",
      "[8401]\ttraining's binary_logloss: 0.331826\n",
      "[8402]\ttraining's binary_logloss: 0.331785\n",
      "[8403]\ttraining's binary_logloss: 0.331748\n",
      "[8404]\ttraining's binary_logloss: 0.331712\n",
      "[8405]\ttraining's binary_logloss: 0.331681\n",
      "[8406]\ttraining's binary_logloss: 0.33165\n",
      "[8407]\ttraining's binary_logloss: 0.331618\n",
      "[8408]\ttraining's binary_logloss: 0.33159\n",
      "[8409]\ttraining's binary_logloss: 0.33155\n",
      "[8410]\ttraining's binary_logloss: 0.331522\n",
      "[8411]\ttraining's binary_logloss: 0.331489\n",
      "[8412]\ttraining's binary_logloss: 0.331462\n",
      "[8413]\ttraining's binary_logloss: 0.331432\n",
      "[8414]\ttraining's binary_logloss: 0.331398\n",
      "[8415]\ttraining's binary_logloss: 0.331364\n",
      "[8416]\ttraining's binary_logloss: 0.331335\n",
      "[8417]\ttraining's binary_logloss: 0.331295\n",
      "[8418]\ttraining's binary_logloss: 0.331265\n",
      "[8419]\ttraining's binary_logloss: 0.331238\n",
      "[8420]\ttraining's binary_logloss: 0.331202\n",
      "[8421]\ttraining's binary_logloss: 0.331177\n",
      "[8422]\ttraining's binary_logloss: 0.331148\n",
      "[8423]\ttraining's binary_logloss: 0.331125\n",
      "[8424]\ttraining's binary_logloss: 0.331096\n",
      "[8425]\ttraining's binary_logloss: 0.331058\n",
      "[8426]\ttraining's binary_logloss: 0.331031\n",
      "[8427]\ttraining's binary_logloss: 0.331005\n",
      "[8428]\ttraining's binary_logloss: 0.330976\n",
      "[8429]\ttraining's binary_logloss: 0.330947\n",
      "[8430]\ttraining's binary_logloss: 0.330896\n",
      "[8431]\ttraining's binary_logloss: 0.330872\n",
      "[8432]\ttraining's binary_logloss: 0.330841\n",
      "[8433]\ttraining's binary_logloss: 0.330815\n",
      "[8434]\ttraining's binary_logloss: 0.33079\n",
      "[8435]\ttraining's binary_logloss: 0.330762\n",
      "[8436]\ttraining's binary_logloss: 0.330737\n",
      "[8437]\ttraining's binary_logloss: 0.330711\n",
      "[8438]\ttraining's binary_logloss: 0.330674\n",
      "[8439]\ttraining's binary_logloss: 0.330628\n",
      "[8440]\ttraining's binary_logloss: 0.330597\n",
      "[8441]\ttraining's binary_logloss: 0.33057\n",
      "[8442]\ttraining's binary_logloss: 0.330536\n",
      "[8443]\ttraining's binary_logloss: 0.330503\n",
      "[8444]\ttraining's binary_logloss: 0.330477\n",
      "[8445]\ttraining's binary_logloss: 0.330442\n",
      "[8446]\ttraining's binary_logloss: 0.330415\n",
      "[8447]\ttraining's binary_logloss: 0.330391\n",
      "[8448]\ttraining's binary_logloss: 0.33036\n",
      "[8449]\ttraining's binary_logloss: 0.330316\n",
      "[8450]\ttraining's binary_logloss: 0.330275\n",
      "[8451]\ttraining's binary_logloss: 0.33024\n",
      "[8452]\ttraining's binary_logloss: 0.330212\n",
      "[8453]\ttraining's binary_logloss: 0.330172\n",
      "[8454]\ttraining's binary_logloss: 0.330147\n",
      "[8455]\ttraining's binary_logloss: 0.330123\n",
      "[8456]\ttraining's binary_logloss: 0.33009\n",
      "[8457]\ttraining's binary_logloss: 0.33006\n",
      "[8458]\ttraining's binary_logloss: 0.330031\n",
      "[8459]\ttraining's binary_logloss: 0.330002\n",
      "[8460]\ttraining's binary_logloss: 0.329963\n",
      "[8461]\ttraining's binary_logloss: 0.329925\n",
      "[8462]\ttraining's binary_logloss: 0.329863\n",
      "[8463]\ttraining's binary_logloss: 0.329835\n",
      "[8464]\ttraining's binary_logloss: 0.329799\n",
      "[8465]\ttraining's binary_logloss: 0.329776\n",
      "[8466]\ttraining's binary_logloss: 0.329739\n",
      "[8467]\ttraining's binary_logloss: 0.329706\n",
      "[8468]\ttraining's binary_logloss: 0.329681\n",
      "[8469]\ttraining's binary_logloss: 0.329656\n",
      "[8470]\ttraining's binary_logloss: 0.329609\n",
      "[8471]\ttraining's binary_logloss: 0.32958\n",
      "[8472]\ttraining's binary_logloss: 0.329557\n",
      "[8473]\ttraining's binary_logloss: 0.329527\n",
      "[8474]\ttraining's binary_logloss: 0.32949\n",
      "[8475]\ttraining's binary_logloss: 0.32945\n",
      "[8476]\ttraining's binary_logloss: 0.329414\n",
      "[8477]\ttraining's binary_logloss: 0.32939\n",
      "[8478]\ttraining's binary_logloss: 0.329367\n",
      "[8479]\ttraining's binary_logloss: 0.329334\n",
      "[8480]\ttraining's binary_logloss: 0.329304\n",
      "[8481]\ttraining's binary_logloss: 0.329272\n",
      "[8482]\ttraining's binary_logloss: 0.329228\n",
      "[8483]\ttraining's binary_logloss: 0.329197\n",
      "[8484]\ttraining's binary_logloss: 0.329162\n",
      "[8485]\ttraining's binary_logloss: 0.329117\n",
      "[8486]\ttraining's binary_logloss: 0.329085\n",
      "[8487]\ttraining's binary_logloss: 0.32905\n",
      "[8488]\ttraining's binary_logloss: 0.329025\n",
      "[8489]\ttraining's binary_logloss: 0.328994\n",
      "[8490]\ttraining's binary_logloss: 0.328972\n",
      "[8491]\ttraining's binary_logloss: 0.328936\n",
      "[8492]\ttraining's binary_logloss: 0.328908\n",
      "[8493]\ttraining's binary_logloss: 0.32888\n",
      "[8494]\ttraining's binary_logloss: 0.32885\n",
      "[8495]\ttraining's binary_logloss: 0.32882\n",
      "[8496]\ttraining's binary_logloss: 0.328791\n",
      "[8497]\ttraining's binary_logloss: 0.328752\n",
      "[8498]\ttraining's binary_logloss: 0.328731\n",
      "[8499]\ttraining's binary_logloss: 0.328698\n",
      "[8500]\ttraining's binary_logloss: 0.328669\n",
      "[8501]\ttraining's binary_logloss: 0.328644\n",
      "[8502]\ttraining's binary_logloss: 0.328612\n",
      "[8503]\ttraining's binary_logloss: 0.328583\n",
      "[8504]\ttraining's binary_logloss: 0.328556\n",
      "[8505]\ttraining's binary_logloss: 0.32853\n",
      "[8506]\ttraining's binary_logloss: 0.328496\n",
      "[8507]\ttraining's binary_logloss: 0.32847\n",
      "[8508]\ttraining's binary_logloss: 0.328446\n",
      "[8509]\ttraining's binary_logloss: 0.328416\n",
      "[8510]\ttraining's binary_logloss: 0.328387\n",
      "[8511]\ttraining's binary_logloss: 0.328366\n",
      "[8512]\ttraining's binary_logloss: 0.32833\n",
      "[8513]\ttraining's binary_logloss: 0.328295\n",
      "[8514]\ttraining's binary_logloss: 0.328248\n",
      "[8515]\ttraining's binary_logloss: 0.328205\n",
      "[8516]\ttraining's binary_logloss: 0.328169\n",
      "[8517]\ttraining's binary_logloss: 0.328144\n",
      "[8518]\ttraining's binary_logloss: 0.328124\n",
      "[8519]\ttraining's binary_logloss: 0.328095\n",
      "[8520]\ttraining's binary_logloss: 0.328058\n",
      "[8521]\ttraining's binary_logloss: 0.328032\n",
      "[8522]\ttraining's binary_logloss: 0.328005\n",
      "[8523]\ttraining's binary_logloss: 0.327985\n",
      "[8524]\ttraining's binary_logloss: 0.327951\n",
      "[8525]\ttraining's binary_logloss: 0.327921\n",
      "[8526]\ttraining's binary_logloss: 0.327889\n",
      "[8527]\ttraining's binary_logloss: 0.327861\n",
      "[8528]\ttraining's binary_logloss: 0.327825\n",
      "[8529]\ttraining's binary_logloss: 0.327794\n",
      "[8530]\ttraining's binary_logloss: 0.327763\n",
      "[8531]\ttraining's binary_logloss: 0.327737\n",
      "[8532]\ttraining's binary_logloss: 0.3277\n",
      "[8533]\ttraining's binary_logloss: 0.327668\n",
      "[8534]\ttraining's binary_logloss: 0.327631\n",
      "[8535]\ttraining's binary_logloss: 0.327607\n",
      "[8536]\ttraining's binary_logloss: 0.327577\n",
      "[8537]\ttraining's binary_logloss: 0.327548\n",
      "[8538]\ttraining's binary_logloss: 0.327521\n",
      "[8539]\ttraining's binary_logloss: 0.327486\n",
      "[8540]\ttraining's binary_logloss: 0.327458\n",
      "[8541]\ttraining's binary_logloss: 0.327437\n",
      "[8542]\ttraining's binary_logloss: 0.327411\n",
      "[8543]\ttraining's binary_logloss: 0.327373\n",
      "[8544]\ttraining's binary_logloss: 0.32734\n",
      "[8545]\ttraining's binary_logloss: 0.327305\n",
      "[8546]\ttraining's binary_logloss: 0.327275\n",
      "[8547]\ttraining's binary_logloss: 0.327251\n",
      "[8548]\ttraining's binary_logloss: 0.327215\n",
      "[8549]\ttraining's binary_logloss: 0.327191\n",
      "[8550]\ttraining's binary_logloss: 0.327168\n",
      "[8551]\ttraining's binary_logloss: 0.327152\n",
      "[8552]\ttraining's binary_logloss: 0.327107\n",
      "[8553]\ttraining's binary_logloss: 0.327071\n",
      "[8554]\ttraining's binary_logloss: 0.327048\n",
      "[8555]\ttraining's binary_logloss: 0.327008\n",
      "[8556]\ttraining's binary_logloss: 0.326986\n",
      "[8557]\ttraining's binary_logloss: 0.326949\n",
      "[8558]\ttraining's binary_logloss: 0.326911\n",
      "[8559]\ttraining's binary_logloss: 0.32688\n",
      "[8560]\ttraining's binary_logloss: 0.326846\n",
      "[8561]\ttraining's binary_logloss: 0.326817\n",
      "[8562]\ttraining's binary_logloss: 0.326784\n",
      "[8563]\ttraining's binary_logloss: 0.326745\n",
      "[8564]\ttraining's binary_logloss: 0.326695\n",
      "[8565]\ttraining's binary_logloss: 0.326665\n",
      "[8566]\ttraining's binary_logloss: 0.326626\n",
      "[8567]\ttraining's binary_logloss: 0.32661\n",
      "[8568]\ttraining's binary_logloss: 0.326569\n",
      "[8569]\ttraining's binary_logloss: 0.326549\n",
      "[8570]\ttraining's binary_logloss: 0.326506\n",
      "[8571]\ttraining's binary_logloss: 0.326465\n",
      "[8572]\ttraining's binary_logloss: 0.326419\n",
      "[8573]\ttraining's binary_logloss: 0.326388\n",
      "[8574]\ttraining's binary_logloss: 0.326365\n",
      "[8575]\ttraining's binary_logloss: 0.326333\n",
      "[8576]\ttraining's binary_logloss: 0.326303\n",
      "[8577]\ttraining's binary_logloss: 0.326268\n",
      "[8578]\ttraining's binary_logloss: 0.326232\n",
      "[8579]\ttraining's binary_logloss: 0.326202\n",
      "[8580]\ttraining's binary_logloss: 0.326178\n",
      "[8581]\ttraining's binary_logloss: 0.326148\n",
      "[8582]\ttraining's binary_logloss: 0.326128\n",
      "[8583]\ttraining's binary_logloss: 0.326097\n",
      "[8584]\ttraining's binary_logloss: 0.326073\n",
      "[8585]\ttraining's binary_logloss: 0.326035\n",
      "[8586]\ttraining's binary_logloss: 0.326003\n",
      "[8587]\ttraining's binary_logloss: 0.325968\n",
      "[8588]\ttraining's binary_logloss: 0.325922\n",
      "[8589]\ttraining's binary_logloss: 0.32589\n",
      "[8590]\ttraining's binary_logloss: 0.325837\n",
      "[8591]\ttraining's binary_logloss: 0.325808\n",
      "[8592]\ttraining's binary_logloss: 0.32577\n",
      "[8593]\ttraining's binary_logloss: 0.325731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8594]\ttraining's binary_logloss: 0.325684\n",
      "[8595]\ttraining's binary_logloss: 0.325645\n",
      "[8596]\ttraining's binary_logloss: 0.325612\n",
      "[8597]\ttraining's binary_logloss: 0.325573\n",
      "[8598]\ttraining's binary_logloss: 0.325548\n",
      "[8599]\ttraining's binary_logloss: 0.3255\n",
      "[8600]\ttraining's binary_logloss: 0.325474\n",
      "[8601]\ttraining's binary_logloss: 0.325432\n",
      "[8602]\ttraining's binary_logloss: 0.325409\n",
      "[8603]\ttraining's binary_logloss: 0.325377\n",
      "[8604]\ttraining's binary_logloss: 0.325345\n",
      "[8605]\ttraining's binary_logloss: 0.325308\n",
      "[8606]\ttraining's binary_logloss: 0.325279\n",
      "[8607]\ttraining's binary_logloss: 0.325252\n",
      "[8608]\ttraining's binary_logloss: 0.325213\n",
      "[8609]\ttraining's binary_logloss: 0.325186\n",
      "[8610]\ttraining's binary_logloss: 0.325161\n",
      "[8611]\ttraining's binary_logloss: 0.32513\n",
      "[8612]\ttraining's binary_logloss: 0.325105\n",
      "[8613]\ttraining's binary_logloss: 0.32507\n",
      "[8614]\ttraining's binary_logloss: 0.32503\n",
      "[8615]\ttraining's binary_logloss: 0.325005\n",
      "[8616]\ttraining's binary_logloss: 0.324963\n",
      "[8617]\ttraining's binary_logloss: 0.324937\n",
      "[8618]\ttraining's binary_logloss: 0.324907\n",
      "[8619]\ttraining's binary_logloss: 0.324883\n",
      "[8620]\ttraining's binary_logloss: 0.324858\n",
      "[8621]\ttraining's binary_logloss: 0.324828\n",
      "[8622]\ttraining's binary_logloss: 0.324794\n",
      "[8623]\ttraining's binary_logloss: 0.324766\n",
      "[8624]\ttraining's binary_logloss: 0.32474\n",
      "[8625]\ttraining's binary_logloss: 0.324713\n",
      "[8626]\ttraining's binary_logloss: 0.32468\n",
      "[8627]\ttraining's binary_logloss: 0.324648\n",
      "[8628]\ttraining's binary_logloss: 0.324615\n",
      "[8629]\ttraining's binary_logloss: 0.324583\n",
      "[8630]\ttraining's binary_logloss: 0.324545\n",
      "[8631]\ttraining's binary_logloss: 0.324511\n",
      "[8632]\ttraining's binary_logloss: 0.324483\n",
      "[8633]\ttraining's binary_logloss: 0.324455\n",
      "[8634]\ttraining's binary_logloss: 0.324416\n",
      "[8635]\ttraining's binary_logloss: 0.324373\n",
      "[8636]\ttraining's binary_logloss: 0.324335\n",
      "[8637]\ttraining's binary_logloss: 0.324306\n",
      "[8638]\ttraining's binary_logloss: 0.32426\n",
      "[8639]\ttraining's binary_logloss: 0.324235\n",
      "[8640]\ttraining's binary_logloss: 0.324211\n",
      "[8641]\ttraining's binary_logloss: 0.324193\n",
      "[8642]\ttraining's binary_logloss: 0.324168\n",
      "[8643]\ttraining's binary_logloss: 0.324131\n",
      "[8644]\ttraining's binary_logloss: 0.324104\n",
      "[8645]\ttraining's binary_logloss: 0.324071\n",
      "[8646]\ttraining's binary_logloss: 0.324041\n",
      "[8647]\ttraining's binary_logloss: 0.324002\n",
      "[8648]\ttraining's binary_logloss: 0.323953\n",
      "[8649]\ttraining's binary_logloss: 0.323918\n",
      "[8650]\ttraining's binary_logloss: 0.323882\n",
      "[8651]\ttraining's binary_logloss: 0.323859\n",
      "[8652]\ttraining's binary_logloss: 0.323824\n",
      "[8653]\ttraining's binary_logloss: 0.323801\n",
      "[8654]\ttraining's binary_logloss: 0.323773\n",
      "[8655]\ttraining's binary_logloss: 0.323745\n",
      "[8656]\ttraining's binary_logloss: 0.323721\n",
      "[8657]\ttraining's binary_logloss: 0.323688\n",
      "[8658]\ttraining's binary_logloss: 0.323667\n",
      "[8659]\ttraining's binary_logloss: 0.323641\n",
      "[8660]\ttraining's binary_logloss: 0.323617\n",
      "[8661]\ttraining's binary_logloss: 0.323588\n",
      "[8662]\ttraining's binary_logloss: 0.323553\n",
      "[8663]\ttraining's binary_logloss: 0.323514\n",
      "[8664]\ttraining's binary_logloss: 0.323493\n",
      "[8665]\ttraining's binary_logloss: 0.323445\n",
      "[8666]\ttraining's binary_logloss: 0.323411\n",
      "[8667]\ttraining's binary_logloss: 0.323387\n",
      "[8668]\ttraining's binary_logloss: 0.323355\n",
      "[8669]\ttraining's binary_logloss: 0.323326\n",
      "[8670]\ttraining's binary_logloss: 0.323281\n",
      "[8671]\ttraining's binary_logloss: 0.323252\n",
      "[8672]\ttraining's binary_logloss: 0.323227\n",
      "[8673]\ttraining's binary_logloss: 0.323199\n",
      "[8674]\ttraining's binary_logloss: 0.323163\n",
      "[8675]\ttraining's binary_logloss: 0.323126\n",
      "[8676]\ttraining's binary_logloss: 0.323097\n",
      "[8677]\ttraining's binary_logloss: 0.323079\n",
      "[8678]\ttraining's binary_logloss: 0.323054\n",
      "[8679]\ttraining's binary_logloss: 0.323014\n",
      "[8680]\ttraining's binary_logloss: 0.322983\n",
      "[8681]\ttraining's binary_logloss: 0.322947\n",
      "[8682]\ttraining's binary_logloss: 0.322923\n",
      "[8683]\ttraining's binary_logloss: 0.322899\n",
      "[8684]\ttraining's binary_logloss: 0.322868\n",
      "[8685]\ttraining's binary_logloss: 0.322847\n",
      "[8686]\ttraining's binary_logloss: 0.322818\n",
      "[8687]\ttraining's binary_logloss: 0.322794\n",
      "[8688]\ttraining's binary_logloss: 0.322775\n",
      "[8689]\ttraining's binary_logloss: 0.322736\n",
      "[8690]\ttraining's binary_logloss: 0.32271\n",
      "[8691]\ttraining's binary_logloss: 0.322678\n",
      "[8692]\ttraining's binary_logloss: 0.322624\n",
      "[8693]\ttraining's binary_logloss: 0.32259\n",
      "[8694]\ttraining's binary_logloss: 0.322568\n",
      "[8695]\ttraining's binary_logloss: 0.322532\n",
      "[8696]\ttraining's binary_logloss: 0.322497\n",
      "[8697]\ttraining's binary_logloss: 0.32247\n",
      "[8698]\ttraining's binary_logloss: 0.322443\n",
      "[8699]\ttraining's binary_logloss: 0.322412\n",
      "[8700]\ttraining's binary_logloss: 0.322386\n",
      "[8701]\ttraining's binary_logloss: 0.322372\n",
      "[8702]\ttraining's binary_logloss: 0.322332\n",
      "[8703]\ttraining's binary_logloss: 0.322296\n",
      "[8704]\ttraining's binary_logloss: 0.322269\n",
      "[8705]\ttraining's binary_logloss: 0.322235\n",
      "[8706]\ttraining's binary_logloss: 0.322206\n",
      "[8707]\ttraining's binary_logloss: 0.322176\n",
      "[8708]\ttraining's binary_logloss: 0.322148\n",
      "[8709]\ttraining's binary_logloss: 0.322104\n",
      "[8710]\ttraining's binary_logloss: 0.322065\n",
      "[8711]\ttraining's binary_logloss: 0.32204\n",
      "[8712]\ttraining's binary_logloss: 0.322006\n",
      "[8713]\ttraining's binary_logloss: 0.321977\n",
      "[8714]\ttraining's binary_logloss: 0.321934\n",
      "[8715]\ttraining's binary_logloss: 0.321891\n",
      "[8716]\ttraining's binary_logloss: 0.321862\n",
      "[8717]\ttraining's binary_logloss: 0.321835\n",
      "[8718]\ttraining's binary_logloss: 0.321811\n",
      "[8719]\ttraining's binary_logloss: 0.321786\n",
      "[8720]\ttraining's binary_logloss: 0.321751\n",
      "[8721]\ttraining's binary_logloss: 0.321721\n",
      "[8722]\ttraining's binary_logloss: 0.321686\n",
      "[8723]\ttraining's binary_logloss: 0.321651\n",
      "[8724]\ttraining's binary_logloss: 0.321627\n",
      "[8725]\ttraining's binary_logloss: 0.321598\n",
      "[8726]\ttraining's binary_logloss: 0.321565\n",
      "[8727]\ttraining's binary_logloss: 0.321535\n",
      "[8728]\ttraining's binary_logloss: 0.321483\n",
      "[8729]\ttraining's binary_logloss: 0.321454\n",
      "[8730]\ttraining's binary_logloss: 0.32142\n",
      "[8731]\ttraining's binary_logloss: 0.321393\n",
      "[8732]\ttraining's binary_logloss: 0.321364\n",
      "[8733]\ttraining's binary_logloss: 0.321334\n",
      "[8734]\ttraining's binary_logloss: 0.321313\n",
      "[8735]\ttraining's binary_logloss: 0.321279\n",
      "[8736]\ttraining's binary_logloss: 0.321256\n",
      "[8737]\ttraining's binary_logloss: 0.321232\n",
      "[8738]\ttraining's binary_logloss: 0.321193\n",
      "[8739]\ttraining's binary_logloss: 0.321161\n",
      "[8740]\ttraining's binary_logloss: 0.321134\n",
      "[8741]\ttraining's binary_logloss: 0.321096\n",
      "[8742]\ttraining's binary_logloss: 0.321063\n",
      "[8743]\ttraining's binary_logloss: 0.321045\n",
      "[8744]\ttraining's binary_logloss: 0.32101\n",
      "[8745]\ttraining's binary_logloss: 0.32098\n",
      "[8746]\ttraining's binary_logloss: 0.320945\n",
      "[8747]\ttraining's binary_logloss: 0.320913\n",
      "[8748]\ttraining's binary_logloss: 0.320879\n",
      "[8749]\ttraining's binary_logloss: 0.320856\n",
      "[8750]\ttraining's binary_logloss: 0.32083\n",
      "[8751]\ttraining's binary_logloss: 0.320786\n",
      "[8752]\ttraining's binary_logloss: 0.320757\n",
      "[8753]\ttraining's binary_logloss: 0.320735\n",
      "[8754]\ttraining's binary_logloss: 0.320712\n",
      "[8755]\ttraining's binary_logloss: 0.320676\n",
      "[8756]\ttraining's binary_logloss: 0.32064\n",
      "[8757]\ttraining's binary_logloss: 0.320619\n",
      "[8758]\ttraining's binary_logloss: 0.320588\n",
      "[8759]\ttraining's binary_logloss: 0.320556\n",
      "[8760]\ttraining's binary_logloss: 0.320529\n",
      "[8761]\ttraining's binary_logloss: 0.320501\n",
      "[8762]\ttraining's binary_logloss: 0.320477\n",
      "[8763]\ttraining's binary_logloss: 0.320454\n",
      "[8764]\ttraining's binary_logloss: 0.320417\n",
      "[8765]\ttraining's binary_logloss: 0.320395\n",
      "[8766]\ttraining's binary_logloss: 0.320368\n",
      "[8767]\ttraining's binary_logloss: 0.32034\n",
      "[8768]\ttraining's binary_logloss: 0.320314\n",
      "[8769]\ttraining's binary_logloss: 0.320289\n",
      "[8770]\ttraining's binary_logloss: 0.320261\n",
      "[8771]\ttraining's binary_logloss: 0.320224\n",
      "[8772]\ttraining's binary_logloss: 0.320183\n",
      "[8773]\ttraining's binary_logloss: 0.320127\n",
      "[8774]\ttraining's binary_logloss: 0.320096\n",
      "[8775]\ttraining's binary_logloss: 0.320068\n",
      "[8776]\ttraining's binary_logloss: 0.32003\n",
      "[8777]\ttraining's binary_logloss: 0.320002\n",
      "[8778]\ttraining's binary_logloss: 0.319968\n",
      "[8779]\ttraining's binary_logloss: 0.319936\n",
      "[8780]\ttraining's binary_logloss: 0.319921\n",
      "[8781]\ttraining's binary_logloss: 0.319881\n",
      "[8782]\ttraining's binary_logloss: 0.319854\n",
      "[8783]\ttraining's binary_logloss: 0.319815\n",
      "[8784]\ttraining's binary_logloss: 0.319789\n",
      "[8785]\ttraining's binary_logloss: 0.319754\n",
      "[8786]\ttraining's binary_logloss: 0.319723\n",
      "[8787]\ttraining's binary_logloss: 0.319702\n",
      "[8788]\ttraining's binary_logloss: 0.319652\n",
      "[8789]\ttraining's binary_logloss: 0.319627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8790]\ttraining's binary_logloss: 0.319604\n",
      "[8791]\ttraining's binary_logloss: 0.319575\n",
      "[8792]\ttraining's binary_logloss: 0.319548\n",
      "[8793]\ttraining's binary_logloss: 0.319518\n",
      "[8794]\ttraining's binary_logloss: 0.319491\n",
      "[8795]\ttraining's binary_logloss: 0.319459\n",
      "[8796]\ttraining's binary_logloss: 0.31942\n",
      "[8797]\ttraining's binary_logloss: 0.319385\n",
      "[8798]\ttraining's binary_logloss: 0.319355\n",
      "[8799]\ttraining's binary_logloss: 0.319321\n",
      "[8800]\ttraining's binary_logloss: 0.319293\n",
      "[8801]\ttraining's binary_logloss: 0.319268\n",
      "[8802]\ttraining's binary_logloss: 0.319242\n",
      "[8803]\ttraining's binary_logloss: 0.319209\n",
      "[8804]\ttraining's binary_logloss: 0.319174\n",
      "[8805]\ttraining's binary_logloss: 0.319146\n",
      "[8806]\ttraining's binary_logloss: 0.31912\n",
      "[8807]\ttraining's binary_logloss: 0.319089\n",
      "[8808]\ttraining's binary_logloss: 0.319061\n",
      "[8809]\ttraining's binary_logloss: 0.319039\n",
      "[8810]\ttraining's binary_logloss: 0.319007\n",
      "[8811]\ttraining's binary_logloss: 0.31897\n",
      "[8812]\ttraining's binary_logloss: 0.318945\n",
      "[8813]\ttraining's binary_logloss: 0.318908\n",
      "[8814]\ttraining's binary_logloss: 0.318843\n",
      "[8815]\ttraining's binary_logloss: 0.318812\n",
      "[8816]\ttraining's binary_logloss: 0.31878\n",
      "[8817]\ttraining's binary_logloss: 0.318755\n",
      "[8818]\ttraining's binary_logloss: 0.318718\n",
      "[8819]\ttraining's binary_logloss: 0.31868\n",
      "[8820]\ttraining's binary_logloss: 0.318644\n",
      "[8821]\ttraining's binary_logloss: 0.318618\n",
      "[8822]\ttraining's binary_logloss: 0.318594\n",
      "[8823]\ttraining's binary_logloss: 0.318567\n",
      "[8824]\ttraining's binary_logloss: 0.318545\n",
      "[8825]\ttraining's binary_logloss: 0.318508\n",
      "[8826]\ttraining's binary_logloss: 0.318471\n",
      "[8827]\ttraining's binary_logloss: 0.318461\n",
      "[8828]\ttraining's binary_logloss: 0.318429\n",
      "[8829]\ttraining's binary_logloss: 0.318406\n",
      "[8830]\ttraining's binary_logloss: 0.318379\n",
      "[8831]\ttraining's binary_logloss: 0.31835\n",
      "[8832]\ttraining's binary_logloss: 0.318328\n",
      "[8833]\ttraining's binary_logloss: 0.318299\n",
      "[8834]\ttraining's binary_logloss: 0.318274\n",
      "[8835]\ttraining's binary_logloss: 0.318241\n",
      "[8836]\ttraining's binary_logloss: 0.318218\n",
      "[8837]\ttraining's binary_logloss: 0.3182\n",
      "[8838]\ttraining's binary_logloss: 0.318181\n",
      "[8839]\ttraining's binary_logloss: 0.318136\n",
      "[8840]\ttraining's binary_logloss: 0.318104\n",
      "[8841]\ttraining's binary_logloss: 0.318079\n",
      "[8842]\ttraining's binary_logloss: 0.318058\n",
      "[8843]\ttraining's binary_logloss: 0.318026\n",
      "[8844]\ttraining's binary_logloss: 0.31798\n",
      "[8845]\ttraining's binary_logloss: 0.317931\n",
      "[8846]\ttraining's binary_logloss: 0.317894\n",
      "[8847]\ttraining's binary_logloss: 0.317863\n",
      "[8848]\ttraining's binary_logloss: 0.317835\n",
      "[8849]\ttraining's binary_logloss: 0.317794\n",
      "[8850]\ttraining's binary_logloss: 0.317765\n",
      "[8851]\ttraining's binary_logloss: 0.317735\n",
      "[8852]\ttraining's binary_logloss: 0.317699\n",
      "[8853]\ttraining's binary_logloss: 0.317674\n",
      "[8854]\ttraining's binary_logloss: 0.317636\n",
      "[8855]\ttraining's binary_logloss: 0.317597\n",
      "[8856]\ttraining's binary_logloss: 0.317579\n",
      "[8857]\ttraining's binary_logloss: 0.31754\n",
      "[8858]\ttraining's binary_logloss: 0.317512\n",
      "[8859]\ttraining's binary_logloss: 0.317488\n",
      "[8860]\ttraining's binary_logloss: 0.317461\n",
      "[8861]\ttraining's binary_logloss: 0.317435\n",
      "[8862]\ttraining's binary_logloss: 0.317403\n",
      "[8863]\ttraining's binary_logloss: 0.317373\n",
      "[8864]\ttraining's binary_logloss: 0.317328\n",
      "[8865]\ttraining's binary_logloss: 0.317299\n",
      "[8866]\ttraining's binary_logloss: 0.31727\n",
      "[8867]\ttraining's binary_logloss: 0.317254\n",
      "[8868]\ttraining's binary_logloss: 0.317224\n",
      "[8869]\ttraining's binary_logloss: 0.3172\n",
      "[8870]\ttraining's binary_logloss: 0.317177\n",
      "[8871]\ttraining's binary_logloss: 0.317147\n",
      "[8872]\ttraining's binary_logloss: 0.317113\n",
      "[8873]\ttraining's binary_logloss: 0.317079\n",
      "[8874]\ttraining's binary_logloss: 0.317021\n",
      "[8875]\ttraining's binary_logloss: 0.316987\n",
      "[8876]\ttraining's binary_logloss: 0.316959\n",
      "[8877]\ttraining's binary_logloss: 0.316933\n",
      "[8878]\ttraining's binary_logloss: 0.316908\n",
      "[8879]\ttraining's binary_logloss: 0.316888\n",
      "[8880]\ttraining's binary_logloss: 0.316858\n",
      "[8881]\ttraining's binary_logloss: 0.316835\n",
      "[8882]\ttraining's binary_logloss: 0.316797\n",
      "[8883]\ttraining's binary_logloss: 0.316767\n",
      "[8884]\ttraining's binary_logloss: 0.31674\n",
      "[8885]\ttraining's binary_logloss: 0.316714\n",
      "[8886]\ttraining's binary_logloss: 0.316693\n",
      "[8887]\ttraining's binary_logloss: 0.316659\n",
      "[8888]\ttraining's binary_logloss: 0.316631\n",
      "[8889]\ttraining's binary_logloss: 0.316584\n",
      "[8890]\ttraining's binary_logloss: 0.316547\n",
      "[8891]\ttraining's binary_logloss: 0.316514\n",
      "[8892]\ttraining's binary_logloss: 0.316481\n",
      "[8893]\ttraining's binary_logloss: 0.316457\n",
      "[8894]\ttraining's binary_logloss: 0.316427\n",
      "[8895]\ttraining's binary_logloss: 0.316379\n",
      "[8896]\ttraining's binary_logloss: 0.316349\n",
      "[8897]\ttraining's binary_logloss: 0.316314\n",
      "[8898]\ttraining's binary_logloss: 0.316286\n",
      "[8899]\ttraining's binary_logloss: 0.316252\n",
      "[8900]\ttraining's binary_logloss: 0.316232\n",
      "[8901]\ttraining's binary_logloss: 0.316199\n",
      "[8902]\ttraining's binary_logloss: 0.31617\n",
      "[8903]\ttraining's binary_logloss: 0.316142\n",
      "[8904]\ttraining's binary_logloss: 0.316116\n",
      "[8905]\ttraining's binary_logloss: 0.316097\n",
      "[8906]\ttraining's binary_logloss: 0.31607\n",
      "[8907]\ttraining's binary_logloss: 0.316038\n",
      "[8908]\ttraining's binary_logloss: 0.316013\n",
      "[8909]\ttraining's binary_logloss: 0.315984\n",
      "[8910]\ttraining's binary_logloss: 0.315955\n",
      "[8911]\ttraining's binary_logloss: 0.315927\n",
      "[8912]\ttraining's binary_logloss: 0.315891\n",
      "[8913]\ttraining's binary_logloss: 0.315865\n",
      "[8914]\ttraining's binary_logloss: 0.315839\n",
      "[8915]\ttraining's binary_logloss: 0.315811\n",
      "[8916]\ttraining's binary_logloss: 0.315782\n",
      "[8917]\ttraining's binary_logloss: 0.315758\n",
      "[8918]\ttraining's binary_logloss: 0.315728\n",
      "[8919]\ttraining's binary_logloss: 0.315692\n",
      "[8920]\ttraining's binary_logloss: 0.31566\n",
      "[8921]\ttraining's binary_logloss: 0.315636\n",
      "[8922]\ttraining's binary_logloss: 0.315613\n",
      "[8923]\ttraining's binary_logloss: 0.315592\n",
      "[8924]\ttraining's binary_logloss: 0.315569\n",
      "[8925]\ttraining's binary_logloss: 0.31554\n",
      "[8926]\ttraining's binary_logloss: 0.315508\n",
      "[8927]\ttraining's binary_logloss: 0.315481\n",
      "[8928]\ttraining's binary_logloss: 0.315454\n",
      "[8929]\ttraining's binary_logloss: 0.315413\n",
      "[8930]\ttraining's binary_logloss: 0.315379\n",
      "[8931]\ttraining's binary_logloss: 0.315346\n",
      "[8932]\ttraining's binary_logloss: 0.315288\n",
      "[8933]\ttraining's binary_logloss: 0.315264\n",
      "[8934]\ttraining's binary_logloss: 0.315231\n",
      "[8935]\ttraining's binary_logloss: 0.315195\n",
      "[8936]\ttraining's binary_logloss: 0.315163\n",
      "[8937]\ttraining's binary_logloss: 0.31514\n",
      "[8938]\ttraining's binary_logloss: 0.31509\n",
      "[8939]\ttraining's binary_logloss: 0.315056\n",
      "[8940]\ttraining's binary_logloss: 0.315022\n",
      "[8941]\ttraining's binary_logloss: 0.31499\n",
      "[8942]\ttraining's binary_logloss: 0.314969\n",
      "[8943]\ttraining's binary_logloss: 0.314944\n",
      "[8944]\ttraining's binary_logloss: 0.31492\n",
      "[8945]\ttraining's binary_logloss: 0.314894\n",
      "[8946]\ttraining's binary_logloss: 0.314866\n",
      "[8947]\ttraining's binary_logloss: 0.314845\n",
      "[8948]\ttraining's binary_logloss: 0.314825\n",
      "[8949]\ttraining's binary_logloss: 0.314793\n",
      "[8950]\ttraining's binary_logloss: 0.314764\n",
      "[8951]\ttraining's binary_logloss: 0.314733\n",
      "[8952]\ttraining's binary_logloss: 0.314707\n",
      "[8953]\ttraining's binary_logloss: 0.314683\n",
      "[8954]\ttraining's binary_logloss: 0.314653\n",
      "[8955]\ttraining's binary_logloss: 0.314623\n",
      "[8956]\ttraining's binary_logloss: 0.314591\n",
      "[8957]\ttraining's binary_logloss: 0.314564\n",
      "[8958]\ttraining's binary_logloss: 0.314545\n",
      "[8959]\ttraining's binary_logloss: 0.314509\n",
      "[8960]\ttraining's binary_logloss: 0.314481\n",
      "[8961]\ttraining's binary_logloss: 0.314443\n",
      "[8962]\ttraining's binary_logloss: 0.314412\n",
      "[8963]\ttraining's binary_logloss: 0.314383\n",
      "[8964]\ttraining's binary_logloss: 0.314361\n",
      "[8965]\ttraining's binary_logloss: 0.314334\n",
      "[8966]\ttraining's binary_logloss: 0.314314\n",
      "[8967]\ttraining's binary_logloss: 0.314275\n",
      "[8968]\ttraining's binary_logloss: 0.314247\n",
      "[8969]\ttraining's binary_logloss: 0.31422\n",
      "[8970]\ttraining's binary_logloss: 0.314183\n",
      "[8971]\ttraining's binary_logloss: 0.314139\n",
      "[8972]\ttraining's binary_logloss: 0.314108\n",
      "[8973]\ttraining's binary_logloss: 0.314075\n",
      "[8974]\ttraining's binary_logloss: 0.314048\n",
      "[8975]\ttraining's binary_logloss: 0.314019\n",
      "[8976]\ttraining's binary_logloss: 0.313984\n",
      "[8977]\ttraining's binary_logloss: 0.313954\n",
      "[8978]\ttraining's binary_logloss: 0.313921\n",
      "[8979]\ttraining's binary_logloss: 0.313892\n",
      "[8980]\ttraining's binary_logloss: 0.313873\n",
      "[8981]\ttraining's binary_logloss: 0.31383\n",
      "[8982]\ttraining's binary_logloss: 0.313781\n",
      "[8983]\ttraining's binary_logloss: 0.313759\n",
      "[8984]\ttraining's binary_logloss: 0.313729\n",
      "[8985]\ttraining's binary_logloss: 0.313695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8986]\ttraining's binary_logloss: 0.313659\n",
      "[8987]\ttraining's binary_logloss: 0.313632\n",
      "[8988]\ttraining's binary_logloss: 0.313603\n",
      "[8989]\ttraining's binary_logloss: 0.313572\n",
      "[8990]\ttraining's binary_logloss: 0.313553\n",
      "[8991]\ttraining's binary_logloss: 0.313519\n",
      "[8992]\ttraining's binary_logloss: 0.313476\n",
      "[8993]\ttraining's binary_logloss: 0.313434\n",
      "[8994]\ttraining's binary_logloss: 0.313395\n",
      "[8995]\ttraining's binary_logloss: 0.313371\n",
      "[8996]\ttraining's binary_logloss: 0.313335\n",
      "[8997]\ttraining's binary_logloss: 0.313313\n",
      "[8998]\ttraining's binary_logloss: 0.313277\n",
      "[8999]\ttraining's binary_logloss: 0.313253\n",
      "[9000]\ttraining's binary_logloss: 0.313225\n",
      "[9001]\ttraining's binary_logloss: 0.313201\n",
      "[9002]\ttraining's binary_logloss: 0.313172\n",
      "[9003]\ttraining's binary_logloss: 0.313142\n",
      "[9004]\ttraining's binary_logloss: 0.31311\n",
      "[9005]\ttraining's binary_logloss: 0.313075\n",
      "[9006]\ttraining's binary_logloss: 0.313046\n",
      "[9007]\ttraining's binary_logloss: 0.313021\n",
      "[9008]\ttraining's binary_logloss: 0.312997\n",
      "[9009]\ttraining's binary_logloss: 0.312974\n",
      "[9010]\ttraining's binary_logloss: 0.312946\n",
      "[9011]\ttraining's binary_logloss: 0.312922\n",
      "[9012]\ttraining's binary_logloss: 0.312897\n",
      "[9013]\ttraining's binary_logloss: 0.312867\n",
      "[9014]\ttraining's binary_logloss: 0.312834\n",
      "[9015]\ttraining's binary_logloss: 0.312796\n",
      "[9016]\ttraining's binary_logloss: 0.312765\n",
      "[9017]\ttraining's binary_logloss: 0.312732\n",
      "[9018]\ttraining's binary_logloss: 0.312709\n",
      "[9019]\ttraining's binary_logloss: 0.312682\n",
      "[9020]\ttraining's binary_logloss: 0.312654\n",
      "[9021]\ttraining's binary_logloss: 0.312631\n",
      "[9022]\ttraining's binary_logloss: 0.312597\n",
      "[9023]\ttraining's binary_logloss: 0.312566\n",
      "[9024]\ttraining's binary_logloss: 0.312522\n",
      "[9025]\ttraining's binary_logloss: 0.3125\n",
      "[9026]\ttraining's binary_logloss: 0.312474\n",
      "[9027]\ttraining's binary_logloss: 0.312442\n",
      "[9028]\ttraining's binary_logloss: 0.312419\n",
      "[9029]\ttraining's binary_logloss: 0.312387\n",
      "[9030]\ttraining's binary_logloss: 0.312363\n",
      "[9031]\ttraining's binary_logloss: 0.312329\n",
      "[9032]\ttraining's binary_logloss: 0.312297\n",
      "[9033]\ttraining's binary_logloss: 0.312246\n",
      "[9034]\ttraining's binary_logloss: 0.312223\n",
      "[9035]\ttraining's binary_logloss: 0.312197\n",
      "[9036]\ttraining's binary_logloss: 0.312156\n",
      "[9037]\ttraining's binary_logloss: 0.312124\n",
      "[9038]\ttraining's binary_logloss: 0.312079\n",
      "[9039]\ttraining's binary_logloss: 0.312053\n",
      "[9040]\ttraining's binary_logloss: 0.312017\n",
      "[9041]\ttraining's binary_logloss: 0.311993\n",
      "[9042]\ttraining's binary_logloss: 0.311976\n",
      "[9043]\ttraining's binary_logloss: 0.311939\n",
      "[9044]\ttraining's binary_logloss: 0.311906\n",
      "[9045]\ttraining's binary_logloss: 0.311849\n",
      "[9046]\ttraining's binary_logloss: 0.311805\n",
      "[9047]\ttraining's binary_logloss: 0.311784\n",
      "[9048]\ttraining's binary_logloss: 0.311756\n",
      "[9049]\ttraining's binary_logloss: 0.311736\n",
      "[9050]\ttraining's binary_logloss: 0.311706\n",
      "[9051]\ttraining's binary_logloss: 0.311671\n",
      "[9052]\ttraining's binary_logloss: 0.311648\n",
      "[9053]\ttraining's binary_logloss: 0.311614\n",
      "[9054]\ttraining's binary_logloss: 0.311583\n",
      "[9055]\ttraining's binary_logloss: 0.311546\n",
      "[9056]\ttraining's binary_logloss: 0.311499\n",
      "[9057]\ttraining's binary_logloss: 0.311472\n",
      "[9058]\ttraining's binary_logloss: 0.311441\n",
      "[9059]\ttraining's binary_logloss: 0.311399\n",
      "[9060]\ttraining's binary_logloss: 0.311371\n",
      "[9061]\ttraining's binary_logloss: 0.31134\n",
      "[9062]\ttraining's binary_logloss: 0.311313\n",
      "[9063]\ttraining's binary_logloss: 0.311288\n",
      "[9064]\ttraining's binary_logloss: 0.311251\n",
      "[9065]\ttraining's binary_logloss: 0.311216\n",
      "[9066]\ttraining's binary_logloss: 0.311196\n",
      "[9067]\ttraining's binary_logloss: 0.311152\n",
      "[9068]\ttraining's binary_logloss: 0.311121\n",
      "[9069]\ttraining's binary_logloss: 0.311104\n",
      "[9070]\ttraining's binary_logloss: 0.31109\n",
      "[9071]\ttraining's binary_logloss: 0.311051\n",
      "[9072]\ttraining's binary_logloss: 0.311022\n",
      "[9073]\ttraining's binary_logloss: 0.310997\n",
      "[9074]\ttraining's binary_logloss: 0.310974\n",
      "[9075]\ttraining's binary_logloss: 0.310953\n",
      "[9076]\ttraining's binary_logloss: 0.310921\n",
      "[9077]\ttraining's binary_logloss: 0.31089\n",
      "[9078]\ttraining's binary_logloss: 0.310863\n",
      "[9079]\ttraining's binary_logloss: 0.310837\n",
      "[9080]\ttraining's binary_logloss: 0.310801\n",
      "[9081]\ttraining's binary_logloss: 0.310766\n",
      "[9082]\ttraining's binary_logloss: 0.310733\n",
      "[9083]\ttraining's binary_logloss: 0.310691\n",
      "[9084]\ttraining's binary_logloss: 0.310662\n",
      "[9085]\ttraining's binary_logloss: 0.310629\n",
      "[9086]\ttraining's binary_logloss: 0.310595\n",
      "[9087]\ttraining's binary_logloss: 0.310567\n",
      "[9088]\ttraining's binary_logloss: 0.310529\n",
      "[9089]\ttraining's binary_logloss: 0.310506\n",
      "[9090]\ttraining's binary_logloss: 0.310483\n",
      "[9091]\ttraining's binary_logloss: 0.310455\n",
      "[9092]\ttraining's binary_logloss: 0.310418\n",
      "[9093]\ttraining's binary_logloss: 0.310377\n",
      "[9094]\ttraining's binary_logloss: 0.310347\n",
      "[9095]\ttraining's binary_logloss: 0.310315\n",
      "[9096]\ttraining's binary_logloss: 0.310286\n",
      "[9097]\ttraining's binary_logloss: 0.310224\n",
      "[9098]\ttraining's binary_logloss: 0.310198\n",
      "[9099]\ttraining's binary_logloss: 0.310166\n",
      "[9100]\ttraining's binary_logloss: 0.310144\n",
      "[9101]\ttraining's binary_logloss: 0.310118\n",
      "[9102]\ttraining's binary_logloss: 0.3101\n",
      "[9103]\ttraining's binary_logloss: 0.310061\n",
      "[9104]\ttraining's binary_logloss: 0.310023\n",
      "[9105]\ttraining's binary_logloss: 0.309999\n",
      "[9106]\ttraining's binary_logloss: 0.309969\n",
      "[9107]\ttraining's binary_logloss: 0.30994\n",
      "[9108]\ttraining's binary_logloss: 0.309913\n",
      "[9109]\ttraining's binary_logloss: 0.309889\n",
      "[9110]\ttraining's binary_logloss: 0.309864\n",
      "[9111]\ttraining's binary_logloss: 0.309841\n",
      "[9112]\ttraining's binary_logloss: 0.309809\n",
      "[9113]\ttraining's binary_logloss: 0.309779\n",
      "[9114]\ttraining's binary_logloss: 0.309753\n",
      "[9115]\ttraining's binary_logloss: 0.309717\n",
      "[9116]\ttraining's binary_logloss: 0.309686\n",
      "[9117]\ttraining's binary_logloss: 0.309667\n",
      "[9118]\ttraining's binary_logloss: 0.309631\n",
      "[9119]\ttraining's binary_logloss: 0.309608\n",
      "[9120]\ttraining's binary_logloss: 0.309582\n",
      "[9121]\ttraining's binary_logloss: 0.30955\n",
      "[9122]\ttraining's binary_logloss: 0.309524\n",
      "[9123]\ttraining's binary_logloss: 0.309488\n",
      "[9124]\ttraining's binary_logloss: 0.30946\n",
      "[9125]\ttraining's binary_logloss: 0.309426\n",
      "[9126]\ttraining's binary_logloss: 0.309401\n",
      "[9127]\ttraining's binary_logloss: 0.309379\n",
      "[9128]\ttraining's binary_logloss: 0.309358\n",
      "[9129]\ttraining's binary_logloss: 0.309328\n",
      "[9130]\ttraining's binary_logloss: 0.309309\n",
      "[9131]\ttraining's binary_logloss: 0.30928\n",
      "[9132]\ttraining's binary_logloss: 0.309242\n",
      "[9133]\ttraining's binary_logloss: 0.309218\n",
      "[9134]\ttraining's binary_logloss: 0.309187\n",
      "[9135]\ttraining's binary_logloss: 0.30916\n",
      "[9136]\ttraining's binary_logloss: 0.309126\n",
      "[9137]\ttraining's binary_logloss: 0.309102\n",
      "[9138]\ttraining's binary_logloss: 0.309063\n",
      "[9139]\ttraining's binary_logloss: 0.309015\n",
      "[9140]\ttraining's binary_logloss: 0.308986\n",
      "[9141]\ttraining's binary_logloss: 0.308959\n",
      "[9142]\ttraining's binary_logloss: 0.308938\n",
      "[9143]\ttraining's binary_logloss: 0.308904\n",
      "[9144]\ttraining's binary_logloss: 0.308875\n",
      "[9145]\ttraining's binary_logloss: 0.308847\n",
      "[9146]\ttraining's binary_logloss: 0.308823\n",
      "[9147]\ttraining's binary_logloss: 0.3088\n",
      "[9148]\ttraining's binary_logloss: 0.308764\n",
      "[9149]\ttraining's binary_logloss: 0.308739\n",
      "[9150]\ttraining's binary_logloss: 0.308711\n",
      "[9151]\ttraining's binary_logloss: 0.308679\n",
      "[9152]\ttraining's binary_logloss: 0.30864\n",
      "[9153]\ttraining's binary_logloss: 0.308604\n",
      "[9154]\ttraining's binary_logloss: 0.308576\n",
      "[9155]\ttraining's binary_logloss: 0.308546\n",
      "[9156]\ttraining's binary_logloss: 0.30852\n",
      "[9157]\ttraining's binary_logloss: 0.308498\n",
      "[9158]\ttraining's binary_logloss: 0.308466\n",
      "[9159]\ttraining's binary_logloss: 0.308415\n",
      "[9160]\ttraining's binary_logloss: 0.30839\n",
      "[9161]\ttraining's binary_logloss: 0.308364\n",
      "[9162]\ttraining's binary_logloss: 0.308328\n",
      "[9163]\ttraining's binary_logloss: 0.308302\n",
      "[9164]\ttraining's binary_logloss: 0.308269\n",
      "[9165]\ttraining's binary_logloss: 0.308232\n",
      "[9166]\ttraining's binary_logloss: 0.308204\n",
      "[9167]\ttraining's binary_logloss: 0.308176\n",
      "[9168]\ttraining's binary_logloss: 0.308148\n",
      "[9169]\ttraining's binary_logloss: 0.308124\n",
      "[9170]\ttraining's binary_logloss: 0.308084\n",
      "[9171]\ttraining's binary_logloss: 0.30806\n",
      "[9172]\ttraining's binary_logloss: 0.308022\n",
      "[9173]\ttraining's binary_logloss: 0.307991\n",
      "[9174]\ttraining's binary_logloss: 0.30796\n",
      "[9175]\ttraining's binary_logloss: 0.307922\n",
      "[9176]\ttraining's binary_logloss: 0.307894\n",
      "[9177]\ttraining's binary_logloss: 0.307862\n",
      "[9178]\ttraining's binary_logloss: 0.307834\n",
      "[9179]\ttraining's binary_logloss: 0.307812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9180]\ttraining's binary_logloss: 0.307772\n",
      "[9181]\ttraining's binary_logloss: 0.307747\n",
      "[9182]\ttraining's binary_logloss: 0.307713\n",
      "[9183]\ttraining's binary_logloss: 0.307681\n",
      "[9184]\ttraining's binary_logloss: 0.307657\n",
      "[9185]\ttraining's binary_logloss: 0.307629\n",
      "[9186]\ttraining's binary_logloss: 0.307604\n",
      "[9187]\ttraining's binary_logloss: 0.307562\n",
      "[9188]\ttraining's binary_logloss: 0.307535\n",
      "[9189]\ttraining's binary_logloss: 0.30751\n",
      "[9190]\ttraining's binary_logloss: 0.30748\n",
      "[9191]\ttraining's binary_logloss: 0.307434\n",
      "[9192]\ttraining's binary_logloss: 0.307404\n",
      "[9193]\ttraining's binary_logloss: 0.30738\n",
      "[9194]\ttraining's binary_logloss: 0.307342\n",
      "[9195]\ttraining's binary_logloss: 0.307317\n",
      "[9196]\ttraining's binary_logloss: 0.307288\n",
      "[9197]\ttraining's binary_logloss: 0.307271\n",
      "[9198]\ttraining's binary_logloss: 0.307246\n",
      "[9199]\ttraining's binary_logloss: 0.307207\n",
      "[9200]\ttraining's binary_logloss: 0.307174\n",
      "[9201]\ttraining's binary_logloss: 0.307137\n",
      "[9202]\ttraining's binary_logloss: 0.307098\n",
      "[9203]\ttraining's binary_logloss: 0.307069\n",
      "[9204]\ttraining's binary_logloss: 0.307046\n",
      "[9205]\ttraining's binary_logloss: 0.307011\n",
      "[9206]\ttraining's binary_logloss: 0.306968\n",
      "[9207]\ttraining's binary_logloss: 0.306932\n",
      "[9208]\ttraining's binary_logloss: 0.306907\n",
      "[9209]\ttraining's binary_logloss: 0.306873\n",
      "[9210]\ttraining's binary_logloss: 0.30685\n",
      "[9211]\ttraining's binary_logloss: 0.306826\n",
      "[9212]\ttraining's binary_logloss: 0.306802\n",
      "[9213]\ttraining's binary_logloss: 0.306758\n",
      "[9214]\ttraining's binary_logloss: 0.306738\n",
      "[9215]\ttraining's binary_logloss: 0.306716\n",
      "[9216]\ttraining's binary_logloss: 0.306684\n",
      "[9217]\ttraining's binary_logloss: 0.306648\n",
      "[9218]\ttraining's binary_logloss: 0.306621\n",
      "[9219]\ttraining's binary_logloss: 0.306585\n",
      "[9220]\ttraining's binary_logloss: 0.306559\n",
      "[9221]\ttraining's binary_logloss: 0.306531\n",
      "[9222]\ttraining's binary_logloss: 0.306503\n",
      "[9223]\ttraining's binary_logloss: 0.306469\n",
      "[9224]\ttraining's binary_logloss: 0.306433\n",
      "[9225]\ttraining's binary_logloss: 0.306398\n",
      "[9226]\ttraining's binary_logloss: 0.306363\n",
      "[9227]\ttraining's binary_logloss: 0.306332\n",
      "[9228]\ttraining's binary_logloss: 0.306308\n",
      "[9229]\ttraining's binary_logloss: 0.306276\n",
      "[9230]\ttraining's binary_logloss: 0.306248\n",
      "[9231]\ttraining's binary_logloss: 0.306215\n",
      "[9232]\ttraining's binary_logloss: 0.30617\n",
      "[9233]\ttraining's binary_logloss: 0.306148\n",
      "[9234]\ttraining's binary_logloss: 0.306127\n",
      "[9235]\ttraining's binary_logloss: 0.306106\n",
      "[9236]\ttraining's binary_logloss: 0.306084\n",
      "[9237]\ttraining's binary_logloss: 0.30605\n",
      "[9238]\ttraining's binary_logloss: 0.306016\n",
      "[9239]\ttraining's binary_logloss: 0.30598\n",
      "[9240]\ttraining's binary_logloss: 0.305957\n",
      "[9241]\ttraining's binary_logloss: 0.305926\n",
      "[9242]\ttraining's binary_logloss: 0.305889\n",
      "[9243]\ttraining's binary_logloss: 0.305857\n",
      "[9244]\ttraining's binary_logloss: 0.305834\n",
      "[9245]\ttraining's binary_logloss: 0.305805\n",
      "[9246]\ttraining's binary_logloss: 0.305774\n",
      "[9247]\ttraining's binary_logloss: 0.305749\n",
      "[9248]\ttraining's binary_logloss: 0.30571\n",
      "[9249]\ttraining's binary_logloss: 0.305684\n",
      "[9250]\ttraining's binary_logloss: 0.305654\n",
      "[9251]\ttraining's binary_logloss: 0.305632\n",
      "[9252]\ttraining's binary_logloss: 0.305608\n",
      "[9253]\ttraining's binary_logloss: 0.305582\n",
      "[9254]\ttraining's binary_logloss: 0.305555\n",
      "[9255]\ttraining's binary_logloss: 0.30553\n",
      "[9256]\ttraining's binary_logloss: 0.3055\n",
      "[9257]\ttraining's binary_logloss: 0.305459\n",
      "[9258]\ttraining's binary_logloss: 0.305422\n",
      "[9259]\ttraining's binary_logloss: 0.305374\n",
      "[9260]\ttraining's binary_logloss: 0.305344\n",
      "[9261]\ttraining's binary_logloss: 0.305323\n",
      "[9262]\ttraining's binary_logloss: 0.305295\n",
      "[9263]\ttraining's binary_logloss: 0.305261\n",
      "[9264]\ttraining's binary_logloss: 0.305235\n",
      "[9265]\ttraining's binary_logloss: 0.305204\n",
      "[9266]\ttraining's binary_logloss: 0.305172\n",
      "[9267]\ttraining's binary_logloss: 0.30514\n",
      "[9268]\ttraining's binary_logloss: 0.305107\n",
      "[9269]\ttraining's binary_logloss: 0.305079\n",
      "[9270]\ttraining's binary_logloss: 0.305042\n",
      "[9271]\ttraining's binary_logloss: 0.305015\n",
      "[9272]\ttraining's binary_logloss: 0.304981\n",
      "[9273]\ttraining's binary_logloss: 0.304958\n",
      "[9274]\ttraining's binary_logloss: 0.30493\n",
      "[9275]\ttraining's binary_logloss: 0.304899\n",
      "[9276]\ttraining's binary_logloss: 0.304883\n",
      "[9277]\ttraining's binary_logloss: 0.304853\n",
      "[9278]\ttraining's binary_logloss: 0.304824\n",
      "[9279]\ttraining's binary_logloss: 0.304802\n",
      "[9280]\ttraining's binary_logloss: 0.304771\n",
      "[9281]\ttraining's binary_logloss: 0.304722\n",
      "[9282]\ttraining's binary_logloss: 0.304695\n",
      "[9283]\ttraining's binary_logloss: 0.304663\n",
      "[9284]\ttraining's binary_logloss: 0.304632\n",
      "[9285]\ttraining's binary_logloss: 0.3046\n",
      "[9286]\ttraining's binary_logloss: 0.304571\n",
      "[9287]\ttraining's binary_logloss: 0.304546\n",
      "[9288]\ttraining's binary_logloss: 0.304505\n",
      "[9289]\ttraining's binary_logloss: 0.304481\n",
      "[9290]\ttraining's binary_logloss: 0.304454\n",
      "[9291]\ttraining's binary_logloss: 0.304418\n",
      "[9292]\ttraining's binary_logloss: 0.304386\n",
      "[9293]\ttraining's binary_logloss: 0.304359\n",
      "[9294]\ttraining's binary_logloss: 0.304319\n",
      "[9295]\ttraining's binary_logloss: 0.304281\n",
      "[9296]\ttraining's binary_logloss: 0.304258\n",
      "[9297]\ttraining's binary_logloss: 0.304229\n",
      "[9298]\ttraining's binary_logloss: 0.304204\n",
      "[9299]\ttraining's binary_logloss: 0.304184\n",
      "[9300]\ttraining's binary_logloss: 0.304154\n",
      "[9301]\ttraining's binary_logloss: 0.30412\n",
      "[9302]\ttraining's binary_logloss: 0.304098\n",
      "[9303]\ttraining's binary_logloss: 0.304078\n",
      "[9304]\ttraining's binary_logloss: 0.304046\n",
      "[9305]\ttraining's binary_logloss: 0.304021\n",
      "[9306]\ttraining's binary_logloss: 0.303991\n",
      "[9307]\ttraining's binary_logloss: 0.303953\n",
      "[9308]\ttraining's binary_logloss: 0.303925\n",
      "[9309]\ttraining's binary_logloss: 0.303906\n",
      "[9310]\ttraining's binary_logloss: 0.303873\n",
      "[9311]\ttraining's binary_logloss: 0.30383\n",
      "[9312]\ttraining's binary_logloss: 0.303806\n",
      "[9313]\ttraining's binary_logloss: 0.303776\n",
      "[9314]\ttraining's binary_logloss: 0.303754\n",
      "[9315]\ttraining's binary_logloss: 0.303728\n",
      "[9316]\ttraining's binary_logloss: 0.303695\n",
      "[9317]\ttraining's binary_logloss: 0.303645\n",
      "[9318]\ttraining's binary_logloss: 0.303617\n",
      "[9319]\ttraining's binary_logloss: 0.303595\n",
      "[9320]\ttraining's binary_logloss: 0.303575\n",
      "[9321]\ttraining's binary_logloss: 0.303546\n",
      "[9322]\ttraining's binary_logloss: 0.303527\n",
      "[9323]\ttraining's binary_logloss: 0.30349\n",
      "[9324]\ttraining's binary_logloss: 0.303451\n",
      "[9325]\ttraining's binary_logloss: 0.303426\n",
      "[9326]\ttraining's binary_logloss: 0.303404\n",
      "[9327]\ttraining's binary_logloss: 0.303373\n",
      "[9328]\ttraining's binary_logloss: 0.303336\n",
      "[9329]\ttraining's binary_logloss: 0.303301\n",
      "[9330]\ttraining's binary_logloss: 0.303283\n",
      "[9331]\ttraining's binary_logloss: 0.30326\n",
      "[9332]\ttraining's binary_logloss: 0.303234\n",
      "[9333]\ttraining's binary_logloss: 0.303206\n",
      "[9334]\ttraining's binary_logloss: 0.303179\n",
      "[9335]\ttraining's binary_logloss: 0.303153\n",
      "[9336]\ttraining's binary_logloss: 0.303123\n",
      "[9337]\ttraining's binary_logloss: 0.3031\n",
      "[9338]\ttraining's binary_logloss: 0.303066\n",
      "[9339]\ttraining's binary_logloss: 0.303028\n",
      "[9340]\ttraining's binary_logloss: 0.302997\n",
      "[9341]\ttraining's binary_logloss: 0.302966\n",
      "[9342]\ttraining's binary_logloss: 0.302936\n",
      "[9343]\ttraining's binary_logloss: 0.302908\n",
      "[9344]\ttraining's binary_logloss: 0.302879\n",
      "[9345]\ttraining's binary_logloss: 0.302846\n",
      "[9346]\ttraining's binary_logloss: 0.302818\n",
      "[9347]\ttraining's binary_logloss: 0.302788\n",
      "[9348]\ttraining's binary_logloss: 0.302765\n",
      "[9349]\ttraining's binary_logloss: 0.302736\n",
      "[9350]\ttraining's binary_logloss: 0.302703\n",
      "[9351]\ttraining's binary_logloss: 0.302678\n",
      "[9352]\ttraining's binary_logloss: 0.302649\n",
      "[9353]\ttraining's binary_logloss: 0.302609\n",
      "[9354]\ttraining's binary_logloss: 0.302569\n",
      "[9355]\ttraining's binary_logloss: 0.302539\n",
      "[9356]\ttraining's binary_logloss: 0.30252\n",
      "[9357]\ttraining's binary_logloss: 0.302482\n",
      "[9358]\ttraining's binary_logloss: 0.302452\n",
      "[9359]\ttraining's binary_logloss: 0.30243\n",
      "[9360]\ttraining's binary_logloss: 0.302403\n",
      "[9361]\ttraining's binary_logloss: 0.30237\n",
      "[9362]\ttraining's binary_logloss: 0.302342\n",
      "[9363]\ttraining's binary_logloss: 0.302299\n",
      "[9364]\ttraining's binary_logloss: 0.302265\n",
      "[9365]\ttraining's binary_logloss: 0.302232\n",
      "[9366]\ttraining's binary_logloss: 0.302191\n",
      "[9367]\ttraining's binary_logloss: 0.302172\n",
      "[9368]\ttraining's binary_logloss: 0.302144\n",
      "[9369]\ttraining's binary_logloss: 0.302107\n",
      "[9370]\ttraining's binary_logloss: 0.302059\n",
      "[9371]\ttraining's binary_logloss: 0.302034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9372]\ttraining's binary_logloss: 0.301998\n",
      "[9373]\ttraining's binary_logloss: 0.301974\n",
      "[9374]\ttraining's binary_logloss: 0.301936\n",
      "[9375]\ttraining's binary_logloss: 0.301901\n",
      "[9376]\ttraining's binary_logloss: 0.301874\n",
      "[9377]\ttraining's binary_logloss: 0.301847\n",
      "[9378]\ttraining's binary_logloss: 0.301824\n",
      "[9379]\ttraining's binary_logloss: 0.301783\n",
      "[9380]\ttraining's binary_logloss: 0.301755\n",
      "[9381]\ttraining's binary_logloss: 0.301725\n",
      "[9382]\ttraining's binary_logloss: 0.30169\n",
      "[9383]\ttraining's binary_logloss: 0.301666\n",
      "[9384]\ttraining's binary_logloss: 0.30164\n",
      "[9385]\ttraining's binary_logloss: 0.30161\n",
      "[9386]\ttraining's binary_logloss: 0.301576\n",
      "[9387]\ttraining's binary_logloss: 0.301535\n",
      "[9388]\ttraining's binary_logloss: 0.301498\n",
      "[9389]\ttraining's binary_logloss: 0.301476\n",
      "[9390]\ttraining's binary_logloss: 0.301453\n",
      "[9391]\ttraining's binary_logloss: 0.301426\n",
      "[9392]\ttraining's binary_logloss: 0.301402\n",
      "[9393]\ttraining's binary_logloss: 0.301364\n",
      "[9394]\ttraining's binary_logloss: 0.301325\n",
      "[9395]\ttraining's binary_logloss: 0.301299\n",
      "[9396]\ttraining's binary_logloss: 0.301278\n",
      "[9397]\ttraining's binary_logloss: 0.301238\n",
      "[9398]\ttraining's binary_logloss: 0.301213\n",
      "[9399]\ttraining's binary_logloss: 0.301185\n",
      "[9400]\ttraining's binary_logloss: 0.301148\n",
      "[9401]\ttraining's binary_logloss: 0.30112\n",
      "[9402]\ttraining's binary_logloss: 0.301094\n",
      "[9403]\ttraining's binary_logloss: 0.301059\n",
      "[9404]\ttraining's binary_logloss: 0.301016\n",
      "[9405]\ttraining's binary_logloss: 0.300982\n",
      "[9406]\ttraining's binary_logloss: 0.300961\n",
      "[9407]\ttraining's binary_logloss: 0.300933\n",
      "[9408]\ttraining's binary_logloss: 0.300909\n",
      "[9409]\ttraining's binary_logloss: 0.300889\n",
      "[9410]\ttraining's binary_logloss: 0.30086\n",
      "[9411]\ttraining's binary_logloss: 0.300828\n",
      "[9412]\ttraining's binary_logloss: 0.300805\n",
      "[9413]\ttraining's binary_logloss: 0.300772\n",
      "[9414]\ttraining's binary_logloss: 0.300745\n",
      "[9415]\ttraining's binary_logloss: 0.300723\n",
      "[9416]\ttraining's binary_logloss: 0.300694\n",
      "[9417]\ttraining's binary_logloss: 0.300674\n",
      "[9418]\ttraining's binary_logloss: 0.300643\n",
      "[9419]\ttraining's binary_logloss: 0.300614\n",
      "[9420]\ttraining's binary_logloss: 0.300592\n",
      "[9421]\ttraining's binary_logloss: 0.300561\n",
      "[9422]\ttraining's binary_logloss: 0.300527\n",
      "[9423]\ttraining's binary_logloss: 0.300497\n",
      "[9424]\ttraining's binary_logloss: 0.300468\n",
      "[9425]\ttraining's binary_logloss: 0.300444\n",
      "[9426]\ttraining's binary_logloss: 0.300415\n",
      "[9427]\ttraining's binary_logloss: 0.300388\n",
      "[9428]\ttraining's binary_logloss: 0.300357\n",
      "[9429]\ttraining's binary_logloss: 0.300311\n",
      "[9430]\ttraining's binary_logloss: 0.300283\n",
      "[9431]\ttraining's binary_logloss: 0.300246\n",
      "[9432]\ttraining's binary_logloss: 0.300219\n",
      "[9433]\ttraining's binary_logloss: 0.300195\n",
      "[9434]\ttraining's binary_logloss: 0.30015\n",
      "[9435]\ttraining's binary_logloss: 0.300126\n",
      "[9436]\ttraining's binary_logloss: 0.300097\n",
      "[9437]\ttraining's binary_logloss: 0.300073\n",
      "[9438]\ttraining's binary_logloss: 0.300041\n",
      "[9439]\ttraining's binary_logloss: 0.300011\n",
      "[9440]\ttraining's binary_logloss: 0.299969\n",
      "[9441]\ttraining's binary_logloss: 0.299943\n",
      "[9442]\ttraining's binary_logloss: 0.299917\n",
      "[9443]\ttraining's binary_logloss: 0.299892\n",
      "[9444]\ttraining's binary_logloss: 0.299868\n",
      "[9445]\ttraining's binary_logloss: 0.299833\n",
      "[9446]\ttraining's binary_logloss: 0.299805\n",
      "[9447]\ttraining's binary_logloss: 0.299771\n",
      "[9448]\ttraining's binary_logloss: 0.299744\n",
      "[9449]\ttraining's binary_logloss: 0.299697\n",
      "[9450]\ttraining's binary_logloss: 0.299667\n",
      "[9451]\ttraining's binary_logloss: 0.29963\n",
      "[9452]\ttraining's binary_logloss: 0.299591\n",
      "[9453]\ttraining's binary_logloss: 0.299569\n",
      "[9454]\ttraining's binary_logloss: 0.299545\n",
      "[9455]\ttraining's binary_logloss: 0.299524\n",
      "[9456]\ttraining's binary_logloss: 0.299501\n",
      "[9457]\ttraining's binary_logloss: 0.299473\n",
      "[9458]\ttraining's binary_logloss: 0.29945\n",
      "[9459]\ttraining's binary_logloss: 0.299422\n",
      "[9460]\ttraining's binary_logloss: 0.2994\n",
      "[9461]\ttraining's binary_logloss: 0.299381\n",
      "[9462]\ttraining's binary_logloss: 0.299352\n",
      "[9463]\ttraining's binary_logloss: 0.29933\n",
      "[9464]\ttraining's binary_logloss: 0.299301\n",
      "[9465]\ttraining's binary_logloss: 0.299286\n",
      "[9466]\ttraining's binary_logloss: 0.29925\n",
      "[9467]\ttraining's binary_logloss: 0.299224\n",
      "[9468]\ttraining's binary_logloss: 0.299202\n",
      "[9469]\ttraining's binary_logloss: 0.299168\n",
      "[9470]\ttraining's binary_logloss: 0.299148\n",
      "[9471]\ttraining's binary_logloss: 0.299119\n",
      "[9472]\ttraining's binary_logloss: 0.29909\n",
      "[9473]\ttraining's binary_logloss: 0.299067\n",
      "[9474]\ttraining's binary_logloss: 0.299031\n",
      "[9475]\ttraining's binary_logloss: 0.298987\n",
      "[9476]\ttraining's binary_logloss: 0.298949\n",
      "[9477]\ttraining's binary_logloss: 0.298923\n",
      "[9478]\ttraining's binary_logloss: 0.298891\n",
      "[9479]\ttraining's binary_logloss: 0.298862\n",
      "[9480]\ttraining's binary_logloss: 0.298838\n",
      "[9481]\ttraining's binary_logloss: 0.298812\n",
      "[9482]\ttraining's binary_logloss: 0.298787\n",
      "[9483]\ttraining's binary_logloss: 0.298766\n",
      "[9484]\ttraining's binary_logloss: 0.29874\n",
      "[9485]\ttraining's binary_logloss: 0.298712\n",
      "[9486]\ttraining's binary_logloss: 0.298689\n",
      "[9487]\ttraining's binary_logloss: 0.298662\n",
      "[9488]\ttraining's binary_logloss: 0.298623\n",
      "[9489]\ttraining's binary_logloss: 0.298591\n",
      "[9490]\ttraining's binary_logloss: 0.298543\n",
      "[9491]\ttraining's binary_logloss: 0.298524\n",
      "[9492]\ttraining's binary_logloss: 0.298499\n",
      "[9493]\ttraining's binary_logloss: 0.298475\n",
      "[9494]\ttraining's binary_logloss: 0.298438\n",
      "[9495]\ttraining's binary_logloss: 0.2984\n",
      "[9496]\ttraining's binary_logloss: 0.298375\n",
      "[9497]\ttraining's binary_logloss: 0.298354\n",
      "[9498]\ttraining's binary_logloss: 0.298307\n",
      "[9499]\ttraining's binary_logloss: 0.298276\n",
      "[9500]\ttraining's binary_logloss: 0.298239\n",
      "[9501]\ttraining's binary_logloss: 0.298221\n",
      "[9502]\ttraining's binary_logloss: 0.298204\n",
      "[9503]\ttraining's binary_logloss: 0.29818\n",
      "[9504]\ttraining's binary_logloss: 0.298157\n",
      "[9505]\ttraining's binary_logloss: 0.298124\n",
      "[9506]\ttraining's binary_logloss: 0.298101\n",
      "[9507]\ttraining's binary_logloss: 0.298071\n",
      "[9508]\ttraining's binary_logloss: 0.298035\n",
      "[9509]\ttraining's binary_logloss: 0.298017\n",
      "[9510]\ttraining's binary_logloss: 0.297959\n",
      "[9511]\ttraining's binary_logloss: 0.297945\n",
      "[9512]\ttraining's binary_logloss: 0.297923\n",
      "[9513]\ttraining's binary_logloss: 0.297901\n",
      "[9514]\ttraining's binary_logloss: 0.297853\n",
      "[9515]\ttraining's binary_logloss: 0.297804\n",
      "[9516]\ttraining's binary_logloss: 0.297772\n",
      "[9517]\ttraining's binary_logloss: 0.297745\n",
      "[9518]\ttraining's binary_logloss: 0.297711\n",
      "[9519]\ttraining's binary_logloss: 0.297669\n",
      "[9520]\ttraining's binary_logloss: 0.297648\n",
      "[9521]\ttraining's binary_logloss: 0.29761\n",
      "[9522]\ttraining's binary_logloss: 0.297583\n",
      "[9523]\ttraining's binary_logloss: 0.297549\n",
      "[9524]\ttraining's binary_logloss: 0.297527\n",
      "[9525]\ttraining's binary_logloss: 0.297499\n",
      "[9526]\ttraining's binary_logloss: 0.297475\n",
      "[9527]\ttraining's binary_logloss: 0.297452\n",
      "[9528]\ttraining's binary_logloss: 0.297423\n",
      "[9529]\ttraining's binary_logloss: 0.297398\n",
      "[9530]\ttraining's binary_logloss: 0.297367\n",
      "[9531]\ttraining's binary_logloss: 0.297335\n",
      "[9532]\ttraining's binary_logloss: 0.297308\n",
      "[9533]\ttraining's binary_logloss: 0.297283\n",
      "[9534]\ttraining's binary_logloss: 0.297254\n",
      "[9535]\ttraining's binary_logloss: 0.297227\n",
      "[9536]\ttraining's binary_logloss: 0.297197\n",
      "[9537]\ttraining's binary_logloss: 0.297165\n",
      "[9538]\ttraining's binary_logloss: 0.297131\n",
      "[9539]\ttraining's binary_logloss: 0.297107\n",
      "[9540]\ttraining's binary_logloss: 0.297089\n",
      "[9541]\ttraining's binary_logloss: 0.297054\n",
      "[9542]\ttraining's binary_logloss: 0.29703\n",
      "[9543]\ttraining's binary_logloss: 0.297006\n",
      "[9544]\ttraining's binary_logloss: 0.296982\n",
      "[9545]\ttraining's binary_logloss: 0.296956\n",
      "[9546]\ttraining's binary_logloss: 0.296923\n",
      "[9547]\ttraining's binary_logloss: 0.296878\n",
      "[9548]\ttraining's binary_logloss: 0.296844\n",
      "[9549]\ttraining's binary_logloss: 0.296825\n",
      "[9550]\ttraining's binary_logloss: 0.296796\n",
      "[9551]\ttraining's binary_logloss: 0.296776\n",
      "[9552]\ttraining's binary_logloss: 0.296749\n",
      "[9553]\ttraining's binary_logloss: 0.296719\n",
      "[9554]\ttraining's binary_logloss: 0.296687\n",
      "[9555]\ttraining's binary_logloss: 0.296659\n",
      "[9556]\ttraining's binary_logloss: 0.296632\n",
      "[9557]\ttraining's binary_logloss: 0.296596\n",
      "[9558]\ttraining's binary_logloss: 0.296564\n",
      "[9559]\ttraining's binary_logloss: 0.29654\n",
      "[9560]\ttraining's binary_logloss: 0.29651\n",
      "[9561]\ttraining's binary_logloss: 0.296467\n",
      "[9562]\ttraining's binary_logloss: 0.296431\n",
      "[9563]\ttraining's binary_logloss: 0.296393\n",
      "[9564]\ttraining's binary_logloss: 0.296368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9565]\ttraining's binary_logloss: 0.296336\n",
      "[9566]\ttraining's binary_logloss: 0.296314\n",
      "[9567]\ttraining's binary_logloss: 0.296291\n",
      "[9568]\ttraining's binary_logloss: 0.29626\n",
      "[9569]\ttraining's binary_logloss: 0.296236\n",
      "[9570]\ttraining's binary_logloss: 0.29621\n",
      "[9571]\ttraining's binary_logloss: 0.296168\n",
      "[9572]\ttraining's binary_logloss: 0.296138\n",
      "[9573]\ttraining's binary_logloss: 0.296104\n",
      "[9574]\ttraining's binary_logloss: 0.296078\n",
      "[9575]\ttraining's binary_logloss: 0.296057\n",
      "[9576]\ttraining's binary_logloss: 0.296034\n",
      "[9577]\ttraining's binary_logloss: 0.295997\n",
      "[9578]\ttraining's binary_logloss: 0.295974\n",
      "[9579]\ttraining's binary_logloss: 0.295952\n",
      "[9580]\ttraining's binary_logloss: 0.295924\n",
      "[9581]\ttraining's binary_logloss: 0.295904\n",
      "[9582]\ttraining's binary_logloss: 0.295887\n",
      "[9583]\ttraining's binary_logloss: 0.295861\n",
      "[9584]\ttraining's binary_logloss: 0.295837\n",
      "[9585]\ttraining's binary_logloss: 0.295805\n",
      "[9586]\ttraining's binary_logloss: 0.295775\n",
      "[9587]\ttraining's binary_logloss: 0.295743\n",
      "[9588]\ttraining's binary_logloss: 0.295715\n",
      "[9589]\ttraining's binary_logloss: 0.295669\n",
      "[9590]\ttraining's binary_logloss: 0.295636\n",
      "[9591]\ttraining's binary_logloss: 0.295605\n",
      "[9592]\ttraining's binary_logloss: 0.295576\n",
      "[9593]\ttraining's binary_logloss: 0.295548\n",
      "[9594]\ttraining's binary_logloss: 0.295521\n",
      "[9595]\ttraining's binary_logloss: 0.295498\n",
      "[9596]\ttraining's binary_logloss: 0.295476\n",
      "[9597]\ttraining's binary_logloss: 0.295442\n",
      "[9598]\ttraining's binary_logloss: 0.295421\n",
      "[9599]\ttraining's binary_logloss: 0.295391\n",
      "[9600]\ttraining's binary_logloss: 0.29536\n",
      "[9601]\ttraining's binary_logloss: 0.295337\n",
      "[9602]\ttraining's binary_logloss: 0.2953\n",
      "[9603]\ttraining's binary_logloss: 0.295273\n",
      "[9604]\ttraining's binary_logloss: 0.295237\n",
      "[9605]\ttraining's binary_logloss: 0.295213\n",
      "[9606]\ttraining's binary_logloss: 0.295172\n",
      "[9607]\ttraining's binary_logloss: 0.295152\n",
      "[9608]\ttraining's binary_logloss: 0.295124\n",
      "[9609]\ttraining's binary_logloss: 0.295095\n",
      "[9610]\ttraining's binary_logloss: 0.295073\n",
      "[9611]\ttraining's binary_logloss: 0.295049\n",
      "[9612]\ttraining's binary_logloss: 0.295021\n",
      "[9613]\ttraining's binary_logloss: 0.294989\n",
      "[9614]\ttraining's binary_logloss: 0.294956\n",
      "[9615]\ttraining's binary_logloss: 0.294923\n",
      "[9616]\ttraining's binary_logloss: 0.294903\n",
      "[9617]\ttraining's binary_logloss: 0.294879\n",
      "[9618]\ttraining's binary_logloss: 0.294849\n",
      "[9619]\ttraining's binary_logloss: 0.294824\n",
      "[9620]\ttraining's binary_logloss: 0.294802\n",
      "[9621]\ttraining's binary_logloss: 0.294773\n",
      "[9622]\ttraining's binary_logloss: 0.294745\n",
      "[9623]\ttraining's binary_logloss: 0.294721\n",
      "[9624]\ttraining's binary_logloss: 0.294698\n",
      "[9625]\ttraining's binary_logloss: 0.294671\n",
      "[9626]\ttraining's binary_logloss: 0.294639\n",
      "[9627]\ttraining's binary_logloss: 0.294615\n",
      "[9628]\ttraining's binary_logloss: 0.294599\n",
      "[9629]\ttraining's binary_logloss: 0.294575\n",
      "[9630]\ttraining's binary_logloss: 0.294552\n",
      "[9631]\ttraining's binary_logloss: 0.294513\n",
      "[9632]\ttraining's binary_logloss: 0.29449\n",
      "[9633]\ttraining's binary_logloss: 0.294451\n",
      "[9634]\ttraining's binary_logloss: 0.294417\n",
      "[9635]\ttraining's binary_logloss: 0.294393\n",
      "[9636]\ttraining's binary_logloss: 0.294357\n",
      "[9637]\ttraining's binary_logloss: 0.294339\n",
      "[9638]\ttraining's binary_logloss: 0.294312\n",
      "[9639]\ttraining's binary_logloss: 0.29427\n",
      "[9640]\ttraining's binary_logloss: 0.294252\n",
      "[9641]\ttraining's binary_logloss: 0.29422\n",
      "[9642]\ttraining's binary_logloss: 0.294184\n",
      "[9643]\ttraining's binary_logloss: 0.29415\n",
      "[9644]\ttraining's binary_logloss: 0.294116\n",
      "[9645]\ttraining's binary_logloss: 0.294072\n",
      "[9646]\ttraining's binary_logloss: 0.294041\n",
      "[9647]\ttraining's binary_logloss: 0.294018\n",
      "[9648]\ttraining's binary_logloss: 0.293984\n",
      "[9649]\ttraining's binary_logloss: 0.293959\n",
      "[9650]\ttraining's binary_logloss: 0.29394\n",
      "[9651]\ttraining's binary_logloss: 0.293916\n",
      "[9652]\ttraining's binary_logloss: 0.293888\n",
      "[9653]\ttraining's binary_logloss: 0.293861\n",
      "[9654]\ttraining's binary_logloss: 0.293825\n",
      "[9655]\ttraining's binary_logloss: 0.293797\n",
      "[9656]\ttraining's binary_logloss: 0.293762\n",
      "[9657]\ttraining's binary_logloss: 0.29373\n",
      "[9658]\ttraining's binary_logloss: 0.293708\n",
      "[9659]\ttraining's binary_logloss: 0.293689\n",
      "[9660]\ttraining's binary_logloss: 0.293649\n",
      "[9661]\ttraining's binary_logloss: 0.293627\n",
      "[9662]\ttraining's binary_logloss: 0.293597\n",
      "[9663]\ttraining's binary_logloss: 0.293573\n",
      "[9664]\ttraining's binary_logloss: 0.293544\n",
      "[9665]\ttraining's binary_logloss: 0.293518\n",
      "[9666]\ttraining's binary_logloss: 0.293491\n",
      "[9667]\ttraining's binary_logloss: 0.293458\n",
      "[9668]\ttraining's binary_logloss: 0.293435\n",
      "[9669]\ttraining's binary_logloss: 0.293403\n",
      "[9670]\ttraining's binary_logloss: 0.293378\n",
      "[9671]\ttraining's binary_logloss: 0.293349\n",
      "[9672]\ttraining's binary_logloss: 0.293328\n",
      "[9673]\ttraining's binary_logloss: 0.293304\n",
      "[9674]\ttraining's binary_logloss: 0.293274\n",
      "[9675]\ttraining's binary_logloss: 0.293237\n",
      "[9676]\ttraining's binary_logloss: 0.293203\n",
      "[9677]\ttraining's binary_logloss: 0.293172\n",
      "[9678]\ttraining's binary_logloss: 0.293145\n",
      "[9679]\ttraining's binary_logloss: 0.293118\n",
      "[9680]\ttraining's binary_logloss: 0.293076\n",
      "[9681]\ttraining's binary_logloss: 0.293055\n",
      "[9682]\ttraining's binary_logloss: 0.293037\n",
      "[9683]\ttraining's binary_logloss: 0.29301\n",
      "[9684]\ttraining's binary_logloss: 0.292985\n",
      "[9685]\ttraining's binary_logloss: 0.292965\n",
      "[9686]\ttraining's binary_logloss: 0.292929\n",
      "[9687]\ttraining's binary_logloss: 0.292904\n",
      "[9688]\ttraining's binary_logloss: 0.292877\n",
      "[9689]\ttraining's binary_logloss: 0.292856\n",
      "[9690]\ttraining's binary_logloss: 0.292814\n",
      "[9691]\ttraining's binary_logloss: 0.292778\n",
      "[9692]\ttraining's binary_logloss: 0.292745\n",
      "[9693]\ttraining's binary_logloss: 0.292718\n",
      "[9694]\ttraining's binary_logloss: 0.292683\n",
      "[9695]\ttraining's binary_logloss: 0.292658\n",
      "[9696]\ttraining's binary_logloss: 0.292635\n",
      "[9697]\ttraining's binary_logloss: 0.292617\n",
      "[9698]\ttraining's binary_logloss: 0.292583\n",
      "[9699]\ttraining's binary_logloss: 0.292554\n",
      "[9700]\ttraining's binary_logloss: 0.292516\n",
      "[9701]\ttraining's binary_logloss: 0.292473\n",
      "[9702]\ttraining's binary_logloss: 0.292449\n",
      "[9703]\ttraining's binary_logloss: 0.292417\n",
      "[9704]\ttraining's binary_logloss: 0.292392\n",
      "[9705]\ttraining's binary_logloss: 0.292365\n",
      "[9706]\ttraining's binary_logloss: 0.292344\n",
      "[9707]\ttraining's binary_logloss: 0.292325\n",
      "[9708]\ttraining's binary_logloss: 0.292274\n",
      "[9709]\ttraining's binary_logloss: 0.292248\n",
      "[9710]\ttraining's binary_logloss: 0.292228\n",
      "[9711]\ttraining's binary_logloss: 0.292201\n",
      "[9712]\ttraining's binary_logloss: 0.292162\n",
      "[9713]\ttraining's binary_logloss: 0.29214\n",
      "[9714]\ttraining's binary_logloss: 0.292118\n",
      "[9715]\ttraining's binary_logloss: 0.292084\n",
      "[9716]\ttraining's binary_logloss: 0.29206\n",
      "[9717]\ttraining's binary_logloss: 0.292025\n",
      "[9718]\ttraining's binary_logloss: 0.291994\n",
      "[9719]\ttraining's binary_logloss: 0.291973\n",
      "[9720]\ttraining's binary_logloss: 0.291951\n",
      "[9721]\ttraining's binary_logloss: 0.291921\n",
      "[9722]\ttraining's binary_logloss: 0.291898\n",
      "[9723]\ttraining's binary_logloss: 0.291876\n",
      "[9724]\ttraining's binary_logloss: 0.291857\n",
      "[9725]\ttraining's binary_logloss: 0.291832\n",
      "[9726]\ttraining's binary_logloss: 0.291812\n",
      "[9727]\ttraining's binary_logloss: 0.291779\n",
      "[9728]\ttraining's binary_logloss: 0.29174\n",
      "[9729]\ttraining's binary_logloss: 0.291714\n",
      "[9730]\ttraining's binary_logloss: 0.291692\n",
      "[9731]\ttraining's binary_logloss: 0.291658\n",
      "[9732]\ttraining's binary_logloss: 0.291632\n",
      "[9733]\ttraining's binary_logloss: 0.291606\n",
      "[9734]\ttraining's binary_logloss: 0.291573\n",
      "[9735]\ttraining's binary_logloss: 0.291543\n",
      "[9736]\ttraining's binary_logloss: 0.291518\n",
      "[9737]\ttraining's binary_logloss: 0.291501\n",
      "[9738]\ttraining's binary_logloss: 0.291472\n",
      "[9739]\ttraining's binary_logloss: 0.291442\n",
      "[9740]\ttraining's binary_logloss: 0.291422\n",
      "[9741]\ttraining's binary_logloss: 0.291388\n",
      "[9742]\ttraining's binary_logloss: 0.291364\n",
      "[9743]\ttraining's binary_logloss: 0.29134\n",
      "[9744]\ttraining's binary_logloss: 0.291313\n",
      "[9745]\ttraining's binary_logloss: 0.291287\n",
      "[9746]\ttraining's binary_logloss: 0.291264\n",
      "[9747]\ttraining's binary_logloss: 0.29124\n",
      "[9748]\ttraining's binary_logloss: 0.291204\n",
      "[9749]\ttraining's binary_logloss: 0.291184\n",
      "[9750]\ttraining's binary_logloss: 0.291158\n",
      "[9751]\ttraining's binary_logloss: 0.291131\n",
      "[9752]\ttraining's binary_logloss: 0.291086\n",
      "[9753]\ttraining's binary_logloss: 0.291052\n",
      "[9754]\ttraining's binary_logloss: 0.291031\n",
      "[9755]\ttraining's binary_logloss: 0.291002\n",
      "[9756]\ttraining's binary_logloss: 0.290972\n",
      "[9757]\ttraining's binary_logloss: 0.290953\n",
      "[9758]\ttraining's binary_logloss: 0.290924\n",
      "[9759]\ttraining's binary_logloss: 0.290904\n",
      "[9760]\ttraining's binary_logloss: 0.290875\n",
      "[9761]\ttraining's binary_logloss: 0.29085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9762]\ttraining's binary_logloss: 0.290817\n",
      "[9763]\ttraining's binary_logloss: 0.290787\n",
      "[9764]\ttraining's binary_logloss: 0.290765\n",
      "[9765]\ttraining's binary_logloss: 0.290737\n",
      "[9766]\ttraining's binary_logloss: 0.290718\n",
      "[9767]\ttraining's binary_logloss: 0.290683\n",
      "[9768]\ttraining's binary_logloss: 0.290656\n",
      "[9769]\ttraining's binary_logloss: 0.290617\n",
      "[9770]\ttraining's binary_logloss: 0.290591\n",
      "[9771]\ttraining's binary_logloss: 0.290546\n",
      "[9772]\ttraining's binary_logloss: 0.290518\n",
      "[9773]\ttraining's binary_logloss: 0.290497\n",
      "[9774]\ttraining's binary_logloss: 0.290475\n",
      "[9775]\ttraining's binary_logloss: 0.290446\n",
      "[9776]\ttraining's binary_logloss: 0.290425\n",
      "[9777]\ttraining's binary_logloss: 0.290404\n",
      "[9778]\ttraining's binary_logloss: 0.290381\n",
      "[9779]\ttraining's binary_logloss: 0.290352\n",
      "[9780]\ttraining's binary_logloss: 0.290317\n",
      "[9781]\ttraining's binary_logloss: 0.290284\n",
      "[9782]\ttraining's binary_logloss: 0.290247\n",
      "[9783]\ttraining's binary_logloss: 0.290229\n",
      "[9784]\ttraining's binary_logloss: 0.290212\n",
      "[9785]\ttraining's binary_logloss: 0.29018\n",
      "[9786]\ttraining's binary_logloss: 0.290155\n",
      "[9787]\ttraining's binary_logloss: 0.290134\n",
      "[9788]\ttraining's binary_logloss: 0.290104\n",
      "[9789]\ttraining's binary_logloss: 0.29007\n",
      "[9790]\ttraining's binary_logloss: 0.290033\n",
      "[9791]\ttraining's binary_logloss: 0.290015\n",
      "[9792]\ttraining's binary_logloss: 0.289988\n",
      "[9793]\ttraining's binary_logloss: 0.289963\n",
      "[9794]\ttraining's binary_logloss: 0.289933\n",
      "[9795]\ttraining's binary_logloss: 0.289908\n",
      "[9796]\ttraining's binary_logloss: 0.289872\n",
      "[9797]\ttraining's binary_logloss: 0.289828\n",
      "[9798]\ttraining's binary_logloss: 0.289779\n",
      "[9799]\ttraining's binary_logloss: 0.289736\n",
      "[9800]\ttraining's binary_logloss: 0.289708\n",
      "[9801]\ttraining's binary_logloss: 0.289681\n",
      "[9802]\ttraining's binary_logloss: 0.289653\n",
      "[9803]\ttraining's binary_logloss: 0.289613\n",
      "[9804]\ttraining's binary_logloss: 0.289585\n",
      "[9805]\ttraining's binary_logloss: 0.289553\n",
      "[9806]\ttraining's binary_logloss: 0.289535\n",
      "[9807]\ttraining's binary_logloss: 0.289495\n",
      "[9808]\ttraining's binary_logloss: 0.289451\n",
      "[9809]\ttraining's binary_logloss: 0.289423\n",
      "[9810]\ttraining's binary_logloss: 0.2894\n",
      "[9811]\ttraining's binary_logloss: 0.289381\n",
      "[9812]\ttraining's binary_logloss: 0.289355\n",
      "[9813]\ttraining's binary_logloss: 0.28933\n",
      "[9814]\ttraining's binary_logloss: 0.2893\n",
      "[9815]\ttraining's binary_logloss: 0.289274\n",
      "[9816]\ttraining's binary_logloss: 0.289256\n",
      "[9817]\ttraining's binary_logloss: 0.289229\n",
      "[9818]\ttraining's binary_logloss: 0.289194\n",
      "[9819]\ttraining's binary_logloss: 0.289176\n",
      "[9820]\ttraining's binary_logloss: 0.28915\n",
      "[9821]\ttraining's binary_logloss: 0.289125\n",
      "[9822]\ttraining's binary_logloss: 0.289099\n",
      "[9823]\ttraining's binary_logloss: 0.289069\n",
      "[9824]\ttraining's binary_logloss: 0.289039\n",
      "[9825]\ttraining's binary_logloss: 0.289\n",
      "[9826]\ttraining's binary_logloss: 0.288975\n",
      "[9827]\ttraining's binary_logloss: 0.288942\n",
      "[9828]\ttraining's binary_logloss: 0.288905\n",
      "[9829]\ttraining's binary_logloss: 0.288876\n",
      "[9830]\ttraining's binary_logloss: 0.288854\n",
      "[9831]\ttraining's binary_logloss: 0.288835\n",
      "[9832]\ttraining's binary_logloss: 0.288801\n",
      "[9833]\ttraining's binary_logloss: 0.288769\n",
      "[9834]\ttraining's binary_logloss: 0.288736\n",
      "[9835]\ttraining's binary_logloss: 0.288716\n",
      "[9836]\ttraining's binary_logloss: 0.288694\n",
      "[9837]\ttraining's binary_logloss: 0.288666\n",
      "[9838]\ttraining's binary_logloss: 0.288643\n",
      "[9839]\ttraining's binary_logloss: 0.288624\n",
      "[9840]\ttraining's binary_logloss: 0.288596\n",
      "[9841]\ttraining's binary_logloss: 0.288557\n",
      "[9842]\ttraining's binary_logloss: 0.288519\n",
      "[9843]\ttraining's binary_logloss: 0.288488\n",
      "[9844]\ttraining's binary_logloss: 0.288467\n",
      "[9845]\ttraining's binary_logloss: 0.288446\n",
      "[9846]\ttraining's binary_logloss: 0.288418\n",
      "[9847]\ttraining's binary_logloss: 0.288399\n",
      "[9848]\ttraining's binary_logloss: 0.288362\n",
      "[9849]\ttraining's binary_logloss: 0.288337\n",
      "[9850]\ttraining's binary_logloss: 0.288318\n",
      "[9851]\ttraining's binary_logloss: 0.288291\n",
      "[9852]\ttraining's binary_logloss: 0.288266\n",
      "[9853]\ttraining's binary_logloss: 0.288229\n",
      "[9854]\ttraining's binary_logloss: 0.288213\n",
      "[9855]\ttraining's binary_logloss: 0.288184\n",
      "[9856]\ttraining's binary_logloss: 0.288159\n",
      "[9857]\ttraining's binary_logloss: 0.288135\n",
      "[9858]\ttraining's binary_logloss: 0.288107\n",
      "[9859]\ttraining's binary_logloss: 0.28808\n",
      "[9860]\ttraining's binary_logloss: 0.288051\n",
      "[9861]\ttraining's binary_logloss: 0.288024\n",
      "[9862]\ttraining's binary_logloss: 0.288002\n",
      "[9863]\ttraining's binary_logloss: 0.287959\n",
      "[9864]\ttraining's binary_logloss: 0.287937\n",
      "[9865]\ttraining's binary_logloss: 0.287915\n",
      "[9866]\ttraining's binary_logloss: 0.287877\n",
      "[9867]\ttraining's binary_logloss: 0.287852\n",
      "[9868]\ttraining's binary_logloss: 0.287829\n",
      "[9869]\ttraining's binary_logloss: 0.287803\n",
      "[9870]\ttraining's binary_logloss: 0.287785\n",
      "[9871]\ttraining's binary_logloss: 0.287759\n",
      "[9872]\ttraining's binary_logloss: 0.287721\n",
      "[9873]\ttraining's binary_logloss: 0.287688\n",
      "[9874]\ttraining's binary_logloss: 0.287664\n",
      "[9875]\ttraining's binary_logloss: 0.287636\n",
      "[9876]\ttraining's binary_logloss: 0.287615\n",
      "[9877]\ttraining's binary_logloss: 0.287592\n",
      "[9878]\ttraining's binary_logloss: 0.287566\n",
      "[9879]\ttraining's binary_logloss: 0.28753\n",
      "[9880]\ttraining's binary_logloss: 0.287507\n",
      "[9881]\ttraining's binary_logloss: 0.287472\n",
      "[9882]\ttraining's binary_logloss: 0.287449\n",
      "[9883]\ttraining's binary_logloss: 0.287421\n",
      "[9884]\ttraining's binary_logloss: 0.287379\n",
      "[9885]\ttraining's binary_logloss: 0.287353\n",
      "[9886]\ttraining's binary_logloss: 0.287321\n",
      "[9887]\ttraining's binary_logloss: 0.287292\n",
      "[9888]\ttraining's binary_logloss: 0.287266\n",
      "[9889]\ttraining's binary_logloss: 0.287222\n",
      "[9890]\ttraining's binary_logloss: 0.287192\n",
      "[9891]\ttraining's binary_logloss: 0.287167\n",
      "[9892]\ttraining's binary_logloss: 0.28714\n",
      "[9893]\ttraining's binary_logloss: 0.287113\n",
      "[9894]\ttraining's binary_logloss: 0.287087\n",
      "[9895]\ttraining's binary_logloss: 0.28706\n",
      "[9896]\ttraining's binary_logloss: 0.28703\n",
      "[9897]\ttraining's binary_logloss: 0.287011\n",
      "[9898]\ttraining's binary_logloss: 0.286983\n",
      "[9899]\ttraining's binary_logloss: 0.286959\n",
      "[9900]\ttraining's binary_logloss: 0.286932\n",
      "[9901]\ttraining's binary_logloss: 0.286908\n",
      "[9902]\ttraining's binary_logloss: 0.286879\n",
      "[9903]\ttraining's binary_logloss: 0.286851\n",
      "[9904]\ttraining's binary_logloss: 0.28683\n",
      "[9905]\ttraining's binary_logloss: 0.286794\n",
      "[9906]\ttraining's binary_logloss: 0.286768\n",
      "[9907]\ttraining's binary_logloss: 0.286748\n",
      "[9908]\ttraining's binary_logloss: 0.286712\n",
      "[9909]\ttraining's binary_logloss: 0.286681\n",
      "[9910]\ttraining's binary_logloss: 0.286654\n",
      "[9911]\ttraining's binary_logloss: 0.28662\n",
      "[9912]\ttraining's binary_logloss: 0.286602\n",
      "[9913]\ttraining's binary_logloss: 0.286569\n",
      "[9914]\ttraining's binary_logloss: 0.286541\n",
      "[9915]\ttraining's binary_logloss: 0.286518\n",
      "[9916]\ttraining's binary_logloss: 0.286493\n",
      "[9917]\ttraining's binary_logloss: 0.286473\n",
      "[9918]\ttraining's binary_logloss: 0.28645\n",
      "[9919]\ttraining's binary_logloss: 0.286427\n",
      "[9920]\ttraining's binary_logloss: 0.28639\n",
      "[9921]\ttraining's binary_logloss: 0.286366\n",
      "[9922]\ttraining's binary_logloss: 0.286333\n",
      "[9923]\ttraining's binary_logloss: 0.286309\n",
      "[9924]\ttraining's binary_logloss: 0.286289\n",
      "[9925]\ttraining's binary_logloss: 0.286267\n",
      "[9926]\ttraining's binary_logloss: 0.286243\n",
      "[9927]\ttraining's binary_logloss: 0.286226\n",
      "[9928]\ttraining's binary_logloss: 0.286204\n",
      "[9929]\ttraining's binary_logloss: 0.286177\n",
      "[9930]\ttraining's binary_logloss: 0.28616\n",
      "[9931]\ttraining's binary_logloss: 0.286133\n",
      "[9932]\ttraining's binary_logloss: 0.2861\n",
      "[9933]\ttraining's binary_logloss: 0.286069\n",
      "[9934]\ttraining's binary_logloss: 0.286036\n",
      "[9935]\ttraining's binary_logloss: 0.286009\n",
      "[9936]\ttraining's binary_logloss: 0.285986\n",
      "[9937]\ttraining's binary_logloss: 0.285965\n",
      "[9938]\ttraining's binary_logloss: 0.285928\n",
      "[9939]\ttraining's binary_logloss: 0.2859\n",
      "[9940]\ttraining's binary_logloss: 0.285855\n",
      "[9941]\ttraining's binary_logloss: 0.285832\n",
      "[9942]\ttraining's binary_logloss: 0.285811\n",
      "[9943]\ttraining's binary_logloss: 0.285788\n",
      "[9944]\ttraining's binary_logloss: 0.285754\n",
      "[9945]\ttraining's binary_logloss: 0.285736\n",
      "[9946]\ttraining's binary_logloss: 0.285706\n",
      "[9947]\ttraining's binary_logloss: 0.285686\n",
      "[9948]\ttraining's binary_logloss: 0.285654\n",
      "[9949]\ttraining's binary_logloss: 0.285636\n",
      "[9950]\ttraining's binary_logloss: 0.28561\n",
      "[9951]\ttraining's binary_logloss: 0.285572\n",
      "[9952]\ttraining's binary_logloss: 0.28555\n",
      "[9953]\ttraining's binary_logloss: 0.285526\n",
      "[9954]\ttraining's binary_logloss: 0.285505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9955]\ttraining's binary_logloss: 0.285475\n",
      "[9956]\ttraining's binary_logloss: 0.285452\n",
      "[9957]\ttraining's binary_logloss: 0.285427\n",
      "[9958]\ttraining's binary_logloss: 0.285397\n",
      "[9959]\ttraining's binary_logloss: 0.285362\n",
      "[9960]\ttraining's binary_logloss: 0.285327\n",
      "[9961]\ttraining's binary_logloss: 0.285298\n",
      "[9962]\ttraining's binary_logloss: 0.285273\n",
      "[9963]\ttraining's binary_logloss: 0.285254\n",
      "[9964]\ttraining's binary_logloss: 0.285232\n",
      "[9965]\ttraining's binary_logloss: 0.285204\n",
      "[9966]\ttraining's binary_logloss: 0.285169\n",
      "[9967]\ttraining's binary_logloss: 0.285141\n",
      "[9968]\ttraining's binary_logloss: 0.285116\n",
      "[9969]\ttraining's binary_logloss: 0.285084\n",
      "[9970]\ttraining's binary_logloss: 0.285061\n",
      "[9971]\ttraining's binary_logloss: 0.285034\n",
      "[9972]\ttraining's binary_logloss: 0.284992\n",
      "[9973]\ttraining's binary_logloss: 0.284962\n",
      "[9974]\ttraining's binary_logloss: 0.284942\n",
      "[9975]\ttraining's binary_logloss: 0.284911\n",
      "[9976]\ttraining's binary_logloss: 0.284888\n",
      "[9977]\ttraining's binary_logloss: 0.28486\n",
      "[9978]\ttraining's binary_logloss: 0.284837\n",
      "[9979]\ttraining's binary_logloss: 0.284804\n",
      "[9980]\ttraining's binary_logloss: 0.284781\n",
      "[9981]\ttraining's binary_logloss: 0.284763\n",
      "[9982]\ttraining's binary_logloss: 0.284733\n",
      "[9983]\ttraining's binary_logloss: 0.284703\n",
      "[9984]\ttraining's binary_logloss: 0.284677\n",
      "[9985]\ttraining's binary_logloss: 0.284655\n",
      "[9986]\ttraining's binary_logloss: 0.28463\n",
      "[9987]\ttraining's binary_logloss: 0.284611\n",
      "[9988]\ttraining's binary_logloss: 0.28458\n",
      "[9989]\ttraining's binary_logloss: 0.284561\n",
      "[9990]\ttraining's binary_logloss: 0.284541\n",
      "[9991]\ttraining's binary_logloss: 0.284507\n",
      "[9992]\ttraining's binary_logloss: 0.284478\n",
      "[9993]\ttraining's binary_logloss: 0.284453\n",
      "[9994]\ttraining's binary_logloss: 0.28443\n",
      "[9995]\ttraining's binary_logloss: 0.284399\n",
      "[9996]\ttraining's binary_logloss: 0.284374\n",
      "[9997]\ttraining's binary_logloss: 0.284351\n",
      "[9998]\ttraining's binary_logloss: 0.284322\n",
      "[9999]\ttraining's binary_logloss: 0.284292\n",
      "[10000]\ttraining's binary_logloss: 0.284251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialiser le modèle avec les poids de classe\n",
    "clf = lgb.LGBMClassifier(\n",
    "    nthread=4,\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=34,\n",
    "    colsample_bytree=0.9497036,\n",
    "    subsample=0.8715623,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.041545473,\n",
    "    reg_lambda=0.0735294,\n",
    "    min_split_gain=0.0222415,\n",
    "    min_child_weight=39.3259775,\n",
    "    silent=-1,\n",
    "    class_weight='balanced',\n",
    "    is_unbalance= True\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric='f1')\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "predictions = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "acc6875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test: 0.8319367967440746\n"
     ]
    }
   ],
   "source": [
    "# Calculer le score F1\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"Score F1 sur l'ensemble de test: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c303ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[2072 1404]\n",
      " [   0 3475]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7cddcc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Initialiser les listes pour stocker les résultats\n",
    "threshold_array = np.linspace(0, 1, 100)\n",
    "f1_list = []\n",
    "\n",
    "# Calculer le F1 pour différents seuils\n",
    "for threshold in threshold_array:\n",
    "    # Labels prédits pour un seuil donné\n",
    "    label_pred_threshold = (probas_pred > threshold).astype(int)\n",
    "    # Calcul du f1 pour un seuil donné\n",
    "    f1_threshold = f1_score(\n",
    "        y_true=y_test, y_pred=label_pred_threshold\n",
    "    )\n",
    "\n",
    "    f1_list.append(f1_threshold)\n",
    "\n",
    "# Trouver l'indice du maximum de la liste des scores F1\n",
    "best_threshold_index = np.argmax(f1_list)\n",
    "\n",
    "# Récupérer le seuil correspondant\n",
    "best_threshold = threshold_array[best_threshold_index]\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.plot(threshold_array, f1_list)\n",
    "plt.xlabel('Seuil')\n",
    "plt.ylabel('Score F1')\n",
    "plt.title('Score F1 en fonction du seuil')\n",
    "plt.scatter(best_threshold, f1_list[best_threshold_index], color='red', label=f'Max F1 at threshold {best_threshold:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Utiliser le seuil optimal pour les prédictions\n",
    "optimal_predictions = (probas_pred > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c394c095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché avec le seuil optimal: 0.2688028482421006\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_with_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1] > best_threshold).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_with_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché avec le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6f4abc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[40291  2111]\n",
      " [ 2818   906]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_hide_test, predictions_with_optimal_threshold)\n",
    "print(\"Matrice de confusion:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b0abb7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 sur l'ensemble de test caché sans le seuil optimal: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble de test avec le seuil optimal\n",
    "predictions_without_optimal_threshold = (clf.predict_proba(X_hide_test)[:, 1]).astype(int)\n",
    "\n",
    "# Calculer le score F1 avec le seuil optimal\n",
    "f1_optimal = f1_score(y_hide_test, predictions_without_optimal_threshold)\n",
    "\n",
    "print(f\"Score F1 sur l'ensemble de test caché sans le seuil optimal: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013803aa",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e33671a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call fit before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sub_preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Créer un DataFrame final avec 'SK_ID_CURR' et les prédictions\u001b[39;00m\n\u001b[1;32m      4\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSK_ID_CURR\u001b[39m\u001b[38;5;124m'\u001b[39m: df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSK_ID_CURR\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m: sub_preds})\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:997\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, raw_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, start_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    995\u001b[0m                   pred_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pred_contrib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 997\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[1;32m    999\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1000\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1001\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/sklearn.py:795\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[0;32m--> 795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[1;32m    797\u001b[0m     X \u001b[38;5;241m=\u001b[39m _LGBMCheckArray(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call fit before exploiting the model."
     ]
    }
   ],
   "source": [
    "sub_preds = clf.predict_proba(df_test[feats])[:, 1]\n",
    "\n",
    "# Créer un DataFrame final avec 'SK_ID_CURR' et les prédictions\n",
    "submission_df = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], 'TARGET': sub_preds})\n",
    "\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
